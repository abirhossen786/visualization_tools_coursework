FN Clarivate Analytics Web of Science
VR 1.0
PT C
AU Rawal, A
   Rawat, DB
   Sadler, B
AF Rawal, Atul
   Rawat, Danda B.
   Sadler, Brian
BE Pham, T
   Solomon, L
TI Recent Advances in Adversarial Machine Learning: Status, Challenges and
   Perspectives
SO ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING FOR MULTI-DOMAIN OPERATIONS
   APPLICATIONS III
SE Proceedings of SPIE
LA English
DT Proceedings Paper
CT Conference on Artificial Intelligence and Machine Learning for
   Multi-Domain Operations Applications III
CY APR 12-16, 2021
CL ELECTR NETWORK
SP SPIE
DE Adversarial Machine Learning; Machine Learning; Cybersecurity; Attack
   Classification; Attack Taxonomy
ID SECURITY
AB The recent advances in machine learning (ML) and Artificial Intelligence (AI) have resulted in widespread application of data-driven learning algorithms. Rapid growth of AI/ML and their penetration within a plethora of civilian and military applications, while successful, has also opened new vulnerabilities. It is now clear that ML algorithms for AI systems are viable targets for malicious attacks. Therefore, there is a pressing need for better understanding of adversarial attacks against ML models, in order to secure them against such malicious attacks. In this paper, we present a survey of adversarial machine learning and some associated countermeasures. We also present a taxonomy of ML/AI system attacks that follow the same properties and characteristics, allowing them to be linked with different defensive approaches. A taxonomy is given for both attack and defense, and attacks proposed in the literature are categorized according to our taxonomy.
C1 [Rawal, Atul; Rawat, Danda B.] Howard Univ, Ctr Excellence AI ML CoE AI ML, Dept Elect Engn & Comp Sci, Washington, DC 20059 USA.
   [Sadler, Brian] US Army, Res Lab, Adelphi, MD USA.
RP Rawal, A (corresponding author), Howard Univ, Ctr Excellence AI ML CoE AI ML, Dept Elect Engn & Comp Sci, Washington, DC 20059 USA.
EM atul.rawal@bison.howard.edu; danda.rawat@howard.edu;
   brian.m.sadler6.civ@mail.mil
RI Rawat, Danda B./B-2973-2012
OI Rawat, Danda B./0000-0003-3638-3464; Rawal, Atul/0000-0003-3443-693X
FU DoD Center of Excellence in AI and Machine Learning (CoE-AIML) at Howard
   University [W911NF-20-2-0277]; U.S. Army Research LaboratoryUnited
   States Department of DefenseUS Army Research Laboratory (ARL)
FX This work was supported in part by the DoD Center of Excellence in AI
   and Machine Learning (CoE-AIML) at Howard University under Contract
   Number W911NF-20-2-0277 with the U.S. Army Research Laboratory.
NR 75
TC 1
Z9 1
U1 134
U2 134
PU SPIE-INT SOC OPTICAL ENGINEERING
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA
SN 0277-786X
EI 1996-756X
BN 978-1-5106-4330-7
J9 PROC SPIE
PY 2021
VL 11746
AR 117462Q
DI 10.1117/12.2583970
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA BS2PQ
UT WOS:000705912400064
DA 2022-04-17
ER

PT J
AU Hagendorff, T
AF Hagendorff, Thilo
TI Linking Human And Machine Behavior: A New Approach to Evaluate Training
   Data Quality for Beneficial Machine Learning
SO MINDS AND MACHINES
LA English
DT Article
DE Artificial intelligence; Machine learning; Machine behavior; Technology
   ethics; Training data; Data quality
ID BIG DATA; DRIVING BEHAVIOR; SOCIAL MEDIA; PERSONALITY; TRAITS; SAFETY;
   MODEL
AB Machine behavior that is based on learning algorithms can be significantly influenced by the exposure to data of different qualities. Up to now, those qualities are solely measured in technical terms, but not in ethical ones, despite the significant role of training and annotation data in supervised machine learning. This is the first study to fill this gap by describing new dimensions of data quality for supervised machine learning applications. Based on the rationale that different social and psychological backgrounds of individuals correlate in practice with different modes of human-computer-interaction, the paper describes from an ethical perspective how varying qualities of behavioral data that individuals leave behind while using digital technologies have socially relevant ramification for the development of machine learning applications. The specific objective of this study is to describe how training data can be selected according to ethical assessments of the behavior it originates from, establishing an innovative filter regime to transition from the big data rationale n = all to a more selective way of processing data for training sets in machine learning. The overarching aim of this research is to promote methods for achieving beneficial machine learning applications that could be widely useful for industry as well as academia.
C1 [Hagendorff, Thilo] Univ Tubingen, Cluster Excellence Machine Learning New Perspect, Tubingen, Germany.
RP Hagendorff, T (corresponding author), Univ Tubingen, Cluster Excellence Machine Learning New Perspect, Tubingen, Germany.
EM thilo.hagendorff@uni-tuebingen.de
FU Cluster of Excellence "Machine Learning -New Perspectives for Science -
   Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under
   Germany's Excellence StrategyGerman Research Foundation (DFG)
   [390727645, EXC 2064/1]
FX This research was supported by the Cluster of Excellence "Machine
   Learning -New Perspectives for Science" funded by the Deutsche
   Forschungsgemeinschaft (DFG, German Research Foundation) under Germany's
   Excellence Strategy-Reference Number EXC 2064/1-Project ID 390727645. I
   would like to thank Sarah Fabi, Zeynep Akata, Ulrike von Luxburg, and
   Sebastian Bordt for very helpful comments on the manuscript.
NR 167
TC 0
Z9 0
U1 151
U2 163
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-6495
EI 1572-8641
J9 MIND MACH
JI Minds Mach.
PD DEC
PY 2021
VL 31
IS 4
SI SI
BP 563
EP 593
DI 10.1007/s11023-021-09573-8
EA SEP 2021
PG 31
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XO4ZS
UT WOS:000699886300001
PM 34602749
OA Green Published, hybrid, Green Submitted
DA 2022-04-17
ER

PT C
AU Umamahesan, A
   Babu, DMI
AF Umamahesan, Aniththa
   Babu, Deepak Mukunthu Iyappan
GP ASSOC COMP MACHINERY
TI From Zero to AI Hero with Automated Machine Learning
SO KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON
   KNOWLEDGE DISCOVERY & DATA MINING
LA English
DT Proceedings Paper
CT 26th ACM SIGKDD International Conference on Knowledge Discovery and Data
   Mining (KDD)
CY AUG 23-27, 2020
CL ELECTR NETWORK
SP Assoc Comp Machinery, ACM SIGMOD, ACM SIGKDD
DE Azure Machine Learning; AutoML; Machine Learning; AI
AB Automated ML is an emerging field in Machine Learning that helps developers and new data scientists with little data science knowledge build Machine Learning models and solutions without understanding the complexity of Learning Algorithm selection, and Hyper parameter tuning. With Azure Machine Learning's automated machine learning capability, given a dataset and a few configuration parameters, you will get a trained high quality machine learning model for the dataset that you can use for predictions. In this session, you will learn how to use Automated ML for productivity gains, empowering domain experts to build ML based solutions and scale to build several models with Azure Machine Learning's Automated ML.
C1 [Umamahesan, Aniththa; Babu, Deepak Mukunthu Iyappan] Microsoft, Azure Machine Learning, Redmond, WA 98052 USA.
RP Babu, DMI (corresponding author), Microsoft, Azure Machine Learning, Redmond, WA 98052 USA.
EM askautomatedml@microsoft.com
NR 0
TC 2
Z9 2
U1 19
U2 22
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-7998-4
PY 2020
BP 3495
EP 3495
DI 10.1145/3394486.3406697
PG 1
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS6LS
UT WOS:000749552303052
DA 2022-04-17
ER

PT J
AU Guan, W
   Perdue, G
   Pesah, A
   Schuld, M
   Terashi, K
   Vallecorsa, S
   Vlimant, JR
AF Guan, Wen
   Perdue, Gabriel
   Pesah, Arthur
   Schuld, Maria
   Terashi, Koji
   Vallecorsa, Sofia
   Vlimant, Jean-Roch
TI Quantum machine learning in high energy physics
SO MACHINE LEARNING-SCIENCE AND TECHNOLOGY
LA English
DT Review
DE particle physics; quantum machine learning; quantum annealing; quantum
   circuit; quantum variational circuit
ID OPTIMIZATION
AB Machine learning has been used in high energy physics (HEP) for a long time, primarily at the analysis level with supervised classification. Quantum computing was postulated in the early 1980s as way to perform computations that would not be tractable with a classical computer. With the advent of noisy intermediate-scale quantum computing devices, more quantum algorithms are being developed with the aim at exploiting the capacity of the hardware for machine learning applications. An interesting question is whether there are ways to apply quantum machine learning to HEP. This paper reviews the first generation of ideas that use quantum machine learning on problems in HEP and provide an outlook on future applications.
C1 [Guan, Wen] Univ Wisconsin, Madison, WI 53706 USA.
   [Perdue, Gabriel] Fermilab Quantum Inst, Fermi Natl Accelerator Lab, POB 500, Batavia, IL 60510 USA.
   [Pesah, Arthur] Tech Univ Denmark, DTU Compute, Lyngby, Denmark.
   [Schuld, Maria] Univ KwaZulu Natal, Sch Chem & Phys, ZA-4000 Durban, South Africa.
   [Terashi, Koji] Univ Tokyo, ICEPP, Bunkyo Ku, 7-3-1 Hongo, Tokyo, JP 3001153, Japan.
   [Vallecorsa, Sofia] CERN IT, 1 Esplanade Particules, CH-1211 Geneva, Switzerland.
   [Vlimant, Jean-Roch] CALTECH, PMA, Pasadena, CA 91125 USA.
RP Vlimant, JR (corresponding author), CALTECH, PMA, Pasadena, CA 91125 USA.
EM jvlimant@caltech.edu
OI Vallecorsa, Sofia/0000-0002-7003-5765; Perdue,
   Gabriel/0000-0001-6785-8720; Pesah, Arthur/0000-0002-5759-6314
FU DOE/HEP QuantISED program; Quantum Machine Learning and Quantum
   Computation Frameworks (QMLQCF) [DE-SC0019227]; Big Data and Informatics
   Flagship; BDSS initiative of the University of KwaZulu-Natal; DOE/HEP
   QuantISED program grant HEP Machine Learning and Optimization Go Quantum
   [0000240323]; Fermi Research Alliance, LLC [DE-AC02-07CH11359]; U.S.
   Department of Energy, Office of Science, Office of High Energy
   PhysicsUnited States Department of Energy (DOE);  [DE-SC0020416]
FX The authors wish to thank Alexander Zlokapa, Joshua Job, Cenk Tuysuz and
   Shaojun Sun for sharing material reproduced here.; JRV is partially
   supported by DOE/HEP QuantISED program grant, Quantum Machine Learning
   and Quantum Computation Frameworks (QMLQCF) for HEP, award number
   DE-SC0019227. MS acknowledges support by the Big Data and Informatics
   Flagship and BDSS initiative of the University of KwaZulu-Natal. WG is
   partially supported by DOE/HEP QuantISED program grant, Application of
   Quantum Machine Learning to High Energy Physics Analysis at the LHC
   using IBM Quantum Computer Simulator and Hardware, award number
   DE-SC0020416. GP is partially supported by the DOE/HEP QuantISED program
   grant HEP Machine Learning and Optimization Go Quantum, identification
   number 0000240323. This manuscript has been authored by Fermi Research
   Alliance, LLC under Contract No. DE-AC02-07CH11359 with the U.S.
   Department of Energy, Office of Science, Office of High Energy Physics.;
   Data sharing is not applicable to this article as no new data were
   created or analysed in this study.
NR 108
TC 6
Z9 6
U1 46
U2 72
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
EI 2632-2153
J9 MACH LEARN-SCI TECHN
JI Mach. Learn.-Sci. Technol.
PD MAR
PY 2021
VL 2
IS 1
AR 011003
DI 10.1088/2632-2153/abc17d
PG 17
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Science & Technology - Other Topics
GA SQ6YW
UT WOS:000660500300003
OA gold, Green Submitted
DA 2022-04-17
ER

PT C
AU Ramesh, RK
   Wang, HY
   Shen, HY
   Fan, ZM
AF Ramesh, Rakshita Kaulgud
   Wang, Haoyu
   Shen, Haiying
   Fan, Zhiming
BE Lefevre, L
   Patterson, S
   Lee, YC
   Shen, H
   Ilager, S
   Goudarzi, M
   Toosi, AN
   Buyya, R
TI Machine Learning for Load Balancing in Cloud Datacenters
SO 21ST IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND INTERNET
   COMPUTING (CCGRID 2021)
LA English
DT Proceedings Paper
CT 21st IEEE/ACM International Symposium on Cluster, Cloud and Internet
   Computing (CCGrid)
CY MAY 10-13, 2021
CL ELECTR NETWORK
SP IEEE, Assoc Comp Machinery, IEEE Comp Soc, IEEE Tech Comm Scalable Comp
DE Load balancing; Cloud computing; Reinforcement learning; Virtual machine
ID VIRTUAL MACHINES
AB In the cloud datacenter, the resource utilization of different virtual machine (VM) and physical machine (PM) varies with time and it may lead to SLO violation and then degrade the application performance. In order to minimize the probability of SLO violation, load balancing is used to dynamically migrate VMs from overloaded PMs to underloaded PMs. Previous load balancing methods fail to achieve long term load balance. To address this problem, in this paper, we propose different load balancing methods and evaluate their performance on several metrics. We use the Fast Fourier Transform (FFT) method, an improved FFT method considering more frequencies in FFT and the long short term memory (LSTM) machine learning model to predict the resource utilization of VM and PM in the future. LSTM can always achieve the best prediction performance in the prediction. Taking advantage of the ML technique, we then propose a heuristic based method and a reinforcement learning (RL) based method relying on ML workload prediction to generate the VM migration plan in the datacenter. We conduct experiments in both trace-driven simulation (based on Google cluster trace, PlanetLab trace, Worldcup trace) and real implementation in terms of the SLO violation rate, the number of migrations and overhead. The experimental results show that the workload prediction helps reduce the SLO violation rate and/or the number of migrations, which improves the load balance performance in a datacenter. Also, the RL based VM migration method outperforms the heuristic based method in a heavily loaded system but does not show obvious advantages in a lightly loaded system.
C1 [Ramesh, Rakshita Kaulgud; Wang, Haoyu; Shen, Haiying; Fan, Zhiming] Univ Virginia, Dept Comp Sci, Charlottesville, VA 22903 USA.
RP Ramesh, RK (corresponding author), Univ Virginia, Dept Comp Sci, Charlottesville, VA 22903 USA.
EM rrk7pb@virginia.edu; hw8c@virginia.edu; hs6ms@virginia.edu;
   zf7ja@virginia.edu
FU U.S. NSFNational Science Foundation (NSF) [NSF-1827674, CCF-1822965];
   Microsoft Research Faculty Fellowship [8300751]; AWS Machine Learning
   Research Awards
FX This research was supported in part by U.S. NSF grants NSF-1827674,
   CCF-1822965 and Microsoft Research Faculty Fellowship 8300751, and AWS
   Machine Learning Research Awards.
NR 29
TC 0
Z9 0
U1 11
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
BN 978-1-7281-9586-5
PY 2021
BP 186
EP 195
DI 10.1109/CCGrid51090.2021.00028
PG 10
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS2NH
UT WOS:000703983200019
DA 2022-04-17
ER

PT J
AU Bone, JM
   Childs, CM
   Menon, A
   Poczos, B
   Feinberg, AW
   LeDuc, PR
   Washburn, NR
AF Bone, Jennifer M.
   Childs, Christopher M.
   Menon, Aditya
   Poczos, Barnabas
   Feinberg, Adam W.
   LeDuc, Philip R.
   Washburn, Newell R.
TI Hierarchical Machine Learning for High-Fidelity 3D Printed Biopolymers
SO ACS BIOMATERIALS SCIENCE & ENGINEERING
LA English
DT Article
DE machine learning; bioprinting; LASSO; hydrogel
ID DESIGN; MODELS
AB A hierarchical machine learning (HML) framework is presented that uses a small dataset to learn and predict the dominant build parameters necessary to print high-fidelity 3D features of alginate hydrogels. We examine the 3D printing of soft hydrogel forms printed with the freeform reversible embedding of suspended hydrogel method based on a CAD file that isolated the single-strand diameter and shape fidelity of printed alginate. Combinations of system variables ranging from print speed, flow rate, ink concentration to nozzle diameter were systematically varied to generate a small dataset of 48 prints. Prints were imaged and scored according to their dimensional similarity to the CAD file, and high print fidelity was defined as prints with less than 10% error from the CAD file. As a part of the HML framework, statistical inference was performed, using the least absolute shrinkage and selection operator to find the dominant variables that drive the error in the final prints. Model fit between the system parameters and print score was elucidated and improved by a parameterized middle layer of variable relationships which showed good performance between the predicted and observed data (R-2 = 0.643). Optimization allowed for the prediction of build parameters that gave rise to high-fidelity prints of the measured features. A trade-off was identified when optimizing for the fidelity of different features printed within the same construct, showing the need for complex predictive design tools. A combination of known and discovered relationships was used to generate process maps for the 3D bioprinting designer that show error minimums based on the chosen input variables. Our approach offers a promising pathway toward scaling 3D bioprinting by optimizing print fidelity via learned build parameters that reduce the need for iterative testing.
C1 [Bone, Jennifer M.; Feinberg, Adam W.; Washburn, Newell R.] Carnegie Mellon Univ, Dept Biomed Engn, Pittsburgh, PA 15213 USA.
   [Childs, Christopher M.; Washburn, Newell R.] Carnegie Mellon Univ, Dept Chem, Pittsburgh, PA 15213 USA.
   [Menon, Aditya; Feinberg, Adam W.] Carnegie Mellon Univ, Dept Mat Sci & Engn, Pittsburgh, PA 15213 USA.
   [Poczos, Barnabas] Carnegie Mellon Univ, Machine Learning Dept, Pittsburgh, PA 15213 USA.
   [LeDuc, Philip R.] Carnegie Mellon Univ, Dept Mech Engn, Pittsburgh, PA 15213 USA.
RP Washburn, NR (corresponding author), Carnegie Mellon Univ, Dept Biomed Engn, Pittsburgh, PA 15213 USA.; Washburn, NR (corresponding author), Carnegie Mellon Univ, Dept Chem, Pittsburgh, PA 15213 USA.
EM washburn@andrew.cmu.edu
RI Hudson, Andrew/ABC-1122-2021; Feinberg, Adam W/AAM-8547-2020
OI Feinberg, Adam W/0000-0003-3338-5456; Childs,
   Christopher/0000-0001-8739-5997; Washburn, Newell/0000-0001-7843-8860
FU Center for Machine Learning and Health (CMLH) at Carnegie Mellon
   University
FX This work was supported by the Center for Machine Learning and Health
   (CMLH) at Carnegie Mellon University.
NR 30
TC 5
Z9 5
U1 38
U2 70
PU AMER CHEMICAL SOC
PI WASHINGTON
PA 1155 16TH ST, NW, WASHINGTON, DC 20036 USA
SN 2373-9878
J9 ACS BIOMATER SCI ENG
JI ACS Biomater. Sci. Eng.
PD DEC
PY 2020
VL 6
IS 12
BP 7021
EP 7031
DI 10.1021/acsbiomaterials.0c00755
PG 11
WC Materials Science, Biomaterials
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Materials Science
GA PG8OY
UT WOS:000599989300047
PM 33320614
DA 2022-04-17
ER

PT C
AU Perrier, E
AF Perrier, Elija
GP ASSOC COMP MACHINERY
TI Quantum Fair Machine Learning
SO AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND
   SOCIETY
LA English
DT Proceedings Paper
CT 4th AAAI/ACM Conference on AI, Ethics, and Society (AIES)
CY MAY 19-21, 2021
CL ELECTR NETWORK
SP AAAI, Assoc Comp Machinery, ACM SIGAI
DE quantum computing; fair machine learning
AB In this paper, we inaugurate the field of quantum fair machine learning. We undertake a comparative analysis of differences and similarities between classical and quantum fair machine learning algorithms, specifying how the unique features of quantum computation alter measures, metrics and remediation strategies when quantum algorithms are subject to fairness constraints. We present the first results in quantum fair machine learning by demonstrating the use of Grover's search algorithm to satisfy statistical parity constraints imposed on quantum algorithms. We provide lower-bounds on iterations needed to achieve such statistical parity within c-tolerance. We extend canonical Lipschitz-conditioned individual fairness criteria to the quantum setting using quantum metrics. We examine the consequences for typical measures of fairness in machine learning context when quantum information processing and quantum data are involved. Finally, we propose open questions and research programmes for this new field of interest to researchers in computer science, ethics and quantum computation.
C1 [Perrier, Elija] Univ Technol, Ctr Quantum Software & Informat, Sydney, NSW, Australia.
   [Perrier, Elija] Australian Natl Univ, Humanising Machine Intelligence, Acton, ACT, Australia.
RP Perrier, E (corresponding author), Univ Technol, Ctr Quantum Software & Informat, Sydney, NSW, Australia.; Perrier, E (corresponding author), Australian Natl Univ, Humanising Machine Intelligence, Acton, ACT, Australia.
EM elija.t.perrier@student.uts.edu.au
NR 29
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-8473-5
PY 2021
BP 843
EP 853
DI 10.1145/3461702.3462611
PG 11
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS7UX
UT WOS:000767973400094
OA Green Submitted
DA 2022-04-17
ER

PT C
AU Tegen, A
   Davidsson, P
   Persson, JA
AF Tegen, Agnes
   Davidsson, Paul
   Persson, Jan A.
BE Hutter, F
   Kersting, K
   Lijffijt, J
   Valera, I
TI A Taxonomy of Interactive Online Machine Learning Strategies
SO MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES, ECML PKDD 2020,
   PT II
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT European Conference on Machine Learning and Principles and Practice of
   Knowledge Discovery in Databases (ECML PKDD)
CY SEP 14-18, 2020
CL ELECTR NETWORK
SP Fraunhofer IAIS, ASML, F Secure, Roche, Amazon, Science, EURA NOVA, Google, NEC, Internet & Data Lab, KNIME, Qualcomm, AI Res, imec, FWO, Ghent Univ, Springer, Visitgent, gentcongres, AI Growth
DE Interactive machine learning; Online learning; Active learning
AB In interactive machine learning, human users and learning algorithms work together in order to solve challenging learning problems, e.g. with limited or no annotated data or trust issues. As annotating data can be costly, it is important to minimize the amount of annotated data needed for training while still getting a high classification accuracy. This is done by attempting to select the most informative data instances for training, where the amount of instances is limited by a labelling budget. In an online learning setting, the decision of whether or not to select an instance for labelling has to be done on-the-fly, as the data arrives in a sequential order and is only valid for a limited time period. We present a taxonomy of interactive online machine learning strategies. An interactive learning strategy determines which instances to label in an unlabelled dataset. In the taxonomy we differentiate between interactive learning strategies when the computer controls the learning process (active learning) and those when human users control the learning process (machine teaching). We then make a distinction between what triggers the learning: active learning could be triggered by uncertainty, time, or randomly, whereas machine teaching could be triggered by errors, state changes, time, or factors related to the user. We also illustrate the taxonomy by implementing versions of the different strategies and performing experiments on a benchmark dataset as well as on a synthetically generated dataset. The results show that the choice of interactive learning strategy affects performance, especially in the beginning of the online learning process, when there is a limited amount of labelled data.
C1 [Tegen, Agnes; Davidsson, Paul; Persson, Jan A.] Malmo Univ, Internet Things & People Res Ctr, Dept Comp Sci & Media Technol, Malmo, Sweden.
RP Tegen, A (corresponding author), Malmo Univ, Internet Things & People Res Ctr, Dept Comp Sci & Media Technol, Malmo, Sweden.
EM agnes.tegen@mau.se
NR 20
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-67661-2; 978-3-030-67660-5
J9 LECT NOTES ARTIF INT
PY 2021
VL 12458
BP 137
EP 153
DI 10.1007/978-3-030-67661-2_9
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Mathematics, Applied
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Mathematics
GA BS4DH
UT WOS:000717542900009
DA 2022-04-17
ER

PT C
AU Mosqueira-Rey, E
   Alonso-Rios, D
   Baamonde-Lozano, A
AF Mosqueira-Rey, Eduardo
   Alonso-Rios, David
   Baamonde-Lozano, Andres
BE Watrobski, J
   Salabun, W
   Toro, C
   Zanni-Merk, C
   Howlett, RJ
   Jain, LC
TI Integrating Iterative Machine Teaching and Active Learning into the
   Machine Learning Loop
SO KNOWLEDGE-BASED AND INTELLIGENT INFORMATION & ENGINEERING SYSTEMS (KSE
   2021)
SE Procedia Computer Science
LA English
DT Proceedings Paper
CT 25th KES International Conference on Knowledge-Based and Intelligent
   Information & Engineering Systems (KES)
CY SEP 08-10, 2021
CL Szczecin, POLAND
SP KES Int
DE Iterative Machine Teaching; Active Learning; Machine Learning;
   Human-in-the-Loop Machine Learning
AB Scholars and practitioners are defining new types of interactions between humans and machine learning algorithms that we can group under the umbrella term of Human-in-the-Loop Machine Learning (HITL-ML). This paper is focused on implementing two approaches to this topic-Iterative Machine Teaching (iMT) and Active Learning (AL)-and analyzing how to integrate them in the learning loop. iMT is a variation of Machine Teaching in which a machine acts as a teacher that tries to transfer knowledge to a machine learning model. The focus of the problem in iMT is how to obtain the optimal training set given a machine learning algorithm and a target model. The idea is to learn a target concept with a minimal number of iterations with the smallest dataset. Active Learning, in contrast, is a specialized type of supervised learning in which humans are incorporated in the loop to act as oracles that analyze unlabeled data. AL allows us to achieve greater accuracy with less data and less training. Our proposal to incorporate iMT and AL into the machine learning loop is to use iMT as a technique to obtain the "Minimum Viable Data (MVD)" for training a learning model, that is, a dataset that allows us to increase speed and reduce complexity in the learning process by allowing to build early prototypes. Next, we will use AL to refine this first prototype by adding new data in an iterative and incremental way. We carried out several experiments to test the feasibility of our proposed approach. They show that the algorithms trained with the teachers converge faster than those that have been trained in a conventional way. Also, AL helps the model to avoid getting stuck and to keep improving after the first few iterations. The two approaches investigated in this paper can be considered complementary, as they correspond to different stages in the learning process. (C) 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (https://crativecommons.org/licenses/by-nc-nd/4.0) Peer-review under responsibility of the scientific committee of KES International.
C1 [Mosqueira-Rey, Eduardo; Alonso-Rios, David; Baamonde-Lozano, Andres] Univ A Coruna, Ctr Invest TIC CITIC, Elvina 15071, A Coruna, Spain.
RP Mosqueira-Rey, E (corresponding author), Univ A Coruna, Ctr Invest TIC CITIC, Elvina 15071, A Coruna, Spain.
EM eduardo@udc.es
RI Alonso Ríos, David/H-9793-2014
OI Alonso Ríos, David/0000-0003-2147-3010
FU State Research Agency of the Spanish Government [PD2019-107194GB-I00/
   AEI/ 10.13039/501100011033]; Xunta de GaliciaXunta de GaliciaEuropean
   Commission [ED431C 2018/34]; European Union ERDFEuropean Commission;
   Centro de Investigacion de Galicia "CITIC"; Xunta de GaliciaXunta de
   GaliciaEuropean Commission; European Union (European Regional
   Development Fund- Galicia 2014-2020 Program) [ED431G2019/01]
FX This work has been supported by the State Research Agency of the Spanish
   Government (grant PD2019-107194GB-I00/ AEI/ 10.13039/501100011033) and
   by the Xunta de Galicia (grant ED431C 2018/34) with the European Union
   ERDF funds. We wish to acknowledge the support received from the Centro
   de Investigacion de Galicia "CITIC", funded by Xunta de Galicia and the
   European Union (European Regional Development Fund- Galicia 2014-2020
   Program, grant ED431G2019/01).
NR 31
TC 0
Z9 0
U1 2
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0509
J9 PROCEDIA COMPUT SCI
PY 2021
VL 192
BP 553
EP 562
DI 10.1016/j.procs.2021.08.057
PG 10
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Computer Science, Information Systems; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic; Mathematics, Applied
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Automation & Control Systems; Computer Science; Engineering; Mathematics
GA BS4LU
UT WOS:000720289000056
OA gold, Green Published
DA 2022-04-17
ER

PT J
AU Hensel, F
   Moor, M
   Rieck, B
AF Hensel, Felix
   Moor, Michael
   Rieck, Bastian
TI A Survey of Topological Machine Learning Methods
SO FRONTIERS IN ARTIFICIAL INTELLIGENCE
LA English
DT Review
DE computational topology; persistent homology; machine learning; topology;
   survey; topological machine learning
ID PERSISTENCE
AB The last decade saw an enormous boost in the field of computational topology: methods and concepts from algebraic and differential topology, formerly confined to the realm of pure mathematics, have demonstrated their utility in numerous areas such as computational biology personalised medicine, and time-dependent data analysis, to name a few. The newly-emerging domain comprising topology-based techniques is often referred to as topological data analysis (TDA). Next to their applications in the aforementioned areas, TDA methods have also proven to be effective in supporting, enhancing, and augmenting both classical machine learning and deep learning models. In this paper, we review the state of the art of a nascent field we refer to as "topological machine learning," i.e., the successful symbiosis of topology-based methods and machine learning algorithms, such as deep neural networks. We identify common threads, current applications, and future challenges.
C1 [Hensel, Felix; Moor, Michael; Rieck, Bastian] Swiss Fed Inst Technol, Machine Learning & Computat Biol Lab, Zurich, Switzerland.
   [Hensel, Felix; Moor, Michael; Rieck, Bastian] Swiss Inst Bioinformat, Lausanne, Switzerland.
RP Rieck, B (corresponding author), Swiss Fed Inst Technol, Machine Learning & Computat Biol Lab, Zurich, Switzerland.; Rieck, B (corresponding author), Swiss Inst Bioinformat, Lausanne, Switzerland.
EM bastian.rieck@bsse.ethz.ch
RI Rieck, Bastian/J-7507-2019
OI Rieck, Bastian/0000-0003-4335-0302
FU Swiss National Science FoundationSwiss National Science Foundation
   (SNSF)European Commission [190466]
FX This work was partially funded and supported by the Swiss National
   Science Foundation [Spark grant 190466, FH and BR]. The funders had no
   role in study design, data collection and analysis, decision to publish,
   or preparation of the manuscript.
NR 65
TC 3
Z9 3
U1 5
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2624-8212
J9 FRONT ARTIF INTELL
JI Front. Artif. Intell.
PY 2021
VL 4
AR 681108
DI 10.3389/frai.2021.681108
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YT9WW
UT WOS:000751704800103
PM 34124648
OA gold, Green Published
DA 2022-04-17
ER

PT J
AU Studer, S
   Bui, TB
   Drescher, C
   Hanuschkin, A
   Winkler, L
   Peters, S
   Muller, KR
AF Studer, Stefan
   Bui, Thanh Binh
   Drescher, Christian
   Hanuschkin, Alexander
   Winkler, Ludwig
   Peters, Steven
   Mueller, Klaus-Robert
TI Towards CRISP-ML(Q): A Machine Learning Process Model with Quality
   Assurance Methodology
SO MACHINE LEARNING AND KNOWLEDGE EXTRACTION
LA English
DT Article
DE machine learning applications; quality assurance methodology; process
   model; automotive industry and academia; best practices; guidelines
ID FEATURE-SELECTION; MULTIPLE IMPUTATION; KNOWLEDGE DISCOVERY; NYSTROM
   METHOD; DEEP; CLASSIFICATION; MATRIX; CANCER
AB Machine learning is an established and frequently used technique in industry and academia, but a standard process model to improve success and efficiency of machine learning applications is still missing. Project organizations and machine learning practitioners face manifold challenges and risks when developing machine learning applications and have a need for guidance to meet business expectations. This paper therefore proposes a process model for the development of machine learning applications, covering six phases from defining the scope to maintaining the deployed machine learning application. Business and data understanding are executed simultaneously in the first phase, as both have considerable impact on the feasibility of the project. The next phases are comprised of data preparation, modeling, evaluation, and deployment. Special focus is applied to the last phase, as a model running in changing real-time environments requires close monitoring and maintenance to reduce the risk of performance degradation over time. With each task of the process, this work proposes quality assurance methodology that is suitable to address challenges in machine learning development that are identified in the form of risks. The methodology is drawn from practical experience and scientific literature, and has proven to be general and stable. The process model expands on CRISP-DM, a data mining process model that enjoys strong industry support, but fails to address machine learning specific tasks. The presented work proposes an industry- and application-neutral process model tailored for machine learning applications with a focus on technical tasks for quality assurance.
C1 [Studer, Stefan; Drescher, Christian; Hanuschkin, Alexander; Peters, Steven] Mercedes Benz AG, Grp Res, Artificial Intelligence Res, D-71059 Sindelfingen, Germany.
   [Bui, Thanh Binh; Winkler, Ludwig; Mueller, Klaus-Robert] Tech Univ Berlin, Machine Learning Grp, D-10587 Berlin, Germany.
   [Hanuschkin, Alexander] Esslingen Univ Appl Sci, Dept Comp Sci & Engn, D-73732 Esslingen, Germany.
   [Mueller, Klaus-Robert] Google Res, Brain Team, D-10117 Berlin, Germany.
   [Mueller, Klaus-Robert] Korea Univ, Dept Artificial Intelligence, Seoul 136713, South Korea.
   [Mueller, Klaus-Robert] Max Planck Inst Informat, D-66123 Saarbrucken, Germany.
RP Studer, S (corresponding author), Mercedes Benz AG, Grp Res, Artificial Intelligence Res, D-71059 Sindelfingen, Germany.; Bui, TB (corresponding author), Tech Univ Berlin, Machine Learning Grp, D-10587 Berlin, Germany.
EM stefan.studer@daimler.com; bui@tu-berlin.de
RI Mueller, Klaus-Robert/Y-3547-2019
OI Mueller, Klaus-Robert/0000-0002-3861-7685; Peters,
   Steven/0000-0003-3131-1664; Studer, Stefan/0000-0003-1598-6899
FU German Federal Ministry of Education and Research (BMBF) via project
   AIAx-Machine Learning-driven EngineeringFederal Ministry of Education &
   Research (BMBF) [01IS18048]; BMBFFederal Ministry of Education &
   Research (BMBF) [01IS14013A-E, 01IS18025A, 01IS18037A, 01GQ1115,
   01GQ0850]; Deutsche Forschungsgesellschaft (DFG) under Grant Math+German
   Research Foundation (DFG) [EXC 2046/1, 390685689]; Technology Promotion
   (IITP) - Korea government [2017-0-00451, 2017-0-01779]
FX This research was supported by the German Federal Ministry of Education
   and Research (BMBF) via project AIAx-Machine Learning-driven Engineering
   (Nr. 01IS18048). K.-R.M. acknowledges partial financial support by the
   BMBF under Grants 01IS14013A-E, 01IS18025A, 01IS18037A, 01GQ1115, and
   01GQ0850; Deutsche Forschungsgesellschaft (DFG) under Grant Math+, EXC
   2046/1, Project ID 390685689, and by the Technology Promotion (IITP)
   grant funded by the Korea government (No. 2017-0-00451, No.
   2017-0-01779).
NR 153
TC 6
Z9 6
U1 12
U2 18
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2504-4990
J9 MACH LEARN KNOW EXTR
JI Mach. Learn. Knowl. Extr.
PD JUN
PY 2021
VL 3
IS 2
BP 392
EP 413
DI 10.3390/make3020020
PG 22
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
WE Emerging Sources Citation Index (ESCI)
SC Computer Science; Engineering
GA RW9US
UT WOS:000646865900001
OA Green Submitted, gold
DA 2022-04-17
ER

PT J
AU Cuoco, E
   Powell, J
   Cavaglia, M
   Ackley, K
   Bejger, M
   Chatterjee, C
   Coughlin, M
   Coughlin, S
   Easter, P
   Essick, R
   Gabbard, H
   Gebhard, T
   Ghosh, S
   Haegel, L
   Iess, A
   Keitel, D
   Marka, Z
   Marka, S
   Morawski, F
   Nguyen, T
   Ormiston, R
   Purrer, M
   Razzano, M
   Staats, K
   Vajente, G
   Williams, D
AF Cuoco, Elena
   Powell, Jade
   Cavaglia, Marco
   Ackley, Kendall
   Bejger, Michal
   Chatterjee, Chayan
   Coughlin, Michael
   Coughlin, Scott
   Easter, Paul
   Essick, Reed
   Gabbard, Hunter
   Gebhard, Timothy
   Ghosh, Shaon
   Haegel, Leila
   Iess, Alberto
   Keitel, David
   Marka, Zsuzsa
   Marka, Szabolcs
   Morawski, Filip
   Nguyen, Tri
   Ormiston, Rich
   Puerrer, Michael
   Razzano, Massimiliano
   Staats, Kai
   Vajente, Gabriele
   Williams, Daniel
TI Enhancing gravitational-wave science with machine learning
SO MACHINE LEARNING-SCIENCE AND TECHNOLOGY
LA English
DT Review
DE gravitational waves; machine learning; deep learning
ID CORE-COLLAPSE SUPERNOVAE; ADVANCED LIGO; INFERENCE; MODELS; DEEP; SPIN;
   CLASSIFICATION; SIGNALS; BURSTS; SEARCH
AB Machine learning has emerged as a popular and powerful approach for solving problems in astrophysics. We review applications of machine learning techniques for the analysis of ground-based gravitational-wave (GW) detector data. Examples include techniques for improving the sensitivity of Advanced Laser Interferometer GW Observatory and Advanced Virgo GW searches, methods for fast measurements of the astrophysical parameters of GW sources, and algorithms for reduction and characterization of non-astrophysical detector noise. These applications demonstrate how machine learning techniques may be harnessed to enhance the science that is possible with current and future GW detectors.
C1 [Cuoco, Elena] European Gravitat Observ EGO, I-56021 Pisa, Italy.
   [Cuoco, Elena] Scuola Normale Super SNS, Piazza Cavalieri 7, I-756126 Pisa, Italy.
   [Cuoco, Elena; Razzano, Massimiliano] Ist Nazl Fis Nucl, Sez Pisa, I-56127 Pisa, Italy.
   [Powell, Jade] Swinburne Univ Technol, OzGrav, Melbourne, Vic 3122, Australia.
   [Cavaglia, Marco] Missouri Univ Sci & Technol, Inst Multimessenger Astrophys & Cosmol, 1315 N Pine St, Rolla, MO 65409 USA.
   [Ackley, Kendall; Easter, Paul] Monash Univ, Sch Phys & Astron, Monash, Vic 3800, Australia.
   [Ackley, Kendall; Chatterjee, Chayan; Easter, Paul] OzGrav ARC Ctr Excellence Gravitat Wave Discovery, Clayton, Vic 3800, Australia.
   [Bejger, Michal; Morawski, Filip] Polish Acad Sci, Nicolaus Copernicus Astron Ctr, Bartycka 18, PL-00716 Warsaw, Poland.
   [Chatterjee, Chayan] Univ Western Australia, Dept Phys, 35 Stirling Highway, Perth, WA 6009, Australia.
   [Coughlin, Michael; Vajente, Gabriele] CALTECH, LIGO, Pasadena, CA 91125 USA.
   [Coughlin, Michael] Univ Minnesota, Sch Phys & Astron, Minneapolis, MN 55455 USA.
   [Coughlin, Scott; Staats, Kai] Northwestern Univ, Ctr Interdisciplinary Explorat & Res Astrophys CI, Evanston, IL 60208 USA.
   [Essick, Reed] Univ Chicago, Kavli Inst Cosmol Phys, Chicago, IL 60637 USA.
   [Gabbard, Hunter; Williams, Daniel] Univ Glasgow, SUPA, Glasgow G12 8QQ, Lanark, Scotland.
   [Gebhard, Timothy] Max Planck Inst Intelligent Syst, Max Planck Ring 4, D-72076 Tubingen, Germany.
   [Gebhard, Timothy] Max Planck ETH Ctr Learning Syst, Max Planck Ring 4, D-72076 Tubingen, Germany.
   [Ghosh, Shaon] Montclair State Univ, Montclair, NJ USA.
   [Haegel, Leila] Univ Paris, CNRS, Astroparticule & Cosmol, F-75013 Paris, France.
   [Iess, Alberto] Univ Roma Tor Vergata, I-00133 Rome, Italy.
   [Iess, Alberto] Ist Nazl Fis Nucl, Sez Roma Tor Vergata, I-00133 Rome, Italy.
   [Keitel, David] Univ Illes Balears, IEEC IAC3, E-07122 Palma De Mallorca, Spain.
   [Marka, Zsuzsa] Columbia Univ City New York, Columbia Astrophys Lab, 550 W 120th St, New York, NY 10027 USA.
   [Marka, Szabolcs] Columbia Univ City New York, Dept Phys, 550 W 120th St, New York, NY 10027 USA.
   [Nguyen, Tri] MIT, LIGO, Cambridge, MA 02139 USA.
   [Ormiston, Rich] Univ Minnesota, Minneapolis, MN 55455 USA.
   [Puerrer, Michael] Albert Einstein Inst, Max Planck Inst Gravitat Phys, Muhlenberg 1, D-14476 Potsdam, Germany.
   [Razzano, Massimiliano] Univ Pisa, Dept Phys, I-56127 Pisa, Italy.
RP Cuoco, E (corresponding author), European Gravitat Observ EGO, I-56021 Pisa, Italy.; Cuoco, E (corresponding author), Scuola Normale Super SNS, Piazza Cavalieri 7, I-756126 Pisa, Italy.; Cuoco, E (corresponding author), Ist Nazl Fis Nucl, Sez Pisa, I-56127 Pisa, Italy.
EM elena.cuoco@ego-gw.it
RI Iess, Alberto/AAT-3181-2021; Marka, Szabolcs/ABE-7493-2021; Keitel,
   David/AAA-1579-2019; Cuoco, Elena/I-8789-2012
OI Iess, Alberto/0000-0001-9658-6752; Keitel, David/0000-0002-2824-626X;
   Cavaglia, Marco/0000-0002-3835-6729; Powell, Jade/0000-0002-1357-4164;
   Chatterjee, Chayan/0000-0001-8700-3455; Easter,
   Paul/0000-0003-2212-9051; Bejger, Michal/0000-0002-4991-8213; Cuoco,
   Elena/0000-0002-6528-3449
FU COST Action - COST (European Cooperation in Science and Technology)
   [CA17137]; Australian Research Council Centre of Excellence for
   Gravitational Wave DiscoveryAustralian Research Council [CE170100004];
   National Science FoundationNational Science Foundation (NSF)
   [PHY-0757058, PHY-0823459, PHY-1921006, PHY-2011334, CCF-1740391,
   INSPIRE 15-47880]; Swiss National Science FoundationSwiss National
   Science Foundation (SNSF)European Commission [181461]; Science and
   Technology Facilities Council (STFC)UK Research & Innovation
   (UKRI)Science & Technology Facilities Council (STFC)Science and
   Technology Development Fund (STDF) [ST/L000946/1]; University of Chicago
   by the Kavli Institute for Cosmological Physics through an endowment
   from the Kavli Foundation; Columbia University in the City of New York;
   NIH Research Facility Improvement GrantUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USA
   [1G20RR030893-01]; New York State Empire State Development, Division of
   Science Technology and Innovation (NYSTAR) [C090171]; Max Planck ETH
   Center for Learning Systems; LIGO Laboratory, NSF [PHY-1764464]; Spanish
   Ministry of Science, Innovation and Universities grant [FPA2016-76821];
   Vicepresidencia i Conselleria d'Innovacio, Recerca i Turisme;
   Conselleria d'Educacio i Universitats of the Govern de les Illes
   Balears; Polish National Science Centre [2016/22/E/ST9/00037,
   2017/26/M/ST9/00978]; United States National Science FoundationNational
   Science Foundation (NSF) [PHY-0757058]
FX This publication is supported by work from COST Action CA17137,
   supported by COST (European Cooperation in Science and Technology). JP,
   KA and PE are supported by the Australian Research Council Centre of
   Excellence for Gravitational Wave Discovery (OzGrav), through project
   number CE170100004. MC is supported by the National Science Foundation
   through award PHY-1921006 and PHY-2011334. LH is supported by the Swiss
   National Science Foundation with the Early Postdoc Mobility grant number
   181461. DW and HG are supported by Science and Technology Facilities
   Council (STFC) grant ST/L000946/1. RE is supported at the University of
   Chicago by the Kavli Institute for Cosmological Physics through an
   endowment from the Kavli Foundation and its founder Fred Kavli. SM and
   ZM thank Columbia University in the City of New York for their generous
   support and are supported by the National Science Foundation under grant
   CCF-1740391. SM and ZM acknowledge computing resources from Columbia
   University's Shared Research Computing Facility project, which is
   supported by NIH Research Facility Improvement Grant 1G20RR030893-01,
   and associated funds from the New York State Empire State Development,
   Division of Science Technology and Innovation (NYSTAR) Contract C090171,
   both awarded April 15, 2010. TDG acknowledges partial funding from the
   Max Planck ETH Center for Learning Systems. Gravity Spy and SC is partly
   supported by the National Science Foundation award INSPIRE 15-47880. VG
   is supported by the LIGO Laboratory, NSF grant PHY-1764464. DK is
   supported by the Spanish Ministry of Science, Innovation and
   Universities grant FPA2016-76821 and the Vicepresidencia i Conselleria
   d'Innovacio, Recerca i Turisme and Conselleria d'Educacio i Universitats
   of the Govern de les Illes Balears. MB and FM are partially supported by
   the Polish National Science Centre Grants No. 2016/22/E/ST9/00037 and
   2017/26/M/ST9/00978. LIGO was constructed by the California Institute of
   Technology and Massachusetts Institute of Technology with funding from
   the United States National Science Foundation under grant PHY-0757058.
   The authors are grateful for computational resources provided by the
   LIGO Laboratory and supported by the National Science Foundation Grants
   PHY-0757058 and PHY-0823459.
NR 235
TC 28
Z9 28
U1 16
U2 20
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
EI 2632-2153
J9 MACH LEARN-SCI TECHN
JI Mach. Learn.-Sci. Technol.
PD MAR
PY 2021
VL 2
IS 1
AR 011002
DI 10.1088/2632-2153/abb93a
PG 19
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Science & Technology - Other Topics
GA SQ6YW
UT WOS:000660500300002
OA Green Submitted, gold, Green Accepted
HC Y
HP N
DA 2022-04-17
ER

PT C
AU Mucke, S
   Piatkowski, N
   Morik, K
AF Muecke, Sascha
   Piatkowski, Nico
   Morik, Katharina
BE Cellier, P
   Driessens, K
TI Hardware Acceleration of Machine Learning Beyond Linear Algebra
SO MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES, ECML PKDD 2019,
   PT I
SE Communications in Computer and Information Science
LA English
DT Proceedings Paper
CT European Conference on Machine Learning and Principles and Practice of
   Knowledge Discovery in Databases (ECML PKDD)
CY SEP 16-20, 2019
CL Wurzburg, GERMANY
SP Bosch, Fraunhofer IAIS, Huawei, ASML, IBM Res, NEC, Kreditech, McKinsey & Co, KNIME, European Res Ctr Informat Syst, Odgers Berndtson, Springer, Vogel Stiftung, German Res Fdn
DE Hardware acceleration; Machine learning; FPGA
AB Specialized hardware for machine learning allows us to train highly accurate models in hours which would otherwise take days or months of computation time. The advent of recent deep learning techniques can largely be explained by the fact that their training and inference rely heavily on fast matrix algebra that can be accelerated easily via programmable graphics processing units (GPU). Thus, vendors praise the GPU as the hardware for machine learning. However, those accelerators have an energy consumption of several hundred Watts. In distributed learning, each node has to meet resource constraints that exceed those of an ordinary workstation-especially when learning is performed at the edge, i.e., close to the data source. The energy consumption is typically highly restricted, and relying on high-end CPUs and GPUs is thus not a viable option. In this work, we present our new quantum-inspired machine learning hardware accelerator. More precisely, we explain how our hardware approximates the solution to several NP-hard data mining and machine learning problems, including k-means clustering, maximum-a-posterior prediction, and binary support vector machine learning. Our device has a worst-case energy consumption of about 1.5W and is thus especially well suited for distributed learning at the edge.
C1 [Muecke, Sascha; Piatkowski, Nico; Morik, Katharina] TU Dortmund, AI Grp, Dortmund, Germany.
RP Mucke, S (corresponding author), TU Dortmund, AI Grp, Dortmund, Germany.
EM sascha.muecke@tu-dortmund.de
NR 9
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1865-0929
EI 1865-0937
BN 978-3-030-43823-4; 978-3-030-43822-7
J9 COMM COM INF SC
PY 2020
VL 1167
BP 342
EP 347
DI 10.1007/978-3-030-43823-4_29
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Interdisciplinary Applications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS4ET
UT WOS:000718585100029
DA 2022-04-17
ER

PT C
AU Saadallah, A
   Morik, K
AF Saadallah, Amal
   Morik, Katharina
BE Webb, G
   Zhang, Z
   Tseng, VS
   Williams, G
   Vlachos, M
   Cao, L
TI Active Sampling for Learning Interpretable Surrogate Machine Learning
   Models
SO 2020 IEEE 7TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND ADVANCED
   ANALYTICS (DSAA 2020)
SE Proceedings of the International Conference on Data Science and Advanced
   Analytics
LA English
DT Proceedings Paper
CT 7th IEEE International Conference on Data Science and Advanced Analytics
   (DSAA)
CY OCT 06-09, 2020
CL Univ Technol Sydney, ELECTR NETWORK
SP IEEE, IEEE Comp Soc, IEEE Computat Intelligence Soc, Amer Stat Assoc, Assoc Comp Machinery, ACM SIGKDD, China Comp Confederat, Macquarie Univ, Monash Univ, Business Events Sydney
HO Univ Technol Sydney
DE Active Sampling; Interpretable Machine Learning; Black-box Model;
   Surrogate Model; Decision Tree
ID DECISION TREE
AB The use of machine learning methods to inform consequential decisions is increasingly expanding across many fields. As a result, the ability to interpret these models has become to a greater extent crucial to increase the related-technologies acceptance level and reliability. In this paper, we propose an active sampling approach for learning accurately interpretable surrogate machine learning model to better approximate black-box models for supervised learning problems. Hence, the surrogate model is used to learn the black-box model and reflect its properties. Active sampling is used as an informed sampling method to adaptively and iteratively build an optimized training set based on the predictions of the black-box model to enhance the accuracy of the surrogate model. Subsequently, the surrogate model is used to interpret and debug the black-box model. The developed method is flexible and can be used to approximate any family of black-box models using any type of interpretable machine learning models, as it only requires the ability to compute their outputs. It is also applicable to both regression and classification tasks. In this work, we bring focus to decision tree due to their proven high interpretability. An experimental evaluation of the method on several real-world data sets is presented to show its flexibility and its robustness compared to traditional approaches for learning surrogate models.
C1 [Saadallah, Amal; Morik, Katharina] TU Dortmund, Artificial Intelligence Grp, Dortmund, Germany.
RP Saadallah, A (corresponding author), TU Dortmund, Artificial Intelligence Grp, Dortmund, Germany.
EM amal.saadallah@cs.tu-dortmund.de; katharina.morik@tu-dortmund.de
FU Deutsche Forschungsgemeinschaft (DFG) within the Collaborative Research
   Center SFB 876German Research Foundation (DFG); Federal Ministry of
   Education and Research of Germany as part of the competence center for
   machine learning ML2R [01-S18038AB]
FX This work is supported by the Deutsche Forschungsgemeinschaft (DFG)
   within the Collaborative Research Center SFB 876 and the Federal
   Ministry of Education and Research of Germany as part of the competence
   center for machine learning ML2R (01-S18038AB).
NR 33
TC 0
Z9 0
U1 4
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
SN 2472-1573
BN 978-1-7281-8206-3
J9 PR INT CONF DATA SC
PY 2020
BP 264
EP 272
DI 10.1109/DSAA49011.2020.00039
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Interdisciplinary Applications; Operations
   Research & Management Science; Mathematics, Applied
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Operations Research & Management Science; Mathematics
GA BR3QC
UT WOS:000648720100028
DA 2022-04-17
ER

PT J
AU Howell, O
   Cui, WP
   Marsland, R
   Mehta, P
AF Howell, Owen
   Cui Wenping
   Marsland, Robert, III
   Mehta, Pankaj
TI Machine learning as ecology
SO JOURNAL OF PHYSICS A-MATHEMATICAL AND THEORETICAL
LA English
DT Article
DE machine learning; support vector machines; ecology
ID SUPPORT-VECTOR
AB Machine learning methods have had spectacular success on numerous problems. Here we show that a prominent class of learning algorithms-including support vector machines (SVMs)-have a natural interpretation in terms of ecological dynamics. We use these ideas to design new online SVM algorithms that exploit ecological invasions, and benchmark performance using the MNIST dataset. Our work provides a new ecological lens through which we can view statistical learning and opens the possibility of designing ecosystems for machine learning.
C1 [Howell, Owen; Cui Wenping; Marsland, Robert, III; Mehta, Pankaj] Boston Univ, Dept Phys, 590 Commonwealth Ave, Boston, MA 02215 USA.
   [Cui Wenping] Boston Coll, Dept Phys, 140 Commonwealth Ave, Chestnut Hill, MA 02467 USA.
   [Mehta, Pankaj] Boston Univ, Coll Data Sci, Boston, MA 02215 USA.
RP Howell, O (corresponding author), Boston Univ, Dept Phys, 590 Commonwealth Ave, Boston, MA 02215 USA.
EM olh20@bu.edu; pankajm@bu.edu
FU BU UROP student funding; NIH NIGMSUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute of General Medical Sciences (NIGMS) [1R35GM119461]; Simons
   Investigator in the Mathematical Modeling of Living Systems (MMLS)
FX OH acknowledges support from BU UROP student funding. The work was
   supported by NIH NIGMS Grant 1R35GM119461, Simons Investigator in the
   Mathematical Modeling of Living Systems (MMLS) to PM.
NR 30
TC 1
Z9 1
U1 21
U2 40
PU IOP PUBLISHING LTD
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 1751-8113
EI 1751-8121
J9 J PHYS A-MATH THEOR
JI J. Phys. A-Math. Theor.
PD AUG 21
PY 2020
VL 53
IS 33
AR 334001
DI 10.1088/1751-8121/ab956e
PG 18
WC Physics, Multidisciplinary; Physics, Mathematical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Physics
GA MX1EQ
UT WOS:000557470100001
PM 33403001
OA Green Submitted, Green Accepted
DA 2022-04-17
ER

PT C
AU Stoop, F
   Mayr, J
   Sulz, C
   Bleicher, F
   Wegener, K
AF Stoop, Fabian
   Mayr, Josef
   Sulz, Clemens
   Bleicher, Friedrich
   Wegener, Konrad
GP IEEE
TI Fleet learning of thermal error compensation in machine tools
SO 2021 26TH IEEE INTERNATIONAL CONFERENCE ON EMERGING TECHNOLOGIES AND
   FACTORY AUTOMATION (ETFA)
SE IEEE International Conference on Emerging Technologies and Factory
   Automation-ETFA
LA English
DT Proceedings Paper
CT 26th IEEE International Conference on Emerging Technologies and Factory
   Automation (ETFA)
CY SEP 07-10, 2021
CL ELECTR NETWORK
SP Inst Elect & Elect Engineers, Malardalen Univ, IEEE Ind Elect Soc
DE fleet learning; machine tool; Industry 4.0; thermal error compensation;
   federated learning
AB Thermal error compensation of machine tools promotes sustainable production. The thermal adaptive learning control (TALC) and machine learning approaches are the required enabling principals. Fleet learnings are key resources to develop sustainable machine tool fleets in terms of thermally induced machine tool error. The target is to integrate each machine tool of the fleet in a learning network. Federated learning with a central cloud server and dedicated edge computing on the one hand keeps the independence of each individual machine tool high and on the other hand leverages the learning of the entire fleet. The outlined concept is based on the TALC, combined with a machine agnostic and machine specific characterization and communication. The proposed system is validated with environmental measurements for two machine tools of the same type, one situated at ETH Zurich and the other one at TU Wien.
C1 [Stoop, Fabian; Wegener, Konrad] Swiss Fed Inst Technol, Inst Machine Tools & Mfg IWF, Zurich, Switzerland.
   [Mayr, Josef] Inspire AG, Zurich, Switzerland.
   [Sulz, Clemens; Bleicher, Friedrich] TU Wien, Inst Prod Engn & Photon Technol IFT, Vienna, Austria.
RP Stoop, F (corresponding author), Swiss Fed Inst Technol, Inst Machine Tools & Mfg IWF, Zurich, Switzerland.
EM stoop@iwf.mavt.ethz.ch; mayr@iwf.mavt.ethz.ch; sulz@ift.at;
   bleicher@ift.at; wegener@iwf.mavt.ethz.ch
OI Stoop, Fabian/0000-0003-1364-4764
FU Austrian Research Promotion Agency (FFG) via the "Austrian Competence
   Centre for Digital Production" (CDP) [854187]; Machine Tool Technologies
   Research Foundation (MTTRF)
FX This work has been partially supported and funded by the Austrian
   Research Promotion Agency (FFG) via the "Austrian Competence Centre for
   Digital Production" (CDP) under the contract number 854187. The authors
   would like to thank the Machine Tool Technologies Research Foundation
   (MTTRF) for the support. Also, special thanks to Nico Zimmerman for his
   helpful contributions.
NR 10
TC 0
Z9 0
U1 2
U2 2
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1946-0740
EI 1946-0759
BN 978-1-7281-2989-1
J9 IEEE INT C EMERG
PY 2021
DI 10.1109/ETFA45728.2021.9613231
PG 4
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Engineering, Industrial; Engineering, Manufacturing; Engineering,
   Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Automation & Control Systems; Computer Science; Engineering
GA BS7TS
UT WOS:000766992600034
OA Green Accepted
DA 2022-04-17
ER

PT J
AU Afzal, AL
   Nair, NK
   Asharaf, S
AF Afzal, A. L.
   Nair, Nikhitha K.
   Asharaf, S.
TI Deep kernel learning in extreme learning machines
SO PATTERN ANALYSIS AND APPLICATIONS
LA English
DT Article
DE Extreme learning machines; Deep kernel machines; Arc-cosine kernel; Deep
   kernel extreme learning machines
ID NETWORKS; MULTIPLE; CLASSIFICATION; APPROXIMATION
AB Emergence of extreme learning machine as a breakneck learning algorithm has marked its prominence in solitary hidden layer feed-forward networks. Kernel-based extreme learning machine (KELM) reflected its efficiency in diverse applications where feature mapping functions of hidden nodes are concealed from users. The conventional KELM algorithms involve only solitary layer of kernels, thereby emulating shallow learning architectures for its feature transformation. Trend in migrating shallow-based learning models into deep learning architectures opens up a new outlook for machine learning domains. This paper attempts to bestow deep kernel learning approach in a conventional shallow architecture. The emerging arc-cosine kernels possess the potential to mimic the prevailing deep layered frameworks to a greater extent. Unlike other kernels such as linear, polynomial and Gaussian, arc-cosine kernels have a recursive nature by itself and have the potential to express multilayer computation in learning models. This paper explores the possibility of building a new deep kernel machine with extreme learning machine and multilayer arc-cosine kernels. This framework outperforms conventional KELM and deep support vector machine in terms of training time and accuracy.
C1 [Afzal, A. L.] Coll Engn Muttathara, Thiruvananthapuram, Kerala, India.
   [Nair, Nikhitha K.; Asharaf, S.] Indian Inst Informat Technol & Management Kerala, Data Engn Lab, Thiruvananthapuram, Kerala, India.
RP Afzal, AL (corresponding author), Coll Engn Muttathara, Thiruvananthapuram, Kerala, India.
EM afzal.res15@iiitmk.ac.in; nikhitha.res17@iiitmk.ac.in;
   asharaf.s@iiitmk.ac.in
NR 32
TC 10
Z9 10
U1 28
U2 45
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1433-7541
EI 1433-755X
J9 PATTERN ANAL APPL
JI Pattern Anal. Appl.
PD FEB
PY 2021
VL 24
IS 1
BP 11
EP 19
DI 10.1007/s10044-020-00891-8
EA JUN 2020
PG 9
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QA5RL
UT WOS:000544215800001
DA 2022-04-17
ER

PT J
AU Janiesch, C
   Zschech, P
   Heinrich, K
AF Janiesch, Christian
   Zschech, Patrick
   Heinrich, Kai
TI Machine learning and deep learning
SO ELECTRONIC MARKETS
LA English
DT Article
DE Machine learning; Deep learning; Artificial intelligence; Artificial
   neural networks; Analytical model building
ID DECISION-MAKING; CONCEPT DRIFT; BLACK-BOX; TRENDS
AB Today, intelligent systems that offer artificial intelligence capabilities often rely on machine learning. Machine learning describes the capacity of systems to learn from problem-specific training data to automate the process of analytical model building and solve associated tasks. Deep learning is a machine learning concept based on artificial neural networks. For many applications, deep learning models outperform shallow machine learning models and traditional data analysis approaches. In this article, we summarize the fundamentals of machine learning and deep learning to generate a broader understanding of the methodical underpinning of current intelligent systems. In particular, we provide a conceptual distinction between relevant terms and concepts, explain the process of automated analytical model building through machine learning and deep learning, and discuss the challenges that arise when implementing such intelligent systems in the field of electronic markets and networked business. These naturally go beyond technological aspects and highlight issues in human-machine interaction and artificial intelligence servitization.
C1 [Janiesch, Christian] Univ Wurzburg, Fac Business Management & Econ, Sanderring 2, D-97070 Wurzburg, Germany.
   [Zschech, Patrick] Friedrich Alexander Univ Erlangen Nurnberg, Inst Informat Syst, Lange Gasse 20, D-90403 Nurnberg, Germany.
   [Heinrich, Kai] Otto von Guericke Univ, Fac Econ & Management, Univ Pl 2, D-39106 Magdeburg, Germany.
RP Janiesch, C (corresponding author), Univ Wurzburg, Fac Business Management & Econ, Sanderring 2, D-97070 Wurzburg, Germany.
EM christian.janiesch@uni-wuerzburg.de; patrick.zschech@fau.de;
   kai.heinrich@ovgu.de
RI Zschech, Patrick/AAG-6517-2019
OI Zschech, Patrick/0000-0002-1105-8086; Janiesch,
   Christian/0000-0002-8050-123X
FU Bayerische Staatsministerium fur Wirtschaft, Landesentwicklung und
   Energie (StMWi) [DIK0143/02]
FX This research and development project is funded by the Bayerische
   Staatsministerium fur Wirtschaft, Landesentwicklung und Energie (StMWi)
   within the framework concept "Informations-und Kommunikationstechnik"
   (grant no. DIK0143/02) and managed by the project management agency
   VDI+VDE Innovation + Technik GmbH..
NR 58
TC 22
Z9 22
U1 123
U2 191
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1019-6781
EI 1422-8890
J9 ELECTRON MARK
JI Electron. Mark.
PD SEP
PY 2021
VL 31
IS 3
BP 685
EP 695
DI 10.1007/s12525-021-00475-2
EA APR 2021
PG 11
WC Business; Management
WE Social Science Citation Index (SSCI)
SC Business & Economics
GA WQ8IX
UT WOS:000638010100001
OA hybrid, Green Submitted
DA 2022-04-17
ER

PT J
AU Ai, L
   Muggleton, SH
   Hocquette, C
   Gromowski, M
   Schmid, U
AF Ai, Lun
   Muggleton, Stephen H.
   Hocquette, Celine
   Gromowski, Mark
   Schmid, Ute
TI Beneficial and harmful explanatory machine learning
SO MACHINE LEARNING
LA English
DT Article
DE Inductive logic programming; Comprehensibility; Ultra-strong machine
   learning; Explainable AI
ID SIMILARITY; EXAMPLES; IMPLICIT; GAME
AB Given the recent successes of Deep Learning in AI there has been increased interest in the role and need for explanations in machine learned theories. A distinct notion in this context is that of Michie's definition of ultra-strong machine learning (USML). USML is demonstrated by a measurable increase in human performance of a task following provision to the human of a symbolic machine learned theory for task performance. A recent paper demonstrates the beneficial effect of a machine learned logic theory for a classification task, yet no existing work to our knowledge has examined the potential harmfulness of machine's involvement for human comprehension during learning. This paper investigates the explanatory effects of a machine learned theory in the context of simple two person games and proposes a framework for identifying the harmfulness of machine explanations based on the Cognitive Science literature. The approach involves a cognitive window consisting of two quantifiable bounds and it is supported by empirical evidence collected from human trials. Our quantitative and qualitative results indicate that human learning aided by a symbolic machine learned theory which satisfies a cognitive window has achieved significantly higher performance than human self learning. Results also demonstrate that human learning aided by a symbolic machine learned theory that fails to satisfy this window leads to significantly worse performance than unaided human learning.
C1 [Ai, Lun; Muggleton, Stephen H.; Hocquette, Celine] Imperial Coll London, Dept Comp, London, England.
   [Gromowski, Mark; Schmid, Ute] Univ Bamberg, Cognit Syst Grp, Bamberg, Germany.
RP Ai, L (corresponding author), Imperial Coll London, Dept Comp, London, England.
EM lun.ai15@imperial.ac.uk; s.muggleton@imperial.ac.uk;
   celine.hocquette16@imperial.ac.uk; mark.gromowski@uni-bamberg.de;
   ute.schmid@uni-bamberg.de
OI Schmid, Ute/0000-0002-1301-0326; Ai, Lun/0000-0003-2731-482X
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)German
   Research Foundation (DFG) [405630557]; UK's EPSRC Human-Like Computing
   Network
FX The contribution of the authors from University of Bamberg is part of a
   project funded by the Deutsche Forschungsgemeinschaft (DFG, German
   Research Foundation) -405630557 (PainFaceReader). The second author
   acknowledges support from the UK's EPSRC Human-Like Computing Network,
   for which he acts as director.
NR 76
TC 2
Z9 2
U1 15
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0885-6125
EI 1573-0565
J9 MACH LEARN
JI Mach. Learn.
PD APR
PY 2021
VL 110
IS 4
BP 695
EP 721
DI 10.1007/s10994-020-05941-0
EA MAR 2021
PG 27
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SB1DF
UT WOS:000627674800001
OA hybrid, Green Submitted
DA 2022-04-17
ER

PT J
AU Weinan, E
AF Weinan, E.
TI Machine Learning and Computational Mathematics
SO COMMUNICATIONS IN COMPUTATIONAL PHYSICS
LA English
DT Article
DE Neural network-based machine learning; machine learning-based algorithm
ID MOLECULAR-DYNAMICS
AB Neural network-based machine learning is capable of approximating functions in very high dimension with unprecedented efficiency and accuracy. This has opened up many exciting new possibilities, not just in traditional areas of artificial intelligence, but also in scientific computing and computational science. At the same time, machine learning has also acquired the reputation of being a set of "black box" type of tricks, without fundamental principles. This has been a real obstacle for making further progress in machine learning.
   In this article, we try to address the following two very important questions: (1) How machine learning has already impacted and will further impact computational mathematics, scientific computing and computational science? (2) How computational mathematics, particularly numerical analysis, can impact machine learning? We describe some of the most important progress that has been made on these issues. Our hope is to put things into a perspective that will help to integrate machine learning with computational mathematics.
C1 [Weinan, E.] Princeton Univ, Dept Math, Princeton, NJ 08544 USA.
   [Weinan, E.] Princeton Univ, Program Appl & Computat Math, Princeton, NJ 08544 USA.
   [Weinan, E.] Beijing Inst Big Data Res, Beijing, Peoples R China.
RP Weinan, E (corresponding author), Princeton Univ, Dept Math, Princeton, NJ 08544 USA.; Weinan, E (corresponding author), Princeton Univ, Program Appl & Computat Math, Princeton, NJ 08544 USA.; Weinan, E (corresponding author), Beijing Inst Big Data Res, Beijing, Peoples R China.
EM weinan@math.princeton.edu
FU ONROffice of Naval Research [N00014-13-1-0338]
FX I am very grateful to my collaborators for their contribution to the
   work described here. In particular, I would like to express my sincere
   gratitude to Roberto Car, Jiequn Han, Arnulf Jentzen, Qianxiao Li, Chao
   Ma, Han Wang, Stephan Wojtowytsch, and Lei Wu for the many discussions
   that we have had on the issues discussed here. This work is supported in
   part by a gift to the Princeton University from iFlytek as well as the
   ONR grant N00014-13-1-0338.
NR 39
TC 7
Z9 7
U1 34
U2 50
PU GLOBAL SCIENCE PRESS
PI WANCHAI
PA ROOM 3208, CENTRAL PLAZA, 18 HARBOUR RD, WANCHAI, HONG KONG 00000,
   PEOPLES R CHINA
SN 1815-2406
EI 1991-7120
J9 COMMUN COMPUT PHYS
JI Commun. Comput. Phys.
PD NOV
PY 2020
VL 28
IS 5
BP 1639
EP 1670
DI 10.4208/cicp.OA-2020-0185
PG 32
WC Physics, Mathematical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Physics
GA OW0YR
UT WOS:000592624200002
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Park, JS
   Park, JH
AF Park, Ji Su
   Park, Jong Hyuk
TI Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement
   Learning, ana Q-Learning
SO JOURNAL OF INFORMATION PROCESSING SYSTEMS
LA English
DT Article
DE Deep Learning; Machine Learning; Reinforcement Learning; Q-Learning
AB In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper.
C1 [Park, Ji Su] Jeonju Univ, Dept Comp Sci & Engn, Jeonju, South Korea.
   [Park, Jong Hyuk] Seoul Natl Univ Sci & Technol SeoulTech, Dept Comp Sci & Engn, Seoul, South Korea.
RP Park, JH (corresponding author), Seoul Natl Univ Sci & Technol SeoulTech, Dept Comp Sci & Engn, Seoul, South Korea.
EM jhpark1@seoultech.ac.kr
NR 18
TC 0
Z9 0
U1 14
U2 21
PU KOREA INFORMATION PROCESSING SOC
PI SEOUL
PA 1002HO YONGSUNGBIZTEL 314-1 2GA HANKANGRO YONGSAN-GU, SEOUL, 140-750,
   SOUTH KOREA
SN 1976-913X
EI 2092-805X
J9 J INF PROCESS SYST
JI J. Inf. Process. Syst.
PD OCT
PY 2020
VL 16
IS 5
BP 1001
EP 1007
DI 10.3745/JIPS.02.0139
PG 7
WC Computer Science, Information Systems
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA OO9YM
UT WOS:000587732100001
DA 2022-04-17
ER

PT C
AU Francisco, M
   Amado, C
AF Francisco, Manuela
   Amado, Cristina
BE Huang, YM
   Lai, CF
   Rocha, T
TI Perusall's Machine Learning Towards Self-regulated Learning
SO INNOVATIVE TECHNOLOGIES AND LEARNING
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 4th International Conference on Innovative Technologies and Learning
   (ICITL)
CY NOV 29-DEC 01, 2021
CL ELECTR NETWORK
SP Natl Cheng Kung Univ, Utad, Oslomet, Natl Yunlin Univ Sci & Technol, Assoc Taiwan Engn Educat & Management
DE Machine learning; Perusall; Collaborative learning; Self-regulated
   learning; Distance education
ID INQUIRY
AB This current work presents exploratory research related to Perusall activity. One of the objectives of this study was to analyze the Perusalll's features, with emphasis on peer work, which can increase individual motivation facilitating self-regulation learning. Perusall is a social web tool that uses a machine learning algorithm, which assesses the quality of annotations and students' engagement. This tool was integrated with the LMS of Universidade Aberta (Portugal) and it was used as a pilot project in a Curricular Unit, from the 2nd year of the Education undergraduate program. We designed a collaborative activity inspired by Inquiry-based Learning and peer-instruction, to be performed on Perusall. 115 students, from 2 classes, were involved. To assess students' work, their engagement and motivation (basis for self-regulation) we analyzed Perusall's reports and scoring based on 6 different components. We also asked students to report positive and negative aspects related to their experience with Perusall. Our findings confirm that collaborative reading tools can help students to get more involved in self-learning, as well machine learning can help instructors work, namely monitoring and assessment tasks.
C1 [Francisco, Manuela] Univ Aberta, Lab Distance Educ & eLearning, Lisbon, Portugal.
   [Francisco, Manuela] Politecn Leira, Ctr Studies Educ & Innovat, Leiria, Portugal.
   [Amado, Cristina] Univ Aberta, Lisbon, Portugal.
RP Francisco, M (corresponding author), Univ Aberta, Lab Distance Educ & eLearning, Lisbon, Portugal.; Francisco, M (corresponding author), Politecn Leira, Ctr Studies Educ & Innovat, Leiria, Portugal.
EM maria.francisco@uab.pt
OI Francisco, Maria/0000-0001-9755-9553
NR 38
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-91540-7; 978-3-030-91539-1
J9 LECT NOTES COMPUT SC
PY 2021
VL 13117
BP 49
EP 58
DI 10.1007/978-3-030-91540-7_6
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Education, Scientific
   Disciplines
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Education & Educational Research
GA BS7UL
UT WOS:000767940800006
DA 2022-04-17
ER

PT J
AU Sugisawa, Y
   Takasugi, K
   Asakawa, N
AF Sugisawa, Yasutomo
   Takasugi, Keigo
   Asakawa, Naoki
TI Machining sequence learning via inverse reinforcement learning
SO PRECISION ENGINEERING-JOURNAL OF THE INTERNATIONAL SOCIETIES FOR
   PRECISION ENGINEERING AND NANOTECHNOLOGY
LA English
DT Article
DE Machining sequence decision; Inverse reinforcement learning; Neural
   network; Graph representation
AB In recent years, process planning automation has been strongly promoted in conjunction with the development of information technology (IT). In manufacturing industries, machining sequencing is one of the elements of computer-aided process planning (CAPP) systems where it has a significant impact on the quality and cost of machined components. Therefore, effective and robust planning rules are essential for practical CAPP systems, and various metrics and constraints have been proposed to facilitate the creation of those rules. However, since it is challenging to address explicit factors such as interference between rules, processing difficulties, and man-ageability, discrepancies that require manual corrections often arise between the generated sequences and the planner's intentions. To resolve this problem, we propose a method of acquiring rules that reproduce the planner's decisions by inverse reinforcement learning (IRL). To apply the IRL process, we focus on identifying a machining sequence that characterizes the planner's decision based on past production processes and interviews with experts. This machining sequence can then be represented using a Markov decision process (MDP) when changing the workpiece shape, which enables the application of IRL. Additionally, to reflect the drawing in-formation in the sequence decision, the workpiece shape is represented as a graph with attached tolerance and roughness values. The graphed machining sequence is then inputted to the graph, where convolutional networking and training are performed. We verified the validity of our proposed method using a small dataset.
C1 [Sugisawa, Yasutomo] Kanazawa Univ, Grad Sch Nat Sci & Technol, Kanazawa, Ishikawa, Japan.
   [Takasugi, Keigo] Kanazawa Univ, Inst Sci & Engn, Kanazawa, Ishikawa, Japan.
   [Asakawa, Naoki] Kanazawa Univ, Adv Mfg Technol Inst, Kanazawa, Ishikawa, Japan.
RP Sugisawa, Y (corresponding author), Kanazawa Univ, Grad Sch Nat Sci & Technol, Kanazawa, Ishikawa, Japan.
EM sugiyasu3417@stu.kanazawa-u.ac.jp; ktaka@se.kanazawa-u.ac.jp;
   nasakawa@se.kanazawa-u.ac.jp
OI Asakawa, Naoki/0000-0002-7387-8282
FU Machine Tool Engineering Foundation [RU-07]
FX This study was financially supported by research project RU-07, the
   Machine Tool Engineering Foundation.
NR 23
TC 0
Z9 0
U1 6
U2 6
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0141-6359
EI 1873-2372
J9 PRECIS ENG
JI Precis. Eng.-J. Int. Soc. Precis. Eng. Nanotechnol.
PD JAN
PY 2022
VL 73
BP 477
EP 487
DI 10.1016/j.precisioneng.2021.09.017
EA OCT 2021
PG 11
WC Engineering, Multidisciplinary; Engineering, Manufacturing; Nanoscience
   & Nanotechnology; Instruments & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Science & Technology - Other Topics; Instruments &
   Instrumentation
GA WX9CQ
UT WOS:000718886300002
OA Bronze
DA 2022-04-17
ER

PT C
AU Zhang, QQ
   Liu, JL
   Zhang, ZQ
   Wen, JY
   Mao, BF
   Yao, X
AF Zhang, Qingquan
   Liu, Jialin
   Zhang, Zeqi
   Wen, Junyi
   Mao, Bifei
   Yao, Xin
BE Farkas, I
   Masulli, P
   Otte, S
   Wermter, S
TI Fairer Machine Learning Through Multi-objective Evolutionary Learning
SO ARTIFICIAL NEURAL NETWORKS AND MACHINE LEARNING - ICANN 2021, PT IV
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 30th International Conference on Artificial Neural Networks (ICANN)
CY SEP 14-17, 2021
CL ELECTR NETWORK
DE Fairness in machine learning; Discrimination in machine learning; AI
   ethics; Fairness measures; Multi-objective learning
AB Dilemma between model accuracy and fairness in machine learning models has been shown theoretically and empirically. So far, dozens of fairness measures have been proposed, among which incompatibility and complementarity exist. However, no fairness measure has been universally accepted as the single fairest measure. No one has considered multiple fairness measures simultaneously. In this paper, we propose a multi-objective evolutionary learning framework for mitigating unfairness caused by considering a single measure only, in which a multi-objective evolutionary algorithm is used during training to balance accuracy and multiple fairness measures simultaneously. In our case study, besides the model accuracy, two fairness measures that are conflicting to each other are selected. Empirical results show that our proposed multi-objective evolutionary learning framework is able to find Pareto-front models efficiently and provide fairer machine learning models that consider multiple fairness measures.
C1 [Zhang, Qingquan; Liu, Jialin; Yao, Xin] Southern Univ Sci & Technol SUSTech, Res Inst Trustworthy Autonomous Syst, Shenzhen, Peoples R China.
   [Zhang, Qingquan; Liu, Jialin; Yao, Xin] Southern Univ Sci & Technol SUSTech, Dept Comp Sci & Engn, Guangdong Prov Key Lab Brain Inspired Intelligent, Shenzhen, Peoples R China.
   [Zhang, Zeqi; Wen, Junyi; Mao, Bifei] Huawei Technol Co Ltd, Trustworthiness Theory Res Ctr, Shenzhen, Peoples R China.
RP Yao, X (corresponding author), Southern Univ Sci & Technol SUSTech, Res Inst Trustworthy Autonomous Syst, Shenzhen, Peoples R China.; Yao, X (corresponding author), Southern Univ Sci & Technol SUSTech, Dept Comp Sci & Engn, Guangdong Prov Key Lab Brain Inspired Intelligent, Shenzhen, Peoples R China.
EM 11930582@mail.sustech.edu.cn; liujl@sustech.edu.cn; xiny@sustech.edu.cn
RI LIU, Jialin/M-3290-2018
OI LIU, Jialin/0000-0001-7047-8454
FU Research Institute of Trustworthy Autonomous Systems; Guangdong
   Provincial Key Laboratory [2020B121201001]; Program for Guangdong
   Introducing Innovative and Entrepreneurial Teams [2017ZT07X386];
   Guangdong Basic and Applied Basic Research Foundation [2021A1515011830];
   Shenzhen Science and Technology Program [KQTD2016112514355531]; Shenzhen
   Fundamental Research Program [JCYJ20180504165652917,
   JCYJ20190809121403553]; Huawei project on "Fundamental Theory and Key
   Technologies of Trustworthy Systems"
FX This work was supported by the Research Institute of Trustworthy
   Autonomous Systems, the Guangdong Provincial Key Laboratory (Grant No.
   2020B121201001), the Program for Guangdong Introducing Innovative and
   Entrepreneurial Teams (Grant No. 2017ZT07X386), the Guangdong Basic and
   Applied Basic Research Foundation (Grant No. 2021A1515011830), the
   Shenzhen Science and Technology Program (Grant No.
   KQTD2016112514355531), the Shenzhen Fundamental Research Program (Grant
   Nos. JCYJ20180504165652917, JCYJ20190809121403553) and Huawei project on
   "Fundamental Theory and Key Technologies of Trustworthy Systems".
NR 34
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-86380-7; 978-3-030-86379-1
J9 LECT NOTES COMPUT SC
PY 2021
VL 12894
BP 111
EP 123
DI 10.1007/978-3-030-86380-7_10
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS3IW
UT WOS:000711927100010
DA 2022-04-17
ER

PT J
AU Luan, H
   Tsai, CC
AF Luan, Hui
   Tsai, Chin-Chung
TI A Review of Using Machine Learning Approaches for Precision Education
SO EDUCATIONAL TECHNOLOGY & SOCIETY
LA English
DT Review
DE Precision education; Personalized learning; Individualized learning;
   Machine learning; Individual differences
ID ARTIFICIAL-INTELLIGENCE; PERFORMANCE; ANALYTICS; PREDICTION; SCIENCE;
   SYSTEM
AB In recent years, in the field of education, there has been a clear progressive trend toward precision education. As a rapidly evolving AI technique, machine learning is viewed as an important means to realize it. In this paper, we systematically review 40 empirical studies regarding machine-learning-based precision education. The results showed that the majority of studies focused on the prediction of learning performance or dropouts, and were carried out in online or blended learning environments among university students majoring in computer science or STEM, whereas the data sources were divergent. The commonly used machine learning algorithms, evaluation methods, and validation approaches are presented. The emerging issues and future directions are discussed accordingly.
C1 [Luan, Hui; Tsai, Chin-Chung] Natl Taiwan Normal Univ, Inst Res Excellence Learning Sci, Taipei, Taiwan.
   [Tsai, Chin-Chung] Natl Taiwan Normal Univ, Program Learning Sci, Taipei, Taiwan.
RP Tsai, CC (corresponding author), Natl Taiwan Normal Univ, Inst Res Excellence Learning Sci, Taipei, Taiwan.; Tsai, CC (corresponding author), Natl Taiwan Normal Univ, Program Learning Sci, Taipei, Taiwan.
EM hluanv@gmail.com; tsaicc@ntnu.edu.tw
FU "Institute for Research Excellence in Learning Sciences" of the National
   Taiwan Normal University (NTNU) from the Featured Areas Research Center
   Program within Ministry of Education (MOE) in Taiwan
FX This work was financially supported by the "Institute for Research
   Excellence in Learning Sciences" of the National Taiwan Normal
   University (NTNU) from the Featured Areas Research Center Program within
   the framework of the Higher Education Sprout Project by the Ministry of
   Education (MOE) in Taiwan.
NR 85
TC 10
Z9 10
U1 63
U2 86
PU INT FORUM EDUCATIONAL TECHNOLOGY & SOC-IFETS
PI DOULIU CITY
PA NATL YUNLIN UNIV SCIENCE & TECHNOLOGY, NO 123, SECTION 3, DAXUE RD,
   DOULIU CITY, YUNLIN COUNTY, TAIWAN
SN 1176-3647
EI 1436-4522
J9 EDUC TECHNOL SOC
JI Educ. Technol. Soc.
PD JAN
PY 2021
VL 24
IS 1
BP 250
EP 266
PG 17
WC Education & Educational Research
WE Social Science Citation Index (SSCI)
SC Education & Educational Research
GA QQ5RX
UT WOS:000624582400019
DA 2022-04-17
ER

PT J
AU Proserpio, D
   Hauser, JR
   Liu, X
   Amano, T
   Burnap, A
   Guo, T
   Lee, D
   Lewis, R
   Misra, K
   Schwarz, E
   Timoshenko, A
   Xu, LL
   Yoganarasimhan, H
AF Proserpio, Davide
   Hauser, John R.
   Liu, Xiao
   Amano, Tomomichi
   Burnap, Alex
   Guo, Tong
   Lee, Dokyun (DK)
   Lewis, Randall
   Misra, Kanishka
   Schwarz, Eric
   Timoshenko, Artem
   Xu, Lilei
   Yoganarasimhan, Hema
TI Soul and machine (learning)
SO MARKETING LETTERS
LA English
DT Article
DE Machine learning; Marketing applications; Knowledge
AB Machine learning is bringing us self-driving cars, medical diagnoses, and language translation, but how can machine learning help marketers improve marketing decisions? Machine learning models predict extremely well, are scalable to "big data," and are a natural fit to analyze rich media content, such as text, images, audio, and video. Examples of current marketing applications include identification of customer needs from online data, accurate prediction of consumer response to advertising, personalized pricing, and product recommendations. But without the human input and insight-the soul-the applications of machine learning are limited. To create competitive or cooperative strategies, to generate creative product designs, to be accurate for "what-if" and "but-for" applications, to devise dynamic policies, to advance knowledge, to protect consumer privacy, and avoid algorithm bias, machine learning needs a soul. The brightest future is based on the synergy of what the machine can do well and what humans do well. We provide examples and predictions for the future.
C1 [Proserpio, Davide] USC Marshall Sch Business, Los Angeles, CA 90089 USA.
   [Hauser, John R.] MIT, Sloan Sch Management, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   [Liu, Xiao] NYU, Stern Sch Business, New York, NY USA.
   [Amano, Tomomichi] Harvard Sch Business, Boston, MA USA.
   [Burnap, Alex] Yale Sch Management, New Haven, CT USA.
   [Guo, Tong] Duke Fuqua Sch Business, Durham, NC USA.
   [Lee, Dokyun (DK)] CMU Tepper Sch Business, Pittsburgh, PA USA.
   [Misra, Kanishka] UCSD Rady Sch Management, San Diego, CA USA.
   [Schwarz, Eric] Univ Michigan, Ross Sch Business, Ann Arbor, MI 48109 USA.
   [Timoshenko, Artem] Northwestern Univ, Kellogg Sch Management, Evanston, IL USA.
   [Xu, Lilei] Airbnb, San Francisco, CA USA.
   [Yoganarasimhan, Hema] UW Foster Sch Business, Seattle, WA USA.
RP Proserpio, D (corresponding author), USC Marshall Sch Business, Los Angeles, CA 90089 USA.
EM proserpi@marshall.usc.edu
RI Liu, Xiao/ABH-6079-2020
OI /0000-0002-5431-2136
NR 26
TC 3
Z9 3
U1 19
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0923-0645
EI 1573-059X
J9 MARKET LETT
JI Mark. Lett.
PD DEC
PY 2020
VL 31
IS 4
SI SI
BP 393
EP 404
DI 10.1007/s11002-020-09538-4
EA AUG 2020
PG 12
WC Business
WE Social Science Citation Index (SSCI)
SC Business & Economics
GA OT6PT
UT WOS:000564994700001
OA Green Published
DA 2022-04-17
ER

PT J
AU Alfaro, ADJ
   Ospina, JVD
AF Alfaro, Anderson Damian Jimenez
   Ospina, Jose Vicente Diaz
TI Systematic literature review: Machine learning techniques (machine
   learning)
SO CUADERNO ACTIVA
LA Spanish
DT Review
DE Machine learning; forecasting; business intelligence; marketing;
   business management
AB Currently, there are a great diversity of models that allow making predictions, and for this there are machine learning techniques that can help organizations to boost their sales through these predictive models. In this article a specialized search of scientific literature is carried out that provides clarity on which are the most used techniques and under what criteria are they effective. According to the research needs, the most relevant articles have been filtered and selected to elucidate how to execute a machine learning project for sales forecasting. From the review carried out, it can be affirmed that the different machine learning techniques found in the literature are evolutions of different known techniques, which is an important component to maintain business competitiveness, and if they are well used could become sales-enhancing tools in companies organizations.
C1 [Alfaro, Anderson Damian Jimenez] Univ Catolica Luis Amigo, Ingn Ind, Medellin, Colombia.
   [Ospina, Jose Vicente Diaz] Univ Catolica Luis Amigo, Ingn Financiero & Negocios, Medellin, Colombia.
RP Alfaro, ADJ (corresponding author), Univ Catolica Luis Amigo, Ingn Ind, Medellin, Colombia.
EM anderson.jimenezas@amigo.edu.co; Jose.diazos@amigo.edu.co
NR 26
TC 0
Z9 0
U1 2
U2 2
PU TECNOLOGICO ANTIOQUIA-INST UNIV, FAC INGENIERIA
PI MEDELLIN
PA CL 78B 72A-220, MEDELLIN, ANTIOQUIA 00000, COLOMBIA
SN 2027-8101
J9 CUAD ACT
JI Cuad. Act.
PD JAN-DEC
PY 2021
IS 13
BP 113
EP 121
PG 9
WC Engineering, Multidisciplinary
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA ZO4XE
UT WOS:000765728300009
DA 2022-04-17
ER

PT S
AU Dey, S
   De, S
   Bhattacharyya, S
AF Dey, Sandip
   De, Sourav
   Bhattacharyya, Siddhartha
BE Bhattacharyya, S
   Pan, I
   Mani, A
   De, S
   Behrman, E
   Chakraborti, S
TI Introduction to quantum machine learning
SO QUANTUM MACHINE LEARNING
SE De Gruyter Frontiers in Computational Intelligence
LA English
DT Editorial Material; Book Chapter
DE machine learning; Grover's Search Algorithm; reinforcement learning;
   quantum annealing; quantum neural networks
ID COMPUTATION; NAVIGATION
AB Quantum Machine Learning (QML) is popularly known to be an integrative approach to learning of the Quantum Physics (QP) and Machine Learning (ML). In this chapter, an outline of the fundamental ideas and features related to quantum machine learning is laid out. The different facets of quantum algorithms are discussed in this chapter. In addition to this, the basic features of quantum reinforcement learning and quantum annealing are also provided in this chapter. Finally, the chapter deliberates about the advancement of quantum neural networks to through light in the direction of QML.
C1 [Dey, Sandip] Sukanta Mahavidyalaya, Dept Comp Sci, Jalpaiguri, W Bengal, India.
   [De, Sourav] Cooch Behar Govt Engn Coll, Dept Comp Sci & Engn, Cooch Behar 736170, W Bengal, India.
   [Bhattacharyya, Siddhartha] CHRIST Deemed Be Univ, Dept Comp Sci & Engn, Hosur Rd, Bangalore 560029, Karnataka, India.
RP Dey, S (corresponding author), Sukanta Mahavidyalaya, Dept Comp Sci, Jalpaiguri, W Bengal, India.
EM dr.ssandip.dey@gmail.com; dr.sourav.de79@gmail.com;
   dr.siddhartha.bhattacharyya@gmail.com
NR 61
TC 1
Z9 1
U1 5
U2 5
PU WALTER DE GRUYTER GMBH
PI BERLIN
PA GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY
SN 2512-8868
BN 978-3-11-067070-7; 978-3-11-067064-6
J9 DE GR FRONT COMPU IN
PY 2020
VL 6
BP 1
EP 9
DI 10.1515/9783110670707-001
D2 10.1515/9783110670707
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic;
   Quantum Science & Technology
WE Book Citation Index – Science (BKCI-S)
SC Computer Science; Engineering; Physics
GA BQ5AP
UT WOS:000596459300002
DA 2022-04-17
ER

PT J
AU Saini, S
   Khosla, PK
   Kaur, M
   Singh, G
AF Saini, Shivani
   Khosla, P. K.
   Kaur, Manjit
   Singh, Gurmohan
TI Quantum Driven Machine Learning
SO INTERNATIONAL JOURNAL OF THEORETICAL PHYSICS
LA English
DT Article
DE Qubit; Quantum computing; Machine learning; Support vector machine; Big
   data
AB Quantum computing is proving to be very beneficial for solving complex machine learning problems. Quantum computers are inherently excellent in handling and manipulating vectors and matrix operations. The ever increasing size of data has started creating bottlenecks for classical machine learning systems. Quantum computers are emerging as potential solutions to tackle big data related problems. This paper presents a quantum machine learning model based on quantum support vector machine (QSVM) algorithm to solve a classification problem. The quantum machine learning model is practically implemented on quantum simulators and real-time superconducting quantum processors. The performance of quantum machine learning model is computed in terms of processing speed and accuracy and compared against its classical counterpart. The breast cancer dataset is used for the classification problem. The results are indicative that quantum computers offer quantum speed-up.
C1 [Saini, Shivani; Khosla, P. K.; Kaur, Manjit; Singh, Gurmohan] Minist Elect & Informat Technol MeitY, Ctr Dev Adv Comp C DAC, Mohali 160071, India.
RP Singh, G (corresponding author), Minist Elect & Informat Technol MeitY, Ctr Dev Adv Comp C DAC, Mohali 160071, India.
EM gurmohan@cdac.in
OI KHOSLA, PRAVEEN/0000-0002-0509-2018
NR 23
TC 0
Z9 0
U1 22
U2 33
PU SPRINGER/PLENUM PUBLISHERS
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0020-7748
EI 1572-9575
J9 INT J THEOR PHYS
JI Int. J. Theor. Phys.
PD DEC
PY 2020
VL 59
IS 12
BP 4013
EP 4024
DI 10.1007/s10773-020-04656-1
EA DEC 2020
PG 12
WC Physics, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Physics
GA PA8OH
UT WOS:000595025900001
DA 2022-04-17
ER

PT J
AU Xu, YY
   Zhou, Y
   Sekula, P
   Ding, LY
AF Xu, Yayin
   Zhou, Ying
   Sekula, Przemyslaw
   Ding, Lieyun
TI Machine learning in construction: From shallow to deep learning
SO DEVELOPMENTS IN THE BUILT ENVIRONMENT
LA English
DT Article
DE Machine learning; Shallow learning; Deep learning; Construction
ID CONVOLUTIONAL NEURAL-NETWORKS; INSPECTION; ALGORITHM; MODEL
AB The development of artificial intelligence technology is currently bringing about new opportunities in construction. Machine learning is a major area of interest within the field of artificial intelligence, playing a pivotal role in the process of making construction "smart". The application of machine learning in construction has the potential to open up an array of opportunities such as site supervision, automatic detection, and intelligent maintenance. However, the implementation of machine learning faces a range of challenges due to the difficulties in acquiring labeled data, especially when applied in a highly complex construction site environment. This paper reviews the history of machine learning development from shallow to deep learning and its applications in construction. The strengths and weaknesses of machine learning technology in construction have been analyzed in order to foresee the future direction of machine learning applications in this sphere. Furthermore, this paper presents suggestions which may benefit researchers in terms of combining specific knowledge domains in construction with machine learning algorithms so as to develop dedicated deep network models for the industry.
C1 [Xu, Yayin] Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Wuhan, Peoples R China.
   [Zhou, Ying; Ding, Lieyun] Huazhong Univ Sci & Technol, Sch Civil & Hydraul Engn, Wuhan, Peoples R China.
   [Sekula, Przemyslaw] Univ Maryland, Dept Civil & Environm Engn, College Pk, MD 20742 USA.
   [Sekula, Przemyslaw] Univ Econ Katowice, Fac Informat & Commun, Katowice, Poland.
RP Zhou, Y (corresponding author), Huazhong Univ Sci & Technol, Sch Civil & Hydraul Engn, Wuhan, Peoples R China.
EM ying_zhou@hust.edu.cn
RI Sekula, Przemyslaw/AAL-3896-2020
OI Sekula, Przemyslaw/0000-0002-4599-1077
FU National Natural Science Foundation of China, ChinaNational Natural
   Science Foundation of China (NSFC) [71732001]
FX This work is supported by the National Natural Science Foundation of
   China, China (No.71732001).
NR 91
TC 16
Z9 16
U1 23
U2 35
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
EI 2666-1659
J9 DEV BUILT ENVIRON
JI Dev. Built Environ.
PD MAY
PY 2021
VL 6
AR 100045
DI 10.1016/j.dibe.2021.100045
EA MAR 2021
PG 13
WC Construction & Building Technology; Engineering, Civil
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Construction & Building Technology; Engineering
GA ST9QL
UT WOS:000662774900003
OA gold
DA 2022-04-17
ER

PT J
AU Khan, TM
   Robles-Kelly, A
AF Khan, Tariq M.
   Robles-Kelly, Antonio
TI Machine Learning: Quantum vs Classical
SO IEEE ACCESS
LA English
DT Article
DE Quantum computing; Computers; Machine learning; Machine learning
   algorithms; Training; Task analysis; Computational modeling; Quantum
   machine learning; quantum computing; quantum algorithms; QuBit
ID ALGORITHMS; SYSTEMS
AB Encouraged by growing computing power and algorithmic development, machine learning technologies have become powerful tools for a wide variety of application areas, spanning from agriculture to chemistry and natural language processing. The use of quantum systems to process classical data using machine learning algorithms has given rise to an emerging research area, i.e. quantum machine learning. Despite its origins in the processing of classical data, quantum machine learning also explores the use of quantum phenomena for learning systems, the use of quantum computers for learning on quantum data and how machine learning algorithms and software can be formulated and implemented on quantum computers. Quantum machine learning can have a transformational effect on computer science. It may speed up the processing of information well beyond the existing classical speeds. Recent work has seen the development of quantum algorithms that could serve as foundations for machine learning applications. Despite its great promise, there are still significant hardware and software challenges that need to be resolved before quantum machine learning becomes practical. In this paper, we present an overview of quantum machine learning in the light of classical approaches. Departing from foundational concepts of machine learning and quantum computing, we discuss various technical contributions, strengths and similarities of the research work in this domain. We also elaborate upon the recent progress of different quantum machine learning approaches, their complexity, and applications in various fields such as physics, chemistry and natural language processing.
C1 [Khan, Tariq M.] Deakin Univ, Sch Informat Technol, Geelong, Vic, Australia.
   [Robles-Kelly, Antonio] Deakin Univ, Sch Informat Technol, Geelong, Vic, Australia.
   [Khan, Tariq M.; Robles-Kelly, Antonio] Deakin Univ, Sch Informat Technol, Geelong, Vic 3217, Australia.
RP Khan, TM (corresponding author), Deakin Univ, Sch Informat Technol, Geelong, Vic 3217, Australia.
EM tariq.khan@deakin.edu.au
OI Khan, Tariq Mahmood/0000-0002-7477-1591
NR 109
TC 3
Z9 3
U1 39
U2 59
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 219275
EP 219294
DI 10.1109/ACCESS.2020.3041719
PG 20
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA PH3CD
UT WOS:000600294400001
OA Green Submitted, gold
DA 2022-04-17
ER

PT C
AU Dwivedi, U
AF Dwivedi, Utkarsh
GP ASSOC COMP MACHINERY
TI Introducing Children to Machine Learning Through Machine Teaching
SO IDC '21: PROCEEDINGS OF INTERACTION DESIGN AND CHILDREN 2021
LA English
DT Proceedings Paper
CT 20th ACM Interaction Design and Children (IDC) Conference
CY JUN 24-30, 2021
CL ELECTR NETWORK
SP Assoc Comp Machinery, Natl & Kapodistrian Univ Athens, LUMS, BRIDGES, EUGAIN, NSF
DE Machine Learning; Games; AI literacy
AB A machine teaching interface is any interface that lets anyone teach an algorithm how to classify a dataset. For my dissertation, I want to explore the use of interactive machine learning interfaces also known as teachable machines for introducing machine learning to children. At its core, such interfaces can be made accessible since they can use audio or images as input data which increases the alternate representations that can be used to communicate concepts. Specifically, I would be building interactive experiences that introduce sighted and blind children to basic concepts of machine learning.
C1 [Dwivedi, Utkarsh] Univ Maryland, College Pk, MD 20742 USA.
RP Dwivedi, U (corresponding author), Univ Maryland, College Pk, MD 20742 USA.
EM udwivedi@umd.edu
NR 29
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-8452-0
PY 2021
BP 641
EP 643
DI 10.1145/3459990.3463394
PG 3
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS7UZ
UT WOS:000767988500083
DA 2022-04-17
ER

PT C
AU Gogan, JL
AF Gogan, Janis L.
GP Assoc Informat Syst
TI Responsible Machine Learning Projects
SO DIGITAL INNOVATION AND ENTREPRENEURSHIP (AMCIS 2021)
LA English
DT Proceedings Paper
CT 27th Annual Americas Conference on Information Systems (AMCIS)
CY AUG 09-13, 2021
CL ELECTR NETWORK
DE Machine learning; Responsible AI; Responsible machine learning;
   artificial intelligence
ID SOCIAL MEDIA; KNOWLEDGE; IDENTIFICATION; MECHANISMS; WORK
AB Machine Learning (ML) is a rapidly-evolving branch of artificial intelligence. Responsible Machine Learning (RML) is the use of ethically-sound governance mechanisms, policies, controls and practices that prevent some ML errors and adverse events caused by ML, detect mistakes and adverse events that nevertheless occur, and minimize stakeholder harm by correcting ML mistakes and adjusting relevant systems, processes, controls and policies. This paper takes stock of relevant findings relevant in prior ML lit reviews and recent scholarly and practitioner papers published in premier IS journals, and offers suggestions for a program of research on RML.
C1 [Gogan, Janis L.] Bentley Univ, Waltham, MA 02452 USA.
RP Gogan, JL (corresponding author), Bentley Univ, Waltham, MA 02452 USA.
EM jgogan@bentley.edu
NR 59
TC 0
Z9 0
U1 3
U2 3
PU ASSOC INFORMATION SYSTEMS
PI ATLANTA
PA P.O. BOX 2712, ATLANTA, GA 30301-2712 USA
PY 2021
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR8LY
UT WOS:000672599802022
DA 2022-04-17
ER

PT J
AU Perry, R
   Mischler, G
   Guo, R
   Lee, T
   Chang, A
   Koul, A
   Franz, C
   Richard, H
   Carmichael, I
   Ablin, P
   Gramfort, A
   Vogelstein, JT
AF Perry, Ronan
   Mischler, Gavin
   Guo, Richard
   Lee, Theodore
   Chang, Alexander
   Koul, Arman
   Franz, Cameron
   Richard, Hugo
   Carmichael, Iain
   Ablin, Pierre
   Gramfort, Alexandre
   Vogelstein, Joshua T.
TI mvlearn: Multiview Machine Learning in Python
SO JOURNAL OF MACHINE LEARNING RESEARCH
LA English
DT Article
DE multiview; machine learning; python; multi-modal; multi-table;
   multi-block
ID CANONICAL CORRELATION-ANALYSIS
AB As data are generated more and more from multiple disparate sources, multiview data sets, where each sample has features in distinct views, have grown in recent years. However, no comprehensive package exists that enables non-specialists to use these methods easily. mvlearn is a Python library which implements the leading multiview machine learning methods. Its simple API closely follows that of scikit-learn for increased ease-of-use. The package can be installed from Python Package Index (PyPI) and the conda package manager and is released under the MIT open-source license. The documentation, detailed examples, and all releases are available at https://mvlearn.github.io/.
C1 [Perry, Ronan; Lee, Theodore; Chang, Alexander; Koul, Arman; Vogelstein, Joshua T.] Johns Hopkins Univ, Dept Biomed Engn, Baltimore, MD 21218 USA.
   [Guo, Richard; Franz, Cameron] Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA.
   [Vogelstein, Joshua T.] Johns Hopkins Univ, Ctr Imaging Sci, Baltimore, MD 21218 USA.
   [Vogelstein, Joshua T.] Johns Hopkins Univ, Kavli Neurosci Discovery Inst, Inst Computat Med, Baltimore, MD 21218 USA.
   [Richard, Hugo; Gramfort, Alexandre] Univ Paris Saclay, INRIA, Palaiseau, France.
   [Carmichael, Iain] Univ Washington, Dept Stat, Seattle, WA 98195 USA.
   [Ablin, Pierre] PSL Univ, Ecole Normale Super, CNRS, Paris, France.
   [Ablin, Pierre] PSL Univ, Ecole Normale Super, DMA, Paris, France.
   [Vogelstein, Joshua T.] Progress Learning, Baltimore, MD 21218 USA.
   [Mischler, Gavin] Columbia Univ, Dept Elect Engn, New York, NY 10027 USA.
RP Vogelstein, JT (corresponding author), Johns Hopkins Univ, Dept Biomed Engn, Baltimore, MD 21218 USA.; Vogelstein, JT (corresponding author), Johns Hopkins Univ, Ctr Imaging Sci, Baltimore, MD 21218 USA.; Vogelstein, JT (corresponding author), Johns Hopkins Univ, Kavli Neurosci Discovery Inst, Inst Computat Med, Baltimore, MD 21218 USA.; Vogelstein, JT (corresponding author), Progress Learning, Baltimore, MD 21218 USA.
EM RPERRY27@JHU.EDU; GM2944@COLUMBIA.EDU; RICHARDG7890@GMAIL.COM;
   TLEE124@JHU.EDU; ALEXC3071@GMAIL.COM; ARMANKOUL@GMAIL.COM;
   CFRANZ3@JHU.EDU; HUGO.RICHARD@INRIA.FR; IDC9@UW.EDU;
   PIERRE.ABLIN@ENS.FR; ALEXANDRE.GRAMFORT@INRIA.FR; JOVO@JHU.EDU
FU Defense Advanced Research Projects Agency (DARPA) Lifelong Learning
   Machines programUnited States Department of DefenseDefense Advanced
   Research Projects Agency (DARPA) [FA8650-18-2-7834]; NIH HHS/United
   StatesUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [R01 AG066184/AG/NIA]; Microsoft
   Research; NeuroData Design class at Johns Hopkins University; NeuroData
   lab at Johns Hopkins UniversityJohns Hopkins University
FX This work is supported by the Defense Advanced Research Projects Agency
   (DARPA) Lifelong Learning Machines program through contract
   FA8650-18-2-7834, by R01 AG066184/AG/NIA NIH HHS/United States, and
   through funding from Microsoft Research. We thank the NeuroData Design
   class and the NeuroData lab at Johns Hopkins University for support and
   guidance as well as the reviewers for their helpful feedback.
NR 33
TC 0
Z9 0
U1 3
U2 4
PU MICROTOME PUBL
PI BROOKLINE
PA 31 GIBBS ST, BROOKLINE, MA 02446 USA
SN 1532-4435
J9 J MACH LEARN RES
JI J. Mach. Learn. Res.
PY 2021
VL 22
AR 109
PG 7
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA SU5GA
UT WOS:000663164600001
DA 2022-04-17
ER

PT J
AU Kuwajima, H
   Yasuoka, H
   Nakae, T
AF Kuwajima, Hiroshi
   Yasuoka, Hirotoshi
   Nakae, Toshihiro
TI Engineering problems in machine learning systems
SO MACHINE LEARNING
LA English
DT Article
DE Machine learning; Software engineering; Systems engineering; Safety
   critical systems; Automated driving; Quality models
AB Fatal accidents are a major issue hindering the wide acceptance of safety-critical systems that employ machine learning and deep learning models, such as automated driving vehicles. In order to use machine learning in a safety-critical system, it is necessary to demonstrate the safety and security of the system through engineering processes. However, thus far, no such widely accepted engineering concepts or frameworks have been established for these systems. The key to using a machine learning model in a deductively engineered system is decomposing the data-driven training of machine learning models into requirement, design, and verification, particularly for machine learning models used in safety-critical systems. Simultaneously, open problems and relevant technical fields are not organized in a manner that enables researchers to select a theme and work on it. In this study, we identify, classify, and explore the open problems in engineering (safety-critical) machine learning systems-that is, in terms of requirement, design, and verification of machine learning models and systems-as well as discuss related works and research directions, using automated driving vehicles as an example. Our results show that machine learning models are characterized by a lack of requirements specification, lack of design specification, lack of interpretability, and lack of robustness. We also perform a gap analysis on a conventional system quality standard SQuaRE with the characteristics of machine learning models to study quality models for machine learning systems. We find that a lack of requirements specification and lack of robustness have the greatest impact on conventional quality models.
C1 [Kuwajima, Hiroshi; Yasuoka, Hirotoshi; Nakae, Toshihiro] DENSO CORP, Tokyo, Japan.
   [Kuwajima, Hiroshi] Tokyo Inst Technol, Tokyo, Japan.
RP Kuwajima, H (corresponding author), DENSO CORP, Tokyo, Japan.; Kuwajima, H (corresponding author), Tokyo Inst Technol, Tokyo, Japan.
EM hiroshi.kuwajima.j7d@jp.denso.com; hirotoshi.yasuoka.j2z@jp.denso.com;
   toshihiro.nakae.j8z@jp.denso.com
OI Kuwajima, Hiroshi/0000-0003-0731-8057
NR 76
TC 8
Z9 8
U1 9
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0885-6125
EI 1573-0565
J9 MACH LEARN
JI Mach. Learn.
PD MAY
PY 2020
VL 109
IS 5
BP 1103
EP 1126
DI 10.1007/s10994-020-05872-w
EA APR 2020
PG 24
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LQ2AA
UT WOS:000528284900001
OA Green Submitted, hybrid
DA 2022-04-17
ER

PT S
AU Mirjalili, S
   Faris, H
   Aljarah, I
AF Mirjalili, Seyedali
   Faris, Hossam
   Aljarah, Ibrahim
BE Mirjalili, S
   Faris, H
   Aljarah, I
TI Introduction to Evolutionary Machine Learning Techniques
SO EVOLUTIONARY MACHINE LEARNING TECHNIQUES: ALGORITHMS AND APPLICATIONS
SE Algorithms for Intelligent Systems
LA English
DT Editorial Material; Book Chapter
DE Machine learning; Artificial Intelligence; Neural network; Support
   vector machine; Feature selection; Supervised learning; Unsupervised
   learning; Evolutionary algorithms; Python; Optimization; Reinforcement
   learning; Classification; Regression; Clustering; Dataset
AB This section first provides an overview of the machine learning field in artificial intelligence (AI). The most well-regarded classes of methods in AI are discussed to show where AI optimization algorithms and machine learning techniques fit in. Different types of learning are briefly covered as well including supervised, unsupervised, and reinforcement techniques. The last part of this chapter includes discussions on evolutionary machine learning, which is the focus of this book.
C1 [Mirjalili, Seyedali] Torrens Univ Australia, Brisbane, Qld 4006, Australia.
   [Mirjalili, Seyedali] Griffith Univ, Brisbane, Qld 4111, Australia.
   [Faris, Hossam; Aljarah, Ibrahim] Univ Jordan, King Abdullah II Sch Informat Technol, Amman, Jordan.
RP Mirjalili, S (corresponding author), Torrens Univ Australia, Brisbane, Qld 4006, Australia.; Mirjalili, S (corresponding author), Griffith Univ, Brisbane, Qld 4111, Australia.
EM ali.mirjalili@gmail.com
RI Aljarah, Ibrahim/J-5770-2019; Mirjalili, Seyedali/P-1372-2018; Faris,
   Hossam/C-2392-2015; Aljarah, Ibrahim/J-4719-2013
OI Mirjalili, Seyedali/0000-0002-1443-9458; Faris,
   Hossam/0000-0003-4261-8127; Aljarah, Ibrahim/0000-0002-9265-9819
NR 13
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER-VERLAG SINGAPORE PTE LTD
PI SINGAPORE
PA 152 BEACH ROAD, #21-01/04 GATEWAY EAST, SINGAPORE, 189721, SINGAPORE
SN 2524-7565
EI 2524-7573
BN 978-981-32-9990-0; 978-981-32-9989-4
J9 ALGO INTELL SY
PY 2020
BP 1
EP 7
DI 10.1007/978-981-32-9990-0_1
D2 10.1007/978-981-32-9990-0
PG 7
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory & Methods
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BQ9YU
UT WOS:000627405000002
DA 2022-04-17
ER

PT C
AU DeGuchy, O
   Alvarez, J
   Kim, A
   Marcia, RF
   Tsogka, C
AF DeGuchy, Omar
   Alvarez, Jacqueline
   Kim, Arnold
   Marcia, Roummel F.
   Tsogka, Chrysoula
BE Zelinski, ME
   Taha, TM
   Howe, J
   Awwal, AA
   Iftekharuddin, KM
TI Machine learning for forward and inverse scattering in synthetic
   aperture radar
SO APPLICATIONS OF MACHINE LEARNING 2020
SE Proceedings of SPIE
LA English
DT Proceedings Paper
CT Conference on Applications of Machine Learning
CY AUG 24-SEP 04, 2020
CL ELECTR NETWORK
SP SPIE
DE Synthetic aperture radar; machine learning; inverse problem
ID TUTORIAL
AB We present a study that uses machine learning to solve the forward and inverse scattering problems for synthetic aperture radar (SAR). Using a training set of known reflectivities as inputs and the resulting SAR measurements as outputs, the machine learning method produces an approximation for the sensing matrix of the forward scattering problem. Conversely, employing that same training set but with the SAR measurements used as inputs and the reflectivities as outputs, the machine learning method produces an approximate inverse of the sensing matrix. This learned approximate inverse mapping allows us to solve the inverse scattering problem as it maps SAR measurements to an estimate of the reflectivity. To interpret these results, we restrict our attention to a neural network arranged as a single, fully-connected layer. By doing so, we are able to interpret and evaluate the mappings produced by machine learning in addition to the results of those mappings. Employing a training set made up of 50,000 of the CIFAR-10 dataset as the reflectivities, we simulate SAR measurements using a physical model for the sensing matrix. With this training set of reflectivities and corresponding SAR measurements, we find that the results of machine learning accurately approximate the sensing matrix and provide a better answer to the inverse scattering problem than the standard SAR inversion formula. We also test the performance of the proposed methodology on a dataset with high resolution images while training with a lower resolution data set. The results are very promising showing again a superior performance for the learned approximate inverse mapping.
C1 [DeGuchy, Omar; Alvarez, Jacqueline; Kim, Arnold; Marcia, Roummel F.; Tsogka, Chrysoula] Univ Calif Merced, 5200 N Lake Rd, Merced, CA 95343 USA.
RP DeGuchy, O (corresponding author), Univ Calif Merced, 5200 N Lake Rd, Merced, CA 95343 USA.
EM odeguchy@ucmerced.edu; jalvarez94@ucmerced.edu; adkim@ucmerced.edu;
   rmarcia@ucmerced.edu; ctsogka@ucmerced.edu
FU National Science FoundationNational Science Foundation (NSF) [DMS
   1840265]; Air Force Office of Scientific ResearchUnited States
   Department of DefenseAir Force Office of Scientific Research (AFOSR)
   [FA9550-17-1-0238, FA9550-18-1-0519]
FX J. Alvarez is supported by the National Science Foundation (Grant: DMS
   1840265). O. DeGuchy, A. D. Kim, and C. Tsogka are supported by the Air
   Force Office of Scientific Research (Grants: FA9550-17-1-0238 and
   FA9550-18-1-0519).
NR 12
TC 1
Z9 1
U1 1
U2 2
PU SPIE-INT SOC OPTICAL ENGINEERING
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA
SN 0277-786X
EI 1996-756X
BN 978-1-5106-3829-7
J9 PROC SPIE
PY 2020
VL 11511
AR 115110S
DI 10.1117/12.2568302
PG 14
WC Computer Science, Artificial Intelligence; Physics, Applied; Imaging
   Science & Photographic Technology
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Physics; Imaging Science & Photographic Technology
GA BQ4II
UT WOS:000589895400020
DA 2022-04-17
ER

PT J
AU Mohr, F
   Wever, M
   Tornede, A
   Hullermeier, E
AF Mohr, Felix
   Wever, Marcel
   Tornede, Alexander
   Huellermeier, Eyke
TI Predicting Machine Learning Pipeline Runtimes in the Context of
   Automated Machine Learning
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Pipelines; Runtime; Prediction algorithms; Predictive models; Machine
   learning; Tools; Machine learning algorithms; Automated machine
   learning; runtime prediction for classifiers and pipelines; hierarchical
   runtime prediction
AB Automated machine learning (AutoML) seeks to automatically find so-called machine learning pipelines that maximize the prediction performance when being used to train a model on a given dataset. One of the main and yet open challenges in AutoMLis an effective use of computational resources: An AutoML process involves the evaluation of many candidate pipelines, which are costly but often ineffective because they are canceled due to a timeout. In this paper, we present an approach to predict the runtime of two-step machine learning pipelines with up to one pre-processor, which can be used to anticipate whether or not a pipeline will time out. Separate runtime models are trained offline for each algorithm that may be used in a pipeline, and an overall prediction is derived from these models. We empirically show that the approach increases successful evaluations made by an AutoML tool while preserving or even improving on the previously best solutions.
C1 [Mohr, Felix] Univ La Sabana, Dept Comp Sci, Chia 250001, Cundinamarca, Colombia.
   [Wever, Marcel; Huellermeier, Eyke] Paderborn Univ, Dept Comp Sci, D-33098 Paderborn, Germany.
   [Tornede, Alexander] Paderborn Univ, Heinz Nixdorf Inst, D-33098 Paderborn, Germany.
RP Mohr, F (corresponding author), Univ La Sabana, Dept Comp Sci, Chia 250001, Cundinamarca, Colombia.
EM fmohr@mail.upb.de; marcel.wever@upb.de; alexander.tornede@upb.de;
   eyke@upb.de
OI Tornede, Alexander/0000-0002-2415-2186
FU German Research Foundation (DFG) within the Collaborative Research
   Center "On-The-Fly Computing"German Research Foundation (DFG) [SFB
   901/3, 160364472]; Paderborn Center for Parallel Computing (PC2)
FX This work was supported in part by the German Research Foundation (DFG)
   within the Collaborative Research Center "On-The-Fly Computing" (SFB
   901/3 Project no. 160364472). The authors gratefully acknowledge support
   by the Paderborn Center for Parallel Computing (PC2), which provided
   computational resources and computing time.
NR 22
TC 1
Z9 1
U1 9
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD SEPT 1
PY 2021
VL 43
IS 9
BP 3055
EP 3066
DI 10.1109/TPAMI.2021.3056950
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TU6DH
UT WOS:000681124300016
PM 33539291
DA 2022-04-17
ER

PT J
AU Field, M
   Hardcastle, N
   Jameson, M
   Aherne, N
   Holloway, L
AF Field, Matthew
   Hardcastle, Nicholas
   Jameson, Michael
   Aherne, Noel
   Holloway, Lois
TI Machine learning applications in radiation oncology
SO PHYSICS & IMAGING IN RADIATION ONCOLOGY
LA English
DT Review
DE Machine learning; Artificial intelligence; Radiation therapy; Data
   mining; Automation
ID BEAM ANGLE SELECTION; CLINICAL DECISION-SUPPORT; REAL-TIME PREDICTION;
   RESPIRATORY TUMOR MOTION; SYNTHETIC CT; CANCER-PATIENTS; STEREOTACTIC
   RADIOSURGERY; GENETIC ALGORITHMS; AUTO-SEGMENTATION; TARGET VOLUMES
AB Machine learning technology has a growing impact on radiation oncology with an increasing presence in research and industry. The prevalence of diverse data including 3D imaging and the 3D radiation dose delivery presents potential for future automation and scope for treatment improvements for cancer patients. Harnessing this potential requires standardization of tools and data, and focused collaboration between fields of expertise. The rapid advancement of radiation oncology treatment technologies presents opportunities for machine learning integration with investments targeted towards data quality, data extraction, software, and engagement with clinical expertise. In this review, we provide an overview of machine learning concepts before reviewing advances in applying machine learning to radiation oncology and integrating these techniques into the radiation oncology workflows. Several key areas are outlined in the radiation oncology workflow where machine learning has been applied and where it can have a significant impact in terms of efficiency, consistency in treatment and overall treatment outcomes. This review highlights that machine learning has key early applications in radiation oncology due to the repetitive nature of many tasks that also currently have human review. Standardized data management of routinely collected imaging and radiation dose data are also highlighted as enabling engagement in research utilizing machine learning and the ability integrate these technologies into clinical workflow to benefit patients. Physicists need to be part of the conversation to facilitate this technical integration.
C1 [Field, Matthew; Holloway, Lois] Univ New South Wales, Fac Med, South Western Sydney Clin Sch, Sydney, NSW, Australia.
   [Field, Matthew; Holloway, Lois] Ingham Inst Appl Med Res, Sydney, NSW, Australia.
   [Holloway, Lois] Liverpool Hosp, Canc Therapy Ctr, Sydney, NSW, Australia.
   [Hardcastle, Nicholas] Peter MacCallum Canc Ctr, Phys Sci, Melbourne, Vic, Australia.
   [Hardcastle, Nicholas; Holloway, Lois] Univ Wollongong, Ctr Med Radiat Phys, Wollongong, NSW, Australia.
   [Aherne, Noel] Mid North Coast Canc Inst, Coffs Harbour, NSW, Australia.
   [Aherne, Noel] Univ New South Wales, Fac Med, Rural Clin Sch, Sydney, NSW, Australia.
   [Jameson, Michael] GenesisCare, Alexandria, NSW, Australia.
   [Jameson, Michael] Univ New South Wales, Fac Med, St Vincents Clin Sch, Sydney, NSW, Australia.
RP Aherne, N (corresponding author), Mid North Coast Canc Inst, Dept Radiat Oncol, 345 Pacific Highway, Coffs Harbour, NSW 2450, Australia.
EM noel.aherne@health.nsw.gov.au
RI ; Field, Matthew/J-2810-2015
OI Jameson, Michael/0000-0003-4867-7670; Field,
   Matthew/0000-0002-6169-6721; Holloway, Lois/0000-0003-4337-2165
FU Varian Medical Systems Collab-orative Research Grant for Kidney SABR
FX The authors declare the following financial interests/personal
   re-lationships which may be considered as potential competing interests:
   N Hardcastle receives funding through a Varian Medical Systems
   Collab-orative Research Grant for Kidney SABR. This grant includes
   compo-nents of machine learning as applied for treatment planning.
NR 175
TC 2
Z9 2
U1 6
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
EI 2405-6316
J9 PHYS IMAG RADIAT ONC
JI Phys. Imag. Radiat. Oncol.
PD JUL
PY 2021
VL 19
BP 13
EP 24
DI 10.1016/j.phro.2021.05.007
EA JUN 2021
PG 12
WC Oncology; Radiology, Nuclear Medicine & Medical Imaging
WE Emerging Sources Citation Index (ESCI)
SC Oncology; Radiology, Nuclear Medicine & Medical Imaging
GA UO5CJ
UT WOS:000694711800003
PM 34307915
OA Green Published, gold
DA 2022-04-17
ER

PT C
AU Sanusi, IT
AF Sanusi, Ismaila Temitayo
GP ASSOC COMP MACHINERY
TI Teaching Machine Learning in K-12 Education
SO ICER 2021: PROCEEDINGS OF THE 17TH ACM CONFERENCE ON INTERNATIONAL
   COMPUTING EDUCATION RESEARCH
LA English
DT Proceedings Paper
CT 17th Annual ACM Conference on International Computing Education Research
   (ICER)
CY AUG 16-19, 2021
CL ELECTR NETWORK
SP Assoc Comp Machinery, ACM Special Interest Grp Comp Sci Educ
DE Teaching machine learning; K-12; Pedagogy; Machine Learning Education;
   Machine Learning Tools
AB This research is interested in how to teach machine learning concepts to K-12 learners. There is limited evidence to support the teaching, learning, and usefulness of machine learning in K-12 settings, hence addressing the evident gap. This research aims to specifically identify pedagogical approaches with the underlying theories and methods in teaching K-12 machine learning as well as design, assess, and determine the impact of machine learning on student outcomes in K-12.
C1 [Sanusi, Ismaila Temitayo] Univ Eastern Finland, Sch Comp, Kuopio, Finland.
RP Sanusi, IT (corresponding author), Univ Eastern Finland, Sch Comp, Kuopio, Finland.
EM ismaila.sanusi@uef.fi
NR 29
TC 0
Z9 0
U1 2
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-8326-4
PY 2021
BP 395
EP 397
DI 10.1145/3446871.3469769
PG 3
WC Computer Science, Theory & Methods; Education & Educational Research;
   Education, Scientific Disciplines
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Education & Educational Research
GA BS8AI
UT WOS:000769652800033
DA 2022-04-17
ER

PT J
AU Cho, S
   Vasarhelyi, MA
   Sun, T
   Zhang, C
AF Cho, Soohyun
   Vasarhelyi, Miklos A.
   Sun, Ting (Sophia)
   Zhang, Chanyuan (Abigail)
TI Learning from Machine Learning in Accounting and Assurance
SO JOURNAL OF EMERGING TECHNOLOGIES IN ACCOUNTING
LA English
DT Editorial Material
DE machine learning; accounting; assurance; inductive reasoning; biases and
   ethics of machine learning
ID AUDIT; FRAUD
AB Machine learning is a subset of artificial intelligence, and it is a computational method that learns patterns from large and complex data. The learning processes enable us to make predictions for future events. In the accounting and assurance profession, machine learning is gradually being applied to various tasks like reviewing source documents, analyzing business transactions or activities, and assessing risks. In academic research, machine learning has been used to make predictions of fraud, bankruptcy, material misstatements, and accounting estimates. More importantly, machine learning is generating awareness about the inductive reasoning methodology, which has long been undervalued in the mainstream of academic research in accounting and auditing. The use of machine learning in accounting/auditing research and practice is also raising concerns about its potential bias and ethical implications. Therefore, this editorial aims to call the readers' attention to these issues and encourage scholars to perform research in this domain.
C1 [Cho, Soohyun; Vasarhelyi, Miklos A.; Zhang, Chanyuan (Abigail)] Rutgers State Univ, New Brunswick, NJ 08901 USA.
   [Sun, Ting (Sophia)] Coll New Jersey, Ewing Township, NJ USA.
   [Zhang, Chanyuan (Abigail)] Southwestern Univ Finance & Econ, Chengdu, Sichuan, Peoples R China.
RP Cho, S (corresponding author), Rutgers State Univ, New Brunswick, NJ 08901 USA.
NR 55
TC 6
Z9 6
U1 11
U2 33
PU AMER ACCOUNTING ASSOC
PI SARASOTA
PA 5717 BESSIE DR, SARASOTA, FL 34233 USA
SN 1554-1908
EI 1558-7940
J9 J EMERG TECHNOL ACCO
JI J. Emerg. Technol. Account.
PD SPR
PY 2020
VL 17
IS 1
BP 1
EP 10
DI 10.2308/jeta-10718
PG 10
WC Business, Finance
WE Emerging Sources Citation Index (ESCI)
SC Business & Economics
GA NS7SI
UT WOS:000572456900001
DA 2022-04-17
ER

PT C
AU Chalabi, NE
   Attia, A
   Akrouf, S
AF Chalabi, Nour Elhouda
   Attia, Abdelouahab
   Akrouf, Samir
BE Auer, ME
   Tsiatsos, T
TI Machine Learning and Deep Learning: Recent Overview in Medical Care
SO INTERNET OF THINGS, INFRASTRUCTURES AND MOBILE APPLICATIONS
SE Advances in Intelligent Systems and Computing
LA English
DT Proceedings Paper
CT 13th International Conference on Interactive Mobile Communication,
   Technologies and Learning (IMCL)
CY OCT 31-NOV 01, 2019
CL Thessaloniki, GREECE
SP Aristotle Univ Thessaloniki
DE Machine; Learning; Deep learning; Medical care; Medical databases
ID SEGMENTATION; IMAGES
AB Medical care has always presented quite wide ranged and challenging problems. However, machine learning techniques and methods as well as deep learning never stopped evolving and tackling those challenges issued by medicine, medical and health care. In order to have a more close up look on how machine learning and deep learning has been affecting medical care in general, we review in this paper some machine learning and deep learning techniques used in a variety of medical care sections such as medical imaging, medical decision, diagnostic, medical records and big data, and disease prediction.
C1 [Chalabi, Nour Elhouda; Attia, Abdelouahab] Mohamed El Bachir El Ibrahimi Univ Bordj Bou Arre, El Anseur, Algeria.
   [Akrouf, Samir] Mohamed Boudiaf Univ Msila, Msila, Algeria.
RP Chalabi, NE (corresponding author), Mohamed El Bachir El Ibrahimi Univ Bordj Bou Arre, El Anseur, Algeria.
EM chalabi.houda94@gmail.com; attia.abdelouahab@gmail.com;
   samir.akrouf@gmail.com
NR 26
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2194-5357
EI 2194-5365
BN 978-3-030-49932-7; 978-3-030-49931-0
J9 ADV INTELL SYST COMP
PY 2021
VL 1192
BP 223
EP 231
DI 10.1007/978-3-030-49932-7_22
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS8HJ
UT WOS:000772212200022
DA 2022-04-17
ER

PT J
AU Roscher, R
   Bohn, B
   Duarte, MF
   Garcke, J
AF Roscher, Ribana
   Bohn, Bastian
   Duarte, Marco F.
   Garcke, Jochen
TI Explainable Machine Learning for Scientific Insights and Discoveries
SO IEEE ACCESS
LA English
DT Article
DE Machine learning; Data models; Mathematical model; Kernel; Biological
   system modeling; Approximation algorithms; Data mining; Explainable
   machine learning; informed machine learning; interpretability;
   scientific consistency; transparency
ID EQUATIONS; NETWORKS; DESIGN; MODEL
AB Machine learning methods have been remarkably successful for a wide range of application areas in the extraction of essential information from data. An exciting and relatively recent development is the uptake of machine learning in the natural sciences, where the major goal is to obtain novel scientific insights and discoveries from observational or simulated data. A prerequisite for obtaining a scientific outcome is domain knowledge, which is needed to gain explainability, but also to enhance scientific consistency. In this article, we review explainable machine learning in view of applications in the natural sciences and discuss three core elements that we identified as relevant in this context: transparency, interpretability, and explainability. With respect to these core elements, we provide a survey of recent scientific works that incorporate machine learning and the way that explainable machine learning is used in combination with domain knowledge from the application areas.
C1 [Roscher, Ribana] Univ Bonn, Inst Geodesy & Geoinformat, D-53115 Bonn, Germany.
   [Roscher, Ribana] Univ Osnabrueck, Inst Comp Sci, D-49074 Osnabruck, Germany.
   [Bohn, Bastian; Garcke, Jochen] Univ Bonn, Inst Numer Simulat, D-53115 Bonn, Germany.
   [Duarte, Marco F.] Univ Massachusetts, Dept Elect & Comp Engn, Amherst, MA 01003 USA.
   [Garcke, Jochen] Fraunhofer Ctr Machine Learning & Fraunhofer SCAI, D-53757 St Augustin, Germany.
RP Garcke, J (corresponding author), Univ Bonn, Inst Numer Simulat, D-53115 Bonn, Germany.; Garcke, J (corresponding author), Fraunhofer Ctr Machine Learning & Fraunhofer SCAI, D-53757 St Augustin, Germany.
EM jochen.garcke@scai.fraunhofer.de
RI Roscher, Ribana/N-2238-2014
OI Roscher, Ribana/0000-0003-0094-6210; Garcke, Jochen/0000-0002-8334-3695
FU Fraunhofer Cluster of Excellence Cognitive Internet Technologies;
   Deutsche ForschungsgemeinschaftGerman Research Foundation (DFG)
   [Sonderforschungsbereich 1060]
FX This work was supported in part by the Fraunhofer Cluster of Excellence
   Cognitive Internet Technologies, and in part by the
   Sonderforschungsbereich 1060-The Mathematics of Emergent Effects-funded
   by the Deutsche Forschungsgemeinschaft.
NR 117
TC 105
Z9 106
U1 80
U2 123
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 42200
EP 42216
DI 10.1109/ACCESS.2020.2976199
PG 17
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA LC5SC
UT WOS:000525389000018
OA gold, Green Submitted
HC Y
HP N
DA 2022-04-17
ER

PT J
AU Gennatas, ED
   Friedman, JH
   Ungar, LH
   Pirracchio, R
   Eaton, E
   Reichmann, LG
   Interian, Y
   Luna, JM
   Simone, CB
   Auerbach, A
   Delgado, E
   van der Laan, MJ
   Solberg, TD
   Valdes, G
AF Gennatas, Efstathios D.
   Friedman, Jerome H.
   Ungar, Lyle H.
   Pirracchio, Romain
   Eaton, Eric
   Reichmann, Lara G.
   Interian, Yannet
   Luna, Jose Marcio
   Simone, Charles B., II
   Auerbach, Andrew
   Delgado, Elier
   van der Laan, Mark J.
   Solberg, Timothy D.
   Valdes, Gilmer
TI Expert-augmented machine learning
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
LA English
DT Article
DE machine learning; medicine; computational medicine
ID ACUTE PHYSIOLOGY SCORE; SAPS; PREDICTION; MORTALITY; APACHE
AB Machine learning is proving invaluable across disciplines. However, its success is often limited by the quality and quantity of available data, while its adoption is limited by the level of trust afforded by given models. Human vs. machine performance is commonly compared empirically to decide whether a certain task should be performed by a computer or an expert. In reality, the optimal learning strategy may involve combining the complementary strengths of humans and machines. Here, we present expert-augmented machine learning (EAML), an automated method that guides the extraction of expert knowledge and its integration into machine-learned models. We used a large dataset of intensive-care patient data to derive 126 decision rules that predict hospital mortality. Using an online platform, we asked 15 clinicians to assess the relative risk of the subpopulation defined by each rule compared to the total sample. We compared the clinician-assessed risk to the empirical risk and found that, while clinicians agreed with the data in most cases, there were notable exceptions where they overestimated or underestimated the true risk. Studying the rules with greatest disagreement, we identified problems with the training data, including one miscoded variable and one hidden confounder. Filtering the rules based on the extent of disagreement between clinician-assessed risk and empirical risk, we improved performance on out-of-sample data and were able to train with less data. EAML provides a platform for automated creation of problem-specific priors, which help build robust and dependable machine-learning models in critical applications.
C1 [Gennatas, Efstathios D.; Solberg, Timothy D.; Valdes, Gilmer] Univ Calif San Francisco, Dept Radiat Oncol, San Francisco, CA 94143 USA.
   Stanford Univ, Dept Stat, Stanford, CA 94305 USA.
   [Ungar, Lyle H.; Eaton, Eric] Univ Penn, Dept Comp & Informat Sci, Philadelphia, PA 19104 USA.
   [Pirracchio, Romain] Univ Calif San Francisco, Dept Anesthesia & Perioperat Care, San Francisco, CA 94143 USA.
   [Reichmann, Lara G.; Interian, Yannet] Univ San Francisco, Data Inst, San Francisco, CA 94105 USA.
   [Luna, Jose Marcio] Univ Penn, Dept Radiat Oncol, Philadelphia, PA 19104 USA.
   [Simone, Charles B., II] New York Proton Ctr, Dept Radiat Oncol, New York, NY 10035 USA.
   [Auerbach, Andrew] Univ Calif San Francisco, Div Hosp Med, San Francisco, CA 94143 USA.
   [Delgado, Elier] Innova Montreal Inc, Montreal, PQ J4W 2P2, Canada.
   [van der Laan, Mark J.] Univ Calif Berkeley, Div Biostat, Berkeley, CA 94720 USA.
   [Gennatas, Efstathios D.] Stanford Univ, Dept Radiat Oncol, Stanford, CA 94305 USA.
RP Gennatas, ED (corresponding author), Univ Calif San Francisco, Dept Radiat Oncol, San Francisco, CA 94143 USA.; Gennatas, ED (corresponding author), Stanford Univ, Dept Radiat Oncol, Stanford, CA 94305 USA.
EM gennatas@stanford.edu
RI Luna, Jose Marcio/ABG-1296-2020
OI Friedman, Jerome/0000-0001-5968-8901; Gennatas,
   Efstathios/0000-0001-9280-3609; Luna, Jose/0000-0002-5513-022X; ,
   Timothy/0000-0001-8829-7774
FU National Institute of Biomedical Imaging and BioengineeringUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute of Biomedical Imaging & Bioengineering
   (NIBIB) [K08EB026500]; National Institute of Allergy and Infectious
   DiseasesUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute of Allergy &
   Infectious Diseases (NIAID) [5R01AI074345-09]; National Center for
   Advancing Translational Sciences through University of California, San
   Francisco-Clinical & Translational Science Institute [Ul1TR001872];
   Wicklow AI in Medicine Research Initiative at the University of San
   Francisco Data Institute
FX We thank two anonymous reviewers for their constructive feedback.
   Research reported in this publication was supported by the National
   Institute of Biomedical Imaging and Bioengineering under Award
   K08EB026500 (G.V.), by the National Institute of Allergy and Infectious
   Diseases under Award 5R01AI074345-09 (M.J.v.d.L.), by the National
   Center for Advancing Translational Sciences through University of
   California, San Francisco-Clinical & Translational Science Institute
   Grant Ul1TR001872 (G.V.), and by the Wicklow AI in Medicine Research
   Initiative at the University of San Francisco Data Institute (L.G.R. and
   Y.I.).
NR 24
TC 19
Z9 19
U1 4
U2 12
PU NATL ACAD SCIENCES
PI WASHINGTON
PA 2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA
SN 0027-8424
J9 P NATL ACAD SCI USA
JI Proc. Natl. Acad. Sci. U. S. A.
PD MAR 3
PY 2020
VL 117
IS 9
BP 4571
EP 4577
DI 10.1073/pnas.1906831117
PG 7
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA KS7FX
UT WOS:000518473500027
PM 32071251
OA Green Published, hybrid, Green Submitted
DA 2022-04-17
ER

PT J
AU Reig, B
   Heacock, L
   Geras, KJ
   Moy, L
AF Reig, Beatriu
   Heacock, Laura
   Geras, Krzysztof J.
   Moy, Linda
TI Machine learning in breast MRI
SO JOURNAL OF MAGNETIC RESONANCE IMAGING
LA English
DT Review
DE breast; MR; machine learning; deep learning; artificial intelligence;
   radiomics
ID BACKGROUND PARENCHYMAL ENHANCEMENT; CARCINOMA IN-SITU; CANCER MOLECULAR
   SUBTYPE; RECURRENCE-FREE SURVIVAL; SUPPORT VECTOR MACHINE; DCE-MRI;
   NEOADJUVANT CHEMOTHERAPY; PREOPERATIVE PREDICTION; FIBROGLANDULAR
   TISSUE; MAMMOGRAPHIC DENSITY
AB Machine-learning techniques have led to remarkable advances in data extraction and analysis of medical imaging. Applications of machine learning to breast MRI continue to expand rapidly as increasingly accurate 3D breast and lesion segmentation allows the combination of radiologist-level interpretation (eg, BI-RADS lexicon), data from advanced multiparametric imaging techniques, and patient-level data such as genetic risk markers. Advances in breast MRI feature extraction have led to rapid dataset analysis, which offers promise in large pooled multiinstitutional data analysis. The object of this review is to provide an overview of machine-learning and deep-learning techniques for breast MRI, including supervised and unsupervised methods, anatomic breast segmentation, and lesion segmentation. Finally, it explores the role of machine learning, current limitations, and future applications to texture analysis, radiomics, and radiogenomics. Technical Efficacy Stage:2 J. Magn. Reson. Imaging 2019. J. Magn. Reson. Imaging 2020;52:998-1018.
C1 [Reig, Beatriu] NYU, Dept Radiol, Sch Med, 560 1St Ave, New York, NY 10016 USA.
   [Heacock, Laura; Geras, Krzysztof J.; Moy, Linda] NYU, Dept Radiol, Sch Med, Bernard & Irene Schwartz Ctr Biomed Imaging, 560 1St Ave, New York, NY 10016 USA.
   [Moy, Linda] NYU, Sch Med, Ctr Adv Imaging Innovat & Res CAI2 R, New York, NY USA.
RP Reig, B (corresponding author), NYU, Sch Med, Canc Inst, 160 E 34 St, New York, NY 10016 USA.
EM beatriu.reig@nyulangone.org
RI Moy, Linda/U-8018-2019
OI Moy, Linda/0000-0001-9564-9360; Reig, Beatriu/0000-0002-6577-8601
FU NATIONAL CANCER INSTITUTEUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Cancer
   Institute (NCI) [R21CA225175] Funding Source: NIH RePORTER; NATIONAL
   INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERINGUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute of Biomedical Imaging & Bioengineering
   (NIBIB) [P41EB017183] Funding Source: NIH RePORTER; NCI NIH HHSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Cancer Institute (NCI) [R21 CA225175]
   Funding Source: Medline; NIBIB NIH HHSUnited States Department of Health
   & Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute of Biomedical Imaging & Bioengineering (NIBIB) [P41 EB017183]
   Funding Source: Medline
NR 125
TC 34
Z9 34
U1 24
U2 84
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1053-1807
EI 1522-2586
J9 J MAGN RESON IMAGING
JI J. Magn. Reson. Imaging
PD OCT
PY 2020
VL 52
IS 4
BP 998
EP 1018
DI 10.1002/jmri.26852
PG 21
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA NN7UI
UT WOS:000568991800003
PM 31276247
OA Green Accepted
DA 2022-04-17
ER

PT J
AU Bai, HR
AF Bai, Huiren
TI The Epistemology of Machine Learning
SO FILOSOFIJA-SOCIOLOGIJA
LA English
DT Article
DE machine learning; epistemological foundation; transparency;
   interpretabil-ity; machine knowledge
AB This paper argues that machine learning is a knowledge-producing enterprise, since we are increasingly relying on artificial intelligence. But the knowledge discovered by machine is completely beyond human experience and human reason, becoming al -most incomprehensible to humans. I argue that standard calls for interpretability that focus on the epistemic inscrutability of black-box machine learning may be misplaced. The problems of transparency and interpretability of machine learning stem from how we perceive the possibility of 'machine knowledge'. In other words, the justification for machine knowledge does not need to include transparency and interpretability. There-fore, I am going to examine some sort of machine learning epistemology and provide three possible justifications for machine knowledge, which are formal justification, model justification and practical justification.
C1 [Bai, Huiren] Zhejiang Univ, Dept Philosophy, 866 Yuhangtang Rd, Hangzhou 310058, Peoples R China.
RP Bai, HR (corresponding author), Zhejiang Univ, Dept Philosophy, 866 Yuhangtang Rd, Hangzhou 310058, Peoples R China.
EM bhuiren@gmail.com
FU National Social Science Fund of China 'Research on Distrib-utive Justice
   of Scientific Knowledge' [17CZX022]
FX The work was supported by the National Social Science Fund of China
   'Research on Distrib-utive Justice of Scientific Knowledge' (17CZX022) .
NR 15
TC 0
Z9 0
U1 2
U2 2
PU LITHUANIAN ACAD SCIENCES
PI VILNIUS
PA AKADEMIJOS ST.2, VILNIUS, 232600, LITHUANIA
SN 0235-7186
J9 FILOS-SOCIOL
JI Filos.-Sociol.
PY 2022
VL 33
IS 1
BP 40
EP 48
PG 9
WC Philosophy; Sociology
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Philosophy; Sociology
GA ZC7NH
UT WOS:000757701400006
DA 2022-04-17
ER

PT C
AU Lassance, C
   Gripon, V
   Mateos, G
AF Lassance, Carlos
   Gripon, Vincent
   Mateos, Gonzalo
GP IEEE
TI GRAPH TOPOLOGY INFERENCE BENCHMARKS FOR MACHINE LEARNING
SO PROCEEDINGS OF THE 2020 IEEE 30TH INTERNATIONAL WORKSHOP ON MACHINE
   LEARNING FOR SIGNAL PROCESSING (MLSP)
SE IEEE International Workshop on Machine Learning for Signal Processing
LA English
DT Proceedings Paper
CT 30th IEEE International Workshop on Machine Learning for Signal
   Processing (MLSP)
CY SEP 21-24, 2020
CL Aalto Univ, ELECTR NETWORK
SP IEEE, IEEE Signal Proc Soc, IEEE Signal Proc Soc, Machine Learning Signal Proc Tech Comm
HO Aalto Univ
DE Graph learning; network topology inference; benchmarks; graph signal
   processing; machine learning
AB Graphs are nowadays ubiquitous in the fields of signal processing and machine learning. As a tool used to express relationships between objects, graphs can be deployed to various ends: (i) clustering of vertices, (ii) semi-supervised classification of vertices, (iii) supervised classification of graph signals, and (iv) denoising of graph signals. However, in many practical cases graphs are not explicitly available and must therefore be inferred from data. Validation is a challenging endeavor that naturally depends on the downstream task for which the graph is learnt. Accordingly, it has often been difficult to compare the efficacy of different algorithms. In this work, we introduce several ease-to-use and publicly released benchmarks specifically designed to reveal the relative merits and limitations of graph inference methods. We also contrast some of the most prominent techniques in the literature.
C1 [Lassance, Carlos; Gripon, Vincent] IMT Atlantique, Lab STICC, Florence, France.
   [Mateos, Gonzalo] Univ Rochester, Dept ECE, Rochester, NY 14627 USA.
RP Lassance, C (corresponding author), IMT Atlantique, Lab STICC, Florence, France.
FU Brittany regionRegion Bretagne; NSFNational Science Foundation (NSF)
   [CCF-1750428]
FX This work was supported in part by the Brittany region and by the NSF
   award CCF-1750428.
NR 26
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2161-0363
BN 978-1-7281-6662-9
J9 IEEE INT WORKS MACH
PY 2020
PG 6
WC Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering
GA BR0UF
UT WOS:000630907800047
DA 2022-04-17
ER

PT C
AU Ferrario, A
   Weibel, R
   Feuerriegel, S
AF Ferrario, Andrea
   Weibel, Raphael
   Feuerriegel, Stefan
GP Assoc Comp Machinery
TI ALEEDSA: Augmented Reality for Interactive Machine Learning
SO CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS
   IN COMPUTING SYSTEMS
LA English
DT Proceedings Paper
CT ACM CHI Conference on Human Factors in Computing Systems (CHI)
CY APR 25-30, 2020
CL Honolulu, HI
SP ACM SIGCHI, Assoc Comp Machinery
DE Augmented reality; Mixed reality; Collaborative interaction; Machine
   learning
AB In this work, we present ALEEDSA: the first system for performing interactive machine learning with augmented reality. The system is characterized by the following three distinctive features: First, immersion is used for visualizing machine learning models in terms of their outcomes. The outcomes can then be compared against domain knowledge (e.g., via counterfactual explanations) so that users can better understand the behavior of machine learning models. Second, interactivity with augmented reality along the complete machine learning pipeline fosters rapid modeling. Third, collaboration enables a multi-user setting, wherein machine learning engineers and domain experts can jointly discuss the behavior of machine learning models. The effectiveness of our proof-of-concept is demonstrated in an experimental study involving both students and business professionals. Altogether, ALEEDSA provides a more straightforward utilization of machine learning in organizational and educational practice.
C1 [Ferrario, Andrea; Weibel, Raphael; Feuerriegel, Stefan] Swiss Fed Inst Technol, Zurich, Switzerland.
RP Ferrario, A (corresponding author), Swiss Fed Inst Technol, Zurich, Switzerland.
EM aferrario@ethz.ch; rweibel@ethz.ch; sfeuerriegel@ethz.ch
RI Feuerriegel, Stefan/ABD-6599-2021
OI Feuerriegel, Stefan/0000-0001-7856-8729
FU ETH Innovedum grant (project: "rETHinking data science education in
   management: Collaborative learning in business analytics"); Digital
   Lives grant from the Swiss National Science Foundation (SNSF)Swiss
   National Science Foundation (SNSF) [183149]
FX Financial support as part of an ETH Innovedum grant (project:
   "rETHinking data science education in management: Collaborative learning
   in business analytics") is gratefully acknowledged. The authors thank
   Eeva Tervahartiala for her support with the user study. Stefan
   Feuerriegel was supported by a Digital Lives grant (183149) from the
   Swiss National Science Foundation (SNSF).
NR 19
TC 0
Z9 0
U1 3
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6819-3
PY 2020
AR LBW085
DI 10.1145/3334480.3382937
PG 8
WC Computer Science, Cybernetics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ9OG
UT WOS:000626317802088
OA Green Accepted
DA 2022-04-17
ER

PT J
AU Li, Y
   Zeng, YJ
   Qing, YY
   Huang, GB
AF Li, Yue
   Zeng, Yijie
   Qing, Yuanyuan
   Huang, Guang-Bin
TI Learning local discriminative representations via extreme learning
   machine for machine fault diagnosis
SO NEUROCOMPUTING
LA English
DT Article
DE Extreme learning machine; Autoencoder; Discriminative information; Local
   geometry; Machine fault diagnosis
ID DIMENSIONALITY; FRAMEWORK; SCHEME
AB Recently, learning data representations have been investigated to reduce the dependences of human intervention and improve the performance of machine fault diagnosis. However, most of the representation learning methods are computationally intensive due to complex training procedures. Extreme learning machine is well-known for its fast training speed and strong generalization ability. It also has been applied to learn data representations for clustering and classification tasks. In this paper, a local discriminant preserving extreme learning machine autoencoder (LDELM-AE) is proposed to learn data representations with the local geometry and local discriminant exploited from the input data. Specifically, LDELM-AE utilizes two graphs to enhance the within-class compactness and between-class separability, respectively. Furthermore, the hierarchical representations can be obtained by stacking several LDELM-AEs. On several benchmark datasets, the proposed method demonstrates better classification accuracies than the state-of-the-art methods. Moreover, the proposed method has been used to diagnostic the rotary machine faults and achieves the diagnostic accuracy of 99.96%, which proves the proposed method is an efficient tool to diagnose machine faults. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Li, Yue; Zeng, Yijie; Qing, Yuanyuan; Huang, Guang-Bin] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
RP Li, Y (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
NR 34
TC 11
Z9 11
U1 2
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD OCT 7
PY 2020
VL 409
BP 275
EP 285
DI 10.1016/j.neucom.2020.05.021
PG 11
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NA9TN
UT WOS:000560159100002
DA 2022-04-17
ER

PT J
AU Lalehzarian, SP
   Gowd, AK
   Liu, JN
AF Lalehzarian, Simon P.
   Gowd, Anirudh K.
   Liu, Joseph N.
TI Machine learning in orthopaedic surgery
SO WORLD JOURNAL OF ORTHOPEDICS
LA English
DT Review
DE Artificial intelligence; Machine learning; Supervised learning;
   Unsupervised learning; Deep learning; Orthopaedic surgery
ID CLINICALLY IMPORTANT DIFFERENCES; CONVOLUTIONAL NEURAL-NETWORKS;
   MAGNETIC-RESONANCE IMAGES; ARTIFICIAL-INTELLIGENCE; SHAPE OPTIMIZATION;
   ALGORITHMS PREDICT; LUMBAR SPINE; TOTAL HIP; CLASSIFICATION;
   SEGMENTATION
AB Artificial intelligence and machine learning in orthopaedic surgery has gained mass interest over the last decade or so. In prior studies, researchers have demonstrated that machine learning in orthopaedics can be used for different applications such as fracture detection, bone tumor diagnosis, detecting hip implant mechanical loosening, and grading osteoarthritis. As time goes on, the utility of artificial intelligence and machine learning algorithms, such as deep learning, continues to grow and expand in orthopaedic surgery. The purpose of this review is to provide an understanding of the concepts of machine learning and a background of current and future orthopaedic applications of machine learning in risk assessment, outcomes assessment, imaging, and basic science fields. In most cases, machine learning has proven to be just as effective, if not more effective, than prior methods such as logistic regression in assessment and prediction. With the help of deep learning algorithms, such as artificial neural networks and convolutional neural networks, artificial intelligence in orthopaedics has been able to improve diagnostic accuracy and speed, flag the most critical and urgent patients for immediate attention, reduce the amount of human error, reduce the strain on medical professionals, and improve care. Because machine learning has shown diagnostic and prognostic uses in orthopaedic surgery, physicians should continue to research these techniques and be trained to use these methods effectively in order to improve orthopaedic treatment.
C1 [Lalehzarian, Simon P.] Rosalind Franklin Univ Med & Sci, Chicago Med Sch, Chicago, IL 60064 USA.
   [Gowd, Anirudh K.] Wake Forest Baptist Med Ctr, Dept Orthopaed Surg, Winston Salem, NC 27157 USA.
   [Liu, Joseph N.] Keck Med USC, USC Epstein Family Ctr Sports Med, 1520 San Pablo St 2000, Los Angeles, CA 90033 USA.
RP Liu, JN (corresponding author), Keck Med USC, USC Epstein Family Ctr Sports Med, 1520 San Pablo St 2000, Los Angeles, CA 90033 USA.
EM joseph.liu@med.usc.edu
RI Liu`, Joseph/AAI-8201-2020
OI Liu`, Joseph/0000-0002-3801-8885
NR 91
TC 1
Z9 1
U1 16
U2 16
PU BAISHIDENG PUBLISHING GROUP INC
PI PLEASANTON
PA 7041 Koll Center Parkway, Suite 160, PLEASANTON, CA, UNITED STATES
SN 2218-5836
J9 WORLD J ORTHOP
JI World J. Orthop.
PD SEP 18
PY 2021
VL 12
IS 9
BP 685
EP 699
DI 10.5312/wjo.v12.i9.685
PG 15
WC Orthopedics
WE Emerging Sources Citation Index (ESCI)
SC Orthopedics
GA WC8NJ
UT WOS:000704508900007
PM 34631452
OA Green Published, gold
DA 2022-04-17
ER

PT C
AU Ma, ZR
   Arteaga, R
   Wang, MX
   Silveira, C
AF Ma, Zhuoren
   Arteaga, Ryan
   Wang, Muxuan
   Silveira, Christine
BE Sun, HB
TI Machine Learning to Optimize Permanent Magnet Synchronous Machines
SO PROCEEDINGS OF 2020 IEEE 2ND INTERNATIONAL CONFERENCE ON CIVIL AVIATION
   SAFETY AND INFORMATION TECHNOLOGY (ICCASIT)
LA English
DT Proceedings Paper
CT 2nd IEEE International Conference on Civil Aviation Safety and
   Information Technology (ICCASIT)
CY OCT 14-16, 2020
CL Wuhan, PEOPLES R CHINA
SP IEEE, China Acad Civil Aviat Sci & Technol, IEEE Beijing Sect, Wuhan Univ, Nanjing Univ Aeronaut & Astronaut
DE Electric motors; Estimation; Machine Learning; PMSM
AB In this paper, we offer a possible approach to estimating motor parameters: Machine Learning. We begin with a simulation of a Permanent Magnet Synchronous Motor (PMSM) model using MATLAB and Simulink. We measure the voltage and current and then send the data to a machine learning model (TensorFlow). From there, we discuss the accuracy of the estimations and future stages of the project. We also use machine learning method to estimate position and speed.
C1 [Ma, Zhuoren; Arteaga, Ryan; Wang, Muxuan; Silveira, Christine] Columbia Univ, New York, NY 10027 USA.
RP Ma, ZR (corresponding author), Columbia Univ, New York, NY 10027 USA.
EM zm2336@columbia.edu; ra2910@columbia.edu; mw3347@columbia.edu;
   cs3876@columbia.edu
NR 8
TC 0
Z9 0
U1 5
U2 7
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-9948-1
PY 2020
BP 579
EP 584
PG 6
WC Engineering, Aerospace; Transportation Science & Technology
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering; Transportation
GA BR6MX
UT WOS:000662085600117
DA 2022-04-17
ER

PT J
AU Jiang, T
   Gradus, JL
   Rosellini, AJ
AF Jiang, Tammy
   Gradus, Jaimie L.
   Rosellini, Anthony J.
TI Supervised Machine Learning: A Brief Primer
SO BEHAVIOR THERAPY
LA English
DT Article
DE machine learning; supervised learning; ensemble methods
ID POSTTRAUMATIC-STRESS-DISORDER; MULTIPLE-IMPUTATION; MENTAL-HEALTH;
   PREDICTION; CLASSIFICATION; REGRESSION; RISK; SELECTION; MODELS;
   REGULARIZATION
AB Machine learning is increasingly used in mental health research and has the potential to advance our understanding of how to characterize, predict, and treat mental disorders and associated adverse health outcomes (e.g., suicidal behavior). Machine learning offers new tools to overcome challenges for which traditional statistical methods are not well-suited. This paper provides an overview of machine learning with a specific focus on supervised learning (i.e., methods that are designed to predict or classify an outcome of interest). Several common supervised learning methods are described, along with applied examples from the published literature. We also provide an overview of supervised learning model building, validation, and performance evaluation. Finally, challenges in creating robust and generalizable machine learning algorithms are discussed.
C1 [Jiang, Tammy; Gradus, Jaimie L.] Boston Univ, Sch Publ Hlth, Boston, MA 02215 USA.
   [Gradus, Jaimie L.] Boston Univ, Sch Med, Boston, MA 02215 USA.
   [Rosellini, Anthony J.] Boston Univ, Ctr Anxiety & Related Disorders, Boston, MA 02215 USA.
   [Rosellini, Anthony J.] Boston Univ, Dept Psychol & Brain Sci, Boston, MA 02215 USA.
RP Rosellini, AJ (corresponding author), Ctr Anxiety & Related Disorders, 900 Commonwealth Ave East,2nd Floor, Boston, MA 02215 USA.
EM ajrosell@bu.edu
FU National Institute of Mental HealthUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute of Mental Health (NIMH) [R01MH109507, R01MH110453,
   K01MH106710, R21MH119492]
FX This work was supported by grants awarded to Dr. Gradus (R01MH109507,
   R01MH110453) and Dr. Rosellini (K01MH106710, R21MH119492) from the
   National Institute of Mental Health. The content of this article is
   solely the responsibility of the authors and does not necessarily
   represent the official views of the National Institute of Mental Health
   or the National Institutes of Health.
NR 77
TC 25
Z9 25
U1 41
U2 63
PU ELSEVIER INC
PI SAN DIEGO
PA 525 B STREET, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0005-7894
EI 1878-1888
J9 BEHAV THER
JI Behav. Therapy
PD SEP
PY 2020
VL 51
IS 5
BP 675
EP 687
PG 13
WC Psychology, Clinical; Psychiatry
WE Social Science Citation Index (SSCI)
SC Psychology; Psychiatry
GA NK4WM
UT WOS:000566732800001
PM 32800297
OA Green Accepted
DA 2022-04-17
ER

PT J
AU Choi, RY
   Coyner, AS
   Kalpathy-Cramer, J
   Chiang, MF
   Campbell, JP
AF Choi, Rene Y.
   Coyner, Aaron S.
   Kalpathy-Cramer, Jayashree
   Chiang, Michael F.
   Campbell, J. Peter
TI Introduction to Machine Learning, Neural Networks, and Deep Learning
SO TRANSLATIONAL VISION SCIENCE & TECHNOLOGY
LA English
DT Article
DE deep learning; machine learning; artificial intelligence
ID ARTIFICIAL-INTELLIGENCE; PREDICTION; MODEL
AB Purpose: To present an overview of current machine learning methods and their use in medical research, focusing on select machine learning techniques, best practices, and deep learning.
   Methods: A systematic literature search in PubMed was performed for articles pertinent to the topic of artificial intelligence methods used in medicine with an emphasis on ophthalmology.
   Results: A review of machine learning and deep learning methodology for the audience without an extensive technical computer programming background.
   Conclusions: Artificial intelligence has a promising future in medicine; however, many challenges remain.
   Translational Relevance: The aim of this review article is to provide the nontechnical readers a layman's explanation of the machine learning methods being used in medicine today. The goal is to provide the reader a better understanding of the potential and challenges of artificial intelligence within the field of medicine.
C1 [Choi, Rene Y.; Chiang, Michael F.; Campbell, J. Peter] Oregon Hlth & Sci Univ, Casey Eye Inst, Dept Ophthalmol, Portland, OR 97239 USA.
   [Coyner, Aaron S.; Chiang, Michael F.] Oregon Hlth & Sci Univ, Dept Med Informat & Clin Epidemiol, Portland, OR 97239 USA.
   [Kalpathy-Cramer, Jayashree] Massachusetts Gen Hosp, Dept Radiol, Athinoula A Martinos Ctr Biomed Imaging, Charlestown, MA USA.
RP Campbell, JP (corresponding author), Oregon Hlth & Sci Univ, Casey Eye Inst, 3375 SW Terwilliger Blvd, Portland, OR 97239 USA.
EM campbelp@ohsu.edu
OI Coyner, Aaron/0000-0003-3261-1909
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01EY19474, K12
   EY027720, P30EY10572]; National Science FoundationNational Science
   Foundation (NSF) [SCH-1622679, SCH-1622542, SCH-1622536]; Research to
   Prevent BlindnessResearch to Prevent Blindness (RPB)
FX This project was supported by grants R01EY19474, K12 EY027720, and
   P30EY10572 from the National Institutes of Health; SCH-1622679,
   SCH-1622542, and SCH-1622536 from the National Science Foundation; and
   by unrestricted departmental funding and a Career Development Award
   (JPC) from Research to Prevent Blindness.
NR 33
TC 39
Z9 40
U1 42
U2 82
PU ASSOC RESEARCH VISION OPHTHALMOLOGY INC
PI ROCKVILLE
PA 12300 TWINBROOK PARKWAY, ROCKVILLE, MD 20852-1606 USA
SN 2164-2591
J9 TRANSL VIS SCI TECHN
JI Transl. Vis. Sci. Technol.
PD JAN
PY 2020
VL 9
IS 2
AR 14
DI 10.1167/tvst.9.2.14
PG 12
WC Ophthalmology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Ophthalmology
GA KR6WJ
UT WOS:000517757300010
PM 32704420
DA 2022-04-17
ER

PT J
AU Patel, L
   Shukla, T
   Huang, XZ
   Ussery, DW
   Wang, SZ
AF Patel, Lauv
   Shukla, Tripti
   Huang, Xiuzhen
   Ussery, David W.
   Wang, Shanzhi
TI Machine Learning Methods in Drug Discovery
SO MOLECULES
LA English
DT Review
DE machine learning; drug discovery; deep learning; in silico screening
ID SUPPORT VECTOR MACHINES; NEURAL-NETWORKS; CHEMICAL SPACE; RANDOM FOREST;
   PREDICTION; SELECTION; CLASSIFICATION; ALGORITHMS; INHIBITORS; FRAMEWORK
AB The advancements of information technology and related processing techniques have created a fertile base for progress in many scientific fields and industries. In the fields of drug discovery and development, machine learning techniques have been used for the development of novel drug candidates. The methods for designing drug targets and novel drug discovery now routinely combine machine learning and deep learning algorithms to enhance the efficiency, efficacy, and quality of developed outputs. The generation and incorporation of big data, through technologies such as high-throughput screening and high through-put computational analysis of databases used for both lead and target discovery, has increased the reliability of the machine learning and deep learning incorporated techniques. The use of these virtual screening and encompassing online information has also been highlighted in developing lead synthesis pathways. In this review, machine learning and deep learning algorithms utilized in drug discovery and associated techniques will be discussed. The applications that produce promising results and methods will be reviewed.
C1 [Patel, Lauv; Shukla, Tripti; Wang, Shanzhi] Univ Arkansas Little Rock, Chem Dept, Little Rock, AR 72204 USA.
   [Huang, Xiuzhen] Arkansas State Univ, Dept Comp Sci, Jonesboro, AR 72467 USA.
   [Ussery, David W.] Univ Arkansas Med Sci, Dept Biomed Informat, Little Rock, AR 72205 USA.
RP Wang, SZ (corresponding author), Univ Arkansas Little Rock, Chem Dept, Little Rock, AR 72204 USA.
EM lhpatel@ualr.edu; tshukla@ualr.edu; xhuang@astate.edu;
   DWUssery@uams.edu; sxwang2@ualr.edu
RI Wang, Shanzhi/AAA-3595-2021
OI Wang, Shanzhi/0000-0002-7068-0756; Ussery, David/0000-0003-3632-5512
FU National Science FoundationNational Science Foundation (NSF)
   [OIA-1946391]; Arkansas Division of Higher Education under 2019-2020
   SURF; Arkansas Research Alliance
FX This work is supported in part by the National Science Foundation under
   Award No. OIA-1946391 and by Arkansas Division of Higher Education under
   2019-2020 SURF; DWU is funded in part by the Arkansas Research Alliance.
NR 101
TC 19
Z9 19
U1 61
U2 89
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1420-3049
J9 MOLECULES
JI Molecules
PD NOV
PY 2020
VL 25
IS 22
AR 5277
DI 10.3390/molecules25225277
PG 17
WC Biochemistry & Molecular Biology; Chemistry, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Chemistry
GA OZ4HN
UT WOS:000594889300001
PM 33198233
OA gold, Green Published
DA 2022-04-17
ER

PT J
AU Kao, YF
   Venkatachalam, R
AF Kao, Ying-Fang
   Venkatachalam, Ragupathy
TI Human and Machine Learning
SO COMPUTATIONAL ECONOMICS
LA English
DT Article
DE Machine learning; Human problem solving; Herbert Simon; Learning;
   Artificial intelligence; Go
ID GAME; COMPUTABILITY; RATIONALITY; CHESS; PLAY; GO
AB In this paper, we consider learning by human beings and machines in the light of Herbert Simon's pioneering contributions to the theory of Human Problem Solving. Using board games of perfect information as a paradigm, we explore differences in human and machine learning in complex strategic environments. In doing so, we contrast theories of learning in classical game theory with computational game theory proposed by Simon. Among theories that invoke computation, we make a further distinction between computable and computational or machine learning theories. We argue that the modern machine learning algorithms, although impressive in terms of their performance, do not necessarily shed enough light on human learning. Instead, they seem to take us further away from Simon's lifelong quest to understand the mechanics of actual human behaviour.
C1 [Venkatachalam, Ragupathy] Goldsmiths Univ London, Inst Management Studies, London SE14 6NW, England.
RP Venkatachalam, R (corresponding author), Goldsmiths Univ London, Inst Management Studies, London SE14 6NW, England.
EM rpathy@gmail.com; seldakao@gmail.com
NR 62
TC 4
Z9 4
U1 16
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0927-7099
EI 1572-9974
J9 COMPUT ECON
JI Comput. Econ.
PD MAR
PY 2021
VL 57
IS 3
SI SI
BP 889
EP 909
DI 10.1007/s10614-018-9803-z
PG 21
WC Economics; Management; Mathematics, Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Business & Economics; Mathematics
GA RN7FG
UT WOS:000640517400008
OA Green Accepted, hybrid
DA 2022-04-17
ER

PT J
AU Hagendorff, T
   Meding, K
AF Hagendorff, Thilo
   Meding, Kristof
TI Ethical considerations and statistical analysis of industry involvement
   in machine learning research
SO AI & SOCIETY
LA English
DT Article; Early Access
DE Machine learning research; Industry influence; Conflict of interest;
   Gender equality; Public-private partnership
ID CONFLICTS-OF-INTEREST; SCIENCE; INNOVATION; PATTERNS; FACULTY; LINKS;
   BIAS
AB Industry involvement in the machine learning (ML) community seems to be increasing. However, the quantitative scale and ethical implications of this influence are rather unknown. For this purpose, we have not only carried out an informed ethical analysis of the field, but have inspected all papers of the main ML conferences NeurIPS, CVPR, and ICML of the last 5 years-almost 11,000 papers in total. Our statistical approach focuses on conflicts of interest, innovation, and gender equality. We have obtained four main findings. (1) Academic-corporate collaborations are growing in numbers. At the same time, we found that conflicts of interest are rarely disclosed. (2) Industry papers amply mention terms that relate to particular trending machine learning topics earlier than academia does. (3) Industry papers are not lagging behind academic papers with regard to how often they mention keywords that are proxies for social impact considerations. (4) Finally, we demonstrate that industry papers fall short of their academic counterparts with respect to the ratio of gender diversity. We believe that this work is a starting point for an informed debate within and outside of the ML community.
C1 [Hagendorff, Thilo] Univ Tubingen, Cluster Excellence Machine Learning New Perspect, Tubingen, Germany.
   [Meding, Kristof] Univ Tubingen, Neural Informat Proc Grp, Tubingen, Germany.
RP Hagendorff, T (corresponding author), Univ Tubingen, Cluster Excellence Machine Learning New Perspect, Tubingen, Germany.
EM thilo.hagendorff@uni-tuebingen.de; kristof.meding@uni-tuebingen.de
FU Cluster of Excellence "Machine Learning -New Perspectives for Science" -
   Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under
   Germany's Excellence StrategyGerman Research Foundation (DFG) [EXC
   2064/1, 390727645]; German Research Foundation (DFG)German Research
   Foundation (DFG) [SFB 1233, 276693517]; Projekt DEAL
FX Thilo Hagendorff was supported by the Cluster of Excellence "Machine
   Learning -New Perspectives for Science" funded by the Deutsche
   Forschungsgemeinschaft (DFG, German Research Foundation) under Germany's
   Excellence Strategy -Reference Number EXC 2064/1 -Project ID 390727645.
   Kristof Meding was supported by the German Research Foundation (DFG):
   SFB 1233, Robust Vision: Inference Principles and Neural Mechanisms, TP
   3, Project ID 276693517. Open Access funding enabled and organized by
   Projekt DEAL.
NR 60
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0951-5666
EI 1435-5655
J9 AI SOC
JI AI Soc.
DI 10.1007/s00146-021-01284-z
EA SEP 2021
PG 11
WC Computer Science, Artificial Intelligence
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA UY7UE
UT WOS:000701723400001
OA hybrid, Green Submitted
DA 2022-04-17
ER

PT C
AU Krishna, KM
   Kannadaguli, P
AF Krishna, Mohan K.
   Kannadaguli, Prashanth
BE Tomar, GS
TI IoT Based CNC Machine Condition Monitoring System Using Machine Learning
   Techniques
SO 2020 IEEE 9TH INTERNATIONAL CONFERENCE ON COMMUNICATION SYSTEMS AND
   NETWORK TECHNOLOGIES (CSNT 2020)
SE International Conference on Communication Systems and Network
   Technologies
LA English
DT Proceedings Paper
CT IEEE 9th International Conference on Communication Systems and Network
   Technologies (CSNT)
CY APR 10-12, 2020
CL SRGIC Banmore, Morena, INDIA
SP IEEE, IEEE MP Sub Sect, Inst Elect & Telecommunicat Engineers, IEEE Bombay Sect, Machine Intelligence Res Labs
HO SRGIC Banmore
DE ANN; Machine learning; CNC Machine; Database Modeling; MER
AB We developed a CNC machine's condition monitoring system based on Artificial Neural Network (ANN) and correlate the same with the real-time CNC machine data. The classification of the condition of a CNC machine was done by deciding whether it is a fresh machine or worn machine using machine learning techniques. In consideration of real time data loaded from a CNC machine we built a database and then modelled an ANN. Based on this approach of machine learning which implements pattern recognition and probabilistic modelling of the CNC machine data, classification of the condition of a CNC machine was done successfully. Finally, performance analysis of this machine model prevail in terms of Machine Error Rate (MER) upholds the impressive fact that modeling using the ANN yields better results over another alternative modeling techniques and can be used for developing Automatic CNC machine condition monitoring and recognition system.
C1 [Krishna, Mohan K.] Vijaya Vittala Inst Technol VVIT, Dept Comp Sci, Bengaluru, India.
   [Kannadaguli, Prashanth] Dhaarini Acad Tech Educ, Bengaluru, India.
RP Krishna, KM (corresponding author), Vijaya Vittala Inst Technol VVIT, Dept Comp Sci, Bengaluru, India.
EM mkkrvdmohankrishna@gmail.com; prashcd@gmail.com
OI K, Prashanth/0000-0002-9449-3568
NR 12
TC 0
Z9 0
U1 9
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
SN 2329-7182
BN 978-1-7281-4976-9
J9 INT CONF COMM SYST
PY 2020
BP 61
EP 65
DI 10.1109/CSNT.2020.12
PG 5
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Telecommunications
GA BQ5ZI
UT WOS:000609773800012
DA 2022-04-17
ER

PT J
AU Kvinevskiy, I
   Bedi, S
   Mann, S
AF Kvinevskiy, Ilarion
   Bedi, Sanjeev
   Mann, Stephen
TI Detecting machine chatter using audio data and machine learning
SO INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY
LA English
DT Article
DE CNC machining; Chatter; Machine learning
AB We present a method for detecting chatter in CNC machining. Our method uses machining learning to train a classifier to determine the chatter threshold, and we use an autoencoder to reduce the dimensionality of the data. We test our method on machining audio data, and successfully detect chatter in the validation data. Our method is amenable to use on the shop floor, as a machinist using our method needs only to classify audio as chatter and non-chatter.
C1 [Kvinevskiy, Ilarion; Bedi, Sanjeev] Univ Waterloo, Dept Mech & Mech Engn, 200 Univ Ave W, Waterloo, ON N2L 3G1, Canada.
   [Mann, Stephen] Univ Waterloo, Cheriton Sch Comp Sci, 200 Univ Ave W, Waterloo, ON N2L 3G1, Canada.
RP Mann, S (corresponding author), Univ Waterloo, Cheriton Sch Comp Sci, 200 Univ Ave W, Waterloo, ON N2L 3G1, Canada.
EM ikvitnevskiy@edu.uwaterloo.ca; sbedi@uwaterloo.ca; smann@uwaterloo.ca
OI Mann, Stephen/0000-0001-8528-2921; Bedi, Sanjeev/0000-0002-6993-8502
NR 11
TC 3
Z9 3
U1 2
U2 9
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0268-3768
EI 1433-3015
J9 INT J ADV MANUF TECH
JI Int. J. Adv. Manuf. Technol.
PD JUN
PY 2020
VL 108
IS 11-12
BP 3707
EP 3716
DI 10.1007/s00170-020-05571-9
EA JUN 2020
PG 10
WC Automation & Control Systems; Engineering, Manufacturing
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Engineering
GA MF0DG
UT WOS:000543010600002
DA 2022-04-17
ER

PT C
AU Saranya, N
   Srinivasan, K
   Kumar, SKP
   Rukkumani, V
   Ramya, R
AF Saranya, N.
   Srinivasan, K.
   Kumar, S. K. Pravin
   Rukkumani, V
   Ramya, R.
BE Smys, S
   Tavares, JMRS
   Balas, VE
   Iliyasu, AM
TI Fruit Classification Using Traditional Machine Learning and Deep
   Learning Approach
SO COMPUTATIONAL VISION AND BIO-INSPIRED COMPUTING
SE Advances in Intelligent Systems and Computing
LA English
DT Proceedings Paper
CT International Conference on Computational Vision and Bio-Inspired
   Computing (ICCVBIC)
CY SEP 25-26, 2019
CL RVS Tech Campus, Coimbatore, INDIA
HO RVS Tech Campus
DE Fruit classification; Machine learning; CNN
AB Advancement in image processing techniques and automation in industrial sector urge its usage in almost all the fields. Fruit classification and grading with its image still remain a challenging task. Fruit classification can be used to perform the sorting and grading process automatically. A traditional method for fruits classification is manual sorting which is time consuming and involves human presence always. Automated sorting process can be used to implement Smart Fresh Park. In this paper, various methods used for fruit classification have experimented. Different fruits considered for classification are five categories of apple, banana, orange and pomegranate. Results were compared by applying the fruit-360 dataset between typical machine learning and deep learning algorithms. To apply machine learning algorithms, basic features of the fruit like the color (RGB Color space), size, height and width were extracted from its image. Traditional-machine learning algorithmsKNNand SVMwere applied over the extracted features. The result shows that using Convolutional Neural Network (CNN) gives a promising result than traditional machine learning algorithms.
C1 [Saranya, N.] Sri Ramakrishna Engn Coll, Dept Informat Technol, Coimbatore, Tamil Nadu, India.
   [Srinivasan, K.; Rukkumani, V; Ramya, R.] Sri Ramakrishna Engn Coll, Dept Elect & Instrumentat Engn, Coimbatore, Tamil Nadu, India.
   [Kumar, S. K. Pravin] United Inst Technol, Dept Elect & Commun Engn, Coimbatore, Tamil Nadu, India.
RP Saranya, N (corresponding author), Sri Ramakrishna Engn Coll, Dept Informat Technol, Coimbatore, Tamil Nadu, India.
EM saranya.pravin@srec.ac.in; hod-eie@srec.ac.in; skpk.87@gmail.com;
   rukkumani.v@srec.ac.insrec.ac.in; ramya.r@srec.ac.in
RI R, Ramya/X-8858-2019; Saranya, N/AAX-9507-2020
OI K, Dr.Srinivasan/0000-0002-5318-0418
FU department of Information Technology, Sri Ramakrishna Engineering
   College, Coimbatore
FX This researchworkwas supported and carried out at the department of
   Information Technology, Sri Ramakrishna Engineering College, Coimbatore.
   We would like to thank our Management, Director (Academics), Principal
   and Head of the Department for supporting us with the infrastructure and
   learning resource to carry out the research work.
NR 16
TC 0
Z9 0
U1 15
U2 27
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2194-5357
EI 2194-5365
BN 978-3-030-37218-7; 978-3-030-37217-0
J9 ADV INTELL SYST COMP
PY 2020
VL 1108
BP 79
EP 89
DI 10.1007/978-3-030-37218-7_10
PG 11
WC Computer Science, Artificial Intelligence; Imaging Science &
   Photographic Technology
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Imaging Science & Photographic Technology
GA BR6AM
UT WOS:000659295600010
DA 2022-04-17
ER

PT J
AU Mizgajski, J
   Szymczak, A
   Morzy, M
   Augustyniak, L
   Szymanski, P
   Zelasko, P
AF Mizgajski, Jan
   Szymczak, Adrian
   Morzy, Mikolaj
   Augustyniak, Lukasz
   Szymanski, Piotr
   Zelasko, Piotr
TI Return on Investment in Machine Learning: Crossing the Chasm between
   Academia and Business
SO FOUNDATIONS OF COMPUTING AND DECISION SCIENCES
LA English
DT Article
DE applied machine learning; machine learning teaching; machine learning
   engineering
ID KNOWLEDGE DISCOVERY
AB Academia remains the central place of machine learning education. While academic culture is the predominant factor influencing the way we teach machine learning to students, many practitioners question this culture, claiming the lack of alignment between academic and business environments. Drawing on professional experiences from both sides of the chasm, we describe the main points of contention, in the hope that it will help better align academic syllabi with the expectations towards future machine learning practitioners. We also provide recommendations for teaching of the applied aspects of machine learning.
C1 [Szymczak, Adrian] Avaya, Durham, NC 27713 USA.
   [Morzy, Mikolaj] Poznan Univ Tech, Poznan, Poland.
   [Szymanski, Piotr] Wroclaw Univ Sci & Technol, Wroclaw, Poland.
   [Zelasko, Piotr] Johns Hopkins Univ, Baltimore, MD 21218 USA.
RP Szymczak, A (corresponding author), Avaya, Durham, NC 27713 USA.
EM mizgajski.jan@gmail.com; drian.dominik.szymczak@gmail.com;
   mikolaj.morzy@put.poznan.pl; lukasz.augustyniak@pwr.edu.pl;
   pi-otr.szymanski@pwr.edu.pl; piotr.andrzej.zelasko@gmail.com
OI Mizgajski, Jan/0000-0002-1774-3973; Szymanski, Piotr/0000-0002-7733-3239
FU Avaya; Faculty of Computing and Telecommunications of the Poznan
   University of Technology; Faculty of Computer Science and Management of
   the Wroclaw University of Science and Technology
FX The authors want to express their gratitude to Avaya for financial
   support and providing an environment for applied machine learning
   research. The work has been also supported by the statutory funds of the
   Faculty of Computing and Telecommunications of the Poznan University of
   Technology and the statutory funds of the Faculty of Computer Science
   and Management of the Wroclaw University of Science and Technology.
NR 85
TC 0
Z9 0
U1 5
U2 8
PU WALTER DE GRUYTER GMBH
PI BERLIN
PA GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY
SN 0867-6356
EI 2300-3405
J9 FOUND COMPUT DECIS S
JI Found. Comput. Decis. Sci.
PD DEC
PY 2020
VL 45
IS 4
BP 281
EP 304
DI 10.2478/fcds-2020-0015
PG 24
WC Computer Science, Artificial Intelligence
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA PG8QH
UT WOS:000599992800002
OA gold
DA 2022-04-17
ER

PT J
AU Amoore, L
AF Amoore, Louise
TI Machine learning political orders
SO REVIEW OF INTERNATIONAL STUDIES
LA English
DT Article; Early Access
DE Politics; Machine Learning; Algorithm; International Order; Rules
ID RISK
AB A significant set of epistemic and political transformations are taking place as states and societies begin to understand themselves and their problems through the paradigm of deep neural network algorithms. A machine learning political order does not merely change the political technologies of governance, but is itself a reordering of politics, of what the political can be. When algorithmic systems reduce the pluridimensionality of politics to the output of a model, they simultaneously foreclose the potential for other political claims to be made and alternative political projects to be built. More than this foreclosure, a machine learning political order actively profits and learns from the fracturing of communities and the destabilising of democratic rights. The transformation from rules-based algorithms to deep learning models has paralleled the undoing of rules-based social and international orders - from the use of machine learning in the campaigns of the UK EU referendum, to the trialling of algorithmic immigration and welfare systems, and the use of deep learning in the COVID-19 pandemic - with political problems becoming reconfigured as machine learning problems. Machine learning political orders decouple their attributes, features and clusters from underlying social values, no longer tethered to notions of good governance or a good society, but searching instead for the optimal function of abstract representations of data.
C1 [Amoore, Louise] Univ Durham, Dept Geog, Durham, England.
RP Amoore, L (corresponding author), Univ Durham, Dept Geog, Durham, England.
EM Louise.amoore@durham.ac.uk
FU European Research Council (ERC)European Research Council (ERC)European
   Commission [ERC-2019-ADG-883107-ALGOSOC]; Independent Research Fund
   Denmark
FX This article developed as part of a collective and collaborative forum
   led by Dr Nicole Grove. In July 2020 Nicole wrote to a group of us with
   a proposal to engage with the theme of 'Engineering Disruption',
   suggesting how 'concepts of design and engineering have become
   themselves forms of political intervention rather than a means of
   political intervention.' In the months that followed, Nicole led us in a
   series of extraordinary conversations and discussions. I am deeply
   grateful to Nicole, to Nisha Shah and Martin Coward at the Review of
   International Studies, and to Charmaine Chua and Neel Ahuja for the
   wonderful and enduring discussions we had in the group. Earlier versions
   of the article were presented at the Engineering Disruption workshop in
   November 2020, where Rocco Bellanova, Carola Westermeier, Debbie Lisle,
   Maja Zehfuss, and Martina Tazzioli so generously gave their insights;
   and at the Disruption by Design roundtable at the British International
   Studies Association conference, June 2021, where the discussion of error
   and failure with our audience was particularly generative. I am grateful
   to the three anonymous reviewers for RIS, whose comments have been so
   very helpful to me, and the Editors Martin Coward and Nisha Shah for
   their patience and generous depth of engagement. The research has
   received funding from the European Research Council (ERC) under Horizon
   2020, Advanced Investigator Grant ERC-2019-ADG-883107-ALGOSOC and from
   the Independent Research Fund Denmark for the AI Reuse project.
NR 59
TC 0
Z9 0
U1 0
U2 0
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0260-2105
EI 1469-9044
J9 REV INT STUD
JI Rev. Int. Stud.
AR PII S0260210522000031
DI 10.1017/S0260210522000031
EA FEB 2022
PG 17
WC International Relations
WE Social Science Citation Index (SSCI)
SC International Relations
GA YZ6DF
UT WOS:000755564500001
DA 2022-04-17
ER

PT J
AU Qayyum, A
   Ijaz, A
   Usama, M
   Iqbal, W
   Qadir, J
   Elkhatib, Y
   Al-Fuqaha, A
AF Qayyum, Adnan
   Ijaz, Aneeqa
   Usama, Muhammad
   Iqbal, Waleed
   Qadir, Junaid
   Elkhatib, Yehia
   Al-Fuqaha, Ala
TI Securing Machine Learning in the Cloud: A Systematic Review of Cloud
   Machine Learning Security
SO FRONTIERS IN BIG DATA
LA English
DT Review
DE Machine Learning as a Service; cloud-hosted machine learning models;
   machine learning security; cloud machine learning security; systematic
   review; attacks; defenses
ID ADVERSARIAL; ATTACKS
AB With the advances in machine learning (ML) and deep learning (DL) techniques, and the potency of cloud computing in offering services efficiently and cost-effectively, Machine Learning as a Service (MLaaS) cloud platforms have become popular. In addition, there is increasing adoption of third-party cloud services for outsourcing training of DL models, which requires substantial costly computational resources (e.g., high-performance graphics processing units (GPUs)). Such widespread usage of cloud-hosted ML/DL services opens a wide range of attack surfaces for adversaries to exploit the ML/DL system to achieve malicious goals. In this article, we conduct a systematic evaluation of literature of cloud-hosted ML/DL models along both the important dimensions-attacks and defenses-related to their security. Our systematic review identified a total of 31 related articles out of which 19 focused on attack, six focused on defense, and six focused on both attack and defense. Our evaluation reveals that there is an increasing interest from the research community on the perspective of attacking and defending different attacks on Machine Learning as a Service platforms. In addition, we identify the limitations and pitfalls of the analyzed articles and highlight open research issues that require further investigation.
C1 [Qayyum, Adnan; Usama, Muhammad; Qadir, Junaid] Informat Technol Univ ITU, Lahore, Pakistan.
   [Ijaz, Aneeqa] Univ Oklahoma, AI4Networks Res Ctr, Norman, OK 73019 USA.
   [Iqbal, Waleed] Queen Mary Univ London, Social Data Sci SDS Lab, London, England.
   [Elkhatib, Yehia] Univ Lancaster, Sch Comp & Commun, Lancaster, England.
   [Al-Fuqaha, Ala] Hamad Bin Khalifa Univ HBKU, Doha, Qatar.
RP Qayyum, A (corresponding author), Informat Technol Univ ITU, Lahore, Pakistan.
EM adnan.qayyum@itu.edu.pk
RI Al-Fuqaha, Ala/ABD-8597-2021; Elkhatib, Yehia/G-9800-2013
OI Al-Fuqaha, Ala/0000-0002-0903-1204; Elkhatib, Yehia/0000-0003-4639-436X
NR 55
TC 2
Z9 2
U1 11
U2 17
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2624-909X
J9 FRONT BIG DATA
JI Front. Big Data
PD NOV 12
PY 2020
VL 3
AR 587139
DI 10.3389/fdata.2020.587139
PG 17
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Multidisciplinary Sciences
WE Emerging Sources Citation Index (ESCI)
SC Computer Science; Science & Technology - Other Topics
GA TK6PA
UT WOS:000674276800001
PM 33693420
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Dietrich, B
   Walther, J
   Weigold, M
   Abele, E
AF Dietrich, Bastian
   Walther, Jessica
   Weigold, Matthias
   Abele, Eberhard
TI Machine learning based very short term load forecasting of machine tools
SO APPLIED ENERGY
LA English
DT Article
DE Energy flexibility; Load forecasting; Machine tool; Machine learning;
   Feature engineering
ID ENERGY-CONSUMPTION; POWER-CONSUMPTION; REGRESSION; FRAMEWORK; EFFICIENT;
   MODELS
AB With the ongoing integration of renewable energies into the electrical power grid, industrial energy flexibility gains importance. To enable demand response applications, knowledge about the future energy demand is necessary. This paper presents a machine learning process to forecast the very short term load of two machine tools, which can be utilized as a decision support basis for control schemes and measures to increase energy flexibility and decrease energy cost in manufacturing. The presented process is developed and evaluated on production machines in a research factory. The results indicate that the developed machine learning process is feasible and creates an accurate very short term load forecasting model for different production machines. It can be used as a blueprint to develop load forecasting models for other production machines using the historic load profile and various machine and process data. A combination of time series features and an Artificial Neural Network proves to be the most robust model regarding the presented machine tools with achieved coefficients of determination between 0.57 and 0.64 for a 100 step forecast. Improvements are still needed regarding the forecasting accuracy, especially of load peaks, for which different measures are proposed.
C1 [Dietrich, Bastian; Walther, Jessica; Weigold, Matthias; Abele, Eberhard] Tech Univ Darmstadt, Inst Prod Management Technol & Machine Tools PTW, Otto Berndt Str 2, D-64287 Darmstadt, Germany.
RP Dietrich, B (corresponding author), Tech Univ Darmstadt, Inst Prod Management Technol & Machine Tools PTW, Otto Berndt Str 2, D-64287 Darmstadt, Germany.
EM b.dietrich@ptw.tr-darmstadt.de
RI Weigold, Matthias/AAC-2312-2021
OI Weigold, Matthias/0000-0002-7820-8544; Walther,
   Jessica/0000-0002-6492-0717
FU German Federal Ministry for Economic Affairs and Energy (BMWi)
   [03ET1455]
FX Funding: The authors are grateful to the German Federal Ministry for
   Economic Affairs and Energy (BMWi) for funding the presented work in the
   project PHI-Factory [Grant No. 03ET1455].
NR 48
TC 11
Z9 12
U1 12
U2 40
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0306-2619
EI 1872-9118
J9 APPL ENERG
JI Appl. Energy
PD OCT 15
PY 2020
VL 276
AR 115440
DI 10.1016/j.apenergy.2020.115440
PG 11
WC Energy & Fuels; Engineering, Chemical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Energy & Fuels; Engineering
GA NR3DD
UT WOS:000571441800006
DA 2022-04-17
ER

PT C
AU Agarwal, N
   Das, S
AF Agarwal, Namita
   Das, Saikat
GP IEEE
TI Interpretable Machine Learning Tools: A Survey
SO 2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI)
LA English
DT Proceedings Paper
CT IEEE Symposium Series on Computational Intelligence (IEEE SSCI)
CY DEC 01-04, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Computat Intelligence Soc
DE machine learning; interpretable machine learning; open-source tools;
   interpretable machine learning tools survey
ID MODELS
AB In recent years machine learning (ML) systems have been deployed extensively in various domains. But most ML-based frameworks lack transparency. To believe in ML models, an individual needs to understand the reasons behind the ML predictions. In this paper, we provide a survey of open-source software tools that help explore and understand the behavior of the ML models. Also, these tools include a variety of interpretable machine learning methods that assist people with understanding the connection between input and output variables through interpretation, validate the decision of a predictive model to enable lucidity, accountability, and fairness in the algorithmic decision-making policies. Furthermore, we provide the state-of-the-art of interpretable machine learning (IML) tools, along with a comparison and a brief discussion of the implementation of those IML tools in various programming languages.
C1 [Agarwal, Namita; Das, Saikat] Univ Memphis, Dept Comp Sci, Memphis, TN 38152 USA.
RP Agarwal, N (corresponding author), Univ Memphis, Dept Comp Sci, Memphis, TN 38152 USA.
EM nfnu@memphis.edu; sdas1@memphis.edu
NR 38
TC 2
Z9 2
U1 4
U2 5
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-2547-3
PY 2020
BP 1528
EP 1534
PG 7
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BS0GU
UT WOS:000682772901075
DA 2022-04-17
ER

PT J
AU Carrasquilla, J
AF Carrasquilla, Juan
TI Machine learning for quantum matter
SO ADVANCES IN PHYSICS-X
LA English
DT Review
DE Strongly correlated quantum systems; machine learning
ID RESTRICTED BOLTZMANN MACHINES; COMPLEX PHYSICAL SYSTEMS; NEURAL-NETWORK;
   SCHRODINGER-EQUATION; PHASE-TRANSITIONS; COMPUTATION; STATES; MODEL;
   POWER
AB Quantum matter, the research field studying phases of matter whose properties are intrinsically quantum mechanical, draws from areas as diverse as hard condensed matter physics, materials science, statistical mechanics, quantum information, quantum gravity, and large-scale numerical simulations. Recently, researchers interested in quantum matter and strongly correlated quantum systems have turned their attention to the algorithms underlying modern machine learning with an eye on making progress in their fields. Here we provide a short review on the recent development and adaptation of machine learning ideas for the purpose advancing research in quantum matter, including ideas ranging from algorithms that recognize conventional and topological states of matter in synthetic experimental data, to representations of quantum states in terms of neural networks and their applications to the simulation and control of quantum systems. We discuss the outlook for future developments in areas at the intersection between machine learning and quantum many-body physics.
   [GRAPHICS]
C1 [Carrasquilla, Juan] MaRS Ctr, Vector Inst Artificial Intelligence, Toronto, ON M5G 1M1, Canada.
   [Carrasquilla, Juan] Univ Waterloo, Dept Phys & Astron, Waterloo, ON, Canada.
RP Carrasquilla, J (corresponding author), MaRS Ctr, Vector Inst Artificial Intelligence, Toronto, ON M5G 1M1, Canada.
EM juanfelipe.carrasquilla@gmail.com
FU Natural Sciences and Engineering Research Council of Canada
   (NSERC)Natural Sciences and Engineering Research Council of Canada
   (NSERC); Google Quantum Research AwardGoogle Incorporated; Canadian
   Institute for Advanced Research (CIFAR) AI chair programCanadian
   Institute for Advanced Research (CIFAR)
FX J.C. acknowledges support from Natural Sciences and Engineering Research
   Council of Canada (NSERC), the Shared Hierarchical Academic Research
   Computing Network (SHARCNET), Compute Canada, Google Quantum Research
   Award, and the Canadian Institute for Advanced Research (CIFAR) AI chair
   program.
NR 288
TC 54
Z9 54
U1 34
U2 52
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 2374-6149
J9 ADV PHYS-X
JI Adv. Phys.-X
PD JAN 1
PY 2020
VL 5
IS 1
AR 1797528
DI 10.1080/23746149.2020.1797528
PG 45
WC Physics, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Physics
GA MU3NB
UT WOS:000555578000001
OA Green Submitted, gold
HC Y
HP N
DA 2022-04-17
ER

PT C
AU Ghorpade, P
   Gadge, A
   Lende, A
   Chordiya, H
   Gosavi, G
   Mishra, A
   Hooli, B
   Ingle, YS
   Shaikh, N
AF Ghorpade, Parag
   Gadge, Aditya
   Lende, Akash
   Chordiya, Hitesh
   Gosavi, Gita
   Mishra, Asima
   Hooli, Basavaraj
   Ingle, Yashwant S.
   Shaikh, Nuzhat
GP IEEE
TI Flood Forecasting Using Machine Learning: A Review
SO 2021 8TH INTERNATIONAL CONFERENCE ON SMART COMPUTING AND COMMUNICATIONS
   (ICSCC)
LA English
DT Proceedings Paper
CT 8th International Conference on Smart Computing and Communications
   (ICSCC)
CY JUL 01-03, 2021
CL Muthoot Inst Technol & Sci, Kochi, INDIA
SP IEEE Kerala Sect, IEEE
HO Muthoot Inst Technol & Sci
DE Flood Prediction; Machine learning; Deep Learning; Forecasting; Hybrid &
   Ensemble Machine learning
ID SUPPORT VECTOR MACHINE; FREQUENCY-ANALYSIS; NEURAL-NETWORKS; MODEL;
   PREDICTION; REGRESSION
AB Floods are the most frequently occurring natural disasters and result in loss of human life, destruction of livelihoods, which in turn, affects the national economies. There are several studies and novel modi operandi to design flood forecasting systems efficaciously. The authors witness and address the recent shift towards data-driven methods for flood prediction. The machine learning-based models trained using climatic parameters' historical data are increasingly useful for forecasting tasks. This paper's main objective is to demonstrate the recent advancements in the flood forecasting field using machine learning algorithms. The authors reviewed some prominent algorithms used for flood forecasting, which various professionals can use to develop their solutions.
C1 [Ghorpade, Parag; Gadge, Aditya; Lende, Akash; Chordiya, Hitesh; Ingle, Yashwant S.; Shaikh, Nuzhat] Modern Educ Societys Coll Engn, Dept Comp Engn, Pune, Maharashtra, India.
   [Gosavi, Gita; Mishra, Asima; Hooli, Basavaraj] Ctr Dev Adv Comp, Pune, Maharashtra, India.
RP Ghorpade, P (corresponding author), Modern Educ Societys Coll Engn, Dept Comp Engn, Pune, Maharashtra, India.
EM paragghorpade1998@gmail.com; gadge.aditya25.256@gmail.com;
   akash.lende12@gmail.com; hiteshac1999@gmail.com; gitag@cdac.in;
   asima@cdac.in; basavarajh@cdac.in; yashwantingle218@gmail.com;
   nfshaikh76@gmail.com
NR 31
TC 1
Z9 1
U1 20
U2 20
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-9687-9
PY 2021
BP 32
EP 36
DI 10.1109/ICSCC51209.2021.9528099
PG 5
WC Computer Science, Theory & Methods; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Telecommunications
GA BS3DO
UT WOS:000709816800007
DA 2022-04-17
ER

PT J
AU Peng, GCY
   Alber, M
   Tepole, AB
   Cannon, W
   De, S
   Dura-Bernal, S
   Garikipati, K
   Karniadakis, G
   Lytton, WW
   Perdikaris, P
   Petzold, L
   Kuhl, E
AF Peng, Grace C. Y.
   Alber, Mark
   Tepole, Adrian Buganza
   Cannon, William
   De, Suvranu
   Dura-Bernal, Salvador
   Garikipati, Krishna
   Karniadakis, George
   Lytton, William W.
   Perdikaris, Paris
   Petzold, Linda
   Kuhl, Ellen
TI Multiscale Modeling Meets Machine Learning: What Can We Learn?
SO ARCHIVES OF COMPUTATIONAL METHODS IN ENGINEERING
LA English
DT Review
DE Machine learning; Multiscale modeling; Physics-based simulation;
   Biomedicine
ID NEURAL-NETWORKS; COMPUTATIONAL HOMOGENIZATION; UNCERTAINTY
   QUANTIFICATION; METABOLITE CONCENTRATIONS; PHYSICS; SYSTEMS;
   IDENTIFICATION; EQUATIONS; DYNAMICS; LEVEL
AB Machine learning is increasingly recognized as a promising technology in the biological, biomedical, and behavioral sciences. There can be no argument that this technique is incredibly successful in image recognition with immediate applications in diagnostics including electrophysiology, radiology, or pathology, where we have access to massive amounts of annotated data. However, machine learning often performs poorly in prognosis, especially when dealing with sparse data. This is a field where classical physics-based simulation seems to remain irreplaceable. In this review, we identify areas in the biomedical sciences where machine learning and multiscale modeling can mutually benefit from one another: Machine learning can integrate physics-based knowledge in the form of governing equations, boundary conditions, or constraints to manage ill-posted problems and robustly handle sparse and noisy data; multiscale modeling can integrate machine learning to create surrogate models, identify system dynamics and parameters, analyze sensitivities, and quantify uncertainty to bridge the scales and understand the emergence of function. With a view towards applications in the life sciences, we discuss the state of the art of combining machine learning and multiscale modeling, identify applications and opportunities, raise open questions, and address potential challenges and limitations. We anticipate that it will stimulate discussion within the community of computational mechanics and reach out to other disciplines including mathematics, statistics, computer science, artificial intelligence, biomedicine, systems biology, and precision medicine to join forces towards creating robust and efficient models for biological systems.
C1 [Peng, Grace C. Y.] NIH, Bldg 10, Bethesda, MD 20892 USA.
   [Alber, Mark] Univ Calif Riverside, Riverside, CA 92521 USA.
   [Tepole, Adrian Buganza] Purdue Univ, Lafayette, IN USA.
   [Cannon, William] Pacific Northwest Natl Lab, Richland, WA 99352 USA.
   [De, Suvranu] Rensselaer Polytech Inst, Troy, NY USA.
   [Dura-Bernal, Salvador; Lytton, William W.] State Univ New York, New York, NY USA.
   [Garikipati, Krishna] Univ Michigan, Ann Arbor, MI 48109 USA.
   [Karniadakis, George] Brown Univ, Providence, RI 02912 USA.
   [Perdikaris, Paris] Univ Penn, Philadelphia, PA 19104 USA.
   [Petzold, Linda] Univ Calif Santa Barbara, Santa Barbara, CA 93106 USA.
   [Kuhl, Ellen] Stanford Univ, Stanford, CA 94305 USA.
RP Kuhl, E (corresponding author), Stanford Univ, Stanford, CA 94305 USA.
EM penggr@mail.nih.gov; malber@ucr.edu; abuganza@purdue.edu;
   william.cannon@pnnl.gov; des@rpi.edu; salvadordura@gmail.com;
   krishna@umich.edu; georgekarniadakis@brown.edu;
   bill.lytton@downstate.edu; pgp@seas.upenn.edu;
   petzold@engineering.ucsb.edu; ekuhl@stanford.edu
RI Kuhl, Ellen/G-4444-2011; Alber, Mark/AAR-1280-2020
OI Kuhl, Ellen/0000-0002-6283-935X; Buganza Tepole,
   Adrian/0000-0001-8531-0603
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [U01 HL116330, R01
   AR074525, U01 EB022546, R01 CA197491, U24 EB028998, U01 HL116323, U01
   HL142518, U01 EB017695, R01 EB014877, U01 HL119578]; DARPAUnited States
   Department of DefenseDefense Advanced Research Projects Agency (DARPA)
   [HR0011199002]; Toyota Research Institute [849910]
FX The authors acknowledge support of the National Institutes of Health
   Grants U01 HL116330 (Alber), R01 AR074525 (Buganza Tepole), U01 EB022546
   (Cannon), R01 CA197491 (De), U24 EB028998 (Dura-Bernal), U01 HL116323
   and U01 HL142518 (Karniadakis), U01 EB017695 (Lytton), R01 EB014877
   (Petzold) and U01 HL119578 (Kuhl), as well as DARPA Grant HR0011199002
   and Toyota Research Institute Grant 849910, (both Garikipati). This work
   was inspired by the 2019 Symposium on Integrating Machine Learning with
   Multiscale Modeling for Biological, Biomedical, and Behavioral Systems
   (ML-MSM) as part of the Interagency Modeling and Analysis Group (IMAG),
   and is endorsed by the Multiscale Modeling (MSM) Consortium, by the U.S.
   Association for Computational Mechanics (USACM) Technical Trust Area
   Biological Systems, and by the U.S. National Committee on Biomechanics
   (USNCB). The authors acknowledge the active discussions within these
   communities.
NR 143
TC 34
Z9 35
U1 17
U2 56
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1134-3060
EI 1886-1784
J9 ARCH COMPUT METHOD E
JI Arch. Comput. Method Eng.
PD MAY
PY 2021
VL 28
IS 3
BP 1017
EP 1037
DI 10.1007/s11831-020-09405-5
EA FEB 2020
PG 21
WC Computer Science, Interdisciplinary Applications; Engineering,
   Multidisciplinary; Mathematics, Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Mathematics
GA RP7LK
UT WOS:000520045900001
PM 34093005
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Aggogeri, F
   Pellegrini, N
   Tagliani, FL
AF Aggogeri, Francesco
   Pellegrini, Nicola
   Tagliani, Franco Luis
TI Recent Advances on Machine Learning Applications in Machining Processes
SO APPLIED SCIENCES-BASEL
LA English
DT Review
DE Machine Learning; Deep Learning; feature extraction; machining process
ID 2-STAGE FEATURE-SELECTION; TOOL WEAR; NEURAL-NETWORK; CHATTER
   PREDICTION; MODEL; SYSTEM; OPTIMIZATION; REPLACEMENT; SIGNALS;
   DECOMPOSITION
AB This study aims to present an overall review of the recent research status regarding Machine Learning (ML) applications in machining processes. In the current industrial systems, processes require the capacity to adapt to manufacturing conditions continuously, guaranteeing high performance in terms of production quality and equipment availability. Artificial Intelligence (AI) offers new opportunities to develop and integrate innovative solutions in conventional machine tools to reduce undesirable effects during operational activities. In particular, the significant increase of the computational capacity may permit the application of complex algorithms to big data volumes in a short time, expanding the potentialities of ML techniques. ML applications are present in several contexts of machining processes, from roughness quality prediction to tool condition monitoring. This review focuses on recent applications and implications, classifying the main problems that may be solved using ML related to the machining quality, energy consumption and conditional monitoring. Finally, a discussion on the advantages and limits of ML algorithms is summarized for future investigations.
C1 [Aggogeri, Francesco; Pellegrini, Nicola; Tagliani, Franco Luis] Univ Brescia, Dept Mech & Ind Engn, Via Branze 38, I-25123 Brescia, Italy.
RP Aggogeri, F (corresponding author), Univ Brescia, Dept Mech & Ind Engn, Via Branze 38, I-25123 Brescia, Italy.
EM francesco.aggogeri@unibs.it; nicola.pellegrini@unibs.it;
   f.tagliani006@unibs.it
OI AGGOGERI, Francesco/0000-0001-9414-3763; Pellegrini,
   Nicola/0000-0002-6108-3941
NR 163
TC 0
Z9 0
U1 43
U2 44
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD SEP
PY 2021
VL 11
IS 18
AR 8764
DI 10.3390/app11188764
PG 27
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Materials Science; Physics
GA UU9KX
UT WOS:000699112600001
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Lei, YG
   Yang, B
   Jiang, XW
   Jia, F
   Li, NP
   Nandi, AK
AF Lei, Yaguo
   Yang, Bin
   Jiang, Xinwei
   Jia, Feng
   Li, Naipeng
   Nandi, Asoke K.
TI Applications of machine learning to machine fault diagnosis: A review
   and roadmap
SO MECHANICAL SYSTEMS AND SIGNAL PROCESSING
LA English
DT Review
DE Machines; Intelligent fault diagnosis; Machine learning; Deep learning;
   Transfer learning; Review and roadmap
ID SUPPORT VECTOR MACHINE; ROLLING-ELEMENT BEARING; CONVOLUTIONAL
   NEURAL-NETWORK; WAVELET PACKET TRANSFORM; DEEP BELIEF NETWORK; EMPIRICAL
   MODE DECOMPOSITION; K-NEAREST-NEIGHBOR; MULTISCALE PERMUTATION ENTROPY;
   PRINCIPAL COMPONENT ANALYSIS; SINGULAR-VALUE DECOMPOSITION
AB Intelligent fault diagnosis (IFD) refers to applications of machine learning theories to machine fault diagnosis. This is a promising way to release the contribution from human labor and automatically recognize the health states of machines, thus it has attracted much attention in the last two or three decades. Although IFD has achieved a considerable number of successes, a review still leaves a blank space to systematically cover the development of IFD from the cradle to the bloom, and rarely provides potential guidelines for the future development. To bridge the gap, this article presents a review and roadmap to systematically cover the development of IFD following the progress of machine learning theories and offer a future perspective. In the past, traditional machine learning theories began to weak the contribution of human labor and brought the era of artificial intelligence to machine fault diagnosis. Over the recent years, the advent of deep learning theories has reformed IFD in further releasing the artificial assistance since the 2010s, which encourages to construct an end-to-end diagnosis procedure. It means to directly bridge the relationship between the increasingly-grown monitoring data and the health states of machines. In the future, transfer learning theories attempt to use the diagnosis knowledge from one or multiple diagnosis tasks to other related ones, which prospectively overcomes the obstacles in applications of IFD to engineering scenarios. Finally, the roadmap of IFD is pictured to show potential research trends when combined with the challenges in this field. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Lei, Yaguo; Yang, Bin; Jiang, Xinwei; Jia, Feng; Li, Naipeng] Xi An Jiao Tong Univ, Key Lab, Educ Minist Modern Design & Rotor Bearing Syst, Xian 710049, Peoples R China.
   [Nandi, Asoke K.] Brunel Univ London, Dept Elect & Comp Engn, Uxbridge UB8 3PH, Middx, England.
RP Lei, YG (corresponding author), Xi An Jiao Tong Univ, Key Lab, Educ Minist Modern Design & Rotor Bearing Syst, Xian 710049, Peoples R China.
EM yaguolei@mail.xjtu.edu.cn
OI Li, Naipeng/0000-0003-0678-8161; Yang, Bin/0000-0002-3015-3580
FU National Key R&D Program of China [2018YFB1306100]; NSFC-Zhejiang Joint
   Fund for the Integration of Industrialization and Informatization
   [U1709208]; National Natural Science Foundation of ChinaNational Natural
   Science Foundation of China (NSFC) [61673311]
FX This research was supported by National Key R&D Program of China
   (2018YFB1306100), NSFC-Zhejiang Joint Fund for the Integration of
   Industrialization and Informatization (U1709208), and National Natural
   Science Foundation of China (61673311).
NR 443
TC 359
Z9 369
U1 513
U2 1113
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0888-3270
EI 1096-1216
J9 MECH SYST SIGNAL PR
JI Mech. Syst. Signal Proc.
PD APR
PY 2020
VL 138
AR 106587
DI 10.1016/j.ymssp.2019.106587
PG 39
WC Engineering, Mechanical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA KR8HE
UT WOS:000517855800037
OA Green Submitted
HC Y
HP Y
DA 2022-04-17
ER

PT C
AU Regazzoni, F
   Bhasin, S
   Pour, AA
   Alshaer, I
   Aydin, F
   Aysu, A
   Beroulle, V
   Di Natale, G
   Franzon, P
   Hely, D
   Homma, N
   Ito, A
   Jap, D
   Kashyap, P
   Polian, I
   Potluri, S
   Ueno, R
   Vatajelu, EI
   Yli-Mayry, V
AF Regazzoni, Francesco
   Bhasin, Shivam
   Pour, Amir Ali
   Alshaer, Ihab
   Aydin, Furkan
   Aysu, Aydin
   Beroulle, Vincent
   Di Natale, Giorgio
   Franzon, Paul
   Hely, David
   Homma, Naofumi
   Ito, Akira
   Jap, Dirmanto
   Kashyap, Priyank
   Polian, Ilia
   Potluri, Seetal
   Ueno, Rei
   Vatajelu, Elena-Ioana
   Yli-Mayry, Ville
GP IEEE
TI Machine Learning and Hardware security: Challenges and Opportunities
   -Invited Talk
SO 2020 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER AIDED-DESIGN (ICCAD)
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
LA English
DT Proceedings Paper
CT 39th IEEE/ACM International Conference On Computer Aided Design (ICCAD)
CY NOV 02-05, 2020
CL ELECTR NETWORK
SP IEEE, Assoc Comp Machinery, IEEE Circuits & Syst Soc, IEEE Council Elect Design Automat, ACM SIGDA, IEEE Electron Devices Soc
DE machine learning; hardware security
AB Machine learning techniques have significantly changed our lives. They helped improving our everyday routines, but they also demonstrated to be au extremely helpful tool for more advanced and complex applications. However, the implications of hardware security problems under a massive diffusion of machine learning techniques are still to be completely understood. This paper first highlights novel applications of machine learning for hardware security, such as evaluation of post quantum cryptography hardware and extraction of physically unclonable functions from neural networks. Later, practical model extraction attack based on electromagnetic side-channel measurements are demonstrated followed by a discussion of strategies to protect proprietary models by watermarking them.
C1 [Regazzoni, Francesco] Univ Amsterdam, Amsterdam, Netherlands.
   [Regazzoni, Francesco] USI, ALaRI, Lugano, Switzerland.
   [Bhasin, Shivam; Jap, Dirmanto] Nanyang Technol Univ, Singapore, Singapore.
   [Pour, Amir Ali; Beroulle, Vincent; Hely, David] Grenoble INP, Grenoble, France.
   [Aydin, Furkan; Aysu, Aydin; Franzon, Paul; Kashyap, Priyank; Potluri, Seetal] North Carolina State Univ, Raleigh, NC USA.
   [Alshaer, Ihab; Di Natale, Giorgio; Vatajelu, Elena-Ioana] Univ Grenoble Alpes, CNRS, TIMA, Grenoble, France.
   [Homma, Naofumi; Ito, Akira; Ueno, Rei; Yli-Mayry, Ville] Tohoku Univ, CREST, Sendai, Miyagi, Japan.
   [Polian, Ilia] Univ Stuttgart, Stuttgart, Germany.
RP Regazzoni, F (corresponding author), USI, ALaRI, Lugano, Switzerland.
RI HELY, Davod/ABE-1952-2021; HELY, David/S-8202-2019
OI HELY, Davod/0000-0003-3249-7667; HELY, David/0000-0003-3249-7667;
   Franzon, Paul/0000-0002-6048-5770; Kashyap, Priyank/0000-0002-0120-0974
FU NSFNational Science Foundation (NSF) [CNS 16-244770]; JST
   CREST,JapanCore Research for Evolutional Science and Technology (CREST)
   [jPMjCR19KS]; European UnionEuropean Commission [871738]
FX This work was performed in the Cooperative Research Project of the
   Research Institute of Electrical Communication, Tohoku University with
   Nanyang Technological University. This research is supported in part by
   the NSF under the Grants No. CNS 16-244770 (Center for Advanced
   Electronics through Machine Learning), by JST CREST Grant
   No.jPMjCR19KS,Japan, and by European Union's Horizon 2020 research and
   innovation programme CPSoSaware (grant agreement No 871738). The authors
   thank Paolo Palmieri and Dado Smailbegovic for the fruitful discussion
   about protection of machine learning algorithms.
NR 33
TC 1
Z9 1
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1933-7760
BN 978-1-6654-2324-3
J9 ICCAD-IEEE ACM INT
PY 2020
DI 10.1145/3400302.3416260
PG 6
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering,
   Manufacturing; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BR8DW
UT WOS:000671087100050
DA 2022-04-17
ER

PT J
AU Alchieri, L
   Badalotti, D
   Bonardi, P
   Bianco, S
AF Alchieri, Leonardo
   Badalotti, Davide
   Bonardi, Pietro
   Bianco, Simone
TI An introduction to quantum machine learning: from quantum logic to
   quantum deep learning
SO QUANTUM MACHINE INTELLIGENCE
LA English
DT Review
DE Quantum computing; Quantum machine learning; Quantum deep learning
ID ALGORITHMS; SUPREMACY
AB The aim of this work is to give an introduction for a non-practical reader to the growing field of quantum machine learning, which is a recent discipline that combines the research areas of machine learning and quantum computing. This work presents the most notable scientific literature about quantum machine learning, starting from the basics of quantum logic to some specific elements and algorithms of quantum computing (such as QRAM, Grover and HHL), in order to allow a better understanding of latest quantum machine learning techniques. The main aspects of quantum machine learning are then covered, with detailed descriptions of some notable algorithms, such as quantum natural gradient and quantum support vector machines, up to the most recent quantum deep learning techniques, such as quantum neural networks.
C1 [Alchieri, Leonardo; Badalotti, Davide; Bonardi, Pietro; Bianco, Simone] Univ Milano Bicocca, Viale Sarca 336, Milan, Italy.
RP Bianco, S (corresponding author), Univ Milano Bicocca, Viale Sarca 336, Milan, Italy.
EM l.alchieri2@campus.unimib.it; d.badalotti@campus.unimib.it;
   p.bonardi2@campus.unimib.it; simone.bianco@unimib.it
OI Bianco, Simone/0000-0002-7070-1545
NR 113
TC 0
Z9 0
U1 29
U2 29
PU SPRINGERNATURE
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND
SN 2524-4906
EI 2524-4914
J9 QUANT MACH INTELL
JI Quant. Mach. Intell.
PD DEC
PY 2021
VL 3
IS 2
AR 28
DI 10.1007/s42484-021-00056-8
PG 30
WC Computer Science, Artificial Intelligence; Quantum Science & Technology
WE Emerging Sources Citation Index (ESCI)
SC Computer Science; Physics
GA WX8KH
UT WOS:000718837900001
DA 2022-04-17
ER

PT J
AU Halbouni, A
   Gunawan, TS
   Habaebi, MH
   Halbouni, M
   Kartiwi, M
   Ahmad, R
AF Halbouni, Asmaa
   Gunawan, Teddy Surya
   Habaebi, Mohamed Hadi
   Halbouni, Murad
   Kartiwi, Mira
   Ahmad, Robiah
TI Machine Learning and Deep Learning Approaches for CyberSecurity: A
   Review
SO IEEE ACCESS
LA English
DT Review
DE Intrusion detection; Machine learning; Deep learning; Computer security;
   Machine learning algorithms; Network security; Computer hacking;
   Cybersecurity; machine learning; deep learning; intrusion detection
   system
ID DETECTION SYSTEMS
AB The rapid evolution and growth of the internet through the last decades led to more concern about cyber-attacks that are continuously increasing and changing. As a result, an effective intrusion detection system was required to protect data, and the discovery of artificial intelligence's sub-fields, machine learning, and deep learning, was one of the most successful ways to address this problem. This paper reviewed intrusion detection systems and discussed what types of learning algorithms machine learning and deep learning are using to protect data from malicious behavior. It discusses recent machine learning and deep learning work with various network implementations, applications, algorithms, learning approaches, and datasets to develop an operational intrusion detection system.
C1 [Halbouni, Asmaa; Gunawan, Teddy Surya; Habaebi, Mohamed Hadi] Int Islamic Univ Malaysia, Dept Elect & Comp Engn, Kuala Lumpur 53100, Malaysia.
   [Halbouni, Murad] Arab Amer Univ, Dept Nat Engn & Technol Sci, Jenin 240, Palestine.
   [Kartiwi, Mira] Int Islamic Univ Malaysia, Informat Syst Dept, Kuala Lumpur 53100, Malaysia.
   [Ahmad, Robiah] Univ Teknol Malaysia, Razak Fac Technol & Informat, Kuala Lumpur 54100, Malaysia.
RP Gunawan, TS (corresponding author), Int Islamic Univ Malaysia, Dept Elect & Comp Engn, Kuala Lumpur 53100, Malaysia.
EM tsgunawan@iium.edu.my
RI Habaebi, Mohamed/F-2460-2011
OI Habaebi, Mohamed/0000-0002-2263-0850
NR 47
TC 0
Z9 0
U1 35
U2 35
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2022
VL 10
BP 19572
EP 19585
DI 10.1109/ACCESS.2022.3151248
PG 14
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA ZH8MT
UT WOS:000761186500001
OA gold, Green Accepted
DA 2022-04-17
ER

PT J
AU Habehh, H
   Gohel, S
AF Habehh, Hafsa
   Gohel, Suril
TI Machine Learning in Healthcare
SO CURRENT GENOMICS
LA English
DT Review
DE Machine learning; healthcare; support vector machine; EHR; genomics;
   artificial intelligence
ID BIG DATA; DEEP; PREDICTION; CLASSIFICATION; PHARMACOGENOMICS; PSYCHOSIS;
   CANCER
AB Recent advancements in Artificial Intelligence (AI) and Machine Learning (ML) technol-ogy have brought on substantial strides in predicting and identifying health emergencies, disease populations, and disease state and immune response, amongst a few. Although, skepticism remains regarding the practical application and interpretation of results from ML-based approaches in healthcare settings, the inclusion of these approaches is increasing at a rapid pace. Here we provide a brief overview of machine learning-based approaches and learning algorithms including super -vised, unsupervised, and reinforcement learning along with examples. Second, we discuss the appli-cation of ML in several healthcare fields, including radiology, genetics, electronic health records, and neuroimaging. We also briefly discuss the risks and challenges of ML application to healthcare such as system privacy and ethical concerns and provide suggestions for future applications.
C1 [Habehh, Hafsa; Gohel, Suril] Rutgers State Univ, Sch Hlth Profess, Dept Hlth Informat, 65 Bergen St, Newark, NJ 07107 USA.
RP Gohel, S (corresponding author), Rutgers State Univ, Sch Hlth Profess, Dept Hlth Informat, 65 Bergen St, Newark, NJ 07107 USA.
EM suril.gohel@rutgers.edu
OI Gohel, Suril/0000-0003-2387-5021
FU NIH/NCATSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Center for Advancing
   Translational Sciences (NCATS) [UL1TR003017]
FX This work was partly supported by NIH/NCATS UL1TR003017. This work is
   solely the responsibility of the authors and does not necessarily
   represent the official views of the NIH, NCATS.
NR 103
TC 1
Z9 1
U1 17
U2 17
PU BENTHAM SCIENCE PUBL LTD
PI SHARJAH
PA EXECUTIVE STE Y-2, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB
   EMIRATES
SN 1389-2029
EI 1875-5488
J9 CURR GENOMICS
JI Curr. Genomics
PY 2021
VL 22
IS 4
BP 291
EP 300
DI 10.2174/1389202922666210705124359
PG 10
WC Biochemistry & Molecular Biology; Genetics & Heredity
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Genetics & Heredity
GA XM8CU
UT WOS:000729048700005
PM 35273459
DA 2022-04-17
ER

PT C
AU Bini, D
   Pamela, D
   Prince, S
AF Bini, D.
   Pamela, D.
   Prince, Shajin
GP IEEE
TI Machine Vision and Machine Learning for Intelligent Agrobots: A review
SO 2020 5TH INTERNATIONAL CONFERENCE ON DEVICES, CIRCUITS AND SYSTEMS
   (ICDCS' 20)
SE Proceedings of the International Conference on Devices, Circuits and
   Systems
LA English
DT Proceedings Paper
CT 5th International Conference on Devices, Circuits and Systems (ICDCS)
CY MAR 05-06, 2020
CL Coimbatore, INDIA
SP Karunya Inst Technol & Sci, Dept Elect & Commun Engn
DE Agrobots; machine vision; machine learning; unmanned vehicles
ID ROBOTICS
AB An intelligent precise autonomous farming by an agricultural robot achieves the farm duties possibly harvesting, weed detection, disease identification, pruning and fertilizing deals with path planning and mapping of the unstructured and uncertain environment. A machine vision-based Agrobots along with artificial intelligence provides unmanned ground vehicle and unmanned aerial vehicle to navigate the path and to implement the agricultural task for minimizing labour and increasing quality food production. The perception-related work uses a machine learning algorithm to detect the feature and analyze the agricultural tasks for the autonomous machine. The trained data sets create the ability for robots to learn and decide the farm practices. The dawn of autonomous system design gives us the outlook to develop a wide range of flexible agronomic equipment based on multi-robot, smart machines and human-robot systems which lessen waste, progresses economic feasibility also reduces conservational impact and intensifies food sustainability. The multi-tasking Agrobots overcomes the effort of farmers in agricultural husbandry, independent of the climatic conditions. In this paper, a study on Agrobots effective in a diverse environment, its control and action process conjoined with mapping and detection using machine vision and machine learning algorithms are distinguished.
C1 [Bini, D.] Karunya Inst Technol & Sci, Dept Elect & Instrumentat Engn, Coimbatore, Tamil Nadu, India.
   [Pamela, D.] Karunya Inst Technol & Sci, Dept Biomed Engn, Coimbatore, Tamil Nadu, India.
   [Prince, Shajin] Karunya Inst Technol & Sci, Dept Elect & Commun Engn, Coimbatore, Tamil Nadu, India.
RP Bini, D (corresponding author), Karunya Inst Technol & Sci, Dept Elect & Instrumentat Engn, Coimbatore, Tamil Nadu, India.
EM binivlsies@gmail.com; pamela@karunya.edu; shajinprince@gmail.com
RI Prince, Shajin/ABF-4676-2021
NR 30
TC 4
Z9 4
U1 10
U2 25
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2470-847X
BN 978-1-7281-6368-0
J9 PR INT CONF DEVICE C
PY 2020
BP 12
EP 16
DI 10.1109/ICDCS48716.2020.243538
PG 5
WC Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering
GA BP9ON
UT WOS:000570034700003
DA 2022-04-17
ER

PT J
AU Verbraeken, J
   Wolting, M
   Katzy, J
   Kloppenburg, J
   Verbelen, T
   Rellermeyer, JS
AF Verbraeken, Joost
   Wolting, Matthijs
   Katzy, Jonathan
   Kloppenburg, Jeroen
   Verbelen, Tim
   Rellermeyer, Jan S.
TI A Survey on Distributed Machine Learning
SO ACM COMPUTING SURVEYS
LA English
DT Article
DE Distributed machine learning; distributed systems
ID NEURAL-NETWORKS; ALGORITHMS; MODELS; CONVERGENCE; SEARCH
AB The demand for artificial intelligence has grown significantly over the past decade, and this growth has been fueled by advances in machine learning techniques and the ability to leverage hardware acceleration. However, to increase the quality of predictions and render machine learning solutions feasible for more complex applications, a substantial amount of training data is required. Although small machine learning models can be trained with modest amounts of data, the input for training larger models such as neural networks grows exponentially with the number of parameters. Since the demand for processing training data has outpaced the increase in computation power of computing machinery, there is a need for distributing the machine learning workload across multiple machines, and turning the centralized into a distributed system. These distributed systems present new challenges: first and foremost, the efficient parallelization of the training process and the creation of a coherent model. This article provides an extensive overview of the current state-of-the-art in the field by outlining the challenges and opportunities of distributed machine learning over conventional (centralized) machine learning, discussing the techniques used for distributed machine learning, and providing an overview of the systems that are available.
C1 [Verbraeken, Joost; Wolting, Matthijs; Katzy, Jonathan; Kloppenburg, Jeroen; Rellermeyer, Jan S.] Delft Univ Technol, Fac Elect Engn Math & Comp Sci, Van Mour Broekmanweg 6, NL-2628 XE Delft, Netherlands.
   [Verbelen, Tim] Univ Ghent, Dept Informat Technol, IDLab, Technol pk 126, B-9052 Ghent, Belgium.
RP Verbraeken, J (corresponding author), Delft Univ Technol, Fac Elect Engn Math & Comp Sci, Van Mour Broekmanweg 6, NL-2628 XE Delft, Netherlands.
EM J.Verbraeken@student.tudelft.nl; matthijswolting@gmail.com;
   J.B.Katzy@student.tudelft.nl; J.Kloppenburg@student.tudelft.nl;
   tim.verbelen@ugent.be; j.s.rellermeyer@tudelft.nl
OI Verbelen, Tim/0000-0003-2731-7262
NR 168
TC 55
Z9 55
U1 25
U2 44
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 0360-0300
EI 1557-7341
J9 ACM COMPUT SURV
JI ACM Comput. Surv.
PD APR
PY 2020
VL 53
IS 2
AR 30
DI 10.1145/3377454
PG 33
WC Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OH4ZH
UT WOS:000582585700009
OA Green Published, Green Submitted
DA 2022-04-17
ER

PT J
AU MacEachern, SJ
   Forkert, ND
AF MacEachern, Sarah J.
   Forkert, Nils D.
TI Machine learning for precision medicine
SO GENOME
LA English
DT Review
DE machine learning; deep learning; precision medicine
ID NEURAL-NETWORKS; DEEP; HISTORY
AB Precision medicine is an emerging approach to clinical research and patient care that focuses on understanding and treating disease by integrating multi-modal or multi-omics data from an individual to make patient-tailored decisions. With the large and complex datasets generated using precision medicine diagnostic approaches, novel techniques to process and understand these complex data were needed. At the same time, computer science has progressed rapidly to develop techniques that enable the storage, processing, and analysis of these complex datasets, a feat that traditional statistics and early computing technologies could not accomplish. Machine learning, a branch of artificial intelligence, is a computer science methodology that aims to identify complex patterns in data that can be used to make predictions or classifications on new unseen data or for advanced exploratory data analysis. Machine learning analysis of precision medicine's multi-modal data allows for broad analysis of large datasets and ultimately a greater understanding of human health and disease. This review focuses on machine learning utilization for precision medicine's "big data", in the context of genetics, genomics, and beyond.
C1 [MacEachern, Sarah J.] Univ Calgary, Cumming Sch Med, Dept Pediat, Calgary, AB, Canada.
   [MacEachern, Sarah J.; Forkert, Nils D.] Univ Calgary, Alberta Childrens Hosp Res Inst, Cumming Sch Med, Calgary, AB, Canada.
   [Forkert, Nils D.] Univ Calgary, Cumming Sch Med, Dept Radiol, Calgary, AB, Canada.
RP Forkert, ND (corresponding author), Univ Calgary, Alberta Childrens Hosp Res Inst, Cumming Sch Med, Calgary, AB, Canada.; Forkert, ND (corresponding author), Univ Calgary, Cumming Sch Med, Dept Radiol, Calgary, AB, Canada.
EM nils.forkert@ucalgary.ca
RI Forkert, Nils Daniel/K-6273-2012
OI Forkert, Nils Daniel/0000-0003-2556-3224
FU Canada Research Chairs programand the River Fund at Calgary
   FoundationCanada Research Chairs
FX This work was supported by the Canada Research Chairs programand the
   River Fund at Calgary Foundation.
NR 50
TC 16
Z9 16
U1 24
U2 40
PU CANADIAN SCIENCE PUBLISHING
PI OTTAWA
PA 65 AURIGA DR, SUITE 203, OTTAWA, ON K2E 7W6, CANADA
SN 0831-2796
EI 1480-3321
J9 GENOME
JI Genome
PD APR
PY 2021
VL 64
IS 4
BP 416
EP 425
DI 10.1139/gen-2020-0131
PG 10
WC Biotechnology & Applied Microbiology; Genetics & Heredity
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biotechnology & Applied Microbiology; Genetics & Heredity
GA RN3AR
UT WOS:000640223400010
PM 33091314
DA 2022-04-17
ER

PT J
AU Suwardi, A
   Wang, FK
   Xue, K
   Han, MY
   Teo, PL
   Wang, P
   Wang, SJ
   Liu, Y
   Ye, EY
   Li, ZB
   Loh, XJ
AF Suwardi, Ady
   Wang, FuKe
   Xue, Kun
   Han, Ming-Yong
   Teo, Peili
   Wang, Pei
   Wang, Shijie
   Liu, Ye
   Ye, Enyi
   Li, Zibiao
   Loh, Xian Jun
TI Machine Learning-Driven Biomaterials Evolution
SO ADVANCED MATERIALS
LA English
DT Review
DE artificial intelligence; biomaterials; machine learning
ID MESENCHYMAL STEM-CELLS; FATIGUE-CRACK GROWTH; STRUCTURE-PROPERTY
   LINKAGES; AUSTENITIC STAINLESS-STEEL; FOREIGN-BODY RESPONSE;
   HIGH-ENTROPY ALLOYS; MECHANICAL-PROPERTIES; TITANIUM-ALLOY; GENE
   DELIVERY; IN-VITRO
AB Biomaterials is an exciting and dynamic field, which uses a collection of diverse materials to achieve desired biological responses. While there is constant evolution and innovation in materials with time, biomaterials research has been hampered by the relatively long development period required. In recent years, driven by the need to accelerate materials development, the applications of machine learning in materials science has progressed in leaps and bounds. The combination of machine learning with high-throughput theoretical predictions and high-throughput experiments (HTE) has shifted the traditional Edisonian (trial and error) paradigm to a data-driven paradigm. In this review, each type of biomaterial and their key properties and use cases are systematically discussed, followed by how machine learning can be applied in the development and design process. The discussions are classified according to various types of materials used including polymers, metals, ceramics, and nanomaterials, and implants using additive manufacturing. Last, the current gaps and potential of machine learning to further aid biomaterials discovery and application are also discussed.
C1 [Suwardi, Ady; Wang, FuKe; Xue, Kun; Han, Ming-Yong; Teo, Peili; Wang, Pei; Wang, Shijie; Liu, Ye; Ye, Enyi; Li, Zibiao; Loh, Xian Jun] ASTAR, Inst Mat Res & Engn, 2 Fusionopolis Way,Innovis 08-03, Singapore 138634, Singapore.
RP Ye, EY; Li, ZB; Loh, XJ (corresponding author), ASTAR, Inst Mat Res & Engn, 2 Fusionopolis Way,Innovis 08-03, Singapore 138634, Singapore.
EM yeey@imre.a-star.edu.sg; lizb@imre.a-star.edu.sg;
   lohxj@imre.a-star.edu.sg
RI Han, Ming-Yong/ABC-6398-2021; Suwardi, Ady/D-1946-2019; Loh, Xian
   Jun/H-6260-2013
OI Han, Ming-Yong/0000-0002-7519-6779; Suwardi, Ady/0000-0002-7342-0431;
   Loh, Xian Jun/0000-0001-8118-6502
FU A*STAR (Agency for Science, Technology and Research)Agency for Science
   Technology & Research (ASTAR)
FX A.S., F.W., K.X., M.-Y.H., P.T., P.W., S.W., and Y.L. contributed
   equally to this work. This work was financially supported by A*STAR
   (Agency for Science, Technology and Research).
NR 311
TC 4
Z9 4
U1 83
U2 86
PU WILEY-V C H VERLAG GMBH
PI WEINHEIM
PA POSTFACH 101161, 69451 WEINHEIM, GERMANY
SN 0935-9648
EI 1521-4095
J9 ADV MATER
JI Adv. Mater.
PD JAN
PY 2022
VL 34
IS 1
AR 2102703
DI 10.1002/adma.202102703
EA OCT 2021
PG 38
WC Chemistry, Multidisciplinary; Chemistry, Physical; Nanoscience &
   Nanotechnology; Materials Science, Multidisciplinary; Physics, Applied;
   Physics, Condensed Matter
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Science & Technology - Other Topics; Materials Science;
   Physics
GA YC7WD
UT WOS:000704363500001
PM 34617632
DA 2022-04-17
ER

PT J
AU Ertugrul, OF
AF Ertugrul, Omer Faruk
TI A novel randomized machine learning approach: Reservoir computing
   extreme learning machine
SO APPLIED SOFT COMPUTING
LA English
DT Article
DE Reservoir computing; Extreme learning machine; Randomization in machine
   learning; Randomized artificial neural network
ID ECHO STATE NETWORKS; NEURAL-NETWORKS; ALGORITHMS
AB In this study, a novel approach that is based on reservoir computing, which is a successful method in modeling sequential datasets, and extreme learning machines, which has a high generalization capacity, was proposed to model a non-sequential dataset or system. The proposed approach does not require any optimization stage; each weight (except weights in the output layer), biases, the number of neurons in the reservoir, activation functions and the parameters of activation functions were determined arbitrarily and the weights in the output layer were calculated based on these arbitrarily assigned parameters. The proposed approach was evaluated and validated with 60 different benchmark datasets. Obtained results were compared with literature findings and results obtained by each of the extreme learning machine (ELM), randomized artificial neural network, random vector functional link, stochastic ELM, and pruned stochastic ELM methods. Achieved results are successful enough to be employed in classification and regression. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Ertugrul, Omer Faruk] Batman Univ, Dept Elect & Elect Engn, TR-72060 Batman, Turkey.
RP Ertugrul, OF (corresponding author), Batman Univ, Dept Elect & Elect Engn, TR-72060 Batman, Turkey.
EM omerfaruk.ertugrul@batman.edu.tr
RI ERTUGRUL, Ömer Faruk/F-7057-2015
NR 61
TC 6
Z9 6
U1 7
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1568-4946
EI 1872-9681
J9 APPL SOFT COMPUT
JI Appl. Soft. Comput.
PD SEP
PY 2020
VL 94
AR 106433
DI 10.1016/j.asoc.2020.106433
PG 12
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NK7IW
UT WOS:000566907500008
DA 2022-04-17
ER

PT J
AU Cui, ZM
AF Cui, Zhongmin
TI Machine Learning and Small Data
SO EDUCATIONAL MEASUREMENT-ISSUES AND PRACTICE
LA English
DT Article
DE automation; irregularity; machine learning; multinomial naive Bayes;
   natural language processing; small sample; support vector machine
AB Commonly used machine learning applications seem to relate to big data. This article provides a gentle review of machine learning and shows why machine learning can be applied to small data too. An example of applying machine learning to screen irregularity reports is presented. In the example, the support vector machine and multinomial naive Bayes methods were used and compared. The performance of machine learning was compared to human experts in terms of flagging records to be excluded from equating. The application of machine learning seemed to be successful, although the data only consisted of a couple of thousand records. Recommendations in using machine learning are provided.
C1 [Cui, Zhongmin] CFA Inst, Charlottesville, VA 22902 USA.
RP Cui, ZM (corresponding author), CFA Inst, Charlottesville, VA 22902 USA.
EM zhongmin.cui@cfainstitute.org
OI Cui, Zhongmin/0000-0003-2426-6762
NR 14
TC 0
Z9 0
U1 55
U2 55
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0731-1745
EI 1745-3992
J9 EDUC MEAS-ISSUES PRA
JI Educ. Meas.-Issues Pract.
PD DEC
PY 2021
VL 40
IS 4
BP 8
EP 12
DI 10.1111/emip.12472
EA NOV 2021
PG 5
WC Education & Educational Research; Psychology, Educational
WE Social Science Citation Index (SSCI)
SC Education & Educational Research; Psychology
GA XT6QA
UT WOS:000722548300001
DA 2022-04-17
ER

PT J
AU Wang, WR
   Gan, YF
   Vong, CM
   Chen, CQ
AF Wang, Weiru
   Gan, Yanfen
   Vong, Chi-Man
   Chen, Chuangquan
TI Homo-ELM: fully homomorphic extreme learning machine
SO INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS
LA English
DT Article
DE Encrypted machine learning; Fully homomorphic encryption; Privacy
   preservation; Extreme learning machine; Encrypted image classification
ID NEURAL-NETWORKS; ENCRYPTION
AB Extreme learning machine (ELM) as a machine learning method has been successfully applied to many classification problems. However, when applying ELM to classification tasks on the encrypted data in cloud, the classification performance is extremely low. Due to the data encryption, ELM is hard to extract informative features from the encrypted data for correct classification. Moreover, the trained neural network is un-protected on the cloud environments, that makes cloud service highly risky to the attackers. In this paper, we propose a novel fully homomorphic ELM (Homo-ELM), which makes cloud searching tasks under a fully protected environment without compromising the privacy of users. To demonstrate the effectiveness of our approach, we conduct a comprehensive experiment on both cloud and local environments. The experiment results show that Homo-ELM can achieve high accuracy on the local environments as well as cloud environments than other machine learning methods.
C1 [Wang, Weiru; Vong, Chi-Man; Chen, Chuangquan] Univ Macau, Fac Sci & Technol, Comp & Informat Sci, Macau, Peoples R China.
   [Gan, Yanfen] Guangdong Univ Foreign Studies, South China Business Coll, Guangzhou, Guangdong, Peoples R China.
RP Vong, CM (corresponding author), Univ Macau, Fac Sci & Technol, Comp & Informat Sci, Macau, Peoples R China.
EM cmvong@umac.mo
RI VONG, Chi-Man/AAU-5720-2020
OI Wang, Weiru/0000-0002-5287-4530
FU University of Macau [2019-00020-FST, 2018-00138-FST]; Science and
   Technology Development Fund of Macau SAR [0021/2019/A, 273/2017/A]
FX The work presented in this paper was funded by the Multi-Year Research
   Grant of the University of Macau (No. 2019-00020-FST, 2018-00138-FST)
   and the Science and Technology Development Fund of Macau SAR
   (No.0021/2019/A, 273/2017/A).
NR 39
TC 2
Z9 2
U1 5
U2 17
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-8071
EI 1868-808X
J9 INT J MACH LEARN CYB
JI Int. J. Mach. Learn. Cybern.
PD JUL
PY 2020
VL 11
IS 7
BP 1531
EP 1540
DI 10.1007/s13042-019-01054-w
EA JAN 2020
PG 10
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LY0KJ
UT WOS:000505338100001
DA 2022-04-17
ER

PT J
AU Visweswaran, S
   Colditz, JB
   O'Halloran, P
   Han, NR
   Taneja, SB
   Welling, J
   Chu, KH
   Sidani, JE
   Primack, BA
AF Visweswaran, Shyam
   Colditz, Jason B.
   O'Halloran, Patrick
   Han, Na-Rae
   Taneja, Sanya B.
   Welling, Joel
   Chu, Kar-Hai
   Sidani, Jaime E.
   Primack, Brian A.
TI Machine Learning Classifiers for Twitter Surveillance of Vaping:
   Comparative Machine Learning Study
SO JOURNAL OF MEDICAL INTERNET RESEARCH
LA English
DT Article
DE vaping; social media; infodemiology; infoveillance; machine learning;
   deep learning
ID SOCIAL MEDIA
AB Background: Twitter presents a valuable and relevant social media platform to study the prevalence of information and sentiment on vaping that may be useful for public health surveillance. Machine learning classifiers that identify vaping-relevant tweets and characterize sentiments in them can underpin a Twitter-based vaping surveillance system. Compared with traditional machine learning classifiers that are reliant on annotations that are expensive to obtain, deep learning classifiers offer the advantage of requiring fewer annotated tweets by leveraging the large numbers of readily available unannotated tweets.
   Objective: This study aims to derive and evaluate traditional and deep learning classifiers that can identify tweets relevant to vaping, tweets of a commercial nature, and tweets with provape sentiments.
   Methods: We continuously collected tweets that matched vaping-related keywords over 2 months from August 2018 to October 2018. From this data set of tweets, a set of 4000 tweets was selected, and each tweet was manually annotated for relevance (vape relevant or not), commercial nature (commercial or not), and sentiment (provape or not). Using the annotated data, we derived traditional classifiers that included logistic regression, random forest, linear support vector machine, and multinomial naive Bayes. In addition, using the annotated data set and a larger unannotated data set of tweets, we derived deep learning classifiers that included a convolutional neural network (CNN), long short-term memory (LSTM) network, LSTM-CNN network, and bidirectional LSTM (BiLSTM) network. The unannotated tweet data were used to derive word vectors that deep learning classifiers can leverage to improve performance.
   Results: LSTM-CNN performed the best with the highest area under the receiver operating characteristic curve (AUC) of 0.96 (95% CI 0.93-0.98) for relevance, all deep learning classifiers including LSTM-CNN performed better than the traditional classifiers with an AUC of 0.99 (95% CI 0.98-0.99) for distinguishing commercial from noncommercial tweets, and BiLSTM performed the best with an AUC of 0.83 (95% CI 0.78-0.89) for provape sentiment. Overall, LSTM-CNN performed the best across all 3 classification tasks.
   Conclusions: We derived and evaluated traditional machine learning and deep learning classifiers to identify vaping-related relevant, commercial, and provape tweets. Overall, deep learning classifiers such as LSTM-CNN had superior performance and had the added advantage of requiring no preprocessing. The performance of these classifiers supports the development of a vaping surveillance system.
C1 [Visweswaran, Shyam; O'Halloran, Patrick] Univ Pittsburgh, Dept Biomed Informat, Pittsburgh, PA 15206 USA.
   [Visweswaran, Shyam; Taneja, Sanya B.] Univ Pittsburgh, Intelligent Syst Program, Pittsburgh, PA 15206 USA.
   [Colditz, Jason B.; Chu, Kar-Hai; Sidani, Jaime E.] Univ Pittsburgh, Sch Med, Pittsburgh, PA 15206 USA.
   [Han, Na-Rae] Univ Pittsburgh, Dept Linguist, Pittsburgh, PA 15206 USA.
   [Welling, Joel] Carnegie Mellon Univ, Pittsburgh Supercomp Ctr, Pittsburgh, PA 15213 USA.
   [Primack, Brian A.] Univ Arkansas, Coll Educ & Hlth Profess, Fayetteville, AR 72701 USA.
RP Visweswaran, S (corresponding author), Univ Pittsburgh, Dept Biomed Informat, Off Baum, 5607 Baum Blvd,Suite 523, Pittsburgh, PA 15206 USA.
EM shv3@pitt.edu
OI Chu, Kar-Hai/0000-0002-2486-8846; Sidani, Jaime/0000-0002-5411-8755;
   Taneja, Sanya/0000-0003-1707-1617; Primack, Brian/0000-0002-5962-0939;
   Welling, Joel/0000-0003-1423-7001; Colditz, Jason/0000-0002-2811-841X
FU National Cancer Institute of the National Institutes of HealthUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Cancer Institute (NCI) [R01-CA225773];
   National Library of Medicine of the National Institutes of HealthUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Library of Medicine (NLM) [R01-LM012095];
   National Science FoundationNational Science Foundation (NSF)
   [ACI-1548562, ACI-1445606]
FX The authors thank Erica Barrett, Daria Williams, and Sarah Matheny for
   data annotation. This work was supported by awards from the National
   Cancer Institute of the National Institutes of Health (R01-CA225773),
   the National Library of Medicine of the National Institutes of Health
   (R01-LM012095), and the National Science Foundation (ACI-1548562 and
   ACI-1445606 to the Pittsburgh Supercomputing Center). The content is
   solely the responsibility of the authors and does not necessarily
   represent the official views of the National Institutes of Health or the
   National Science Foundation.
NR 44
TC 5
Z9 5
U1 1
U2 6
PU JMIR PUBLICATIONS, INC
PI TORONTO
PA 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA
SN 1438-8871
J9 J MED INTERNET RES
JI J. Med. Internet Res.
PD AUG 12
PY 2020
VL 22
IS 8
AR e17478
DI 10.2196/17478
PG 14
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Health Care Sciences & Services; Medical Informatics
GA NW5MC
UT WOS:000575055000015
PM 32784184
OA gold, Green Published
DA 2022-04-17
ER

PT J
AU Kamerzell, TJ
   Middaugh, CR
AF Kamerzell, Tim J.
   Middaugh, C. Russell
TI Prediction Machines: Applied Machine Learning for Therapeutic Protein
   Design and Development
SO JOURNAL OF PHARMACEUTICAL SCIENCES
LA English
DT Review
DE Machine learning; Protein stability; Formulation; Viscosity; Excipient
ID CONCENTRATION-DEPENDENT VISCOSITY; EMPIRICAL PHASE-DIAGRAMS; SUPPORT
   VECTOR MACHINE; MONOCLONAL-ANTIBODY; BIOPHYSICAL CHARACTERIZATION;
   SUBVISIBLE PARTICLES; AGGREGATE FORMATION; STABILITY PROFILES;
   NEURAL-NETWORKS; SPECTROSCOPY
AB The rapid growth in technological advances and quantity of scientific data over the past decade has led to several challenges including data storage and analysis. Accurate models of complex datasets were previously difficult to develop and interpret. However, improvements in machine learning algorithms have since enabled unparalleled classification and prediction capabilities. The application of machine learning can be seen throughout diverse industries due to their ease of use and interpretability. In this review, we describe popular machine learning algorithms and highlight their application in pharmaceutical protein development. Machine learning models have now been applied to better understand the nonlinear concentration dependent viscosity of protein solutions, predict protein oxidation and deamidation rates, classify sub-visible particles and compare the physical stability of proteins. We also applied several machine learning algorithms using previously published data and describe models with improved predictions and classification. The authors hope that this review can be used as a resource to others and encourage continued application of machine learning algorithms to problems in pharmaceutical protein development.
C1 [Kamerzell, Tim J.; Middaugh, C. Russell] Univ Kansas, Dept Pharmaceut Chem, Lawrence, KS 66045 USA.
   [Kamerzell, Tim J.] HCA MidWest Hlth, Div Internal Med, Overland Pk, KS USA.
RP Kamerzell, TJ (corresponding author), Univ Kansas, Dept Pharmaceut Chem, Lawrence, KS 66045 USA.
EM tkamerzell@ku.edu
FU HCA Healthcare
FX This research was supported (in whole or in part) by HCA Healthcare
   and/or an HCA Healthcare affiliated entity. The views expressed in this
   publication represent those of the author(s) and do not necessarily
   represent the official views of HCA Healthcare or any of its affiliated
   entities.
NR 106
TC 2
Z9 3
U1 13
U2 30
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0022-3549
EI 1520-6017
J9 J PHARM SCI-US
JI J. Pharm. Sci.
PD FEB
PY 2021
VL 110
IS 2
BP 665
EP 681
DI 10.1016/j.xphs.2020.11.034
EA JAN 2021
PG 17
WC Chemistry, Medicinal; Chemistry, Multidisciplinary; Pharmacology &
   Pharmacy
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Pharmacology & Pharmacy; Chemistry
GA PS7SV
UT WOS:000608126900013
PM 33278409
DA 2022-04-17
ER

PT C
AU Sousa, A
   Faria, JP
   Mendes-Moreira, J
   Gomes, D
   Henriques, PC
   Graca, R
AF Sousa, Andre
   Faria, Joao Pascoal
   Mendes-Moreira, Joao
   Gomes, Duarte
   Henriques, Pedro Castro
   Graca, Ricardo
BE Kamp, M
   Koprinska, I
   Bibal, A
   Bouadi, T
   Frenay, B
   Galarraga, L
   Oramas, J
   Adilova, L
TI Applying Machine Learning to Risk Assessment in Software Projects
SO MACHINE LEARNING AND PRINCIPLES AND PRACTICE OF KNOWLEDGE DISCOVERY IN
   DATABASES, PT II
SE Communications in Computer and Information Science
LA English
DT Proceedings Paper
CT 21st Joint European Conference on Machine Learning and Principles and
   Practice of Knowledge Discovery in Databases (ECML PKDD)
CY SEP 13-17, 2021
CL ELECTR NETWORK
SP Google, ASML, Amazon, Ikerlan, KNIME, EurAi, Springer
DE Risk management; Risk assessment; Software projects; Machine learning;
   Classification
AB Risk management is one of the ten knowledge areas discussed in the Project Management Body of Knowledge (PMBOK), which serves as a guide that should be followed to increase the chances of project success. The popularity of research regarding the application of risk management in software projects has been consistently growing in recent years, especially with the application of machine learning techniques to help identify risk levels of risk factors of a project before its development begins, with the goal of improving the likelihood of success of these projects. This paper presents the results of the application of machine learning techniques for risk assessment in software projects. A Python application was developed and, using Scikit-learn, two machine learning models, trained using software project risk data shared by a partner company of this project, were created to predict risk impact and likelihood levels on a scale of 1 to 3.
   Different algorithms were tested to compare the results obtained by high performance but non-interpretable algorithms (e.g., Support Vector Machine) and the ones obtained by interpretable algorithms (e.g., Random Forest), whose performance tends to be lower than their non-interpretable counterparts. The results showed that Support Vector Machine and Naive Bayes were the best performing algorithms. Support Vector Machine had an accuracy of 69% in predicting impact levels, and Naive Bayes had an accuracy of 63% in predicting likelihood levels, but the results presented in other evaluation metrics (e.g., AUC, Precision) show the potential of the approach presented in this use case.
C1 [Sousa, Andre; Faria, Joao Pascoal; Mendes-Moreira, Joao] Univ Porto, Fac Engn, Porto, Portugal.
   [Gomes, Duarte; Henriques, Pedro Castro] Strongstep, Porto, Portugal.
   [Graca, Ricardo] Fraunhofer AICOS, Porto, Portugal.
RP Sousa, A (corresponding author), Univ Porto, Fac Engn, Porto, Portugal.
EM up201902618@fe.up.pt; jpf@fe.up.pt; jmoreira@fe.up.pt;
   duarte.gomes@strongstep.pt; pedroch@strongstep.pt;
   ricardo.graca@fraunhofer.pt
RI Faria, Joao/B-5496-2012
OI Faria, Joao/0000-0003-3825-3954
FU Norte Portugal Regional Operational Programme (NORTE 2020), under the
   PORTUGAL 2020 Partnership Agreement, through the European Regional
   Development Fund (ERDF) [NORTE-01-0247-FEDER-039887]
FX This article is a result of the project PROMESSA
   -NORTE-01-0247-FEDER-039887, supported by Norte Portugal Regional
   Operational Programme (NORTE 2020), under the PORTUGAL 2020 Partnership
   Agreement, through the European Regional Development Fund (ERDF).
NR 21
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1865-0929
EI 1865-0937
BN 978-3-030-93733-1; 978-3-030-93732-4
J9 COMM COM INF SC
PY 2021
VL 1525
BP 104
EP 118
DI 10.1007/978-3-030-93733-1_7
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS8EC
UT WOS:000771712800007
DA 2022-04-17
ER

PT C
AU Wang, G
   Ciptadi, A
   Ahmadzadeh, A
AF Wang, Gang
   Ciptadi, Arridhana
   Ahmadzadeh, Ali
GP ASSOC COMP MACHINERY
TI MLHat: Deployable Machine Learning for Security Defense
SO KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE
   DISCOVERY & DATA MINING
LA English
DT Proceedings Paper
CT 27th ACM SIGKDD International Conference on Knowledge Discovery and Data
   Mining (KDD)
CY AUG 14-18, 2021
CL ELECTR NETWORK
SP Assoc Comp Machinery, ACM SIGMOD, ACM SIGKDD
DE Security and Privacy; Deployable Machine Learning; Adversarial Machine
   Learning
AB The MLHat workshop aims to bring together academic researchers and industry practitioners to discuss the open challenges, potential solutions, and best practices to deploy machine learning at scale for security defense. The workshop will discuss related topics from both defender perspectives (white-hat) and the attacker perspectives ( black-hat). We call the workshop MLHats, to serve as a place for people who are interested in using machine learning to solve practical security problems. The workshop will focus on defining new machine learning paradigms under various security application contexts and identifying exciting new future research directions. At the same time, the workshop will also have a strong industry presence to provide insights into the challenges in deploying and maintaining machine learning models and the much-needed discussion on the capabilities that the state-of-the-arts failed to provide.
C1 [Wang, Gang] UIUC, Champaign, IL 61820 USA.
   [Ciptadi, Arridhana] TruEra, Redmond, WA USA.
   [Ahmadzadeh, Ali] Blue Hexagon, San Francisco, CA USA.
RP Wang, G (corresponding author), UIUC, Champaign, IL 61820 USA.
EM gangw@illinois.edu; arridhana@gmail.com; ali@bluehexagon.ai
FU Blue Hexagon; University of Illinois
FX We thank Blue Hexagon and University of Illinois for their support for
   this workshop.
NR 0
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-8332-5
PY 2021
BP 4161
EP 4162
DI 10.1145/3447548.3469463
PG 2
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS6LU
UT WOS:000749556804077
DA 2022-04-17
ER

PT C
AU Kimmel, R
   Li, T
   Winston, D
AF Kimmel, Richard
   Li, Tong
   Winston, David
GP ACM
TI An Enhanced Machine Learning Model for Adaptive Monte Carlo Yield
   Analysis
SO PROCEEDINGS OF THE 2020 ACM/IEEE 2ND WORKSHOP ON MACHINE LEARNING FOR
   CAD (MLCAD '20)
LA English
DT Proceedings Paper
CT 2nd ACM/IEEE Workshop on Machine Learning for CAD (MLCAD)
CY NOV 16-20, 2020
CL ELECTR NETWORK
SP IEEE, Assoc Comp Machinery, ACM Special Interest Grp Design Automat, IEEE Council Elect Design Automat
DE Monte Carlo; Machine Learning; Yield Analysis; Support Vector Machine;
   Statistical Blockade
AB This paper presents a novel methodology for generating machine learning models used by an adaptive Monte Carlo analysis. The advantages of this methodology are that model generation occurs at the beginning of the analysis with no retraining required, it applies to both classification and regression models, and accuracy of the Monte Carlo analysis is not impacted by the accuracy of the model. This paper discusses the details of constructing and enhancing the machine learning model with emphasis on model training. It will then show how the model enables a Monte Carlo analysis that monitors and adapts to model mispredictions.
C1 [Kimmel, Richard] IBM Corp, Elect Design Automat, Poughkeepsie, NY 12601 USA.
   [Li, Tong] IBM Corp, Elect Design Automat, Austin, TX USA.
   [Winston, David] IBM Corp, Elect Design Automat, Charlotte, NC USA.
RP Kimmel, R (corresponding author), IBM Corp, Elect Design Automat, Poughkeepsie, NY 12601 USA.
EM rkimmel@us.ibm.com; tongli@us.ibm.com; winstond@us.ibm.com
NR 21
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-7519-1
PY 2020
BP 89
EP 94
DI 10.1145/3380446.3430635
PG 6
WC Computer Science, Artificial Intelligence; Engineering, Manufacturing;
   Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BR8CI
UT WOS:000670756800019
DA 2022-04-17
ER

PT J
AU Mukhopadhyay, S
AF Mukhopadhyay, Subhadeep
TI InfoGram and admissible machine learning
SO MACHINE LEARNING
LA English
DT Article
DE Admissible machine learning; InfoGram; L-Features; Information-theory;
   ALFA-testing; Algorithmic risk management; Fairness; Interpretability;
   COREml; FINEml
ID RISK
AB We have entered a new era of machine learning (ML), where the most accurate algorithm with superior predictive power may not even be deployable, unless it is admissible under the regulatory constraints. This has led to great interest in developing fair, transparent and trustworthy ML methods. The purpose of this article is to introduce a new information-theoretic learning framework (admissible machine learning) and algorithmic risk-management tools (InfoGram, L-features, ALFA-testing) that can guide an analyst to redesign off-the-shelf ML methods to be regulatory compliant, while maintaining good prediction accuracy. We have illustrated our approach using several real-data examples from financial sectors, biomedical research, marketing campaigns, and the criminal justice system.
C1 [Mukhopadhyay, Subhadeep] United Analyt & Computat Intelligence Inc, Mountain View, CA 94043 USA.
   [Mukhopadhyay, Subhadeep] H20 Ai, Mountain View, CA 94043 USA.
RP Mukhopadhyay, S (corresponding author), United Analyt & Computat Intelligence Inc, Mountain View, CA 94043 USA.; Mukhopadhyay, S (corresponding author), H20 Ai, Mountain View, CA 94043 USA.
EM deep@unitedstatalgo.com
NR 27
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0885-6125
EI 1573-0565
J9 MACH LEARN
JI Mach. Learn.
PD JAN
PY 2022
VL 111
IS 1
BP 205
EP 242
DI 10.1007/s10994-021-06121-4
EA JAN 2022
PG 38
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YU0UR
UT WOS:000741620000001
OA Green Submitted
DA 2022-04-17
ER

PT C
AU Chen, CJ
   Lin, BR
   Lin, CH
   Chen, CF
   Tsai, MF
AF Chen, Chang-Jun
   Lin, Bo-Ru
   Lin, Cheng-Han
   Chen, Chi-Feng
   Tsai, Ming-Fong
GP IEEE
TI Smart Vending Machine System Prototyped with Deep- and Machine-Learning
   Technologies
SO 2020 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS - TAIWAN
   (ICCE-TAIWAN)
SE IEEE International Conference on Consumer Electronics-Taiwan
LA English
DT Proceedings Paper
CT 7th IEEE International Conference on Consumer Electronics - Taiwan
   (ICCE-Taiwan)
CY SEP 28-30, 2020
CL Taoyuan, TAIWAN
SP Inst Elect & Elect Engineers, Taiwan Consumer Elect Soc, IEEE Consumer Technol Soc, Natl Cent Univ, Minist Sci & Technol, Bur Foreign Trade, Minist Econ Affairs
DE Smart Vending Machine System; Deep Learning; Machine Learing
AB This paper proposes a smart vending machine system combined with deep learning and machine learning technologies. The proposed system is combined with temperature and camera sensor to obtain consumer without individual information and upload this information to cloud server. The system uses face recognition with deep learning to obtain the gender information. It uses the k nearest neighbors (KNN) machine learning method to group based on temperature, time, price and gender information. The proposed system relies on grouping information to dynamically adjust price in real time.
C1 [Chen, Chang-Jun; Lin, Bo-Ru; Tsai, Ming-Fong] Natl United Univ, Dept Elect Engn, Miaoli, Taiwan.
   [Lin, Cheng-Han] Fooyin Univ, Dept Hlth Business Adm, Kaohsiung, Taiwan.
   [Chen, Chi-Feng] Feng Chia Univ, Ind PhD Program Internet Things, Taichung, Taiwan.
RP Tsai, MF (corresponding author), Natl United Univ, Dept Elect Engn, Miaoli, Taiwan.
EM mingfongtsai@gmail.com
FU Ministry of Science and Technology of TaiwanMinistry of Science and
   Technology, Taiwan [MOST 108-2622-E-239-004-CC3, MOST
   109-2622-E-239-002-CC3]
FX We thank the Ministry of Science and Technology of Taiwan for supports
   of this project under grant number MOST 108-2622-E-239-004-CC3 ans MOST
   109-2622-E-239-002-CC3. We thank coauthors and reviewers for their
   valuable opinions.
NR 5
TC 0
Z9 0
U1 6
U2 7
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2381-5779
BN 978-1-7281-7399-3
J9 IEEE INT C ELECTR TA
PY 2020
PG 2
WC Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Computer Science, Hardware & Architecture; Engineering,
   Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BR3OE
UT WOS:000648532300143
DA 2022-04-17
ER

PT J
AU Olowononi, FO
   Rawat, DB
   Liu, C
AF Olowononi, Felix O.
   Rawat, Danda B.
   Liu, Chunmei
TI Resilient Machine Learning for Networked Cyber Physical Systems: A
   Survey for Machine Learning Security to Securing Machine Learning for
   CPS
SO IEEE COMMUNICATIONS SURVEYS AND TUTORIALS
LA English
DT Article
DE Security; Computer security; Machine learning; Wireless sensor networks;
   Resilience; Sensor systems; Computers; Adversarial attacks;
   cybersecurity; machine learning; resiliency in cyber physical systems
ID ADVERSARIAL ATTACKS; INTRUSION DETECTION; INTERNET; EXAMPLES; THINGS
AB Cyber Physical Systems (CPS) are characterized by their ability to integrate the physical and information or cyber worlds. Their deployment in critical infrastructure have demonstrated a potential to transform the world. However, harnessing this potential is limited by their critical nature and the far reaching effects of cyber attacks on human, infrastructure and the environment. An attraction for cyber concerns in CPS rises from the process of sending information from sensors to actuators over the wireless communication medium, thereby widening the attack surface. Traditionally, CPS security has been investigated from the perspective of preventing intruders from gaining access to the system using cryptography and other access control techniques. Most research work have therefore focused on the detection of attacks in CPS. However, in a world of increasing adversaries, it is becoming more difficult to totally prevent CPS from adversarial attacks, hence the need to focus on making CPS resilient. Resilient CPS are designed to withstand disruptions and remain functional despite the operation of adversaries. One of the dominant methodologies explored for building resilient CPS is dependent on machine learning (ML) algorithms. However, rising from recent research in adversarial ML, we posit that ML algorithms for securing CPS must themselves be resilient. This article is therefore aimed at comprehensively surveying the interactions between resilient CPS using ML and resilient ML when applied in CPS. The paper concludes with a number of research trends and promising future research directions. Furthermore, with this article, readers can have a thorough understanding of recent advances on ML-based security and securing ML for CPS and countermeasures, as well as research trends in this active research area.
C1 [Olowononi, Felix O.; Rawat, Danda B.; Liu, Chunmei] Howard Univ, Data Sci & Cybersecur Ctr DSC2, Dept Elect Engn & Comp Sci, Washington, DC 20059 USA.
RP Rawat, DB (corresponding author), Howard Univ, Data Sci & Cybersecur Ctr DSC2, Dept Elect Engn & Comp Sci, Washington, DC 20059 USA.
EM danda.rawat@howard.edu
RI Rawat, Danda B./B-2973-2012
OI Rawat, Danda B./0000-0003-3638-3464
FU USA NSFNational Science Foundation (NSF) [CNS/SaTC 2039583, CNS 1650831,
   1828811]; DoD Center of Excellence in AI and Machine Learning at Howard
   University [W911NF-20-2-0277]; USA Army Research Laboratory; USA
   Department of Homeland SecurityUnited States Department of Homeland
   Security (DHS) [2017-ST-062-000003]
FX This work was supported in part by the USA NSF under Grant CNS/SaTC
   2039583, Grant CNS 1650831, and Grant 1828811; in part by the DoD Center
   of Excellence in AI and Machine Learning at Howard University under
   Grant W911NF-20-2-0277, with the USA Army Research Laboratory; and in
   part by the USA Department of Homeland Security under Grant Award
   2017-ST-062-000003.
NR 193
TC 14
Z9 14
U1 13
U2 19
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
EI 1553-877X
J9 IEEE COMMUN SURV TUT
JI IEEE Commun. Surv. Tutor.
PY 2021
VL 23
IS 1
BP 524
EP 552
DI 10.1109/COMST.2020.3036778
PG 29
WC Computer Science, Information Systems; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA RA0DM
UT WOS:000631089200018
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Gambella, C
   Ghaddar, B
   Naoum-Sawaya, J
AF Gambella, Claudio
   Ghaddar, Bissan
   Naoum-Sawaya, Joe
TI Optimization problems for machine learning: A survey
SO EUROPEAN JOURNAL OF OPERATIONAL RESEARCH
LA English
DT Review
DE Analytics; Mathematical programming; Machine learning; Deep learning
ID SUPPLY CHAIN MANAGEMENT; CLUSTER NEWTON METHOD; BIG DATA ANALYTICS;
   MIXED-INTEGER; FEATURE-SELECTION; BAYESIAN NETWORKS; PROGRAMMING
   APPROACH; OPERATIONS-RESEARCH; VARIABLE SELECTION; DECISION TREES
AB This paper surveys the machine learning literature and presents in an optimization framework several commonly used machine learning approaches. Particularly, mathematical optimization models are presented for regression, classification, clustering, deep learning, and adversarial learning, as well as new emerging applications in machine teaching, empirical model learning, and Bayesian network structure learning. Such models can benefit from the advancement of numerical optimization techniques which have already played a distinctive role in several machine learning settings. The strengths and the shortcomings of these models are discussed and potential research directions and open problems are highlighted. (C) 2020 Elsevier B.V. Allrights reserved.
C1 [Gambella, Claudio] IBM Res Ireland, Dublin 15, Ireland.
   [Ghaddar, Bissan; Naoum-Sawaya, Joe] Univ Western Ontario, Ivey Business Sch, London, ON N6G 0N1, Canada.
RP Gambella, C (corresponding author), IBM Res Ireland, Dublin 15, Ireland.
EM claudio.gambella1@ie.ibm.com; bghaddar@uwaterloo.ca;
   jnaoumsa@uwaterloo.ca
FU NSERCNatural Sciences and Engineering Research Council of Canada (NSERC)
   [RGPIN-2017-04185, RGPIN-2017-03962]
FX We are very grateful to four anonymous referees for their valuable
   feedback and comments that helped improve the content and presentation
   of the paper. Joe Naoum-Sawaya was supported by NSERC Discovery Grant
   RGPIN-2017-03962 and Bissan Ghaddar was supported by NSERC Discovery
   Grant RGPIN-2017-04185.
NR 228
TC 21
Z9 21
U1 57
U2 184
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0377-2217
EI 1872-6860
J9 EUR J OPER RES
JI Eur. J. Oper. Res.
PD MAY 1
PY 2021
VL 290
IS 3
BP 807
EP 828
DI 10.1016/j.ejor.2020.08.045
EA JAN 2021
PG 22
WC Management; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Business & Economics; Operations Research & Management Science
GA PO9BS
UT WOS:000605460600001
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Fang, HK
   Qian, Q
AF Fang, Haokun
   Qian, Quan
TI Privacy Preserving Machine Learning with Homomorphic Encryption and
   Federated Learning
SO FUTURE INTERNET
LA English
DT Article
DE multi-party machine learning; privacy preserving machine learning;
   homomorphic encryption
AB Privacy protection has been an important concern with the great success of machine learning. In this paper, it proposes a multi-party privacy preserving machine learning framework, named PFMLP, based on partially homomorphic encryption and federated learning. The core idea is all learning parties just transmitting the encrypted gradients by homomorphic encryption. From experiments, the model trained by PFMLP has almost the same accuracy, and the deviation is less than 1%. Considering the computational overhead of homomorphic encryption, we use an improved Paillier algorithm which can speed up the training by 25-28%. Moreover, comparisons on encryption key length, the learning network structure, number of learning clients, etc. are also discussed in detail in the paper.
C1 [Fang, Haokun; Qian, Quan] Shanghai Univ, Sch Comp Engn & Sci, Shanghai 200444, Peoples R China.
   [Qian, Quan] Shanghai Univ, Mat Genome Inst, Shanghai 200444, Peoples R China.
   [Fang, Haokun] 99 Shangda Rd, Shanghai 200444, Peoples R China.
RP Qian, Q (corresponding author), Shanghai Univ, Sch Comp Engn & Sci, Shanghai 200444, Peoples R China.; Qian, Q (corresponding author), Shanghai Univ, Mat Genome Inst, Shanghai 200444, Peoples R China.
EM fhk2014@shu.edu.cn; qqian@shu.edu.cn
FU National Key Research and Development Program of China [2018YFB0704400];
   Key Program of Science and Technology of Yunnan Province
   [202002AB080001-2]; Research and Development Program in Key Areas of
   Guangdong Province [2018B010113001]
FX This work is partially sponsored by the National Key Research and
   Development Program of China (2018YFB0704400), Key Program of Science
   and Technology of Yunnan Province (202002AB080001-2), Research and
   Development Program in Key Areas of Guangdong Province (2018B010113001).
   The authors gratefully appreciate the anonymous reviewers for their
   valuable comments.
NR 51
TC 6
Z9 6
U1 13
U2 16
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1999-5903
J9 FUTURE INTERNET
JI Future Internet
PD APR
PY 2021
VL 13
IS 4
AR 94
DI 10.3390/fi13040094
PG 20
WC Computer Science, Information Systems
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA RR3VE
UT WOS:000643029400001
OA gold
DA 2022-04-17
ER

PT C
AU Mohd, T
   Harussani, M
   Masrom, S
   Johari, N
   Alfat, L
AF Mohd, Thuraiya
   Harussani, Muhamad
   Masrom, Suraya
   Johari, Noraini
   Alfat, Lathifah
TI Modelling Office Building Rent Prediction based on Auto Model in Machine
   Learning
SO ENVIRONMENT-BEHAVIOUR PROCEEDINGS JOURNAL
LA English
DT Proceedings Paper
CT 10th AMER International Conference on Quality of Life (AicQoL)
CY MAR 16-17, 2022
CL Batu Ferringhi, MALAYSIA
SP AMER
DE Office Rent; Machine Learning; Prediction
AB This paper applies a new approach in identifying the best Machine Learning model to predict office rent and determining the most significant factors influencing rental values. The Auto Model uses three (3) distinct types of Machine Learning algorithms, namely the Decision Tree, Random Forest, and Support Vector Machine. The Auto Model highlights that the Decision Tree outperformed Random Forest and Support Vector Machine for better predictability. The results of statistical analysis using Auto Model suggest that among the factors that influence office building rental, amenities, and inhouse services show significant roles in the model.
C1 [Mohd, Thuraiya] Univ Teknol MARA, Ctr Grad Studies, Perak Branch, Seri Iskandar Campus, Seri Iskandar 32610, Perak, Malaysia.
   [Harussani, Muhamad] Univ Teknol MARA, GreenSafe Cities GreSAFE Res Grp, Dept Built Environm Studies & Technol, Perak Branch,Fac Architecture Planning & Surveyin, Seri Iskandar Campus, Seri Iskandar 32610, Perak, Malaysia.
   [Masrom, Suraya] Univ Teknol MARA, Malaysia Machine Learning & Interact Visualizat M, Fac Comp & Math Sci, Perak Branch, Tapah Campus, Tapah 35400, Perak, Malaysia.
   [Johari, Noraini] Univ Teknol MARA, Dept Built Environm Studies & Technol, Fac Architecture Planning & Surveying, Perak Branch, Seri Iskandar Campus, Perak 32610, Perak, Malaysia.
   [Alfat, Lathifah] Univ Pembangunan Jaya, Fac Technol & Design, Kota Tangerang Selatan, Indonesia.
RP Mohd, T (corresponding author), Univ Teknol MARA, Ctr Grad Studies, Perak Branch, Seri Iskandar Campus, Seri Iskandar 32610, Perak, Malaysia.
EM thura231@uitm.edu.my; muhdharussani97@gmail.com; suray078@uitm.edu.my;
   norai127@uitm.edu.my; lathifah.alfat@upj.ac.id
FU National Real Estate Research Coordinator (NAPREC); Universiti Teknologi
   MARA
FX The authors would like to thank the National Real Estate Research
   Coordinator (NAPREC) for funding this research and Universiti Teknologi
   MARA for providing the necessary support to enable its successful
   implementation. By providing such ideas through this paper, we hope that
   this paper can provide a significant body of knowledge on real estate
   study in Machine Learning applications.
NR 20
TC 0
Z9 0
U1 0
U2 0
PU E-IPH LTD UK
PI SHEFFIELD
PA THE LEADMILL, 6 LEADMILL RD, PO BOX STUDIO 7, SHEFFIELD, S1 4SE, ENGLAND
SN 2398-4287
J9 ENVIRON-BEHAV PROC J
JI Environ.-Behav. Proc. J.
PD MAR
PY 2022
VL 7
IS 19
PG 8
WC Environmental Studies
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Environmental Sciences & Ecology
GA 0C9DW
UT WOS:000775606400006
DA 2022-04-17
ER

PT J
AU De Iaco, S
   Hristopulos, DT
   Lin, G
AF De Iaco, Sandra
   Hristopulos, Dionissios T.
   Lin, Guang
TI Special Issue: Geostatistics and Machine Learning
SO MATHEMATICAL GEOSCIENCES
LA English
DT Article
DE Geostatistics; Statistical learning; Machine learning; Spatial process;
   Gaussian process regression
ID SPACE
AB Recent years have seen a steady growth in the number of papers that apply machine learning methods to problems in the earth sciences. Although they have different origins, machine learning and geostatistics share concepts and methods. For example, the kriging formalism can be cast in the machine learning framework of Gaussian process regression. Machine learning, with its focus on algorithms and ability to seek, identify, and exploit hidden structures in big data sets, is providing new tools for exploration and prediction in the earth sciences. Geostatistics, on the other hand, offers interpretable models of spatial (and spatiotemporal) dependence. This special issue on Geostatistics and Machine Learning aims to investigate applications of machine learning methods as well as hybrid approaches combining machine learning and geostatistics which advance our understanding and predictive ability of spatial processes.
C1 [De Iaco, Sandra] Univ Salento, Dept Econ Sci, Sect Math & Stat, Lecce, Italy.
   [Hristopulos, Dionissios T.] Tech Univ Crete, Sch Elect & Comp Engn, Khania 73100, Greece.
   [Lin, Guang] Purdue Univ, Dept Math, W Lafayette, IN 47907 USA.
   [Lin, Guang] Purdue Univ, Sch Mech Engn, W Lafayette, IN 47907 USA.
RP De Iaco, S (corresponding author), Univ Salento, Dept Econ Sci, Sect Math & Stat, Lecce, Italy.
EM sandra.deiaco@unisalento.it; dchristopoulos@ece.tuc.gr;
   guanglin@purdue.edu
OI Lin, Guang/0000-0002-0976-1987; De Iaco, Sandra/0000-0003-1820-2068
FU National Science FoundationNational Science Foundation (NSF)
   [DMS-1555072, DMS-1736364, CMMI-1634832, CMMI-1560834]; Brookhaven
   National LaboratoryUnited States Department of Energy (DOE) [382247];
   ARO/MURIMURI [W911NF-15-1-0562]; U.S. Department of Energy (DOE) Office
   of Science Advanced Scientific Computing Research programUnited States
   Department of Energy (DOE) [DE-SC0021142]
FX GL gratefully acknowledges the support from the National Science
   Foundation (DMS-1555072, DMS-1736364, CMMI-1634832, and CMMI-1560834),
   and the Brookhaven National Laboratory Subcontract 382247, ARO/MURI
   grant W911NF-15-1-0562, and U.S. Department of Energy (DOE) Office of
   Science Advanced Scientific Computing Research program DE-SC0021142.
NR 35
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1874-8961
EI 1874-8953
J9 MATH GEOSCI
JI Math Geosci.
PD APR
PY 2022
VL 54
IS 3
SI SI
BP 459
EP 465
DI 10.1007/s11004-022-09998-6
EA MAR 2022
PG 7
WC Geosciences, Multidisciplinary; Mathematics, Interdisciplinary
   Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Geology; Mathematics
GA 0G4NL
UT WOS:000771334100001
OA hybrid
DA 2022-04-17
ER

PT C
AU Sharma, R
   Kaushik, B
   Gondhi, N
AF Sharma, Reya
   Kaushik, Baijnath
   Gondhi, Naveen
GP IEEE
TI Character Recognition using Machine Learning and Deep Learning - A
   Survey
SO 2020 INTERNATIONAL CONFERENCE ON EMERGING SMART COMPUTING AND
   INFORMATICS (ESCI)
LA English
DT Proceedings Paper
CT 2nd IEEE International Conference on Emerging Smart Computing and
   Informatics (ESCI)
CY MAR 12-14, 2020
CL All India Shri Shivaji Memorial Soc, Inst Informat Technol, Pune, INDIA
SP IEEE
HO All India Shri Shivaji Memorial Soc, Inst Informat Technol
DE Deep learning; machine learning; OCR; CNN; pattern recognition
AB Digitization of machine printed or handwritten text documents have become very popular with the advancements in computing and technology. Humans have tried to automatized their work by replacing themselves with machines. The transformation from manual to automatization gave rise to several research areas and text recognition is one among them. Deep learning and machine learning techniques have been proved to be very suitable for optical character recognition. In this work, an up-to-date overview of four machine learning and deep learning architectures, viz., Support vector machine, Artificial neural network, Naive Bayes and Convolutional neural network have been discussed in detail.
C1 [Sharma, Reya; Kaushik, Baijnath; Gondhi, Naveen] Shri Mata Vaishno Devi Univ, Comp Sci & Engn, Katra, India.
RP Sharma, R (corresponding author), Shri Mata Vaishno Devi Univ, Comp Sci & Engn, Katra, India.
EM sharmareya327@gmail.com; baijnath.kaushik@smvdu.ac.in;
   naveen.gondhi@smvdu.ac.in
NR 28
TC 0
Z9 0
U1 2
U2 4
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-5263-9
PY 2020
BP 341
EP 345
PG 5
WC Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR8AU
UT WOS:000670589300066
DA 2022-04-17
ER

PT J
AU Chen, QA
   Wei, HP
   Rashid, M
   Cai, ZQ
AF Chen, Qiuan
   Wei, Haipeng
   Rashid, Muhammad
   Cai, Zhiqiang
TI Kernel extreme learning machine based hierarchical machine learning for
   multi-type and concurrent fault diagnosis
SO MEASUREMENT
LA English
DT Article
DE Hierarchical machine learning; Kernel extreme learning machine;
   Multi-type and concurrent faults; Fault diagnosis; Gearbox
ID ALGORITHM; FRAMEWORK; MODEL
AB The detection and identification of faults in rotary machines are of great significance to the mechanical equipment reliability especially the gearbox. Traditional machine learning algorithms suffer from low diagnosis accuracy of faults that have multiple types and exist concurrently. A novel machine learning method called hierarchical machine learning (HML) was proposed in this study to improve the faults diagnosis accuracy. The proposed algorithm consists of two layers. The first layer comprises a traditional machine learning model to identify the faults with distinguishable features and filter out these faults with indistinguishable features. The second layer model recognizes the faults filtered out by the first layer. In order to verify the effectiveness of the proposed method, the gearbox simulation experiment is carried out in the study. The simulation results validate that the proposed method outperforms other algorithms under an identical measure.
C1 [Chen, Qiuan; Rashid, Muhammad; Cai, Zhiqiang] Northwestern Polytech Univ, Sch Mech Engn, Dept Ind Engn, Xian 710072, Peoples R China.
   [Chen, Qiuan; Rashid, Muhammad; Cai, Zhiqiang] Northwestern Polytech Univ, Minist Ind & Informat Technol, Key Lab Ind Engn & Intelligent Mfg, Xian 710072, Peoples R China.
   [Wei, Haipeng] Beijing Inst Astronaut Syst Engn, Beijing 10076, Peoples R China.
RP Cai, ZQ (corresponding author), Northwestern Polytech Univ, Sch Mech Engn, Dept Ind Engn, Xian 710072, Peoples R China.
EM caizhiqiang@nwpu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [71871181, 71631001]; Key R&D Program of
   Shaanxi Province [2021ZDLGY10-06, 2021ZDLGY12-03]; 111 ProjectMinistry
   of Education, China - 111 Project [B13044]
FX The authors thank research support from the National Natural Science
   Foundation of China (Nos. 71871181, 71631001), the Key R&D Program of
   Shaanxi Province (Nos. 2021ZDLGY10-06, 2021ZDLGY12-03) and the 111
   Project (No. B13044).
NR 46
TC 1
Z9 1
U1 13
U2 13
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0263-2241
EI 1873-412X
J9 MEASUREMENT
JI Measurement
PD NOV
PY 2021
VL 184
AR 109923
DI 10.1016/j.measurement.2021.109923
EA JUL 2021
PG 12
WC Engineering, Multidisciplinary; Instruments & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Instruments & Instrumentation
GA WD2FU
UT WOS:000704764100004
DA 2022-04-17
ER

PT J
AU Duranthon, O
   Marsili, M
   Xie, R
AF Duranthon, O.
   Marsili, M.
   Xie, R.
TI Maximal relevance and optimal learning machines
SO JOURNAL OF STATISTICAL MECHANICS-THEORY AND EXPERIMENT
LA English
DT Article
DE learning theory; machine learning; statistical inference
ID NEURAL-NETWORKS
AB We explore the hypothesis that learning machines extract representations of maximal relevance, where the relevance is defined as the entropy of the energy distribution of the internal representation. We show that the mutual information between the internal representation of a learning machine and the features that it extracts from the data is bounded from below by the relevance. This motivates our study of models with maximal relevance-that we call optimal learning machines-as candidates of maximally informative representations. We analyse how the maximisation of the relevance is constrained both by the architecture of the model used and by the available data, in practical cases. We find that sub-extensive features that do not affect the thermodynamics of the model, may affect significantly learning performance, and that criticality enhances learning performance, but the existence of a critical point is not a necessary condition. On specific learning tasks, we find that (i) the maximal values of the likelihood are achieved by models with maximal relevance, (ii) internal representations approach the maximal relevance that can be achieved in a finite dataset and (iii) learning is associated with a broadening of the spectrum of energy levels of the internal representation, in agreement with the maximum relevance hypothesis.
C1 [Duranthon, O.] Ecole Normale Super, Dept Phys, 24 Rue Lhomond, F-75005 Paris, France.
   [Marsili, M.] Abdus Salam Int Ctr Theoret Phys, Str Costiera 11, I-34151 Trieste, Italy.
   [Xie, R.] Cent China Normal Univ, Key Lab Quark & Lepton Phys MOE, Wuhan 430079, Peoples R China.
   [Xie, R.] Cent China Normal Univ, Inst Particle Phys, Wuhan 430079, Peoples R China.
RP Marsili, M (corresponding author), Abdus Salam Int Ctr Theoret Phys, Str Costiera 11, I-34151 Trieste, Italy.
EM marsili@ictp.it
RI Marsili, Matteo/AAX-2124-2021
FU Chinal Scholarship Council (CSC) [202006770018]
FX We benefitted from discussions with Jean Barbier, Riccardo Zecchina,
   Federico Ricci-Tersenghi and Yasser Roudi. We are grateful to the
   authors of [25] for sharing their data with us. We thank an anonymous
   referee of MSML2020 for pointing out the example in section 3.1.
   Rongrong Xie acknowledges a fellowship from the Chinal Scholarship
   Council (CSC) under Grant CSC No. 202006770018.
NR 34
TC 0
Z9 0
U1 3
U2 4
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 1742-5468
J9 J STAT MECH-THEORY E
JI J. Stat. Mech.-Theory Exp.
PD MAR
PY 2021
VL 2021
IS 3
AR 033409
DI 10.1088/1742-5468/abe6ff
PG 30
WC Mechanics; Physics, Mathematical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Mechanics; Physics
GA QZ4RH
UT WOS:000630715000001
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Wong, LJ
   Michaels, AJ
AF Wong, Lauren J.
   Michaels, Alan J.
TI Transfer Learning for Radio Frequency Machine Learning: A Taxonomy and
   Survey
SO SENSORS
LA English
DT Article
DE machine learning (ML); deep learning (DL); transfer learning (TL); radio
   frequency machine learning (RFML)
ID CONVOLUTIONAL NEURAL-NETWORK; DEEP; CLASSIFICATION
AB Transfer learning is a pervasive technology in computer vision and natural language processing fields, yielding exponential performance improvements by leveraging prior knowledge gained from data with different distributions. However, while recent works seek to mature machine learning and deep learning techniques in applications related to wireless communications, a field loosely termed radio frequency machine learning, few have demonstrated the use of transfer learning techniques for yielding performance gains, improved generalization, or to address concerns of training data costs. With modifications to existing transfer learning taxonomies constructed to support transfer learning in other modalities, this paper presents a tailored taxonomy for radio frequency applications, yielding a consistent framework that can be used to compare and contrast existing and future works. This work offers such a taxonomy, discusses the small body of existing works in transfer learning for radio frequency machine learning, and outlines directions where future research is needed to mature the field.
C1 [Wong, Lauren J.; Michaels, Alan J.] Virginia Tech, Hume Ctr Natl Secur & Technol, Blacksburg, VA 24061 USA.
   [Wong, Lauren J.] Intel AI Lab, Santa Clara, CA 95054 USA.
RP Wong, LJ (corresponding author), Virginia Tech, Hume Ctr Natl Secur & Technol, Blacksburg, VA 24061 USA.; Wong, LJ (corresponding author), Intel AI Lab, Santa Clara, CA 95054 USA.
EM ljwong@vt.edu; ajm@vt.edu
OI Wong, Lauren/0000-0001-5896-0176
NR 56
TC 0
Z9 0
U1 3
U2 3
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD FEB
PY 2022
VL 22
IS 4
AR 1416
DI 10.3390/s22041416
PG 14
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Instruments & Instrumentation
GA ZN5KD
UT WOS:000765072200001
PM 35214317
OA gold, Green Published
DA 2022-04-17
ER

PT J
AU Ozdemir, ME
   Ali, Z
   Subeshan, B
   Asmatulu, E
AF Erkinay Ozdemir, Merve
   Ali, Zaara
   Subeshan, Balakrishnan
   Asmatulu, Eylem
TI Applying machine learning approach in recycling
SO JOURNAL OF MATERIAL CYCLES AND WASTE MANAGEMENT
LA English
DT Review
DE Machine learning; Neural network; Decision making; Advanced recycling
ID FUNCTION NEURAL-NETWORKS; SUPPORT VECTOR MACHINE; WASTE GENERATION;
   PREDICTION; MODEL; CLASSIFICATION; SPECTROSCOPY; COLLECTION; HEALTH; AID
AB Waste generation has been increasing drastically based on the world's population and economic growth. This has significantly affected human health, natural life, and ecology. The utilization of limited natural resources, and the harming of the earth in the process of mineral extraction, and waste management have far exceeded limits. The recycling rate are continuously increasing; however, assessments show that humans will be creating more waste than ever before. Some difficulties during recycling include the significant expense involved during the separation of recyclable waste from non-disposable waste. Machine learning is the utilization of artificial intelligence (AI) that provides a framework to take as a structural improvement of the fact without being programmed. Machine learning concentrates on the advancement of programs that can obtain the information and use it to learn to make future decisions. The classification and separation of materials in a mixed recycling application in machine learning is a division of AI that is playing an important role for better separation of complex waste. The primary purpose of this study is to analyze AI by focusing on machine learning algorithms used in recycling systems. This study is a compilation of the most recent developments in machine learning used in recycling industries.
C1 [Erkinay Ozdemir, Merve] Iskenderun Tech Univ, Dept Elect Elect Engn, TR-31200 Iskenderun, Hatay, Turkey.
   [Ali, Zaara; Subeshan, Balakrishnan; Asmatulu, Eylem] Wichita State Univ, Dept Mech Engn, 1845 Fairmount St, Wichita, KS 67260 USA.
RP Asmatulu, E (corresponding author), Wichita State Univ, Dept Mech Engn, 1845 Fairmount St, Wichita, KS 67260 USA.
EM e.asmatulu@wichita.edu
OI Asmatulu, Eylem/0000-0002-5605-2251; Erkinay Ozdemir,
   merve/0000-0001-8864-385X
NR 131
TC 4
Z9 4
U1 12
U2 26
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1438-4957
EI 1611-8227
J9 J MATER CYCLES WASTE
JI J. Mater. Cycles Waste Manag.
PD MAY
PY 2021
VL 23
IS 3
BP 855
EP 871
DI 10.1007/s10163-021-01182-y
EA FEB 2021
PG 17
WC Environmental Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Environmental Sciences & Ecology
GA RU7FU
UT WOS:000618935000001
DA 2022-04-17
ER

PT C
AU Kumar, A
   Abhishek, K
   Shah, K
   Patel, D
   Jain, Y
   Chheda, H
   Nerurka, P
AF Kumar, Ajay
   Abhishek, Kumar
   Shah, Kunjal
   Patel, Divy
   Jain, Yash
   Chheda, Harsh
   Nerurka, Pranav
BE VillazonTerrazas, B
   OrtizRodriguez, F
   Tiwari, SM
   Shandilya, SK
TI Malware Detection Using Machine Learning
SO KNOWLEDGE GRAPHS AND SEMANTIC WEB, KGSWC 2020
SE Communications in Computer and Information Science
LA English
DT Proceedings Paper
CT 2nd Iberoamerican Knowledge Graphs and Semantic Web Conference (KGSWC) /
   1st Indo-American Knowledge Graphs and Semantic Web Conference
CY NOV 26-27, 2020
CL Merida, MEXICO
DE Security; Malware; Machine learning
AB Decision making using Machine Learning can be efficiently applied to security. Malware has become a big risk in today's times. In order to provide protection for the same, we present a machine-learning based technique for predicting Windows PE files as benign or malignant based on fifty-seven of their attributes. We have used the Brazilian Malware dataset, which had around 1,00,000 samples and 57 labels. We have made seven models, and have achieved 99.7% accuracy for the Random Forest model, which is very high when compared to other existing systems. Thus using the Random Forest model one can make a decision on whether a particular file is malware or benign.
C1 [Kumar, Ajay; Abhishek, Kumar] NIT Patna, Patna, Bihar, India.
   [Shah, Kunjal; Patel, Divy; Jain, Yash; Chheda, Harsh; Nerurka, Pranav] Veermata Jijabai Technol Inst, Mumbai, Maharashtra, India.
   [Nerurka, Pranav] NMIMS Mumbai, Mumbai, Maharashtra, India.
RP Abhishek, K (corresponding author), NIT Patna, Patna, Bihar, India.
EM ajayk.phd18@nitp.ac.in; kumar.abhishek.cse@nitp.ac.in;
   kshah_b18@vjti.ac.in; dspatel_b17@it.vjti.ac.in;
   ysjain_b17@it.vjti.ac.in; hkchheda_b17@it.vjti.ac.in; pranav.n@nmims.edu
RI ; Abhishek, Kumar/C-9914-2017
OI nerurkar, pranav/0000-0002-9100-6437; Abhishek,
   Kumar/0000-0001-6825-2392
NR 30
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1865-0929
EI 1865-0937
BN 978-3-030-65384-2; 978-3-030-65383-5
J9 COMM COM INF SC
PY 2020
VL 1232
BP 61
EP 71
DI 10.1007/978-3-030-65384-2_5
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS7HL
UT WOS:000761598800005
DA 2022-04-17
ER

PT J
AU Calzavara, S
   Conti, M
   Focardi, R
   Rabitti, A
   Tolomei, G
AF Calzavara, Stefano
   Conti, Mauro
   Focardi, Riccardo
   Rabitti, Alvise
   Tolomei, Gabriele
TI Machine Learning for Web Vulnerability Detection: The Case of Cross-Site
   Request Forgery
SO IEEE SECURITY & PRIVACY
LA English
DT Article
DE Security; Tools; Browsers; Supervised learning; Forgery; Social
   networking (online); Machine learning
AB We propose a methodology to leverage machine learning (ML) for the detection of web application vulnerabilities. We use it in the design of Mitch, the first ML solution for the black-box detection of cross-site request forgery vulnerabilities. Finally, we show the effectiveness of Mitch on real software.
C1 [Calzavara, Stefano; Focardi, Riccardo; Rabitti, Alvise] Univ Ca Foscari Venezia, Venice, Italy.
   [Conti, Mauro] Univ Padua, Padua, Italy.
   [Tolomei, Gabriele] Sapienza Univ Rome, Rome, Italy.
RP Calzavara, S (corresponding author), Univ Ca Foscari Venezia, Venice, Italy.
EM calzavara@dais.unive.it; conti@math.unipd.it; focardi@unive.it;
   alvise.rabitti@unive.it; tolomei@di.uniroma1.it
RI Conti, Mauro/F-9145-2012; Focardi, Riccardo/A-8281-2016
OI Conti, Mauro/0000-0002-3612-1934; Focardi, Riccardo/0000-0003-0101-0692;
   Calzavara, Stefano/0000-0001-9179-8270
FU project Machine Learning for Web Security - Incentivi alla Ricerca
   Individuale program of Universita Ca' Foscari Venezia
FX This article was supported by the project Machine Learning for Web
   Security, funded by the Incentivi alla Ricerca Individuale program of
   Universita Ca' Foscari Venezia.
NR 17
TC 3
Z9 4
U1 4
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1540-7993
EI 1558-4046
J9 IEEE SECUR PRIV
JI IEEE Secur. Priv.
PD MAY-JUN
PY 2020
VL 18
IS 3
BP 8
EP 16
DI 10.1109/MSEC.2019.2961649
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LS2OV
UT WOS:000536229600003
DA 2022-04-17
ER

PT J
AU Bach, P
   Chernozhukov, V
   Kurz, MS
   Spindler, M
AF Bach, Philipp
   Chernozhukov, Victor
   Kurz, Malte S.
   Spindler, Martin
TI DoubleML - An Object-Oriented Implementation of Double Machine Learning
   in Python
SO JOURNAL OF MACHINE LEARNING RESEARCH
LA English
DT Article
DE machine learning; causal inference; causal machine learning; Python
AB DoubleML is an open-source Python library implementing the double machine learning framework of Chernozhukov et al. (2018) for a variety of causal models. It contains functionalities for valid statistical inference on causal parameters when the estimation of nuisance parameters is based on machine learning methods. The object-oriented implementation of DoubleML provides a high flexibility in terms of model specifications and makes it easily extendable. The package is distributed under the MIT license and relies on core libraries from the scientific Python ecosystem: scikit-learn, numpy, pandas, scipy, statsmodels and joblib. Source code, documentation and an extensive user guide can be found at https://github.com/DoubleML/doubleml-for-py and https://docs.doubleml.org.
C1 [Bach, Philipp; Kurz, Malte S.; Spindler, Martin] Univ Hamburg, Fac Business Adm, Moorweidenstr 18, D-20148 Hamburg, Germany.
   [Chernozhukov, Victor] MIT, Dept Econ, 50 Mem Dr, Cambridge, MA 02142 USA.
   [Chernozhukov, Victor] MIT, Ctr Stat & Data Sci, 50 Mem Dr, Cambridge, MA 02142 USA.
RP Kurz, MS (corresponding author), Univ Hamburg, Fac Business Adm, Moorweidenstr 18, D-20148 Hamburg, Germany.
EM PHILIPP.BACH@UNI-HAMBURG.DE; VCHERN@MIT.EDU;
   MALTE.SIMON.KURZ@UNI-HAMBURG.DE; MARTIN.SPINDLER@UNI-HAMBURG.DE
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)German
   Research Foundation (DFG) [431701914]
FX This work was funded by the Deutsche Forschungsgemeinschaft (DFG, German
   Research Foundation) - Project Number 431701914.
NR 17
TC 0
Z9 0
U1 0
U2 0
PU MICROTOME PUBL
PI BROOKLINE
PA 31 GIBBS ST, BROOKLINE, MA 02446 USA
SN 1532-4435
J9 J MACH LEARN RES
JI J. Mach. Learn. Res.
PY 2022
VL 23
BP 1
EP 6
PG 6
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA ZQ1MI
UT WOS:000766876100001
DA 2022-04-17
ER

PT J
AU Bharodia, N
   Chen, W
AF Bharodia, Nehalkumar
   Chen, Wei
TI What can we learn from what a machine has learned? Interpreting credit
   risk machine learning models
SO JOURNAL OF RISK MODEL VALIDATION
LA English
DT Article
DE machine learning; credit scoring; model interpretability; feature
   importance
AB For being able to analyze unstructured and alternative data, machine learning algorithms are gaining popularity in financial risk management. Alongside the technological advances in learning power and the digitalization of society, new financial technologies are also leading to more innovation in the business of lending. However, machine learning models are often viewed as lacking in terms of transparency and interpretability, which hinders model validation and prevents business users from adopting these models in practice. In this paper, we study a few popular machine learning models using LendingClub loan data, and judge these on performance and interpretability. Our study independently shows LendingClub has sound risk assessment. The findings and techniques used in this paper can be extended to other models.
C1 [Bharodia, Nehalkumar; Chen, Wei] SAS Inst Inc, 100 SAS Campus Dr, Cary, NC 27513 USA.
RP Bharodia, N (corresponding author), SAS Inst Inc, 100 SAS Campus Dr, Cary, NC 27513 USA.
EM nehal.kumar@sas.com; wei.chen@sas.com
NR 20
TC 0
Z9 0
U1 6
U2 6
PU INCISIVE MEDIA
PI LONDON
PA HAYMARKET HOUSE, 28-29 HAYMARKET, LONDON, SW1Y 4RX, ENGLAND
SN 1753-9579
EI 1753-9587
J9 J RISK MODEL VALIDAT
JI J. Risk Model Valid.
PD JUN
PY 2021
VL 15
IS 2
BP 1
EP 22
DI 10.21314/JRMV.2020.235
PG 22
WC Business, Finance
WE Social Science Citation Index (SSCI)
SC Business & Economics
GA WM2PF
UT WOS:000710932000002
DA 2022-04-17
ER

PT J
AU Huang, YM
   Li, XY
   Zhu, YX
   Lei, H
   Zhu, QS
   Yang, S
AF Huang, Yi-Ming
   Li, Xiao-Yu
   Zhu, Yi-Xuan
   Lei, Hang
   Zhu, Qing-Sheng
   Yang, Shan
TI Learning Unitary Transformation by Quantum Machine Learning Model
SO CMC-COMPUTERS MATERIALS & CONTINUA
LA English
DT Article
DE Machine learning; quantum computing; unitary transformation
AB Quantum machine learning (QML) is a rapidly rising research field that incorporates ideas from quantum computing and machine learning to develop emerging tools for scientific research and improving data processing. How to efficiently control or manipulate the quantum system is a fundamental and vexing problem in quantum computing. It can be described as learning or approximating a unitary operator. Since the success of the hybrid-based quantum machine learning model proposed in recent years, we investigate to apply the techniques from QML to tackle this problem. Based on the Choi-Jamiolkowski isomorphism in quantum computing, we transfer the original problem of learning a unitary operator to a min-max optimization problem which can also be viewed as a quantum generative adversarial network. Besides, we select the spectral norm between the target and generated unitary operators as the regularization term in the loss function. Inspired by the hybrid quantum-classical framework widely used in quantum machine learning, we employ the variational quantum circuit and gradient descent based optimizers to solve the min-max optimization problem. In our numerical experiments, the results imply that our proposed method can successfully approximate the desired unitary operator and dramatically reduce the number of quantum gates of the traditional approach. The average fidelity between the states that are produced by applying target and generated unitary on random input states is around 0.997.
C1 [Huang, Yi-Ming; Li, Xiao-Yu; Zhu, Yi-Xuan; Lei, Hang] Univ Elect Sci & Technol China, Sch Informat & Software Engn, Chengdu 610054, Peoples R China.
   [Zhu, Qing-Sheng] Univ Elect Sci & Technol China, Sch Phys, Chengdu 610054, Peoples R China.
   [Yang, Shan] Jackson State Univ, Dept Chem Phys & Atmospher Sci, Jackson, MS 39217 USA.
RP Li, XY (corresponding author), Univ Elect Sci & Technol China, Sch Informat & Software Engn, Chengdu 610054, Peoples R China.
EM xiaoyuuestc@uestc.edu.cn
FU National Key Research and Development Plan of China [2018YFA0306703]
FX This work has received support from the National Key Research and
   Development Plan of China under Grant No. 2018YFA0306703.
NR 25
TC 0
Z9 0
U1 4
U2 8
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1546-2218
EI 1546-2226
J9 CMC-COMPUT MATER CON
JI CMC-Comput. Mat. Contin.
PY 2021
VL 68
IS 1
BP 789
EP 803
DI 10.32604/cmc.2021.016663
PG 15
WC Computer Science, Information Systems; Materials Science,
   Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Materials Science
GA RC5DX
UT WOS:000632822900040
OA gold
DA 2022-04-17
ER

PT J
AU Nicora, G
   Rios, M
   Abu-Hanna, A
   Bellazzi, R
AF Nicora, Giovanna
   Rios, Miguel
   Abu-Hanna, Ameen
   Bellazzi, Riccardo
TI Evaluating pointwise reliability of machine learning prediction
SO JOURNAL OF BIOMEDICAL INFORMATICS
LA English
DT Article
DE Machine learning trustworthiness; Predictive reliability; Uncertainty
ID SUPPORT VECTOR MACHINES; REJECT OPTION; CLASSIFICATION; UNCERTAINTY
AB Interest in Machine Learning applications to tackle clinical and biological problems is increasing. This is driven by promising results reported in many research papers, the increasing number of AI-based software products, and by the general interest in Artificial Intelligence to solve complex problems. It is therefore of importance to improve the quality of machine learning output and add safeguards to support their adoption. In addition to regulatory and logistical strategies, a crucial aspect is to detect when a Machine Learning model is not able to generalize to new unseen instances, which may originate from a population distant to that of the training population or from an under-represented subpopulation. As a result, the prediction of the machine learning model for these instances may be often wrong, given that the model is applied outside its "reliable" space of work, leading to a decreasing trust of the final users, such as clinicians. For this reason, when a model is deployed in practice, it would be important to advise users when the model's predictions may be unreliable, especially in high-stakes applications, including those in healthcare. Yet, reliability assessment of each machine learning prediction is still poorly addressed.
   Here, we review approaches that can support the identification of unreliable predictions, we harmonize the notation and terminology of relevant concepts, and we highlight and extend possible interrelationships and overlap among concepts. We then demonstrate, on simulated and real data for ICU in-hospital death prediction, a possible integrative framework for the identification of reliable and unreliable predictions. To do so, our proposed approach implements two complementary principles, namely the density principle and the local fit principle. The density principle verifies that the instance we want to evaluate is similar to the training set. The local fit principle verifies that the trained model performs well on training subsets that are more similar to the instance under evaluation. Our work can contribute to consolidating work in machine learning especially in medicine.
C1 [Nicora, Giovanna; Bellazzi, Riccardo] Univ Pavia, Dept Elect Comp & Biomed Engn, Pavia, Italy.
   [Rios, Miguel; Abu-Hanna, Ameen] Univ Amsterdam, Amsterdam UMC, Dept Med Informat, Amsterdam, Netherlands.
RP Nicora, G (corresponding author), Univ Pavia, Dept Elect Comp & Biomed Engn, Pavia, Italy.
EM giovanna.nicora01@universitadipavia.it
FU Department of Electrical, Computer and Biomedical Engineering of
   University of Pavia; European CommissionEuropean CommissionEuropean
   Commission Joint Research Centre [101016233]
FX We thank the anonymous reviewers for their careful reading of our
   manuscript and their many insightful comments and suggestions. This work
   was partially supported by the Department of Electrical, Computer and
   Biomedical Engineering of University of Pavia and by the European
   Commission as part of the PERISCOPE project (Grant Agreement 101016233)
   , coordinated by the University of Pavia.
NR 97
TC 0
Z9 0
U1 2
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1532-0464
EI 1532-0480
J9 J BIOMED INFORM
JI J. Biomed. Inform.
PD MAR
PY 2022
VL 127
AR 103996
DI 10.1016/j.jbi.2022.103996
PG 15
WC Computer Science, Interdisciplinary Applications; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Medical Informatics
GA ZR5YJ
UT WOS:000767857700003
PM 35041981
OA hybrid
DA 2022-04-17
ER

PT J
AU Tsai, CW
   Chen, YP
   Tang, TC
   Luo, YC
AF Tsai, Chun-Wei
   Chen, Yi-Ping
   Tang, Tzu-Chieh
   Luo, Yu-Chen
TI An efficient parallel machine learning-based blockchain framework
SO ICT EXPRESS
LA English
DT Article
DE Machine learning; Blockchain; Deep learning
AB The unlimited possibilities of machine learning have been shown in several successful reports and applications. However, how to make sure that the searched results of a machine learning system are not tampered by anyone and how to prevent the other users in the same network environment from easily getting our private data are two critical research issues when we immerse into powerful machine learning-based systems or applications. This situation is just like other modern information systems that confront security and privacy issues. The development of blockchain provides us an alternative way to address these two issues. That is why some recent studies have attempted to develop machine learning systems with blockchain technologies or to apply machine learning methods to blockchain systems. To show what the combination of blockchain and machine learning is capable of doing, in this paper, we proposed a parallel framework to find out suitable hyperparameters of deep learning in a blockchain environment by using a metaheuristic algorithm. The proposed framework also takes into account the issue of communication cost, by limiting the number of information exchanges between miners and blockchain. (C) 2021 The Korean Institute of Communications and Information Sciences (KICS). Publishing services by Elsevier B.V.
C1 [Tsai, Chun-Wei; Chen, Yi-Ping; Tang, Tzu-Chieh; Luo, Yu-Chen] Natl Sun Yat Sen Univ, Dept Comp Sci & Engn, Kaohsiung 80424, Taiwan.
RP Tsai, CW (corresponding author), Natl Sun Yat Sen Univ, Dept Comp Sci & Engn, Kaohsiung 80424, Taiwan.
EM cwtsai@mail.cse.nsysu.edu.tw
FU Min-istry of Science and Technology of Taiwan, R.O.C.
   [MOST108-2221-E-005-021-MY3, MOST110-2218-E-110-007-MBK]
FX The authors would like to thank the editor and anonymous reviewers for
   their valuable comments and suggestions on the paper. This work was
   supported in part by the Min-istry of Science and Technology of Taiwan,
   R.O.C., under Contracts MOST108-2221-E-005-021-MY3 and
   MOST110-2218-E-110-007-MBK.
NR 28
TC 0
Z9 0
U1 11
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2405-9595
J9 ICT EXPRESS
JI ICT Express
PD SEP
PY 2021
VL 7
IS 3
BP 300
EP 307
DI 10.1016/j.icte.2021.08.014
EA SEP 2021
PG 8
WC Computer Science, Information Systems; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA UX1CQ
UT WOS:000700585500007
OA gold
DA 2022-04-17
ER

PT J
AU Yahia, S
   Said, S
   Zaied, M
AF Yahia, Siwar
   Said, Salwa
   Zaied, Mourad
TI Wavelet extreme learning machine and deep learning for data
   classification
SO NEUROCOMPUTING
LA English
DT Article
DE Extreme learning machine; Wavelet neural networks; Deep learning; Data
   classification; ELM auto-encoder
ID NEURAL-NETWORK; DIABETES DISEASE; FACE RECOGNITION; ALGORITHM; KERNEL;
   ELM
AB Recently, the Extreme Learning Machine (ELM) algorithm has been applied to various fields due to its rapidity and significant generalization performance. Traditionally, deep learning (DL) and wavelet neural networks (WNN) methods reach a high classification accuracy in machine learning applications. As a result, a new structure based on WNN, deep architecture and ELM is proposed in this paper. The proposed method is based on Extreme Learning Machine Auto-Encoder with DL structure and a composite wavelet activation function used in the hidden nodes. To evaluate the performance of our approach, we used standard benchmark data-sets, namely COIL-20, Pima Indian Diabetes (PID), MNIST and EMNIST. Experimental results show that our method offers satisfactory results and performance compared to other approaches. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Yahia, Siwar] Natl Engn Sch Sfax, Sfax, Tunisia.
   [Yahia, Siwar; Said, Salwa; Zaied, Mourad] RTIM Reaserch Grp Intelligent Machine, Gabes, Tunisia.
RP Yahia, S (corresponding author), Natl Engn Sch Sfax, Sfax, Tunisia.
EM yahiasiwar@yahoo.fr
NR 64
TC 1
Z9 1
U1 3
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD JAN 22
PY 2022
VL 470
BP 280
EP 289
DI 10.1016/j.neucom.2020.04.158
PG 10
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZI7TJ
UT WOS:000761818900002
DA 2022-04-17
ER

PT J
AU Yang, F
   Zhang, Q
   Ji, XK
   Zhang, YC
   Li, WT
   Peng, SL
   Xue, FZ
AF Yang, Fan
   Zhang, Qi
   Ji, Xiaokang
   Zhang, Yanchun
   Li, Wentao
   Peng, Shaoliang
   Xue, Fuzhong
TI Machine Learning Applications in Drug Repurposing
SO INTERDISCIPLINARY SCIENCES-COMPUTATIONAL LIFE SCIENCES
LA English
DT Review
DE Machine learning; Deep learning; COVID-19; Drug repurposing
AB The coronavirus disease (COVID-19) has led to an rush to repurpose existing drugs, although the underlying evidence base is of variable quality. Drug repurposing is a technique by taking advantage of existing known drugs or drug combinations to be explored in an unexpected medical scenario. Drug repurposing, hence, plays a vital role in accelerating the pre-clinical process of designing novel drugs by saving time and cost compared to the traditional de novo drug discovery processes. Since drug repurposing depends on massive observed data from existing drugs and diseases, the tremendous growth of publicly available large-scale machine learning methods supplies the state-of-the-art application of data science to signaling disease, medicine, therapeutics, and identifying targets with the least error. In this article, we introduce guidelines on strategies and options of utilizing machine learning approaches for accelerating drug repurposing. We discuss how to employ machine learning methods in studying precision medicine, and as an instance, how machine learning approaches can accelerate COVID-19 drug repurposing by developing Chinese traditional medicine therapy. This article provides a strong reasonableness for employing machine learning methods for drug repurposing, including during fighting for COVID-19 pandemic.
C1 [Yang, Fan; Ji, Xiaokang; Xue, Fuzhong] Shandong Univ, Cheeloo Coll Med, Sch Publ Hlth, Dept Biostat, Jinan 250012, Peoples R China.
   [Yang, Fan; Zhang, Qi; Ji, Xiaokang; Xue, Fuzhong] Shandong Univ, Inst Med Dataol, Cheeloo Coll Med, Jinan 250012, Peoples R China.
   [Zhang, Yanchun] Victoria Univ, Inst Sustainable Ind & Liveable Citie, Melbourne, Vic, Australia.
   [Zhang, Yanchun] Zhejiang Lab Regenerat Med Vis & Brain Hlth, Oujiang Lab, Wenzhou 325001, Zhejiang, Peoples R China.
   [Peng, Shaoliang] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Peoples R China.
   [Li, Wentao; Peng, Shaoliang] Natl Univ Def Technol, Sch Comp Sci, Changsha, Peoples R China.
   [Peng, Shaoliang] Peng Cheng Lab, Shenzhen, Peoples R China.
RP Xue, FZ (corresponding author), Shandong Univ, Cheeloo Coll Med, Sch Publ Hlth, Dept Biostat, Jinan 250012, Peoples R China.; Xue, FZ (corresponding author), Shandong Univ, Inst Med Dataol, Cheeloo Coll Med, Jinan 250012, Peoples R China.; Peng, SL (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Peoples R China.; Peng, SL (corresponding author), Natl Univ Def Technol, Sch Comp Sci, Changsha, Peoples R China.; Peng, SL (corresponding author), Peng Cheng Lab, Shenzhen, Peoples R China.
EM fanyang@sdu.edu.cn; 201884000301@sdu.edu.cn; jxk@sdu.edu.cn;
   yanchun.zhang@vu.edu.au; liwentao2016@163.com; slpeng@hnu.edu.cn;
   xuefzh@sdu.edu.cn
FU China Postdoctoral Science FoundationChina Postdoctoral Science
   Foundation [2019M662373]; National Key Research and Development Program
   of China [2020YFC2003500, 2017YFB0202602, 2018YFC0910405,
   2017YFC1311003, 2016YFC1302500, 2016YFB0200400, 2017YFB0202104]
FX This work was supported by the China Postdoctoral Science Foundation
   (2019M662373) and the National Key Research and Development Program of
   China (2020YFC2003500, 2017YFB0202602, 2018YFC0910405, 2017YFC1311003,
   2016YFC1302500, 2016YFB0200400, and 2017YFB0202104).
NR 29
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1913-2751
EI 1867-1462
J9 INTERDISCIP SCI
JI Interdiscip. Sci.
PD MAR
PY 2022
VL 14
IS 1
BP 15
EP 21
DI 10.1007/s12539-021-00487-8
EA JAN 2022
PG 7
WC Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Mathematical & Computational Biology
GA ZP1XM
UT WOS:000745560100002
PM 35066811
OA Green Published, Bronze
DA 2022-04-17
ER

PT J
AU Auslander, N
   Gussow, AB
   Koonin, EV
AF Auslander, Noam
   Gussow, Ayal B.
   Koonin, Eugene V.
TI Incorporating Machine Learning into Established Bioinformatics
   Frameworks
SO INTERNATIONAL JOURNAL OF MOLECULAR SCIENCES
LA English
DT Review
DE machine learning; deep learning; bioinformatics methods; phylogenetics
ID PROTEIN-PROTEIN INTERACTIONS; PREDICTION; IDENTIFICATION; INTEGRATION;
   ALGORITHM; GENES
AB The exponential growth of biomedical data in recent years has urged the application of numerous machine learning techniques to address emerging problems in biology and clinical research. By enabling the automatic feature extraction, selection, and generation of predictive models, these methods can be used to efficiently study complex biological systems. Machine learning techniques are frequently integrated with bioinformatic methods, as well as curated databases and biological networks, to enhance training and validation, identify the best interpretable features, and enable feature and model investigation. Here, we review recently developed methods that incorporate machine learning within the same framework with techniques from molecular evolution, protein structure analysis, systems biology, and disease genomics. We outline the challenges posed for machine learning, and, in particular, deep learning in biomedicine, and suggest unique opportunities for machine learning techniques integrated with established bioinformatics approaches to overcome some of these challenges.
C1 [Auslander, Noam; Gussow, Ayal B.; Koonin, Eugene V.] Natl Lib Med, Natl Ctr Biotechnol Informat, NIH, Bethesda, MD 20894 USA.
RP Auslander, N; Koonin, EV (corresponding author), Natl Lib Med, Natl Ctr Biotechnol Informat, NIH, Bethesda, MD 20894 USA.
EM noam.auslander@nih.gov; ayal.gussow@nih.gov; koonin@ncbi.nlm.nih.gov
OI Koonin, Eugene/0000-0003-3943-8299; Ausalnder, Noam/0000-0002-1923-8735
FU intramural research program at the National Institutes of Health
   (National Library of Medicine)
FX The authors' research is supported by the intramural research program at
   the National Institutes of Health (National Library of Medicine). This
   research received no external funding.
NR 224
TC 2
Z9 2
U1 28
U2 40
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1422-0067
J9 INT J MOL SCI
JI Int. J. Mol. Sci.
PD MAR
PY 2021
VL 22
IS 6
AR 2903
DI 10.3390/ijms22062903
PG 19
WC Biochemistry & Molecular Biology; Chemistry, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Chemistry
GA RV3GE
UT WOS:000645724900001
PM 33809353
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Chen, DS
   Wang, TF
   Zhu, JW
   Zhu, B
   Wang, ZL
   Cao, JG
   Feng, CH
   Zhao, JW
AF Chen, De-Sheng
   Wang, Tong-Fu
   Zhu, Jia-Wang
   Zhu, Bo
   Wang, Zeng-Liang
   Cao, Jian-Gang
   Feng, Cai-Hong
   Zhao, Jun-Wei
TI A Novel Application of Unsupervised Machine Learning and Supervised
   Machine Learning-Derived Radiomics in Anterior Cruciate Ligament Rupture
SO RISK MANAGEMENT AND HEALTHCARE POLICY
LA English
DT Article
DE unsupervised machine learning; supervised machine learning; radiomics;
   anterior cruciate ligament rupture
ID DIAGNOSIS; KNEE; MRI; ACCURACY; LESIONS; INJURY; TEARS
AB Purpose: We aim to present an unsupervised machine learning application in anterior cruciate ligament (ACL) rupture and evaluate whether supervised machine learning-derived radiomics features enable prediction of ACL rupture accurately.
   Patients and Methods: Sixty-eight patients were reviewed. Their demographic features were recorded, radiomics features were extracted, and the input dataset was defined as a collection of demographic features and radiomics features. The input dataset was automatically classified by the unsupervised machine learning algorithm. Then, we used a supervised machine learning algorithm to construct a radiomics model. The t-test and least absolute shrinkage and selection operator (LASSO) method were used for feature selection, random forest and support vector machine (SVM) were used as machine learning classifiers. For each model, the sensitivity, specificity, accuracy, and the area under the curve (AUC) of receiver operating characteristic (ROC) curves were calculated to evaluate model performance.
   Results: In total, 5 demographic features were recorded and 106 radiomics features were extracted. By applying the unsupervised machine learning algorithm, patients were divided into 5 groups. Group 5 had the highest incidence of ACL rupture and left knee involvement. There were significant differences in left knee involvement among the groups. Forty-three radiomics features were extracted using t-test and 7 radiomics features were extracted using LASSO method. We found that the combination of LASSO selection method and random forest classifier has the highest sensitivity, specificity, accuracy, and AUC. The 7 radiomics features extracted by LASSO method were potential predictors for ACL rupture.
   Conclusion: We validated the clinical application of unsupervised machine learning involving ACL rupture. Moreover, we found 7 radiomics features which were potential predictors for ACL rupture. The study indicated that radiomics could be a valuable method in the prediction of ACL rupture.
C1 [Chen, De-Sheng; Wang, Tong-Fu; Zhu, Jia-Wang; Zhu, Bo; Wang, Zeng-Liang; Cao, Jian-Gang; Feng, Cai-Hong; Zhao, Jun-Wei] Tianjin Univ, Tianjin Hosp, Dept Sports Med & Arthroscopy, Tianjin, Peoples R China.
RP Zhu, JW (corresponding author), Tianjin Univ, Tianjin Hosp, Dept Sports Med & Arthroscopy, Tianjin, Peoples R China.
EM zhulingelou@126.com
NR 34
TC 0
Z9 0
U1 6
U2 8
PU DOVE MEDICAL PRESS LTD
PI ALBANY
PA PO BOX 300-008, ALBANY, AUCKLAND 0752, NEW ZEALAND
EI 1179-1594
J9 RISK MANAG HEALTHC P
JI RISK MANAG. HEALTHC. POLICY
PY 2021
VL 14
BP 2657
EP 2664
DI 10.2147/RMHP.S312330
PG 8
WC Health Care Sciences & Services; Health Policy & Services
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Health Care Sciences & Services
GA SZ4ZC
UT WOS:000666574000001
PM 34188576
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Wang, QY
AF Wang, Qiyu
TI Cryptocurrencies asset pricing via machine learning
SO INTERNATIONAL JOURNAL OF DATA SCIENCE AND ANALYTICS
LA English
DT Article
DE Machine learning; Asset pricing; Crypto factors
ID BITCOIN; INEFFICIENCY; VOLATILITY; MOMENTUM
AB In this paper, we study the cryptocurrency asset pricing via machine learning. The common pricing factors similar to equity asset pricing are constructed. The classical equity-based risk factors including size, momentum, and value to growth from the Fama-French three factor model are studied. For volatility risk factor category, we investigate realized volatility, skewness and jump. We also investigate liquidity factors including bid-ask, volume growth and Roll's measure. We collect other crypto-unique factors. We show the machine learning models which could handle 30 characteristics together explain most of the excess return of cryptocurrencies.
C1 [Wang, Qiyu] Zhejiang Univ Finance & Econ, China Acad Financial Res, Hangzhou, Peoples R China.
RP Wang, QY (corresponding author), Zhejiang Univ Finance & Econ, China Acad Financial Res, Hangzhou, Peoples R China.
EM qiyu.wang@qq.com
FU High-dimensional Time Series and Portfolio Optimization, Zhejiang
   Natural Science Fund, Youth project [LQ19A010004]; Zhejiang University
   [101000-12204]
FX The paper is sponsored by i) High-dimensional Time Series and Portfolio
   Optimization, LQ19A010004, Zhejiang Natural Science Fund, Youth project,
   2019.01-2021.12; ii) Asset pricing and deep learning, Zhejiang
   University AFR,101000-12204, 2019.06-2020.12..
NR 35
TC 0
Z9 0
U1 5
U2 15
PU SPRINGERNATURE
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND
SN 2364-415X
EI 2364-4168
J9 INT J DATA SCI ANAL
JI Int. J, Data Sci. Anal.
PD AUG
PY 2021
VL 12
IS 2
SI SI
BP 175
EP 183
DI 10.1007/s41060-021-00252-6
EA MAY 2021
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA UA4AU
UT WOS:000652470200001
DA 2022-04-17
ER

PT J
AU Brillinger, M
   Wuwer, M
   Hadi, MA
   Haas, F
AF Brillinger, Markus
   Wuwer, Marcel
   Hadi, Muaaz Abdul
   Haas, Franz
TI Energy prediction for CNC machining with machine learning
SO CIRP JOURNAL OF MANUFACTURING SCIENCE AND TECHNOLOGY
LA English
DT Article
DE Energy prediction; CNC machine tools; Machine learning; CNC machining;
   NC code
ID POWER-CONSUMPTION; SURFACE-ROUGHNESS; OPTIMIZATION; EFFICIENCY; MODELS
AB Nowadays, the reduction of CO2 emissions by moving from fossil to renewable energy sources is on the policy of many governments. At the same time, these governments are forcing the reduction of energy consumption. Since large industries have been in the focus for the last decade, today also small and medium enterprises with production lot size one are increasingly being obliged to reduce their energy requirements in production. Energy-efficient CNC machine tools contribute to this goal. In machining processes, the machining strategy also has a significant influence on energy demand. For manufacturing of lot size one, the prediction of the energy demand of a machining strategy, before a part is manufactured plays a decisive role. In numerous previous studies, analytical models between the energy demand and the machining strategy have been developed. However, their accuracy depends largely on the parameterization of these models by dedicated experiments. In this paper, different machine learning algorithms, especially variations of the decision tree ('DecisionTree', 'RandomForest', boosted 'RandomForest') are investigated for their ability to predict the energy demand of CNC machining operations based on real production data, without the need for dedicated experiments. As shown in this paper, the most accurate energy demand predictions can be achieved with the 'RandomForest' algorithm. (C) 2021 The Authors.
C1 [Brillinger, Markus; Wuwer, Marcel; Hadi, Muaaz Abdul] Pro2Future GmbH, Area 4-2 Cognit Prod Syst,Inffeldgasse 25f, A-8010 Graz, Austria.
   [Haas, Franz] Graz Univ Technol, Inst Prod Engn, Inffeldgasse 25f, A-8010 Graz, Austria.
RP Brillinger, M (corresponding author), Pro2Future GmbH, Area 4-2 Cognit Prod Syst,Inffeldgasse 25f, A-8010 Graz, Austria.
EM markus.brillinger@pro2future.at
OI Brillinger, Markus/0000-0002-0499-8491
FU FFG [854184]; Pro2Future GmbH; Austrian Federal Ministry of Transport,
   Innovation and Technology; Austrian Federal Ministry for Digital and
   Economic Affairs; Province of Upper Austria; Province of Syyria
FX This work has partially been supported by the FFG, Contract No. 854184;
   Pro2Future GmbH is funded within the Austrian COMET Program Competence
   Centers for Excellent Technologies under the auspices of the Austrian
   Federal Ministry of Transport, Innovation and Technology, the Austrian
   Federal Ministry for Digital and Economic Affairs and of the Provinces
   of Upper Austria and Syyria. COMET is managed by the Austrian Research
   Promotion Agency FFG.
NR 37
TC 1
Z9 1
U1 17
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1755-5817
J9 CIRP J MANUF SCI TEC
JI CIRP J. Manuf. Sci. Technol.
PD NOV
PY 2021
VL 35
BP 715
EP 723
DI 10.1016/j.cirpj.2021.07.014
EA SEP 2021
PG 9
WC Engineering, Manufacturing
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA WD3EM
UT WOS:000704828400006
OA hybrid
DA 2022-04-17
ER

PT J
AU Glikis, R
   Makris, C
   Tsirakis, N
AF Glikis, Rafael
   Makris, Christos
   Tsirakis, Nikos
TI DrCaptcha: An Interactive Machine Learning Application
SO COMPUTER SCIENCE AND INFORMATION SYSTEMS
LA English
DT Article
DE machine learning; neural networks; transfer learning; interactive
   machine learning; ensemble techniques
AB The creation of a Machine Learning system is a typical process that is mostly automated. However, we may address some problems in the during development, such as the over-training on the training set. A technique for eliminating this phenomenon is the assembling of ensembles of models that cooperate to make predictions. Another problem that almost always occurs is the necessity of the human factor in the data preparation process. In this paper, we present DrCaptcha [15], an interactive machine learning system that provides third-party applications with a CAPTCHA service and, at the same time, uses the user's input to train artificial neural networks that can be combined to create a powerful OCR system. A different way to tackle this problem is to use transfer learning, as we did in one of our experiments [33], to retrain models trained on massive datasets and retrain them in a smaller dataset.
C1 [Glikis, Rafael; Makris, Christos; Tsirakis, Nikos] Univ Patras, Comp Engn & Informat Dept, Patras 26500, Greece.
RP Glikis, R (corresponding author), Univ Patras, Comp Engn & Informat Dept, Patras 26500, Greece.
EM rglykys@ceid.upatras.gr; makri@ceid.upatras.gr; tsirakis@ceid.upatras.gr
NR 30
TC 0
Z9 0
U1 3
U2 4
PU COMSIS CONSORTIUM
PI NOVI SAD
PA UNIV NOVI SAD, FAC TECH SCI, TRG DOSITEJA OBRADOVICA 6, NOVI SAD, 21000,
   SERBIA
SN 1820-0214
J9 COMPUT SCI INF SYST
JI Comput. Sci. Inf. Syst.
PD OCT
PY 2021
VL 18
IS 3
BP 687
EP 702
DI 10.2298/CSIS200130048G
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TE9HE
UT WOS:000670316400005
OA gold
DA 2022-04-17
ER

PT J
AU Chen, SYC
   Yoo, S
AF Chen, Samuel Yen-Chi
   Yoo, Shinjae
TI Federated Quantum Machine Learning
SO ENTROPY
LA English
DT Article
DE quantum machine learning; federated learning; quantum neural networks;
   variational quantum circuits; privacy-preserving AI
ID CONVERGENCE; NETWORKS
AB Distributed training across several quantum computers could significantly improve the training time and if we could share the learned model, not the data, it could potentially improve the data privacy as the training would happen where the data is located. One of the potential schemes to achieve this property is the federated learning (FL), which consists of several clients or local nodes learning on their own data and a central node to aggregate the models collected from those local nodes. However, to the best of our knowledge, no work has been done in quantum machine learning (QML) in federation setting yet. In this work, we present the federated training on hybrid quantum-classical machine learning models although our framework could be generalized to pure quantum machine learning model. Specifically, we consider the quantum neural network (QNN) coupled with classical pre-trained convolutional model. Our distributed federated learning scheme demonstrated almost the same level of trained model accuracies and yet significantly faster distributed training. It demonstrates a promising future research direction for scaling and privacy aspects.
C1 [Chen, Samuel Yen-Chi; Yoo, Shinjae] Brookhaven Natl Lab, Computat Sci Initiat, Upton, NY 11973 USA.
RP Chen, SYC (corresponding author), Brookhaven Natl Lab, Computat Sci Initiat, Upton, NY 11973 USA.
EM ychen@bnl.gov; sjyoo@bnl.gov
RI Chen, Samuel Yen-Chi/AAZ-4019-2020
OI Chen, Samuel Yen-Chi/0000-0003-0114-4826
FU U.S. Department of Energy, Office of Science, Advanced Scientific
   Computing ResearchUnited States Department of Energy (DOE)
   [DE-SC-0012704]; Brookhaven National Laboratory LDRDUnited States
   Department of Energy (DOE) [20-024]
FX This work is supported by the U.S. Department of Energy, Office of
   Science, Advanced Scientific Computing Research under Award Number
   DE-SC-0012704 and the Brookhaven National Laboratory LDRD #20-024.
NR 116
TC 5
Z9 5
U1 10
U2 19
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1099-4300
J9 ENTROPY-SWITZ
JI Entropy
PD APR
PY 2021
VL 23
IS 4
AR 460
DI 10.3390/e23040460
PG 14
WC Physics, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Physics
GA RR2VI
UT WOS:000642962200001
PM 33924721
OA Green Published, Green Submitted, gold
DA 2022-04-17
ER

PT J
AU Xiao, WC
   Xue, JL
   Miao, YS
   Li, Z
   Chen, C
   Wu, M
   Li, W
   Zhou, LD
AF Xiao, Wencong
   Xue, Jilong
   Miao, Youshan
   Li, Zhen
   Chen, Cheng
   Wu, Ming
   Li, Wei
   Zhou, Lidong
TI Distributed Graph Computation Meets Machine Learning
SO IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS
LA English
DT Article
DE Graph computing; distributed machine learning; heterogeneity; stale
   synchronous parallel; MEGA model
ID ANALYTICS; FRAMEWORK; SYSTEM
AB TuX(2) is a new distributed graph engine that bridges graph computation and distributed machine learning. TuX(2) inherits the benefits of elegant graph computation model, efficient graph layout, and balanced parallelism to scale to billion-edge graphs, while extended and optimized for distributed machine learning to support heterogeneity in data model, Stale Synchronous Parallel in scheduling, and a new Mini-batch, Exchange, GlobalSync, and Apply (MEGA) model for programming. TuX(2) further introduces a hybrid vertex-cut graph optimization and supports various consistency models in fault tolerance for machine learning. We have developed a set of representative distributed machine learning algorithms in TuX(2), covering both supervised and unsupervised learning. Compared to the implementations on distributed machine learning platforms, writing those algorithms in TuX(2) takes only about 25 percent of the code: our graph computation model hides the detailed management of data layout, partitioning, and parallelism from developers. The extensive evaluation of TuX(2), using large datasets with up to 64 billion of edges, shows that TuX(2) outperforms PowerGraph/PowerLyra, the state-of-the-art distributed graph engines, by an order of magnitude, while beating two state-of-the-art distributed machine learning systems by at least 60 percent.
C1 [Xiao, Wencong] Alibaba Grp, Hangzhou 311121, Peoples R China.
   [Xue, Jilong; Miao, Youshan; Zhou, Lidong] Microsoft Res, Beijing 100080, Peoples R China.
   [Li, Zhen] Google, Mountain View, CA 94043 USA.
   [Chen, Cheng] ByteDance, Beijing 100089, Peoples R China.
   [Wu, Ming] Conflux Fdn, Singapore 48619, Singapore.
   [Li, Wei] Beihang Univ, State Key Lab Software Dev Environm, Beijing 100083, Peoples R China.
RP Xiao, WC (corresponding author), Alibaba Grp, Hangzhou 311121, Peoples R China.
EM wencong.xwc@alibaba-inc.com; jxue@microsoft.com; yomia@microsoft.com;
   lizhenpi@gmail.com; chencheng.kit@bytedance.com; ming@conflux-chain.org;
   liwei@nlsde.buaa.edu.cn; lidongz@microsoft.com
OI Zhou, Lidong`/0000-0002-7258-3116
FU State Key Laboratory of Software Development Environment
   [SKLSDE-2017ZX-01]; NSF of ChinaNational Natural Science Foundation of
   China (NSFC) [61472009]
FX The authors would like to thank their NSDI'17 shepherd Adam Wierman and
   the anonymous reviewers of NSDI'17 and TPDS for their valuable comments
   and suggestions. They were grateful to their colleague Jay Lorch, who
   carefully went through the article and helped improve the quality of
   writing greatly. They would like to thank their colleague Zhenhua Han
   from the University of Hong Kong, who helped improve the writing quality
   of the journal verison. Wencong Xiao was supported by State Key
   Laboratory of Software Development Environment (Grand No.
   SKLSDE-2017ZX-01). Jilong Xue was partially supported by NSF of China
   (No. 61472009). A preliminary version of this work titled "TuX2:
   Distributed graph computation for machine learning" [1] was published in
   the 14th USENIX Symposium on Networked System Design and Implementation
   (NSDI 2017).
NR 82
TC 1
Z9 1
U1 5
U2 20
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1045-9219
EI 1558-2183
J9 IEEE T PARALL DISTR
JI IEEE Trans. Parallel Distrib. Syst.
PD JUL 1
PY 2020
VL 31
IS 7
BP 1588
EP 1604
DI 10.1109/TPDS.2020.2970047
PG 17
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LE2GW
UT WOS:000526542500004
DA 2022-04-17
ER

PT C
AU Doghri, T
   Szczecinski, L
   Benesty, J
   Mitiche, A
AF Doghri, Tayssir
   Szczecinski, Leszek
   Benesty, Jacob
   Mitiche, Amar
BE Farkas, I
   Masulli, P
   Wermter, S
TI Bilinear Models for Machine Learning
SO ARTIFICIAL NEURAL NETWORKS AND MACHINE LEARNING, ICANN 2020, PT I
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 29th International Conference on Artificial Neural Networks (ICANN)
CY SEP 15-18, 2020
CL Bratislava, SLOVAKIA
DE Classification; Bilinear forms; Machine learning
AB In this work we define and analyze the bilinear models which replace the conventional linear operation used in many building blocks of machine learning (ML). The main idea is to devise the ML algorithms which are adapted to the objects they treat. In the case of monochromatic images, we show that the bilinear operation exploits better the structure of the image than the conventional linear operation which ignores the spatial relationship between the pixels. This translates into significantly smaller number of parameters required to yield the same performance. We show numerical examples of classification in the MNIST data set.
C1 [Doghri, Tayssir; Szczecinski, Leszek; Benesty, Jacob; Mitiche, Amar] Inst Natl Rech Sci, 800 Gauchetiere Ouest,Suite 6900, Montreal, PQ H5A 1K6, Canada.
RP Doghri, T (corresponding author), Inst Natl Rech Sci, 800 Gauchetiere Ouest,Suite 6900, Montreal, PQ H5A 1K6, Canada.
EM tayssir.doghri@emt.inrs.ca; leszek@emt.inrs.ca; benesty@emt.inrs.ca;
   mitiche@emt.inrs.ca
NR 10
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-61609-0; 978-3-030-61608-3
J9 LECT NOTES COMPUT SC
PY 2020
VL 12396
BP 687
EP 698
DI 10.1007/978-3-030-61609-0_54
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods; Imaging Science &
   Photographic Technology
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Imaging Science & Photographic Technology
GA BS3OI
UT WOS:000713772700054
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Li, Q
   Fan, QL
   Han, QX
   Geng, WJ
   Zhao, HH
   Ding, XN
   Yan, JY
   Zhu, HY
AF Li Qi
   Fan Qiu-Ling
   Han Qiu-Xia
   Geng Wen-Jia
   Zhao Huan-Huan
   Ding Xiao-Nan
   Yan Jing-Yao
   Zhu Han-Yu
TI Machine learning in nephrology: scratching the surface
SO CHINESE MEDICAL JOURNAL
LA English
DT Review
DE Machine learning; Nephrology; Kidney diseases
ID ACUTE KIDNEY INJURY; DIFFERENTIAL DIAGNOSTIC MODEL; STAGE RENAL-DISEASE;
   ARTIFICIAL-INTELLIGENCE; DIABETIC-NEPHROPATHY; IGA NEPHROPATHY; RISK
   PREDICTION; RANDOM FOREST; ANEMIA MANAGEMENT; NEURAL-NETWORK
AB Machine learning shows enormous potential in facilitating decision-making regarding kidney diseases. With the development of data preservation and processing, as well as the advancement of machine learning algorithms, machine learning is expected to make remarkable breakthroughs in nephrology. Machine learning models have yielded many preliminaries to moderate and several excellent achievements in the fields, including analysis of renal pathological images, diagnosis and prognosis of chronic kidney diseases and acute kidney injury, as well as management of dialysis treatments. However, it is just scratching the surface of the field; at the same time, machine learning and its applications in renal diseases are facing a number of challenges. In this review, we discuss the application status, challenges and future prospects of machine learning in nephrology to help people further understand and improve the capacity for prediction, detection, and care quality in kidney diseases.
C1 [Li Qi; Han Qiu-Xia; Zhao Huan-Huan; Ding Xiao-Nan; Yan Jing-Yao; Zhu Han-Yu] Chinese Peoples Liberat Army Gen Hosp, Chinese Peoples Liberat Army Inst Nephrol, Natl Clin Res Ctr Kidney Dis,State Key Lab Kidney, Dept Nephrol,Beijing Key Lab Kidney Dis, Beijing 100853, Peoples R China.
   [Fan Qiu-Ling] China Med Univ, Affiliated Hosp 1, Dept Nephrol, Shenyang 110000, Liaoning, Peoples R China.
   [Geng Wen-Jia] Guangzhou Univ Chinese Med, Guangdong Prov Hosp Chinese Med, Guangdong Prov Hosp Chinese Med, Dept Nephrol,Nephrol Inst,Affiliated Hosp 1, Guangzhou 510120, Guangdong, Peoples R China.
RP Zhu, HY (corresponding author), Chinese Peoples Liberat Army Gen Hosp, Dept Nephrol, 28 Fuxing Rd, Beijing 100853, Peoples R China.
EM hanyuzhu301@126.com
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61971441, 61671479, 81804056]; National Key
   R&D Program of China [2016YFC1305500]
FX This work was supported by grants from the National Natural Science
   Foundation of China (Nos. 61971441, 61671479, and 81804056), and the
   National Key R&D Program of China (No. 2016YFC1305500).
NR 87
TC 4
Z9 4
U1 6
U2 13
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0366-6999
EI 2542-5641
J9 CHINESE MED J-PEKING
JI Chin. Med. J.
PD MAR 20
PY 2020
VL 133
IS 6
BP 687
EP 698
DI 10.1097/CM9.0000000000000694
PG 12
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA LE6RN
UT WOS:000526850800009
PM 32049747
OA gold, Green Published
DA 2022-04-17
ER

PT J
AU Lin, ZC
AF Lin, Zhou-Chen
TI How Can Machine Learning and Optimization Help Each Other Better?
SO JOURNAL OF THE OPERATIONS RESEARCH SOCIETY OF CHINA
LA English
DT Article
DE Optimization; Machine learning; Generalization ability; Data
AB Optimization is an indispensable part of machine learning as machine learning needs to solve mathematical models efficiently. On the other hand, machine learning can also provide new momenta and new ideas for optimization. This paper aims at investigating how to make the interactions between optimization and machine learning more effective.
C1 [Lin, Zhou-Chen] Peking Univ, Key Lab Machine Percept, Sch Elect Engn & Comp Sci, Beijing 100871, Peoples R China.
RP Lin, ZC (corresponding author), Peking Univ, Key Lab Machine Percept, Sch Elect Engn & Comp Sci, Beijing 100871, Peoples R China.
EM zlin@pku.edu.cn
NR 41
TC 0
Z9 0
U1 7
U2 20
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 2194-668X
EI 2194-6698
J9 J OPER RES SOC CHINA
JI J. Oper. Res. Soc. China
PD JUN
PY 2020
VL 8
IS 2
SI SI
BP 341
EP 351
DI 10.1007/s40305-019-00285-6
PG 11
WC Operations Research & Management Science
WE Emerging Sources Citation Index (ESCI)
SC Operations Research & Management Science
GA MD9PU
UT WOS:000544299100006
DA 2022-04-17
ER

PT J
AU Nikparvar, B
   Thill, JC
AF Nikparvar, Behnam
   Thill, Jean-Claude
TI Machine Learning of Spatial Data
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Review
DE spatial machine learning; spatial dependence; spatial heterogeneity;
   scale; spatial observation matrix; learning algorithm; deep learning
ID ARTIFICIAL NEURAL-NETWORKS; AREAL UNIT PROBLEM; IMAGE TEXTURE; TRAFFIC
   FLOW; LAND-COVER; CLASSIFICATION; HETEROGENEITY; PERFORMANCE;
   PREDICTION; MODELS
AB Properties of spatially explicit data are often ignored or inadequately handled in machine learning for spatial domains of application. At the same time, resources that would identify these properties and investigate their influence and methods to handle them in machine learning applications are lagging behind. In this survey of the literature, we seek to identify and discuss spatial properties of data that influence the performance of machine learning. We review some of the best practices in handling such properties in spatial domains and discuss their advantages and disadvantages. We recognize two broad strands in this literature. In the first, the properties of spatial data are developed in the spatial observation matrix without amending the substance of the learning algorithm; in the other, spatial data properties are handled in the learning algorithm itself. While the latter have been far less explored, we argue that they offer the most promising prospects for the future of spatial machine learning.
C1 [Nikparvar, Behnam] Univ N Carolina, Infrastruct & Environm Syst Program, 9201 Univ City Blvd, Charlotte, NC 28223 USA.
   [Thill, Jean-Claude] Univ N Carolina, Dept Geog & Earth Sci, 9201 Univ City Blvd, Charlotte, NC 28223 USA.
   [Thill, Jean-Claude] Univ N Carolina, Sch Data Sci, 9201 Univ City Blvd, Charlotte, NC 28223 USA.
RP Nikparvar, B (corresponding author), Univ N Carolina, Infrastruct & Environm Syst Program, 9201 Univ City Blvd, Charlotte, NC 28223 USA.
EM bnikparvar@gmail.com; jfthill@uncc.edu
OI nikparvar, behnam/0000-0002-7828-9356; Thill,
   Jean-Claude/0000-0002-6651-8123
NR 191
TC 2
Z9 2
U1 16
U2 18
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD SEP
PY 2021
VL 10
IS 9
AR 600
DI 10.3390/ijgi10090600
PG 32
WC Computer Science, Information Systems; Geography, Physical; Remote
   Sensing
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Physical Geography; Remote Sensing
GA UX2JK
UT WOS:000700671700001
OA gold
DA 2022-04-17
ER

PT J
AU Goodswen, SJ
   Barratt, JLN
   Kennedy, PJ
   Kaufer, A
   Calarco, L
   Ellis, JT
AF Goodswen, Stephen J.
   Barratt, Joel L. N.
   Kennedy, Paul J.
   Kaufer, Alexa
   Calarco, Larissa
   Ellis, John T.
TI Machine learning and applications in microbiology
SO FEMS MICROBIOLOGY REVIEWS
LA English
DT Review
DE machine learning; microbiology; supervised learning; unsupervised
   learning; classification; K-means clustering
ID MYCOBACTERIUM-TUBERCULOSIS; DIMENSIONALITY REDUCTION; CLASSIFICATION;
   PREDICTION; COMMUNITIES; VALIDATION; RESISTANCE; MALARIA; CHINA
AB To understand the intricacies of microorganisms at the molecular level requires making sense of copious volumes of data such that it may now be humanly impossible to detect insightful data patterns without an artificial intelligence application called machine learning. Applying machine learning to address biological problems is expected to grow at an unprecedented rate, yet it is perceived by the uninitiated as a mysterious and daunting entity entrusted to the domain of mathematicians and computer scientists. The aim of this review is to identify key points required to start the journey of becoming an effective machine learning practitioner. These key points are further reinforced with an evaluation of how machine learning has been applied so far in a broad scope of real-life microbiology examples. This includes predicting drug targets or vaccine candidates, diagnosing microorganisms causing infectious diseases, classifying drug resistance against antimicrobial medicines, predicting disease outbreaks and exploring microbial interactions. Our hope is to inspire microbiologists and other related researchers to join the emerging machine learning revolution.
C1 [Goodswen, Stephen J.; Kaufer, Alexa; Calarco, Larissa; Ellis, John T.] Univ Technol Sydney UTS, Sch Life Sci, 15 Broadway, Ultimo, NSW 2007, Australia.
   [Barratt, Joel L. N.] Ctr Dis Control & Prevent, Ctr Global Hlth, Div Parasit Dis & Malaria, Parasit Dis Branch, 1600 Clifton Rd, Atlanta, GA 30333 USA.
   [Kennedy, Paul J.] Univ Technol Sydney UTS, Fac Engn & Informat Technol, Sch Comp Sci, 15 Broadway, Ultimo, NSW 2007, Australia.
   [Kennedy, Paul J.] Univ Technol Sydney UTS, Australian Artificial Intelligence Inst, 15 Broadway, Ultimo, NSW 2007, Australia.
RP Ellis, JT (corresponding author), Univ Technol Sydney UTS, Sch Life Sci, 15 Broadway, Ultimo, NSW 2007, Australia.; Kennedy, PJ (corresponding author), Univ Technol Sydney UTS, Fac Engn & Informat Technol, Sch Comp Sci, 15 Broadway, Ultimo, NSW 2007, Australia.; Kennedy, PJ (corresponding author), Univ Technol Sydney UTS, Australian Artificial Intelligence Inst, 15 Broadway, Ultimo, NSW 2007, Australia.
EM Paul.Kennedy@uts.edu.au; john.t.ellis@alumni.uts.edu.au
RI ; Ellis, John/L-6988-2016; Kennedy, Paul/M-8450-2014
OI Goodswen, Stephen/0000-0001-6184-3157; Ellis, John/0000-0001-7328-4831;
   Barratt, Joel/0000-0001-8711-2408; Kennedy, Paul/0000-0001-7837-3171
NR 105
TC 3
Z9 3
U1 19
U2 24
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 0168-6445
EI 1574-6976
J9 FEMS MICROBIOL REV
JI Fems Microbiol. Rev.
PD SEP
PY 2021
VL 45
IS 5
AR fuab015
DI 10.1093/femsre/fuab015
EA MAR 2021
PG 19
WC Microbiology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Microbiology
GA WK1DV
UT WOS:000709474600010
PM 33724378
OA hybrid, Green Published
DA 2022-04-17
ER

PT J
AU Moscatelli, M
   Parlapiano, F
   Narizzano, S
   Viggiano, G
AF Moscatelli, Mirko
   Parlapiano, Fabio
   Narizzano, Simone
   Viggiano, Gianluca
TI Corporate default forecasting with machine learning
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Credit scoring; Machine learning; Random forest; Gradient boosting
   machine
ID CLASSIFICATION ALGORITHMS; CREDIT; MODELS
AB We analyze the performance of a set of machine learning models in predicting default risk, using standard statistical models, such as the logistic regression, as a benchmark. When only a limited information set is available, for example in the case of an external assessment of credit risk, we find that machine learning models provide substantial gains in discriminatory power and precision, relative to statistical models. This advantage diminishes when confidential information, such as credit behavioral indicators, is also available, and it becomes negligible when the dataset is small. Moreover, we evaluate the consequences of using a credit allocation rule based on machine learning ratings on the overall supply of credit and the number of borrowers gaining access to credit. Machine learning models concentrate a greater extent of credit towards safer and larger borrowers, which would result in lower credit losses for their lenders. (c) 2020 Elsevier Ltd. All rights reserved.
C1 [Moscatelli, Mirko; Parlapiano, Fabio] Bank Italy, Econ & Stat Dept, Via Nazl 91, I-00181 Rome, Italy.
   [Narizzano, Simone; Viggiano, Gianluca] Bank Italy, Markets & Payments Syst Dept, Via Nazl 91, I-00181 Rome, Italy.
RP Parlapiano, F (corresponding author), Bank Italy, Econ & Stat Dept, Via Nazl 91, I-00181 Rome, Italy.
EM mirko.moscatelli@bancaditalia.it; fabio.parlapiano@bancaditalia.it;
   simone.narizzano@bancaditalia.it; gianluca.viggiano@bancaditalia.it
NR 25
TC 18
Z9 18
U1 15
U2 56
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD DEC 15
PY 2020
VL 161
AR 113567
DI 10.1016/j.eswa.2020.113567
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Operations Research & Management Science
GA NZ0LD
UT WOS:000576782300009
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Lu, L
   Kurfess, T
   Saldana, C
AF Lu, Lance
   Kurfess, Thomas
   Saldana, Christopher
TI Effects of Extrinsic Noise Factors on Machine Learning-Based Chatter
   Detection in Machining
SO SMART AND SUSTAINABLE MANUFACTURING SYSTEMS
LA English
DT Article
DE machining; machine learning; chatter
ID SIGNALS; TOOL; SUPPRESSION; SYSTEM; WEAR
AB Unmitigated chatter can result in poor part quality, accelerated tool wear, and possible damage to spindle and machine. While various methods have been shown to effectively detect chatter, implementation of these methods in noisy environments, such as factory floors, has not been well studied. The present study seeks to explore the effects of extrinsic noise sources on threshold-based and machine learning-based chatter detection methods using audio signals of the machining process. To accomplish this, stable and unstable cuts were made on a milling machine and the audio signal was collected. Data augmentation using Gaussian white noise and periodic noise was conducted to simulate a range of noise levels and types. The performance of these techniques were then compared with respect to the increasing levels of noise. It was found that machine learning-based approaches achieved satisfactory accuracies up to 98.6 % under the presence of extrinsic noise. Conventional static threshold techniques, however, failed under most noise conditions and resulted in false positives depending on the threshold values used. Furthermore, support vector machine approaches demonstrated an ability to classify noisy data despite limited training.
C1 [Lu, Lance; Kurfess, Thomas; Saldana, Christopher] Georgia Inst Technol, George W Woodruff Sch Mech Engn, 801 Ferst Dr, Atlanta, GA 30332 USA.
RP Saldana, C (corresponding author), Georgia Inst Technol, George W Woodruff Sch Mech Engn, 801 Ferst Dr, Atlanta, GA 30332 USA.
EM christopher.saldana@me.gatech.edu
FU National Science Foundation (NSF) Civil, Mechanical and Manufacturing
   Innovation (CMMI)National Science Foundation (NSF)NSF - Directorate for
   Engineering (ENG) [DE-EE0008303];  [CMMI-1646013];  [CMMI-1825640]; 
   [IIP-1631803]
FX This work was supported in part by DE-EE0008303 and the National Science
   Foundation (NSF) Civil, Mechanical and Manufacturing Innovation (CMMI).
   This work was also partially supported by NSF CMMI-1646013,
   CMMI-1825640, and IIP-1631803.
NR 27
TC 0
Z9 0
U1 4
U2 4
PU AMER SOC TESTING MATERIALS
PI W CONSHOHOCKEN
PA 100 BARR HARBOR DR, W CONSHOHOCKEN, PA 19428-2959 USA
SN 2520-6478
EI 2572-3928
J9 SMART SUSTAIN MANUF
JI Smart Sustain. Manuf. Syst.
PY 2021
VL 5
IS 1
BP 167
EP 180
DI 10.1520/SSMS20210007
PG 14
WC Engineering, Manufacturing
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA UA5OS
UT WOS:000685211800001
DA 2022-04-17
ER

PT J
AU Caramiaux, B
   Francoise, J
   Liu, WY
   Sanchez, T
   Bevilacqua, F
AF Caramiaux, Baptiste
   Francoise, Jules
   Liu, Wanyu
   Sanchez, Teo
   Bevilacqua, Frederic
TI Machine Learning Approaches for Motor Learning: A Short Review
SO FRONTIERS IN COMPUTER SCIENCE
LA English
DT Review
DE movement; computational modeling; machine learning; motor control; motor
   learning
ID TASK; VARIABILITY; DYNAMICS
AB Machine learning approaches have seen a considerable number of applications in human movement modeling but remain limited for motor learning. Motor learning requires that motor variability be taken into account and poses new challenges because the algorithms need to be able to differentiate between new movements and variation in known ones. In this short review, we outline existing machine learning models for motor learning and their adaptation capabilities. We identify and describe three types of adaptation: Parameter adaptation in probabilistic models, Transfer and meta-learning in deep neural networks, and Planning adaptation by reinforcement learning. To conclude, we discuss challenges for applying these models in the domain of motor learning support systems.
C1 [Caramiaux, Baptiste; Liu, Wanyu; Sanchez, Teo] Univ Paris Saclay, CNRS, INRIA, LRI, Gif Sur Yvette, France.
   [Francoise, Jules] Univ Paris Saclay, CNRS, LIMSI, Orsay, France.
   [Liu, Wanyu; Bevilacqua, Frederic] Sorbonne Univ, CNRS, STMS IRCAM, Paris, France.
RP Caramiaux, B (corresponding author), Univ Paris Saclay, CNRS, INRIA, LRI, Gif Sur Yvette, France.
EM baptiste.caramiaux@lri.fr
FU French National Research AgencyFrench National Research Agency (ANR)
   [ANR-18-CE33-0002, ANR-19-CE33-0001]
FX This research was supported by the ELEMENT project (ANR-18-CE33-0002)
   and the ARCOL project (ANR-19-CE33-0001) from the French National
   Research Agency.
NR 65
TC 2
Z9 2
U1 4
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2624-9898
J9 FRONT COMP SCI-SWITZ
JI Front. Comput. Sci.-Switz
PD MAY 29
PY 2020
VL 2
AR 16
DI 10.3389/fcomp.2020.00016
PG 7
WC Computer Science, Interdisciplinary Applications
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA WE9MA
UT WOS:000705940500001
OA gold, Green Submitted
DA 2022-04-17
ER

PT J
AU Pereira, FS
AF Pereira, Fernando Silva
TI Machine Learning Evidence
SO RED-REVISTA ELECTRONICA DE DIREITO
LA Portuguese
DT Article
DE Artificial Intelligence; Machine Learning Evidence; Evidence; Civil
   Procedure Law
AB Machine learning is a field of artificial intelligence that gives computers the ability to learn without being explicitly programmed, posing the problem of using the outputs of deep learning software as evidence in a judicial process. Focusing on Civil Procedure Law, this article aims to reflect on this problem, from the point of view of the admissibility and weight of such an evidence, giving close attention to the north-American experience, where the problem of the use of scientific and technic evidence has been largely discussed.
C1 [Pereira, Fernando Silva] Univ Porto, Fac Direito, Rua Bragas 223, P-4050123 Porto, Portugal.
   [Pereira, Fernando Silva] CIJE, Rua Bragas 223, P-4050123 Porto, Portugal.
RP Pereira, FS (corresponding author), Univ Porto, Fac Direito, Rua Bragas 223, P-4050123 Porto, Portugal.; Pereira, FS (corresponding author), CIJE, Rua Bragas 223, P-4050123 Porto, Portugal.
EM fpereira@direito.up.pt
NR 26
TC 0
Z9 0
U1 1
U2 3
PU CENTRO INVESTIGACAO JURIDICO-ECONOMICA-CIJE
PI PORTO
PA FAC LAW UNIV PORTO, RUA BRAGAS, 223-TORREAO POENTE, OFF 325, PORTO,
   4050-123, PORTUGAL
SN 2182-9845
J9 RED-REV ELECTRON DIR
JI RED-Rev. Electron. Dir.
PD OCT
PY 2020
VL 23
IS 3
BP 79
EP 98
DI 10.24840/2182-9845_2020-0003_0006
PG 20
WC Law
WE Emerging Sources Citation Index (ESCI)
SC Government & Law
GA PX4VG
UT WOS:000611353500006
OA Bronze
DA 2022-04-17
ER

PT J
AU Rudin, C
   Chen, CF
   Chen, Z
   Huang, HY
   Semenova, L
   Zhong, CD
AF Rudin, Cynthia
   Chen, Chaofan
   Chen, Zhi
   Huang, Haiyang
   Semenova, Lesia
   Zhong, Chudi
TI Interpretable machine learning: Fundamental principles and 10 grand
   challenges
SO STATISTICS SURVEYS
LA English
DT Article
DE Interpretable machine learning; explainable machine learning
ID DEEP NEURAL-NETWORKS; FUNCTION APPROXIMATION; HOSPITAL MORTALITY; ACUTE
   PHYSIOLOGY; CHEST-PAIN; RISK SCORE; CLASSIFICATION; MODELS; MARGIN;
   RULES
AB Interpretability in machine learning (ML) is crucial for high stakes decisions and troubleshooting. In this work, we provide fundamental principles for interpretable ML, and dispel common misunderstandings that dilute the importance of this crucial topic. We also identify 10 technical challenge areas in interpretable machine learning and provide history and background on each problem. Some of these problems are classically important, and some are recent problems that have arisen in the last few years. These problems are: (1) Optimizing sparse logical models such as decision trees; (2) Optimization of scoring systems; (3) Placing constraints into generalized additive models to encourage sparsity and better interpretability; (4) Modern case-based reasoning, including neural networks and matching for causal inference; (5) Complete supervised disentanglement of neural networks; (6) Complete or even partial unsupervised disentanglement of neural networks; (7) Dimensionality reduction for data visualization; (8) Machine learning models that can incorporate physics and other generative or causal constraints; (9) Characterization of the "Rashomon set" of good models; and (10) Interpretable reinforcement learning. This survey is suitable as a starting point for statisticians and computer scientists interested in working in interpretable machine learning.
EM cynthia@cs.duke.edu; chaofan.chen@maine.edu; zhi.chen1@duke.edu;
   haiyang.huane@duke.edu; lesia.semenova@duke.edu; chudi.zhong@duke.edu
FU DOEUnited States Department of Energy (DOE) [DE-SC0021358]; NSFNational
   Science Foundation (NSF) [DGE-2022040, CCF-1934964]; NIDAUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Drug Abuse (NIDA) [DA054994-01]
FX Partial support provided by grants DOE DE-SC0021358, NSF DGE-2022040,
   NSF CCF-1934964, and NIDA DA054994-01.
NR 341
TC 1
Z9 1
U1 12
U2 12
PU AMER STATISTICAL ASSOC
PI ALEXANDRIA
PA 732 N WASHINGTON ST, ALEXANDRIA, VA 22314-1943 USA
SN 1935-7516
J9 STAT SURV
JI Statist. Surv.
PY 2022
VL 16
BP 1
EP 85
DI 10.1214/21-SS133
PG 85
WC Statistics & Probability
WE Emerging Sources Citation Index (ESCI)
SC Mathematics
GA YH6AY
UT WOS:000743249300001
OA gold, Green Submitted
DA 2022-04-17
ER

PT C
AU Kwon, J
   Jung, D
   Park, H
AF Kwon, Jungmin
   Jung, Daeun
   Park, Hyunggon
GP IEEE
TI Traffic Data Classification using Machine Learning Algorithms in SDN
   Networks
SO 11TH INTERNATIONAL CONFERENCE ON ICT CONVERGENCE: DATA, NETWORK, AND AI
   IN THE AGE OF UNTACT (ICTC 2020)
SE International Conference on Information and Communication Technology
   Convergence
LA English
DT Proceedings Paper
CT 11th International Conference on Information and Communication
   Technology Convergence (ICTC) - Data, Network, and AI in the age of
   Untact (ICTC)
CY OCT 21-23, 2020
CL Jeju, SOUTH KOREA
SP Korean Inst Commun & Informat Sci, IEEE Commun Soc, IEICE Commun Soc, Minist Sci & ICT, Elect & Telecommunicat Res Inst, Korean Federat Sci & Technol Soc, Samsung Elect, LG Elect, SK Telecom, LGU+, KT, SOLiD, FRTek, Huawei, Ericsson LG, ICT Convergence Korea Forum, Soc Safety Syst Forum, 5G Based Smart Factory Standardizat Forum, Jeju Convent & Visitors Bur, Korea Assoc Photon Ind Dev
DE Machine learning; supervised learning; automatic network data
   classification; ONOS
ID SYSTEM
AB As an efficient approach to proactively monitoring network dynamics, automatically analyzing network data, and predicting network usage, machine learning has been widely deployed. This enables the networks to be efficiently and autonomously coped with in SDN/NFV environment. In particular, network intelligent technology can be adopted into the infrastructure management, network operations, and service assurance. In this paper, we study the automatic network data classification based on machine learning, where several machine learning algorithms are deployed to automatically classify real network traffic data collected from ONOS (Open Network Operating System) platform. From the experiment results with simple network topology, we conclude that machine learning algorithms can effectively classify the network traffic data. However, it is also observed machine algorithms may only show a limited performance in practice if they are blindly deployed. This is because there exists not only the data that needs to be delivered to the receivers but also the data required for network maintenance in a real network system. Therefore, it is essential to develop machine learning algorithms that explicitly consider the characteristics of real network traffic data in target network scenarios.
C1 [Kwon, Jungmin; Jung, Daeun; Park, Hyunggon] Ewha Womans Univ, Dept Elect & Elect Engn, Seoul, South Korea.
   [Jung, Daeun; Park, Hyunggon] Ewha Womans Univ, Smart Factory Multidisciplinary Program, Seoul, South Korea.
   [Park, Hyunggon] Alan Turing Inst, London, England.
RP Kwon, J (corresponding author), Ewha Womans Univ, Dept Elect & Elect Engn, Seoul, South Korea.
EM jungmin.kwon@ewhain.net; daeun.jung@ewhain.net; hyunggon.park@ewha.ac.kr
FU Institute of Information & communications Technology Planning &
   Evaluation (IITP) - Korea government (MSIT) [2019-0-00024]; National
   Research Foundation of Korea (NRF) - Korea government (MSIT)
   [NRF2020R1A2B5B01002528]
FX This work was supported by Institute of Information & communications
   Technology Planning & Evaluation (IITP) grant funded by the Korea
   government (MSIT) (No. 2019-0-00024, Supervised Agile Machine Learning
   Techniques for Network Automation based on Network Data Analytics
   Function) and supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT) (No.
   NRF2020R1A2B5B01002528).
NR 20
TC 0
Z9 0
U1 0
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2162-1233
BN 978-1-7281-6758-9
J9 I C INF COMM TECH CO
PY 2020
BP 1031
EP 1033
PG 3
WC Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering
GA BS1LP
UT WOS:000692529100247
DA 2022-04-17
ER

PT S
AU Chen, IY
   Joshi, S
   Ghassemi, M
   Ranganath, R
AF Chen, Irene Y.
   Joshi, Shalmali
   Ghassemi, Marzyeh
   Ranganath, Rajesh
BE Altman, RB
TI Probabilistic Machine Learning for Healthcare
SO ANNUAL REVIEW OF BIOMEDICAL DATA SCIENCE, VOL 4
SE Annual Review of Biomedical Data Science
LA English
DT Article; Book Chapter
DE probabilistic modeling; health; electronic health records; machine
   learning; artificial intelligence
ID PREDICTION; PHENOTYPES; INFERENCE; SURVIVAL; DISEASE; SYSTEMS; ASTHMA;
   BIAS
AB Machine learning can be used to make sense of healthcare data. Probabilistic machine learning models help provide a complete picture of observed data in healthcare. In this review, we examine how probabilistic machine learning can advance healthcare. We consider challenges in the predictive model building pipeline where probabilistic models can be beneficial, including calibration and missing data. Beyond predictive models, we also investigate the utility of probabilistic machine learning models in phenotyping, in generative models for clinical use cases, and in reinforcement learning.
C1 [Chen, Irene Y.] MIT, Dept Elect Engn & Comp Sci, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   [Joshi, Shalmali; Ghassemi, Marzyeh] Vector Inst, Toronto, ON M5G 1M1, Canada.
   [Ghassemi, Marzyeh] MIT, Inst Med & Evaluat Sci, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   [Ranganath, Rajesh] NYU, Courant Inst, Dept Comp Sci, 550 1St Ave, New York, NY 10012 USA.
   [Ranganath, Rajesh] NYU, Ctr Data Sci, 550 1St Ave, New York, NY 10012 USA.
   [Ranganath, Rajesh] NYU, Grossman Sch Med, Dept Populat Hlth, New York, NY 10016 USA.
RP Chen, IY (corresponding author), MIT, Dept Elect Engn & Comp Sci, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
EM iychen@mit.edu; shalmali@vectorinstitute.ai
FU CIFAR (Canadian Institute for Advanced Research) AI Chair at the Vector
   Institute; Microsoft Research grant; NIH/NHLBI award [R01 HL148248]
FX The authors thank Noemie Elhadad, Rahul G. Krishnan, Peter Schulam,
   Peter Szolovits, and Wouter van Amsterdam for helpful and useful
   feedback. This work was supported in part by a CIFAR (Canadian Institute
   for Advanced Research) AI Chair at the Vector Institute (to M.G.), a
   Microsoft Research grant (to M.G.), and NIH/NHLBI award R01 HL148248 (to
   R.R.).
NR 137
TC 0
Z9 0
U1 24
U2 29
PU ANNUAL REVIEWS
PI PALO ALTO
PA 4139 EL CAMINO WAY, PO BOX 10139, PALO ALTO, CA 94303-0897 USA
SN 2574-3414
J9 ANNU REV BIOMED DA S
JI Annu. Rev. Biomed. Data Sci.
PY 2021
VL 4
BP 393
EP 415
DI 10.1146/annurev-biodatasci-092820-033938
PG 23
WC Biochemical Research Methods; Mathematical & Computational Biology
WE Emerging Sources Citation Index (ESCI); Book Citation Index – Science (BKCI-S)
SC Biochemistry & Molecular Biology; Mathematical & Computational Biology
GA BR9LO
UT WOS:000677831600018
PM 34465179
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Makhmet, AS
   Sharaev, MG
   Dyusembaev, AE
   Kustubayeva, AM
AF Makhmet, A. S.
   Sharaev, M. G.
   Dyusembaev, A. E.
   Kustubayeva, A. M.
TI Machine learning for brain signal analysis
SO INTERNATIONAL JOURNAL OF BIOLOGY AND CHEMISTRY
LA English
DT Article
DE EEG; fMRI; machine learning; MVPA; brain signal analysis
ID FMRI DATA; DEPRESSION
AB Machine learning (ML) is an effective tool for analysing signals from the human brain. Machine Learning techniques provide new insight into the understanding of brain function in healthy subjects and patients with neurological and mental disorders. Here we introduce the application of machine learning to resonance imaging (fMRI) and Electroencephalography (EEG). The article provides a brief overview of the theoretical concept of machine learning and its types: supervised, unsupervised and reinforcement learning. The potential of machine learning applications in pathology is discussed. Differences between EEG and fMRI methods regarding machine learning application and an overview of the techniques employed in different research studies are reviewed. The new machine learning methods invented for analysis of brain signals in the resting ate and during the performance of the different cognitive tasks would be useful and worth considering in other domains, not limited to medicine.
C1 [Makhmet, A. S.; Dyusembaev, A. E.; Kustubayeva, A. M.] Al Farabi Kazakh Natl Univ, Alma Ata, Kazakhstan.
   [Sharaev, M. G.] Skolkovo Inst Sci & Technol, Moscow, Russia.
RP Kustubayeva, AM (corresponding author), Al Farabi Kazakh Natl Univ, Alma Ata, Kazakhstan.
EM almkuo@kaznu.kz
OI Makhmet, Ainur/0000-0002-5423-3550
FU Ministry of Education and Science of KazakhstanGovernment of the
   Republic of KazakhstanMinistry of Education and Science of the Republic
   of Kazakhstan [AP08856595]; RFBRRussian Foundation for Basic Research
   (RFBR) [18-29-01032]
FX Research was supported by research grant from Ministry of Education and
   Science of Kazakhstan to A.M. Kustubayeva (AP08856595 "EEG/MRI study of
   brain development, emotional-cognitive functions, and genetic markers in
   different age groups").; M.G. Sharaev was supported by RFBR, research
   project 18-29-01032.
NR 34
TC 0
Z9 0
U1 0
U2 0
PU AL-FARABI KAZAKH NATL UNIV
PI BAKU
PA INST APPL MATH, BAKU STATE U, Z KHALILOV, 23, BAKU, AZ1148, AZERBAIJAN
SN 2218-7979
EI 2409-370X
J9 INT J BIOL CHEM-KAZ
JI Int. J. Biol. Chem.
PY 2021
VL 14
IS 2
BP 4
EP 11
DI 10.26577/ijbch.2021.v14.i2.01
PG 8
WC Biology
WE Emerging Sources Citation Index (ESCI)
SC Life Sciences & Biomedicine - Other Topics
GA YU7PP
UT WOS:000752230700001
OA gold
DA 2022-04-17
ER

PT J
AU Ma, ZJ
   Mei, G
   Piccialli, F
AF Ma, Zhengjing
   Mei, Gang
   Piccialli, Francesco
TI Machine learning for landslides prevention: a survey
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Review
DE Natural disasters; Landslides prevention; Machine learning; Supervised
   learning; Unsupervised learning; Deep learning
ID ARTIFICIAL NEURAL-NETWORKS; SUPPORT VECTOR MACHINES; OBJECT-ORIENTED
   ANALYSIS; LOGISTIC MODEL TREE; 3 GORGES RESERVOIR; DECISION-TREE; RANDOM
   FOREST; SUSCEPTIBILITY ASSESSMENT; RAINFALL THRESHOLD; IMAGE-ANALYSIS
AB Landslides are one of the most critical categories of natural disasters worldwide and induce severely destructive outcomes to human life and the overall economic system. To reduce its negative effects, landslides prevention has become an urgent task, which includes investigating landslide-related information and predicting potential landslides. Machine learning is a state-of-the-art analytics tool that has been widely used in landslides prevention. This paper presents a comprehensive survey of relevant research on machine learning applied in landslides prevention, mainly focusing on (1) landslides detection based on images, (2) landslides susceptibility assessment, and (3) the development of landslide warning systems. Moreover, this paper discusses the current challenges and potential opportunities in the application of machine learning algorithms for landslides prevention.
C1 [Ma, Zhengjing; Mei, Gang] China Univ Geosci Beijing, Sch Engn & Technol, Beijing 100083, Peoples R China.
   [Piccialli, Francesco] Univ Naples Federico II, Dept Math & Applicat R Caccioppoli, Naples, Italy.
RP Mei, G (corresponding author), China Univ Geosci Beijing, Sch Engn & Technol, Beijing 100083, Peoples R China.; Piccialli, F (corresponding author), Univ Naples Federico II, Dept Math & Applicat R Caccioppoli, Naples, Italy.
EM gang.mei@cugb.edu.cn; francesco.piccialli@unina.it
RI Mei, Gang/C-9124-2016
OI Mei, Gang/0000-0003-0026-5423
FU Universita degli Studi di Napoli Federico II within the CRUI-CARE
   Agreement
FX Open access funding provided by Universita degli Studi di Napoli
   Federico II within the CRUI-CARE Agreement.
NR 193
TC 12
Z9 12
U1 37
U2 73
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD SEP
PY 2021
VL 33
IS 17
SI SI
BP 10881
EP 10907
DI 10.1007/s00521-020-05529-8
EA NOV 2020
PG 27
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TZ1GX
UT WOS:000591283600001
OA Green Submitted, hybrid
DA 2022-04-17
ER

PT J
AU Wang, X
   Yang, LM
AF Wang, Xue
   Yang, Liming
TI Laplacian Generalized Eigenvalues Extreme Learning Machine
SO NEURAL PROCESSING LETTERS
LA English
DT Article
DE Extreme learning machine; Semi-supervised classification; Generalized
   eigenvalues; Laplacian learning
ID SUPPORT VECTOR MACHINE; CLASSIFICATION; SPARSE; ROBUST
AB Semi-supervised learning is an attractive technique for using unlabeled data in classification. In this work, an efficient semi-supervised extreme learning machine (ELM) classification framework is proposed by introducing the Laplacian regularization term. It tries to build two nonparallel hyperplanes such that each hyperplane is closer to one of the two classes and farther away from the other class in ELM feature space, based on which, two new semi-supervised ELM classification algorithms are proposed. First, we formulate semi-supervised ELM as a ratio form, and reformulate it as a generalized eigenvalue problem (called Laplacian generalized eigenvalue extreme learning machine, LapGELM) to solve simply. Then we replace the form of ratio with a form of difference so that the optimization problems can be transformed into a standard eigenvalue problem (called Laplacian standard eigenvalue ELM, LapSELM) to control overfit and solve quickly. Furthermore, the proposed algorithms are implemented on various datasets with different sizes and structures. Compared with traditional methods, experiment results show the feasibility and effectiveness of the proposed algorithms due to their simplicity, rapidity, and good generalization performance.
C1 [Wang, Xue] China Agr Univ, Coll Informat & Elect Engn, Beijing 100083, Peoples R China.
   [Yang, Liming] China Agr Univ, Coll Sci, Beijing 100083, Peoples R China.
RP Yang, LM (corresponding author), China Agr Univ, Coll Sci, Beijing 100083, Peoples R China.
EM cauyanglm@163.com
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [11471010]; Chinese Universities Scientific
   Fund
FX This work was supported in part by National Natural Science Foundation
   of China (No. 11471010) and Chinese Universities Scientific Fund.
NR 28
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1370-4621
EI 1573-773X
J9 NEURAL PROCESS LETT
JI Neural Process. Lett.
PD FEB
PY 2022
VL 54
IS 1
BP 467
EP 499
DI 10.1007/s11063-021-10640-5
EA OCT 2021
PG 33
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZI1MS
UT WOS:000703828600001
DA 2022-04-17
ER

PT J
AU Rahmani, AM
   Yousefpoor, E
   Yousefpoor, MS
   Mehmood, Z
   Haider, A
   Hosseinzadeh, M
   Naqvi, RA
AF Rahmani, Amir Masoud
   Yousefpoor, Efat
   Yousefpoor, Mohammad Sadegh
   Mehmood, Zahid
   Haider, Amir
   Hosseinzadeh, Mehdi
   Ali Naqvi, Rizwan
TI Machine Learning (ML) in Medicine: Review, Applications, and Challenges
SO MATHEMATICS
LA English
DT Review
DE artificial intelligence (AI); machine learning (ML); diagnosis;
   treatment; medicine
ID ARTIFICIAL-INTELLIGENCE; DECISION-SUPPORT; FUZZY-LOGIC; DIAGNOSIS;
   ALGORITHMS; NETWORKS; CLASSIFICATION; PRINCIPLES; PREDICTION; SELECTION
AB Today, artificial intelligence (AI) and machine learning (ML) have dramatically advanced in various industries, especially medicine. AI describes computational programs that mimic and simulate human intelligence, for example, a person's behavior in solving problems or his ability for learning. Furthermore, ML is a subset of artificial intelligence. It extracts patterns from raw data automatically. The purpose of this paper is to help researchers gain a proper understanding of machine learning and its applications in healthcare. In this paper, we first present a classification of machine learning-based schemes in healthcare. According to our proposed taxonomy, machine learning-based schemes in healthcare are categorized based on data pre-processing methods (data cleaning methods, data reduction methods), learning methods (unsupervised learning, supervised learning, semi-supervised learning, and reinforcement learning), evaluation methods (simulation-based evaluation and practical implementation-based evaluation in real environment) and applications (diagnosis, treatment). According to our proposed classification, we review some studies presented in machine learning applications for healthcare. We believe that this review paper helps researchers to familiarize themselves with the newest research on ML applications in medicine, recognize their challenges and limitations in this area, and identify future research directions.
C1 [Rahmani, Amir Masoud] Natl Yunlin Univ Sci & Technol, Future Technol Res Ctr, Touliu 64002, Taiwan.
   [Yousefpoor, Efat; Yousefpoor, Mohammad Sadegh] Islamic Azad Univ, Dept Comp Engn, Dezful Branch, Dezful 73210, Iran.
   [Mehmood, Zahid] Univ Engn & Technol, Dept Comp Engn, Taxila 47050, Pakistan.
   [Haider, Amir; Ali Naqvi, Rizwan] Sejong Univ, Sch Intelligent Mechatron Engn, 209 Neungdong Ro, Seoul 05006, South Korea.
   [Hosseinzadeh, Mehdi] Gachon Univ, Pattern Recognit & Machine Learning Lab, 1342 Seongnamdaero, Seongnam 13120, South Korea.
RP Naqvi, RA (corresponding author), Sejong Univ, Sch Intelligent Mechatron Engn, 209 Neungdong Ro, Seoul 05006, South Korea.; Hosseinzadeh, M (corresponding author), Gachon Univ, Pattern Recognit & Machine Learning Lab, 1342 Seongnamdaero, Seongnam 13120, South Korea.
EM rahmania@yuntech.edu.tw; eyousefpoor@iaud.ac.ir;
   ms.yousefpoor@iaud.ac.ir; zahid.mehmood@uettaxila.edu.pk;
   amirhaider@sejong.ac.kr; mehdi@gachon.ac.kr; rizwanali@sejong.ac.kr
OI Naqvi, Rizwan Ali/0000-0002-7473-8441; Mehmood, Dr.
   Zahid/0000-0003-4888-2594; , mehdi/0000-0003-1088-4551; Haider,
   Amir/0000-0002-1534-061X
NR 150
TC 1
Z9 1
U1 26
U2 26
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2227-7390
J9 MATHEMATICS-BASEL
JI Mathematics
PD NOV
PY 2021
VL 9
IS 22
AR 2970
DI 10.3390/math9222970
PG 52
WC Mathematics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Mathematics
GA XF2MO
UT WOS:000723910100001
OA gold
DA 2022-04-17
ER

PT J
AU Chen, YY
   Wang, X
   Du, XH
AF Chen, Yuanyuan
   Wang, Xuan
   Du, Xiaohui
TI Diagnostic evaluation model of English learning based on machine
   learning
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Machine learning; English learning; diagnosis; evaluation model
AB The diagnostic evaluation model of English learning is difficult to judge the subjective factors in student learning, so some diagnostic evaluation models of English learning are difficult to apply to English learning practice. In order to improve the effect of English learning, based on machine learning technology, this study combines the needs of English evaluation to build a diagnostic evaluation model of English learning based on machine learning. Moreover, this study compares the methods of random forest, Bayesian network, decision tree, perceptron, K-nearest neighbor and multi-model fusion, and selects the best algorithm for diagnostic analysis. The diagnostic evaluation model of English studies constructed in this paper mainly evaluates and judges the errors in students' English learning. In addition, this study validates the methods proposed in this study through controlled experiments. The research results show that the method proposed in this study has a certain effect.
C1 [Chen, Yuanyuan; Wang, Xuan] Hebei GEO Univ, Huaxin Coll, Shijiazhuang, Hebei, Peoples R China.
   [Du, Xiaohui] Hebei Normal Univ, Coll Presch Educ, Dept Tourism, Shijiazhuang, Hebei, Peoples R China.
RP Du, XH (corresponding author), Hebei Normal Univ, Shijiazhuang, Hebei, Peoples R China.
EM chenyuanyuan09@sina.com
NR 24
TC 2
Z9 2
U1 14
U2 14
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PY 2021
VL 40
IS 2
BP 2169
EP 2179
DI 10.3233/JIFS-189216
PG 11
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QH1ZP
UT WOS:000618076700038
DA 2022-04-17
ER

PT J
AU Waldow, F
   Schnaubelt, M
   Krauss, C
   Fischer, TG
AF Waldow, Fabian
   Schnaubelt, Matthias
   Krauss, Christopher
   Fischer, Thomas Gunter
TI Machine Learning in Futures Markets
SO JOURNAL OF RISK AND FINANCIAL MANAGEMENT
LA English
DT Article
DE statistical arbitrage; futures markets; machine learning
ID STATISTICAL ARBITRAGE; NEURAL-NETWORKS
AB In this paper, we demonstrate how a well-established machine learning-based statistical arbitrage strategy can be successfully transferred from equity to futures markets. First, we preprocess futures time series comprised of front months to render them suitable for our returns-based trading framework and compile a data set comprised of 60 futures covering nearly 10 trading years. Next, we train several machine learning models to predict whether the h-day-ahead return of each future out- or underperforms the corresponding cross-sectional median return. Finally, we enter long/short positions for the top/flop-k futures for a duration of h days and assess the financial performance of the resulting portfolio in an out-of-sample testing period. Thereby, we find the machine learning models to yield statistically significant out-of-sample break-even transaction costs of 6.3 bp-a clear challenge to the semi-strong form of market efficiency. Finally, we discuss sources of profitability and the robustness of our findings.
C1 [Waldow, Fabian; Schnaubelt, Matthias; Krauss, Christopher; Fischer, Thomas Gunter] Univ Erlangen Nurnberg, Dept Stat & Econometr, D-90403 Nurnberg, Germany.
RP Waldow, F (corresponding author), Univ Erlangen Nurnberg, Dept Stat & Econometr, D-90403 Nurnberg, Germany.
EM fabian.waldow@fau.de; matthias.schnaubelt@fau.de;
   christopher.krauss@fau.de; thomas.g.fischer@fau.de
NR 40
TC 0
Z9 0
U1 5
U2 11
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 1911-8066
EI 1911-8074
J9 J RISK FINANC MANAG
JI J. Risk Financ. Manag.
PD MAR
PY 2021
VL 14
IS 3
AR 119
DI 10.3390/jrfm14030119
PG 14
WC Business, Finance
WE Emerging Sources Citation Index (ESCI)
SC Business & Economics
GA RG0TF
UT WOS:000635248100001
OA gold, Green Published
DA 2022-04-17
ER

PT J
AU Zhang, L
   He, M
   Shao, SF
AF Zhang, Lei
   He, Mu
   Shao, Shaofeng
TI Machine learning for halide perovskite materials
SO NANO ENERGY
LA English
DT Article
DE Halide perovskites; Machine learning; Solar cells
ID LATTICE-CONSTANT PREDICTION; SOLAR-CELLS; LEAD-FREE; HYDROGEN EVOLUTION;
   CHARGE ESTIMATION; HIGHLY EFFICIENT; NEURAL-NETWORKS; STABILITY; STATE;
   BATTERIES
AB Halide perovskite materials serve as excellent candidates for solar cell and optoelectronic devices. Recently, the design of the halide perovskite materials is greatly facilitated by machine learning techniques, which effectively identify suitable halide perovskite candidates and unveil hidden relationships by algorithms that mimic the human cognitive functions. In this manuscript, we review recent progresses on the machine learning studies of the halide perovskite materials, including the prediction and understanding of lead-free and stable halide perovskite materials. The structural descriptors to describe the property and performance of the halide perovskite materials are discussed. In addition, the design strategy of the additive species for the halide perovskite materials via the machine learning technique is provided. Suggestions to further develop the halide perovskite-based systems via the machine learning methods in the future are provided.
C1 [Zhang, Lei; He, Mu; Shao, Shaofeng] Nanjing Univ Informat Sci & Technol, Sch Chem & Mat Sci, Nanjing 210044, Peoples R China.
   [Zhang, Lei] Shanghai Ximi Informat Technol Co Ltd, Shanghai 200001, Peoples R China.
RP Zhang, L (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Chem & Mat Sci, Nanjing 210044, Peoples R China.
EM 002699@nuist.edu.cn
RI Zhang, Lei/U-4622-2019
OI Zhang, Lei/0000-0001-6873-7314
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [51702165]
FX This work was supported by the National Natural Science Foundation of
   China (No. 51702165). The authors acknowledge computational support from
   NSCCSZ Shenzhen, China.
NR 178
TC 18
Z9 18
U1 54
U2 164
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2211-2855
EI 2211-3282
J9 NANO ENERGY
JI Nano Energy
PD DEC
PY 2020
VL 78
AR 105380
DI 10.1016/j.nanoen.2020.105380
PG 13
WC Chemistry, Physical; Nanoscience & Nanotechnology; Materials Science,
   Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Science & Technology - Other Topics; Materials Science;
   Physics
GA PA0EX
UT WOS:000595291200006
DA 2022-04-17
ER

PT J
AU Li, H
   Yang, X
   Li, Y
   Hao, LY
   Zhang, TL
AF Li, Hui
   Yang, Xi
   Li, Yang
   Hao, Li-Ying
   Zhang, Tian-Lun
TI Evolutionary extreme learning machine with sparse cost matrix for
   imbalanced learning
SO ISA TRANSACTIONS
LA English
DT Article
DE Extreme learning machine; Imbalanced learning; Evolutionary algorithm;
   Error bound model; Cost matrix
ID SUPPORT VECTOR MACHINES; DIFFERENTIAL EVOLUTION; CLASSIFICATION;
   MAPREDUCE; PERFORMANCE; WEIGHTS
AB Extreme learning machine is a popular machine learning technique for single hidden layer feed-forward neural network. However, due to the assumption of equal misclassification cost, the conventional extreme learning machine fails to properly learn the characteristics of the data with skewed category distribution. In this paper, to enhance the representation of few-shot cases, we break down that assumption by assigning penalty factors to different classes, and minimizing the cumulative classification cost. To this end, a case-weighting extreme learning machine is developed on a sparse cost matrix with a diagonal form. To be more actionable, we formulate a multi-objective optimization with respect to penalty factors, and optimize this problem using an evolutionary algorithm combined with an error bound model. By doing so, this proposed method is developed into an adaptive cost-sensitive learning, which is guided by the relation between the generalization ability and the case-weighting factors. In a broad experimental study, our method achieves competitive results on benchmark and real-world datasets for software bug reports identification. (C) 2019 ISA. Published by Elsevier Ltd. All rights reserved.
C1 [Li, Hui; Yang, Xi; Li, Yang; Zhang, Tian-Lun] Dalian Maritime Univ, Coll Informat Sci & Technol, Dalian, Peoples R China.
   [Hao, Li-Ying] Dalian Maritime Univ, Maritime Elect Engn Coll, Dalian, Peoples R China.
RP Zhang, TL (corresponding author), Dalian Maritime Univ, Coll Informat Sci & Technol, Dalian, Peoples R China.
EM threekingdomst@163.com
FU National Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [61602077, 61672122, 71831002]; Natural Science
   Foundation of Liaoning Province of ChinaNatural Science Foundation of
   Liaoning Province [201705440097]; Program for Innovative Research Team
   in University, China [IRT_17R13]; Fundamental Research Funds for the
   Central Universities, ChinaFundamental Research Funds for the Central
   Universities [3132019355, 3132019501, 3132019502]; Next Generation
   Internet Innovation Project of CERNET, China [NGII20181205]
FX This work is supported by National Science Foundation of China (No.
   61602077, 61672122 and 71831002), the Natural Science Foundation of
   Liaoning Province of China (No. 201705440097), the Program for
   Innovative Research Team in University, China (IRT_17R13), the
   Fundamental Research Funds for the Central Universities, China (No.
   3132019355, 3132019501 and 3132019502), the Next Generation Internet
   Innovation Project of CERNET, China (No. NGII20181205).
NR 51
TC 13
Z9 14
U1 3
U2 25
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0019-0578
EI 1879-2022
J9 ISA T
JI ISA Trans.
PD MAY
PY 2020
VL 100
BP 198
EP 209
DI 10.1016/j.isatra.2019.11.020
PG 12
WC Automation & Control Systems; Engineering, Multidisciplinary;
   Instruments & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Engineering; Instruments & Instrumentation
GA LN1HZ
UT WOS:000532697600018
PM 31784047
DA 2022-04-17
ER

PT C
AU Hosam, E
   Hosny, H
   Ashraf, W
   Kaseb, AS
AF Hosam, Eman
   Hosny, Hagar
   Ashraf, Walaa
   Kaseb, Ahmed S.
GP IEEE
TI SQL Injection Detection Using Machine Learning Techniques
SO 2021 8TH INTERNATIONAL CONFERENCE ON SOFT COMPUTING & MACHINE
   INTELLIGENCE (ISCMI 2021)
SE International Conference on Soft Computing & Machine Intelligence ISCMI
LA English
DT Proceedings Paper
CT 8th International Conference on Soft Computing & Machine Intelligence
   (ISCMI)
CY NOV 26-27, 2021
CL Cairo, EGYPT
SP IEEE Africa Council
DE cybersecurity; cyberattacks; SQL injection; SQL injection detection;
   machine learning; feature selection
AB SQL Injection is one of the most popular cyberattacks in which hackers can gain unauthorized access to sensitive data such as customer information, trade secrets, etc. SQL Injection works by injecting malicious SQL code into user input fields in order to illegitimately read, update, or delete database contents. Detecting SQL Injection is a binary classification problem in which it is required to decide whether a user input is malicious (i.e., includes an injected SQL code) or benign. SQL Injection can be detected using rule-based, machine learning, or deep learning techniques. This paper focuses on machine learning techniques for SQL Injection detection. The paper defines 13 relevant features that can be extracted from user inputs, and it presents and evaluates 6 different machine learning algorithms. A feature selection process is also conducted, and the models achieve an accuracy up to 99.6%. The presented models show clear abilities to generalize to unseen data and perform well with a limited training set size. Overall, Logistic Regression is concluded to be the most performing model.
C1 [Hosam, Eman; Hosny, Hagar; Ashraf, Walaa; Kaseb, Ahmed S.] Cairo Univ, Fac Engn, Comp Engn Dept, Cairo, Egypt.
RP Hosam, E (corresponding author), Cairo Univ, Fac Engn, Comp Engn Dept, Cairo, Egypt.
EM eman.hosam@eng.cu.edu.eg; hagarhosny19@gmail.com;
   walaa_farouk315@hotmail.com; akaseb@eng.cu.edu.eg
NR 15
TC 0
Z9 0
U1 1
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2640-0154
EI 2640-0146
BN 978-1-7281-8683-2
J9 INT CONF SOFT COMP
PY 2021
BP 15
EP 20
DI 10.1109/ISCMI53840.2021.9654820
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS6OS
UT WOS:000750613100003
DA 2022-04-17
ER

PT C
AU Kowsher, M
   Sanjid, MZI
   Das, A
   Ahmed, M
   Sarker, MMH
AF Kowsher, Md
   Sanjid, Md Zahidul Islam
   Das, Avishek
   Ahmed, Mahid
   Sarker, Md Murad Hossain
BE Klimova, A
   Bilas, A
   Harmandaris, V
   Kalligiannaki, E
   Kanellou, E
   Boukhanovsky, A
TI Machine Learning and Deep Learning based Information Extraction from
   Bangla Names
SO 9TH INTERNATIONAL YOUNG SCIENTISTS CONFERENCE IN COMPUTATIONAL SCIENCE,
   YSC2020
SE Procedia Computer Science
LA English
DT Proceedings Paper
CT 9th International Young Scientists Conference in Computational Science
   (YSC)
CY SEP 05-13, 2020
CL ELECTR NETWORK
SP ITMO Univ, Univ Amsterdam, Univ Crete, Fdn Res & Technol Hellas
DE Information extraction; Machine learning; Deep learning; Impact
   learning; Demographic
AB Machine learning and deep learning have been perceived as a commended technique for different pattern recognition purposes among data. A chunk of consideration has been given to social and demographic research and with an amalgamation of various machine learning and deep learning algorithms. In this paper, we anticipate structuring a machine learning and deep neural network-based mechanized system that can effectively induce religion, sexual orientation utilizing just the names of the masses. Additionally, our goal stretches out by inferring valuable demographic attributes like region and religious conversion using some additional information like age and parent's name of the individual. By and large 10 machine learning and 3 deep learning algorithms are implemented to assemble this model which can derive 4 particular religions (Hindu, Muslim, Buddhist, and Christian), Gender (Male and Female), 6 regions (Dhaka, Khulna, Raj shahi, Chittagong, Sylhet, Barisal), and religious conversions with the most raised exactness pace. We also analyzed the performance and compared among all algorithms by using different statistical methods. (C) 2020 The Authors. Published by Elsevier B.V.
C1 [Kowsher, Md; Ahmed, Mahid] Noakhali Sci & Technol Univ, Noakhali 3814, Bangladesh.
   [Sanjid, Md Zahidul Islam] BRAC Univ, Dhaka, Bangladesh.
   [Das, Avishek] Chittagong Univ Engn & Technol, Dhaka 4349, Bangladesh.
   [Sarker, Md Murad Hossain] Comilla Univ, Comilla 3506, Bangladesh.
RP Kowsher, M (corresponding author), Noakhali Sci & Technol Univ, Noakhali 3814, Bangladesh.
EM ga.kowsher@gmail.com
RI Kowsher/AAH-5826-2021
OI Kowsher/0000-0001-5469-3437; Das, Avishek/0000-0002-1589-8322
NR 18
TC 3
Z9 3
U1 1
U2 1
PU ELSEVIER
PI AMSTERDAM
PA Radarweg 29, PO Box 211, AMSTERDAM, NETHERLANDS
SN 1877-0509
J9 PROCEDIA COMPUT SCI
PY 2020
VL 178
BP 224
EP 233
DI 10.1016/j.procs.2020.11.024
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering;
   Computer Science, Theory & Methods; Mathematics, Applied
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Mathematics
GA BR1TP
UT WOS:000635443400024
OA gold
DA 2022-04-17
ER

PT C
AU Khan, AI
   Al-Habsi, S
AF Khan, Asharul Islam
   Al-Habsi, Salim
BE Singh, V
   Asari, VK
   Li, KC
TI Machine Learning in Computer Vision
SO INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND DATA SCIENCE
SE Procedia Computer Science
LA English
DT Proceedings Paper
CT International Conference on Computational Intelligence and Data Science
   (ICCIDS)
CY SEP 06-07, 2019
CL NorthCap Univ, Gurugram, INDIA
HO NorthCap Univ
DE machine learning; image processing; object detection; computer vision;
   artificial intelligence; image classification; neural network; support
   vector machine
AB During last few years the computer applications have gone dramatic transfoi tation from simple data processing to machine learning, thanks to the availability and accessibility of huge volume of data collected through sensors and internet. The idea of machine learning demonstrates and propagates the facts that computer has the ability to improve itself with the passage of time. The western countries have shown great interest on the topic of machine learning, computer vision, and pattern recognition via organizing conferences, workshops, collective discussion, experimentation, and real life implementation. This study on machine learning and computer vision explores and analytically evaluates the machine learning applications in computer vision and predicts future prospects. The study has found that the machine learning strategies in computer vision are supervised, un-supervised, and semi-supervised. The commonly used algorithms are neural networks, k-means clustering, and support vector machine. The most recent applications of machine learning in computer vision are object detection, object classification, and extraction of relevant infounation from images, graphic documents, and videos. Additionally, Tensor flow, Faster-RCNN-Inception-V2 model, and Anaconda software development environment used to identify cars and persons in images. (C) 2020 The Authors. Published by Elsevier B.V.
C1 [Khan, Asharul Islam] Sultan Qaboos Univ, Remote Sensing & GIS Res Ctr, POB 33 AlKhodh, Muscat 123, Oman.
   [Al-Habsi, Salim] Gulf Coll, POB 885, Muscat 123, Oman.
RP Khan, AI (corresponding author), Sultan Qaboos Univ, Remote Sensing & GIS Res Ctr, POB 33 AlKhodh, Muscat 123, Oman.
EM ashar.367@gmail.com
RI khan, asharul/ABE-2744-2020; khan, asharul/AAK-5903-2020
OI khan, asharul/0000-0002-4355-0251; 
NR 38
TC 15
Z9 16
U1 23
U2 30
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0509
J9 PROCEDIA COMPUT SCI
PY 2020
VL 167
BP 1444
EP 1451
DI 10.1016/j.procs.2020.03.355
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ2YR
UT WOS:000582710700147
OA gold
DA 2022-04-17
ER

PT C
AU Mohammed, J
   Mahmud, MJ
AF Mohammed, Jaby
   Mahmud, Md Jubaer
GP IEEE
TI Selection of a machine learning algorithm for OSHA fatalities
SO 2020 IEEE TECHNOLOGY & ENGINEERING MANAGEMENT CONFERENCE (TEMSCON 2020)
LA English
DT Proceedings Paper
CT Annual IEEE Technology and Engineering Management Conference (TEMSCON)
CY JUN 03-06, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Technol & Engn Management Soc
DE machine learning; OSHA; machine learning algorithm; fatalities
AB Traditional programming has already cleared its path to machine learning. With the abundance of data that is available in different applications and fields, it has grown exponentially in the past years. With the available data, machine learning models can predict the output. The different models that have been used have transformed a wide range of real-world applications. Workplace safety is one of the most important factors that make an organization successful. Every organization has a plan that describes what employees should do in order to prevent injury, but still, accidents happen at the workplace. Accident related data is available with the Occupational Safety and Health Administration (OSHA). There are different machine learning algorithms that are used to predict the required output. In this paper, the authors are investigating different machine learning algorithms and their accuracy to the predicted results.
C1 [Mohammed, Jaby; Mahmud, Md Jubaer] Illinois State Univ, Dept Technol, Normal, IL 61761 USA.
RP Mohammed, J (corresponding author), Illinois State Univ, Dept Technol, Normal, IL 61761 USA.
EM jmohamm@ilstu.edu; mmahmu1@ilstu.edu
NR 11
TC 0
Z9 0
U1 1
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-4224-1
PY 2020
PG 5
WC Business; Engineering, Multidisciplinary; Management
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Business & Economics; Engineering
GA BQ7NC
UT WOS:000617753200028
DA 2022-04-17
ER

PT J
AU Krasikov, S
   Tranter, A
   Bogdanov, A
   Kivshar, Y
AF Krasikov, Sergey
   Tranter, Aaron
   Bogdanov, Andrey
   Kivshar, Yuri
TI Intelligent metaphotonics empowered by machine learning
SO OPTO-ELECTRONIC ADVANCES
LA English
DT Review
DE metaphotonics; machine learning; artificial intelligence
ID DEEP NEURAL-NETWORK; INVERSE-DESIGN; BROAD-BAND;
   ARTIFICIAL-INTELLIGENCE; EYE DISPLAY; SCATTERING; METASURFACES;
   METAMATERIALS; OPTIMIZATION; EFFICIENT
AB In the recent years, a dramatic boost of the research is observed at the junction of photonics, machine learning and artificial intelligence. A new methodology can be applied to the description of a variety of photonic systems including optical waveguides, nanoantennas, and metasurfaces. These novel approaches underpin the fundamental principles of lightmatter interaction developed for a smart design of intelligent photonic devices. Artificial intelligence and machine learning penetrate rapidly into the fundamental physics of light, and they provide effective tools for the study of the field of metaphotonics driven by optically induced electric and magnetic resonances. Here we overview the evaluation of metaphotonics induced by artificial intelligence and present a summary of the concepts of machine learning with some specific examples developed and demonstrated for metasystems and metasurfaces.
C1 [Krasikov, Sergey; Kivshar, Yuri] Australian Natl Univ, Res Sch Phys, Nonlinear Phys Ctr, Canberra, ACT 2601, Australia.
   [Krasikov, Sergey; Bogdanov, Andrey] ITMO Univ, Sch Phys & Engn, St Petersburg 197101, Russia.
   [Tranter, Aaron] Australian Natl Univ, Res Sch Phys, Dept Quantum Sci, Ctr Quantum Computat & Commun Technol, Canberra, ACT 2601, Australia.
RP Kivshar, Y (corresponding author), Australian Natl Univ, Res Sch Phys, Nonlinear Phys Ctr, Canberra, ACT 2601, Australia.
EM yuri.kivshar@anu.edu.au
FU Priority 2030 Federal Academic Leadership Program; Foundation for the
   Advancement of Theoretical Physics and Mathematics "BASIS"; Australian
   Research CouncilAustralian Research Council [DP200101168, DP210101292,
   CE170100012]; Strategic Fund of the Australian National University;
   Russian Science FoundationRussian Science Foundation (RSF)
   [21-72-30018]; US Army International Office [FA5209-21-P0034]
FX The authors acknowledge useful comments and suggestions received from A.
   Chukhrov, A. Slobozhanyuk, I. Melchakova, and P. Belov. This research
   was supported by Priority 2030 Federal Academic Leadership Program. A.B.
   acknowledges a support from the Foundation for the Advancement of
   Theoretical Physics and Mathematics "BASIS". A.T. acknowledges a support
   from the Australian Research Council (grant CE170100012). Y.K.
   acknowledges a support from the Strategic Fund of the Australian
   National University, The Australian Research Council (grants DP200101168
   and DP210101292), the Russian Science Foundation (grant 21-72-30018),
   and the US Army International Office (grant FA5209-21-P0034).
NR 226
TC 0
Z9 0
U1 0
U2 0
PU CAS, INST OPTICS & ELECTRONICS, ED OFF OPTO-ELECTRONIC JOURNALS
PI CHENGDU
PA NO 1 GUANGDIAN AVENUE, CHENGDU, 610209, PEOPLES R CHINA
SN 2096-4579
J9 OPTO-ELECTRON ADV
JI Opto-Electron. Adv.
PY 2022
VL 5
IS 3
AR 210147
DI 10.29026/oea.2022.210147
PG 24
WC Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Optics
GA 0H5RN
UT WOS:000778790100005
OA Green Submitted, gold
DA 2022-04-17
ER

PT C
AU Agustian, D
   Pertama, PPGP
   Crisnapati, PN
   Novayanti, PD
AF Agustian, Diki
   Pertama, Pande Putu Gede Putra
   Crisnapati, Padma Nyoman
   Novayanti, Putu Devi
GP IEEE
TI Implementation of Machine Learning Using Google's Teachable Machine
   Based on Android
SO 3RD INTERNATIONAL CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEMS
   (ICORIS 2021)
LA English
DT Proceedings Paper
CT 3rd International Conference on Cybernetics and Intelligent System
   (ICORIS)
CY OCT 25-26, 2021
CL Dipa Makasar Univ, ELECTR NETWORK
SP Binus Univ
HO Dipa Makasar Univ
DE android; google's teachable machine; machine learning
AB Many people think that machine learning is difficult to build and do not know how to implement it. This is one of the problems in writing this report. In this study, the system development method used is the waterfall which starts from the requirements analysis stage, system design, system implementation, system testing and system maintenance. The design of this system uses flowcharts, Unified Modeling Languages (UML) and interface design. In this study, it is known that Android devices can be implemented with a machine learning model. Each model in this study has been tested for models and each model has an accuracy, precision and sensitivity ranging from 97-100%. Google's Teachable Machine can create a machine learning model with a test accuracy rate of up to 100%. The level of accuracy can be reduced according to the level of lighting at the detection site.
C1 [Agustian, Diki; Crisnapati, Padma Nyoman; Novayanti, Putu Devi] ITB STIKOM Bali, Comp Syst Program, Denpasar, Indonesia.
   [Pertama, Pande Putu Gede Putra] ITB STIKOM Bali, Informat Syst Program, Denpasar, Indonesia.
RP Agustian, D (corresponding author), ITB STIKOM Bali, Comp Syst Program, Denpasar, Indonesia.
EM dikiagustiann@gmail.com; putrapertama@stikom-bali.ac.id;
   crisnapati@stikom-bali.ac.id; devinovayanti@stikom-bali.ac.id
NR 11
TC 0
Z9 0
U1 1
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-6654-2580-3
PY 2021
BP 220
EP 226
DI 10.1109/ICORIS52787.2021.9649528
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS7XN
UT WOS:000768467000041
DA 2022-04-17
ER

PT J
AU Ding, JQ
   Xu, N
   Nguyen, MT
   Qiao, Q
   Shi, Y
   He, Y
   Shao, Q
AF Ding, Jiaqi
   Xu, Nan
   Manh Tien Nguyen
   Qiao, Qi
   Shi, Yao
   He, Yi
   Shao, Qing
TI Machine learning for molecular thermodynamics
SO CHINESE JOURNAL OF CHEMICAL ENGINEERING
LA English
DT Review
DE Machine learning; Thermodynamic properties; Molecular engineering;
   Molecular simulation; Force field
ID STRUCTURE-PROPERTY RELATIONSHIP; SOLVATION FREE-ENERGIES;
   FEATURE-SELECTION; NEURAL-NETWORK; FORCE-FIELD; DYNAMICS SIMULATIONS;
   ORGANIC-COMPOUNDS; PURE COMPONENTS; MODELS; DESIGN
AB Thermodynamic properties of complex systems play an essential role in developing chemical engineering processes. It remains a challenge to predict the thermodynamic properties of complex systems in a wide range and describe the behavior of ions and molecules in complex systems. Machine learning emerges as a powerful tool to resolve this issue because it can describe complex relationships beyond the capacity of traditional mathematical functions. This minireview will summarize some fundamental concepts of machine learning methods and their applications in three aspects of the molecular thermodynamics using several examples. The first aspect is to apply machine learning methods to predict the thermodynamic properties of a broad spectrum of systems based on known data. The second aspect is to integer machine learning and molecular simulations to accelerate the discovery of materials. The third aspect is to develop machine learning force field that can eliminate the barrier between quantum mechanics and all-atom molecular dynamics simulations. The applications in these three aspects illustrate the potential of machine learning in molecular thermodynamics of chemical engineering. We will also discuss the perspective of the broad applications of machine learning in chemical engineering. (C) 2021 The Chemical Industry and Engineering Society of China, and Chemical Industry Press Co., Ltd. All rights reserved.
C1 [Ding, Jiaqi; Xu, Nan; Shi, Yao; He, Yi] Zhejiang Univ, Coll Chem & Biol Engn, Hangzhou 310027, Peoples R China.
   [Manh Tien Nguyen; Qiao, Qi; Shao, Qing] Univ Kentucky, Chem & Mat Engn Dept, Lexington, KY 40506 USA.
   [Shi, Yao] Zhejiang Univ, Key Lab Biomass Chem Engn, Minist Educ, Hangzhou 310027, Peoples R China.
   [He, Yi] Univ Washington, Dept Chem Engn, Seattle, WA 98195 USA.
RP He, Y; Shao, Q (corresponding author), Zhejiang Univ, Coll Chem & Biol Engn, Hangzhou 310027, Peoples R China.
EM yihezj@zju.edu.cn; qshao@uky.edu
OI Ding, Jiaqi/0000-0003-4549-051X
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [21676245, 51933009]; National Key Research
   and Development Program of China [2017YFB0702502]; Leading Innovative
   and Entrepreneur Team Introduction Program of Zhejiang [2019R01006];
   Startup Funds of the University of Kentucky
FX Jiaqi Ding, Nan Xu, Dr. Yao Shi and Dr. Yi He acknowledge financial
   supports from the National Natural Science Foundation of China (21676245
   and 51933009), the National Key Research and Development Program of
   China (2017YFB0702502), and the Leading Innovative and Entrepreneur Team
   Introduction Program of Zhejiang (2019R01006). Manh Tien Nguyen, Dr. Qi
   Qiao and Dr. Qing Shao thank the financial support provided by the
   Startup Funds of the University of Kentucky.
NR 155
TC 2
Z9 2
U1 41
U2 59
PU CHEMICAL INDUSTRY PRESS CO LTD
PI BEIJING
PA NO 13, QINGNIANHU SOUTH ST, DONGCHENG DIST, BEIJING 100011, PEOPLES R
   CHINA
SN 1004-9541
EI 2210-321X
J9 CHINESE J CHEM ENG
JI Chin. J. Chem. Eng.
PD MAR
PY 2021
VL 31
SI SI
BP 227
EP 239
DI 10.1016/j.cjche.2020.10.044
PG 13
WC Engineering, Chemical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA SD0KV
UT WOS:000651052400024
DA 2022-04-17
ER

PT C
AU Xie, H
   Wei, L
   Fang, F
AF Xie, Hui
   Wei, Li
   Fang, Fang
GP IEEE
TI Research on Privacy Protection Based on Machine Learning
SO IWCMC 2021: 2021 17TH INTERNATIONAL WIRELESS COMMUNICATIONS & MOBILE
   COMPUTING CONFERENCE (IWCMC)
SE International Wireless Communications and Mobile Computing Conference
LA English
DT Proceedings Paper
CT 17th IEEE International Wireless Communications and Mobile Computing
   Conference (IEEE IWCMC)
CY JUN 28-JUL 02, 2021
CL ELECTR NETWORK
SP IEEE, IEEE Harbin Sect, IEEE Commun Soc Harbin Chapter, Huawei
DE Machine Learning; Privacy Protection
ID 5G; SDN
AB In recent years, as the development of machine learning become more and more faster, people's lives have been convenient, while security risks have also arisen. The security and privacy issues of machine learning put its own development into a difficult position. Machine learning models can be trained and predicted on the basis of a large amount of data, while these data will inevitably contain a varying amount of sensitive or private information. With the frequent occurrence of data security and privacy leaks, and the degree of leakage gradually deepens, the way to guarantee data security and privacy has attracted much attention. This article discusses privacy protection based on machine learning by analyzing machine learning and the privacy issues it facing.
C1 [Xie, Hui; Wei, Li; Fang, Fang] Xiangnan Univ, Sch Software & Commun Engn, Chenzhou, Hunan, Peoples R China.
RP Wei, L (corresponding author), Xiangnan Univ, Sch Software & Commun Engn, Chenzhou, Hunan, Peoples R China.
EM xiehui@xnu.edu.cn; 95140305@smail.xtu.edu.cn; fang20000fang@163.com
FU Hunan Provincial Social Science Achievement Review Committee
   [XSP21YBC460]; Scientific research project of Hunan Provincial
   Department of Education [18C1025]; XiangNan University Innovation and
   Entrepreneurship Training Program [57]; XiangNan University Scientific
   research project [36]
FX 1. The subject of Hunan Provincial Social Science Achievement Review
   Committee, the multi-level extension optimization decision analysis
   research of network digital library resources (NO. XSP21YBC460).; 2.
   Scientific research project of Hunan Provincial Department of Education,
   research on multi-granularity structure of concept lattice supported by
   big data set (NO.18C1025).; 3. XiangNan University Innovation and
   Entrepreneurship Training Program for College Students in 2020,
   Internet+Remote Mountain Villagers Health Management Cloud Service
   System (NO.57).; 4. XiangNan University Scientific research project in
   2019,Monitoring and control system for water quality security in Longhu
   Cave water source area based on cloud technology(NO.36).
NR 18
TC 0
Z9 0
U1 10
U2 10
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2376-6492
BN 978-1-7281-8616-0
J9 INT WIREL COMMUN
PY 2021
BP 1003
EP 1006
DI 10.1109/IWCMC51323.2021.9498632
PG 4
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Engineering, Electrical & Electronic; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Telecommunications
GA BS2VJ
UT WOS:000707024100185
DA 2022-04-17
ER

PT J
AU Sun, SW
   Wang, CY
   Ding, H
   Zou, Q
AF Sun, Shanwen
   Wang, Chunyu
   Ding, Hui
   Zou, Quan
TI Machine learning and its applications in plant molecular studies
SO BRIEFINGS IN FUNCTIONAL GENOMICS
LA English
DT Review
DE supervised machine learning; unsupervised machine learning; evaluation
   metrics; plants; genomics
ID PRINCIPAL COMPONENT ANALYSIS; SUBCELLULAR-LOCALIZATION; CLIMATE-CHANGE;
   IDENTIFICATION; PROTEINS; GENE; RESISTANCE; GENOMICS; NETWORK;
   PREDICTION
AB The advent of high-throughput genomic technologies has resulted in the accumulation of massive amounts of genomic information. However, biologists are challenged with how to effectively analyze these data. Machine learning can provide tools for better and more efficient data analysis. Unfortunately, because many plant biologists are unfamiliar with machine learning, its application in plant molecular studies has been restricted to a few species and a limited set of algorithms. Thus, in this study, we provide the basic steps for developing machine learning frameworks and present a comprehensive overview of machine learning algorithms and various evaluation metrics. Furthermore, we introduce sources of important curated plant genomic data and R packages to enable plant biologists to easily and quickly apply appropriate machine learning algorithms in their research. Finally, we discuss current applications of machine learning algorithms for identifying various genes related to resistance to biotic and abiotic stress. Broad application of machine learning and the accumulation of plant sequencing data will advance plant molecular studies.
C1 [Sun, Shanwen; Zou, Quan] Univ Elect Sci & Technol China, Inst Fundamental & Frontier Sci, Chengdu 610054, Peoples R China.
   [Wang, Chunyu] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Peoples R China.
   [Ding, Hui] Univ Elect Sci & Technol China, Ctr Informat Biol, Chengdu, Peoples R China.
RP Zou, Q (corresponding author), Univ Elect Sci & Technol China, Inst Fundamental & Frontier Sci, Chengdu 610054, Peoples R China.
EM zouquan@nclab.net
OI Sun, Shanwen/0000-0003-4358-8636
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [91935302, 61771331, 61922020, 91735306]
FX This work was supported by the National Natural Science Foundation of
   China (Nos. 91935302, 61771331, 61922020 and 91735306).
NR 114
TC 10
Z9 10
U1 8
U2 28
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 2041-2649
EI 2041-2657
J9 BRIEF FUNCT GENOMICS
JI Brief. Funct. Genomics
PD JAN
PY 2020
VL 19
IS 1
BP 40
EP 48
DI 10.1093/bfgp/elz036
PG 9
WC Biotechnology & Applied Microbiology; Genetics & Heredity
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biotechnology & Applied Microbiology; Genetics & Heredity
GA PI1ZC
UT WOS:000600895900004
PM 31867668
DA 2022-04-17
ER

PT J
AU Litz, H
   Hashemi, M
AF Litz, Heiner
   Hashemi, Milad
TI Machine Learning for Systems
SO IEEE MICRO
LA English
DT Editorial Material
DE Special issues and sections; Machine learning; Neural networks; Computer
   architecture; Training data
AB The six papers in this special section focus on machine learning for computer systems. Specialized computer systems have driven the performance and capability of deep learning over the past decade.1 However, as machine learning models and systems improve, there is a growing opportunity to also use these models to improve how we design, architect, optimize, and automate computer systems and software. This is a challenging area, both from a learning and a systems perspective. Systems often impose tight size, latency, or reliability constraints on learning mechanisms that do not arise in other applications of machine learning, such as computer vision or natural language processing. From a learning perspective, systems is a challenging application, where input features are often large and sparse, action spaces are gigantic, and generalization is a key attribute.
C1 [Litz, Heiner] Univ Calif Santa Cruz, Santa Cruz, CA 95064 USA.
   [Hashemi, Milad] Google, Mountain View, CA 94043 USA.
RP Litz, H (corresponding author), Univ Calif Santa Cruz, Santa Cruz, CA 95064 USA.
EM hlitz@ucsc.edu; miladhashemi@utexas.edu
NR 1
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0272-1732
EI 1937-4143
J9 IEEE MICRO
JI IEEE Micro
PD SEP-OCT
PY 2020
VL 40
IS 5
BP 6
EP 7
DI 10.1109/MM.2020.3016551
PG 2
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NM0IW
UT WOS:000567789900002
DA 2022-04-17
ER

PT C
AU Thakur, MK
   Goundkar, RR
AF Thakur, Manish Kumar
   Goundkar, Raju Ramakrishna
BE Satapathy, SC
   Bhateja, V
   Mohanty, JR
   Udgata, SK
TI Evaluation of Content Using Machine Learning
SO SMART INTELLIGENT COMPUTING AND APPLICATIONS, VOL 2
SE Smart Innovation Systems and Technologies
LA English
DT Proceedings Paper
CT 3rd International Conference on Smart Computing and Informatics (SCI)
CY DEC 21-22, 2018
CL Bhubaneswar, INDIA
SP Kalinga Inst Ind Technol, Sch Comp Engn, Kalinga Inst Ind Technol, Sch Comp Applicat, KES Int
DE Machine learning; Image retrieval; TBIR; CBIR
AB Machine learning is one of the most widely used approaches in current day for effective analysis and prediction purpose in the domain of image processing applications. This paper thus makes a study of existing image retrieval methods. It has been a challenge to implement human recognition method in machines for a long time now. In this process number of methods and procedures are developed to implement the human recognition system in machines. It is however still not possible to achieve the accuracy human are bestowed with. There are number of ways in which different researchers have attempted this task. The paper describes the method along with the parameters used, processing method, and the accuracy achieved. The latest method being machine learning, this study concentrates on the development of supervised learning and thereof the progress made by the unsupervised learning methods. The two techniques Text-based Image Retrieval and Content-Based Image Retrieval are the important retrieval methods dealt with.
C1 [Thakur, Manish Kumar] VTU, Acharya Inst Technol, Bengaluru, India.
   [Goundkar, Raju Ramakrishna] CMR Univ, Bengaluru, India.
RP Thakur, MK (corresponding author), VTU, Acharya Inst Technol, Bengaluru, India.
EM manishkthakur@acharya.ac.in; rrgondkar@gmail.com
NR 9
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 2190-3018
EI 2190-3026
BN 978-981-32-9690-9; 978-981-32-9689-3
J9 SMART INNOV SYST TEC
PY 2020
VL 160
BP 593
EP 599
DI 10.1007/978-981-32-9690-9_65
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BP2PT
UT WOS:000544256200058
DA 2022-04-17
ER

PT J
AU Sealfon, RSG
   Mariani, LH
   Kretzler, M
   Troyanskaya, OG
AF Sealfon, Rachel S. G.
   Mariani, Laura H.
   Kretzler, Matthias
   Troyanskaya, Olga G.
TI Machine learning, the kidney, and genotype-phenotype analysis
SO KIDNEY INTERNATIONAL
LA English
DT Review
DE deep learning; genotype; machine learning
ID NONCODING VARIANTS; APOL1 GENE; DISEASE; PREDICTION; NEPHROPATHY;
   MODELS; PATHOGENICITY; ASSOCIATION; PROGRESSION; NETWORK
AB With biomedical research transitioning into data-rich science, machine learning provides a powerful toolkit for extracting knowledge from large-scale biological data sets. The increasing availability of comprehensive kidney omics compendia (transcriptomics, proteomics, metabolomics, and genome sequencing), as well as other data modalities such as electronic health records, digital nephropathology repositories, and radiology renal images, makes machine learning approaches increasingly essential for analyzing human kidney data sets. Here, we discuss how machine learning approaches can be applied to the study of kidney disease, with a particular focus on how they can be used for understanding the relationship between genotype and phenotype.
C1 [Sealfon, Rachel S. G.; Troyanskaya, Olga G.] Simons Fdn, Flatiron Inst, Ctr Computat Biol, New York, NY USA.
   [Mariani, Laura H.; Kretzler, Matthias] Univ Michigan, Div Nephrol, 1560 MSRB II,1150 W Med Ctr Dr,SPC5676, Ann Arbor, MI 48109 USA.
   [Troyanskaya, Olga G.] Princeton Univ, Lewis Sigler Inst Integrat Genom, Princeton, NJ 08544 USA.
   [Troyanskaya, Olga G.] Princeton Univ, Dept Comp Sci, Comp Sci Bldg,Room 320,35 Olden St, Princeton, NJ 08544 USA.
RP Kretzler, M (corresponding author), Univ Michigan, Div Nephrol, 1560 MSRB II,1150 W Med Ctr Dr,SPC5676, Ann Arbor, MI 48109 USA.; Troyanskaya, OG (corresponding author), Princeton Univ, Dept Comp Sci, Comp Sci Bldg,Room 320,35 Olden St, Princeton, NJ 08544 USA.
EM kretzler@umich.edu; ogt@cs.princeton.edu
FU National Institutes of Health (NIH)/National Institute of Diabetes and
   Digestive and Kidney Diseases (NIDDK)United States Department of Health
   & Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute of Diabetes & Digestive & Kidney Diseases (NIDDK) [K08
   DK115891]; NIH/NIDDKUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   of Diabetes & Digestive & Kidney Diseases (NIDDK) [U24DK100845,
   UGDK114907, U2CDK114886]; NIHUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [UH3TR002158]
FX The authors thank Aaron K. Wong for feedback on the manuscript. LHM is
   supported by the National Institutes of Health (NIH)/National Institute
   of Diabetes and Digestive and Kidney Diseases (NIDDK) (K08 DK115891).
   This work is supported by NIH/NIDDK grants U24DK100845, UGDK114907, and
   U2CDK114886 and NIH grant UH3TR002158 to OGT. OGT is a senior fellow of
   the Genetic Networks program of the Canadian Institute for Advanced
   Research (CIFAR).
NR 82
TC 10
Z9 10
U1 3
U2 17
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0085-2538
EI 1523-1755
J9 KIDNEY INT
JI Kidney Int.
PD JUN
PY 2020
VL 97
IS 6
BP 1141
EP 1149
DI 10.1016/j.kint.2020.02.028
PG 9
WC Urology & Nephrology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Urology & Nephrology
GA LZ1IT
UT WOS:000540984000015
PM 32359808
OA Green Accepted
DA 2022-04-17
ER

PT J
AU Xue, MF
   Yuan, CX
   Wu, HY
   Zhang, YS
   Liu, WQ
AF Xue, Mingfu
   Yuan, Chengxiang
   Wu, Heyi
   Zhang, Yushu
   Liu, Weiqiang
TI Machine Learning Security: Threats, Countermeasures, and Evaluations
SO IEEE ACCESS
LA English
DT Article
DE Machine learning; Security; Data models; Machine learning algorithms;
   Training; Training data; Prediction algorithms; Artificial intelligence
   security; poisoning attacks; backdoor attacks; adversarial examples;
   privacy-preserving machine learning
ID POISONING ATTACKS; DEFENSES
AB Machine learning has been pervasively used in a wide range of applications due to its technical breakthroughs in recent years. It has demonstrated significant success in dealing with various complex problems, and shows capabilities close to humans or even beyond humans. However, recent studies show that machine learning models are vulnerable to various attacks, which will compromise the security of the models themselves and the application systems. Moreover, such attacks are stealthy due to the unexplained nature of the deep learning models. In this survey, we systematically analyze the security issues of machine learning, focusing on existing attacks on machine learning systems, corresponding defenses or secure learning techniques, and security evaluation methods. Instead of focusing on one stage or one type of attack, this paper covers all the aspects of machine learning security from the training phase to the test phase. First, the machine learning model in the presence of adversaries is presented, and the reasons why machine learning can be attacked are analyzed. Then, the machine learning security-related issues are classified into five categories: training set poisoning; backdoors in the training set; adversarial example attacks; model theft; recovery of sensitive training data. The threat models, attack approaches, and defense techniques are analyzed systematically. To demonstrate that these threats are real concerns in the physical world, we also reviewed the attacks in real-world conditions. Several suggestions on security evaluations of machine learning systems are also provided. Last, future directions for machine learning security are also presented.
C1 [Xue, Mingfu; Yuan, Chengxiang; Zhang, Yushu] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 210016, Peoples R China.
   [Wu, Heyi] Nanjing Upsec Network Secur Technol Res Inst Co L, Nanjing 211100, Peoples R China.
   [Liu, Weiqiang] Nanjing Univ Aeronaut & Astronaut, Coll Elect & Informat Engn, Nanjing 210016, Peoples R China.
RP Xue, MF (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 210016, Peoples R China.; Liu, WQ (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Elect & Informat Engn, Nanjing 210016, Peoples R China.
EM mingfu.xue@nuaa.edu.cn; liuweiqiang@nuaa.edu.cn
OI Liu, Weiqiang/0000-0001-8398-8648; Xue, Mingfu/0000-0003-2408-503X
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61602241]; Natural Science Foundation of
   Jiangsu ProvinceNatural Science Foundation of Jiangsu Province
   [BK20150758]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61602241, and in part by the Natural
   Science Foundation of Jiangsu Province under Grant BK20150758.
NR 123
TC 18
Z9 18
U1 16
U2 38
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 74720
EP 74742
DI 10.1109/ACCESS.2020.2987435
PG 23
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA LK4KW
UT WOS:000530830800100
OA gold
DA 2022-04-17
ER

PT C
AU Huang-Fu, CY
   Liao, CH
   Wu, JY
AF Huang-Fu, Cheng-Yo
   Liao, Chen-Hsuan
   Wu, Jiun-Yu
BE Chang, M
   Chen, NS
   Sampson, DG
   Tlili, A
TI Comparing the performance of machine learning and deep learning
   algorithms classifying messages in Facebook learning group
SO IEEE 21ST INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES
   (ICALT 2021)
SE IEEE International Conference on Advanced Learning Technologies
LA English
DT Proceedings Paper
CT 21st IEEE International Conference on Advanced Learning Technologies
   (ICALT)
CY JUL 12-15, 2021
CL ELECTR NETWORK
SP IEEE, IEEE Tech Comm Learning Technol, IEEE Comp Soc
DE learning analytics; big data; machine learning; deep learning; feature
   extraction
ID ATTENTION; ONLINE
AB The use of computer-mediated communication (CMC) has been ubiquitous in higher education. To better understand students' behaviors and facilitate students' learning through CMC, this study aimed to classify messages in Facebook learning group which was created as an on-line discussion board. Different machine learning and deep learning classification models were proposed, trained and testified with corpuses from PTT, one of the famous on-line forums in Taiwan. Furthermore, the classification of Facebook messages by these well-trained models were compared with human coding. Results revealed that recurrent neural network (RNN) with word to vector (W2V) for feature extraction demonstrated the best performance in accuracy. In addition, the combination of RNN and TF-IDF was proved to have the highest correlation with human work. Implications for artificial intelligence (AI) in education context was discussed.
C1 [Huang-Fu, Cheng-Yo] Ind Technol Res Inst, Computat Intelligence Technol Ctr, Hsinchu, Taiwan.
   [Liao, Chen-Hsuan; Wu, Jiun-Yu] Natl Yang Ming Chiao Tung Univ, Inst Educ, Hsinchu, Taiwan.
RP Huang-Fu, CY (corresponding author), Ind Technol Res Inst, Computat Intelligence Technol Ctr, Hsinchu, Taiwan.
EM jason022085@gmail.com; abugu.ie08g@nctu.edu.tw; jiunyu.rms@gmail.com
FU Ministry of Science and Technology, TaiwanMinistry of Science and
   Technology, Taiwan [108-2511-H-009-013-MY3]
FX This research was partially supported by 108-2511-H-009-013-MY3 from the
   Ministry of Science and Technology, Taiwan.
NR 13
TC 0
Z9 0
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
SN 2161-3761
BN 978-1-6654-4106-3
J9 IEEE INT CONF ADV LE
PY 2021
BP 347
EP 349
DI 10.1109/ICALT52272.2021.00111
PG 3
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory & Methods;
   Education & Educational Research
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Education & Educational Research
GA BS4HI
UT WOS:000719352000104
DA 2022-04-17
ER

PT J
AU Liu, B
   Ding, M
   Shaham, S
   Rahayu, W
   Farokhi, F
   Lin, ZH
AF Liu, Bo
   Ding, Ming
   Shaham, Sina
   Rahayu, Wenny
   Farokhi, Farhad
   Lin, Zihuai
TI When Machine Learning Meets Privacy: A Survey and Outlook
SO ACM COMPUTING SURVEYS
LA English
DT Article
DE Machine learning; privacy; deep learning; differential privacy
ID INFERENCE ATTACKS; PERMISSIONS; REGRESSION; SERVICES; AWARE; AGE
AB The newly emerged machine learning (e.g., deep learning) methods have become a strong driving force to revolutionize a wide range of industries, such as smart healthcare, financial technology, and surveillance systems. Meanwhile, privacy has emerged as a big concern in this machine learning-based artificial intelligence era. It is important to note that the problem of privacy preservation in the context of machine learning is quite different from that in traditional data privacy protection, as machine learning can act as both friend and foe. Currently, the work on the preservation of privacy and machine learning are still in an infancy stage, as most existing solutions only focus on privacy problems during the machine learning process. Therefore, a comprehensive study on the privacy preservation problems and machine learning is required. This article surveys the state of the art in privacy issues and solutions for machine learning. The survey covers three categories of interactions between privacy and machine learning: (i) private machine learning, (ii) machine learning-aided privacy protection, and (iii) machine learning-based privacy attack and corresponding protection schemes. The current research progress in each category is reviewed and the key challenges are identified. Finally, based on our in-depth analysis of the area of privacy and machine learning, we point out future research directions in this field.
C1 [Liu, Bo] Univ Technol Sydney, Sch Comp Sci, 15 Broadway, Ultimo, NSW 2007, Australia.
   [Ding, Ming] CSIRO, Data61, 5-13 Garden St, Eveleigh, NSW 2015, Australia.
   [Shaham, Sina; Lin, Zihuai] Univ Sydney, Camperdown, NSW 2006, Australia.
   [Rahayu, Wenny] La Trobe Univ, Plenty Rd,Kingsbury Dr, Bundoora, Vic 3086, Australia.
   [Farokhi, Farhad] Univ Melbourne, Parkville, Vic 3010, Australia.
RP Liu, B (corresponding author), Univ Technol Sydney, Sch Comp Sci, 15 Broadway, Ultimo, NSW 2007, Australia.
EM bo.liu@uts.edu.au; ming.ding@data61.csiro.au; sina.shaham@sydney.edu.au;
   W.Rahayu@latrobe.edu.au; Farhad.Farokhi@unimelb.edu.au;
   zihuai.lin@sydney.edu.au
RI Ding, Ming/AAW-4395-2021; Farokhi, Farhad/M-2683-2018
OI Farokhi, Farhad/0000-0002-5102-7073; LIU, BO/0000-0002-3603-6617
NR 181
TC 12
Z9 12
U1 276
U2 387
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 0360-0300
EI 1557-7341
J9 ACM COMPUT SURV
JI ACM Comput. Surv.
PD APR
PY 2021
VL 54
IS 2
AR 31
DI 10.1145/3436755
PG 36
WC Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RT4QD
UT WOS:000644444900006
OA Green Published
DA 2022-04-17
ER

PT J
AU Benton, WC
AF Benton, William C.
TI Machine Learning Systems and Intelligent Applications
SO IEEE SOFTWARE
LA English
DT Article
DE Machine learning; Data models; Pipelines; Feature extraction; Training;
   Task analysis; Artificial Intelligence; machine learning; distributed
   applications
AB Machine learning techniques are useful in a wide range of contexts, but techniques alone are insufficient to solve real business problems. We introduce the intelligent applications concept, which characterizes the structure and responsibilities of contemporary machine learning systems.
C1 [Benton, William C.] Red Hat, Raleigh, NC 27601 USA.
RP Benton, WC (corresponding author), Red Hat, Raleigh, NC 27601 USA.
EM willb@acm.org
OI Benton, William/0000-0001-6295-5521
NR 15
TC 5
Z9 5
U1 82
U2 164
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0740-7459
EI 1937-4194
J9 IEEE SOFTWARE
JI IEEE Softw.
PD JUL-AUG
PY 2020
VL 37
IS 4
BP 43
EP 49
DI 10.1109/MS.2020.2985224
PG 7
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MB3WW
UT WOS:000542536700007
DA 2022-04-17
ER

PT J
AU Badr, A
AF Badr, Assem
TI Awesome back-propagation machine learning paradigm
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Neural network; Machine learning algorithms; Back-propagation
ID NETWORKS
AB For a better future in machine learning (ML), it is necessary to modify our current concepts to get the fastest ML. Many designers had attempted to find the optimal learning rates in their applications through many algorithms over the past decades, but they have not yet achieved their target of highest speed of back-propagation (BP). This research proposes a novel BP rule called the Instant Learning Ratios-Machine Learning (ILR-ML) or (ILRML). Unlike the traditional BP algorithms, the ILR-ML offers its learning without the concepts of the learning rate(s). The ILR-ML has a new concept called the "Learning Ratio" and indicated by a sign (Delta l). The ILR-ML performs the full BP algorithm with 100% accuracy per each learning iteration. The ILR-ML is more suitable for the online machine learning.
C1 [Badr, Assem] Modern Acad Engn & Technol, Comp Dept, Cairo, Egypt.
RP Badr, A (corresponding author), Modern Acad Engn & Technol, Comp Dept, Cairo, Egypt.
EM abmageed@eng.modern-academy.edu.eg
RI Badr, Assem/ABF-7545-2021
NR 35
TC 0
Z9 0
U1 5
U2 6
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD OCT
PY 2021
VL 33
IS 20
BP 13225
EP 13249
DI 10.1007/s00521-021-05951-6
EA APR 2021
PG 25
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WL7HG
UT WOS:000642260200010
DA 2022-04-17
ER

PT C
AU Kumar, RSS
   Nystrom, M
   Lambert, J
   Marshall, A
   Goertzel, M
   Comissoneru, A
   Swann, M
   Xia, S
AF Kumar, Ram Shankar Siva
   Nystrom, Magnus
   Lambert, John
   Marshall, Andrew
   Goertzel, Mario
   Comissoneru, Andi
   Swann, Matt
   Xia, Sharon
GP IEEE Comp Soc
TI Adversarial Machine Learning - Industry Perspectives
SO 2020 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2020)
LA English
DT Proceedings Paper
CT 41st IEEE Symposium on Security and Privacy (SP)
CY MAY 18-21, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc
DE adversarial machine learning; software security; engineering
AB Based on interviews with 28 organizations, we found that industry practitioners are not equipped with tactical and strategic tools to protect, detect and respond to attacks on their Machine Learning (ML) systems. We leverage the insights from the interviews and enumerate the gaps in securing machine learning systems when viewed in the context of traditional software security development. We write this paper from the perspective of two personas: developers/ML engineers and security incident responders. The goal of this paper is to layout the research agenda to amend the Security Development Lifecycle for industrial-grade software in the adversarial ML era.
C1 [Kumar, Ram Shankar Siva; Nystrom, Magnus; Lambert, John; Marshall, Andrew; Goertzel, Mario; Comissoneru, Andi; Swann, Matt; Xia, Sharon] Microsoft, Redmond, WA 98052 USA.
RP Kumar, RSS (corresponding author), Microsoft, Redmond, WA 98052 USA.
EM Ram.Shankar@microsoft.com; mnystrom@microsoft.com; johnla@microsoft.com;
   amarshal@microsoft.com; mariogo@microsoft.com; andic@microsoft.com;
   mswann@microsoft.com; shxia@microsoft.com
NR 43
TC 8
Z9 9
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
BN 978-1-7281-9346-5
PY 2020
BP 69
EP 75
DI 10.1109/SPW50608.2020.00028
PG 7
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR8ZR
UT WOS:000674766800010
OA Green Submitted, Bronze
DA 2022-04-17
ER

PT J
AU Chamikara, MAP
   Bertok, P
   Khalil, I
   Liu, D
   Camtepe, S
AF Chamikara, M. A. P.
   Bertok, P.
   Khalil, I.
   Liu, D.
   Camtepe, S.
TI Privacy preserving distributed machine learning with federated learning
SO COMPUTER COMMUNICATIONS
LA English
DT Article
DE Data privacy; Distributed data privacy; Privacy preserving machine
   learning; Distributed machine learning; Federated learning
ID DATA PERTURBATION; SURVEILLANCE; INFORMATION; SECURITY; SYSTEM
AB Edge computing and distributed machine learning have advanced to a level that can revolutionize a particular organization. Distributed devices such as the Internet of Things (IoT) often produce a large amount of data, eventually resulting in big data that can be vital in uncovering hidden patterns, and other insights in numerous fields such as healthcare, banking, and policing. Data related to areas such as healthcare and banking can contain potentially sensitive data that can become public if they are not appropriately sanitized. Federated learning (FedML) is a recently developed distributed machine learning (DML) approach that tries to preserve privacy by bringing the learning of an ML model to data owners' devices. However, literature shows different attack methods such as membership inference that exploit the vulnerabilities of ML models as well as the coordinating servers to retrieve private data. Hence, FedML needs additional measures to guarantee data privacy. Furthermore, big data often requires more resources than available in a standard computer. This paper addresses these issues by proposing a distributed perturbation algorithm named as DISTPAB, for privacy preservation of horizontally partitioned data. DISTPAB alleviates computational bottlenecks by distributing the task of privacy preservation utilizing the asymmetry of resources of a distributed environment, which can have resource-constrained devices as well as high-performance computers. Experiments show that DISTPAB provides high accuracy, high efficiency, high scalability, and high attack resistance. Further experiments on privacy-preserving FedML show that DISTPAB is an excellent solution to stop privacy leaks in DML while preserving high data utility.
C1 [Chamikara, M. A. P.; Bertok, P.; Khalil, I.] RMIT Univ, Melbourne, Vic, Australia.
   [Chamikara, M. A. P.; Liu, D.; Camtepe, S.] CSIRO Data61, Sydney, NSW, Australia.
RP Chamikara, MAP (corresponding author), RMIT Univ, Melbourne, Vic, Australia.; Chamikara, MAP (corresponding author), CSIRO Data61, Sydney, NSW, Australia.
EM pathumchamikara.mahawagaarachchige@rmit.edu.au
RI Chamikara, M.A.P./I-6127-2017; Camtepe, Seyit/E-6113-2013
OI Chamikara, M.A.P./0000-0002-4286-3774; Khalil,
   Ibrahim/0000-0001-5512-114X; Camtepe, Seyit/0000-0001-6353-8359
NR 60
TC 5
Z9 6
U1 13
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0140-3664
EI 1873-703X
J9 COMPUT COMMUN
JI Comput. Commun.
PD APR 1
PY 2021
VL 171
BP 112
EP 125
DI 10.1016/j.comcom.2021.02.014
EA FEB 2021
PG 14
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Telecommunications
GA TI1FR
UT WOS:000672528100011
OA Green Published, Green Submitted
DA 2022-04-17
ER

PT J
AU Brumen, B
   Cernezel, A
   Bosnjak, L
AF Brumen, Bostjan
   Cernezel, Ales
   Bosnjak, Leon
TI Overview of Machine Learning Process Modelling
SO ENTROPY
LA English
DT Article
DE data mining; machine learning; learning curves; learning process; power
   law
ID POWER-LAW
AB Much research has been conducted in the area of machine learning algorithms; however, the question of a general description of an artificial learner's (empirical) performance has mainly remained unanswered. A general, restrictions-free theory on its performance has not been developed yet. In this study, we investigate which function most appropriately describes learning curves produced by several machine learning algorithms, and how well these curves can predict the future performance of an algorithm. Decision trees, neural networks, Naive Bayes, and Support Vector Machines were applied to 130 datasets from publicly available repositories. Three different functions (power, logarithmic, and exponential) were fit to the measured outputs. Using rigorous statistical methods and two measures for the goodness-of-fit, the power law model proved to be the most appropriate model for describing the learning curve produced by the algorithms in terms of goodness-of-fit and prediction capabilities. The presented study, first of its kind in scale and rigour, provides results (and methods) that can be used to assess the performance of novel or existing artificial learners and forecast their 'capacity to learn' based on the amount of available or desired data.
C1 [Brumen, Bostjan; Cernezel, Ales; Bosnjak, Leon] Univ Maribor, Fac Elect Engn & Comp Sci, Koroska Cesta 46, Maribor 2000, Slovenia.
RP Brumen, B (corresponding author), Univ Maribor, Fac Elect Engn & Comp Sci, Koroska Cesta 46, Maribor 2000, Slovenia.
EM bostjan.brumen@um.si; ales.cernezel@gmail.com; leon.bosnjak@um.si
RI Brumen, Bostjan/K-8007-2013
OI Brumen, Bostjan/0000-0002-0560-1230
FU Slovenian Research AgencySlovenian Research Agency - Slovenia [P2-0057]
FX The authors acknowledge the financial support from the Slovenian
   Research Agency (research core funding No. P2-0057).
NR 41
TC 0
Z9 0
U1 9
U2 11
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1099-4300
J9 ENTROPY-SWITZ
JI Entropy
PD SEP
PY 2021
VL 23
IS 9
AR 1123
DI 10.3390/e23091123
PG 21
WC Physics, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Physics
GA UV6DT
UT WOS:000699567200001
PM 34573748
OA Green Published
DA 2022-04-17
ER

PT J
AU Clark, B
   Feinstein, Z
   Simaan, M
AF Clark, Brian
   Feinstein, Zachary
   Simaan, Majeed
TI A machine learning efficient frontier
SO OPERATIONS RESEARCH LETTERS
LA English
DT Article
DE Portfolio theory; Machine learning; Tactical asset allocation;
   Estimation risk
ID PORTFOLIO; REGULARIZATION; VOLATILITY; SELECTION
AB We propose a simple approach to bridge between portfolio theory and machine learning. The outcome is an out-of-sample machine learning efficient frontier based on two assets, high risk and low risk. By rotating between the two assets, we show that the proposed frontier dominates the mean-variance efficient frontier out-of-sample. Our results, therefore, shed important light on the appeal of machine learning into portfolio selection under estimation risk. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Clark, Brian] Rensselaer Polytech Inst, Lally Sch Management, 110 8th St,Pittsburgh Bldg, Troy, NY 12180 USA.
   [Feinstein, Zachary; Simaan, Majeed] Stevens Inst Technol, Sch Business, Babbio Ctr, 1 Castle Point Terrace, Hoboken, NJ 07030 USA.
RP Simaan, M (corresponding author), Stevens Inst Technol, Sch Business, Babbio Ctr, 1 Castle Point Terrace, Hoboken, NJ 07030 USA.
EM msimaan@stevens.edu
OI Simaan, Majeed/0000-0002-7758-6965
NR 14
TC 1
Z9 1
U1 3
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-6377
EI 1872-7468
J9 OPER RES LETT
JI Oper. Res. Lett.
PD SEP
PY 2020
VL 48
IS 5
BP 630
EP 634
DI 10.1016/j.orl.2020.07.016
PG 5
WC Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Operations Research & Management Science
GA NU8CF
UT WOS:000573865100017
DA 2022-04-17
ER

PT C
AU Villarroya, S
   Baumann, P
AF Villarroya, Sebastian
   Baumann, Peter
GP IEEE
TI On the Integration of Machine Learning and Array Databases
SO 2020 IEEE 36TH INTERNATIONAL CONFERENCE ON DATA ENGINEERING (ICDE 2020)
SE IEEE International Conference on Data Engineering
LA English
DT Proceedings Paper
CT IEEE 36th International Conference on Data Engineering (ICDE)
CY APR 20-24, 2020
CL Dallas, TX
SP IEEE, IEEE Comp Soc
DE array data; array database managers; machine learning; efficient array
   machine learning
AB Machine Learning is increasingly being applied to many different application domains. From cancer detection to weather forecast, a large number of different applications leverage machine learning algorithms to get faster and more accurate results over huge datasets. Although many of these datasets are mainly composed of array data, a vast majority of machine learning applications do not use array databases. This tutorial focuses on the integration of machine learning algorithms and array databases. By implementing machine learning algorithms in array databases users can boost the native efficient array data processing with machine learning methods to perform accurate and fast array data analytics.
C1 [Villarroya, Sebastian; Baumann, Peter] Jacobs Univ Bremen, Comp Sci & Elect Engn, Bremen, Germany.
RP Villarroya, S (corresponding author), Jacobs Univ Bremen, Comp Sci & Elect Engn, Bremen, Germany.
EM s.villarroyafernandez@jacobs-university.de;
   p.baumann@jacobs-university.de
RI Baumann, Peter/ABH-1702-2020
OI Baumann, Peter/0000-0003-3860-4726
FU German ministry of education and research (BMBF)Federal Ministry of
   Education & Research (BMBF) [01 IS 18047]
FX The work in this paper is part of the DeepRain project, funded by the
   German ministry of education and research (BMBF) under grant number 01
   IS 18047
NR 28
TC 1
Z9 1
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
SN 1084-4627
BN 978-1-7281-2903-7
J9 PROC INT CONF DATA
PY 2020
BP 1794
EP 1797
DI 10.1109/ICDE48307.2020.00170
PG 4
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ3CR
UT WOS:000584252700165
DA 2022-04-17
ER

PT J
AU Yang, C
   Wang, WF
   Zhang, YH
   Zhang, ZK
   Shen, LN
   Li, YP
   See, J
AF Yang, Cong
   Wang, Wenfeng
   Zhang, Yunhui
   Zhang, Zhikai
   Shen, Lina
   Li, Yipeng
   See, John
TI MLife: a lite framework for machine learning lifecycle initialization
SO MACHINE LEARNING
LA English
DT Article
DE Machine learning; Machine learning lifecycle; Machine learning system;
   Deep learning; Data flow
AB Machine learning (ML) lifecycle is a cyclic process to build an efficient ML system. Though a lot of commercial and community (non-commercial) frameworks have been proposed to streamline the major stages in the ML lifecycle, they are normally overqualified and insufficient for an ML system in its nascent phase. Driven by real-world experience in building and maintaining ML systems, we find that it is more efficient to initialize the major stages of ML lifecycle first for trial and error, followed by the extension of specific stages to acclimatize towards more complex scenarios. For this, we introduce a simple yet flexible framework, MLife, for fast ML lifecycle initialization. This is built on the fact that data flow in MLife is in a closed loop driven by bad cases, especially those which impact ML model performance the most but also provide the most value for further ML model development-a key factor towards enabling enterprises to fast track their ML capabilities. Better yet, MLife is also flexible enough to be easily extensible to more complex scenarios for future maintenance. For this, we introduce two real-world use cases to demonstrate that MLife is particularly suitable for ML systems in their early phases.
C1 [Yang, Cong; Wang, Wenfeng; Zhang, Yunhui; Zhang, Zhikai; Shen, Lina] Horizon Robot, Nanjing, Peoples R China.
   [Li, Yipeng] Clobot, Seattle, WA 98195 USA.
   [See, John] Heriot Watt Univ Malaysia, Putrajaya, Malaysia.
RP Li, YP (corresponding author), Clobot, Seattle, WA 98195 USA.
EM yipeng.li@outlook.com
FU Horizon Robotics under the Research Program of Smart Retail and Driver
   Monitoring System; CREST R&D Grant, Malaysia [T03C1-17]; Clobotics
FX The work is supported by the funding from Clobotics and Horizon Robotics
   under the Research Program of Smart Retail and Driver Monitoring System,
   respectively, and in part by CREST R&D Grant T03C1-17, Malaysia.
NR 32
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0885-6125
EI 1573-0565
J9 MACH LEARN
JI Mach. Learn.
PD DEC
PY 2021
VL 110
IS 11-12
BP 2993
EP 3013
DI 10.1007/s10994-021-06052-0
EA OCT 2021
PG 21
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XC3CN
UT WOS:000707305700002
PM 34664001
OA Bronze, Green Published
DA 2022-04-17
ER

PT C
AU Sanusi, IT
   Oyelere, SS
AF Sanusi, Ismaila Temitayo
   Oyelere, Solomon Sunday
GP IEEE
TI Pedagogies of Machine Learning in K-12 Context
SO 2020 IEEE FRONTIERS IN EDUCATION CONFERENCE (FIE 2020)
SE Frontiers in Education Conference
LA English
DT Proceedings Paper
CT IEEE Frontiers in Education Conference (FIE)
CY OCT 21-24, 2020
CL Uppsala, SWEDEN
SP IEEE, Amer Soc Engn Educ, Educ Res & Methods Div, IEEE Educ Soc, IEEE Comp Soc
DE pedagogy; machine learning; K-12; digital technologies; active learning
ID IMPLEMENTATION; FRAMEWORK
AB This research Full paper presents the pedagogies of machine learning in K-12. The new learning pedagogies and technologies are introduced with the aim of enhancing student engagement, experience and learning outcome. This study examined how machine learning has been taught in the recent past and further explores the ways and suitable approaches for K-12 context. Literatures on pedagogies associated with machine learning were reviewed to understand the dynamics and suitability of these pedagogies to support machine learning teaching. Though studies have explored pedagogies for machine learning in higher education context, few studies explored pedagogical strategies for teaching machine learning in K-12. In all, the pedagogies employed in teaching and learning of machine learning has not witnessed much research in literature. The pedagogical strategies revealed in the literature are mostly adopted in the higher education institutions to enable the of teaching machine learning concepts. The literature survey revealed several pedagogical strategies such as problem-based learning, project-based learning and collaborative learning used in higher education institutions. The revealed pedagogies suggest learners-centered approaches such as active learning, inquiry-based, participatory learning, design-oriented learning among others will be suitable for teaching machine learning in K-12 settings.
C1 [Sanusi, Ismaila Temitayo; Oyelere, Solomon Sunday] Univ Eastern Finland, Sch Comp, Joensuu, Finland.
RP Sanusi, IT (corresponding author), Univ Eastern Finland, Sch Comp, Joensuu, Finland.
EM ismails@uef.fi; solomon.oyelere@uef.fi
RI Sanusi, Ismaila Temitayo Temitayo/AAX-3164-2021
OI Sanusi, Ismaila Temitayo Temitayo/0000-0002-5705-6684
FU Jenny and Antti Wihuri Foundation
FX Work by author, Solomon Sunday Oyelere was supported by the Jenny and
   Antti Wihuri Foundation
NR 80
TC 1
Z9 1
U1 10
U2 10
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 0190-5848
BN 978-1-7281-8961-1
J9 PROC FRONT EDUC CONF
PY 2020
PG 8
WC Education, Scientific Disciplines; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Education & Educational Research; Engineering
GA BR3IP
UT WOS:000646660800249
DA 2022-04-17
ER

PT J
AU Hong, XB
   Guan, SU
   Man, KL
   Wong, PWH
AF Hong, Xianbin
   Guan, Sheng-Uei
   Man, Ka Lok
   Wong, Prudence W. H.
TI Lifelong Machine Learning Architecture for Classification
SO SYMMETRY-BASEL
LA English
DT Article
DE lifelong machine learning; continuous learning; sentiment
   classification; natural language processing
AB Benefiting from the rapid development of big data and high-performance computing, more data is available and more tasks could be solved by machine learning now. Even so, it is still difficult to maximum the power of big data due to each dataset is isolated with others. Although open source datasets are available, algorithms' performance is asymmetric with the data volume. Hence, the AI community wishes to raise a symmetric continuous learning architecture which can automatically learn and adapt to different tasks. Such a learning architecture also is commonly called as lifelong machine learning (LML). This learning paradigm could manage the learning process and accumulate meta-knowledge by itself during learning different tasks. The meta-knowledge is shared among all tasks symmetrically to help them to improve performance. With the growth of meta-knowledge, the performance of each task is expected to be better and better. In order to demonstrate the application of lifelong machine learning, this paper proposed a novel and symmetric lifelong learning approach for sentiment classification as an example to show how it adapts different domains and keeps efficiency meanwhile.
C1 [Hong, Xianbin; Guan, Sheng-Uei; Man, Ka Lok] Xian Jiaotong Liverpool Univ, Res Inst Big Data Analyt, Suzhou 215123, Peoples R China.
   [Wong, Prudence W. H.] Univ Liverpool, Dept Comp Sci, Liverpool L69 3BX, Merseyside, England.
RP Hong, XB (corresponding author), Xian Jiaotong Liverpool Univ, Res Inst Big Data Analyt, Suzhou 215123, Peoples R China.
EM Xianbin.Hong@xjtlu.edu.cn; Steven.Guan@xjtlu.edu.cn;
   Ka.Man@xjtlu.edu.cn; PWong@liverpool.ac.uk
RI Hong, Xianbin/AAQ-5875-2021
OI Hong, Xianbin/0000-0003-1678-0948; Guan, Steven
   Sheng-Uei/0000-0002-3968-9752
FU CERNET Innovation Project [NGII20161010]
FX This research was supported by the CERNET Innovation Project under Grant
   NGII20161010.
NR 46
TC 2
Z9 2
U1 5
U2 11
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2073-8994
J9 SYMMETRY-BASEL
JI Symmetry-Basel
PD MAY
PY 2020
VL 12
IS 5
AR 852
DI 10.3390/sym12050852
PG 29
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA LY0PO
UT WOS:000540226400170
OA gold
DA 2022-04-17
ER

PT J
AU Grzadzielewska, M
AF Grzadzielewska, Malgorzata
TI Using Machine Learning in Burnout Prediction: A Survey
SO CHILD AND ADOLESCENT SOCIAL WORK JOURNAL
LA English
DT Article
DE Machine learning; Supervised machine learning; Prediction; Burnout;
   Social work
AB Accurate prediction provides a number of important benefits for research and decision-making. Occupational burnout is intertwined with individual, cultural, and social factors, the resolution of which requires methods that can deal with large amounts of data. The application of such methods capable of dealing with large datasets is a relatively novel research area in social science. For this purpose, this article presents insights into machine learning methods, mainly related to prediction tasks. A brief review of these techniques in burnout domain was applied. It is shown that the choice of a method depends on the presence of certain dependent variables. This paper also presents a comparison between novel and traditional approaches, which shows that the appropriateness of a technique depends on the aim of the research. The theoretical and practical implications of using machine learning methods in this context is also presented in the paper. It is found that a gap in the study of burnout exists which requires the attention of social work researchers. Through machine learning techniques, new theoretical models of burnout can be created. These algorithms can also provide new approaches to create data-driven interventions. Burnout monitoring systems supported by machine-learning algorithms can also be used in recruitment processes and to supervise employees. Applying machine learning methods in reducing burnout can also provide socio-economic benefits such as help to reduce employee turnover and improve general working conditions.
C1 [Grzadzielewska, Malgorzata] Nicolaus Copernicus Univ, Ctr Family Res, Ul Lwowska 1, PL-87100 Torun, Poland.
RP Grzadzielewska, M (corresponding author), Nicolaus Copernicus Univ, Ctr Family Res, Ul Lwowska 1, PL-87100 Torun, Poland.
EM mgrzadzielewska@umk.pl
RI Grzadzielewska, Małgorzata/AAT-8091-2021
OI Grzadzielewska, Malgorzata/0000-0002-6070-2421
NR 56
TC 3
Z9 3
U1 5
U2 9
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0738-0151
EI 1573-2797
J9 CHILD ADOLESC SOC WO
JI Child Adolesc. Soc. Work J.
PD APR
PY 2021
VL 38
IS 2
SI SI
BP 175
EP 180
DI 10.1007/s10560-020-00733-w
EA JAN 2021
PG 6
WC Social Work
WE Social Science Citation Index (SSCI)
SC Social Work
GA RD3JV
UT WOS:000608003500001
OA hybrid
DA 2022-04-17
ER

PT J
AU Wang, HJ
   Zhang, LM
   Yin, KS
   Luo, HY
   Li, JH
AF Wang, Haojie
   Zhang, Limin
   Yin, Kesheng
   Luo, Hongyu
   Li, Jinhui
TI Landslide identification using machine learning
SO GEOSCIENCE FRONTIERS
LA English
DT Article
DE Landslide risk; Landslide identification; Machine learning; Deep
   learning; Big data; Convolutional neural networks
ID SPATIAL VARIABILITY; FORESTED LANDSLIDES; REGRESSION; INVENTORY;
   PREDICTION
AB Landslide identification is critical for risk assessment and mitigation. This paper proposes a novel machine-learning and deep-learning method to identify natural-terrain landslides using integrated geodatabases. First, landslide-related data are compiled, including topographic data, geological data and rainfall-related data. Then, three integrated geodatabases are established; namely, Recent Landslide Database (RecLD), Relict Landslide Database (RelLD) and Joint Landslide Database (JLD). After that, five machine learning and deep learning algorithms, including logistic regression (LR), support vector machine (SVM), random forest (RF), boosting methods and convolutional neural network (CNN), are utilized and evaluated on each database. A case study in Lantau, Hong Kong, is conducted to demonstrate the application of the proposed method. From the results of the case study, CNN achieves an identification accuracy of 92.5% on RecLD, and outperforms other algorithms due to its strengths in feature extraction and multi dimensional data processing. Boosting methods come second in terms of accuracy, followed by RF, LR and SVM. By using machine learning and deep learning techniques, the proposed landslide identification method shows outstanding robustness and great potential in tackling the landslide identification problem.
C1 [Wang, Haojie; Zhang, Limin; Yin, Kesheng; Luo, Hongyu] Hong Kong Univ Sci & Technol, Dept Civil & Environm Engn, Hong Kong, Peoples R China.
   [Li, Jinhui] Harbin Inst Technol Shenzhen, Dept Civil & Environm Engn, Shenzhen 518055, Peoples R China.
RP Zhang, LM (corresponding author), Hong Kong Univ Sci & Technol, Dept Civil & Environm Engn, Hong Kong, Peoples R China.
EM cezhangl@ust.hk
RI Wang, Haojie/ABC-1339-2020; Zhang, Li-Min/G-9891-2011
OI Zhang, Li-Min/0000-0001-7208-5515; Luo, Hongyu/0000-0002-2986-9418
FU Research Grants Council of the Hong Kong SAR GovernmentHong Kong
   Research Grants Council [16205719, AoE/E-603/18, 16206217]
FX This research is supported by the Research Grants Council of the Hong
   Kong SAR Government (Nos. 16205719, AoE/E-603/18 and 16206217). The
   authors would also like to thank the Geotechnical Engineering Office of
   Civil Engineering and Development Department for providing the DTM and
   landslide inventory data.
NR 35
TC 39
Z9 39
U1 99
U2 167
PU CHINA UNIV GEOSCIENCES, BEIJING
PI HAIDIAN DISTRICT
PA 29 XUEYUAN RD, HAIDIAN DISTRICT, 100083, PEOPLES R CHINA
SN 1674-9871
J9 GEOSCI FRONT
JI Geosci. Front.
PD JAN
PY 2021
VL 12
IS 1
BP 351
EP 364
DI 10.1016/j.gsf.2020.02.012
PG 14
WC Geosciences, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Geology
GA PD0QZ
UT WOS:000597401000025
HC Y
HP N
DA 2022-04-17
ER

PT C
AU Kannan, N
   Yeh, CYC
   Chou, CY
   Chan, TW
AF Kannan, N.
   Yeh, Charles Y. C.
   Chou, Chih-Yueh
   Chan, Tak-Wai
BE Rodrigo, MMT
   Iyer, S
   Mitrovic, A
TI A Machine Learning Approach to Estimating Student Mastery by Predicting
   Feedback Request and Solving Time in Online Learning System
SO 29TH INTERNATIONAL CONFERENCE ON COMPUTERS IN EDUCATION (ICCE 2021), VOL
   I
LA English
DT Proceedings Paper
CT 29th International Conference on Computers in Education (ICCE)
CY NOV 22-26, 2021
CL ELECTR NETWORK
SP Asia Pacific Soc Comp Educ, Thailand Natl Elect & Comp Technol Ctr, Khon Kaen Univ, Mae Fah Luang Univ, Khon Kaen Univ, Fac Educ, Artificial Intelligence Assoc Thailand, KMUTNB
DE Machine learning; prediction; regression; online learning system
AB One of the most significant challenges for computers in education is the capacity to provide intelligent and adaptable learning systems to meet the real needs of students. In order to create efficient adaptive or personalized mechanisms for educational content, student models are proposed to estimate the actual knowledge or mastery level of students. Some earlier student models were proposed to estimate student mastery based on the correctness (e.g., correct or incorrect) of responses, feedback request, and solving time using classical Markov process and logistic regression models. In particular, these models were applied to predicting student future correctness, feedback request, and solving time (i.e., on the next question). The advent of increasingly large-scale datasets has turned Machine Learning (ML) methods such as conventional machine-learning algorithms and deep learning models for prediction into competitive alternatives to classical Markov process and logistic regression models. In addition, prediction by ML methods has numerous advantages such as interpretability, good accuracy, ease of maintenance, less execution time, and appropriately handling of missing data. Moreover, recent studies exhibit the significant achievement of ML prediction methods for estimating students' performance and mastery using learning log data (i.e., correctness, feedback request level, solving time, etc.). Hence, it is reasonable to use ML methods to estimate student mastery by predicting the feedback request level and solving time. This study analyzed the data logged by an online learning system called Math-Island, which teaches elementary level mathematics by incorporating game mechanisms and scaffolding feedback. Machine-learning regression methods such as Multiple Linear Regression (MLR), Support Vector Regression (SVR), Random Forest Regression (RFR), Extra Trees (ET), and Gradient Boosting Regression (GBR) were applied. The results showed that RFR and GBR were found to outperform other models to predict future feedback request level and solving time. The results lead to several future works. First, incorporating ML predictive models into Math-Island tutoring system to identify the individual student's actual needs and; reduce learning loss substantially. Second, it drives to effectively build a more efficient adaptive mechanism within the current session to utilize students' active learning time.
C1 [Kannan, N.; Yeh, Charles Y. C.; Chan, Tak-Wai] Natl Cent Univ, Grad Inst Network Learning Technol, Taoyuan, Taiwan.
   [Chou, Chih-Yueh] Yuan Ze Univ, Dept Comp Sci & Engn, Taoyuan, Taiwan.
RP Kannan, N (corresponding author), Natl Cent Univ, Grad Inst Network Learning Technol, Taoyuan, Taiwan.
EM kannannataraj@g.ncu.edu.tw
FU Ministry of Science and Technology of the Republic of China,
   TaiwanMinistry of Science and Technology, Taiwan [MOST 109-2511-H-008
   -011 -MY3]; Research Center for Science and Technology for Learning,
   National Central University, Taiwan
FX The authors would like to thank the Ministry of Science and Technology
   of the Republic of China, Taiwan, for financial support (MOST
   109-2511-H-008 -011 -MY3), and Research Center for Science and
   Technology for Learning, National Central University, Taiwan. The
   authors would also like to thank all co-author for their assistance
   during this study.
NR 32
TC 0
Z9 0
U1 0
U2 0
PU ASIA PACIFIC SOC COMPUTERS IN EDUCATION
PI TAOYUAN CITY
PA NO 300, JUNGDA RD, JHONGLI DISTRICT, TAOYUAN CITY, 320, TAIWAN
BN 978-986-97214-7-9
PY 2021
BP 241
EP 250
PG 10
WC Computer Science, Interdisciplinary Applications; Education &
   Educational Research
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Education & Educational Research
GA BS8GL
UT WOS:000772144100035
DA 2022-04-17
ER

PT J
AU Jones, CM
   Buchlak, QD
   Oakden-Rayner, L
   Milne, M
   Seah, J
   Esmaili, N
   Hachey, B
AF Jones, Catherine M.
   Buchlak, Quinlan D.
   Oakden-Rayner, Luke
   Milne, Michael
   Seah, Jarrel
   Esmaili, Nazanin
   Hachey, Ben
TI Chest radiographs and machine learning - Past, present and future
SO JOURNAL OF MEDICAL IMAGING AND RADIATION ONCOLOGY
LA English
DT Review
DE chest X-ray; clinical decision support; deep learning; machine learning;
   radiomics
ID PULMONARY TUBERCULOSIS; ACCURACY; CLASSIFICATION; SOFTWARE; SCORE
AB Despite its simple acquisition technique, the chest X-ray remains the most common first-line imaging tool for chest assessment globally. Recent evidence for image analysis using modern machine learning points to possible improvements in both the efficiency and the accuracy of chest X-ray interpretation. While promising, these machine learning algorithms have not provided comprehensive assessment of findings in an image and do not account for clinical history or other relevant clinical information. However, the rapid evolution in technology and evidence base for its use suggests that the next generation of comprehensive, well-tested machine learning algorithms will be a revolution akin to early advances in X-ray technology. Current use cases, strengths, limitations and applications of chest X-ray machine learning systems are discussed.
C1 [Jones, Catherine M.; Milne, Michael] I MED Radiol Network, Brisbane, Qld, Australia.
   [Jones, Catherine M.; Buchlak, Quinlan D.; Milne, Michael; Seah, Jarrel; Hachey, Ben] Annalise Ai, Sydney, NSW, Australia.
   [Buchlak, Quinlan D.; Esmaili, Nazanin] Univ Notre Dame Australia, Sch Med, Sydney, NSW, Australia.
   [Buchlak, Quinlan D.; Seah, Jarrel; Hachey, Ben] Harrison Ai, Sydney, NSW, Australia.
   [Oakden-Rayner, Luke] Univ Adelaide, Australian Inst Machine Learning, Adelaide, SA, Australia.
   [Seah, Jarrel] Alfred Hlth, Dept Radiol, Melbourne, Vic, Australia.
   [Esmaili, Nazanin] Univ Technol Sydney, Fac Engn & Informat Technol, Sydney, NSW, Australia.
RP Buchlak, QD (corresponding author), Univ Notre Dame Australia, 160 Oxford St, Darlinghurst, NSW 2010, Australia.
EM quinlan.buchlak1@my.nd.edu.au
OI Seah, Jarrel/0000-0002-2305-7873
NR 53
TC 1
Z9 1
U1 2
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1754-9477
EI 1754-9485
J9 J MED IMAG RADIAT ON
JI J. Med. Imag. Radiat. Oncol.
PD AUG
PY 2021
VL 65
IS 5
SI SI
BP 538
EP 544
DI 10.1111/1754-9485.13274
EA JUN 2021
PG 7
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA TT2DX
UT WOS:000665694200001
PM 34169648
OA Green Published, hybrid
DA 2022-04-17
ER

PT J
AU Anita, CS
   Nagarajan, P
   Lakshminarayanan, E
   Sankar, MN
   Rishikanth, VR
AF Anita, C. S.
   Nagarajan, P.
   Lakshminarayanan, E.
   Sankar, M. Naveen
   Rishikanth, V. R.
TI Machine Vision and Machine Learning based Fruit Quality Monitoring
SO REVISTA GEINTEC-GESTAO INOVACAO E TECNOLOGIAS
LA English
DT Article
DE SVM; Machine Learning; Classification; Image Processing
AB The efficiency of the logistics of agricultural food needs to assure that its products are safe and of quality. This would earn the trust of consumers. To provide smart farming and packing solutions, the proposed work is an intelligent system using machine learning and image processing on Apple quality detection. The Apple image dataset was used with two stages of fruit, one is healthy and another one is damaged. The machine learning model is trained with this dataset to identify the the fruit quality. The proposed technique uses feature extraction using image processing technique and SVM algorithm is applied to train and detect the quality of fruit.
C1 [Anita, C. S.] RMD Engn Coll, Dept CSE, Kavaraipettai, India.
   [Nagarajan, P.] Rajalakshmi Inst Technol, Dept ECE, Chennai, Tamil Nadu, India.
   [Lakshminarayanan, E.; Sankar, M. Naveen; Rishikanth, V. R.] Cognizant Technol Solut, Chennai, Tamil Nadu, India.
RP Anita, CS (corresponding author), RMD Engn Coll, Dept CSE, Kavaraipettai, India.
EM csa.cse@rmd.ac.in; nagarajan.p@ritchennai.edu.in
RI pandian, nagarajan/AAZ-1559-2021
NR 8
TC 0
Z9 0
U1 4
U2 10
PU ASSOC ACAD PROPRIEDADE INTELECTUAL
PI ARACAJU
PA RUA JOSUE C CUNHA 395, DISTRICT COROA DO MEIO, ARACAJU, SERGIPE 00000,
   BRAZIL
SN 2237-0722
J9 REV GEINTEC
JI Rev. GEINTEC
PD APR-JUN
PY 2021
VL 11
IS 2
BP 836
EP 842
DI 10.47059/revistageintec.v11i2.1717
PG 7
WC Management
WE Emerging Sources Citation Index (ESCI)
SC Business & Economics
GA SO3RW
UT WOS:000658894000066
OA hybrid
DA 2022-04-17
ER

PT C
AU von Rueden, L
   Mayer, S
   Sifa, R
   Bauckhage, C
   Garcke, J
AF von Rueden, Laura
   Mayer, Sebastian
   Sifa, Rafet
   Bauckhage, Christian
   Garcke, Jochen
BE Berthold, MR
   Feelders, A
   Krempl, G
TI Combining Machine Learning and Simulation to a Hybrid Modelling
   Approach: Current and Future Directions
SO ADVANCES IN INTELLIGENT DATA ANALYSIS XVIII, IDA 2020
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 18th International Symposium on Intelligent Data Analysis (IDA)
CY APR 27-29, 2020
CL ELECTR NETWORK
DE Machine learning; Simulation; Hybrid approaches
AB In this paper, we describe the combination of machine learning and simulation towards a hybrid modelling approach. Such a combination of data-based and knowledge-based modelling is motivated by applications that are partly based on causal relationships, while other effects result from hidden dependencies that are represented in huge amounts of data. Our aim is to bridge the knowledge gap between the two individual communities from machine learning and simulation to promote the development of hybrid systems. We present a conceptual framework that helps to identify potential combined approaches and employ it to give a structured overview of different types of combinations using exemplary approaches of simulation-assisted machine learning and machine-learning assisted simulation. We also discuss an advanced pairing in the context of Industry 4.0 where we see particular further potential for hybrid systems.
C1 [von Rueden, Laura; Mayer, Sebastian; Sifa, Rafet; Bauckhage, Christian; Garcke, Jochen] Fraunhofer Ctr Machine Learning, St Augustin, Germany.
   [von Rueden, Laura; Sifa, Rafet; Bauckhage, Christian] Fraunhofer IAIS, St Augustin, Germany.
   [Mayer, Sebastian; Garcke, Jochen] Fraunhofer SCAI, St Augustin, Germany.
   [Garcke, Jochen] Univ Bonn, Inst Numer Simulat, Bonn, Germany.
RP von Rueden, L (corresponding author), Fraunhofer Ctr Machine Learning, St Augustin, Germany.; von Rueden, L (corresponding author), Fraunhofer IAIS, St Augustin, Germany.
EM laura.von.rueden@iais.fraunhofer.de
OI Mayer, Sebastian/0000-0002-1909-7805
NR 41
TC 9
Z9 9
U1 4
U2 4
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-44584-3; 978-3-030-44583-6
J9 LECT NOTES COMPUT SC
PY 2020
VL 12080
BP 548
EP 560
DI 10.1007/978-3-030-44584-3_43
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS4UM
UT WOS:000722624000043
OA hybrid
DA 2022-04-17
ER

PT J
AU Hugle, M
   Omoumi, P
   van Laar, JM
   Boedecker, J
   Hugle, T
AF Hugle, Maria
   Omoumi, Patrick
   van Laar, Jacob M.
   Boedecker, Joschka
   Hugle, Thomas
TI Applied machine learning and artificial intelligence in rheumatology
SO RHEUMATOLOGY ADVANCES IN PRACTICE
LA English
DT Review
DE machine learning; neural networks; deep learning; rheumatology;
   artificial intelligence
ID DEEP; OSTEOARTHRITIS
AB Machine learning as a field of artificial intelligence is increasingly applied in medicine to assist patients and physicians. Growing datasets provide a sound basis with which to apply machine learning methods that learn from previous experiences. This review explains the basics of machine learning and its subfields of supervised learning, unsupervised learning, reinforcement learning and deep learning. We provide an overview of current machine learning applications in rheumatology, mainly supervised learning methods for e-diagnosis, disease detection and medical image analysis. In the future, machine learning will be likely to assist rheumatologists in predicting the course of the disease and identifying important disease factors. Even more interestingly, machine learning will probably be able to make treatment propositions and estimate their expected benefit (e.g. by reinforcement learning). Thus, in future, shared decision-making will not only include the patient's opinion and the rheumatologist's empirical and evidence-based experience, but it will also be influenced by machine-learned evidence.
C1 [Hugle, Maria; Boedecker, Joschka] Univ Freiburg, Dept Comp Sci, Freiburg, Germany.
   [Omoumi, Patrick] Lausanne Univ Hosp, Dept Diagnost & Intervent Radiol, Lausanne, Switzerland.
   [Omoumi, Patrick; Hugle, Thomas] Univ Lausanne, Lausanne, Switzerland.
   [van Laar, Jacob M.] Univ Hosp Utrecht, Dept Rheumatol, Utrecht, Netherlands.
   [Hugle, Thomas] Lausanne Univ Hosp, Dept Rheumatol, Lausanne, Switzerland.
RP Hugle, T (corresponding author), CHU Vaudois, Univ Hosp Lausanne, Dept Rheumatol, Av Pierre Decker 4, CH-1011 Lausanne, Switzerland.
EM thomas.hugle@chuv.ch
NR 55
TC 27
Z9 27
U1 36
U2 57
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
EI 2514-1775
J9 RHEUMATOL ADV PRACT
JI Rheumatol. Adv. Pract.
PY 2020
VL 4
IS 1
AR rkaa005
DI 10.1093/rap/rkaa005
PG 10
WC Rheumatology
WE Emerging Sources Citation Index (ESCI)
SC Rheumatology
GA MO0VE
UT WOS:000551254000005
PM 32296743
OA Green Published, gold
DA 2022-04-17
ER

PT C
AU Alani, MM
AF Alani, Mohammed M.
BE Begusic, D
   Rozic, N
   Radic, J
   Saric, M
TI On Recent Security Issues in Machine Learning
SO 2020 28TH INTERNATIONAL CONFERENCE ON SOFTWARE, TELECOMMUNICATIONS AND
   COMPUTER NETWORKS (SOFTCOM)
SE International Conference on Software in Telecommunications and Computer
   Networks
LA English
DT Proceedings Paper
CT 28th International Conference on Software, Telecommunications and
   Computer Networks (SoftCOM)
CY SEP 17-19, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Commun Soc, IEEE Commun Soc, Croatia Chapter, Univ Split, Fac Elect Engn Mech Engn & Naval Architecture, Croatian Commun & Informat Soc, Croatian Acad Engn, IEEE Croatia Sect
DE machine learning; security; threat; attack; ai
ID ATTACKS
AB In recent years, applications of machine learning have grown rapidly in various areas. With the accelerating rate of data generation, and recent developments in big data analytics, machine learning has become a de facto standard in many applications that benefited the society in many areas. However, with the increasing number and types of machine learning applications, it has become a target for an increasing number of malicious actors. Security challenges became more complex and diverse in machine-learning-based systems.
   In this paper, we present a concise survey and discussion of the mechanisms employed by attackers to exploit vulnerabilities in machine learning algorithms or injecting malicious data. The paper focuses on most recent attacks reported in literature and discusses the methods proposed to counter these attacks and reduce their impact.
C1 [Alani, Mohammed M.] ACM, Abu Dhabi, U Arab Emirates.
RP Alani, MM (corresponding author), ACM, Abu Dhabi, U Arab Emirates.
EM m@alani.me
RI Alani, Mohammed M./M-4289-2019
OI Alani, Mohammed M./0000-0002-4324-1774
NR 35
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1848-1744
BN 978-953-290-099-6
J9 INT CONF SOFTW
PY 2020
BP 384
EP 389
PG 6
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Telecommunications
GA BR3CD
UT WOS:000644442300069
DA 2022-04-17
ER

PT J
AU Guijo-Rubio, D
   Gutierrez, PA
   Hervas-Martinez, C
AF Guijo-Rubio, David
   Antonio Gutierrez, Pedro
   Hervas-Martinez, Cesar
TI Machine learning methods in organ transplantation
SO CURRENT OPINION IN ORGAN TRANSPLANTATION
LA English
DT Review
DE artificial intelligence; machine learning; organ transplantation
ID ARTIFICIAL NEURAL-NETWORKS; GRAFT-SURVIVAL; RECIPIENTS
AB Purpose of reviewMachine learning techniques play an important role in organ transplantation. Analysing the main tasks for which they are being applied, together with the advantages and disadvantages of their use, can be of crucial interest for clinical practitioners.Recent findingsIn the last 10 years, there has been an explosion of interest in the application of machine-learning techniques to organ transplantation. Several approaches have been proposed in the literature aiming to find universal models by considering multicenter cohorts or from different countries. Moreover, recently, deep learning has also been applied demonstrating a notable ability when dealing with a vast amount of information.SummaryOrgan transplantation can benefit from machine learning in such a way to improve the current procedures for donor--recipient matching or to improve standard scores. However, a correct preprocessing is needed to provide consistent and high quality databases for machine-learning algorithms, aiming to robust and fair approaches to support expert decision-making systems.
C1 [Guijo-Rubio, David; Antonio Gutierrez, Pedro; Hervas-Martinez, Cesar] Univ Cordoba, Dept Comp Sci & Numer Anal, Rabanales Campus,Albert Einstein Bldg,3rd Floor, Cordoba 14014, Spain.
RP Hervas-Martinez, C (corresponding author), Univ Cordoba, Dept Comp Sci & Numer Anal, Rabanales Campus,Albert Einstein Bldg,3rd Floor, Cordoba 14014, Spain.
EM chervas@uco.es
RI Gutiérrez, Pedro Antonio/K-6051-2014; Guijo-Rubio, David/AAT-6335-2021
OI Gutiérrez, Pedro Antonio/0000-0002-2657-776X; Guijo-Rubio,
   David/0000-0002-8035-4057
FU FEDER fundsEuropean Commission; Spanish Ministry of Economy and
   CompetitivenessSpanish Government [TIN2017-85887-C21-P]; Fundacion de
   Investigacion Biomedica de Cordoba (FIBICO) [PI15/01570]; Spanish
   Ministry of Education and Science, FPU Predoctoral ProgramGerman
   Research Foundation (DFG) [FPU16/02128]
FX FEDER funds and Spanish Ministry of Economy and Competitiveness, grant
   reference: TIN2017-85887-C21-P. Fundacion de Investigacion Biomedica de
   Cordoba (FIBICO), grant reference: PI15/01570. David GuijoRubio's
   research: Spanish Ministry of Education and Science, FPU Predoctoral
   Program, grant reference FPU16/02128.
NR 39
TC 0
Z9 0
U1 0
U2 1
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 1087-2418
EI 1531-7013
J9 CURR OPIN ORGAN TRAN
JI Curr. Opin. Organ Transpl.
PD AUG
PY 2020
VL 25
IS 4
BP 399
EP 405
DI 10.1097/MOT.0000000000000774
PG 7
WC Transplantation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Transplantation
GA NC5YH
UT WOS:000561293200015
PM 32618714
DA 2022-04-17
ER

PT J
AU Monteiro, JP
   Ramos, D
   Carneiro, D
   Duarte, F
   Fernandes, JM
   Novais, P
AF Monteiro, Jose Pedro
   Ramos, Diogo
   Carneiro, Davide
   Duarte, Francisco
   Fernandes, Joao M.
   Novais, Paulo
TI Meta-learning and the new challenges of machine learning
SO INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS
LA English
DT Article
DE meta-learning; machine learning; algorithm selection; streaming machine
   learning
ID ALGORITHM SELECTION
AB In the last years, organizations and companies in general have found the true potential value of collecting and using data for supporting decision-making. As a consequence, data are being collected at an unprecedented rate. This poses several challenges, including, for example, regarding the storage and processing of these data. Machine Learning (ML) is also not an exception, in the sense that algorithms must now deal with novel challenges, such as learn from streaming data or deal with concept drift. ML engineers also have a harder task when it comes to selecting the most appropriate model, given the wealth of algorithms and possible configurations that exist nowadays. At the same time, training time is a stronger restriction as the computational complexity of the training model increases. In this paper we propose a framework for dealing with these challenges, based on meta-learning. Specifically, we tackle two well-defined problems: automatic algorithm selection and continuous algorithm updates that do not require the retraining of the whole algorithm to adapt to new data. Results show that the proposed framework can contribute to ameliorate the identified issues.
C1 [Monteiro, Jose Pedro; Carneiro, Davide; Duarte, Francisco; Fernandes, Joao M.; Novais, Paulo] Univ Minho, Algoritmi Ctr, Dept Informat, Felgueiras, Portugal.
   [Ramos, Diogo; Carneiro, Davide] Politecn Porto, CIICESI, ESTG, Felgueiras, Portugal.
RP Carneiro, D (corresponding author), Escola Super Tecnol & Gestao, Rua Curral, P-4610156 Felgueiras, Portugal.
EM dcarneiro@estg.ipp.pt
RI Novais, Paulo/M-4053-2013; Carneiro, Davide/A-3490-2014; Duarte,
   Francisco J./B-6197-2009
OI Novais, Paulo/0000-0002-3549-0754; Carneiro, Davide/0000-0002-6650-0388;
   Fernandes, Joao M./0000-0003-1174-1966; Monteiro, Jose
   Pedro/0000-0003-3977-4786; Duarte, Francisco J./0000-0001-9270-2226
FU Fundacao para a Ciencia e a TecnologiaPortuguese Foundation for Science
   and TechnologyEuropean Commission [UIDB/04728/ 2020,
   UID/CEC/00319/2019]; European Regional Development FundEuropean
   Commission [31/SI/2017, 39900]
FX Fundacao para a Ciencia e a Tecnologia, Grant/Award Numbers: UIDB/04728/
   2020, UID/CEC/00319/2019; European Regional Development Fund,
   Grant/Award Number: 31/SI/2017 Proj. No. 39900
NR 47
TC 0
Z9 0
U1 2
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0884-8173
EI 1098-111X
J9 INT J INTELL SYST
JI Int. J. Intell. Syst.
PD NOV
PY 2021
VL 36
IS 11
BP 6240
EP 6272
DI 10.1002/int.22549
EA JUN 2021
PG 33
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UU2VS
UT WOS:000668245900001
DA 2022-04-17
ER

PT C
AU Mensik, M
   Duzi, M
   Albert, A
   Patschka, V
   Pajr, M
AF Mensik, Marek
   Duzi, Marie
   Albert, Adam
   Patschka, Vojtech
   Pajr, Miroslav
BE Dahanayake, A
   Huiskonen, J
   Kiyoki, Y
   Thalheim, B
   Jaakkola, H
   Yoshida, N
TI Machine Learning Using TIL
SO INFORMATION MODELLING AND KNOWLEDGE BASES XXXI
SE Frontiers in Artificial Intelligence and Applications
LA English
DT Proceedings Paper
CT 29th International Conference on Information Modeling and Knowledge
   Bases (EJC)
CY JUN 03-07, 2019
CL Lappeenranta, FINLAND
DE Machine learning; Transparent Intensional Logic; TIL; generalization;
   specialization; hypothesis; heuristics
ID COMMUNICATION
AB In this paper we deal with machine learning methods and algorithms applied to the area of geographic data. First, we briefly introduce learning with a supervisor that is applied in our case. Then we describe the algorithm 'Framework' together with heuristic methods used in it. Definitions of particular geographic objects, i.e. their concepts, are formulated in our background theory Transparent Intensional Logic (TIL) as TIL constructions. These concepts serve as general hypotheses. Basic principles of supervised machine learning are generalization and specialization. Given a positive example, the learner generalizes, while after a near-miss example specialization is applied. Heuristic methods deal with the way generalization and specialization are applied.
C1 [Mensik, Marek; Duzi, Marie; Albert, Adam; Patschka, Vojtech] VSB Tech Univ Ostrava, Dept Comp Sci FEI, 17 Listopadu 15, Ostrava 70833, Czech Republic.
   [Pajr, Miroslav] Silesian Univ Opava, Inst Comp Sci, Bezrucovo Nam 13, Opava 74601, Czech Republic.
RP Mensik, M (corresponding author), VSB Tech Univ Ostrava, Dept Comp Sci FEI, 17 Listopadu 15, Ostrava 70833, Czech Republic.
RI Mensik, Marek/C-1329-2013; Albert, Adam/AAR-7647-2021
OI Mensik, Marek/0000-0001-9482-3777
FU Grant Agency of the Czech RepublicGrant Agency of the Czech Republic
   [GA18-23891S]
FX This research has been supported by the Grant Agency of the Czech
   Republic, project No. GA18-23891S, "Hyperintensional Reasoning over
   Natural Language Texts".
NR 14
TC 1
Z9 1
U1 0
U2 0
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 0922-6389
EI 1879-8314
BN 978-1-64368-045-3; 978-1-64368-044-6
J9 FRONT ARTIF INTEL AP
PY 2020
VL 321
BP 344
EP 362
DI 10.3233/FAIA200024
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Software Engineering; Computer Science,
   Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR0GB
UT WOS:000628990500023
DA 2022-04-17
ER

PT C
AU Thurner, V
   Sickendiek, J
AF Thurner, Veronika
   Sickendiek, Johanna
BE Auer, ME
   Ruutmann, T
TI STEM4Girls-Workshop on Machine Learning
SO EDUCATING ENGINEERS FOR FUTURE INDUSTRIAL REVOLUTIONS, ICL2020, VOL 1
SE Advances in Intelligent Systems and Computing
LA English
DT Proceedings Paper
CT 23rd International Conference on Interactive Collaborative Learning
   (ICL) / 49th IGIP International Conference on Engineering Pedagogy -
   Educating Engineers for Future Industrial Revolutions
CY SEP 23-25, 2020
CL ELECTR NETWORK
SP IGIP, Univ Technol Tallinn
DE Gender gap; Girls in CS; K12 education; STEM education; Machine learning
AB Although female specialists in the STEM area are urgently needed in the work force, the percentage of women in STEM study programs in higher education is still rather low. One reason for this are gender-related stereotypes that still persist in many modern cultures, which associate STEM as being a "male" domain. To actively draw young women towards STEM and Computer Science, we design a workshop for girls in the age group of 10th grade in secondary education. This workshop introduces the girls to machine learning in the application context of fashion and shopping. We define both cognitive and affective learning objectives and corresponding observable outcomes that indicate whether the learning objectives were reached or not. Based on these learning objectives, we develop a didactic concept for our workshop, as well as a web application as a front end for the machine learning application. Finally, we execute a pilot run of our workshop, which we evaluate with respect to participant satisfaction and the achievement of the learning objectives.
C1 [Thurner, Veronika; Sickendiek, Johanna] Munich Univ Appl Sci, Munich, Germany.
RP Thurner, V (corresponding author), Munich Univ Appl Sci, Munich, Germany.
EM veronika.thurner@hm.edu; johanna.sickendiek@gmail.com
NR 8
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2194-5357
EI 2194-5365
BN 978-3-030-68198-2; 978-3-030-68197-5
J9 ADV INTELL SYST COMP
PY 2021
VL 1328
BP 744
EP 755
DI 10.1007/978-3-030-68198-2_70
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Education, Scientific Disciplines; Engineering, Industrial
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Education & Educational Research; Engineering
GA BS8HY
UT WOS:000772389500070
DA 2022-04-17
ER

PT J
AU Rodrigues, S
   Mutter, G
   Ramos, HG
   Morgado-Dias, F
AF Rodrigues, Sandy
   Muetter, Gerhard
   Ramos, Helena Geirinhas
   Morgado-Dias, F.
TI Machine Learning Photovoltaic String Analyzer
SO ENTROPY
LA English
DT Article
DE machine learning prediction models; PV string; PV fault; hybrid
   methodology; ensemble methodology
AB Photovoltaic (PV) system energy production is non-linear because it is influenced by the random nature of weather conditions. The use of machine learning techniques to model the PV system energy production is recommended since there is no known way to deal well with non-linear data. In order to detect PV system faults, the machine learning models should provide accurate outputs. The aim of this work is to accurately predict the DC energy of six PV strings of a utility-scale PV system and to accurately detect PV string faults by benchmarking the results of four machine learning methodologies known to improve the accuracy of the machine learning models, such as the data mining methodology, machine learning technique benchmarking methodology, hybrid methodology, and the ensemble methodology. A new hybrid methodology is proposed in this work which combines the use of a fuzzy system and the use of a machine learning system containing five different trained machine learning models, such as the regression tree, artificial neural networks, multi-gene genetic programming, Gaussian process, and support vector machines for regression. The results showed that the hybrid methodology provided the most accurate machine learning predictions of the PV string DC energy, and consequently the PV string fault detection is successful.
C1 [Rodrigues, Sandy; Ramos, Helena Geirinhas] Univ Lisbon, Inst Super Tecn, Inst Telecomunicacoes, P-1049001 Lisbon, Portugal.
   [Rodrigues, Sandy; Morgado-Dias, F.] Madeira Interact Technol M ITI, Lab Robot & Syst Engn LARSyS, P-9020105 Funchal, Portugal.
   [Rodrigues, Sandy; Morgado-Dias, F.] Inst & Interact Technol Inst ITI, P-9020105 Funchal, Portugal.
   [Muetter, Gerhard] ALTESO GmbH, A-1010 Vienna, Austria.
   [Morgado-Dias, F.] Univ Madeira, Fac Exact Sci & Engn, P-9020105 Funchal, Portugal.
RP Rodrigues, S (corresponding author), Univ Lisbon, Inst Super Tecn, Inst Telecomunicacoes, P-1049001 Lisbon, Portugal.; Rodrigues, S (corresponding author), Madeira Interact Technol M ITI, Lab Robot & Syst Engn LARSyS, P-9020105 Funchal, Portugal.; Rodrigues, S (corresponding author), Inst & Interact Technol Inst ITI, P-9020105 Funchal, Portugal.
EM sandycarmo@hotmail.com; muetter@alteso.at; hgramos@ist.utl.pt;
   morgado@uma.pt
RI Ramos, Helena/G-1059-2010; Morgado Dias, Fernando/J-7770-2012;
   Rodrigues, Sandy/F-1399-2015
OI Ramos, Helena/0000-0002-4931-7960; Morgado Dias,
   Fernando/0000-0001-7334-3993; Rodrigues, Sandy/0000-0003-1989-4852
FU ARDITI (Agencia Regional para o Desenvolvimento da Investigacao,
   Tecnologia e Inovacao) [M1420-09-5369-FSE-000001]; Portuguese Science
   and Technology Foundation (FCT)Portuguese Foundation for Science and
   Technology [LA 9 -UID/EEA/50009/2019, UID/EEA/50008/2013,
   UID/EEA/50008/2019]; Fundacao para a Ciencia e a Tecnologia
   (FCT)Portuguese Foundation for Science and TechnologyEuropean Commission
   [UID/CEC/50021/2013, SFRH/BSAB/136312/2018]
FX The PhD Grant financial support from ARDITI (Agencia Regional para o
   Desenvolvimento da Investigacao, Tecnologia e Inovacao) under the scope
   of the project M1420-09-5369-FSE-000001, is gratefully appreciated.
   Acknowledgments to the Portuguese Science and Technology Foundation
   (FCT) for their support through Projeto Estrategico LA 9
   -UID/EEA/50009/2019. This work was also developed under the Instituto de
   Telecomunicacoes and it was supported in part by the Portuguese Science
   and Technology Foundation (FCT) projects: UID/EEA/50008/2013 and
   UID/EEA/50008/2019. This support is gratefully acknowledged. This work
   was also supported by national funds through Fundacao para a Ciencia e a
   Tecnologia (FCT) under reference UID/CEC/50021/2013 and grant
   SFRH/BSAB/136312/2018.
NR 12
TC 1
Z9 1
U1 3
U2 5
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1099-4300
J9 ENTROPY-SWITZ
JI Entropy
PD FEB
PY 2020
VL 22
IS 2
AR 205
DI 10.3390/e22020205
PG 18
WC Physics, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Physics
GA KW7NM
UT WOS:000521371400105
PM 33285980
OA gold, Green Published
DA 2022-04-17
ER

PT C
AU Mohamed-Iliasse, M
   Loubna, B
   Abdelaziz, B
AF Mohamed-Iliasse, Mahraz
   Loubna, Benabbou
   Abdelaziz, Berrado
BE Benadada, Y
   Mhada, FZ
TI Is Machine Learning Revolutionizing Supply Chain?
SO GOL'20: 2020 5TH INTERNATIONAL CONFERENCE ON LOGISTICS OPERATIONS
   MANAGEMENT (GOL)
LA English
DT Proceedings Paper
CT 5th IEEE International Conference on Logistics Operations Management
   (GOL)
CY OCT 28-30, 2020
CL ELECTR NETWORK
SP Univ Havre Normandy, Univ Mohammed V Rabat, ENSIAS Sch, IEEE, IEEE Morocco Sect, CNRST, Moroccan Assoc Logist Chain, Sidi Mohamed Abdellah Univ, FST
DE Supply chain; Machine Learning; Digital Transformation
ID ARTIFICIAL-INTELLIGENCE; MODEL; INVENTORY; MANAGEMENT; ALGORITHM;
   FRAMEWORK; POLICIES
AB The current supply chain ecosystem benefits from a great dynamic: the digitalization of companies and exchanges. For all the players in the sector, this is a real revolution, and machine learning is at the heart of this revolution. It has radically transformed companies: the evolution of communication media, the automation of many processes, the growing importance of information systems, etc. However, this fundamental transformation of work environments and organizational modes is far from over. In the current economic context of globalization of trade and increased competition, the greatest attention is focused on the objective of continuously reducing cost prices. Optimization requires efforts from all links in the supply chain to ensure very fine management. In this context, machine learning and the data on which it is based, is a real opportunity. In more recent years, a series of practical supply chain applications of machine learning (ML) have been introduced. By interconnecting the ML methods applied to the SC, the document indicates current SC applications and visualizes potential research gaps. In this article, we examine the applicability of machine learning techniques to the supply chain. The main objective of this paper is therefore to study how Machine Learning can be integrated into the range of tools available to Supply Chain decision-makers to take advantage of the increase in the volume of available data, through these tools particularly adapted to this type of processing.
C1 [Mohamed-Iliasse, Mahraz; Abdelaziz, Berrado] Mohamed V Univ, Ecole Mohammadia Ingn, Res Team AMIPS, Rabat, Morocco.
   [Loubna, Benabbou] Univ Quebec Rimouski, Dept Management Sci, Levis, PQ, Canada.
RP Mohamed-Iliasse, M (corresponding author), Mohamed V Univ, Ecole Mohammadia Ingn, Res Team AMIPS, Rabat, Morocco.
EM m.mahraz@hotmail.fr; loubna_benabbou@uqar.ca; berrado@emi.ac.ma
NR 50
TC 1
Z9 1
U1 9
U2 14
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-6425-0
PY 2020
BP 39
EP 48
DI 10.1109/GOL49479.2020.9314713
PG 10
WC Engineering, Electrical & Electronic; Operations Research & Management
   Science
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering; Operations Research & Management Science
GA BS0BB
UT WOS:000680722500007
DA 2022-04-17
ER

PT J
AU Alenezi, HS
   Faisal, MH
AF Alenezi, Hadeel S.
   Faisal, Maha H.
TI Utilizing crowdsourcing and machine learning in education: Literature
   review
SO EDUCATION AND INFORMATION TECHNOLOGIES
LA English
DT Review
DE Machine learning; Crowdsourcing; Education; E-learning
AB For many years, learning continues to be a vital developing field since it is the key measure of the world's civilization and evolution with its enormous effect on both individuals and societies. Enhancing existing learning activities in general will have a significant impact on literacy rates around the world. One of the crucial activities in education is the assessment method because it is the primary way used to evaluate the student during their studies. The main purpose of this review is to examine the existing learning and e-learning approaches that use either crowdsourcing, machine learning, or both crowdsourcing and machine learning in their proposed solutions. This review will also investigate the addressed applications to identify the existing researches related to the assessment. Identifying all existing applications will assist in finding the unexplored gaps and limitations. This study presents a systematic literature review investigating 30 papers from the following databases: IEEE and ACM Digital Library. After performing the analysis, we found that crowdsourcing is utilized in 47.8% of the investigated learning activities, while each of the machine learning and the hybrid solutions are utilized in 26% of the investigated learning activities. Furthermore, all the existing approaches regarding the exam assessment problem that are using machine learning or crowdsourcing were identified. Some of the existing assessment systems are using the crowdsourcing approach and other systems are using the machine learning, however, none of the approaches provide a hybrid assessment system that uses both crowdsourcing and machine learning. Finally, it is found that using either crowdsourcing or machine learning in the online courses will enhance the interactions between the students. It is concluded that the current learning activities need to be enhanced since it is directly affecting the student's performance. Moreover, merging both the machine learning to the crowd wisdom will increase the accuracy and the efficiency of education.
C1 [Alenezi, Hadeel S.; Faisal, Maha H.] Kuwait Univ, Dept Comp Engn, Kuwait, Kuwait.
RP Alenezi, HS (corresponding author), Kuwait Univ, Dept Comp Engn, Kuwait, Kuwait.
EM hadeel.alenezi@grad.ku.edu.kw; maha.faisal@ku.edu.kw
RI Faisal, Maha/O-5923-2019
OI Faisal, Maha/0000-0001-8074-5456; Alenezi, Hadeel/0000-0002-3774-368X
NR 38
TC 7
Z9 7
U1 15
U2 32
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1360-2357
EI 1573-7608
J9 EDUC INF TECHNOL
JI Educ. Inf. Technol.
PD JUL
PY 2020
VL 25
IS 4
BP 2971
EP 2986
DI 10.1007/s10639-020-10102-w
PG 16
WC Education & Educational Research
WE Social Science Citation Index (SSCI)
SC Education & Educational Research
GA ME9JM
UT WOS:000544969800031
DA 2022-04-17
ER

PT J
AU Roland, T
   Bock, C
   Tschoellitsch, T
   Maletzky, A
   Hochreiter, S
   Meier, J
   Klambauer, G
AF Roland, Theresa
   Boeck, Carl
   Tschoellitsch, Thomas
   Maletzky, Alexander
   Hochreiter, Sepp
   Meier, Jens
   Klambauer, Guenter
TI Domain Shifts in Machine Learning Based Covid-19 Diagnosis From Blood
   Tests
SO JOURNAL OF MEDICAL SYSTEMS
LA English
DT Article
DE Machine learning; Domain shift; COVID-19; Blood test
ID ADAPTATION; INFECTION
AB Many previous studies claim to have developed machine learning models that diagnose COVID-19 from blood tests. However, we hypothesize that changes in the underlying distribution of the data, so called domain shifts, affect the predictive performance and reliability and are a reason for the failure of such machine learning models in clinical application. Domain shifts can be caused, e.g., by changes in the disease prevalence (spreading or tested population), by refined RT-PCR testing procedures (way of taking samples, laboratory procedures), or by virus mutations. Therefore, machine learning models for diagnosing COVID-19 or other diseases may not be reliable and degrade in performance over time. We investigate whether domain shifts are present in COVID-19 datasets and how they affect machine learning methods. We further set out to estimate the mortality risk based on routinely acquired blood tests in a hospital setting throughout pandemics and under domain shifts. We reveal domain shifts by evaluating the models on a large-scale dataset with different assessment strategies, such as temporal validation. We present the novel finding that domain shifts strongly affect machine learning models for COVID-19 diagnosis and deteriorate their predictive performance and credibility. Therefore, frequent re-training and re-assessment are indispensable for robust models enabling clinical utility.
C1 [Roland, Theresa; Hochreiter, Sepp; Klambauer, Guenter] Johannes Kepler Univ Linz, Inst Machine Learning, ELLIS Unit Linz, LIT AI Lab, Linz, Austria.
   [Boeck, Carl; Tschoellitsch, Thomas; Meier, Jens] Johannes Kepler Univ Linz, Kepler Univ Hosp GmbH, Dept Anesthesiol & Crit Care Med, Linz, Austria.
   [Maletzky, Alexander] RISC Software GmbH, Hagenberg Im, Austria.
RP Roland, T (corresponding author), Johannes Kepler Univ Linz, Inst Machine Learning, ELLIS Unit Linz, LIT AI Lab, Linz, Austria.
EM theresa.roland@jku.at
OI Maletzky, Alexander/0000-0003-4378-7854; Klambauer,
   Gunter/0000-0003-2861-5552; Hochreiter, Sepp/0000-0001-7449-2528
FU project Medical Cognitive Computing Center [Wi-2018-439843]; project
   AI-MOTION [LIT-2018-6-YOU-212]; project AI-SNN [LIT-2018-6-YOU-214];
   project Deep-Flood [LIT-2019-8-YOU-213]; project PRIMAL [FFG-873979];
   project S3AI [FFG-872172]; project DL for granular flow [FFG-871302];
   project ELISE ( H2020-ICT-2019-3) [951847]; project AIDD (MSCA-ITN-2020)
   [956832]
FX We thank the projects Medical Cognitive Computing Center
   (Wi-2018-439843) and AI-MOTION (LIT-2018-6-YOU-212), AI-SNN
   (LIT-2018-6-YOU-214), Deep-Flood (LIT-2019-8-YOU-213), PRIMAL
   (FFG-873979), S3AI (FFG-872172), DL for granular flow (FFG-871302),
   ELISE (H2020-ICT-2019-3 ID: 951847), AIDD (MSCA-ITN-2020 ID: 956832). We
   thank Janssen Pharmaceutica, UCB Bio-pharma SRL, Merck Healthcare KGaA,
   Audi.JKU Deep Learning Center, TGW LOGISTICS GROUP GMBH, Silicon Austria
   Labs (SAL), FILL Gesellschaft mbH, Anyline GmbH, Google, ZF
   Friedrichshafen AG, Robert Bosch GmbH, Software Competence Center
   Hagenberg GmbH, TuV Austria, and the NVIDIA Corporation. We thank Franz
   Grandits, Innosol for the daily download of the age distribution data of
   the newly infected COVID-19 patients from BMSGPK.
NR 67
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0148-5598
EI 1573-689X
J9 J MED SYST
JI J. Med. Syst.
PD MAR 29
PY 2022
VL 46
IS 5
AR 23
DI 10.1007/s10916-022-01807-1
PG 12
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Health Care Sciences & Services; Medical Informatics
GA 0B8MB
UT WOS:000774881200001
PM 35348909
OA hybrid, Green Published
DA 2022-04-17
ER

PT J
AU Mainali, S
   Darsie, ME
   Smetana, KS
AF Mainali, Shraddha
   Darsie, Marin E.
   Smetana, Keaton S.
TI Machine Learning in Action: Stroke Diagnosis and Outcome Prediction
SO FRONTIERS IN NEUROLOGY
LA English
DT Review
DE machine learning; artificial intelligence; deep learning; stroke
   diagnosis; stroke prognosis; stroke outcome prediction; machine learning
   in medical imaging; machine learning in medicine
ID HEALTH-CARE PROFESSIONALS; ACUTE ISCHEMIC-STROKE; EARLY MANAGEMENT; 2018
   GUIDELINES; BIG DATA; MRI; THROMBOLYSIS; ASSOCIATION; HEMORRHAGE;
   ALGORITHM
AB The application of machine learning has rapidly evolved in medicine over the past decade. In stroke, commercially available machine learning algorithms have already been incorporated into clinical application for rapid diagnosis. The creation and advancement of deep learning techniques have greatly improved clinical utilization of machine learning tools and new algorithms continue to emerge with improved accuracy in stroke diagnosis and outcome prediction. Although imaging-based feature recognition and segmentation have significantly facilitated rapid stroke diagnosis and triaging, stroke prognostication is dependent on a multitude of patient specific as well as clinical factors and hence accurate outcome prediction remains challenging. Despite its vital role in stroke diagnosis and prognostication, it is important to recognize that machine learning output is only as good as the input data and the appropriateness of algorithm applied to any specific data set. Additionally, many studies on machine learning tend to be limited by small sample size and hence concerted efforts to collate data could improve evaluation of future machine learning tools in stroke. In the present state, machine learning technology serves as a helpful and efficient tool for rapid clinical decision making while oversight from clinical experts is still required to address specific aspects not accounted for in an automated algorithm. This article provides an overview of machine learning technology and a tabulated review of pertinent machine learning studies related to stroke diagnosis and outcome prediction.
C1 [Mainali, Shraddha] Virginia Commonwealth Univ, Dept Neurol, Med Coll Virginia Campus, Richmond, VA 23284 USA.
   [Darsie, Marin E.] Univ Wisconsin Hosp & Clin, Dept Emergency Med, Madison, WI 53792 USA.
   [Darsie, Marin E.] Univ Wisconsin Hosp & Clin, Dept Neurol Surg, Madison, WI 53792 USA.
   [Smetana, Keaton S.] Ohio State Univ, Dept Pharm, Wexner Med Ctr, Columbus, OH 43210 USA.
RP Mainali, S (corresponding author), Virginia Commonwealth Univ, Dept Neurol, Med Coll Virginia Campus, Richmond, VA 23284 USA.
EM shraddha.mainali@vcuhealth.org
RI Smetana, Keaton/ABA-6412-2020
OI Smetana, Keaton/0000-0002-4680-1116
NR 98
TC 0
Z9 0
U1 40
U2 40
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-2295
J9 FRONT NEUROL
JI Front. Neurol.
PD DEC 6
PY 2021
VL 12
AR 734345
DI 10.3389/fneur.2021.734345
PG 16
WC Clinical Neurology; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Neurosciences & Neurology
GA XQ3UJ
UT WOS:000731472800001
PM 34938254
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Lo Vercio, L
   Amador, K
   Bannister, JJ
   Crites, S
   Gutierrez, A
   MacDonald, ME
   Moore, J
   Mouches, P
   Rajashekar, D
   Schimert, S
   Subbanna, N
   Tuladhar, A
   Wang, N
   Wilms, M
   Winder, A
   Forkert, ND
AF Lo Vercio, Lucas
   Amador, Kimberly
   Bannister, Jordan J.
   Crites, Sebastian
   Gutierrez, Alejandro
   MacDonald, M. Ethan
   Moore, Jasmine
   Mouches, Pauline
   Rajashekar, Deepthi
   Schimert, Serena
   Subbanna, Nagesh
   Tuladhar, Anup
   Wang, Nanjia
   Wilms, Matthias
   Winder, Anthony
   Forkert, Nils D.
TI Supervised machine learning tools: a tutorial for clinicians
SO JOURNAL OF NEURAL ENGINEERING
LA English
DT Review
DE machine learning; artificial intelligence; classification; regression;
   deep learning
ID FEATURE-SELECTION; IMAGE SEGMENTATION; BRAIN-TUMORS; PREDICTION;
   CLASSIFICATION; NEUROSCIENCE; INFORMATION; RECOGNITION; ASSOCIATION;
   IMPUTATION
AB In an increasingly data-driven world, artificial intelligence is expected to be a key tool for converting big data into tangible benefits and the healthcare domain is no exception to this. Machine learning aims to identify complex patterns in multi-dimensional data and use these uncovered patterns to classify new unseen cases or make data-driven predictions. In recent years, deep neural networks have shown to be capable of producing results that considerably exceed those of conventional machine learning methods for various classification and regression tasks. In this paper, we provide an accessible tutorial of the most important supervised machine learning concepts and methods, including deep learning, which are potentially the most relevant for the medical domain. We aim to take some of the mystery out of machine learning and depict how machine learning models can be useful for medical applications. Finally, this tutorial provides a few practical suggestions for how to properly design a machine learning model for a generic medical problem.
C1 [Lo Vercio, Lucas; Amador, Kimberly; Bannister, Jordan J.; Crites, Sebastian; Gutierrez, Alejandro; MacDonald, M. Ethan; Moore, Jasmine; Mouches, Pauline; Rajashekar, Deepthi; Schimert, Serena; Subbanna, Nagesh; Tuladhar, Anup; Wang, Nanjia; Wilms, Matthias; Winder, Anthony; Forkert, Nils D.] Univ Calgary, Dept Radiol, Calgary, AB, Canada.
RP Lo Vercio, L (corresponding author), Univ Calgary, Dept Radiol, Calgary, AB, Canada.
RI Tuladhar, Anup/AAL-7139-2020; Vercio, Lucas Lo/AAR-4408-2021; mouches,
   pauline/AFT-3154-2022; Forkert, Nils Daniel/K-6273-2012
OI Vercio, Lucas Lo/0000-0002-5465-6801; Forkert, Nils
   Daniel/0000-0003-2556-3224; Amador, Kimberly/0000-0003-3956-1895;
   Mouches, Pauline/0000-0002-0304-5584; Gutierrez,
   Alejandro/0000-0003-1224-7169; MacDonald, M Ethan/0000-0001-5421-3536;
   Moore, Jasmine/0000-0001-9333-2730
FU Canada Research Chairs program at Calgary FoundationCanada Research
   Chairs; River Fund at Calgary Foundation
FX This work was supported by the Canada Research Chairs program and the
   River Fund at Calgary Foundation.
NR 114
TC 12
Z9 12
U1 8
U2 17
PU IOP PUBLISHING LTD
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 1741-2560
EI 1741-2552
J9 J NEURAL ENG
JI J. Neural Eng.
PD DEC
PY 2020
VL 17
IS 6
AR 062001
DI 10.1088/1741-2552/abbff2
PG 19
WC Engineering, Biomedical; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Neurosciences & Neurology
GA PI5KA
UT WOS:000601128500001
PM 33036008
DA 2022-04-17
ER

PT J
AU Alridha, A
   Wahbi, FA
   Kadhim, MK
AF Alridha, Ahmed
   Wahbi, Fadhil Abdalhasan
   Kadhim, Mazin Kareem
TI Training analysis of optimization models in machine learning
SO INTERNATIONAL JOURNAL OF NONLINEAR ANALYSIS AND APPLICATIONS
LA English
DT Article
DE machine learning; mathematical programming; optimization techniques
AB Machine learning is fast evolving, with numerous theoretical advances and applications in a variety of domains. In reality, most machine learning algorithms are based on optimization issues. This interaction is also explored in the special topic on machine learning and large-scale optimization. Furthermore, machine learning optimization issues have several unique characteristics that are rarely seen in other optimization contexts. Aside from that, the notions of classical optimization vs machine learning will be discussed. Finally, this study will give an outline of these peculiar aspects of machine learning optimization.
C1 [Alridha, Ahmed; Wahbi, Fadhil Abdalhasan; Kadhim, Mazin Kareem] Minist Educ, Dept Math Sci, Babylon, Iraq.
RP Alridha, A (corresponding author), Minist Educ, Dept Math Sci, Babylon, Iraq.
EM amqa92@yahoo.com; Fadhilf40@gmail.com; mazen.marjan22@gmail.com
OI Hasan ALRIDHA, Ahmed/0000-0002-2192-5251
NR 12
TC 0
Z9 0
U1 26
U2 29
PU SEMNAN UNIV
PI SEMNAN
PA MOLAVI BLVD, SEMNAN, REPUBLIC ISLAMIC 00000, IRAN
SN 2008-6822
J9 INT J NONLINEAR ANAL
JI Int. J. Nonlinear Anal. Appl.
PY 2021
VL 12
IS 2
BP 1453
EP 1461
DI 10.22075/ijnaa.2021.5261
PG 9
WC Mathematics
WE Emerging Sources Citation Index (ESCI)
SC Mathematics
GA UK3OA
UT WOS:000691881100022
DA 2022-04-17
ER

PT C
AU Bhushan, S
   Burgreen, GW
   Bowman, JL
   Dettwiller, ID
   Brewer, W
AF Bhushan, Shanti
   Burgreen, Greg W.
   Bowman, Joshua L.
   Dettwiller, Ian D.
   Brewer, Wesley
GP IEEE Comp Soc
TI Predictions of Steady and Unsteady Flows using Machine-learned Surrogate
   Models
SO 2020 IEEE/ACM WORKSHOP ON MACHINE LEARNING IN HIGH PERFORMANCE COMPUTING
   ENVIRONMENTS (MLHPC 2020) AND WORKSHOP ON ARTIFICIAL INTELLIGENCE AND
   MACHINE LEARNING FOR SCIENTIFIC APPLICATIONS (AI4S 2020)
LA English
DT Proceedings Paper
CT IEEE/ACM Workshop on Machine Learning in High Performance Computing
   Environments (MLHPC) / Workshop on Artificial Intelligence and Machine
   Learning for Scientific Applications (AI4S)
CY NOV 09-19, 2020
CL ELECTR NETWORK
SP IEEE, ACM, TCHPC, SIGHPC, IEEE Comp Soc
DE Machine learning; turbulence modeling; rotor modeling; unsteady boundary
   layer flows
ID DIRECT NUMERICAL-SIMULATION; PSEUDOSPECTRAL SOLVER; NEURAL-NETWORKS;
   TURBULENT
AB The applicability of computational fluid dynamics (CFD) based design tools depend on the accuracy and complexity of the physical models, for example turbulence models, which remains an unsolved problem in physics, and rotor models that dictates the computational cost of rotorcraft and wind/hydro turbine farm simulations. The research focuses on investigation of the ability of neural networks to learn correlation between desired modeling variables and flow parameters, thereby providing surrogate models. For the turbulence modeling, the machine learned turbulence model is developed for unsteady boundary layer flow, and the predictions are validated against DNS data and compared with one-equation unsteady Reynolds Averaged Navier-Stokes (URANS) predictions. The machine-learned model performs much better than the URANS model due to its ability to incorporate the non-linear correlation between turbulent stresses and rate-of-strain. The development of the surrogate rotor model builds on the hypothesis that if a model can mimic the axial and tangential momentum deficit generated by a blade resolved model, then it should produce a qualitatively and quantitatively similar wake recovery. An initial validation of the hypothesis was performed, which showed encouraging results.
C1 [Bhushan, Shanti] Mississippi State Univ, Dept Mech Engn, Starkville, MS 39762 USA.
   [Burgreen, Greg W.] Mississippi State Univ, Ctr Adv Vehicular Syst, Starkville, MS USA.
   [Bowman, Joshua L.] Mississippi State Univ, Dept Aerosp Engn, Starkville, MS USA.
   [Dettwiller, Ian D.] Engineer Res & Dev Ctr, Vicksburg, MS USA.
   [Brewer, Wesley] DoD HPCMP PET GDIT, Vicksburg, MS USA.
RP Bhushan, S (corresponding author), Mississippi State Univ, Dept Mech Engn, Starkville, MS 39762 USA.
EM bhushan@me.msstate.edu; greg.burgreen@msstate.edu; jb1060@msstate.edu;
   ian.d.dettwiller@usace.army.mil; Wesley.Brewer@GDIT.com
FU Engineering Research & Development Center [W912HZ-17-2-0014]; Department
   of Defense (DoD) High Performance Computing Modernization Program
   (HPCMP) under User Productivity Enhancement, Technology Transfer, and
   Training (PET) [47QFSA18K0111, ID04180146]
FX Effort at Mississippi State University was sponsored by the Engineering
   Research & Development Center under Cooperative Agreement number
   W912HZ-17-2-0014. The views and conclusions contained herein are those
   of the authors and should not be interpreted as necessarily representing
   the official policies or endorsements, either expressed or implied, of
   the Engineering Research & Development Center or the U.S. Government.;
   This material is also based upon work supported by, or in part by, the
   Department of Defense (DoD) High Performance Computing Modernization
   Program (HPCMP) under User Productivity Enhancement, Technology
   Transfer, and Training (PET) contract #47QFSA18K0111, TO#ID04180146.
NR 25
TC 1
Z9 1
U1 7
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
BN 978-1-6654-2291-8
PY 2020
BP 80
EP 87
DI 10.1109/MLHPCAI4S51975.2020.00016
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR8DS
UT WOS:000671059400009
DA 2022-04-17
ER

PT J
AU Biswas, R
   Rashmi, R
   Lourderaj, U
AF Biswas, Rupayan
   Rashmi, Richa
   Lourderaj, Upakarasamy
TI Machine Learning in Chemical Dynamics
SO RESONANCE-JOURNAL OF SCIENCE EDUCATION
LA English
DT Article
DE Machine learning; neural networks; Gaussian process for regression;
   potential energy surface
AB Machine learning has been applied to various fields and is envisaged as the technology of the future. We discuss here, the applications of machine learning methods to represent potential energy surfaces - an important aspect of chemical dynamics. We illustrate the process of machine learning using simple examples, and demonstrate how it can be extended to complicated problems.
C1 [Biswas, Rupayan; Rashmi, Richa; Lourderaj, Upakarasamy] HBNI, Sch Chem Sci, Natl Inst Sci Educ & Res, Jatni PO Khurdha, Bhubaneswar, Odisha, India.
RP Biswas, R; Rashmi, R; Lourderaj, U (corresponding author), HBNI, Sch Chem Sci, Natl Inst Sci Educ & Res, Jatni PO Khurdha, Bhubaneswar, Odisha, India.
EM rupayan@niser.ac.in; richa.rashmi@niser.ac.in; u.lourderaj@niser.ac.in
OI Lourderaj, Upakarasamy/0000-0002-5550-9694
NR 18
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER INDIA
PI NEW DELHI
PA 7TH FLOOR, VIJAYA BUILDING, 17, BARAKHAMBA ROAD, NEW DELHI, 110 001,
   INDIA
SN 0971-8044
EI 0973-712X
J9 RESONANCE
JI Resonance
PD JAN
PY 2020
VL 25
IS 1
BP 59
EP 75
DI 10.1007/s12045-019-0922-1
PG 17
WC Education, Scientific Disciplines
WE Emerging Sources Citation Index (ESCI)
SC Education & Educational Research
GA KU1CM
UT WOS:000519447700007
DA 2022-04-17
ER

PT J
AU Meng, T
   Jing, XY
   Yan, Z
   Pedrycz, W
AF Meng, Tong
   Jing, Xuyang
   Yan, Zheng
   Pedrycz, Witold
TI A survey on machine learning for data fusion
SO INFORMATION FUSION
LA English
DT Article
DE Data fusion; Machine learning; Fusion methods; Fusion criteria
ID MULTISENSOR DATA FUSION; SUPPORT VECTOR MACHINE; INFORMATION FUSION;
   INTRUSION DETECTION; MINING OPINIONS; INTERNET; PRIVACY
AB Data fusion is a prevalent way to deal with imperfect raw data for capturing reliable, valuable and accurate information. Comparing with a range of classical probabilistic data fusion techniques, machine learning method that automatically learns from past experiences without explicitly programming, remarkably renovates fusion techniques by offering the strong ability of computing and predicting. Nevertheless, the literature still lacks a thorough review of the recent advances of machine learning for data fusion. Therefore, it is beneficial to review and summarize the state of the art in order to gain a deep insight on how machine learning can benefit and optimize data fusion. In this paper, we provide a comprehensive survey on data fusion methods based on machine learning. We first offer a detailed introduction to the background of data fusion and machine learning in terms of definitions, applications, architectures, processes, and typical techniques. Then, we propose a number of requirements and employ them as criteria to review and evaluate the performance of existing fusion methods based on machine learning. Through the literature review, analysis and comparison, we finally come up with a number of open issues and propose future research directions in this field.
C1 [Meng, Tong; Jing, Xuyang; Yan, Zheng] Xidian Univ, Sch Cyber Engn, State Key Lab Integrated Serv Networks, Xian, Peoples R China.
   [Yan, Zheng] Aalto Univ, Dept Commun & Networking, Espoo, Finland.
   [Pedrycz, Witold] Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB, Canada.
RP Yan, Z (corresponding author), Xidian Univ, 119 POX,2 South Taibai Rd, Xian 710071, Peoples R China.
EM zheng.yan@aalto.fi
RI Jing, Xuyang/AAP-5757-2021
OI Jing, Xuyang/0000-0003-2274-0969; Yan, Zheng/0000-0002-9697-2108
FU NSFCNational Natural Science Foundation of China (NSFC) [61672410,
   61802293, U1536202]; Academy of FinlandAcademy of Finland [308087,
   314203]; National Postdoctoral Program for Innovative Talents
   [BX20180238]; China Postdoctoral Science FoundationChina Postdoctoral
   Science Foundation [2018M633461]; Fundamental Research Funds for the
   Central UniversitiesFundamental Research Funds for the Central
   Universities [JB191504]; Shaanxi Innovation Team project [2018TD-007];
   111 projectMinistry of Education, China - 111 Project [B16037]
FX This work is sponsored by the NSFC (grants 61672410, 61802293 and
   U1536202), Academy of Finland (grants 308087 and 314203), National
   Postdoctoral Program for Innovative Talents (grant BX20180238), the
   Project funded by China Postdoctoral Science Foundation (grant
   2018M633461), the Fundamental Research Funds for the Central
   Universities (grant JB191504), the Shaanxi Innovation Team project
   (grant 2018TD-007), and the 111 project (grants B16037).
NR 79
TC 108
Z9 112
U1 109
U2 248
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1566-2535
EI 1872-6305
J9 INFORM FUSION
JI Inf. Fusion
PD MAY
PY 2020
VL 57
BP 115
EP 129
DI 10.1016/j.inffus.2019.12.001
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KG2EX
UT WOS:000509755200009
OA Green Published
HC Y
HP N
DA 2022-04-17
ER

PT J
AU Zhang, T
   Zhu, TQ
   Xiong, P
   Huo, H
   Tari, Z
   Zhou, WL
AF Zhang, Tao
   Zhu, Tianqing
   Xiong, Ping
   Huo, Huan
   Tari, Zahir
   Zhou, Wanlei
TI Correlated Differential Privacy: Feature Selection in Machine Learning
SO IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS
LA English
DT Article
DE Correlation; Differential privacy; Sensitivity; Feature extraction;
   Machine learning; Machine learning algorithms; Differential privacy;
   data correlation; feature selection; machine learning
AB Privacy preserving in machine learning is a crucial issue in industry informatics since data used for training in industries usually contain sensitive information. Existing differentially private machine learning algorithms have not considered the impact of data correlation, which may lead to more privacy leakage than expected in industrial applications. For example, data collected for traffic monitoring may contain some correlated records due to temporal correlation or user correlation. To fill this gap, in this article, we propose a correlation reduction scheme with differentially private feature selection considering the issue of privacy loss when data have correlation in machine learning tasks. The proposed scheme involves five steps with the goal of managing the extent of data correlation, preserving the privacy, and supporting accuracy in the prediction results. In this way, the impact of data correlation is relieved with the proposed feature selection scheme, and moreover the privacy issue of data correlation in learning is guaranteed. The proposed method can be widely used in machine learning algorithms, which provide services in industrial areas. Experiments show that the proposed scheme can produce better prediction results with machine learning tasks and fewer mean square errors for data queries compared to existing schemes.
C1 [Zhang, Tao; Zhu, Tianqing; Huo, Huan; Zhou, Wanlei] Univ Technol Sydney, Sch Comp Sci, Ultimo, NSW 2007, Australia.
   [Zhu, Tianqing] China Univ Geosci, Sch Comp Sci, Wuhan 430074, Peoples R China.
   [Xiong, Ping] Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, Wuhan 430073, Peoples R China.
   [Tari, Zahir] RMIT Univ, Sch Comp Sci, CE&SE Discipline, Melbourne, Vic 3000, Australia.
RP Zhu, TQ (corresponding author), Univ Technol Sydney, Sch Comp Sci, Ultimo, NSW 2007, Australia.; Zhu, TQ (corresponding author), China Univ Geosci, Sch Comp Sci, Wuhan 430074, Peoples R China.
EM tao.zhang-3@student.uts.edu.au; tianqing.zhu@uts.edu.au;
   pingxiong@znufe.edu.cn; huan.huo@uts.edu.au; zahir.tari@rmit.edu.au;
   wanlei.zhou@uts.edu.au
OI Tari, Zahir/0000-0002-1235-9673; zhang, tao/0000-0003-4696-641X
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61972366]; Australian Research
   CouncilAustralian Research Council [LP170100123]; Ministry of Education,
   Humanities, and Social Science Project of China [19A 10520035]
FX This work was supported by the National Natural Science Foundation of
   China 61972366, in part by the Australian Research Council under Linkage
   Grant LP170100123, and in part by the Ministry of Education, Humanities,
   and Social Science Project of China under 19A 10520035. Paper no.
   TII-19-2171.
NR 30
TC 18
Z9 20
U1 7
U2 32
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1551-3203
EI 1941-0050
J9 IEEE T IND INFORM
JI IEEE Trans. Ind. Inform.
PD MAR
PY 2020
VL 16
IS 3
BP 2115
EP 2124
DI 10.1109/TII.2019.2936825
PG 10
WC Automation & Control Systems; Computer Science, Interdisciplinary
   Applications; Engineering, Industrial
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science; Engineering
GA KH8LX
UT WOS:000510903200065
OA Green Submitted, Green Published
DA 2022-04-17
ER

PT J
AU Lin, E
   Lin, CH
   Lane, HY
AF Lin, Eugene
   Lin, Chieh-Hsin
   Lane, Hsien-Yuan
TI Machine Learning and Deep Learning for the Pharmacogenomics of
   Antidepressant Treatments
SO CLINICAL PSYCHOPHARMACOLOGY AND NEUROSCIENCE
LA English
DT Review
DE Antidepressive agents; Artificial intelligence; Deep learning; Genomics;
   Machine learning; Neuroimaging
ID DEPRESSION; PSYCHIATRY; CLASSIFICATION; OPPORTUNITIES; TOOL
AB A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD). In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms.
C1 [Lin, Eugene] Univ Washington, Dept Biostat, Seattle, WA 98195 USA.
   [Lin, Eugene] Univ Washington, Dept Elect & Comp Engn, Seattle, WA 98195 USA.
   [Lin, Eugene; Lin, Chieh-Hsin; Lane, Hsien-Yuan] China Med Univ, Grad Inst Biomed Sci, Taichung, Taiwan.
   [Lin, Chieh-Hsin] Chang Gung Univ, Kaohsiung Chang Gung Mem Hosp, Dept Psychiat, Coll Med, 123 Dapi Rd, Kaohsiung 83301, Taiwan.
   [Lin, Chieh-Hsin] Chang Gung Univ, Sch Med, Taoyuan, Taiwan.
   [Lane, Hsien-Yuan] China Med Univ Hosp, Dept Psychiat, 2 Yude Rd, Taichung 40447, Taiwan.
   [Lane, Hsien-Yuan] China Med Univ Hosp, Brain Dis Res Ctr, Taichung, Taiwan.
   [Lane, Hsien-Yuan] Asia Univ, Coll Med & Hlth Sci, Dept Psychol, Taichung, Taiwan.
RP Lin, CH (corresponding author), Chang Gung Univ, Kaohsiung Chang Gung Mem Hosp, Dept Psychiat, Coll Med, 123 Dapi Rd, Kaohsiung 83301, Taiwan.; Lane, HY (corresponding author), China Med Univ Hosp, Dept Psychiat, 2 Yude Rd, Taichung 40447, Taiwan.
EM cyndi36@gmail.com; hylane@gmail.com
FU National Health Research Institutes, TaiwanNational Health Research
   Institutes - Taiwan [NHRI-EX109-10731NI]; Ministry of Science and
   Technology in TaiwanMinistry of Science and Technology, Taiwan [MOST
   109-2622-B-039-001-CC2, 109-2314-B-039-001, 109-2314-B-039-039-MY3];
   Taiwan Ministry of Health and Welfare Clinical Trial and Research Center
   of Excellence [MOHW109-TDU-B-212-114004]; China Medical University and
   HospitalChina Medical University [DMR-109-MOST-03]
FX This work was supported by National Health Research Institutes, Taiwan
   (NHRI-EX109-10731NI) , Ministry of Science and Technology in Taiwan
   (MOST 109-2622-B-039-001-CC2; 109-2314-B-039-001;109-2314-B-039-039-MY3)
   , Taiwan Ministry of Health and Welfare Clinical Trial and Research
   Center of Excellence (MOHW109-TDU-B-212-114004) , China Medical
   University and Hospital (DMR-109-MOST-03) . The funding sources had no
   involvement in the article.
NR 79
TC 0
Z9 0
U1 4
U2 4
PU KOREAN COLL NEUROPSYCHOPHARMACOLOGY
PI SEOUL
PA RN 1003 OFFICETEL 40, 63-RO YEONGDEUNGPO-GU, SEOUL, 150-731, SOUTH KOREA
SN 1738-1088
EI 2093-4327
J9 CLIN PSYCHOPHARM NEU
JI Clin. Psychopharmacol. Neurosci.
PD NOV
PY 2021
VL 19
IS 4
BP 577
EP 588
DI 10.9758/cpn.2021.19.4.577
PG 12
WC Neurosciences; Pharmacology & Pharmacy
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Neurosciences & Neurology; Pharmacology & Pharmacy
GA WN8WT
UT WOS:000712048500001
PM 34690113
OA gold, Green Published
DA 2022-04-17
ER

PT J
AU Moreno, M
   Lourenco, V
   Fiorini, SR
   Costa, P
   Brandao, R
   Civitarese, D
   Cerqueira, R
AF Moreno, Marcio
   Lourenco, Vitor
   Fiorini, Sandro Rama
   Costa, Polyana
   Brandao, Rafael
   Civitarese, Daniel
   Cerqueira, Renato
TI Managing Machine Learning Workflow Components
SO INTERNATIONAL JOURNAL OF SEMANTIC COMPUTING
LA English
DT Article; Proceedings Paper
CT 14th IEEE International Conference on Semantic Computing (ICSC)
CY FEB 03-05, 2020
CL San Diego, CA
SP IEEE, IEEE Comp Soc
DE Machine learning; workflow management; Hyperknowledge
AB Machine Learning Workflows (MLWfs) have become an essential and disruptive approach in problem-solving over several industries. However, the development process of MLWfs may be complex, time-consuming, and error-prone. To handle this problem, we introduce machine learning workflow management (MLWfM) as a technique to aid the development and reuse of MLWfs and their components through three aspects: representation, execution, and creation. We introduce our approach to structure MLWfs' components and metadata in order to aid component retrieval and reuse of new MLWfs. We also consider the execution of these components within a tool. A hybrid knowledge representation, called Hyperknowledge, frames our methodology, supporting the three MLWfM's aspects. To validate our approach, we show a practical use case in the Oil & Gas industry. In addition, to evaluate the feasibility of the proposed technique, we create a dataset of MLWfs executions and discuss the MLWfM's performance in loading and querying this dataset.
C1 [Moreno, Marcio; Lourenco, Vitor; Fiorini, Sandro Rama; Costa, Polyana; Brandao, Rafael; Civitarese, Daniel; Cerqueira, Renato] IBM Res, Sao Paulo, Brazil.
RP Moreno, M (corresponding author), IBM Res, Sao Paulo, Brazil.
EM mmoreno@br.ibm.com; vitor.nascimento@ibm.com; sandro.fiorini@ibm.com;
   polyana.bezerra@ibm.com; rmello@br.ibm.com; sallesd@br.ibm.com;
   rcerq@br.ibm.com
NR 20
TC 0
Z9 0
U1 0
U2 2
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 1793-351X
EI 1793-7108
J9 INT J SEMANT COMPUT
JI Int. J. Semant. Comput.
PD JUN
PY 2020
VL 14
IS 2
SI SI
BP 295
EP 309
DI 10.1142/S1793351X20400115
PG 15
WC Computer Science, Artificial Intelligence
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA NX7GP
UT WOS:000575875200007
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Brunton, SL
AF Brunton, Steven L.
TI Applying machine learning to study fluid mechanics
SO ACTA MECHANICA SINICA
LA English
DT Review; Early Access
DE Machine learning; Fluid mechanics; Physics-informed machine learning;
   Neural networks; Deep learning
ID ACTIVE FLOW-CONTROL; NEURAL-NETWORKS; MODEL-REDUCTION; FRAMEWORK;
   TRANSIENT; DYNAMICS
AB This paper provides a short overview of how to use machine learning to build data-driven models in fluid mechanics. The process of machine learning is broken down into five stages: (1) formulating a problem to model, (2) collecting and curating training data to inform the model, (3) choosing an architecture with which to represent the model, (4) designing a loss function to assess the performance of the model, and (5) selecting and implementing an optimization algorithm to train the model. At each stage, we discuss how prior physical knowledge may be embedding into the process, with specific examples from the field of fluid mechanics.
C1 [Brunton, Steven L.] Univ Washington, Dept Mech Engn, Seattle, WA 98195 USA.
RP Brunton, SL (corresponding author), Univ Washington, Dept Mech Engn, Seattle, WA 98195 USA.
EM sbrunton@uw.edu
NR 110
TC 2
Z9 2
U1 38
U2 38
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 0567-7718
EI 1614-3116
J9 ACTA MECH SINICA-PRC
JI Acta Mech. Sin.
DI 10.1007/s10409-021-01143-6
EA JAN 2022
PG 9
WC Engineering, Mechanical; Mechanics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Mechanics
GA XZ6RW
UT WOS:000737778100001
OA Green Submitted, hybrid
DA 2022-04-17
ER

PT J
AU Westermayr, J
   Marquetand, P
AF Westermayr, Julia
   Marquetand, Philipp
TI Machine learning and excited-state molecular dynamics
SO MACHINE LEARNING-SCIENCE AND TECHNOLOGY
LA English
DT Article
DE machine learning; photodynamics; photochemistry; excited states; quantum
   chemistry; nonadiabatic couplings; spin-orbit couplings
AB Machine learning is employed at an increasing rate in the research field of quantum chemistry. While the majority of approaches target the investigation of chemical systems in their electronic ground state, the inclusion of light into the processes leads to electronically excited states and gives rise to several new challenges. Here, we survey recent advances for excited-state dynamics based on machine learning. In doing so, we highlight successes, pitfalls, challenges and future avenues for machine learning approaches for light-induced molecular processes.
C1 [Westermayr, Julia; Marquetand, Philipp] Univ Vienna, Fac Chem, Inst Theoret Chem, Wahringer Str 17, A-1090 Vienna, Austria.
   [Marquetand, Philipp] Univ Vienna, Vienna Res Platform Accelerating Photoreact Disco, Wahringer Str 17, A-1090 Vienna, Austria.
   [Marquetand, Philipp] Univ Vienna, Fac Chem, Data Sci Uni Vienna, Wahringer Str 29, A-1090 Vienna, Austria.
RP Marquetand, P (corresponding author), Univ Vienna, Fac Chem, Inst Theoret Chem, Wahringer Str 17, A-1090 Vienna, Austria.; Marquetand, P (corresponding author), Univ Vienna, Vienna Res Platform Accelerating Photoreact Disco, Wahringer Str 17, A-1090 Vienna, Austria.; Marquetand, P (corresponding author), Univ Vienna, Fac Chem, Data Sci Uni Vienna, Wahringer Str 29, A-1090 Vienna, Austria.
EM philipp.marquetand@univie.ac.at
OI Westermayr, Julia/0000-0002-6531-0742
FU Austrian Science FundAustrian Science Fund (FWF) [W 1232]; University of
   Vienna
FX This work was financially supported by the Austrian Science Fund, W 1232
   (MolTag) and the uni:docs program of the University of Vienna (J W). P M
   thanks the University of Vienna for continuous support, also in the
   frame of the research platform ViRAPID.
NR 272
TC 14
Z9 14
U1 7
U2 7
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
EI 2632-2153
J9 MACH LEARN-SCI TECHN
JI Mach. Learn.-Sci. Technol.
PD DEC
PY 2020
VL 1
IS 4
AR 043001
DI 10.1088/2632-2153/ab9c3e
PG 19
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Science & Technology - Other Topics
GA VK7YC
UT WOS:000754876300001
OA gold, Green Submitted
DA 2022-04-17
ER

PT J
AU Kao, IH
   Hsu, YW
   Lai, YH
   Perng, JW
AF Kao, I-Hsi
   Hsu, Ya-Wen
   Lai, Yi Horng
   Perng, Jau-Woei
TI Laser Cladding Quality Monitoring Using Coaxial Image Based on Machine
   Learning
SO IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT
LA English
DT Article
DE Coaxial image; failure detection; laser cladding; machine learning;
   monitoring
ID FAULT-DETECTION; CLASSIFICATION; REGRESSION; ENERGY; FUSION; MODEL
AB The processing quality of laser cladding is a topic of interest to laser machine manufacturers. The management of various experimental data and process quality of the laser machine can effectively guide the customer to better adjust the processing parameters. This study finds that the processing quality of laser cladding is related to the signal of the coaxial image. Therefore, this study uses a machine learning method to establish a model of coaxial image and laser processing quality. The study does not merely implement a single machine learning method but also compares various machine learning algorithms. Convolutional neural networks and autoencoders are implemented as algorithms for the feature extraction phase. Linear regression, random forest, support vector machine, and SoftMax neural networks are implemented as algorithms for classification. The receiver operating characteristic curve and the accuracy rate are the result indicators of this paper. The experimental results show that there is indeed a correlation between the laser processing quality and the coaxial image, and the algorithm in this study can effectively supervise the processing quality of laser cladding.
C1 [Kao, I-Hsi; Hsu, Ya-Wen; Lai, Yi Horng; Perng, Jau-Woei] Natl Sun Yat Sen Univ, Dept Mech & Electromech Engn, Kaohsiung 804, Taiwan.
RP Perng, JW (corresponding author), Natl Sun Yat Sen Univ, Dept Mech & Electromech Engn, Kaohsiung 804, Taiwan.
EM jwperng@faculty.nsysu.edu.tw
OI Kao, I-Hsi/0000-0003-4462-5515
FU Ministry of Science and Technology, TaiwanMinistry of Science and
   Technology, Taiwan [107-2218-E-110-001]; Tongtai Machine & Tool Company,
   Ltd.
FX This work was supported in part by the Ministry of Science and
   Technology, Taiwan, under Grant 107-2218-E-110-001, and in part by
   Tongtai Machine & Tool Company, Ltd.
NR 54
TC 4
Z9 4
U1 9
U2 19
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9456
EI 1557-9662
J9 IEEE T INSTRUM MEAS
JI IEEE Trans. Instrum. Meas.
PD JUN
PY 2020
VL 69
IS 6
BP 2868
EP 2880
DI 10.1109/TIM.2019.2926878
PN 1
PG 13
WC Engineering, Electrical & Electronic; Instruments & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Instruments & Instrumentation
GA MH3HH
UT WOS:000546622100026
DA 2022-04-17
ER

PT J
AU Gupta, U
   Gupta, D
AF Gupta, Umesh
   Gupta, Deepak
TI Regularized based implicit Lagrangian twin extreme learning machine in
   primal for pattern classification
SO INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS
LA English
DT Article
DE Support vector machine; Extreme learning machine; Twin extreme learning
   machine; Smoothing approaches
ID SUPPORT VECTOR MACHINE; REGRESSION; ROBUST; ENSEMBLE; ELM
AB In this paper, we suggest a novel approach termed as regularized based implicit Lagrangian twin extreme learning machine in primal as a pair of unconstrained convex minimization problem (RILTELM) where regularization term is added to follow the structural risk minimization principle. Here, we consider 2-norm of the slack vector of variables to make the problem strongly convex which results in a unique solution. Since it has non-smooth plus functions in their objective function, so we find an approximate solution by replacing the non-smooth plus function with smooth approximation function because to find an approximation solution in primal space is always superior to its dual. Due to non-smooth plus function, we solve the problem by either smooth approximation approach or generalized derivative approach. In addition, a functional iterative scheme is also suggested to find the optimal solution. Hence, no external optimization toolbox is required unlike in twin extreme learning machine (TELM) and twin support vector machine (TWSVM). The numerical experiments are demonstrated on artificial and real-world datasets and compared with TWSVM, ELM, TELM and LSTELM to establish the efficacy and applicability of proposed RILTELM.
C1 [Gupta, Umesh; Gupta, Deepak] Natl Inst Technol Arunachal Pradesh, Dept Comp Sci & Engn, Papum Pare, Arunachal Prade, India.
RP Gupta, D (corresponding author), Natl Inst Technol Arunachal Pradesh, Dept Comp Sci & Engn, Papum Pare, Arunachal Prade, India.
EM er.umeshgupta@gmail.com; deepak@nitap.ac.in
RI GUPTA, UMESH/AAC-4589-2021; Gupta, Deepak/H-4151-2019
OI GUPTA, UMESH/0000-0002-1547-7974; Gupta, Deepak/0000-0002-6375-8615
NR 69
TC 3
Z9 3
U1 4
U2 8
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-8071
EI 1868-808X
J9 INT J MACH LEARN CYB
JI Int. J. Mach. Learn. Cybern.
PD MAY
PY 2021
VL 12
IS 5
BP 1311
EP 1342
DI 10.1007/s13042-020-01235-y
EA JAN 2021
PG 32
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RM9EB
UT WOS:000604481300001
DA 2022-04-17
ER

PT J
AU Lu, HL
   Li, MJ
   He, T
   Wang, SQ
   Narayanan, V
   Chan, KVS
AF Lu, Hanlin
   Li, Ming-Ju
   He, Ting
   Wang, Shiqiang
   Narayanan, Vijaykrishnan
   Chan, Kevin S.
TI Robust Coreset Construction for Distributed Machine Learning
SO IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS
LA English
DT Article
DE Machine learning; Approximation algorithms; Machine learning algorithms;
   Distributed databases; Data models; Cost function; Clustering
   algorithms; Coreset; distributed machine learning; distributed k-means;
   distributed k-median
ID BIG
AB Coreset, which is a summary of the original dataset in the form of a small weighted set in the same sample space, provides a promising approach to enable machine learning over distributed data. Although viewed as a proxy of the original dataset, each coreset is only designed to approximate the cost function of a specific machine learning problem, and thus different coresets are often required to solve different machine learning problems, increasing the communication overhead. We resolve this dilemma by developing robust coreset construction algorithms that can support a variety of machine learning problems. Motivated by empirical evidence that suitably-weighted k-clustering centers provide a robust coreset, we harden the observation by establishing theoretical conditions under which the coreset provides a guaranteed approximation for a broad range of machine learning problems, and developing both centralized and distributed algorithms to generate coresets satisfying the conditions. The robustness of the proposed algorithms is verified through extensive experiments on diverse datasets with respect to both supervised and unsupervised learning problems.
C1 [Lu, Hanlin; He, Ting; Narayanan, Vijaykrishnan] Penn State Univ, Dept Comp Sci & Engn, University Pk, PA 16802 USA.
   [Li, Ming-Ju] Amazon Com Inc, Seattle, WA 98109 USA.
   [Wang, Shiqiang] IBM Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.
   [Chan, Kevin S.] US Army, Res Lab, Adelphi, MD 20783 USA.
RP Lu, HL (corresponding author), Penn State Univ, Dept Comp Sci & Engn, University Pk, PA 16802 USA.
EM hzl263@psu.edu; mingju.li1128@gmail.com; tzh58@psu.edu;
   wangshiq@us.ibm.com; vxn9@psu.edu; kevin.s.chan.civ@mail.mil
FU U.S. Army Research LaboratoryUnited States Department of DefenseUS Army
   Research Laboratory (ARL); U.K. Ministry of Defence [W911NF-16-3-0001];
   National Science Foundation (NSF)National Science Foundation (NSF)
   [1317560]
FX This work was supported in part by the U.S. Army Research Laboratory and
   the U.K. Ministry of Defence under Agreement W911NF-16-3-0001. The work
   of Hanlin Lu and Vijaykrishnan Narayanan were supported in part by the
   National Science Foundation (NSF) under Grant 1317560.
NR 48
TC 3
Z9 3
U1 1
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0733-8716
EI 1558-0008
J9 IEEE J SEL AREA COMM
JI IEEE J. Sel. Areas Commun.
PD OCT
PY 2020
VL 38
IS 10
BP 2400
EP 2417
DI 10.1109/JSAC.2020.3000373
PG 18
WC Engineering, Electrical & Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Telecommunications
GA NR7FA
UT WOS:000571725400014
OA Green Submitted
DA 2022-04-17
ER

PT C
AU Hashemi, Y
   Nayebi, M
   Antoniol, G
AF Hashemi, Yalda
   Nayebi, Maleknaz
   Antoniol, Giuliano
BE Kontogiannis, K
   Khomh, F
   Chatzigeorgiou, A
   Fokaefs, ME
   Zhou, M
TI Documentation of Machine Learning Software
SO PROCEEDINGS OF THE 2020 IEEE 27TH INTERNATIONAL CONFERENCE ON SOFTWARE
   ANALYSIS, EVOLUTION, AND REENGINEERING (SANER '20)
LA English
DT Proceedings Paper
CT 27th IEEE International Conference on Software Analysis, Evolution, and
   Reengineering (SANER)
CY FEB 18-21, 2020
CL London, CANADA
SP IEEE, IEEE Comp Soc, Western Univ, IEEE Tech Council Software Engn
DE Software Engineering; Machine Learning; Software Documentation; Mining
   Software Repositories
AB Machine Learning software documentation is different from most of the documentations that were studied in software engineering research. Often, the users of these documentations are not software experts. The increasing interest in using data science and in particular, machine learning in different fields attracted scientists and engineers with various levels of knowledge about programming and software engineering. Our ultimate goal is automated generation and adaptation of machine learning software documents for users with different levels of expertise. We are interested in understanding the nature and triggers of the problems and the impact of the users' levels of expertise in the process of documentation evolution. We will investigate the Stack Overflow Q&As and classify the documentation related Q/As within the machine learning domain to understand the types and triggers of the problems as well as the potential change requests to the documentation. We intend to use the results for building on top of the state of the art techniques for automatic documentation generation and extending on the adoption, summarization, and explanation of software functionalities.
C1 [Hashemi, Yalda; Nayebi, Maleknaz; Antoniol, Giuliano] Ecole Polytech Montreal, Dept Comp & Software Engn, Montreal, PQ, Canada.
RP Hashemi, Y (corresponding author), Ecole Polytech Montreal, Dept Comp & Software Engn, Montreal, PQ, Canada.
EM yalda.hashemi@polymtl.ca; maleknaz.nayebi@polymtl.ca;
   giuliano.antoniol@polymtl.ca
NR 5
TC 1
Z9 1
U1 2
U2 3
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-5143-4
PY 2020
BP 666
EP 667
PG 2
WC Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BP8WU
UT WOS:000568240800076
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Andrienko, N
   Andrienko, G
   Adilova, L
   Wrobel, S
AF Andrienko, Natalia
   Andrienko, Gennady
   Adilova, Linara
   Wrobel, Stefan
TI Visual Analytics for Human-Centered Machine Learning
SO IEEE COMPUTER GRAPHICS AND APPLICATIONS
LA English
DT Article
DE Computer science; Bridges; Computational modeling; Visual analytics;
   Human intelligence; Buildings; Machine learning
ID MODEL
AB We introduce a new research area in visual analytics (VA) aiming to bridge existing gaps between methods of interactive machine learning (ML) and eXplainable Artificial Intelligence (XAI), on one side, and human minds, on the other side. The gaps are, first, a conceptual mismatch between ML/XAI outputs and human mental models and ways of reasoning, and second, a mismatch between the information quantity and level of detail and human capabilities to perceive and understand. A grand challenge is to adapt ML and XAI to human goals, concepts, values, and ways of thinking. Complementing the current efforts in XAI towards solving this challenge, VA can contribute by exploiting the potential of visualization as an effective way of communicating information to humans and a strong trigger of human abstractive perception and thinking. We propose a cross-disciplinary research framework and formulate research directions for VA.
C1 [Andrienko, Natalia] City Univ London, London EC1V 0HB, England.
   [Adilova, Linara] Ruhr Univ Bochum, D-44801 Bochum, Germany.
   [Wrobel, Stefan] Univ Bonn, D-53113 Bonn, Germany.
RP Andrienko, N (corresponding author), City Univ London, London EC1V 0HB, England.
EM nathaliya.andriyenko@iais.fraunhofer.de;
   gennadiy.andriyenko@iais.fraunhofer.de;
   linara.adilova@iais.fraunhofer.de; stefan.wrobel@iais.fraunhofer.de
RI ; Andrienko, Gennady/B-6486-2014
OI Andrienko, Natalia/0000-0003-3313-1560; Andrienko,
   Gennady/0000-0002-8574-6295
FU Fraunhofer Center for Machine Learning within the Fraunhofer Cluster for
   Cognitive Internet Technologies; DFG within Priority Programme 1894 (SPP
   VGI); EU under project SoBigData++; SESAR under project TAPAS; SESAR
   under project SIMBAD
FX This work was supported by Fraunhofer Center for Machine Learning within
   the Fraunhofer Cluster for Cognitive Internet Technologies, by DFG
   within Priority Programme 1894 (SPP VGI), by EU under project
   SoBigData++, and by SESAR under projects TAPAS and SIMBAD.
NR 17
TC 0
Z9 0
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0272-1716
EI 1558-1756
J9 IEEE COMPUT GRAPH
JI IEEE Comput. Graph. Appl.
PD JAN 1
PY 2022
VL 42
IS 1
BP 123
EP 133
DI 10.1109/MCG.2021.3130314
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YO9LT
UT WOS:000748254800024
PM 35077350
OA Green Accepted
DA 2022-04-17
ER

PT C
AU Fradkov, AL
AF Fradkov, Alexander L.
TI Early History of Machine Learning
SO IFAC PAPERSONLINE
LA English
DT Proceedings Paper
CT 21st IFAC World Congress on Automatic Control - Meeting Societal
   Challenges
CY JUL 11-17, 2020
CL ELECTR NETWORK
SP Int Federat Automat Control, Siemens, Bayer, ABB, MathWorks, Phoenix Contact, Ifak Technol, Berlin Heart, Elsevier, De Gruyter, Tele Medi GmbH
DE Machine Learning; Neural Networks; Separation Theorems; Convex
   Optimization
ID BACK-PROPAGATION; NEURAL-NETWORKS; POINT; COMMON; MODEL
AB Machine learning belongs to the crossroad of cybernetics (control science) and computer science. It is attracting recently an overwhelming interest, both of professionals and of the general public. In the talk a brief overview of the historical development of the machine learning field with a focus on the development of mathematical apparatus in its first decades is provided. A number of little-known facts published in hard to reach sources are presented. Copyright (C) 2020 The Authors.
C1 [Fradkov, Alexander L.] Russian Acad Sci, Inst Problems Mech Engn, St Petersburg, Russia.
RP Fradkov, AL (corresponding author), Russian Acad Sci, Inst Problems Mech Engn, St Petersburg, Russia.
EM Alexander.Fradkov@gmail.com
RI Fradkov, Alexander L/J-3814-2013
OI Fradkov, Alexander L/0000-0002-5633-0944
FU Government of Russian Federation [08-08]
FX Supported by the Government of Russian Federation, project 08-08
NR 55
TC 3
Z9 4
U1 6
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2405-8963
J9 IFAC PAPERSONLINE
JI IFAC PAPERSONLINE
PY 2020
VL 53
IS 2
BP 1385
EP 1390
DI 10.1016/j.ifacol.2020.12.1888
PG 6
WC Automation & Control Systems
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Automation & Control Systems
GA SF2LK
UT WOS:000652592500224
OA gold
DA 2022-04-17
ER

PT J
AU Hou, BY
   Chen, Q
   Wang, YY
   Nafa, Y
   Li, ZH
AF Hou, Boyi
   Chen, Qun
   Wang, Yanyan
   Nafa, Youcef
   Li, Zhanhuai
TI Gradual Machine Learning for Entity Resolution
SO IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
LA English
DT Article
DE Erbium; Machine learning; Task analysis; Labeling; Training; Training
   data; Data models; Gradual machine learning; entity resolution;
   unsupervised learning; factor graph inference
AB Usually considered as a classification problem, entity resolution (ER) can be very challenging on real data due to the prevalence of dirty values. The state-of-the-art solutions for ER were built on a variety of learning models (most notably deep neural networks), which require lots of accurately labeled training data. Unfortunately, high-quality labeled data usually require expensive manual work, and are therefore not readily available in many real scenarios. In this paper, we propose a novel learning paradigm for ER, called gradual machine learning, which aims to enable effective machine labeling without the requirement for manual labeling effort. It begins with some easy instances in a task, which can be automatically labeled by the machine with high accuracy, and then gradually labels more challenging instances by iterative factor graph inference. In gradual machine learning, the hard instances in a task are gradually labeled in small stages based on the estimated evidential certainty provided by the labeled easier instances. Our extensive experiments on real data have shown that the performance of the proposed approach is considerably better than its unsupervised alternatives, and highly competitive compared to the state-of-the-art supervised techniques. Using ER as a test case, we demonstrate that gradual machine learning is a promising paradigm potentially applicable to other challenging classification tasks requiring extensive labeling effort.
C1 [Hou, Boyi; Chen, Qun; Wang, Yanyan; Nafa, Youcef; Li, Zhanhuai] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.
   [Hou, Boyi; Chen, Qun; Wang, Yanyan; Nafa, Youcef; Li, Zhanhuai] Northwestern Polytech Univ, Key Lab Big Data Storage & Management, Minist Ind & Informat Technol, 127 West Youyi Rd, Xian 710072, Shaanxi, Peoples R China.
RP Chen, Q (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.
EM ntoskrnl@nwpu.edu.cn; chenbenben@nwpu.edu.cn; wangyanyan@nwpu.edu.cn;
   youcef.nafa@mail.nwpu.edu.cn; lizhh@nwpu.edu.cn
FU Fundamental Research Funds for the Central UniversitiesFundamental
   Research Funds for the Central Universities [3102019-DX1004]; National
   Key Research and Development Program of China [2018YFB1003400]; National
   Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [61672432, 61732014]; Natural Science Basic Research
   Plan in Shaanxi Province of China [2018JM6086]
FX This work was supported by the Fundamental Research Funds for the
   Central Universities (Program No. 3102019-DX1004), National Key Research
   and Development Program of China (Program No. 2018YFB1003400), National
   Natural Science Foundation of China (Grant No. 61672432, No. 61732014),
   Natural Science Basic Research Plan in Shaanxi Province of China
   (Program No. 2018JM6086).
NR 53
TC 1
Z9 1
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1041-4347
EI 1558-2191
J9 IEEE T KNOWL DATA EN
JI IEEE Trans. Knowl. Data Eng.
PD APR 1
PY 2022
VL 34
IS 4
BP 1803
EP 1814
DI 10.1109/TKDE.2020.3006142
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZP7TV
UT WOS:000766623600022
OA Green Submitted
DA 2022-04-17
ER

PT C
AU Parisot, O
   Tamisier, T
AF Parisot, Olivier
   Tamisier, Thomas
BE DeMarsico, M
   DiBaja, GS
   Fred, A
TI Automated Machine Learning for Wind Farms Location
SO PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION
   APPLICATIONS AND METHODS (ICPRAM)
LA English
DT Proceedings Paper
CT 10th International Conference on Pattern Recognition Applications and
   Methods (ICPRAM)
CY FEB 04-06, 2021
CL ELECTR NETWORK
DE Automated Machine Learning; Wind Farms Location
AB Automated Machine Learning aims at preparing effective Machine Learning models with little or no data science expertise. Tedious tasks like preprocessing, algorithm selection and hyper-parameters optimization are then automatized: end-users just have to apply and deploy the model that best suits the real world problem. In this paper, we experiment Automated Machine Learning to leverage open data sources for predicting potential next wind farms location in Luxembourg, France, Belgium and Germany.
C1 [Parisot, Olivier; Tamisier, Thomas] Luxembourg Inst Sci & Technol LIST, 5 Ave Hauts Fourneaux, L-4362 Esch Sur Alzette, Luxembourg.
RP Parisot, O (corresponding author), Luxembourg Inst Sci & Technol LIST, 5 Ave Hauts Fourneaux, L-4362 Esch Sur Alzette, Luxembourg.
OI Parisot, Olivier/0000-0002-3293-3628
FU FEDER Data Analytics Platform project
FX This work was funded by the FEDER Data Analytics Platform project
   (http://tiny.cc/feder-dap-project).Special thanks to Anne Hendrick,
   Samuel Renault and Raynald Jadoul for their support.
NR 21
TC 0
Z9 0
U1 7
U2 8
PU SCITEPRESS
PI SETUBAL
PA AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL
BN 978-989-758-486-2
PY 2021
BP 222
EP 227
DI 10.5220/0010232102220227
PG 6
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR6PY
UT WOS:000662835900024
OA hybrid
DA 2022-04-17
ER

PT J
AU Xu, TF
   Liang, F
AF Xu, Tianfang
   Liang, Feng
TI Machine learning for hydrologic sciences: An introductory overview
SO WILEY INTERDISCIPLINARY REVIEWS-WATER
LA English
DT Article
DE data-driven modeling; deep learning; hydrology; machine learning;
   process-based modeling
ID SUPPORT VECTOR MACHINES; UNCERTAINTY QUANTIFICATION; BAYESIAN
   CALIBRATION; GAUSSIAN-PROCESSES; NEURAL-NETWORKS; SATELLITE DATA; DATA
   LENGTH; BIG DATA; MODELS; PREDICTION
AB The hydrologic community has experienced a surge in interest in machine learning in recent years. This interest is primarily driven by rapidly growing hydrologic data repositories, as well as success of machine learning in various academic and commercial applications, now possible due to increasing accessibility to enabling hardware and software. This overview is intended for readers new to the field of machine learning. It provides a non-technical introduction, placed within a historical context, to commonly used machine learning algorithms and deep learning architectures. Applications in hydrologic sciences are summarized next, with a focus on recent studies. They include the detection of patterns and events such as land use change, approximation of hydrologic variables and processes such as rainfall-runoff modeling, and mining relationships among variables for identifying controlling factors. The use of machine learning is also discussed in the context of integrated with process-based modeling for parameterization, surrogate modeling, and bias correction. Finally, the article highlights challenges of extrapolating robustness, physical interpretability, and small sample size in hydrologic applications.
C1 [Xu, Tianfang] Arizona State Univ, Sch Sustainable Engn & Built Environm, Tempe, AZ 85281 USA.
   [Liang, Feng] Univ Illinois, Dept Stat, Champaign, IL USA.
RP Xu, TF (corresponding author), Arizona State Univ, Sch Sustainable Engn & Built Environm, Tempe, AZ 85281 USA.
EM tianfang.xu@asu.edu
FU Climate Program Office [NA20OAR4310341]; National Science
   FoundationNational Science Foundation (NSF) [OAC-1931297]
FX Climate Program Office, Grant/Award Number: NA20OAR4310341; National
   Science Foundation, Grant/Award Number: OAC-1931297
NR 220
TC 5
Z9 5
U1 33
U2 50
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 2049-1948
J9 WIRES WATER
JI Wiley Interdiscip. Rev.-Water
PD SEP
PY 2021
VL 8
IS 5
AR e1533
DI 10.1002/wat2.1533
EA MAY 2021
PG 29
WC Environmental Sciences; Water Resources
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Environmental Sciences & Ecology; Water Resources
GA TV0HL
UT WOS:000655346100001
DA 2022-04-17
ER

PT S
AU Angarita-Zapata, JS
   Masegosa, AD
   Triguero, I
AF Angarita-Zapata, Juan S.
   Masegosa, Antonio D.
   Triguero, Isaac
BE Santiago, OL
   Corona, CC
   Neto, AJS
   Verdegay, JL
TI Evaluating Automated Machine Learning on Supervised Regression Traffic
   Forecasting Problems
SO COMPUTATIONAL INTELLIGENCE IN EMERGING TECHNOLOGIES FOR ENGINEERING
   APPLICATIONS
SE Studies in Computational Intelligence
LA English
DT Article; Book Chapter
DE Traffic forecasting; Supervised learning; Machine learning; Automated
   machine learning; Computational intelligence; Intelligent transportation
   systems
ID PREDICTION
AB Traffic forecasting is a well-known strategy that supports road users and decision-makers to plan their movements on the roads and to improve the management of traffic, respectively. Current data availability and growing computational capacities have increased the use of machine learning methods to tackle traffic forecasting, which is mostly modelled as a supervised regression problem. Despite the broad range of machine learning algorithms, there are no baselines to determine what are the most suitable methods and their hyper-parameters configurations to approach the different traffic forecasting regression problems reported in the literature. In machine learning, this is known as the model selection problem, and although automated machine learning methods have proved successful dealing with this problem in other areas, it has hardly been explored in traffic forecasting. In this work, we go deeply into the benefits of automated machine learning in the aforementioned field. To this end, we use Auto-WEKA, a well-known AutoML method, on a subset of families of traffic forecasting regression problems characterised by having loop detectors, as traffic data source, and scales of predictions focused on the point and the road segment levels within freeway and urban environments. The experiments include data from the Caltrans Performance Measurement System and the Madrid City Council. The results show that AutoML methods can provide competitive results for TF with low human intervention.
C1 [Angarita-Zapata, Juan S.; Masegosa, Antonio D.] Univ Deusto, DeustoTech, Fac Engn, Bilbao, Spain.
   [Masegosa, Antonio D.] Ikerbasque, Basque Fdn Sci, Bilbao, Spain.
   [Triguero, Isaac] Univ Nottingham, Sch Comp Sci, Computat Optimisat & Learning COL Lab, Nottingham, England.
RP Angarita-Zapata, JS (corresponding author), Univ Deusto, DeustoTech, Fac Engn, Bilbao, Spain.
EM js.angarita@deusto.es; ad.masegosa@deusto.es;
   Isaac.Triguero@nottingham.ac.uk
RI Masegosa, Antonio D./AAA-7848-2019; Angarita-Zapata, Juan S./T-5569-2017
OI Masegosa, Antonio D./0000-0001-7759-9072; Angarita-Zapata, Juan
   S./0000-0002-3104-9179; Triguero, Isaac/0000-0002-0150-0651
FU European UnionEuropean Commission [636220, 815069, 665959]
FX This project has received funding from the European Union's Horizon 2020
   research and innovation programme under grant agreements No 636220 and
   No 815069, and the Marie Sklodowska-Curie grant agreement No. 665959.
NR 37
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1860-949X
EI 1860-9503
BN 978-3-030-34409-2; 978-3-030-34408-5
J9 STUD COMPUT INTELL
PY 2020
VL 872
BP 187
EP 204
DI 10.1007/978-3-030-34409-2_11
D2 10.1007/978-3-030-34409-2
PG 18
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BR6LB
UT WOS:000661834000012
OA Green Accepted
DA 2022-04-17
ER

PT C
AU Baskaya, E
   Bronz, M
AF Baskaya, Elgiz
   Bronz, Murat
GP IEEE
TI Machine learning for drone operations: challenge accepted
SO 2020 AIAA/IEEE 39TH DIGITAL AVIONICS SYSTEMS CONFERENCE (DASC)
   PROCEEDINGS
SE IEEE-AIAA Digital Avionics Systems Conference
LA English
DT Proceedings Paper
CT 39th AIAA/IEEE Digital Avionics Systems Conference (DASC)
CY OCT 11-16, 2020
CL ELECTR NETWORK
SP AIAA, AIAA Digital Avion Tech Comm, IEEE Aerosp Elect Syst Soc, IEEE, NASA, MITRE, Reliable Robot, Presagis, SW Res Inst, Port San Antonio
DE Artificial Intelligence; Machine Learning; Certification; Drones
AB Machine learning is among the top research topics of the last decade in terms of practicality and popularity. Though often unnoticed, machine learning guides many aspects of our lives since its introduction via the big tech companies. Its abilities rise, defeating 9-dan Go professional, their accuracy increase, enabling smooth voice recognition, adding intelligence to our daily lives. However, its development is mostly supported by high tech companies for now rather than the public, or regulations, who show increasing concern about its usage. Despite some reluctance, machine learning has started to appear in aviation as well. Operational improvements were among the first applications. In this paper, we offer to present an introduction to machine learning, compare it with well known modeling techniques by giving an example from aviation and question their fitness for certification. We discuss the enablers and try to understand the limitations that might result or prevent the use of machine learning on certified safety systems. Similar considerations are held for systems that do not require certification, but need to be taken into account in risk analysis methods. The ultimate purpose of this paper is to highlight the existing challenges which prevent machine learning algorithms from having a wider role in drone avionics, and more generally in aviation.
C1 [Baskaya, Elgiz] Univ Toulouse, ENAC, Grp ADP, Steria Res Chaire Drone Syst, Toulouse, France.
   [Bronz, Murat] Univ Toulouse, ENAC, Toulouse, France.
RP Baskaya, E (corresponding author), Univ Toulouse, ENAC, Grp ADP, Steria Res Chaire Drone Syst, Toulouse, France.
EM elgiz.baskaya@enac.fr; murat.bronz@enac.fr
NR 41
TC 0
Z9 0
U1 0
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2155-7195
BN 978-1-7281-9825-5
J9 IEEEAAIA DIGIT AVION
PY 2020
PG 10
WC Engineering, Aerospace; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering
GA BR3FO
UT WOS:000646035600063
DA 2022-04-17
ER

PT J
AU Ho, WKO
   Tang, BS
   Wong, SW
AF Ho, Winky K. O.
   Tang, Bo-Sin
   Wong, Siu Wai
TI Predicting property prices with machine learning algorithms
SO JOURNAL OF PROPERTY RESEARCH
LA English
DT Article
DE Machine Learning algorithms; SVM; RF; GBM; property valuation
ID SUPPORT VECTOR MACHINES; MASS APPRAISAL; REGRESSION
AB This study uses three machine learning algorithms including, support vector machine (SVM), random forest (RF) and gradient boosting machine (GBM) in the appraisal of property prices. It applies these methods to examine a data sample of about 40,000 housing transactions in a period of over 18 years in Hong Kong, and then compares the results of these algorithms. In terms of predictive power, RF and GBM have achieved better performance when compared to SVM. The three performance metrics including mean squared error (MSE), root mean squared error (RMSE) and mean absolute percentage error (MAPE) associated with these two algorithms also unambiguously outperform those of SVM. However, our study has found that SVM is still a useful algorithm in data fitting because it can produce reasonably accurate predictions within a tight time constraint. Our conclusion is that machine learning offers a promising, alternative technique in property valuation and appraisal research especially in relation to property price prediction.
C1 [Ho, Winky K. O.] Univ Hong Kong, Dept Real Estate & Construct, Hong Kong, Peoples R China.
   [Tang, Bo-Sin] Univ Hong Kong, Dept Urban Planning & Design, Hong Kong, Peoples R China.
   [Wong, Siu Wai] Hong Kong Polytech Univ, Dept Bldg & Real Estate, Hong Kong, Peoples R China.
RP Tang, BS (corresponding author), Univ Hong Kong, Dept Urban Planning & Design, Hong Kong, Peoples R China.
EM bsbstang@hku.hk
RI Tang, Bo-sin/B-1126-2008; Ho, Winky K.O./P-9107-2015
OI Tang, Bo-sin/0000-0003-1909-2059; Ho, Winky K.O./0000-0002-6333-2833
FU Research Grants Council, University Grants Committee [17202818]
FX This work was supported by the Research Grants Council, University
   Grants Committee [17202818].
NR 75
TC 12
Z9 12
U1 6
U2 14
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0959-9916
EI 1466-4453
J9 J PROP RES
JI J. Prop. Res.
PD JAN 2
PY 2021
VL 38
IS 1
BP 48
EP 70
DI 10.1080/09599916.2020.1832558
EA OCT 2020
PG 23
WC Urban Studies
WE Emerging Sources Citation Index (ESCI)
SC Urban Studies
GA QG3EJ
UT WOS:000586644700001
OA hybrid
DA 2022-04-17
ER

PT J
AU Scott, IA
AF Scott, Ian A.
TI Demystifying machine learning: a primer for physicians
SO INTERNAL MEDICINE JOURNAL
LA English
DT Review
DE machine learning; prediction model; deep learning
ID HEALTH; CLASSIFICATION; ACCURACY; GUIDE
AB Machine learning is a tool for analysing digitised data sets and formulating predictions that can optimise clinical decision-making. It aims to identify complex patterns in large data sets and encode them into models that can then classify new unseen cases or make predictions on new data. Machine learning methods take several forms and individual models can be of many different types. More than 50 models have been approved for use in routine healthcare, and the numbers continue to grow exponentially. The reliability and robustness of any model depends on multiple factors, including the quality and quantity of the data used to develop the models, and the selection of features in the data considered most important to maximising accuracy. In ensuring models are safe, effective and reproducible in routine care, physicians need to have some understanding of how these models are developed and evaluated, and to collaborate with data and computer scientists in their design and validation. This narrative review introduces principles, methods and examples of machine learning in a way that does not require mastery of highly complex statistical and computational concepts.
C1 [Scott, Ian A.] Princess Alexandra Hosp, Internal Med & Clin Epidemiol, Brisbane, Qld, Australia.
   [Scott, Ian A.] Univ Queensland, Sch Clin Med, Brisbane, Qld, Australia.
RP Scott, IA (corresponding author), Princess Alexandra Hosp, 199 Ipswich Rd, Brisbane, Qld 4102, Australia.
EM ian.scott@health.qld.gov.au
NR 49
TC 3
Z9 3
U1 1
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1444-0903
EI 1445-5994
J9 INTERN MED J
JI Intern. Med. J.
PD SEP
PY 2021
VL 51
IS 9
BP 1388
EP 1400
DI 10.1111/imj.15200
PG 13
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA US0CG
UT WOS:000697104900004
PM 33462882
DA 2022-04-17
ER

PT J
AU Lutz, B
   Kisskalt, D
   Mayr, A
   Regulin, D
   Pantano, M
   Franke, J
AF Lutz, Benjamin
   Kisskalt, Dominik
   Mayr, Andreas
   Regulin, Daniel
   Pantano, Matteo
   Franke, Joerg
TI In-situ identification of material batches using machine learning for
   machining operations
SO JOURNAL OF INTELLIGENT MANUFACTURING
LA English
DT Article
DE Process monitoring; Machine learning; Material batches; Machining
AB In subtractive manufacturing, differences in machinability among batches of the same material can be observed. Ignoring these deviations can potentially reduce product quality and increase manufacturing costs. To consider the influence of the material batch in process optimization models, the batch needs to be efficiently identified. Thus, a smart service is proposed for in-situ material batch identification. This service is driven by a supervised machine learning model, which analyzes the signals of the machine's control, especially torque data, for batch classification. The proposed approach is validated by cutting experiments with five different batches of the same specified material at various cutting conditions. Using this data, multiple classification models are trained and optimized. It is shown that the investigated batches can be correctly identified with close to 90% prediction accuracy using machine learning. Out of all the investigated algorithms, the best results are achieved using a Support Vector Machine with 89.0% prediction accuracy for individual batches and 98.9% while combining batches of similar machinability.
C1 [Lutz, Benjamin; Kisskalt, Dominik; Mayr, Andreas; Franke, Joerg] Friedrich Alexander Univ Erlangen Nurnberg, Inst Factory Automat & Prod Syst, Egerlandstr 7-9, D-91058 Erlangen, Germany.
   [Lutz, Benjamin; Regulin, Daniel; Pantano, Matteo] Siemens AG, Otto Hahn Ring 6, D-81739 Munich, Germany.
RP Lutz, B (corresponding author), Friedrich Alexander Univ Erlangen Nurnberg, Inst Factory Automat & Prod Syst, Egerlandstr 7-9, D-91058 Erlangen, Germany.; Lutz, B (corresponding author), Siemens AG, Otto Hahn Ring 6, D-81739 Munich, Germany.
EM benjamin.lutz@faps.fau.de
OI Lutz, Benjamin/0000-0002-4319-4701
FU Projekt DEAL
FX Open Access funding enabled and organized by Projekt DEAL.
NR 25
TC 4
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0956-5515
EI 1572-8145
J9 J INTELL MANUF
JI J. Intell. Manuf.
PD JUN
PY 2021
VL 32
IS 5
BP 1485
EP 1495
DI 10.1007/s10845-020-01718-3
EA DEC 2020
PG 11
WC Computer Science, Artificial Intelligence; Engineering, Manufacturing
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RX1VA
UT WOS:000602291400001
OA hybrid
DA 2022-04-17
ER

PT J
AU Ri, JH
   Tian, GZ
   Liu, Y
   Xu, WH
   Lou, JG
AF Ri, Jong-Hyok
   Tian, Guanzhong
   Liu, Yong
   Xu, Wei-hua
   Lou, Jun-gang
TI Extreme learning machine with hybrid cost function of G-mean and
   probability for imbalance learning
SO INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS
LA English
DT Article
DE Extreme learning machine; Imbalance learning; G-mean
ID NETWORKS; ALGORITHM; STRATEGY; ELM
AB Extreme learning machine(ELM) is a simple and fast machine learning algorithm. However, similar to other conventional learning algorithms, the classical ELM can not well process the problem of imbalanced data distribution. In this paper, in order to improve the learning performance of classical ELM for imbalanced data learning, we present a novel variant of the ELM algorithm based on a hybrid cost function which employs the probability that given training sample belong in each class to calculate the G-mean. We perform comparable experiments for our approach and the state-of-the-arts methods on standard classification datasets which consist of 58 binary datasets and 9 multiclass datasets under different degrees of imbalance ratio. Experimental results show that our proposed algorithm can improve the classification performance significantly compared with other state-of-the-art methods.
C1 [Ri, Jong-Hyok; Tian, Guanzhong; Liu, Yong; Xu, Wei-hua; Lou, Jun-gang] Zhejiang Univ, Inst Cyber Syst & Control, Hangzhou 310027, Peoples R China.
   [Ri, Jong-Hyok] Kim Il Sung Univ, Inst Informat Technol, Pyongyang 190016, North Korea.
   [Liu, Yong; Xu, Wei-hua] Zhejiang Univ, State Key Lab Ind Control Technol, Hangzhou, Peoples R China.
RP Liu, Y (corresponding author), Zhejiang Univ, Inst Cyber Syst & Control, Hangzhou 310027, Peoples R China.; Liu, Y (corresponding author), Zhejiang Univ, State Key Lab Ind Control Technol, Hangzhou, Peoples R China.
EM yongliu@iipc.zju.edu.cn
OI liu, yong/0000-0003-4822-8939
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61836015, 61771193]
FX This work is supported by the National Natural Science Foundation of
   China under Grant 61836015, 61771193.
NR 42
TC 5
Z9 5
U1 5
U2 18
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-8071
EI 1868-808X
J9 INT J MACH LEARN CYB
JI Int. J. Mach. Learn. Cybern.
PD SEP
PY 2020
VL 11
IS 9
BP 2007
EP 2020
DI 10.1007/s13042-020-01090-x
EA FEB 2020
PG 14
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MP2EM
UT WOS:000515959200001
DA 2022-04-17
ER

PT J
AU Cozman, FG
   Munhoz, HN
AF Cozman, Fabio Gagliardi
   Munhoz, Hugo Neri
TI Some thoughts on knowledge-enhanced machine learning
SO INTERNATIONAL JOURNAL OF APPROXIMATE REASONING
LA English
DT Article
DE Knowledge representation; Machine learning
ID LOGIC; EXPLANATIONS; COMPLEXITY; INFERENCE
AB How can we employ theoretical insights and practical tools from knowledge representation and reasoning to enhance machine learning, and when is it worthwhile to do so? This paper is based on an invited talk delivered at ECSQARU2019 around this question. It emphasizes the knowledge representation and reasoning side of knowledge-enhanced machine learning, looking at a few case studies: the finite model theory of probabilistic languages, the generation of explanations for embeddings, and an "explainable" version of the Winograd Challenge. (C) 2021 Elsevier Inc. All rights reserved.
C1 [Cozman, Fabio Gagliardi; Munhoz, Hugo Neri] Univ Sao Paulo, Escola Politecn, Sao Paulo, Brazil.
RP Cozman, FG (corresponding author), Univ Sao Paulo, Escola Politecn, Sao Paulo, Brazil.
EM fgcozman@usp.br
OI Gagliardi Cozman, Fabio/0000-0003-4077-4935
FU Conselho Nacional de Desenvolvimento Cientifico e Tecnologico
   (CNPq)Conselho Nacional de Desenvolvimento Cientifico e Tecnologico
   (CNPQ) [312180/2018-7]; Fundacao de Amparo a Pesquisa do Estado de Sao
   Paulo (FAPESP)Fundacao de Amparo a Pesquisa do Estado de Sao Paulo
   (FAPESP) [2016/18841-0, 2019/07665-4, 2018/09681-4]; Coordenacao de
   Aperfeicoamento de Pessoal de Nivel Superior (CAPES)Coordenacao de
   Aperfeicoamento de Pessoal de Nivel Superior (CAPES) [001]
FX The first author has been partially supported by the Conselho Nacional
   de Desenvolvimento Cientifico e Tecnologico (CNPq) , grant 312180/20187.
   The second author has been supported by the FundacAo de Amparo a
   Pesquisa do Estado de SAo Paulo (FAPESP) , grant 2018/096814.; The work
   was also supported by the FundacAo de Amparo a Pesquisa do Estado de SAo
   Paulo (FAPESP) , grants 2016/18841-0 and 2019/076654, and also by the
   CoordenacAo de Aperfeicoamento de Pessoal de Nivel Superior (CAPES)
   -finance code 001.
NR 118
TC 1
Z9 1
U1 3
U2 6
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0888-613X
EI 1873-4731
J9 INT J APPROX REASON
JI Int. J. Approx. Reasoning
PD SEP
PY 2021
VL 136
BP 308
EP 324
DI 10.1016/j.ijar.2021.06.003
EA JUL 2021
PG 17
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TP6CL
UT WOS:000677685200016
DA 2022-04-17
ER

PT J
AU Spelda, P
AF Spelda, Petr
TI Machine learning, inductive reasoning, and reliability of
   generalisations
SO AI & SOCIETY
LA English
DT Article
DE Representation; Object naturalism; Subject naturalism; Machine learning;
   Statistical learning theory; Deep learning
ID NETWORKS
AB The present paper shows how statistical learning theory and machine learning models can be used to enhance understanding of AI-related epistemological issues regarding inductive reasoning and reliability of generalisations. Towards this aim, the paper proceeds as follows. First, it expounds Price's dual image of representation in terms of the notions of e-representations and i-representations that constitute subject naturalism. For Price, this is not a strictly anti-representationalist position but rather a dualist one (e- and i-representations). Second, the paper links this debate with machine learning in terms of statistical learning theory becoming more viable epistemological tool when it abandons the perspective of object naturalism. The paper then argues that machine learning grounds a form of knowing that can be understood in terms of e- and i-representation learning. Third, this synthesis shows a way of analysing inductive reasoning in terms of reliability of generalisations stemming from a structure of e- and i-representations. In the age of Artificial Intelligence, connecting Price's dual view of representation with Deep Learning provides an epistemological way forward and even perhaps an approach to how knowing is possible.
C1 [Spelda, Petr] Charles Univ Prague, Periculum Charles Univ Res Ctr Excellence, U Krize 8, Prague 15800 5, Czech Republic.
RP Spelda, P (corresponding author), Charles Univ Prague, Periculum Charles Univ Res Ctr Excellence, U Krize 8, Prague 15800 5, Czech Republic.
EM petr.spelda@fsv.cuni.cz
FU Charles University's research centers program [UNCE/HUM/037];
   Metropolitan University Prague [VVZ C4SS 52-04]
FX This research was supported by the Charles University's research centers
   program no. UNCE/HUM/037. The Human-Machine Nexus and Its Implications
   for the International Order and by the grant from VVZ C4SS 52-04 at
   Metropolitan University Prague. I would like to express my gratitude to
   both anonymous reviewers and dr. Vit Stritecky for the time they
   invested in making insightful suggestions greatly improving the paper.
NR 20
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0951-5666
EI 1435-5655
J9 AI SOC
JI AI Soc.
PD MAR
PY 2020
VL 35
IS 1
BP 29
EP 37
DI 10.1007/s00146-018-0860-6
PG 9
WC Computer Science, Artificial Intelligence
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA KK4CH
UT WOS:000512691600004
DA 2022-04-17
ER

PT J
AU Ahmed, U
   Issa, GF
   Khan, MA
   Aftab, S
   Khan, MF
   Said, RAT
   Ghazal, TM
   Ahmad, M
AF Ahmed, Usama
   Issa, Ghassan F.
   Khan, Muhammad Adnan
   Aftab, Shabib
   Khan, Muhammad Farhan
   Said, Raed A. T.
   Ghazal, Taher M.
   Ahmad, Munir
TI Prediction of Diabetes Empowered With Fused Machine Learning
SO IEEE ACCESS
LA English
DT Article
DE Diabetes; Mathematical models; Support vector machines; Machine
   learning; Diseases; Prediction algorithms; Machine learning algorithms;
   Diabetic prediction; fuzzy system; fused machine learning model;
   diabetic symptoms; disease prediction
ID SVM
AB In the medical field, it is essential to predict diseases early to prevent them. Diabetes is one of the most dangerous diseases all over the world. In modern lifestyles, sugar and fat are typically present in our dietary habits, which have increased the risk of diabetes. To predict the disease, it is extremely important to understand its symptoms. Currently, machine-learning (ML) algorithms are valuable for disease detection. This article presents a model using a fused machine learning approach for diabetes prediction. The conceptual framework consists of two types of models: Support Vector Machine (SVM) and Artificial Neural Network (ANN) models. These models analyze the dataset to determine whether a diabetes diagnosis is positive or negative. The dataset used in this research is divided into training data and testing data with a ratio of 70:30 respectively. The output of these models becomes the input membership function for the fuzzy model, whereas the fuzzy logic finally determines whether a diabetes diagnosis is positive or negative. A cloud storage system stores the fused models for future use. Based on the patient's real-time medical record, the fused model predicts whether the patient is diabetic or not. The proposed fused ML model has a prediction accuracy of 94.87, which is higher than the previously published methods.
C1 [Ahmed, Usama; Khan, Muhammad Adnan] Riphah Int Univ, Fac Comp, Riphah Sch Comp & Innovat, Lahore 54000, Pakistan.
   [Ahmed, Usama; Aftab, Shabib] Virtual Univ Pakistan, Dept Comp Sci, Lahore 54000, Pakistan.
   [Issa, Ghassan F.; Ghazal, Taher M.] Skyline Univ Coll, Sch Informat Technol, Al Sharjah, U Arab Emirates.
   [Khan, Muhammad Adnan] Dachau Univ, Dept Software, Pattern Recognit & Machine Learning Lab, Seongnam Si 13557, South Korea.
   [Aftab, Shabib; Ahmad, Munir] Natl Coll Business Adm & Econ, Sch Comp Sci, Lahore 54000, Pakistan.
   [Khan, Muhammad Farhan] Univ Hlth Sci, Dept Forens Sci, Lahore 54000, Pakistan.
   [Said, Raed A. T.] Canadian Univ Dubai, Fac Management, Dubai, U Arab Emirates.
   [Ghazal, Taher M.] Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Ctr Cyber Secur, Bangi 43600, Selangor, Malaysia.
RP Khan, MA (corresponding author), Riphah Int Univ, Fac Comp, Riphah Sch Comp & Innovat, Lahore 54000, Pakistan.; Khan, MA (corresponding author), Dachau Univ, Dept Software, Pattern Recognit & Machine Learning Lab, Seongnam Si 13557, South Korea.; Ahmad, M (corresponding author), Natl Coll Business Adm & Econ, Sch Comp Sci, Lahore 54000, Pakistan.
EM adnan@gachon.ac.kr; munir@ncbae.edu.pk
RI Ghazal, Taher M./AAS-7443-2021; Ahmad, Munir/F-7482-2018
OI Ghazal, Taher M./0000-0003-0672-7924; Ahmad, Munir/0000-0002-5240-0984;
   Khan, Muhammad Adnan/0000-0003-4854-9935
NR 19
TC 0
Z9 0
U1 7
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2022
VL 10
BP 8529
EP 8538
DI 10.1109/ACCESS.2022.3142097
PG 10
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA YS1QO
UT WOS:000750459200001
OA gold
DA 2022-04-17
ER

PT C
AU Ward, L
   Sivaraman, G
   Pauloski, JG
   Babuji, Y
   Chard, R
   Dandu, N
   Redfern, PC
   Assary, RS
   Chard, K
   Curtiss, LA
   Thakur, R
   Foster, I
AF Ward, Logan
   Sivaraman, Ganesh
   Pauloski, J. Gregory
   Babuji, Yadu
   Chard, Ryan
   Dandu, Naveen
   Redfern, Paul C.
   Assary, Rajeev S.
   Chard, Kyle
   Curtiss, Larry A.
   Thakur, Rajeev
   Foster, Ian
GP IEEE Comp Soc
TI Colmena: Scalable Machine-Learning-Based Steering of Ensemble
   Simulations for High Performance Computing
SO PROCEEDINGS OF THE WORKSHOP ON MACHINE LEARNING IN HIGH PERFORMANCE
   COMPUTING ENVIRONMENTS (MLHPC 2021)
LA English
DT Proceedings Paper
CT 7th IEEE/ACM Workshop on Machine Learning in High Performance Computing
   Environments (MLHPC)
CY NOV 14-19, 2021
CL St Louis, MO
SP IEEE Comp Soc, TCHPC, ACM, SIGHPC, IEEE
DE Machine learning; Computational Steering; Many Task Computing
AB Scientific applications that involve simulation ensembles can be accelerated greatly by using experiment design methods to select the best simulations to perform. Methods that use machine learning (ML) to create proxy models of simulations show particular promise for guiding ensembles but are challenging to deploy because of the need to coordinate dynamic mixes of simulation and learning tasks. We present Colmena, an open-source Python framework that allows users to steer campaigns by providing just the implementations of individual tasks plus the logic used to choose which tasks to execute when. Colmena handles task dispatch, results collation, ML model invocation, and ML model (re)training, using Parsl to execute tasks on HPC systems. We describe the design of Colmena and illustrate its capabilities by applying it to electrolyte design, where it both scales to 65 536 CPUs and accelerates the discovery rate for high-performance molecules by a factor of 100 over unguided searches.
C1 [Ward, Logan; Sivaraman, Ganesh; Chard, Ryan; Thakur, Rajeev; Foster, Ian] Argonne Natl Lab, Data Sci & Learning Div, Lemont, IL 60439 USA.
   [Pauloski, J. Gregory; Babuji, Yadu; Chard, Kyle; Foster, Ian] Univ Chicago, Dept Comp Sci, Chicago, IL 60637 USA.
   [Ward, Logan; Dandu, Naveen; Redfern, Paul C.; Assary, Rajeev S.; Curtiss, Larry A.] Univ Chicago, Joint Ctr Energy Storage Res, Chicago, IL 60637 USA.
RP Ward, L (corresponding author), Argonne Natl Lab, Data Sci & Learning Div, Lemont, IL 60439 USA.; Ward, L (corresponding author), Univ Chicago, Joint Ctr Energy Storage Res, Chicago, IL 60637 USA.
OI /0000-0001-9056-9855
FU ExaLearn Co-design Center of Exascale Computing Project [17-SC-20-SC];
   NSFNational Science Foundation (NSF) [1550588, 2004894]; ALCF Data
   Science Program; US Department of Energy, Office of Science, Basic
   Energy SciencesUnited States Department of Energy (DOE); DOE Office of
   Science User FacilityUnited States Department of Energy (DOE)
   [DE-AC02-06CH11357]
FX LW, GS, GP, RC, RT, and IF acknowledge support by the ExaLearn Co-design
   Center of Exascale Computing Project (17-SC-20-SC), a collaborative
   effort of the U.S. Department of Energy Office of Science and the
   National Nuclear Security Administration, to develop Colmena and
   evaluate its performance on HPC. YB and KC were supported to integrate
   Parsl support into Colmena by NSF Grant 1550588 and ExaWorks Project
   within the Exascale Computing Project. GP and KC were supported to
   develop the value server by NSF Grant 2004894. LW, ND, PCR, RSA, and LAC
   were supported to define the electrolyte design problem and develop the
   computational workflows need to solve it by the Joint Center for Energy
   Storage Research (JCESR), an Energy Innovation Hub funded by the US
   Department of Energy, Office of Science, Basic Energy Sciences. This
   research used resources of the Argonne Leadership Computing Facility
   (ALCF), which is a DOE Office of Science User Facility supported under
   Contract DE-AC02-06CH11357, and was supported by the ALCF Data Science
   Program.
NR 41
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
BN 978-1-6654-1124-0
PY 2021
BP 9
EP 20
DI 10.1109/MLHPC54614.2021.00007
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS7CA
UT WOS:000758468900002
OA Green Submitted
DA 2022-04-17
ER

PT C
AU Laugel, T
   Lesot, MJ
   Marsala, C
   Renard, X
   Detyniecki, M
AF Laugel, Thibault
   Lesot, Marie-Jeanne
   Marsala, Christophe
   Renard, Xavier
   Detyniecki, Marcin
BE Brefeld, U
   Fromont, E
   Hotho, A
   Knobbe, A
   Maathuis, M
   Robardet, C
TI Unjustified Classification Regions and Counterfactual Explanations in
   Machine Learning
SO MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES, ECML PKDD 2019,
   PT II
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT European Conference on Machine Learning and Principles and Practice of
   Knowledge Discovery in Databases (ECML PKDD)
CY SEP 16-20, 2019
CL Wurzburg, GERMANY
SP Bosch, Fraunhofer IAIS, Huawei, ASML, IBM Res, NEC, Kreditech, McKinsey & Co, KNIME, European Res Ctr Informat Syst, Odgers Berndtson, Springer, Vogel Stiftung, German Res Fdn
DE Machine learning interpretability; Counterfactual explanations
AB Post-hoc interpretability approaches, although powerful tools to generate explanations for predictions made by a trained blackbox model, have been shown to be vulnerable to issues caused by lack of robustness of the classifier. In particular, this paper focuses on the notion of explanation justification, defined as connectedness to ground-truth data, in the context of counterfactuals. In this work, we explore the extent of the risk of generating unjustified explanations. We propose an empirical study to assess the vulnerability of classifiers and show that the chosen learning algorithm heavily impacts the vulnerability of the model. Additionally, we show that state-of-the-art post-hoc counterfactual approaches can minimize the impact of this risk by generating less local explanations (Source code available at: https://github.com/thibaultlaugel/truce).
C1 [Laugel, Thibault; Lesot, Marie-Jeanne; Marsala, Christophe; Detyniecki, Marcin] Sorbonne Univ, LIP6, CNRS, F-75005 Paris, France.
   [Renard, Xavier; Detyniecki, Marcin] AXA, Paris, France.
   [Detyniecki, Marcin] Polish Acad Sci, IBS PAN, Warsaw, Poland.
RP Laugel, T (corresponding author), Sorbonne Univ, LIP6, CNRS, F-75005 Paris, France.
EM thibault.laugel@lip6.fr
OI Marsala, Christophe/0000-0002-4022-9796
FU AXA Research Fund
FX This work has been done as part of the Joint Research Initiative (JRI)
   project "Interpretability for human-friendly machine learning models"
   funded by the AXA Research Fund.
NR 30
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-46147-8; 978-3-030-46146-1
J9 LECT NOTES ARTIF INT
PY 2020
VL 11907
BP 37
EP 54
DI 10.1007/978-3-030-46147-8_3
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS4EZ
UT WOS:000718664100003
DA 2022-04-17
ER

PT J
AU Li, L
   Zhao, KY
   Li, SC
   Sun, RZ
   Cai, SH
AF Li, Li
   Zhao, Kaiyi
   Li, Sicong
   Sun, Ruizhi
   Cai, Saihua
TI Extreme Learning Machine for Supervised Classification with Self-paced
   Learning
SO NEURAL PROCESSING LETTERS
LA English
DT Article
DE Classification; Extreme learning machine; Self-paced learning; Accuracy
AB The extreme learning machine (ELM), a typical machine learning algorithm based on feedforward neural network, has been widely used in classification, clustering, regression and feature learning. However, the traditional ELM learns all samples at once, and sample weights of traditional methods are defined before the learning process and they will not change during the learning process. So, its performance is vulnerable to noisy data and outliers, finding a way to solve this problem is meaningful. In this work, we propose a model of self-paced ELM named SP-ELM for binary classification and multi-classification originated from the self-paced learning paradigm. Concretely, the algorithm takes the importance of samples into account according to the loss of predicted value and real value, and it establishes the model from the simple samples to complex samples. By setting certain restrictions, the influence of complex data on the model is reduced. Four different self-paced regularization terms are adopted in the paper to select the instances. Experimental results demonstrate the effectiveness and of the proposed method by comparing it with other improved ELMs.
C1 [Li, Li; Zhao, Kaiyi; Li, Sicong; Sun, Ruizhi; Cai, Saihua] China Agr Univ, Coll Informat & Elect Engn, Beijing 100083, Peoples R China.
   [Sun, Ruizhi] Minist Agr, Sci Res Base Integrated Technol Precis Agr Anim H, Beijing 100083, Peoples R China.
RP Sun, RZ (corresponding author), China Agr Univ, Coll Informat & Elect Engn, Beijing 100083, Peoples R China.; Sun, RZ (corresponding author), Minist Agr, Sci Res Base Integrated Technol Precis Agr Anim H, Beijing 100083, Peoples R China.
EM sunruizhi@cau.edu.cn
OI Cai, Saihua/0000-0003-0743-1156
NR 45
TC 4
Z9 4
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1370-4621
EI 1573-773X
J9 NEURAL PROCESS LETT
JI Neural Process. Lett.
PD DEC
PY 2020
VL 52
IS 3
SI SI
BP 1723
EP 1744
DI 10.1007/s11063-020-10286-9
EA JUN 2020
PG 22
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PB7MK
UT WOS:000541122700001
DA 2022-04-17
ER

PT J
AU Orru, G
   Monaro, M
   Conversano, C
   Gemignani, A
   Sartori, G
AF Orru, Graziella
   Monaro, Merylin
   Conversano, Ciro
   Gemignani, Angelo
   Sartori, Giuseppe
TI Machine Learning in Psychometrics and Psychological Research
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE machine learning; cross-validation; replicability; machine learning in
   psychological experiments; machine learning in psychometrics
ID CROSS-VALIDATION; FUTURE; RATIO
AB Recent controversies about the level of replicability of behavioral research analyzed using statistical inference have cast interest in developing more efficient techniques for analyzing the results of psychological experiments. Here we claim that complementing the analytical workflow of psychological experiments with Machine Learning-based analysis will both maximize accuracy and minimize replicability issues. As compared to statistical inference, ML analysis of experimental data is model agnostic and primarily focused on prediction rather than inference. We also highlight some potential pitfalls resulting from adoption of Machine Learning based experiment analysis. If not properly used it can lead to over-optimistic accuracy estimates similarly observed using statistical inference. Remedies to such pitfalls are also presented such and building model based on cross validation and the use of ensemble models. ML models are typically regarded as black boxes and we will discuss strategies aimed at rendering more transparent the predictions.
C1 [Orru, Graziella; Conversano, Ciro; Gemignani, Angelo] Univ Pisa, Dept Surg Med Mol & Crit Area Pathol, Pisa, Italy.
   [Monaro, Merylin; Sartori, Giuseppe] Univ Padua, Dept Gen Psychol, Padua, Italy.
RP Orru, G (corresponding author), Univ Pisa, Dept Surg Med Mol & Crit Area Pathol, Pisa, Italy.
EM graziella.orru@gmail.com; giuseppe.sartori@unipd.it
RI Monaro, Merylin/AAM-3066-2021; Gemignani, Angelo/AAC-3308-2022; Orru,
   Graziella/AAT-2410-2020; Sartori, Giuseppe/B-8140-2008; Conversano,
   Ciro/ABE-1007-2020
OI Monaro, Merylin/0000-0001-5598-691X; Orru,
   Graziella/0000-0002-8769-7693; Conversano, Ciro/0000-0002-0726-3634
FU BACKUP Project Horizon 2020
FX GO, MM, and GS were found within the BACKUP Project Horizon 2020.
NR 50
TC 26
Z9 26
U1 9
U2 10
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JAN 10
PY 2020
VL 10
AR 2970
DI 10.3389/fpsyg.2019.02970
PG 10
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA KF5KP
UT WOS:000509281100001
PM 31998200
OA gold, Green Published
DA 2022-04-17
ER

PT J
AU Lou, RR
   Lv, ZH
   Dang, SP
   Su, TY
   Li, XF
AF Lou, Ranran
   Lv, Zhihan
   Dang, Shuping
   Su, Tianyun
   Li, Xinfang
TI Application of machine learning in ocean data
SO MULTIMEDIA SYSTEMS
LA English
DT Article; Early Access
DE Ocean; Data; Ocean data; Machine learning
ID DEEP NEURAL-NETWORK; RISK ANALYSIS; INDEX; CLASSIFICATION; PREDICTION;
   ALGORITHM; COASTAL; IDENTIFICATION; MODULATION; MODELS
AB In recent years, machine learning has become a hot research method in various fields and has been applied to every aspect of our life, providing an intelligent solution to problems that could not be solved or difficult to be solved before. Machine learning is driven by data. It learns from a part of the input data and builds a model. The model is used to predict and analyze another part of the data to get the results people want. With the continuous advancement of ocean observation technology, the amount of ocean data and data dimensions are rising sharply. The use of traditional data analysis methods to analyze massive amounts of data has revealed many shortcomings. The development of machine learning has solved these shortcomings. Nowadays, the use of machine learning technology to analyze and apply ocean data becomes the focus of scientific research. This method has important practical and long-term significance for protecting the ocean environment, predicting ocean elements, exploring the unknown, and responding to extreme weather. This paper focuses on the analysis of the state of the art and specific practices of machine learning in ocean data, review the application examples of machine learning in various fields such as ocean sound source identification and positioning, ocean element prediction, ocean biodiversity monitoring, and deep-sea resource monitoring. We also point out some constraints that still exist in the research and put forward the future development direction and application prospects.
C1 [Lou, Ranran; Lv, Zhihan] Qingdao Univ QDU, Sch Data Sci & Software Engn, Qingdao, Peoples R China.
   [Su, Tianyun; Li, Xinfang] Pilot Natl Lab Marine Sci & Technol, Lab Reg Oceanog & Numer Modeling, Qingdao, Peoples R China.
   [Su, Tianyun; Li, Xinfang] MNR, Inst Oceanog 1, Marine Data & Informat Ctr, Qingdao, Peoples R China.
   [Su, Tianyun; Li, Xinfang] AeroSp Ground Ocean Big Data Applicat Technol, Natl Engn Lab Integrated, Qingdao, Peoples R China.
   [Dang, Shuping] King Abdullah Univ Sci & Technol KAUST, Comp Elect & Math Sci & Engn Div, Thuwal, Saudi Arabia.
RP Lv, ZH (corresponding author), Qingdao Univ QDU, Sch Data Sci & Software Engn, Qingdao, Peoples R China.
EM louranran1113@gmail.com; lvzhihan@gmail.com; shuping.dang@kaust.edu.sa;
   sutiany@fio.org.cn; lixinfang@fio.org.cn
RI Lv, Zhihan/I-3187-2014
OI Lv, Zhihan/0000-0003-2525-3074
FU National Natural Science Foundation of China (NSFC)National Natural
   Science Foundation of China (NSFC) [61902203]; Key Research and
   Development Plan-Major Scientific and Technological Innovation Projects
   of ShanDong Province [2019JZZY020101]
FX This work was supported in part by the National Natural Science
   Foundation of China (NSFC) under Grant no. 61902203, Key Research and
   Development Plan-Major Scientific and Technological Innovation Projects
   of ShanDong Province (2019JZZY020101).
NR 96
TC 26
Z9 26
U1 40
U2 62
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0942-4962
EI 1432-1882
J9 MULTIMEDIA SYST
JI Multimedia Syst.
DI 10.1007/s00530-020-00733-x
EA FEB 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QG8MB
UT WOS:000617834300001
OA Green Submitted
HC Y
HP N
DA 2022-04-17
ER

PT J
AU Lohani, S
   Kirby, BT
   Brodsky, M
   Danaci, O
   Glasser, RT
AF Lohani, Sanjaya
   Kirby, Brian T.
   Brodsky, Michael
   Danaci, Onur
   Glasser, Ryan T.
TI Machine learning assisted quantum state estimation
SO MACHINE LEARNING-SCIENCE AND TECHNOLOGY
LA English
DT Article
DE machine learning; quantum tomography; convolutional neural networks;
   deep learning; quantum optics
ID NEURAL-NETWORKS; ENTANGLEMENT
AB We build a general quantum state tomography framework that makes use of machine learning techniques to reconstruct quantum states from a given set of coincidence measurements. For a wide range of pure and mixed input states we demonstrate via simulations that our method produces functionally equivalent reconstructed states to that of traditional methods with the added benefit that expensive computations are front-loaded with our system. Further, by training our system with measurement results that include simulated noise sources we are able to demonstrate a significantly enhanced average fidelity when compared to typical reconstruction methods. These enhancements in average fidelity are also shown to persist when we consider state reconstruction from partial tomography data where several measurements are missing. We anticipate that the present results combining the fields of machine intelligence and quantum state estimation will greatly improve and speed up tomography-based quantum experiments.
C1 [Lohani, Sanjaya; Danaci, Onur; Glasser, Ryan T.] Tulane Univ, New Orleans, LA 70118 USA.
   [Kirby, Brian T.; Brodsky, Michael] United States Army Res Lab, Adelphi, MD 20783 USA.
RP Lohani, S (corresponding author), Tulane Univ, New Orleans, LA 70118 USA.
EM slohani@tulane.edu; brian.t.kirby4.civ@mail.mil; rglasser@tulane.edu
RI Lohani, Sanjaya/J-8207-2019
OI Lohani, Sanjaya/0000-0003-0699-0669; Glasser, Ryan/0000-0001-7257-9064;
   Kirby, Brian/0000-0002-2698-9887
FU Army Research LaboratoryUnited States Department of DefenseUS Army
   Research Laboratory (ARL); Army Research Office [W911NF-19-2-0087,
   W911NF-20-2-0168]
FX This material is based upon work supported by, or in part by, the Army
   Research Laboratory and the Army Research Office under contract/grant
   numbers W911NF-19-2-0087 and W911NF-20-2-0168. The views and conclusions
   contained in this document are those of the authors and should not be
   interpreted as representing the official policies, either expressed or
   implied, of the Army Research Laboratory or the U S Government. The U S
   Government is authorized to reproduce and distribute reprints for
   Government purposes notwithstanding any copyright notation herein.
NR 32
TC 19
Z9 19
U1 2
U2 3
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
EI 2632-2153
J9 MACH LEARN-SCI TECHN
JI Mach. Learn.-Sci. Technol.
PD SEP
PY 2020
VL 1
IS 3
AR 035007
DI 10.1088/2632-2153/ab9a21
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Science & Technology - Other Topics
GA SR2FE
UT WOS:000660858500001
OA Green Submitted, gold
DA 2022-04-17
ER

PT J
AU Fitchett, JC
   Karadimitriou, K
   West, Z
   Hughes, DM
AF Fitchett, James C.
   Karadimitriou, Kosmas
   West, Zella
   Hughes, David M.
TI Machine Learning for Pipe Condition Assessments
SO JOURNAL AMERICAN WATER WORKS ASSOCIATION
LA English
DT Article
DE Pipes; Rehabilitation; Condition Assessment; Machine Learning
AB Key Takeaways
   Utilities replace water mains by responding to failures or proactively choosing pipes likely to fail. Machine learning can find fragile pipes more accurately than using age or historical breaks as indicators.
   More accurate and often less expensive than other condition assessments, machine learning uses hundreds of variables to find patterns most people can't see.
   Timely selection of the right pipes to inspect, repair, or replace can reduce breaks and optimize the pipes' remaining useful life.
C1 [Fitchett, James C.; Karadimitriou, Kosmas; West, Zella] VODA Ai, Boston, MA 02109 USA.
RP Fitchett, JC (corresponding author), VODA Ai, Boston, MA 02109 USA.
EM jim@voda.ai
NR 0
TC 2
Z9 2
U1 4
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 2164-4535
EI 1551-8833
J9 J AM WATER WORKS ASS
JI J. Am. Water Work Assoc.
PD MAY
PY 2020
VL 112
IS 5
BP 50
EP 55
DI 10.1002/awwa.1501
PG 6
WC Engineering, Civil; Water Resources
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Water Resources
GA LJ3QH
UT WOS:000530082100008
DA 2022-04-17
ER

PT J
AU Khan, MA
   Ghazal, TM
   Lee, SW
   Rehman, A
AF Khan, Muhammad Adnan
   Ghazal, Taher M.
   Lee, Sang-Woong
   Rehman, Abdur
TI Data Fusion-Based Machine Learning Architecture for Intrusion Detection
SO CMC-COMPUTERS MATERIALS & CONTINUA
LA English
DT Article
DE Wireless internet of sensor networks; machine learning; deep extreme
   learning machine; artificial intelligence; data fusion
ID SMART CITIES; OPTIMIZATION; SIMULATION; NETWORKS; CITY
AB In recent years, the infrastructure of Wireless Internet of Sensor Networks (WIoSNs) has been more complicated owing to developments in the internet and devices' connectivity. To effectively prepare, control, hold and optimize wireless sensor networks, a better assessment needs to be conducted. The field of artificial intelligence has made a great deal of progress with deep learning systems and these techniques have been used for data analysis. This study investigates the methodology of Real Time Sequential Deep Extreme Learning Machine (RTS-DELM) implemented to wireless Internet of Things (IoT) enabled sensor networks for the detection of any intrusion activity. Data fusion is a well-known methodology that can be beneficial for the improvement of data accuracy, as well as for the maximizing of wireless sensor networks lifespan. We also suggested an approach that not only makes the casting of parallel data fusion network but also render their computations more effective. By using the Real Time Sequential Deep Extreme Learning Machine (RTSDELM) methodology, an excessive degree of reliability with a minimal error rate of any intrusion activity in wireless sensor networks is accomplished. Simulation results show that wireless sensor networks are optimized effectively to monitor and detect any malicious or intrusion activity through this proposed approach. Eventually, threats and a more general outlook are explored.
C1 [Khan, Muhammad Adnan; Lee, Sang-Woong] Gachon Univ, Dept Software, Pattern Recognit & Machine Learning Lab, Seongnam 13557, South Korea.
   [Ghazal, Taher M.] Univ Kebansaan Malaysia UKM, Fac Informat Sci & Technol, Ctr Cyber Secur, Bangi 43600, Selangor, Malaysia.
   [Ghazal, Taher M.] Univ City Sharjah, Sch Informat Technol, Skyline Univ Coll, Sharjah 1797, U Arab Emirates.
   [Rehman, Abdur] Natl Coll Business Adm & Econ, Sch Comp Sci, Lahore 54000, Pakistan.
RP Lee, SW (corresponding author), Gachon Univ, Dept Software, Pattern Recognit & Machine Learning Lab, Seongnam 13557, South Korea.
EM slee@gachon.ac.kr
RI Sakhawat, Abdur Rehman/AAG-6184-2020; Ghazal, Taher M./AAS-7443-2021
OI Sakhawat, Abdur Rehman/0000-0002-5867-8231; Ghazal, Taher
   M./0000-0003-0672-7924; Khan, Muhammad Adnan/0000-0003-4854-9935
NR 57
TC 1
Z9 1
U1 9
U2 9
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1546-2218
EI 1546-2226
J9 CMC-COMPUT MATER CON
JI CMC-Comput. Mat. Contin.
PY 2022
VL 70
IS 2
BP 3399
EP 3413
DI 10.32604/cmc.2022.020173
PG 15
WC Computer Science, Information Systems; Materials Science,
   Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Materials Science
GA WD5UT
UT WOS:000705006000001
OA gold
DA 2022-04-17
ER

PT C
AU Blanzeisky, W
   Cunningham, P
AF Blanzeisky, William
   Cunningham, Padraig
BE Kamp, M
   Koprinska, I
   Bibal, A
   Bouadi, T
   Frenay, B
   Galarraga, L
   Oramas, J
   Adilova, L
TI Algorithmic Factors Influencing Bias in Machine Learning
SO MACHINE LEARNING AND PRINCIPLES AND PRACTICE OF KNOWLEDGE DISCOVERY IN
   DATABASES, ECML PKDD 2021, PT I
SE Communications in Computer and Information Science
LA English
DT Proceedings Paper
CT 21st Joint European Conference on Machine Learning and Principles and
   Practice of Knowledge Discovery in Databases (ECML PKDD)
CY SEP 13-17, 2021
CL ELECTR NETWORK
SP Google, ASML, Amazon, Ikerlan, KNIME, EurAi, Springer
DE Bias; Fairness; Model capacity; Regularisation
ID DISCRIMINATION; REGRESSION
AB It is fair to say that many of the prominent examples of bias in Machine Learning (ML) arise from bias in the training data. In fact, some would argue that supervised ML algorithms cannot be biased, they reflect the data on which they are trained. In this paper, we demonstrate how ML algorithms can misrepresent the training data through underestimation. We show how irreducible error, regularization, and feature and class imbalance can contribute to this underestimation. The paper concludes with a demonstration of how the careful management of synthetic counterfactuals can ameliorate the impact of this underestimation bias.
C1 [Blanzeisky, William; Cunningham, Padraig] Univ Coll Dublin, Sch Comp Sci, Dublin 4, Dublin, Ireland.
RP Blanzeisky, W (corresponding author), Univ Coll Dublin, Sch Comp Sci, Dublin 4, Dublin, Ireland.
EM william.blanzeisky@ucdconnect.ie
OI Cunningham, Padraig/0000-0002-3499-0810
FU Science Foundation Ireland through the SFI Centre for Research Training
   in Machine LearningScience Foundation Ireland [18/CRT/6183]; Microsoft
   Ireland
FX This work was funded by Science Foundation Ireland through the SFI
   Centre for Research Training in Machine Learning (Grant No. 18/CRT/6183)
   with support from Microsoft Ireland.
NR 27
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1865-0929
EI 1865-0937
BN 978-3-030-93736-2; 978-3-030-93735-5
J9 COMM COM INF SC
PY 2021
VL 1524
BP 559
EP 574
DI 10.1007/978-3-030-93736-2_41
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS8LL
UT WOS:000773469200041
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Yang, L
   Feng, L
   Zhang, LQ
   Tian, LW
AF Yang, Lei
   Feng, Li
   Zhang, Longqing
   Tian, Liwei
TI Predicting freshmen enrollment based on machine learning
SO JOURNAL OF SUPERCOMPUTING
LA English
DT Article
DE Deep learning; Enrollment; Data mining; Machine learning
AB The enrollment rate of freshmen has always been a headache for colleges and universities. It is also very difficult to accurately predict the number of freshmen before they register. In recent years, deep learning and machine learning technology have made a breakthrough and are widely used in data processing, edge computing, and situation awareness. So far, no researcher has used machine learning methods to forecast the enrollment of new students, because the intuitive feeling is that the registration of a freshman is very subjective, dependent on several factors. To date, the number of freshmen in universities has always been forecasted using traditional methods, that is, phone calls and fee payment status inquiries. On the basis of the historical admission enrollment data of a university, this study used a variety of machine learning methods, including decision tree, random forest, and back propagation neural network, for forecasting. Based on the results of our research, it is possible to predict whether a freshman will register in a university, which makes this work very worthy of further study.
C1 [Yang, Lei; Feng, Li; Zhang, Longqing; Tian, Liwei] Macau Univ Sci & Technol, WeiLong Rd, Macau, Peoples R China.
RP Feng, L (corresponding author), Macau Univ Sci & Technol, WeiLong Rd, Macau, Peoples R China.
EM lfeng@must.edu.mo
OI Yang, Lei/0000-0001-6526-809X
FU National Nature Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61872452, 61872451, 61702365]; Macao FDCT
   [0098/2018/A3, 0076/2019/A2, 0037/2020/A1]
FX This work was supported in part by the National Nature Science
   Foundation of China under Grants 61872452, 61872451, and 61702365, in
   part by the Macao FDCT under Grants 0098/2018/A3, 0076/2019/A2, and
   0037/2020/A1. Li Feng is the corresponding author.
NR 31
TC 0
Z9 0
U1 11
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0920-8542
EI 1573-0484
J9 J SUPERCOMPUT
JI J. Supercomput.
PD OCT
PY 2021
VL 77
IS 10
BP 11853
EP 11865
DI 10.1007/s11227-021-03763-y
EA MAR 2021
PG 13
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UP8WV
UT WOS:000634689500005
DA 2022-04-17
ER

PT J
AU Bibal, A
   Lognoul, M
   de Streel, A
   Frenay, B
AF Bibal, Adrien
   Lognoul, Michael
   de Streel, Alexandre
   Frenay, Benoit
TI Legal requirements on explainability in machine learning
SO ARTIFICIAL INTELLIGENCE AND LAW
LA English
DT Article
DE Interpretability; Explainability; Machine learning; Law
ID AUTOMATED DECISION-MAKING; MODELS; EXPLANATION; SELECTION
AB Deep learning and other black-box models are becoming more and more popular today. Despite their high performance, they may not be accepted ethically or legally because of their lack of explainability. This paper presents the increasing number of legal requirements on machine learning model interpretability and explainability in the context of private and public decision making. It then explains how those legal requirements can be implemented into machine-learning models and concludes with a call for more inter-disciplinary research on explainability.
C1 [Bibal, Adrien; Frenay, Benoit] Univ Namur, Fac Comp Sci, PReCISE, NADI, Rue Grandgagnage 21, B-5000 Namur, Belgium.
   [Lognoul, Michael; de Streel, Alexandre] Univ Namur, Fac Law, CRIDS, NADI, Rempart Vierge 5, B-5000 Namur, Belgium.
RP Bibal, A (corresponding author), Univ Namur, Fac Comp Sci, PReCISE, NADI, Rue Grandgagnage 21, B-5000 Namur, Belgium.
EM adrien.bibal@unamur.be; michael.lognoul@unamur.be;
   alexandre.destreel@unamur.be; benoit.frenay@unamur.be
OI Frenay, Benoit/0000-0002-7859-2750
NR 41
TC 11
Z9 11
U1 4
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-8463
EI 1572-8382
J9 ARTIF INTELL LAW
JI Artif. Intell. Law
PD JUN
PY 2021
VL 29
IS 2
BP 149
EP 169
DI 10.1007/s10506-020-09270-4
EA JUL 2020
PG 21
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Law
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Government & Law
GA SD6HV
UT WOS:000559371800001
DA 2022-04-17
ER

PT C
AU Krishnamurthy, P
   Chowdhury, AB
   Tan, B
   Khorrami, F
   Karri, R
AF Krishnamurthy, Prashanth
   Chowdhury, Animesh Basak
   Tan, Benjamin
   Khorrami, Farshad
   Karri, Ramesh
GP ACM
TI Explaining and Interpreting Machine Learning CAD Decisions: An IC
   Testing Case Study
SO PROCEEDINGS OF THE 2020 ACM/IEEE 2ND WORKSHOP ON MACHINE LEARNING FOR
   CAD (MLCAD '20)
LA English
DT Proceedings Paper
CT 2nd ACM/IEEE Workshop on Machine Learning for CAD (MLCAD)
CY NOV 16-20, 2020
CL ELECTR NETWORK
SP IEEE, Assoc Comp Machinery, ACM Special Interest Grp Design Automat, IEEE Council Elect Design Automat
DE Interpretable Machine Learning; IC Testing; Test-Point Insertion
AB We provide a methodology to explain and interpret machine learning decisions in Computer-Aided Design (CAD) flows. We demonstrate the efficacy of the methodology to the VLSI testing case. Such a tool will provide designers with insight into the "black box" machine learning models/classifiers through human readable sentences based on normally understood design rules or new design rules. The methodology builds on an intrinsically explainable, rule-based ML framework, called Sentences in Feature Subsets (SiFS), to mine human readable decision rules from empirical data sets. SiFS derives decision rules as compact Boolean logic sentences involving subsets of features in the input data. The approach is applied to test point insertion problem in circuits and compared to the ground truth and traditional design rules.
C1 [Krishnamurthy, Prashanth; Chowdhury, Animesh Basak; Tan, Benjamin; Khorrami, Farshad; Karri, Ramesh] NYU, Brooklyn, NY 11201 USA.
RP Krishnamurthy, P (corresponding author), NYU, Brooklyn, NY 11201 USA.
EM prashanth.krishnamurthy@nyu.edu; abc586@nyu.edu; benjamin.tan@nyu.edu;
   khorrami@nyu.edu; rkarri@nyu.edu
RI Tan, Benjamin/Q-8521-2019
OI Tan, Benjamin/0000-0002-7642-3638
FU ONR Award [N00014-18-1-2058, N00014-18-12672]; DARPAUnited States
   Department of DefenseDefense Advanced Research Projects Agency (DARPA)
   [FA8750-20-1-0502]; NYU/NYUAD Center for Cyber Security
FX This work was supported in part by ONR Award #N00014-18-12672 and DARPA
   grant #FA8750-20-1-0502. B. Tan and R. Karri are supported in part by
   ONR Award #N00014-18-1-2058. R. Karri is supported in part by the
   NYU/NYUAD Center for Cyber Security.
NR 16
TC 1
Z9 1
U1 2
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-7519-1
PY 2020
BP 129
EP 134
DI 10.1145/3380446.3430643
PG 6
WC Computer Science, Artificial Intelligence; Engineering, Manufacturing;
   Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BR8CI
UT WOS:000670756800027
DA 2022-04-17
ER

PT J
AU Kadam, S
   Vaidya, V
AF Kadam, Suvarna
   Vaidya, Vinay
TI Cognitive Evaluation of Machine Learning Agents
SO COGNITIVE SYSTEMS RESEARCH
LA English
DT Article
DE Cognition Framework; Machine Learning; Cognitive Evaluation; Machine
   Cognition; Cognition Metrics; Evaluation Metrics
ID BLOOMS TAXONOMY; MEMORY; INTELLIGENCE; NEUROSCIENCE; MINDS
AB Advances in applying statistical Machine Learning (ML) led to several claims of human-level or near-human performance in tasks such as image classification & speech recognition. Such claims are unscientific primarily for two reasons, (1) They incorrectly enforce the notion that task-specific performance can be treated as manifestation of General Intelligence and (2) They are not verifiable as currently there is no set benchmark for measuring human-like cognition in a machine learning agent. Moreover, ML agent's performance is influenced by knowledge ingested in it by its human designers. Therefore, agent's performance may not necessarily reflect its true cognition. In this paper, we propose a framework that draws parallels from human cognition to measure machine's cognition. Human cognitive learning is quite well studied in developmental psychology with frameworks and metrics in place to measure actual learning. To either believe or refute the claims of human-level performance of machine learning agent, we need scientific methodology to measure its cognition. Our framework formalizes incremental implementation of human-like cognitive processes in ML agents with an implicit goal to measure it. The framework offers guiding principles for measuring, (1) Task-specific machine cognition and (2) General machine cognition that spans across tasks. The framework also provides guidelines for building domain-specific task taxonomies to cognitively profile tasks. We demonstrate application of the framework with a case study where two ML agents that perform Vision and NLP tasks are cognitively evaluated. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Kadam, Suvarna; Vaidya, Vinay] SPPU, Dept Technol, Pune, Maharashtra, India.
RP Kadam, S (corresponding author), SPPU, Dept Technol, Pune, Maharashtra, India.
EM skadam@unipune.ac.in
RI Kadam, Suvarna/N-3807-2019
OI Kadam, Suvarna/0000-0003-1772-4657
NR 95
TC 0
Z9 0
U1 2
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2214-4366
EI 1389-0417
J9 COGN SYST RES
JI Cogn. Syst. Res.
PD MAR
PY 2021
VL 66
BP 100
EP 121
DI 10.1016/j.cogsys.2020.11.003
PG 22
WC Computer Science, Artificial Intelligence; Neurosciences; Psychology,
   Experimental
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Neurosciences & Neurology; Psychology
GA SJ5DX
UT WOS:000655556100009
DA 2022-04-17
ER

PT C
AU Das, S
   Agarwal, N
   Venugopal, D
   Sheldon, FT
   Shiva, S
AF Das, Saikat
   Agarwal, Namita
   Venugopal, Deepak
   Sheldon, Frederick T.
   Shiva, Sajjan
GP IEEE
TI Taxonomy and Survey of Interpretable Machine Learning Method
SO 2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI)
LA English
DT Proceedings Paper
CT IEEE Symposium Series on Computational Intelligence (IEEE SSCI)
CY DEC 01-04, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Computat Intelligence Soc
DE Interpretable machine learning; taxonomy; survey; black box machine
   learning; machine learning
ID MODELS
AB Since traditional machine learning (ML) techniques use black-box model, the internal operation of the classifier is unknown to human. Due to this black-box nature of the ML classifier, the trustworthiness of their predictions is sometimes questionable. Interpretable machine learning (IML) is a way of dissecting the ML classifiers to overcome this shortcoming and provide a more reasoned explanation of model predictions. In this paper, we explore several IML methods and their applications in various domains. Moreover, a detailed survey of IML methods along with identifying the essential building blocks of a black-box model is presented here. Herein, we have identified and described the requirements of IML methods and for completeness, a taxonomy of IML methods which classifies each into distinct groupings or sub-categories, is proposed. The goal, therefore, is to describe the state-of-the-art for IML methods and explain those in more concrete and understandable ways by providing better basis of knowledge for those building blocks and our associated requirements analysis.
C1 [Das, Saikat; Agarwal, Namita; Venugopal, Deepak; Shiva, Sajjan] Univ Memphis, Dept Comp Sci, Memphis, TN 38152 USA.
   [Sheldon, Frederick T.] Univ Idaho, Dept Comp Sci, Coeur Dalene, ID USA.
RP Das, S (corresponding author), Univ Memphis, Dept Comp Sci, Memphis, TN 38152 USA.
EM sdas1@memphis.edu; nfnu@memphis.edu; dvngopal@memphis.edu;
   sheldon@uidaho.edu; sshiva@memphis.edu
NR 41
TC 2
Z9 2
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-2547-3
PY 2020
BP 670
EP 677
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BS0GU
UT WOS:000682772900091
DA 2022-04-17
ER

PT C
AU Rosiene, JA
   Rosiene, CP
AF Rosiene, Joel A.
   Rosiene, Carolyn Pe
GP IEEE
TI SPAM: Simplifying Python for Approaching Machine Learning
SO 2020 IEEE FRONTIERS IN EDUCATION CONFERENCE (FIE 2020)
SE Frontiers in Education Conference
LA English
DT Proceedings Paper
CT IEEE Frontiers in Education Conference (FIE)
CY OCT 21-24, 2020
CL Uppsala, SWEDEN
SP IEEE, Amer Soc Engn Educ, Educ Res & Methods Div, IEEE Educ Soc, IEEE Comp Soc
DE Python; machine learning; functors; monads
AB This WIP paper presents an approach to teaching Python in a first course in machine learning for non-majors. The flexibility of Python enables a skilled programmer to be very expressive, but it can be troublesome to the new student. Students who come to Python from an imperative language often approach the language "non-Pythonically", leading to reliance on traditional programming constructs. We present an alternative approach whereby the concept of functors and monads are introduced early to aid in teaching and learning machine learning.
C1 [Rosiene, Joel A.] Eastern Connecticut State Univ, Dept Comp Sci, Windham, CT 06226 USA.
   [Rosiene, Carolyn Pe] Univ Hartford, Dept Comp Sci, Hartford, CT 06117 USA.
RP Rosiene, JA (corresponding author), Eastern Connecticut State Univ, Dept Comp Sci, Windham, CT 06226 USA.
EM rosienej@easternct.edu; rosiene@hartford.edu
NR 6
TC 0
Z9 0
U1 0
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 0190-5848
BN 978-1-7281-8961-1
J9 PROC FRONT EDUC CONF
PY 2020
PG 3
WC Education, Scientific Disciplines; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Education & Educational Research; Engineering
GA BR3IP
UT WOS:000646660800104
DA 2022-04-17
ER

PT C
AU Fournier-Viger, P
   Nawaz, MS
   Song, W
   Gan, WS
AF Fournier-Viger, Philippe
   Nawaz, M. Saqib
   Song, Wei
   Gan, Wensheng
BE Kamp, M
   Koprinska, I
   Bibal, A
   Bouadi, T
   Frenay, B
   Galarraga, L
   Oramas, J
   Adilova, L
TI Machine Learning for Intelligent Industrial Design
SO MACHINE LEARNING AND PRINCIPLES AND PRACTICE OF KNOWLEDGE DISCOVERY IN
   DATABASES, PT II
SE Communications in Computer and Information Science
LA English
DT Proceedings Paper
CT 21st Joint European Conference on Machine Learning and Principles and
   Practice of Knowledge Discovery in Databases (ECML PKDD)
CY SEP 13-17, 2021
CL ELECTR NETWORK
SP Google, ASML, Amazon, Ikerlan, KNIME, EurAi, Springer
DE Machine learning; Product design; Industrial design; Product users;
   Review
ID PRODUCT DESIGN; SYSTEM; ACCEPTABILITY; OPTIMIZATION; METHODOLOGY;
   SUPPORT
AB Machine learning (ML) techniques have been used to build intelligent software for several domains. This paper reviews and discuss opportunities for using these techniques to build intelligent software for industrial design. Industrial design, sometimes called product design or new product development, is the process of conceiving products to be mass-produced in factories. It consists of several steps such as: analyzing potential customers wants and needs, planning, prototype design, and user evaluation. During each of these steps, data can be collected as documents such as product specifications and feedback forms, or by other means such as using sensors. A promising way of improving these processes to reduce costs (time and investments) and produce better designs, is to analyze data generated or used during product design using ML techniques, and to build intelligent design software. Although several studies have been carried out on this topic, there remains numerous research opportunities. This paper provides a survey of recent studies related to the use of ML in industrial design. The goal is to provide an introduction to this emerging research area and highlight limitations of previous studies and opportunities.
C1 [Fournier-Viger, Philippe; Nawaz, M. Saqib] Harbin Inst Technol Shenzhen, Shenzhen, Peoples R China.
   [Song, Wei] North China Univ Technol, Beijing, Peoples R China.
   [Gan, Wensheng] Jinan Univ, Guangzhou, Peoples R China.
RP Fournier-Viger, P (corresponding author), Harbin Inst Technol Shenzhen, Shenzhen, Peoples R China.
EM philfv@hit.edu.cn; msaqibnawaz@hit.edu.cn; songwei@ncut.edu.cn;
   wsgan@jnu.edu.cn
OI Song, Wei/0000-0003-0649-8850; Gan, Wensheng/0000-0002-5781-8116
NR 47
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1865-0929
EI 1865-0937
BN 978-3-030-93733-1; 978-3-030-93732-4
J9 COMM COM INF SC
PY 2021
VL 1525
BP 158
EP 172
DI 10.1007/978-3-030-93733-1_11
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS8EC
UT WOS:000771712800011
DA 2022-04-17
ER

PT J
AU Alehegn, M
AF Alehegn, Minyechil
TI Application of machine learning and deep learning for the prediction of
   HIV/AIDS
SO HIV & AIDS REVIEW
LA English
DT Article
DE deep learning; HIV/AIDS; machine learning; prediction
AB Introduction: Nowadays human immunodeficiency virus (HIV)/acquired immunodeficiency syndrome (AIDS) is very dangerous. HIV targets the resistant system and weakens people's denial against many contaminations and some kinds of cancer. As the virus breaks up and impairs the function of immunity, infected people gradually become immunodeficient. Both deep learning and machine learning models play a great role in the prediction of diseases. The function of immunity is CD4 cell count. In this study both the machine learning and deep learning algorithms were applied.
   Material and methods: In this paper the data were collected from data world. Support vector machine, random forest, naive Bayes, gated recurrent unit, and long short-term memory were used to fit the incidence data. The performance of the model was evaluated by accuracy, precision, sensitivity, and F-score with respective errors.
   Results: Based on the evaluation, deep learning models achieve better results in the metrics of accuracy, precision, and F-score than machine learning models. But in sensitivity metrics machine learning models achieve better result than deep learning. Machine learning algorithms SVM, RF, and NB provide accuracy of 89.00%, 87.00%, and 86.94%; precision of 75.89%, 74.97%, and 75.78%; sensi-tivity of 87.96%, 84.00%, and 84.12%; F-score of 82.87%, 80.03%, and 79.05%, respectively. LSTM, GRU provides accuracy of 97.65%, 96.00%, precision of 77.35%, 84.00%, sensitivity of 87.93%, 82.98%, and F-score of 82.03%, 83.20%, respectively.
   Conclusions: The possibility survival of the illness is less than no illness. The existence of TB negative is higher than TB positive. In the machine learning model SVM provides better sensitivity with 87.96%, long short-term memory provides accuracy of 97.65%, precision of 77.35%, sensitivity of 87.93%, and F-score of 82.03%.
C1 [Alehegn, Minyechil] Mizan Tepi Univ, Tepi, Ethiopia.
RP Alehegn, M (corresponding author), Mizan Tepi Univ, Tepi, Ethiopia.
EM minyechil21@gmail.com
OI Tefera, Minyechil Alehegn/0000-0001-5046-7002
NR 28
TC 0
Z9 0
U1 0
U2 0
PU TERMEDIA PUBLISHING HOUSE LTD
PI POZNAN
PA KLEEBERGA ST 2, POZNAN, 61-615, POLAND
SN 1730-1270
EI 1732-2707
J9 HIV AIDS REV
JI HIV AIDS Rev.
PY 2022
VL 21
IS 1
BP 17
EP 23
DI 10.5114/hivar.2022.112852
PG 7
WC Infectious Diseases
WE Emerging Sources Citation Index (ESCI)
SC Infectious Diseases
GA ZB5UO
UT WOS:000756907100001
OA gold
DA 2022-04-17
ER

PT J
AU Mahmood, A
   Tiwari, AK
   Singh, SK
   Udmale, SS
AF Mahmood, Atif
   Tiwari, Amod Kumar
   Singh, Sanjay Kumar
   Udmale, Sandeep S.
TI Contemporary machine learning applications in agriculture: Quo Vadis?
SO CONCURRENCY AND COMPUTATION-PRACTICE & EXPERIENCE
LA English
DT Article; Early Access
DE agriculture; classification; deep learning; machine learning;
   recognition
ID NEURAL-NETWORK; WEED DETECTION; CLASSIFICATION; PREDICTION; VISION;
   IDENTIFICATION; DISEASE; CROPS; QUALITY; SYSTEM
AB Agricultural automation is an emerging subject today to accomplish the food demands of individuals across the globe. Machine learning is one such agricultural automation tool that has been adopted briskly in the recent decade due to its ability to process countless input data and handle non-linear tasks. Availability and continuous development of agricultural data led the machine learning pervasive in multiple aspects of agriculture. This paper systematically analyses and summarizes the 81 quality research efforts published in the past decade dedicated to the various contemporary machine learning applications in agriculture and food production systems. We examined and categorized each agricultural problem under study into four categories and each category into its subcategories. The finding demonstrates the contemporary applications of machine learning in broad agricultural subcategories and determines where it is heading shortly; based upon contributions of researchers, utilization of machine learning models/algorithms, and the availability of agricultural datasets. Through the analysis, it is discovered that the current innovation can help the improvement of agricultural automation to accomplish the advantages of minimal cost, high efficiency, and better precision. This paper can serve as an investigatory guide for researchers, academicians, engineers, and manufacturers to understand and apply modern and upgraded cognitive technologies to each subcategory of the agricultural sector.
C1 [Mahmood, Atif; Tiwari, Amod Kumar] Dr APJ Abdul Kalam Tech Univ, Dept Comp Sci & Engn, Lucknow, Uttar Pradesh, India.
   [Singh, Sanjay Kumar] Dr APJ Abdul Kalam Tech Univ, Dept Comp Sci, Lucknow, Uttar Pradesh, India.
   [Udmale, Sandeep S.] Veermata Jijabai Technol Inst, Dept Comp Engn & IT, Mumbai, Maharashtra, India.
RP Mahmood, A (corresponding author), Dr APJ Abdul Kalam Tech Univ, Dept Comp Sci & Engn, Lucknow, Uttar Pradesh, India.
EM atif.mahmood@recsonbhadra.ac.in
NR 99
TC 0
Z9 0
U1 1
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1532-0626
EI 1532-0634
J9 CONCURR COMP-PRACT E
JI Concurr. Comput.-Pract. Exp.
AR e6940
DI 10.1002/cpe.6940
EA MAR 2022
PG 36
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZV4HD
UT WOS:000770492400001
DA 2022-04-17
ER

PT J
AU Jiang, XW
   Yan, TH
   Zhu, JJ
   He, B
   Li, WH
   Du, HP
   Sun, SS
AF Jiang, X. W.
   Yan, T. H.
   Zhu, J. J.
   He, B.
   Li, W. H.
   Du, H. P.
   Sun, S. S.
TI Densely Connected Deep Extreme Learning Machine Algorithm
SO COGNITIVE COMPUTATION
LA English
DT Article
DE Extreme learning machine (ELM); Densely connections; Deep learning;
   Representation learning
AB As a single hidden layer feed-forward neural network, the extreme learning machine (ELM) has been extensively studied for its short training time and good generalization ability. Recently, with the deep learning algorithm becoming a research hotspot, some deep extreme learning machine algorithms such as multi-layer extreme learning machine (ML-ELM) and hierarchical extreme learning machine (H-ELM) have also been proposed. However, the deep ELM algorithm also has many shortcomings: (1) when the number of model layers is shallow, the random feature mapping makes the sample features cannot be fully learned and utilized; (2) when the number of model layers is deep, the validity of the sample features will decrease after continuous abstraction and generalization. In order to solve the above problems, this paper proposes a densely connected deep ELM algorithm: dense-HELM (D-HELM). Benchmark data sets of different sizes have been employed for the property of the D-HELM algorithm. Compared with the H-ELM algorithm on the benchmark dataset, the average test accuracy is increased by 5.34% and the average training time is decreased by 21.15%. On the NORB dataset, the proposed D-HELM algorithm still maintains the best classification results and the fastest training speed. The D-HELM algorithm can make full use of the features of hidden layer learning by using the densely connected network structure and effectively reduce the number of parameters. Compared with the H-ELM algorithm, the D-HELM algorithm significantly improves the recognition accuracy and accelerates the training speed of the algorithm.
C1 [Jiang, X. W.; Yan, T. H.; Zhu, J. J.] China Jiliang Univ, Sch Mech & Elect Engn, Hangzhou, Peoples R China.
   [He, B.] Ocean Univ China, Sch Informat Sci & Engn, Qingdao, Shandong, Peoples R China.
   [Li, W. H.; Du, H. P.; Sun, S. S.] Univ Wollongong, Fac Engn & Informat Syst, Wollongong, NSW 2522, Australia.
RP Yan, TH (corresponding author), China Jiliang Univ, Sch Mech & Elect Engn, Hangzhou, Peoples R China.
EM thyan@cjlu.edu.cn
RI Yan, T. H./G-5773-2010
OI Yan, T. H./0000-0003-3916-3926
FU Key Research and Development Program of China [2016YFC0301400]; Natural
   Science Foundation of ChinaNational Natural Science Foundation of China
   (NSFC) [51379198, 51075377, 31202036]
FX This work is partially supported by the Key Research and Development
   Program of China (2016YFC0301400) and Natural Science Foundation of
   China (51379198, 51075377, and 31202036).
NR 30
TC 8
Z9 8
U1 5
U2 14
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1866-9956
EI 1866-9964
J9 COGN COMPUT
JI Cogn. Comput.
PD SEP
PY 2020
VL 12
IS 5
BP 979
EP 990
DI 10.1007/s12559-020-09752-2
EA AUG 2020
PG 12
WC Computer Science, Artificial Intelligence; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Neurosciences & Neurology
GA NM8KE
UT WOS:000557315100001
DA 2022-04-17
ER

PT J
AU Keeble, JWT
   Rios, A
AF Keeble, J. W. T.
   Rios, A.
TI Machine learning the deuteron
SO PHYSICS LETTERS B
LA English
DT Article
DE Deuteron; Quantum many-body theory; Machine learning; Neural networks
ID VARIATIONAL CALCULATIONS
AB We use machine learning techniques to solve the nuclear two-body bound state problem, the deuteron. We use a minimal one-layer, feed-forward neural network to represent the deuteron S- and D-state wavefunction in momentum space, and solve the problem variationally using ready-made machine learning tools. We benchmark our results with exact diagonalisation solutions. We find that a network with 6 hidden nodes (or 24 parameters) can provide a faithful representation of the ground state wavefunction, with a binding energy that is within 0.1% of exact results. This exploratory proof-of-principle simulation may provide insight for future potential solutions of the nuclear many-body problem using variational artificial neural network techniques. (C) 2020 The Author(s). Published by Elsevier B.V.
C1 [Keeble, J. W. T.; Rios, A.] Univ Surrey, Fac Engn & Phys Sci, Dept Phys, Guildford GU2 7XH, Surrey, England.
RP Rios, A (corresponding author), Univ Surrey, Fac Engn & Phys Sci, Dept Phys, Guildford GU2 7XH, Surrey, England.
EM a.rios@surrey.ac.uk
RI Huguet, Arnau Rios/E-9984-2010
OI /0000-0002-8759-3202
FU UK Science and Technology Facilities Council (STFC)UK Research &
   Innovation (UKRI)Science & Technology Facilities Council (STFC)
   [ST/P005314/1]; STFCUK Research & Innovation (UKRI)Science & Technology
   Facilities Council (STFC) [ST/P005314/1] Funding Source: UKRI
FX This work is supported by the UK Science and Technology Facilities
   Council (STFC) through grant ST/P005314/1. We thank Pierre Arthuis and
   Mehdi Drissi for a careful reading of the manuscript and for useful
   discussions.
NR 38
TC 11
Z9 11
U1 2
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0370-2693
EI 1873-2445
J9 PHYS LETT B
JI Phys. Lett. B
PD OCT 10
PY 2020
VL 809
AR 135743
DI 10.1016/j.physletb.2020.135743
PG 7
WC Astronomy & Astrophysics; Physics, Nuclear; Physics, Particles & Fields
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Astronomy & Astrophysics; Physics
GA OG4QU
UT WOS:000581871500045
OA Green Published, gold, Green Submitted
DA 2022-04-17
ER

PT J
AU Friederich, P
   Krenn, M
   Tamblyn, I
   Aspuru-Guzik, A
AF Friederich, Pascal
   Krenn, Mario
   Tamblyn, Isaac
   Aspuru-Guzik, Alan
TI Scientific intuition inspired by machine learning-generated hypotheses
SO MACHINE LEARNING-SCIENCE AND TECHNOLOGY
LA English
DT Article
DE machine learning; interpretability; organic electronics; quantum optics;
   artificial intelligence
ID DESIGN; ENTANGLEMENT
AB Machine learning with application to questions in the physical sciences has become a widely used tool, successfully applied to classification, regression and optimization tasks in many areas. Research focus mostly lies in improving the accuracy of the machine learning models in numerical predictions, while scientific understanding is still almost exclusively generated by human researchers analysing numerical results and drawing conclusions. In this work, we shift the focus on the insights and the knowledge obtained by the machine learning models themselves. In particular, we study how it can be extracted and used to inspire human scientists to increase their intuitions and understanding of natural systems. We apply gradient boosting in decision trees to extract human-interpretable insights from big data sets from chemistry and physics. In chemistry, we not only rediscover widely know rules of thumb but also find new interesting motifs that tell us how to control solubility and energy levels of organic molecules. At the same time, in quantum physics, we gain new understanding on experiments for quantum entanglement. The ability to go beyond numerics and to enter the realm of scientific insight and hypothesis generation opens the door to use machine learning to accelerate the discovery of conceptual understanding in some of the most challenging domains of science.
C1 [Friederich, Pascal; Krenn, Mario; Aspuru-Guzik, Alan] Univ Toronto, Dept Chem, Chem Phys Theory Grp, Toronto, ON, Canada.
   [Friederich, Pascal; Krenn, Mario; Aspuru-Guzik, Alan] Univ Toronto, Dept Comp Sci, Toronto, ON, Canada.
   [Friederich, Pascal] Karlsruhe Inst Technol, Inst Theoret Informat, Fasanengarten 5, D-76131 Karlsruhe, Germany.
   [Friederich, Pascal] Karlsruhe Inst Technol, Inst Nanotechnol, Hermann von Helmholtz Pl 1, D-76344 Eggenstein Leopoldshafen, Germany.
   [Krenn, Mario; Tamblyn, Isaac; Aspuru-Guzik, Alan] Vector Inst Artificial Intelligence, Toronto, ON, Canada.
   [Tamblyn, Isaac] Natl Res Council Canada, Ottawa, ON, Canada.
   [Aspuru-Guzik, Alan] Canadian Inst Adv Res CIFAR, Toronto, ON, Canada.
RP Friederich, P; Aspuru-Guzik, A (corresponding author), Univ Toronto, Dept Chem, Chem Phys Theory Grp, Toronto, ON, Canada.; Friederich, P; Aspuru-Guzik, A (corresponding author), Univ Toronto, Dept Comp Sci, Toronto, ON, Canada.; Friederich, P (corresponding author), Karlsruhe Inst Technol, Inst Theoret Informat, Fasanengarten 5, D-76131 Karlsruhe, Germany.; Friederich, P (corresponding author), Karlsruhe Inst Technol, Inst Nanotechnol, Hermann von Helmholtz Pl 1, D-76344 Eggenstein Leopoldshafen, Germany.; Aspuru-Guzik, A (corresponding author), Vector Inst Artificial Intelligence, Toronto, ON, Canada.; Aspuru-Guzik, A (corresponding author), Canadian Inst Adv Res CIFAR, Toronto, ON, Canada.
EM pascal.friederich@kit.edu; alan@aspuru.com
RI Aspuru-Guzik, Alan/A-4984-2008; Krenn, Mario/A-2799-2013
OI Aspuru-Guzik, Alan/0000-0002-8277-4434; Krenn, Mario/0000-0003-1620-9207
FU European UnionEuropean Commission [795206]; Austrian Science Fund (FWF)
   through the Erwin Schrodinger fellowshipAustrian Science Fund (FWF)
   [J4309]; AI4D Program; MCF Program; Natural Resources CanadaNatural
   Resources CanadaCanadian Forest Service; Canada 150 Research Chairs
   program
FX PF acknowledges funding the European Union's Horizon 2020 research and
   innovation programme under the Marie Skodowska-Curie Grant Agreement No.
   795206 (MolDesign). MK acknowledges support from the Austrian Science
   Fund (FWF) through the Erwin Schrodinger fellowship No. J4309. IT
   acknowledges NSERC and performed work at the NRC under the auspices of
   the AI4D and MCF Programs. AA-G thanks Anders G FrOseth for his generous
   support. AA-G acknowledges the generous support of Natural Resources
   Canada and the Canada 150 Research Chairs program.
NR 53
TC 6
Z9 6
U1 4
U2 6
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
EI 2632-2153
J9 MACH LEARN-SCI TECHN
JI Mach. Learn.-Sci. Technol.
PD JUN
PY 2021
VL 2
IS 2
AR 025027
DI 10.1088/2632-2153/abda08
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Science & Technology - Other Topics
GA SR2HQ
UT WOS:000660864900001
OA Green Submitted, gold, Green Published
DA 2022-04-17
ER

PT C
AU Guo, M
   Mukherjee, M
   Liang, G
   Zhang, JY
AF Guo, Mian
   Mukherjee, Mithun
   Liang, Gen
   Zhang, Jinyou
GP IEEE
TI Computation Offloading for Machine Learning in Industrial Environments
SO IECON 2020: THE 46TH ANNUAL CONFERENCE OF THE IEEE INDUSTRIAL
   ELECTRONICS SOCIETY
SE IEEE Industrial Electronics Society
LA English
DT Proceedings Paper
CT 46th Annual Conference of the IEEE-Industrial-Electronics-Society
   (IECON)
CY OCT 19-21, 2020
CL ELECTR NETWORK
SP IEEE Ind Elect Soc, Nangyang Technol Univ, Inst Elect & Elect Engineers, Smart Grid Power Elect Consortium Singapore
DE Edge computing; computation offloading; machine learning; federated
   learning; industrial environment
AB Industrial applications, such as real-time manufacturing, fault classification and inference, autonomous cars, etc., are data-driven applications that require machine learning with a wealth of data generated from industrial Internet of Things (IoT) devices. However, conventional approaches of transmitting this rich data to a remote data center to learn may be undesired due to the non-negligible network transmission delay and the sensitiveness of data privacy. By deploying a number of computing-capable devices at the network edge, edge computing supports the implementation of machine learning close to the industrial environment. Considering the heterogeneous computing capability as well as network location of edge devices, there are two types of feasible edge computing based machine learning models, including the centralized learning and federated learning models. In centralized learning, a resource-rich edge server aggregates the data from different IoT devices and performs machine learning. In federated learning, distributed edge devices and a federated server collaborate to perform machine learning. The features that data should be offloaded in centralized learning while it is locally trained in federated learning make centralized learning and federated learning quite different. We study the computation offloading problem for edge computing based machine learning in an industrial environment, considering the abovementioned machine learning models. We formulate a machine learning-based offloading problem with the goal of minimizing the training delay. Then, an energy-constrained delay-greedy (ECDG) algorithm is designed to solve the problem. Finally, simulation studies based on the MNIST dataset have been conducted to illustrate the efficiency of the proposal.
C1 [Guo, Mian; Mukherjee, Mithun; Liang, Gen; Zhang, Jinyou] Guangdong Univ Petrochem Technol, Maoming, Peoples R China.
RP Guo, M (corresponding author), Guangdong Univ Petrochem Technol, Maoming, Peoples R China.
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61901128]; Guangdong Basic and Applied Basic
   Research Foundation [2018B030311054, 2020A1515011528]; "Climbing"
   Program of Guangdong Province [pdjh2020b0392]
FX This work was supported partly by the National Natural Science
   Foundation of China under Grants 61901128, the Guangdong Basic and
   Applied Basic Research Foundation under Grant 2018B030311054 and
   2020A1515011528, the "Climbing" Program of Guangdong Province under
   grant pdjh2020b0392. The corresponding author is Gen Liang.
NR 10
TC 1
Z9 1
U1 2
U2 4
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1553-572X
BN 978-1-7281-5414-5
J9 IEEE IND ELEC
PY 2020
BP 4465
EP 4470
PG 6
WC Automation & Control Systems; Computer Science, Information Systems;
   Computer Science, Theory & Methods; Green & Sustainable Science &
   Technology; Energy & Fuels; Engineering, Manufacturing; Engineering,
   Electrical & Electronic; Robotics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Automation & Control Systems; Computer Science; Science & Technology -
   Other Topics; Energy & Fuels; Engineering; Robotics
GA BR2DJ
UT WOS:000637323704074
DA 2022-04-17
ER

PT C
AU Shahriar, H
   Qian, K
   Zhang, H
AF Shahriar, Hossain
   Qian, Kai
   Zhang, Hao
BE Chan, WK
   Claycomb, B
   Takakura, H
   Yang, JJ
   Teranishi, Y
   Towey, D
   Segura, S
   Shahriar, H
   Reisman, S
   Ahamed, SI
TI Learning Environment Containerization of Machine Leaning for
   Cybersecurity
SO 2020 IEEE 44TH ANNUAL COMPUTERS, SOFTWARE, AND APPLICATIONS CONFERENCE
   (COMPSAC 2020)
SE Proceedings International Computer Software and Applications Conference
LA English
DT Proceedings Paper
CT 44th Annual IEEE-Computer-Society International Conference on Computers,
   Software, and Applications (COMPSAC)
CY JUL 13-17, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc
DE Machine learning; Cybersecurity; Containerization; Docker
AB Machine learning plays a critical role in detecting and preventing in the field of cybersecurity. However, many students have difficulties on configuring the appropriate coding environment and retrieving datasets on their own computers, which, to some extent, wastes valuable time for learning core contents of machine learning and cybersecurity. In this paper, we propose an approach with learning environment containerization of machine learning algorithm and dataset. This will help students focus more on learning contents and have valuable hand-on experience through Docker container and get rid of the trouble of configuration coding environment and retrieve dataset. This paper provides an overview of case- based hands-on lab with logistic regression algorithm for credit card fraud prediction.
C1 [Shahriar, Hossain; Qian, Kai; Zhang, Hao] Kennesaw State Univ, Kennesaw, GA 30144 USA.
RP Shahriar, H (corresponding author), Kennesaw State Univ, Kennesaw, GA 30144 USA.
EM hshahria@kennesaw.edu; kqian@kennesaw.edu;
   hzhang13@students.kennesaw.edu
NR 7
TC 0
Z9 0
U1 0
U2 2
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 0730-3157
BN 978-1-7281-7303-0
J9 P INT COMP SOFTW APP
PY 2020
BP 1131
EP 1132
DI 10.1109/COMPSAC48688.2020.0-105
PG 2
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR0HX
UT WOS:000629086600164
DA 2022-04-17
ER

PT J
AU Sturm, T
   Gerlach, JP
   Pumplun, L
   Mesbah, N
   Peters, F
   Tauchert, C
   Nan, N
   Buxmannb, P
AF Sturm, Timo
   Gerlach, Jin P.
   Pumplun, Luisa
   Mesbah, Neda
   Peters, Felix
   Tauchert, Christoph
   Nan, Ning
   Buxmannb, Peter
TI COORDINATING HUMAN AND MACHINE LEARNING FOR EFFECTIVE ORGANIZATIONAL
   LEARNING
SO MIS QUARTERLY
LA English
DT Article
DE Artificial intelligence; machine learning; human-machine coordination;
   organizational learning; simulation; agent-based modeling
ID INFORMATION-TECHNOLOGY; ARTIFICIAL-INTELLIGENCE; KNOWLEDGE MANAGEMENT;
   DRUG DISCOVERY; EXPLOITATION; EXPLORATION; SYSTEMS; PERSPECTIVES;
   INNOVATION; IMPACT
AB With the rise of machine learning (ML), humans are no longer the only ones capable of learning and contributing to an organization's stock of knowledge. We study how organizations can coordinate human learning and ML in order to learn effectively as a whole. Based on a series of agent-based simulations, we find that, first, ML can reduce an organization's demand for human explorative learning that is aimed at uncovering new ideas; second, adjustments to ML systems made by humans are largely beneficial, but this effect can diminish or even become harmful under certain conditions; and third, reliance on knowledge created by ML systems can facilitate organizational learning in turbulent environments, but this requires significant investments in the initial setup of these systems as well as adequately coordinating them with humans. These insights contribute to rethinking organizational learning in the presence of ML and can aid organizations in reallocating scarce resources to facilitate organizational learning in practice.
C1 [Sturm, Timo; Pumplun, Luisa; Mesbah, Neda; Peters, Felix; Tauchert, Christoph; Buxmannb, Peter] Tech Univ Darmstadt, Software & Digital Business Grp, Hochschulstr 1, D-64289 Darmstadt, Germany.
   [Gerlach, Jin P.] Univ Passau, Sch Business Econ & Informat Syst, Dr Hans Kapfinger Str 12, D-94032 Passau, Germany.
   [Nan, Ning] Univ British Columbia, Sauder Sch Business, 2053 Main Mall, Vancouver, BC, Canada.
RP Sturm, T (corresponding author), Tech Univ Darmstadt, Software & Digital Business Grp, Hochschulstr 1, D-64289 Darmstadt, Germany.
EM timo.sturm@tu-darmstadt.de; jin.gerlach@uni-passau.de;
   luisa.pumplun@tu-darmstadt.de; neda.mesbah@tu-darmstadt.de;
   felix.peters@tu-darmstadt.de; christoph.tauchert@tu-darmstadt.de;
   ning.nan@sauderubc.ca; peterbuxmann@tu-darmstadt.de
RI Sturm, Timo/W-1109-2018; Sturm, Timo/P-8325-2019
OI Sturm, Timo/0000-0003-3243-2433; Pumplun, Luisa/0000-0001-8881-9587
FU German Federal Ministry of Education and Research within National
   Research Center for Applied Cybersecurity ATHENE; Hessen State Ministry
   for Higher Education, Research and the Arts within National Research
   Center for Applied Cybersecurity ATHENE; Social Sciences and Humanities
   Research Council of CanadaSocial Sciences and Humanities Research
   Council of Canada (SSHRC) [SSHRC 435-2017-0138]
FX We thank the senior editors of this special issue, Nick Berente, Bin Gu,
   Jan Recker, and Radhika Santhanam, our associate editor, Yuqing Ren, and
   our anonymous reviewers for their constructive feedback that has been
   invaluable in helping us to improve this manuscript. We also thank Ron
   Cenfetelli, Thomas Widjaja, Thomas Hess, Alexander Benlian, Christian
   Olt, Anne Zoll, Amina Wagner, Melanie Reuter-Oppermann, Mariska Fecho,
   Jennifer Wiefel, Verena Eitle, Adrian Engelbrecht, Marco Bender, Nicole
   Eling, Deborah Mateja, and Alexander Brinkmann for their insightful
   feedback throughout this project. This research has been funded by the
   German Federal Ministry of Education and Research and the Hessen State
   Ministry for Higher Education, Research and the Arts within their joint
   support of the National Research Center for Applied Cybersecurity
   ATHENE, and by the Social Sciences and Humanities Research Council of
   Canada (SSHRC 435-2017-0138) . Calculations for this research were
   conducted on the Lichtenberg high performance computer of the Technical
   University of Darmstadt and computing services of the Google Cloud
   Platform.
NR 100
TC 1
Z9 1
U1 99
U2 118
PU SOC INFORM MANAGE-MIS RES CENT
PI MINNEAPOLIS
PA UNIV MINNESOTA-SCH MANAGEMENT 271 19TH AVE SOUTH, MINNEAPOLIS, MN 55455
   USA
SN 0276-7783
J9 MIS QUART
JI MIS Q.
PD SEP
PY 2021
VL 45
IS 3
SI SI
BP 1581
EP 1602
DI 10.25300/MISQ/2021/16543
PG 22
WC Computer Science, Information Systems; Information Science & Library
   Science; Management
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Information Science & Library Science; Business &
   Economics
GA UL3FL
UT WOS:000692541000019
DA 2022-04-17
ER

PT J
AU Borstelmann, SM
AF Borstelmann, Stephen M.
TI Machine Learning Principles for Radiology Investigators
SO ACADEMIC RADIOLOGY
LA English
DT Review
DE Artificial Intelligence; AI; Machine Learning; Data Science; Statistics;
   Radiology; Review
ID CHALLENGES; CANCER; DIAGNOSIS
AB Artificial intelligence and deep learning are areas of high interest for radiology investigators at present. However, the field of machine learning encompasses multiple statistics-based techniques useful for investigators, which may be complementary to deep learning approaches. After a refresher in basic statistical concepts, relevant considerations for machine learning practitioners are reviewed: regression, classification, decision boundaries, and bias-variance tradeoff. Regularization, ground truth, and populations are discussed along with compute and data management principles. Advanced statistical machine learning techniques including bootstrapping, bagging, boosting, decision trees, random forest, XGboost, and support vector machines are reviewed along with relevant examples from the radiology literature.
C1 [Borstelmann, Stephen M.] Univ Cent Florida, Sch Med, UCF Coll Med, 6850 Lake Nona Blvd, Orlando, FL 32827 USA.
RP Borstelmann, SM (corresponding author), Univ Cent Florida, Sch Med, UCF Coll Med, 6850 Lake Nona Blvd, Orlando, FL 32827 USA.
EM sborstelmannmd@gmail.com
OI , Stephen/0000-0002-4806-5183
NR 48
TC 13
Z9 13
U1 8
U2 26
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 1076-6332
EI 1878-4046
J9 ACAD RADIOL
JI Acad. Radiol.
PD JAN
PY 2020
VL 27
IS 1
SI SI
BP 13
EP 25
DI 10.1016/j.acra.2019.07.030
PG 13
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA JX7NC
UT WOS:000503916400004
PM 31818379
DA 2022-04-17
ER

PT J
AU Kleesiek, J
   Murray, JM
   Strack, C
   Kaissis, G
   Braren, R
AF Kleesiek, Jens
   Murray, Jacob M.
   Strack, Christian
   Kaissis, Georgios
   Braren, Rickmer
TI A primer on machine learning
SO RADIOLOGE
LA German
DT Article
DE New technologies; Machine learning; Deep learning; Artificial neural
   networks; Digital literacy
AB Background The methods of machine learning and artificial intelligence are slowly but surely being introduced in everyday medical practice. In the future, they will support us in diagnosis and therapy and thus improve treatment for the benefit of the individual patient. It is therefore important to deal with this topic and to develop a basic understanding of it. Objectives This article gives an overview of the exciting and dynamic field of machine learning and serves as an introduction to some methods primarily from the realm of supervised learning. In addition to definitions and simple examples, limitations are discussed. Conclusions The basic principles behind the methods are simple. Nevertheless, due to their high dimensional nature, the factors influencing the results are often difficult or impossible to understand by humans. In order to build confidence in the new technologies and to guarantee their safe application, we need explainable algorithms and prospective effectiveness studies.
C1 [Kleesiek, Jens; Murray, Jacob M.; Strack, Christian] Deutsch Krebsforschungszentrum DKFZ, Abt Radiol, AG Computat Radiol, Neuenheimer Feld 280, D-69120 Heidelberg, Germany.
   [Murray, Jacob M.; Strack, Christian] Heidelberg Univ, Heidelberg, Germany.
   [Kaissis, Georgios; Braren, Rickmer] Tech Univ Munich, Sch Med, Dept Diagnost & Intervent Radiol, Munich, Germany.
   [Kleesiek, Jens; Braren, Rickmer] German Canc Consortium DKTK, Heidelberg, Germany.
RP Kleesiek, J (corresponding author), Deutsch Krebsforschungszentrum DKFZ, Abt Radiol, AG Computat Radiol, Neuenheimer Feld 280, D-69120 Heidelberg, Germany.
EM j.kleesiek@dkfz-heidelberg.de
RI Braren, Rickmer/U-3254-2018
OI Braren, Rickmer/0000-0001-6039-6957
NR 14
TC 4
Z9 4
U1 2
U2 13
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 0033-832X
EI 1432-2102
J9 RADIOLOGE
JI Radiologe
PD JAN
PY 2020
VL 60
IS 1
SI SI
BP 24
EP 31
DI 10.1007/s00117-019-00616-x
PG 8
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA KK8KP
UT WOS:000512985500004
PM 31811324
DA 2022-04-17
ER

PT J
AU Zheng, JH
   Cole, T
   Zhang, YX
   Kim, J
   Tang, SY
AF Zheng, Jiahao
   Cole, Tim
   Zhang, Yuxin
   Kim, Jeeson
   Tang, Shi-Yang
TI Exploiting machine learning for bestowing intelligence to microfluidics
SO BIOSENSORS & BIOELECTRONICS
LA English
DT Article
DE Machine learning; Microfluidics; Intelligent systems; Deep learning
ID SINGLE-CELL; HIGH-THROUGHPUT; LIQUID BIOPSY; LABEL-FREE; BLOOD;
   MICROPARTICLES; FABRICATION; ALGORITHMS; ENHANCE; ASSAY
AB Intelligent microfluidics is an emerging cross-discipline research area formed by combining microfluidics with machine learning. It uses the advantages of microfluidics, such as high throughput and controllability, and the powerful data processing capabilities of machine learning, resulting in improved systems in biotechnology and chemistry. Compared to traditional microfluidics using manual analysis methods, intelligent microfluidics needs less human intervention, and results in a more user-friendly experience with faster processing. There is a paucity of literature reviewing this burgeoning and highly promising cross-discipline. Therefore, we herein comprehensively and systematically summarize several aspects of microfluidic applications enabled by machine learning. We list the types of microfluidics used in intelligent microfluidic applications over the last five years, as well as the machine learning algorithms and the hardware used for training. We also present the most recent advances in key technologies, developments, challenges, and the emerging opportunities created by intelligent microfluidics.
C1 [Zheng, Jiahao; Cole, Tim; Zhang, Yuxin; Tang, Shi-Yang] Univ Birmingham, Dept Elect Elect & Syst Engn, Birmingham B15 2TT, W Midlands, England.
   [Kim, Jeeson] Sejong Univ, Dept Intelligent Mechatron Engn, Seoul 05006, South Korea.
RP Tang, SY (corresponding author), Univ Birmingham, Dept Elect Elect & Syst Engn, Birmingham B15 2TT, W Midlands, England.; Kim, J (corresponding author), Sejong Univ, Dept Intelligent Mechatron Engn, Seoul 05006, South Korea.
EM jeesonkim@sejong.ac.kr; S.Tang@bham.ac.uk
RI ; Tang, Shiyang/I-3580-2018
OI Cole, Tim/0000-0002-0221-1560; Zhang, Yuxin/0000-0001-8867-9350; Tang,
   Shiyang/0000-0002-3079-8880
FU Royal Society, UKRoyal Society of London [IEC\NSFC\201223]
FX S.-Y.T. is grateful for the support from the Royal Society, UK (IEC
   \NSFC\201223).
NR 142
TC 2
Z9 2
U1 39
U2 40
PU ELSEVIER ADVANCED TECHNOLOGY
PI OXFORD
PA OXFORD FULFILLMENT CENTRE THE BOULEVARD, LANGFORD LANE, KIDLINGTON,
   OXFORD OX5 1GB, OXON, ENGLAND
SN 0956-5663
EI 1873-4235
J9 BIOSENS BIOELECTRON
JI Biosens. Bioelectron.
PD DEC 15
PY 2021
VL 194
AR 113666
DI 10.1016/j.bios.2021.113666
EA SEP 2021
PG 22
WC Biophysics; Biotechnology & Applied Microbiology; Chemistry, Analytical;
   Electrochemistry; Nanoscience & Nanotechnology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biophysics; Biotechnology & Applied Microbiology; Chemistry;
   Electrochemistry; Science & Technology - Other Topics
GA WD8LT
UT WOS:000705187000001
PM 34600338
DA 2022-04-17
ER

PT C
AU Dcruz, F
   Tiwari, V
   Soni, M
AF Dcruz, Francis
   Tiwari, Vijitashw
   Soni, Mayur
BE Karrupusamy, P
   Chen, J
   Shi, Y
TI Using Machine Learning to Help Students with Learning Disabilities Learn
SO SUSTAINABLE COMMUNICATION NETWORKS AND APPLICATION, ICSCN 2019
SE Lecture Notes on Data Engineering and Communications Technologies
LA English
DT Proceedings Paper
CT International Conference on Sustainable Communication Networks and
   Application (ICSCN)
CY JUL 30-31, 2019
CL Surya Engn Coll, Erode, INDIA
HO Surya Engn Coll
DE Multimodal learning material; Special Needs Children; Web mining;
   Machine learning
AB The concept behind this learning modal is to connect education with technology to meet the different needs of each student. The main aim of personalized learning is to help students with disabilities.
   Students with a disability often need subject matter presented through different methods, therefore it is imperative that these technological advances benefit all students with different learning styles. Machine Learning opens up new ways to help students with disabilities. Children with autism which is a neurological disorder need a personalized development system for their daily activities. Technology can play a substantial part.
   The system includes 4 parts: (i) To predict the learning level of the user. (ii) Generating multimodal learning materials using web mining. (iii) User preferences are associated with the result. (iv) Personalized contents for users delineated with an intelligent interface.
C1 [Dcruz, Francis; Tiwari, Vijitashw; Soni, Mayur] St Francis Inst Technol, Dept Comp Engn, Mumbai, Maharashtra, India.
RP Dcruz, F (corresponding author), St Francis Inst Technol, Dept Comp Engn, Mumbai, Maharashtra, India.
EM dcruzfrancis04@gmail.com; vijitashw10@gmail.com; mayursoni299@gmail.com
NR 15
TC 0
Z9 0
U1 4
U2 5
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2367-4512
BN 978-3-030-34515-0; 978-3-030-34514-3
J9 LECT NOTE DATA ENG
PY 2020
VL 39
BP 262
EP 269
DI 10.1007/978-3-030-34515-0_27
PG 8
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Telecommunications
GA BQ6RO
UT WOS:000613009100027
DA 2022-04-17
ER

PT J
AU Lamata, L
AF Lamata, Lucas
TI Quantum machine learning and quantum biomimetics: A perspective
SO MACHINE LEARNING-SCIENCE AND TECHNOLOGY
LA English
DT Article
DE quantum machine learning; quantum biomimetics; quantum artificial
   intelligence; quantum reinforcement learning; quantum autoencoders;
   quantum artificial life; quantum memristors
ID ARTIFICIAL LIFE; GAME; MEMRISTORS; GO
AB Quantum machine learning has emerged as an exciting and promising paradigm inside quantum technologies. It may permit, on the one hand, to carry out more efficient machine learning calculations by means of quantum devices, while, on the other hand, to employ machine learning techniques to better control quantum systems. Inside quantum machine learning, quantum reinforcement learning aims at developing 'intelligent' quantum agents that may interact with the outer world and adapt to it, with the strategy of achieving some final goal. Another paradigm inside quantum machine learning is that of quantum autoencoders, which may allow one for employing fewer resources in a quantum device via a training process. Moreover, the field of quantum biomimetics aims at establishing analogies between biological and quantum systems, to look for previously inadvertent connections that may enable useful applications. Two recent examples are the concepts of quantum artificial life, as well as of quantum memristors. In this Perspective, we give an overview of these topics, describing the related research carried out by the scientific community.
C1 [Lamata, Lucas] Univ Seville, Mol Nucl, Dept Fis Atom, Seville 41080, Spain.
RP Lamata, L (corresponding author), Univ Seville, Mol Nucl, Dept Fis Atom, Seville 41080, Spain.
RI Lamata, Lucas/B-2439-2009
OI Lamata, Lucas/0000-0002-9504-8685
FU [PGC2018-095113-B-I00];  [PID2019-104002GB-C21];  [PID2019-104002GB-C22]
FX I acknowledge collaborations and useful discussions on the topics
   presented in this article with Enrique Solano, Mikel Sanz, Unai
   Alvarez-Rodriguez, Jose Martin-Guerrero, Pablo Escandell-Montero,
   Francisco Albarran-Arriagada, Juan Carlos Retamal, Francisco
   Cardenas-Lopez, Yongcheng Ding, Xi Chen, Shang Yu, and Rei Li. Funding
   from Spanish PGC2018-095113-B-I00, PID2019-104002GB-C21 and
   PID2019-104002GB-C22 (MCIU/AEI/FEDER, UE) is acknowledged.
NR 110
TC 25
Z9 25
U1 6
U2 7
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
EI 2632-2153
J9 MACH LEARN-SCI TECHN
JI Mach. Learn.-Sci. Technol.
PD SEP
PY 2020
VL 1
IS 3
AR 033002
DI 10.1088/2632-2153/ab9803
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Science & Technology - Other Topics
GA SR2GA
UT WOS:000660860700001
OA gold, Green Submitted, Green Published
DA 2022-04-17
ER

PT J
AU Kaptan, S
   Vattulainen, I
AF Kaptan, Shreyas
   Vattulainen, Ilpo
TI Machine learning in the analysis of biomolecular simulations
SO ADVANCES IN PHYSICS-X
LA English
DT Review
DE Biomolecular simulations; molecular dynamics; machine learning; deep
   learning; biophysics
ID MOLECULAR-DYNAMICS TRAJECTORIES; PARTIAL LEAST-SQUARES; PRINCIPAL
   COMPONENT; ORDER PARAMETERS; CLUSTER-ANALYSIS; DIMENSIONALITY;
   METADYNAMICS; LANDSCAPES; PROTEINS; MIXTURE
AB Machine learning has rapidly become a key method for the analysis and organization of large-scale data in all scientific disciplines. In life sciences, the use of machine learning techniques is a particularly appealing idea since the enormous capacity of computational infrastructures generates terabytes of data through millisecond simulations of atomistic and molecular-scale biomolecular systems. Due to this explosion of data, the automation, reproducibility, and objectivity provided by machine learning methods are highly desirable features in the analysis of complex systems. In this review, we focus on the use of machine learning in biomolecular simulations. We discuss the main categories of machine learning tasks, such as dimensionality reduction, clustering, regression, and classification used in the analysis of simulation data. We then introduce the most popular classes of techniques involved in these tasks for the purpose of enhanced sampling, coordinate discovery, and structure prediction. Whenever possible, we explain the scope and limitations of machine learning approaches, and we discuss examples of applications of these techniques.
C1 [Kaptan, Shreyas; Vattulainen, Ilpo] Univ Helsinki, Dept Phys, Helsinki, Finland.
RP Vattulainen, I (corresponding author), Univ Helsinki, Dept Phys, Helsinki, Finland.
EM Ilpo.Vattulainen@helsinki.fi
OI Vattulainen, Ilpo/0000-0001-7408-3214
FU Sigrid Juselius FoundationSigrid Juselius Foundation; Academy of
   FinlandAcademy of Finland [331349]; Human Frontier Science ProgramHuman
   Frontier Science Program [RGP0059/2019]; Helsinki Institute of Life
   Science (HiLIFE) Fellow program; University of Helsinki; EUEuropean
   Commission
FX We thank CSC - IT Center for Science (Espoo, Finland) for computing
   resources. We thank the Sigrid Juselius Foundation, the Academy of
   Finland (project no. 331349), Human Frontier Science Program (project
   no. RGP0059/2019), and the Helsinki Institute of Life Science (HiLIFE)
   Fellow program for financial support (I.V.). We also thank the
   University of Helsinki (3-year project grants) and the EU (Marie
   Skodowska-Curie Fellowship program) for funding (SK).
NR 98
TC 0
Z9 0
U1 38
U2 38
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 2374-6149
J9 ADV PHYS-X
JI Adv. Phys.-X
PD DEC 31
PY 2022
VL 7
IS 1
DI 10.1080/23746149.2021.2006080
PG 31
WC Physics, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Physics
GA YE4XG
UT WOS:000741129900001
OA gold, Green Published
DA 2022-04-17
ER

PT C
AU Sutedja, I
AF Sutedja, Indrajani
GP IEEE
TI Descriptive and Predictive Analysis on Heart Disease with Machine
   Learning and Deep Learning
SO 3RD INTERNATIONAL CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEMS
   (ICORIS 2021)
LA English
DT Proceedings Paper
CT 3rd International Conference on Cybernetics and Intelligent System
   (ICORIS)
CY OCT 25-26, 2021
CL Dipa Makasar Univ, ELECTR NETWORK
SP Binus Univ
HO Dipa Makasar Univ
DE Machine Learning; Deep Learning; Heart Disease
ID IMPLEMENTATION; CLASSIFICATION; MODEL
AB At present, one of the most fatal diseases in the world is heart disease. The mortality rate caused by heart disease is still relatively high, thus more intense effort in the prevention is needed, for instance by improving the achievement of a prediction model on heart disease. This research objective is to implement a prediction comparison of several machine learning and deep learning models, whether an individual is suffering from heart disease or not. In this research, the methodology used comprises of three machine learning models and three deep learning models to obtain the highest accuracy in predicting heart disease. Machine learning models applied in this research are Logistic Regression, Support Vector Machine (SVM), and Naive Bayes, meanwhile models which are applied for Deep Learning method include Long Short Term Memory (LSTM), Convolutional Neural Network (CNN), and Recurrent Neural Network (RNN). The accuracy obtained from this research consists of Logistic Regression by 86%, SVM by 88%, and Naive Bayes by 86% Meanwhile, the accuracy of LSTM achieves 84% RNN has 90%, and CNN takes 84% The conclusion derived from this research is RNN model prevails with the highest accuracy by having 90% and becomes the best one to predict whether an individual is suffering from heart disease or not.
C1 [Sutedja, Indrajani] Bina Nusantara Univ, Informat Syst Dept, Sch Informat Syst, Jakarta, Indonesia.
RP Sutedja, I (corresponding author), Bina Nusantara Univ, Informat Syst Dept, Sch Informat Syst, Jakarta, Indonesia.
EM indrajani@binus.ac.id
NR 25
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-6654-2580-3
PY 2021
BP 505
EP 510
DI 10.1109/ICORIS52787.2021.9649585
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS7XN
UT WOS:000768467000088
DA 2022-04-17
ER

PT C
AU Kim, JW
   Namgung, J
   Moon, YS
   Choi, MJ
AF Kim, Jong-Wouk
   Namgung, Juhong
   Moon, Yang-Sae
   Choi, Mi-Jung
GP IEEE
TI Experimental Comparison of Machine Learning Models in Malware Packing
   Detection
SO APNOMS 2020: 2020 21ST ASIA-PACIFIC NETWORK OPERATIONS AND MANAGEMENT
   SYMPOSIUM (APNOMS)
SE Asia-Pacific Network Operations and Management Symposium-APNOMS
LA English
DT Proceedings Paper
CT 21st Asia-Pacific Network Operations and Management Symposium (APNOMS)
CY SEP 22-25, 2020
CL Daegu, SOUTH KOREA
SP KICS, KNOM, IEICE ICM, IEEE, IEEE Commun Soc
DE Malware; Packing; Machine Learning; Security
AB Recently, malware is widely distributed by combining recent technologies such as packing, encoding and obfuscation to bypass anti-virus software. These kinds of technologies allow malware to survive longer, infect various computers and devices for longer periods of time, create a number of mutated malware, and make experts spend longer to analyze malware. Packers disrupt the reverse engineering process, making it difficult for security researchers to analyze new or unknown malware. Thus, we need to analyze as many malware as possible by first detecting the packed malware and analyzing not-packed malware, and then unpack the packed malware. Previously, the packing detection methods were based on mainly signature and entropy detection. However, these methods have increased the undetected rate with the appearance of custom packers. Due to these problems, there have been many research efforts on machine learning-based malware packing detection and classification. In this paper, we present an extensive experimental comparison of these machine learning-based algorithms. In particular, we extract a total of 13 important features and considers eight machine learning algorithms to detect the packing of malware. Experimental results show that we can also detect well malware packed by custom packers which did not studied in previous studies.
C1 [Kim, Jong-Wouk; Namgung, Juhong; Moon, Yang-Sae; Choi, Mi-Jung] Kangwon Natl Univ, Dept Comp Sci, Gangwon 24341, South Korea.
RP Kim, JW (corresponding author), Kangwon Natl Univ, Dept Comp Sci, Gangwon 24341, South Korea.
EM goldbear564@kangwon.ac.kr; namgung_juhong@kangwon.ac.kr;
   ysmoon@kangwon.ac.kr; mjchoi@kangwon.ac.kr
FU Korea Electric Power Corporation [R18XA05]; National Research Foundation
   of Korea (NRF) - Korea Government(MSIT) [NRF-2020R1A2C1012117];
   Information sharing technology for national cyber incident response
FX This work was partially supported by Information sharing technology for
   national cyber incident response and Korea Electric Power Corporation
   (Grant number:R18XA05) and supported by National Research Foundation of
   Korea (NRF) grant funded by the Korea Government(MSIT) (No.
   NRF-2020R1A2C1012117, Development of machine learning based intrusion
   detection platform to secure end device in edge computing environment).
NR 17
TC 0
Z9 0
U1 1
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2576-8565
EI 2576-8557
BN 978-89-950043-8-8
J9 ASIA-PAC NETW OPER M
PY 2020
BP 377
EP 380
PG 4
WC Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Telecommunications
GA BR0RX
UT WOS:000630323900077
DA 2022-04-17
ER

PT J
AU Hashemi, M
   Karimi, HA
AF Hashemi, Mahdi
   Karimi, Hassan A.
TI Weighted Machine Learning for Spatial-Temporal Data
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Machine learning; Training; Correlation; Support vector machines;
   Kernel; Spatial databases; Bandwidth; Analytical learning;
   autocorrelation; inductive learning; machine learning; spatial data;
   temporal data
ID ALGORITHMS; CLASSIFICATION; MODEL; PATTERNS; SENSOR; TIME
AB Applying machine learning techniques to spatial-temporal data poses the question that how the recorded location and time for training samples should contribute to the training and testing process. The prior knowledge of how spatial-temporal phenomena are autocorrelated cannot be properly captured by machine learning techniques, which either ignore location and time altogether or consider them as input features. Not to mention that the latter approach leads to slightly increased sparseness of data in the feature space and more free parameters in the predictor; thus, demanding for larger training datasets. We use the prior knowledge about the spatial-temporal autocorrelation to determine how relevant each training sample would be, given its spatial and temporal distances to the irresponsive (unlabeled) sample. Weighted machine learning techniques use this prior knowledge by taking the relevance of training samples with regard to the irresponsive sample into account as training samples' weights. The proposed approach overcomes the aforementioned issues by enriching the training process with the prior knowledge about spatial-temporal autocorrelation. Because the spatial-temporal weight of training samples depends on the irresponsive sample's location and time, the machine needs to be trained separately for each irresponsive sample. However, we show that in practice using only a small subset of training samples with largest spatial-temporal weights not only mitigates the training time but also results in the best accuracy in most cases.
C1 [Hashemi, Mahdi] George Mason Univ, Dept Informat Sci & Technol, Fairfax, VA 22030 USA.
   [Karimi, Hassan A.] Univ Pittsburgh, Sch Comp & Informat, Pittsburgh, PA 15213 USA.
RP Hashemi, M (corresponding author), George Mason Univ, Dept Informat Sci & Technol, Fairfax, VA 22030 USA.
EM mhashem2@gmu.edu; hkarimi@pitt.edu
OI Hashemi, Mahdi/0000-0003-0212-0228
NR 65
TC 3
Z9 3
U1 4
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PY 2020
VL 13
BP 3066
EP 3082
DI 10.1109/JSTARS.2020.2995834
PG 17
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA MD1DP
UT WOS:000543715900002
OA gold
DA 2022-04-17
ER

PT S
AU Velankar, M
   Deshpande, A
   Kulkarni, P
AF Velankar, Makarand
   Deshpande, Amod
   Kulkarni, Parag
BE Das, R
   Bhattacharyya, S
   Nandy, S
TI Application of Machine Learning in Music Analytics
SO MACHINE LEARNING APPLICATIONS: EMERGING TRENDS
SE De Gruyter Frontiers in Computational Intelligence
LA English
DT Article; Book Chapter
DE Computational music; feature engineering; pattern recognition; music
   classification; and clustering; machine learning
ID MELODY EXTRACTION
AB With the growth of the internet and social media, music data is growing at an enormous rate. Music analytics has a wide canvas covering all aspects related to music. This chapter provides a glimpse of this large canvas with sample applications covered in detail. Machine learning has taken a central role in the progress of many domains including music analytics. This chapter will help the readers to understand various applications of machine learning in computational musicology. Music feature learning and musical pattern recognition give conceptual understanding and the challenges involved. Feature engineering algorithms for pitch detection or tempo estimation are covered in more detail with available popular feature extraction tools. Music classification and clustering examples explore the use of machine learning. Various applications ranging from the query by humming to music recommendations are provided for efficient music information retrieval. Future directions and challenges with deep learning as a new approach and incorporation of human cognition and perception as a challenge makes this domain a challenging research domain.
C1 [Velankar, Makarand] SPPU, Cummins Coll, Pune, Maharashtra, India.
   [Velankar, Makarand] SPPU, PICT, Pune, Maharashtra, India.
   [Deshpande, Amod] Consonance Acoust, Aurangabad, Maharashtra, India.
   [Kulkarni, Parag] Iknowlat Res Labs Pvt Ltd, Pune, Maharashtra, India.
RP Velankar, M (corresponding author), SPPU, Cummins Coll, Pune, Maharashtra, India.; Velankar, M (corresponding author), SPPU, PICT, Pune, Maharashtra, India.
OI Kulkarni, Parag/0000-0001-9350-4889
NR 32
TC 0
Z9 0
U1 0
U2 2
PU WALTER DE GRUYTER GMBH
PI BERLIN
PA GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY
SN 2512-8868
BN 978-3-11-061098-7; 978-3-11-060853-3
J9 DE GR FRONT COMPU IN
PY 2020
VL 5
BP 43
EP 63
DI 10.1515/9783110610987-005
D2 10.1515/9783110610987
PG 21
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
WE Book Citation Index – Science (BKCI-S)
SC Computer Science; Engineering
GA BQ5AO
UT WOS:000596457500004
DA 2022-04-17
ER

PT J
AU Zorn, KM
   Foil, DH
   Lane, TR
   Hillwalker, W
   Feifarek, DJ
   Jones, F
   Klaren, WD
   Brinkman, AM
   Ekins, S
AF Zorn, Kimberley M.
   Foil, Daniel H.
   Lane, Thomas R.
   Hillwalker, Wendy
   Feifarek, David J.
   Jones, Frank
   Klaren, William D.
   Brinkman, Ashley M.
   Ekins, Sean
TI Comparison of Machine Learning Models for the Androgen Receptor
SO ENVIRONMENTAL SCIENCE & TECHNOLOGY
LA English
DT Article
DE androgen receptor; Bayesian; endocrine disruption; machine learning
AB The androgen receptor (AR) is a target of interest for endocrine disruption research, as altered signaling can affect normal reproductive and neurological development for generations. In an effort to prioritize compounds with alternative methodologies, the U.S. Environmental Protection Agency (EPA) used in vitro data from 11 assays to construct models of AR agonist and antagonist signaling pathways. While these EPA ToxCast AR models require in vitro data to assign a bioactivity score, Bayesian machine learning methods can be used for prospective prediction from molecule structure alone. This approach was applied to multiple types of data corresponding to the EPAs AR signaling pathway with proprietary software, Assay Central. The training performance of all machine learning models, including six other algorithms, was evaluated by internal 5-fold cross-validation statistics. Bayesian machine learning models were also evaluated with external predictions of reference chemicals to compare prediction accuracies to published results from the EPA. The machine learning model group selected for further studies of endocrine disruption consisted of continuous AC(50) data from the February 2019 release of ToxCast/Tox21. These efforts demonstrate how machine learning can be used to predict AR-mediated bioactivity and can also be applied to other targets of endocrine disruption.
C1 [Zorn, Kimberley M.; Foil, Daniel H.; Lane, Thomas R.; Ekins, Sean] Collaborat Pharmaceut Inc, Raleigh, NC 27606 USA.
   [Hillwalker, Wendy; Feifarek, David J.; Jones, Frank; Klaren, William D.; Brinkman, Ashley M.] SC Johnson & Son Inc, Global Prod Safety, Racine, WI 53404 USA.
RP Ekins, S (corresponding author), Collaborat Pharmaceut Inc, Raleigh, NC 27606 USA.
EM sean@collaborationspharma.com
RI Foil, Daniel/AAJ-1809-2021
OI Foil, Daniel/0000-0003-0512-8997
FU SC Johnson and Son, Inc.; NIH NIGMSUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute of General Medical Sciences (NIGMS) [R44GM122196-02A1];
   National Institute of Environmental Health Sciences of the National
   Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   of Environmental Health Sciences (NIEHS) [R43ES031038]
FX We kindly acknowledge SC Johnson and Son, Inc. for funding. We also
   acknowledge NIH NIGMS funding to develop the software from
   R44GM122196-02A1. Research reported in this publication was supported by
   the National Institute of Environmental Health Sciences of the National
   Institutes of Health under Award Number R43ES031038. The content is
   solely the responsibility of the authors and does not necessarily
   represent the official views of the National Institutes of Health. We
   are also grateful to the EPA for providing the Tox21/ToxCast data sets,
   Dr. Alex M. Clark (Molecular Materials Informatics, Inc.) for Assay
   Central support, and Dr. William C. Kershaw for constructive criticism.
   We acknowledge Dr. Daniel P. Russo for the development of the
   alternative machine learning algorithm pipeline and support.
NR 45
TC 3
Z9 3
U1 17
U2 42
PU AMER CHEMICAL SOC
PI WASHINGTON
PA 1155 16TH ST, NW, WASHINGTON, DC 20036 USA
SN 0013-936X
EI 1520-5851
J9 ENVIRON SCI TECHNOL
JI Environ. Sci. Technol.
PD NOV 3
PY 2020
VL 54
IS 21
BP 13690
EP 13700
DI 10.1021/acs.est.0c03984
PG 11
WC Engineering, Environmental; Environmental Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Environmental Sciences & Ecology
GA OR1QE
UT WOS:000589249900034
PM 33085465
OA Green Accepted
DA 2022-04-17
ER

PT C
AU Huo, ZX
AF Huo, Zixuan
GP IEEE
TI Sales Prediction based on Machine Learning
SO 2021 2ND INTERNATIONAL CONFERENCE ON E-COMMERCE AND INTERNET TECHNOLOGY
   (ECIT 2021)
LA English
DT Proceedings Paper
CT 2nd International Conference on E-Commerce and Internet Technology
   (ECIT)
CY MAR 05-07, 2021
CL ELECTR NETWORK
DE Sales Prediction; Regression; Machine Learning; Deep Learning
AB With the increasing influence of the Internet on people's life, the development of e-commerce platforms is more rapid, with users and earnings of these platforms showing a growing trend. In recent years, the strong support of national policies has also provided a good environment for the development of the e-commerce industry. Under the impact of the epidemic this year, the role of the e-commerce industry in the development of the national economy has become more prominent. In such cases, the number and the competitiveness of e-commerce platforms and e-commerce enterprises are increasing. If a platform wants to maintain its advantage in the competition, it must be able to better meet the needs of users, and do a good job in all aspects of coordination and management. At this point, the accurate forecast of the sales volume of e-commerce platforms is particularly important. At present, there are many studies on e-commerce sales prediction, but we are still exploring the prediction model that can be better applied in different scenarios. In this paper, we try and evaluate two linear models, three machine learning models and two deep learning models, finding that machine learning and deep learning models have no advantage in improving the accuracy of sales forecast, but on a predictive basis, models perform better when they include information on calendar and price.
C1 [Huo, Zixuan] Beijing Univ Posts & Telecommun, Int Sch, Beijing, Peoples R China.
RP Huo, ZX (corresponding author), Beijing Univ Posts & Telecommun, Int Sch, Beijing, Peoples R China.
EM huozixuan@bupt.edu.cn
NR 21
TC 0
Z9 0
U1 10
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
BN 978-1-6654-3873-5
PY 2021
BP 410
EP 415
DI 10.1109/ECIT52743.2021.00093
PG 6
WC Business; Computer Science, Interdisciplinary Applications; Management
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Business & Economics; Computer Science
GA BR8SG
UT WOS:000672805700086
DA 2022-04-17
ER

PT J
AU Shouval, R
   Fein, JA
   Savani, B
   Mohty, M
   Nagler, A
AF Shouval, Roni
   Fein, Joshua A.
   Savani, Bipin
   Mohty, Mohamad
   Nagler, Arnon
TI Machine learning and artificial intelligence in haematology
SO BRITISH JOURNAL OF HAEMATOLOGY
LA English
DT Review
DE machine learning; artificial intelligence; haematology; prediction
   models; leukaemia
ID STEM-CELL TRANSPLANTATION; BIG DATA; PREDICTION; VALIDATION; ALGORITHM;
   LYMPHOMA; SYSTEM; SCORE; CLASSIFICATION; DIAGNOSIS
AB Digitalization of the medical record and integration of genomic methods into clinical practice have resulted in an unprecedented wealth of data. Machine learning is a subdomain of artificial intelligence that attempts to computationally extract meaningful insights from complex data structures. Applications of machine learning in haematological scenarios are steadily increasing. However, basic concepts are often unfamiliar to clinicians and investigators. The purpose of this review is to provide readers with tools to interpret and critically appraise machine learning literature. We begin with the elucidation of standard terminology and then review examples in haematology. Guidelines for designing and evaluating machine-learning studies are provided. Finally, we discuss limitations of the machine-learning approach.
C1 [Shouval, Roni] Mem Sloan Kettering Canc Ctr, Dept Med, Adult Bone Marrow Transplant Serv, 1275 York Ave,Box 298, New York, NY 10065 USA.
   [Shouval, Roni; Nagler, Arnon] Tel Aviv Univ, Sackler Sch Med, Chaim Sheba Med Ctr, Hematol & Bone Marrow Transplantat Div, Tel Aviv, Israel.
   [Fein, Joshua A.] Univ Connecticut, Med Ctr, Farmington, CT USA.
   [Savani, Bipin] Vanderbilt Univ, Med Ctr, Dept Med, Div Hematol Oncol, Nashville, TN USA.
   [Mohty, Mohamad] Hop St Antoine, AP HP, CEREST TC, European Soc Blood & Marrow Transplantat Paris St, Paris, France.
   [Mohty, Mohamad] Hop St Antoine, AP HP, Serv Hematol Clin & Therapie Cellulaire, Paris, France.
RP Shouval, R (corresponding author), Mem Sloan Kettering Canc Ctr, Dept Med, Adult Bone Marrow Transplant Serv, 1275 York Ave,Box 298, New York, NY 10065 USA.
EM shouval@gmail.com
OI Shouval, Roni/0000-0001-9827-8032; Fein, Joshua/0000-0001-5441-1516
FU Varda and Boaz Dotan Research Center in Hemato-oncology, Idea Award
   Research Grant, Tel-Aviv University
FX The study was supported by the Varda and Boaz Dotan Research Center in
   Hemato-oncology, Idea Award Research Grant, Tel-Aviv University. Figures
   1 and 4 include visual elements adapted from FontAwesome icons and are
   used under a Creative Commons 4.0 license
   (https://creativecommons.org/licenses/by/4.0/legalcode.) Icons
   "database", "desktop" and "user-md" and can be found at
   www.fontawesome.com.
NR 77
TC 16
Z9 16
U1 17
U2 27
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0007-1048
EI 1365-2141
J9 BRIT J HAEMATOL
JI Br. J. Haematol.
PD JAN
PY 2021
VL 192
IS 2
BP 239
EP 250
DI 10.1111/bjh.16915
EA JUN 2020
PG 12
WC Hematology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Hematology
GA PT1AV
UT WOS:000545164100001
PM 32602593
DA 2022-04-17
ER

PT J
AU Chkirbene, Z
   Erbad, A
   Hamila, R
   Gouissem, A
   Mohamed, A
   Hamdi, M
AF Chkirbene, Zina
   Erbad, Aiman
   Hamila, Ridha
   Gouissem, Ala
   Mohamed, Amr
   Hamdi, Mounir
TI Machine Learning Based Cloud Computing Anomalies Detection
SO IEEE NETWORK
LA English
DT Article
DE Machine learning; Machine learning algorithms; Data models; Security;
   Predictive models; Training; Cloud computing
AB Recently, machine learning algorithms have been proposed to design new security systems for anomalies detection as they exhibit fast processing with real-time predictions. However, one of the major challenges in machine learning-based intrusion detection methods is how to include enough training examples for all the possible classes in the model to avoid the class imbalance problem and accurately detect the intrusions and their types. in this article, we propose a novel weighted classes classification scheme to secure the network against malicious nodes while alleviating the problem of imbalanced data. in the proposed system, we combine a supervised machine learning algorithm with the network node past information and a specific designed best effort iterative algorithm to enhance the accuracy of rarely detectable attacks. The machine learning algorithm is used to generate a classifier that differentiates between the investigated attacks. The system stores these decisions in a private database. Then, we design a new weight optimization algorithm that exploits these decisions to generate a weights vector that includes the best weight for each class. The proposed model enhances the overall detection accuracy and maximizes the number of correctly detectable classes even for the classes with a relatively low number of training entries. The UNSW dataset has been used to evaluate the performance of the proposed model and compare it with state of the art techniques.
C1 [Chkirbene, Zina; Erbad, Aiman; Gouissem, Ala] Qatar Univ, Doha, Qatar.
   [Hamila, Ridha] Qatar Univ, Dept Elect Engn, Doha, Qatar.
   [Mohamed, Amr] Qatar Univ, Coll Engn, Doha, Qatar.
   [Gouissem, Ala; Hamdi, Mounir] Hamad Bin Khalif Univ, Ar Rayyan, Qatar.
RP Chkirbene, Z (corresponding author), Qatar Univ, Doha, Qatar.
RI Mohamed, Amr/AFP-6226-2022
OI Erbad, Aiman/0000-0001-7565-5253; Mohamed, Amr/0000-0002-1583-7503
FU NPRP award from the Qatar National Research Fund (a member of The Qatar
   Foundation) [NPRP 8-634-1-131]
FX This publication was made possible by the NPRP award (NPRP 8-634-1-131)
   from the Qatar National Research Fund (a member of The Qatar
   Foundation). The statements made herein are solely the responsibility of
   the author[s].
NR 15
TC 3
Z9 3
U1 3
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0890-8044
EI 1558-156X
J9 IEEE NETWORK
JI IEEE Netw.
PD NOV-DEC
PY 2020
VL 34
IS 6
BP 178
EP 183
DI 10.1109/MNET.011.2000097
PG 6
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Engineering, Electrical & Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA PE8XD
UT WOS:000598643800026
DA 2022-04-17
ER

PT J
AU Carneiro, D
   Guimaraes, M
   Carvalho, M
   Novais, P
AF Carneiro, Davide
   Guimaraes, Miguel
   Carvalho, Mariana
   Novais, Paulo
TI Using meta-learning to predict performance metrics in machine learning
   problems
SO EXPERT SYSTEMS
LA English
DT Article; Early Access
DE error prediction; interactive machine learning; meta-learning
AB Machine learning has been facing significant challenges over the last years, much of which stem from the new characteristics of machine learning problems, such as learning from streaming data or incorporating human feedback into existing datasets and models. In these dynamic scenarios, data change over time and models must adapt. However, new data do not necessarily mean new patterns. The main goal of this paper is to devise a method to predict a model's performance metrics before it is trained, in order to decide whether it is worth it to train it or not. That is, will the model hold significantly better results than the current one? To address this issue, we propose the use of meta-learning. Specifically, we evaluate two different meta-models, one built for a specific machine learning problem, and another built based on many different problems, meant to be a generic meta-model, applicable to virtually any problem. In this paper, we focus only on the prediction of the root mean square error (RMSE). Results show that it is possible to accurately predict the RMSE of future models, event in streaming scenarios. Moreover, results also show that it is possible to reduce the need for re-training models between 60% and 98%, depending on the problem and on the threshold used.
C1 [Carneiro, Davide; Guimaraes, Miguel; Carvalho, Mariana] ESTG, CIICESI, Politecn Porto, Felgueiras, Portugal.
   [Carneiro, Davide; Novais, Paulo] Univ Minho, Ctr ALGORITMI, Braga, Portugal.
RP Carneiro, D (corresponding author), ESTG, CIICESI, Politecn Porto, Porto, Portugal.
EM dcarneiro@estg.ipp.pt
RI Carneiro, Davide/A-3490-2014; Novais, Paulo/M-4053-2013
OI Carneiro, Davide/0000-0002-6650-0388; Carvalho,
   Mariana/0000-0003-2190-4319; Novais, Paulo/0000-0002-3549-0754
FU Fundacao para a Ciencia e a TecnologiaPortuguese Foundation for Science
   and TechnologyEuropean Commission; European Regional Development
   FundEuropean Commission; European UnionEuropean Commission
FX Fundacao para a Ciencia e a Tecnologia; European Regional Development
   Fund; European Union
NR 17
TC 0
Z9 0
U1 3
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0266-4720
EI 1468-0394
J9 EXPERT SYST
JI Expert Syst.
AR e12900
DI 10.1111/exsy.12900
EA NOV 2021
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XE1EW
UT WOS:000723139700001
DA 2022-04-17
ER

PT J
AU Schweidtmann, AM
   Esche, E
   Fischer, A
   Kloft, M
   Repke, JU
   Sager, S
   Mitsos, A
AF Schweidtmann, Artur M.
   Esche, Erik
   Fischer, Asja
   Kloft, Marius
   Repke, Jens-Uwe
   Sager, Sebastian
   Mitsos, Alexander
TI Machine Learning in Chemical Engineering: A Perspective
SO CHEMIE INGENIEUR TECHNIK
LA English
DT Review
DE Deep learning; Hybrid modeling; Machine learning; Optimization;
   Reinforcement learning
ID SOFT-SENSOR; NEURAL-NETWORKS; HYBRID MODELS; EXPERT SYSTEM;
   OPTIMIZATION; REGRESSION; IDENTIFICATION; CHALLENGES; PREDICTION;
   ANALYTICS
AB The transformation of the chemical industry to renewable energy and feedstock supply requires new paradigms for the design of flexible plants, (bio-)catalysts, and functional materials. Recent breakthroughs in machine learning (ML) provide unique opportunities, but only joint interdisciplinary research between the ML and chemical engineering (CE) communities will unfold the full potential. We identify six challenges that will open new methods for CE and formulate new types of problems for ML: (1) optimal decision making, (2) introducing and enforcing physics in ML, (3) information and knowledge representation, (4) heterogeneity of data, (5) safety and trust in ML applications, and (6) creativity. Under the umbrella of these challenges, we discuss perspectives for future interdisciplinary research that will enable the transformation of CE.
C1 [Schweidtmann, Artur M.] Delft Univ Technol, Dept Chem Engn, Maasweg 9, NL-2629 HZ Delft, Netherlands.
   [Schweidtmann, Artur M.; Mitsos, Alexander] Rhein Westfal TH Aachen, Aachener Verfahrenstech, Forckenbeckstr 51, D-52074 Aachen, Germany.
   [Esche, Erik; Repke, Jens-Uwe] Tech Univ Berlin, Fachgebiet Dynam & Betriebtech Anlagen, Str 17 Juni 135, D-10623 Berlin, Germany.
   [Fischer, Asja] Ruhr Univ Bochum, Dept Math, Univ Str 150, D-44801 Bochum, Germany.
   [Sager, Sebastian] Tech Univ Kaiserslautern, Dept Comp Sci, Erwin Schrodinger Str 52, D-67663 Kaiserslautern, Germany.
   [Mitsos, Alexander] JARA Ctr Simulat & Data Sci CSD, Aachen, Germany.
   [Mitsos, Alexander] Forschungszentrum Julich, Energy & Climate Res IEK 10 Energy Syst Engn, Wilhelm Johnen Str, D-52428 Julich, Germany.
RP Schweidtmann, AM (corresponding author), Delft Univ Technol, Dept Chem Engn, Maasweg 9, NL-2629 HZ Delft, Netherlands.; Schweidtmann, AM (corresponding author), Rhein Westfal TH Aachen, Aachener Verfahrenstech, Forckenbeckstr 51, D-52074 Aachen, Germany.
EM a.schweidtmann@tudelft.nl
FU DFGGerman Research Foundation (DFG)European Commission [SPP 2331]; TU
   Delft AI Labs Programme; Carl-Zeiss Foundation; German Research
   Foundation (DFG)German Research Foundation (DFG) [KL 2698/2-1]; Federal
   Ministry of Science and Education (BMBF)Federal Ministry of Education &
   Research (BMBF) [01IS18051A, 031B0770E]
FX The authors gratefully acknowledge the DFG for establishing the Priority
   Programme SPP 2331 ''Machine learning in chemical engineering. Knowledge
   meets data: Interpretability, Extrapolation, Reliability, Trust''. AMS
   is supported by the TU Delft AI Labs Programme. MK acknowledges support
   by the Carl-Zeiss Foundation, by the German Research Foundation (DFG)
   award KL 2698/2-1, and by the Federal Ministry of Science and Education
   (BMBF) awards 01IS18051A and 031B0770E.
NR 128
TC 2
Z9 2
U1 24
U2 24
PU WILEY-V C H VERLAG GMBH
PI WEINHEIM
PA POSTFACH 101161, 69451 WEINHEIM, GERMANY
SN 0009-286X
EI 1522-2640
J9 CHEM-ING-TECH
JI Chem. Ing. Tech.
PD DEC
PY 2021
VL 93
IS 12
SI SI
BP 2029
EP 2039
DI 10.1002/cite.202100083
EA OCT 2021
PG 11
WC Engineering, Chemical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA XB1UB
UT WOS:000709860100001
OA hybrid, Green Published
DA 2022-04-17
ER

PT C
AU Peerzada, SA
   Seethalani, J
AF Peerzada, Sheeraz Ahmad
   Seethalani, Jitendra
BE Satapathy, SC
   Bhateja, V
   Mohanty, JR
   Udgata, SK
TI Machine Learning and Its Implications on Educational Data Base (U-DISE)
SO SMART INTELLIGENT COMPUTING AND APPLICATIONS, VOL 2
SE Smart Innovation Systems and Technologies
LA English
DT Proceedings Paper
CT 3rd International Conference on Smart Computing and Informatics (SCI)
CY DEC 21-22, 2018
CL Bhubaneswar, INDIA
SP Kalinga Inst Ind Technol, Sch Comp Engn, Kalinga Inst Ind Technol, Sch Comp Applicat, KES Int
DE Machine learning; Supervised; Unsupervised; Deep; Reinforcement machine
   learning algorithms
AB Machine Learning is an emerging trend. To learn from data as well as from past experiences and decision making is most important educational aspects in current educational system. Machine learning is widely used in Artificial Intelligence. Machine Learning is that branch of science which is used to detect different patterns in data and is used to predict future. In this paper we study how Machine Learning can help us in the field of education.
C1 [Peerzada, Sheeraz Ahmad; Seethalani, Jitendra] Sri Satya Sai Univ Technol & Med Sci, Dept Comp Sci, Sehore 466001, MP, India.
RP Peerzada, SA (corresponding author), Sri Satya Sai Univ Technol & Med Sci, Dept Comp Sci, Sehore 466001, MP, India.
EM sheerazmphil@gmail.com; dr.jsheetlani@gmail.com
OI Sheetlani, Jitendra/0000-0002-5666-512X
NR 13
TC 0
Z9 0
U1 7
U2 15
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 2190-3018
EI 2190-3026
BN 978-981-32-9690-9; 978-981-32-9689-3
J9 SMART INNOV SYST TEC
PY 2020
VL 160
BP 291
EP 300
DI 10.1007/978-981-32-9690-9_29
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BP2PT
UT WOS:000544256200029
DA 2022-04-17
ER

PT S
AU Donti, PL
   Kolter, JZ
AF Donti, Priya L.
   Kolter, J. Zico
BE Gadgil, A
   Tomich, TP
TI Machine Learning for Sustainable Energy Systems
SO ANNUAL REVIEW OF ENVIRONMENT AND RESOURCES, VOL 46, 2021
SE Annual Review of Environment and Resources
LA English
DT Review; Book Chapter
DE sustainable energy; energy transition; climate change; machine learning;
   artificial intelligence
ID CONVOLUTIONAL NEURAL-NETWORK; MATERIALS DISCOVERY; UNCERTAINTY
   QUANTIFICATION; ARTIFICIAL-INTELLIGENCE; DEMAND RESPONSE; GENERATION;
   DECISION; MODEL; OPTIMIZATION; ELECTRICITY
AB In recent years, machine learning has proven to be a powerful tool for deriving insights from data. In this review, we describe ways in which machine learning has been leveraged to facilitate the development and operation of sustainable energy systems. We first provide a taxonomy of machine learning paradigms and techniques, along with a discussion of their strengths and limitations. We then provide an overview of existing research using machine learning for sustainable energy production, delivery, and storage. Finally, we identify gaps in this literature, propose future research directions, and discuss important considerations for deployment.
C1 [Donti, Priya L.; Kolter, J. Zico] Carnegie Mellon Univ, Comp Sci Dept, Pittsburgh, PA 15213 USA.
   [Donti, Priya L.] Carnegie Mellon Univ, Dept Engn & Publ Policy, Pittsburgh, PA 15213 USA.
   [Kolter, J. Zico] Bosch Ctr Artificial Intelligence, Pittsburgh, PA 15222 USA.
RP Donti, PL (corresponding author), Carnegie Mellon Univ, Comp Sci Dept, Pittsburgh, PA 15213 USA.; Donti, PL (corresponding author), Carnegie Mellon Univ, Dept Engn & Publ Policy, Pittsburgh, PA 15213 USA.
EM pdonti@cs.cmu.edu
FU US Department of Energy Computational Science Graduate FellowshipUnited
   States Department of Energy (DOE) [DE-FG02-97ER25308]; Center for
   Climate and Energy Decision Making [SES-00949710]; Computational
   Sustainability Network; Bosch Center for Artificial Intelligence
FX The writing of this review was supported by a US Department of Energy
   Computational Science Graduate Fellowship (DE-FG02-97ER25308), the
   Center for Climate and Energy Decision Making through a cooperative
   agreement between theNational Science Foundation andCarnegie Mellon
   University (SES-00949710), the Computational Sustainability Network, and
   the Bosch Center for Artificial Intelligence. We thank Kyle Bradbury
   (Duke University), Lauren Kuntz (Gaiascope, Inc.), and Aidan O'Sullivan
   (University College London) for their thoughtful feedback on the
   manuscript.
NR 166
TC 0
Z9 0
U1 33
U2 33
PU ANNUAL REVIEWS
PI PALO ALTO
PA 4139 EL CAMINO WAY, PO BOX 10139, PALO ALTO, CA 94303-0897 USA
SN 1543-5938
BN 978-0-8243-2346-2
J9 ANNU REV ENV RESOUR
JI Annu. Rev. Environ. Resour
PY 2021
VL 46
BP 719
EP 747
DI 10.1146/annurev-environ-020220-061831
PG 29
WC Environmental Sciences; Environmental Studies
WE Book Citation Index – Social Sciences & Humanities (BKCI-SSH); Book Citation Index – Science (BKCI-S); Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Environmental Sciences & Ecology
GA BS3NZ
UT WOS:000713670600026
OA gold
DA 2022-04-17
ER

PT J
AU Vega, R
   Flores, L
   Greiner, R
AF Vega, Roberto
   Flores, Leonardo
   Greiner, Russell
TI SIMLR: Machine Learning inside the SIR Model for COVID-19 Forecasting
SO FORECASTING
LA English
DT Article
DE COVID-19; probabilistic graphical models; interpretable machine learning
AB Accurate forecasts of the number of newly infected people during an epidemic are critical for making effective timely decisions. This paper addresses this challenge using the SIMLR model, which incorporates machine learning (ML) into the epidemiological SIR model. For each region, SIMLR tracks the changes in the policies implemented at the government level, which it uses to estimate the time-varying parameters of an SIR model for forecasting the number of new infections one to four weeks in advance. It also forecasts the probability of changes in those government policies at each of these future times, which is essential for the longer-range forecasts. We applied SIMLR to data from in Canada and the United States, and show that its mean average percentage error is as good as state-of-the-art forecasting models, with the added advantage of being an interpretable model. We expect that this approach will be useful not only for forecasting COVID-19 infections, but also in predicting the evolution of other infectious diseases.
C1 [Vega, Roberto; Greiner, Russell] Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2R3, Canada.
   [Vega, Roberto; Greiner, Russell] Alberta Machine Intelligence Inst, Edmonton, AB T5J 3B1, Canada.
RP Vega, R (corresponding author), Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2R3, Canada.; Vega, R (corresponding author), Alberta Machine Intelligence Inst, Edmonton, AB T5J 3B1, Canada.
EM rvega@ualberta.ca; leonardo.flores.q@gmail.com; rgreiner@ualberta.ca
FU Alberta Machine Intelligence Institute
FX This research was funded by Alberta Machine Intelligence Institute.
NR 33
TC 1
Z9 1
U1 0
U2 0
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2571-9394
J9 FORECASTING-BASEL
JI Forecasting
PD MAR
PY 2022
VL 4
IS 1
BP 72
EP 94
DI 10.3390/forecast4010005
PG 23
WC Multidisciplinary Sciences
WE Emerging Sources Citation Index (ESCI)
SC Science & Technology - Other Topics
GA 0C6TU
UT WOS:000775444300001
OA Green Submitted, gold
DA 2022-04-17
ER

PT C
AU Cecil, T
   Braam, K
   Omran, A
   Poonawala, A
   Shu, J
   Vandam, C
AF Cecil, Thomas
   Braam, Kyle
   Omran, Ahmed
   Poonawala, Amyn
   Shu, Jason
   Vandam, Clark
BE Owa, S
   Phillips, MC
TI Machine Learning ILT for Memory Customers
SO OPTICAL MICROLITHOGRAPHY XXXIV
SE Proceedings of SPIE
LA English
DT Proceedings Paper
CT Conference on Optical Microlithography XXXIV
CY FEB 22-26, 2021
CL ELECTR NETWORK
SP SPIE
DE Inverse Lithography Technology; ILT; Machine Learning; OPC; Neural
   Networks
AB In this paper. we will present a machine learning solution targeted for memory customers including both assist feature and main feature mask synthesis. In a previous paper, we demonstrated machine learning ILT solutions for the creation of assist features using a neural network. In this paper, we extend the solution to include main features masks, which we can create using machine learning models which take into account the full ILT corrected masks during training. In practice, while the correction of main features is often visually more intuitive, there are underlying edge to edge and polygon to polygon interactions that are not easily captured by local influence edge perturbations found in typical OPC solvers but can be captured by ILT and machine learning solutions trained on ILT masks.
C1 [Cecil, Thomas; Braam, Kyle; Omran, Ahmed; Poonawala, Amyn; Shu, Jason; Vandam, Clark] Synopsys, 690 E Middlefield Rd, Mountain View, CA 94043 USA.
RP Cecil, T (corresponding author), Synopsys, 690 E Middlefield Rd, Mountain View, CA 94043 USA.
NR 11
TC 0
Z9 0
U1 2
U2 2
PU SPIE-INT SOC OPTICAL ENGINEERING
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA
SN 0277-786X
EI 1996-756X
BN 978-1-5106-4060-3; 978-1-5106-4059-7
J9 PROC SPIE
PY 2021
VL 11613
AR 116130P
DI 10.1117/12.2587107
PG 7
WC Engineering, Manufacturing; Engineering, Electrical & Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering; Optics
GA BR8SN
UT WOS:000672826200016
DA 2022-04-17
ER

PT J
AU Wang, J
   Lu, SY
   Wang, SH
   Zhang, YD
AF Wang, Jian
   Lu, Siyuan
   Wang, Shui-Hua
   Zhang, Yu-Dong
TI A review on extreme learning machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE extreme learning machine; neural network; medical imaging;
   classification; optimization; clustering; regression
ID RESTRICTED BOLTZMANN MACHINE; ARTIFICIAL NEURAL-NETWORK; FAULT-DIAGNOSIS
   METHOD; OBJECT RECOGNITION; FEATURE-SELECTION; TUMOR DETECTION; ELM;
   CLASSIFICATION; ALGORITHM; PREDICTION
AB Extreme learning machine (ELM) is a training algorithm for single hidden layer feedforward neural network (SLFN), which converges much faster than traditional methods and yields promising performance. In this paper, we hope to present a comprehensive review on ELM. Firstly, we will focus on the theoretical analysis including universal approximation theory and generalization. Then, the various improvements are listed, which help ELM works better in terms of stability, efficiency, and accuracy. Because of its outstanding performance, ELM has been successfully applied in many real-time learning tasks for classification, clustering, and regression. Besides, we report the applications of ELM in medical imaging: MRI, CT, and mammogram. The controversies of ELM were also discussed in this paper. We aim to report these advances and find some future perspectives.
C1 [Wang, Jian; Lu, Siyuan; Zhang, Yu-Dong] Univ Leicester, Sch Informat, Leicester LE1 7RH, Leics, England.
   [Wang, Shui-Hua; Zhang, Yu-Dong] Henan Polytech Univ, Sch Comp Sci & Technol, Jiaozuo 454000, Henan, Peoples R China.
   [Wang, Shui-Hua] Univ Leicester, Dept Cardiovasc Sci, Leicester LE1 7RH, Leics, England.
   [Wang, Shui-Hua; Zhang, Yu-Dong] King Abdulaziz Univ, Fac Comp & Informat Technol, Dept Informat Syst, Jeddah 21589, Saudi Arabia.
   [Wang, Shui-Hua] Loughborough Univ, Sch Architecture Bldg & Civil Engn, Loughborough LE11 3TU, Leics, England.
RP Zhang, YD (corresponding author), Univ Leicester, Sch Informat, Leicester LE1 7RH, Leics, England.; Wang, SH; Zhang, YD (corresponding author), Henan Polytech Univ, Sch Comp Sci & Technol, Jiaozuo 454000, Henan, Peoples R China.; Wang, SH (corresponding author), Univ Leicester, Dept Cardiovasc Sci, Leicester LE1 7RH, Leics, England.; Wang, SH; Zhang, YD (corresponding author), King Abdulaziz Univ, Fac Comp & Informat Technol, Dept Informat Syst, Jeddah 21589, Saudi Arabia.; Wang, SH (corresponding author), Loughborough Univ, Sch Architecture Bldg & Civil Engn, Loughborough LE11 3TU, Leics, England.
EM jw830@le.ac.uk; sl672@le.ac.uk; shuihuawang@ieee.org;
   yudongzhang@ieee.org
RI Zhang, Yudong/I-7633-2013; Wang, Shuihua/G-7326-2016; Lu,
   Siyuan/ABE-7949-2020
OI Zhang, Yudong/0000-0002-4870-1493; Wang, Shuihua/0000-0003-4713-2791; 
FU Henan Key Research and Development Project [182102310629]; National Key
   Research and Development Plan [2017YFB1103202]; Guangxi Key Laboratory
   of Trusted Software [kx201901]; International Exchanges Cost Share Royal
   Society [RP202G0230]; Hope Foundation for Cancer Research [RM60G0680];
   Medical Research Council Confidence in Concept Award, UK [MC_PC_17171];
   Fundamental Research Funds for the Central UniversitiesFundamental
   Research Funds for the Central Universities [CDLS-2020-03]; Key
   Laboratory of Child Development and Learning Science (Southeast
   University), Ministry of Education
FX This work was supported by Henan Key Research and Development Project
   (182102310629), National Key Research and Development Plan
   (2017YFB1103202), Guangxi Key Laboratory of Trusted Software (kx201901),
   International Exchanges Cost Share Royal Society (RP202G0230), Hope
   Foundation for Cancer Research (RM60G0680); Medical Research Council
   Confidence in Concept Award, UK (MC_PC_17171); Fundamental Research
   Funds for the Central Universities (CDLS-2020-03); Key Laboratory of
   Child Development and Learning Science (Southeast University), Ministry
   of Education.
NR 246
TC 5
Z9 5
U1 39
U2 59
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
DI 10.1007/s11042-021-11007-7
EA MAY 2021
PG 50
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF7NX
UT WOS:000652938900001
OA hybrid
DA 2022-04-17
ER

PT C
AU Shahzad, A
   Duyen, TTG
AF Shahzad, Abid
   Tran Thi Giac Duyen
GP Assoc Informat Syst
TI Machine Learning-based Systems for Supplier Evaluation and Selection in
   New Zealand SMEs Completed Research
SO DIGITAL INNOVATION AND ENTREPRENEURSHIP (AMCIS 2021)
LA English
DT Proceedings Paper
CT 27th Annual Americas Conference on Information Systems (AMCIS)
CY AUG 09-13, 2021
CL ELECTR NETWORK
DE Machine Learning; supplier management; supplier evaluation and
   selection; New Zealand enterprises
AB The supplier evaluation and selection process play an essential role in the business processes. This process ensures the seamless delivery of products and services to customers, enhance the business, support business growth, and keep the competitive advantage. Nevertheless, there is little empirical research on the practical application of new technology such as Machine Learning in supplier evaluation and selection to solve the problems with the existing supplier management processes of New Zealand enterprises. This research aims to explore and understand the supplier management process and to determine the effective use of Machine Learning in supplier evaluation and selection processes in New Zealand enterprises. Based on the findings, this research proposes the recommendation that helps New Zealand enterprises in improving, enhancing the operations, and maximising the effectiveness of evaluating and selecting the strategic suppliers to strengthen their value chain.
C1 [Shahzad, Abid; Tran Thi Giac Duyen] ICL Grad Business Sch, Auckland, New Zealand.
RP Shahzad, A (corresponding author), ICL Grad Business Sch, Auckland, New Zealand.
EM abidshahzad@icl.ac.nz; 102945@icl.school.nz
FU Future research on the application of Machine Learning
FX This research represents a significant opportunity to recognize new gaps
   and to present the need for further development in the area of Machine
   Learning research. To provide statistical results, quantitative research
   that should focus the broader population of New Zealand enterprises is
   recommended. Additional research and data will test the findings from
   this investigation and will prove whether this research is statistically
   significant or due to chance. Future research on the application of
   Machine Learning to supplier evaluation and selection in New Zealand
   enterprises would be highly recommended with a larger sample size.
NR 17
TC 0
Z9 0
U1 3
U2 3
PU ASSOC INFORMATION SYSTEMS
PI ATLANTA
PA P.O. BOX 2712, ATLANTA, GA 30301-2712 USA
PY 2021
PG 10
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR8LY
UT WOS:000672599801080
DA 2022-04-17
ER

PT C
AU Lounici, S
   Njeh, M
   Ermis, O
   Onen, M
   Trabelsi, S
AF Lounici, Sofiane
   Njeh, Mohamed
   Ermis, Orhan
   Onen, Melek
   Trabelsi, Slim
GP IEEE Comp Soc
TI Yes We can: Watermarking Machine Learning Models beyond Classification
SO 2021 IEEE 34TH COMPUTER SECURITY FOUNDATIONS SYMPOSIUM (CSF 2021)
SE Proceedings IEEE Computer Security Foundations Symposium
LA English
DT Proceedings Paper
CT IEEE 34th Computer Security Foundations Symposium (CSF)
CY JUN 21-24, 2021
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc
DE Watermarking; machine learning; neural networks; reinforcement learning;
   regression; machine translation
AB Since machine learning models have become a valuable asset for companies, watermarking techniques have been developed to protect the intellectual property of these models and prevent model theft. We observe that current watermarking frameworks solely target image classification tasks, neglecting a considerable part of machine learning techniques. In this paper, we propose to address this lack and study the watermarking process of various machine learning techniques such as machine translation, regression, binary image classification and reinforcement learning models. We adapt current definitions to each specific technique and we evaluate the main characteristics of the watermarking process, in particular the robustness of the models against a rational adversary. We show that watermarking models beyond classification is possible while preserving their overall performance. We further investigate various attacks and discuss the importance of the performance metric in the verification process and its impact on the success of the adversary.
C1 [Lounici, Sofiane; Trabelsi, Slim] SAP Secur Res, Mougins, France.
   [Njeh, Mohamed; Ermis, Orhan; Onen, Melek] EURECOM, Sophia Antipolis, France.
RP Lounici, S (corresponding author), SAP Secur Res, Mougins, France.
EM sofiane.lounici@sap.com; njeh@eurecom.fr; ermis@eurecom.fr;
   onen@eurecom.fr; slim.trabelsi@sap.com
FU 3IA Cote d'Azur program [ANR19-P3IA-0002]
FX This work has been partially supported by the 3IA Cote d'Azur program
   (reference number ANR19-P3IA-0002).
NR 33
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
SN 1940-1434
EI 2374-8303
BN 978-1-7281-7607-9
J9 P IEEE COMPUT SECUR
PY 2021
BP 483
EP 496
DI 10.1109/CSF51468.2021.00044
PG 14
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods; Mathematics, Applied
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Mathematics
GA BS4HD
UT WOS:000719322000032
DA 2022-04-17
ER

PT J
AU Li, HH
   Wen, GH
AF Li, Huihui
   Wen, Guihua
TI Modeling reverse thinking for machine learning
SO SOFT COMPUTING
LA English
DT Article
DE Machine learning; Inertial thinking model; Modeling reverse thinking
ID BIG DATA; INTEGRATION; DIVERGENT
AB Human inertial thinking schemes can be formed through learning, which are then applied to quickly solve similar problems later. However, when problems are significantly different, inertial thinking generally presents the solutions that are definitely imperfect. In such cases, people will apply creative thinking, such as reverse thinking, to solve problems. Similarly, machine learning methods also form inertial thinking schemes through learning the knowledge from a large amount of data. However, when the testing samples are vastly different, the formed inertial thinking schemes will inevitably generate errors. This kind of inertial thinking is called illusion inertial thinking. Because all machine learning methods do not consider the illusion inertial thinking, in this paper we propose a new method that uses the reverse thinking to correct the illusion inertial thinking, which increases the generalization ability of machine learning methods. Experimental results on benchmark data sets validated the proposed method.
C1 [Li, Huihui; Wen, Guihua] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
RP Wen, GH (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
EM crghwen@scut.edu.cn
OI LI, HUIHUI/0000-0003-0463-8178
FU China National Science FoundationNational Natural Science Foundation of
   China (NSFC) [60973083/61273363]; Science and Technology Planning
   Project of Guangdong Province [2014A010103009/2015A020217002]; Guangzhou
   Science and Technology Planning Project [201504291154480, 201604020179,
   201803010088]
FX This study was supported by the China National Science Foundation
   (60973083/61273363), Science and Technology Planning Project of
   Guangdong Province (2014A010103009/2015A020217002), and Guangzhou
   Science and Technology Planning Project (201504291154480, 201604020179,
   201803010088).
NR 45
TC 2
Z9 2
U1 5
U2 12
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1432-7643
EI 1433-7479
J9 SOFT COMPUT
JI Soft Comput.
PD JAN
PY 2020
VL 24
IS 2
BP 1483
EP 1496
DI 10.1007/s00500-019-03980-x
PG 14
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA KG1FE
UT WOS:000509686300046
OA Green Submitted
DA 2022-04-17
ER

PT C
AU Ahmed, H
   Younis, EMG
   Ali, AA
AF Ahmed, Hager
   Younis, Eman M. G.
   Ali, Abdelmgeid A.
GP IEEE
TI Predicting Diabetes using Distributed Machine Learning based on Apache
   Spark
SO PROCEEDINGS OF 2020 INTERNATIONAL CONFERENCE ON INNOVATIVE TRENDS IN
   COMMUNICATION AND COMPUTER ENGINEERING (ITCE)
LA English
DT Proceedings Paper
CT International Conference on Innovative Trends in Communication and
   Computer Engineering (ITCE)
CY FEB 08-09, 2020
CL Aswan, EGYPT
SP IEEE, Aswan Univ, Fac Engn, Natl Telecommunicat Regulat Author, Si Vis, Smart Syst, New Tech Acad Networks Solut
DE Diabetes; Distributed Machine Learning; Apache Spark
ID SUPPORT VECTOR MACHINES
AB Diabetes mellitus is a long-standing disease. It constitutes a severe challenge for public health worldwide. As stated by the International Diabetes Federation, there are presently about 246 million diabetic people around the world, and this number is anticipated to increase to around 380 million by the year 2025. More than this, 3.8 million death cases occur annually due to diabetes complications. The primary objective of this work is developing an applicable system to predict diabetes using distributed machine learning based on big data platforms such as Spark. In this context, this study aims to develop models using distributed machine learning based on Apache Spark to predict diabetes. Five machine learning classification methods were used like Decision Tree, Support Vector Machine, Logistic Regression Classifier, Naive Bayes, and Random Forest Classifier. Comparison between different algorithms was calculated using three measures, which are accuracy, recall, and precision. The experimental results proposed that LR achieved the highest percentage of accuracy, recall, and precision,82%, 92%, and 82%, respectively.
C1 [Ahmed, Hager; Younis, Eman M. G.] Fac Comp & Informat, Dept Informat Syst, Al Minya, Egypt.
   [Ali, Abdelmgeid A.] Fac Comp & Informat, Dept Comp Sci, Al Minya, Egypt.
RP Ahmed, H (corresponding author), Fac Comp & Informat, Dept Informat Syst, Al Minya, Egypt.
EM hager.saleh.fci@gmail.com; eman.younas@mu.edu.eg; abdelmgeid@yahoo.com
NR 18
TC 1
Z9 1
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-4800-7
PY 2020
BP 44
EP 49
PG 6
WC Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS4ME
UT WOS:000720348300008
DA 2022-04-17
ER

PT J
AU Zhang, YA
   Wu, QB
   Hu, JL
AF Zhang, Yuao
   Wu, Qingbiao
   Hu, Jueliang
TI An Adaptive Learning Algorithm for Regularized Extreme Learning Machine
SO IEEE ACCESS
LA English
DT Article
DE Adaptive; convergence; convexity; extreme learning machine (ELM);
   regularization
ID NEURAL-NETWORKS; REGRESSION; SELECTION; CHOICE
AB Extreme learning machine (ELM) has become popular in recent years, due to its robust approximation capacity and fast learning speed. It is common to add a l(2) penalty term in basic ELM to avoid over-fitting. However, in l(2)-regularized extreme learning machine (l(2)-RELM), choosing a suitable regularization factor is random and time consuming. In order to select a satisfactory regularization factor automatically, we proposed an adaptive regularized extreme learning machine (A-RELM) by replacing the regularization factor with a function. The function is defined in terms of the output weights named regularization function. And an iterative algorithm is proposed for obtaining the output weights, therefore, allowing for deriving their values simultaneously. Besides, the constructed regularization function ensures the convexity of the model, which contributes to a globally optimal solution. The convergence analysis of the iterative algorithm guarantees the effectiveness of the model training. Experimental results on some UCI benchmarks and the Yale face database B indicate the superiority of our proposed algorithm.
C1 [Zhang, Yuao; Wu, Qingbiao] Zhejiang Univ, Dept Math, Hangzhou 310007, Peoples R China.
   [Hu, Jueliang] Zhejiang Sci Tech Univ, Dept Math, Hangzhou 310018, Peoples R China.
RP Hu, JL (corresponding author), Zhejiang Sci Tech Univ, Dept Math, Hangzhou 310018, Peoples R China.
EM hujlhz@163.com
OI Zhang, Yuao/0000-0002-8664-9788
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [11771393]
FX This work was supported by the National Natural Science Foundation of
   China (Grant no. 11771393).
NR 52
TC 1
Z9 1
U1 7
U2 20
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 20736
EP 20745
DI 10.1109/ACCESS.2021.3054483
PG 10
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA QE6BG
UT WOS:000616290300001
OA gold
DA 2022-04-17
ER

PT J
AU Turgeon, S
   Lanovaz, MJ
AF Turgeon, Stephanie
   Lanovaz, Marc J.
TI Tutorial: Applying Machine Learning in Behavioral Research
SO PERSPECTIVES ON BEHAVIOR SCIENCE
LA English
DT Article
DE Artificial intelligence; Behavior analysis; Machine learning; Tutorial
ID SINGLE-CASE DATA; SELECTION; OUTCOMES
AB Machine-learning algorithms hold promise for revolutionizing how educators and clinicians make decisions. However, researchers in behavior analysis have been slow to adopt this methodology to further develop their understanding of human behavior and improve the application of the science to problems of applied significance. One potential explanation for the scarcity of research is that machine learning is not typically taught as part of training programs in behavior analysis. This tutorial aims to address this barrier by promoting increased research using machine learning in behavior analysis. We present how to apply the random forest, support vector machine, stochastic gradient descent, and k-nearest neighbors algorithms on a small dataset to better identify parents of children with autism who would benefit from a behavior analytic interactive web training. These step-by-step applications should allow researchers to implement machine-learning algorithms with novel research questions and datasets.
C1 [Turgeon, Stephanie; Lanovaz, Marc J.] Univ Montreal, Ecole Psychoeduc, CP 6128,Succursale Ctr Ville, Montreal, PQ H3C 3J7, Canada.
   [Lanovaz, Marc J.] Ctr Rech Inst Univ Sante Mentale Montreal, Montreal, PQ, Canada.
RP Lanovaz, MJ (corresponding author), Univ Montreal, Ecole Psychoeduc, CP 6128,Succursale Ctr Ville, Montreal, PQ H3C 3J7, Canada.; Lanovaz, MJ (corresponding author), Ctr Rech Inst Univ Sante Mentale Montreal, Montreal, PQ, Canada.
EM marc.lanovaz@umontreal.ca
RI Lanovaz, Marc J/K-9614-2019
OI Lanovaz, Marc J/0000-0002-9023-0314
FU Social Sciences and Humanities Research Council of Canada (SSHRC)Social
   Sciences and Humanities Research Council of Canada (SSHRC)CGIAR; Fonds
   de recherche du Quebec - SanteFonds de la Recherche en Sante du Quebec
   [269462]
FX This study was funded in part by a Graduate Scholarship from the Social
   Sciences and Humanities Research Council of Canada (SSHRC) to the first
   author and a salary award from the Fonds de recherche du Quebec - Sante
   (#269462) to the second author.
NR 40
TC 4
Z9 4
U1 4
U2 8
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2520-8969
EI 2520-8977
J9 PERSPECT BEHAV SCI
JI Perspect. Behav. Sci.
PD DEC
PY 2020
VL 43
IS 4
BP 697
EP 723
DI 10.1007/s40614-020-00270-y
EA NOV 2020
PG 27
WC Psychology, Clinical
WE Social Science Citation Index (SSCI)
SC Psychology
GA PC8PK
UT WOS:000588277100001
PM 33381685
OA Green Published, Green Submitted, Green Accepted
DA 2022-04-17
ER

PT J
AU Wu, YM
   Guo, Y
   Ma, J
   Sa, Y
   Li, QF
   Zhang, N
AF Wu, Yameng
   Guo, Yu
   Ma, Jun
   Sa, Yu
   Li, Qifeng
   Zhang, Ning
TI Research Progress of Gliomas in Machine Learning
SO CELLS
LA English
DT Review
DE gliomas; machine learning; prediction; radiomics; gene expression
ID NEURAL-NETWORK MODEL; GENE-EXPRESSION DATA; MRI TEXTURE; CLASSIFICATION;
   PREDICTION; CANCER; PERSPECTIVES; ORGANIZATION; DIAGNOSIS; SELECTION
AB In the field of gliomas research, the broad availability of genetic and image information originated by computer technologies and the booming of biomedical publications has led to the advent of the big-data era. Machine learning methods were applied as possible approaches to speed up the data mining processes. In this article, we reviewed the present situation and future orientations of machine learning application in gliomas within the context of workflows to integrate analysis for precision cancer care. Publicly available tools or algorithms for key machine learning technologies in the literature mining for glioma clinical research were reviewed and compared. Further, the existing solutions of machine learning methods and their limitations in glioma prediction and diagnostics, such as overfitting and class imbalanced, were critically analyzed.
C1 [Wu, Yameng; Guo, Yu; Ma, Jun; Sa, Yu; Li, Qifeng; Zhang, Ning] Tianjin Univ, Dept Biomed Engn, Tianjin Key Lab BME Measurement, Tianjin 300000, Peoples R China.
RP Zhang, N (corresponding author), Tianjin Univ, Dept Biomed Engn, Tianjin Key Lab BME Measurement, Tianjin 300000, Peoples R China.
EM wuyameng@tju.edu.cn; guoyu@tju.edu.cn; majun1@tju.edu.cn;
   sayu@tju.edu.cn; qfli@tju.edu.cn; zhni@tju.edu.cn
OI Wu, yameng/0000-0003-3267-3069
FU Key Projects in the Science & Technology Pillar Program of Tianjin
   [20YFZCSN00530]; Independent Innovation Foundation of Tianjin University
   [2020XYF-0110, 2020XY-0058]
FX This work was supported by grants from Key Projects in the Science &
   Technology Pillar Program of Tianjin (20YFZCSN00530) and Independent
   Innovation Foundation of Tianjin University (2020XYF-0110, 2020XY-0058).
NR 87
TC 0
Z9 0
U1 5
U2 5
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2073-4409
J9 CELLS-BASEL
JI Cells
PD NOV
PY 2021
VL 10
IS 11
AR 3169
DI 10.3390/cells10113169
PG 16
WC Cell Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Cell Biology
GA XG8DQ
UT WOS:000724978800001
PM 34831392
OA gold, Green Published
DA 2022-04-17
ER

PT J
AU Basu, S
   Johnson, KT
   Berkowitz, SA
AF Basu, Sanjay
   Johnson, Karl T.
   Berkowitz, Seth A.
TI Use of Machine Learning Approaches in Clinical Epidemiological Research
   of Diabetes
SO CURRENT DIABETES REPORTS
LA English
DT Review
DE Machine learning; Diabetes
ID INDIVIDUAL PARTICIPANT DATA; GLYCEMIC CONTROL; RISK EQUATIONS;
   COMPLICATIONS; RETINOPATHY; VALIDATION; PREDICTION; ENSEMBLE;
   CLASSIFICATION; CLASSIFIERS
AB Purpose of Review Machine learning approaches-which seek to predict outcomes or classify patient features by recognizing patterns in large datasets-are increasingly applied to clinical epidemiology research on diabetes. Given its novelty and emergence in fields outside of biomedical research, machine learning terminology, techniques, and research findings may be unfamiliar to diabetes researchers. Our aim was to present the use of machine learning approaches in an approachable way, drawing from clinical epidemiological research in diabetes published from 1 Jan 2017 to 1 June 2020. Recent Findings Machine learning approaches using tree-based learners-which produce decision trees to help guide clinical interventions-frequently have higher sensitivity and specificity than traditional regression models for risk prediction. Machine learning approaches using neural networking and "deep learning" can be applied to medical image data, particularly for the identification and staging of diabetic retinopathy and skin ulcers. Among the machine learning approaches reviewed, researchers identified new strategies to develop standard datasets for rigorous comparisons across older and newer approaches, methods to illustrate how a machine learner was treating underlying data, and approaches to improve the transparency of the machine learning process. Machine learning approaches have the potential to improve risk stratification and outcome prediction for clinical epidemiology applications. Achieving this potential would be facilitated by use of universal open-source datasets for fair comparisons. More work remains in the application of strategies to communicate how the machine learners are generating their predictions.
C1 [Basu, Sanjay] Harvard Med Sch, Ctr Primary Care, Boston, MA 02115 USA.
   [Basu, Sanjay] Collect Hlth, Res & Populat Hlth, San Francisco, CA USA.
   [Basu, Sanjay] Imperial Coll London, Sch Publ Hlth, London SW7, England.
   [Johnson, Karl T.; Berkowitz, Seth A.] Univ N Carolina, Gen Med & Clin Epidemiol, Chapel Hill, NC 27515 USA.
RP Basu, S (corresponding author), Harvard Med Sch, Ctr Primary Care, Boston, MA 02115 USA.; Basu, S (corresponding author), Collect Hlth, Res & Populat Hlth, San Francisco, CA USA.; Basu, S (corresponding author), Imperial Coll London, Sch Publ Hlth, London SW7, England.
EM sanjay_basu@hms.harvard.edu
NR 125
TC 2
Z9 2
U1 16
U2 30
PU CURRENT MEDICINE GROUP
PI PHILADELPHIA
PA 400 MARKET STREET, STE 700, PHILADELPHIA, PA 19106 USA
SN 1534-4827
EI 1539-0829
J9 CURR DIABETES REP
JI Curr. Diabetes Rep.
PD DEC
PY 2020
VL 20
IS 12
AR 80
DI 10.1007/s11892-020-01353-5
PG 19
WC Endocrinology & Metabolism
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Endocrinology & Metabolism
GA PA3VZ
UT WOS:000595568500001
PM 33270183
DA 2022-04-17
ER

PT J
AU Feng, Q
   Maier, W
   Stehle, T
   Mohring, HC
AF Feng, Qi
   Maier, Walther
   Stehle, Thomas
   Mohring, Hans-Christian
TI Optimization of a clamping concept based on machine learning
SO PRODUCTION ENGINEERING-RESEARCH AND DEVELOPMENT
LA English
DT Article
DE Fixtures; Clamping concept; Machine learning; FEM; Workpiece
   deflections; Vibrations
ID COMPUTER-AIDED FIXTURE; FINITE-ELEMENT-ANALYSIS; LAYOUT DESIGN;
   INTELLIGENT FIXTURES; KNOWLEDGE MODEL; SETUP; DEFORMATION; METHODOLOGY;
   WORKPIECE; SYSTEM
AB Fixtures are an important element of the manufacturing system, as they ensure productive and accurate machining of differently shaped workpieces. Regarding the fixture design or the layout of fixture elements, a high static and dynamic stiffness of fixtures is therefore required to ensure the defined position and orientation of workpieces under process loads, e.g. cutting forces. Nowadays, with the increase in computing performance and the development of new algorithms, machine learning (ML) offers an appropriate possibility to use regression methods for creating realistic, rapid and reliable equivalent ML models instead of simulations based on the finite element method (FEM). This research work introduces a novel method that allows an optimization of clamping concepts and fixture design by means of ML, in order to reduce manufacturing errors and to obtain an increased stiffness of fixtures and machining accuracy. This paper describes the preparation of a dataset for training ML models, the systematic selection of the most promising regression algorithm based on relevant criteria, the implementation of the chosen algorithm Extreme Gradient Boosting (XGBoost) and other comparable algorithms, the analysis of their regression results, and the validation of the optimization for a selected clamping concept.
C1 [Feng, Qi; Maier, Walther; Stehle, Thomas; Mohring, Hans-Christian] Univ Stuttgart, Inst Machine Tools IfW, Holzgartenstr 17, Stuttgart, Germany.
RP Feng, Q (corresponding author), Univ Stuttgart, Inst Machine Tools IfW, Holzgartenstr 17, Stuttgart, Germany.
EM qi.feng@gsame.uni-stuttgart.de
RI Möhring, Hans-Christian/ABF-5022-2021
OI Feng, Qi/0000-0002-6774-144X
FU Deutsche Forschungsgemeinschaft (DFG-German Research Foundation) within
   the Exzellenzinitiative (Excellence Initiative)-GSC 262German Research
   Foundation (DFG); Landesministerium fur Wissenschaft, Forschung und
   Kunst BadenWurttemberg (Ministry of Science, Research and the Arts of
   the State of Baden-Wurttemberg)
FX This work was supported by the Deutsche Forschungsgemeinschaft
   (DFG-German Research Foundation) within the Exzellenzinitiative
   (Excellence Initiative)-GSC 262 and the Landesministerium fur
   Wissenschaft, Forschung und Kunst BadenWurttemberg (Ministry of Science,
   Research and the Arts of the State of Baden-Wurttemberg) within the
   Nachhaltigkeitsforderung (sustainability support) of the projects of the
   Exzellenzinitiative II. The authors would like to thank Dr. P. Reimann
   (IPVS Institute for Parallel and Distributed Systems, University of
   Stuttgart) for the helpful discussion of machine learning.
NR 65
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 0944-6524
EI 1863-7353
J9 PROD ENG-RES DEV
JI Prod. Eng.-Res. Dev.
PD FEB
PY 2022
VL 16
IS 1
BP 9
EP 22
DI 10.1007/s11740-021-01073-z
EA AUG 2021
PG 14
WC Engineering, Manufacturing
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA YJ4XB
UT WOS:000686080600001
OA hybrid
DA 2022-04-17
ER

PT J
AU Yu, CL
   Jiang, JC
AF Yu, Chunling
   Jiang, Jingchao
TI A Perspective on Using Machine Learning in 3D Bioprinting
SO INTERNATIONAL JOURNAL OF BIOPRINTING
LA English
DT Article
DE 3D printing; Bioprinting; Machine learning
ID SUPPORT STRUCTURES; OPTIMIZATION; TRENDS
AB Recently, three-dimensional (3D) printing technologies have been widely applied in industry and our daily lives. The term 3D bioprinting has been coined to describe 3D printing at the biomedical level. Machine learning is currently becoming increasingly active and has been used to improve 3D printing processes, such as process optimization, dimensional accuracy analysis, manufacturing defect detection, and material property prediction. However, few studies have been found to use machine learning in 3D bioprinting processes. In this paper, related machine learning methods used in 3D printing are briefly reviewed and a perspective on how machine learning can also benefit 3D bioprinting is discussed. We believe that machine learning can significantly affect the future development of 3D bioprinting and hope this paper can inspire some ideas on how machine learning can be used to improve 3D bioprinting.
C1 [Yu, Chunling] Ningbo Univ, Fac Maritime & Transportat, Ningbo 315211, Zhejiang, Peoples R China.
   [Jiang, Jingchao] Univ Auckland, Dept Mech Engn, Auckland 1010, New Zealand.
RP Jiang, JC (corresponding author), Univ Auckland, Dept Mech Engn, Auckland 1010, New Zealand.
EM jjia547@aucklanduni.ac.nz
RI Jiang, Jingchao/R-1303-2019
OI Jiang, Jingchao/0000-0002-0446-3454
FU K.C.Wong Magna Fund in Ningbo University
FX This research is sponsored by K.C.Wong Magna Fund in Ningbo University.
NR 38
TC 46
Z9 46
U1 24
U2 54
PU WHIOCE PUBLISHING PTE LTD, SINGAPORE
PI SINGAPORE
PA 7030 ANG MO KIO AVE 5, 04-15 NORTHSTAR AMK, SINGAPORE, 569880, SINGAPORE
SN 2424-7723
EI 2424-8002
J9 INT J BIOPRINTING
JI Int. J. Bioprinting
PY 2020
VL 6
IS 1
AR 253
DI 10.18063/ijb.v6i1.253
PG 8
WC Engineering, Biomedical; Materials Science, Biomaterials
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Materials Science
GA KJ9EG
UT WOS:000512357000002
PM 32782987
OA Green Published, gold
DA 2022-04-17
ER

PT S
AU Satapathy, SC
   Jena, AK
   Singh, J
   Bilgaiyan, S
AF Satapathy, Suresh Chandra
   Jena, Ajay Kumar
   Singh, Jagannath
   Bilgaiyan, Saurabh
BA Satapathy, SC
   Jena, AK
   Singh, J
   Bilgaiyan, S
BF Satapathy, SC
   Jena, AK
   Singh, J
   Bilgaiyan, S
TI Usage of Machine Learning in Software Testing
SO AUTOMATED SOFTWARE ENGINEERING: A DEEP LEARNING-BASED APPROACH
SE Learning and Analytics in Intelligent Systems
LA English
DT Article; Book Chapter
DE Machine learning; Software testing; Defect prediction; Vulnerability
   analysis; Automated software testing
ID STATIC ANALYSIS; DIVERSITY
AB Finding, pinpointing and correcting bugs in the software takes a lot of effort for software developers. Traditional testing requires humans to search and analyze data. Humans being prone to poor assumptions and hence skewed results leads to overlooked bugs. Machine learning helps systems to learn and apply the learned knowledge in the future which helps software testers with more accurate knowledge. Capability of several advanced machine learning techniques such as deep learning in a number of software engineering tasks such as code completion, defect prediction, bug localization, clone detection, code search and learning API sequences. A lot of approaches have been proposed by the researchers over the years at modifying programs automatically. Repairing programs by generate-and-validate techniques gain a lot by producing acceptable patches to the programmers and not overfitting through learning from past history and generating patches from correct code via probabilistic model. These approaches given the right environments play significant role in reducing the effort and time consumption as well as cost of the bug fixing for the software developers. In this chapter, various machine learning algorithms and their impact in software testing and bug fixing are explored. The last chapter concludes with the future of machine learning and predictive analysis and how they might be used for addressing the challenge of reacting faster to dynamic expectations of customers and their needs.
C1 [Satapathy, Suresh Chandra; Jena, Ajay Kumar; Singh, Jagannath; Bilgaiyan, Saurabh] Deemed Be Univ, Kalinga Inst Ind Technol KIIT, Sch Comp Engn, Bhubaneswar, Odisha, India.
RP Satapathy, SC (corresponding author), Deemed Be Univ, Kalinga Inst Ind Technol KIIT, Sch Comp Engn, Bhubaneswar, Odisha, India.
NR 32
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2662-3447
EI 2662-3455
BN 978-3-030-38006-9; 978-3-030-38005-2
J9 LEARN ANAL INTELL SY
PY 2020
VL 8
BP 39
EP 54
DI 10.1007/978-3-030-38006-9_3
D2 10.1007/978-3-030-38006-9
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
WE Book Citation Index – Science (BKCI-S)
SC Computer Science
GA BR8QW
UT WOS:000672768600004
DA 2022-04-17
ER

PT C
AU Magnini, B
   Lavelli, A
   Magnolini, S
AF Magnini, Bernardo
   Lavelli, Alberto
   Magnolini, Simone
BE Calzolari, N
   Bechet, F
   Blache, P
   Choukri, K
   Cieri, C
   Declerck, T
   Goggi, S
   Isahara, H
   Maegaard, B
   Mariani, J
   Mazo, H
   Moreno, A
   Odijk, J
   Piperidis, S
TI Comparing Machine Learning and Deep Learning Approaches on NLP Tasks for
   the Italian Language
SO PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES
   AND EVALUATION (LREC 2020)
LA English
DT Proceedings Paper
CT 12th International Conference on Language Resources and Evaluation
   (LREC)
CY MAY 11-16, 2020
CL Marseille, FRANCE
DE Machine Learning; Deep Learning; Italian Language
AB We present a comparison between deep learning and traditional machine learning methods for various NLP tasks in Italian. We carried on experiments using available datasets (e.g., from the Evalita shared tasks) on two sequence tagging tasks (i.e., named entity recognition and nominal entity recognition) and four classification tasks (i.e., lexical relations among words, semantic relations among sentences, sentiment analysis and text classification). We show that deep learning approaches outperform traditional machine learning algorithms in sequence tagging, while for classification tasks that heavily rely on semantics approaches based on feature engineering are still competitive. We think that a similar analysis could be carried out for other languages to provide an assessment of machine learning / deep learning models across different languages.
C1 [Magnini, Bernardo; Lavelli, Alberto; Magnolini, Simone] Fdn Bruno Kessler, Via Sommar 18, Povo, Italy.
RP Magnini, B (corresponding author), Fdn Bruno Kessler, Via Sommar 18, Povo, Italy.
EM magnini@fbk.eu; lavelli@fbk.eu; magnolini@fbk.eu
NR 40
TC 2
Z9 2
U1 0
U2 0
PU EUROPEAN LANGUAGE RESOURCES ASSOC-ELRA
PI PARIS
PA 55-57, RUE BRILLAT-SAVARIN, PARIS, 75013, FRANCE
BN 979-10-95546-34-4
PY 2020
BP 2110
EP 2119
PG 10
WC Computer Science, Interdisciplinary Applications; Linguistics; Language
   & Linguistics
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Linguistics
GA BS4ZZ
UT WOS:000724697203012
DA 2022-04-17
ER

PT J
AU Psihas, F
   Groh, M
   Tunnell, C
   Warburton, K
AF Psihas, Fernanda
   Groh, Micah
   Tunnell, Christopher
   Warburton, Karl
TI A review on machine learning for neutrino experiments
SO INTERNATIONAL JOURNAL OF MODERN PHYSICS A
LA English
DT Review
DE Neutrinos; machine learning; deep learning; review
AB Neutrino experiments study the least understood of the Standard Model particles by observing their direct interactions with matter or searching for ultra-rare signals. The study of neutrinos typically requires overcoming large backgrounds, elusive signals, and small statistics. The introduction of state-of-the-art machine learning tools to solve analysis tasks has made major impacts to these challenges in neutrino experiments across the board. Machine learning algorithms have become an integral tool of neutrino physics, and their development is of great importance to the capabilities of next generation experiments. An understanding of the roadblocks, both human and computational, and the challenges that still exist in the application of these techniques is critical to their proper and beneficial utilization for physics applications. This review presents the current status of machine learning applications for neutrino physics in terms of the challenges and opportunities that are at the intersection between these two fields.
C1 [Psihas, Fernanda] Fermilab Natl Accelerator Lab, Neutrino Div, POB 500, Batavia, IL 60510 USA.
   [Groh, Micah] Indiana Univ, Dept Phys, Bloomington, IN 47405 USA.
   [Tunnell, Christopher] Rice Univ, Dept Phys & Astron, Houston, TX USA.
   [Warburton, Karl] Iowa State Univ, Dept Phys & Astron, Ames, IA USA.
RP Psihas, F (corresponding author), Fermilab Natl Accelerator Lab, Neutrino Div, POB 500, Batavia, IL 60510 USA.
EM psihas@fnal.gov; mcgroh@iu.edu; tunnell@rice.edu; karlwarb@iastate.edu
OI Psihas, Fernanda/0000-0001-7393-4662
FU U.S. Department of Energy, Office of Science, Office of High Energy
   PhysicsUnited States Department of Energy (DOE) [DE-AC02-07CH11359]
FX The authors thank Justin Vasel for his helpful review of this
   manuscript. The authors would like to acknowledge Georgia Karagiorgi for
   productive conversations about the exciting directions of R&D for
   accelerated hardware as well as Taritree Wongjirad, Kazuhiro Terao, and
   Tingjun Yang for their useful insight of the challenges of LArTPC
   applications. Fermilab is operated by Fermi Research Alliance, LLC under
   Contract No. DE-AC02-07CH11359 with the U.S. Department of Energy,
   Office of Science, Office of High Energy Physics. The United States
   Government retains and the publisher, by accepting the article for
   publication, acknowledges that the United States Government retains a
   nonexclusive, paid-up, irrevocable, world-wide license to publish or
   reproduce the published form of this manuscript, or allow others to do
   so, for United States Government purposes.
NR 63
TC 2
Z9 2
U1 5
U2 6
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0217-751X
EI 1793-656X
J9 INT J MOD PHYS A
JI Int. J. Mod. Phys. A
PD NOV 30
PY 2020
VL 35
IS 33
AR 2043005
DI 10.1142/S0217751X20430058
PG 24
WC Physics, Nuclear; Physics, Particles & Fields
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Physics
GA PG6XM
UT WOS:000599876300003
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Raschka, S
   Patterson, J
   Nolet, C
AF Raschka, Sebastian
   Patterson, Joshua
   Nolet, Corey
TI Machine Learning in Python: Main Developments and Technology Trends in
   Data Science, Machine Learning, and Artificial Intelligence
SO INFORMATION
LA English
DT Review
DE Python; machine learning; deep learning; GPU computing; data science;
   neural networks
ID MODEL
AB Smarter applications are making better use of the insights gleaned from data, having an impact on every industry and research discipline. At the core of this revolution lies the tools and the methods that are driving it, from processing the massive piles of data generated each day to learning from and taking useful action. Deep neural networks, along with advancements in classical machine learning and scalable general-purpose graphics processing unit (GPU) computing, have become critical components of artificial intelligence, enabling many of these astounding breakthroughs and lowering the barrier to adoption. Python continues to be the most preferred language for scientific computing, data science, and machine learning, boosting both performance and productivity by enabling the use of low-level libraries and clean high-level APIs. This survey offers insight into the field of machine learning with Python, taking a tour through important topics to identify some of the core hardware and software paradigms that have enabled it. We cover widely-used libraries and concepts, collected together for holistic comparison, with the goal of educating the reader and driving the field of Python machine learning forward.
C1 [Raschka, Sebastian] Univ Wisconsin Madison, Dept Stat, Madison, WI 53575 USA.
   [Patterson, Joshua; Nolet, Corey] NVIDIA, Santa Clara, CA 95051 USA.
   [Nolet, Corey] Univ Maryland, Dept Comp Sci & Elect Engn, Baltimore, MD 21250 USA.
   [Raschka, Sebastian] 1300 Univ Ave,Med Sci Bldg, Madison, WI 53706 USA.
RP Raschka, S (corresponding author), Univ Wisconsin Madison, Dept Stat, Madison, WI 53575 USA.; Raschka, S (corresponding author), 1300 Univ Ave,Med Sci Bldg, Madison, WI 53706 USA.
EM sraschka@wisc.edu; joshuap@nvidia.com; cnolet@nvidia.com
OI Raschka, Sebastian/0000-0001-6989-4493
FU Office of the Vice Chancellor for Research and Graduate Education at the
   University of Wisconsin-Madison; Wisconsin Alumni Research Foundation
FX Support for this review article was provided by the Office of the Vice
   Chancellor for Research and Graduate Education at the University of
   Wisconsin-Madison with funding from the Wisconsin Alumni Research
   Foundation.
NR 232
TC 32
Z9 32
U1 17
U2 31
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2078-2489
J9 INFORMATION
JI Information
PD APR
PY 2020
VL 11
IS 4
AR 193
DI 10.3390/info11040193
PG 44
WC Computer Science, Information Systems
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA LO8YL
UT WOS:000533911600040
OA Green Submitted, gold
DA 2022-04-17
ER

PT J
AU Zhang, JM
   Harman, M
   Ma, L
   Liu, Y
AF Zhang, Jie M.
   Harman, Mark
   Ma, Lei
   Liu, Yang
TI Machine Learning Testing: Survey, Landscapes and Horizons
SO IEEE TRANSACTIONS ON SOFTWARE ENGINEERING
LA English
DT Article
DE Machine learning; software testing; deep neural network
ID COMPUTER-AIDED DIAGNOSIS; SYMBOLIC EXECUTION; SAMPLE-SIZE; CLASSIFIER;
   PERFORMANCE
AB This paper provides a comprehensive survey of techniques for testing machine learning systems; Machine Learning Testing (ML testing) research. It covers 144 papers on testing properties (e.g., correctness, robustness, and fairness), testing components (e.g., the data, learning program, and framework), testing workflow (e.g., test generation and test evaluation), and application scenarios (e.g., autonomous driving, machine translation). The paper also analyses trends concerning datasets, research trends, and research focus, concluding with research challenges and promising research directions in ML testing.
C1 [Zhang, Jie M.] UCL, CREST, London WC1E 6BT, England.
   [Harman, Mark] Facebook, London W1T 1FB, England.
   [Ma, Lei] Kyushu Univ, Fukuoka 8190395, Japan.
   [Liu, Yang] Nanyang Technol Univ, Singapore 639798, Singapore.
RP Zhang, JM (corresponding author), UCL, CREST, London WC1E 6BT, England.
EM jie.zhang@ucl.ac.uk; mark.harman@ucl.ac.uk; malei@ait.kyushu-u.ac.jp;
   yangliu@ntu.edu.sg
RI M, SUDHA RANI/AAZ-2068-2021; Liu, Yang/D-2306-2013
OI M, SUDHA RANI/0000-0002-8491-0508; Liu, Yang/0000-0001-7300-9215
FU ERCEuropean Research Council (ERC)European Commission [741278]; JSPS
   KAKENHIMinistry of Education, Culture, Sports, Science and Technology,
   Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for
   Scientific Research (KAKENHI) [19K24348, 19H04086]; Qdaijump Research
   Program [01277]; NVIDIA AI Tech Center (NVAITC); Singapore National
   Research FoundationNational Research Foundation, Singapore
   [NRF2018NCRNCR005-0001]; National Satellite of Excellence in Trustworthy
   Software System [NRF2018NCR-NSOE003-0001]; NTU research grant
   [NGF-2019-06-024]
FX Jie M. Zhang and Mark Harman was supported by the ERC advanced grant
   with No. 741278. Lei Ma was supported by the JSPS KAKENHI Grant
   no.19K24348, 19H04086, Qdaijump Research Program No.01277, and NVIDIA AI
   Tech Center (NVAITC). Yang Liu was supported by Singapore National
   Research Foundation with No. NRF2018NCRNCR005-0001, National Satellite
   of Excellence in Trustworthy Software System No.
   NRF2018NCR-NSOE003-0001, NTU research grant NGF-2019-06-024. Before
   submitting, we sent the paper to those whom we cited, to check our
   comments for accuracy and omission. This also provided one final stage
   in the systematic trawling of the literature for relevant work. Many
   thanks to those members of the community who kindly provided comments
   and feedback on earlier drafts of this paper.
NR 287
TC 54
Z9 54
U1 9
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0098-5589
EI 1939-3520
J9 IEEE T SOFTWARE ENG
JI IEEE Trans. Softw. Eng.
PD JAN 1
PY 2022
VL 48
IS 1
BP 1
EP 36
DI 10.1109/TSE.2019.2962027
PG 36
WC Computer Science, Software Engineering; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YG0HJ
UT WOS:000742179000001
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Liu, ZC
   Zhu, DY
   Raju, L
   Cai, WS
AF Liu, Zhaocheng
   Zhu, Dayu
   Raju, Lakshmi
   Cai, Wenshan
TI Tackling Photonic Inverse Design with Machine Learning
SO ADVANCED SCIENCE
LA English
DT Review
DE inverse design; machine learning; nanophotonics; neural networks
ID SPLIT-RING RESONATOR; SHAPE OPTIMIZATION; SILICON PHOTONICS;
   NEURAL-NETWORKS; DEEP; METASURFACES; REFLECTION; PREDICTION; FRAMEWORK;
   CRYSTALS
AB Machine learning, as a study of algorithms that automate prediction and decision-making based on complex data, has become one of the most effective tools in the study of artificial intelligence. In recent years, scientific communities have been gradually merging data-driven approaches with research, enabling dramatic progress in revealing underlying mechanisms, predicting essential properties, and discovering unconventional phenomena. It is becoming an indispensable tool in the fields of, for instance, quantum physics, organic chemistry, and medical imaging. Very recently, machine learning has been adopted in the research of photonics and optics as an alternative approach to address the inverse design problem. In this report, the fast advances of machine-learning-enabled photonic design strategies in the past few years are summarized. In particular, deep learning methods, a subset of machine learning algorithms, dealing with intractable high degrees-of-freedom structure design are focused upon.
C1 [Liu, Zhaocheng; Zhu, Dayu; Raju, Lakshmi; Cai, Wenshan] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
   [Cai, Wenshan] Georgia Inst Technol, Sch Mat Sci & Engn, Atlanta, GA 30332 USA.
RP Liu, ZC; Cai, WS (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.; Cai, WS (corresponding author), Georgia Inst Technol, Sch Mat Sci & Engn, Atlanta, GA 30332 USA.
EM zcliu@gatech.edu; wcai@gatech.edu
RI Liu, Zhaocheng/T-8674-2019
OI Liu, Zhaocheng/0000-0001-6623-9231
FU Office of Naval ResearchOffice of Naval Research [N00014-17-1-2555];
   National Science FoundationNational Science Foundation (NSF)
   [DMR-2004749]; National Science Foundation Graduate Research
   FellowshipNational Science Foundation (NSF) [DGE-1650044]
FX This work was funded by the Office of Naval Research under Grant No.
   N00014-17-1-2555, and by the National Science Foundation under Grant No.
   DMR-2004749. L.R. was supported in part by the National Science
   Foundation Graduate Research Fellowship under Grant DGE-1650044.
NR 127
TC 17
Z9 17
U1 40
U2 72
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
EI 2198-3844
J9 ADV SCI
JI Adv. Sci.
PD MAR
PY 2021
VL 8
IS 5
AR 2002923
DI 10.1002/advs.202002923
EA JAN 2021
PG 15
WC Chemistry, Multidisciplinary; Nanoscience & Nanotechnology; Materials
   Science, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Science & Technology - Other Topics; Materials Science
GA QS7SK
UT WOS:000605576700001
PM 33717846
OA gold, Green Published
DA 2022-04-17
ER

PT C
AU Chen, SC
   Putra, DS
AF Chen, Seng-Chi
   Putra, Dwi Sudarno
BE Meen, TH
TI Machine Learning Implementation on BLDCM Commutation
SO PROCEEDINGS OF THE 2ND IEEE EURASIA CONFERENCE ON BIOMEDICAL
   ENGINEERING, HEALTHCARE AND SUSTAINABILITY 2020 (IEEE ECBIOS 2020):
   BIOMEDICAL ENGINEERING, HEALTHCARE AND SUSTAINABILITY
LA English
DT Proceedings Paper
CT 2nd IEEE Eurasia Conference on Biomedical Engineering, Healthcare and
   Sustainability (IEEE ECBIOS) - Biomedical Engineering, Healthcare and
   Sustainability
CY MAY 29-31, 2020
CL Tainan, TAIWAN
SP Inst Elect & Elect Engineers, Chia Nan Univ Pharm & Sci, Int Inst Knowledge Innovat & Invent
DE machine learning; BLDC commutation; six-step control and hardware
   implementation
AB One way to do the commutation process at BLDCM is the six-step method. And hardware implementation for this method can be done in various ways. This paper will try to run a BLDCM commutation process using machine learning. Machine learning is an artificial intelligence method that can respond based on the learning process that was carried out previously through existing data sets. In this study, the training process is done offline. Then the "weight" obtained from the training is used in the Machine Learning structure which is implemented on the F28069M microcontroller. From the hardware implementation, it is proven that Machine Learning can be used in the BLDC motor commutation process.
C1 [Chen, Seng-Chi; Putra, Dwi Sudarno] Southern Taiwan Univ Sci & Technol, Dept Elect Engn, 1 Nan Tai St, Tainan 71005, Taiwan.
RP Chen, SC (corresponding author), Southern Taiwan Univ Sci & Technol, Dept Elect Engn, 1 Nan Tai St, Tainan 71005, Taiwan.
EM amtfcsg123@mail.stust.edu.tw; dwisudarnoputra@ft.unp.ac.id
RI Putra, Dwi Sudarno/AAS-1067-2021
NR 8
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-8712-9
PY 2020
BP 154
EP 157
PG 4
WC Computer Science, Artificial Intelligence; Engineering, Biomedical;
   Engineering, Environmental
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BR1ZZ
UT WOS:000636949400043
DA 2022-04-17
ER

PT J
AU Roy, S
   Rana, D
AF Roy, Sayan
   Rana, Debanjan
TI Machine Learning in Nonlinear Dynamical Systems
SO RESONANCE-JOURNAL OF SCIENCE EDUCATION
LA English
DT Article
DE Nonlinear dynamical systems; machine learning; dynamical modelling
AB In this article, we discuss some of the recent developments in applying machine learning (ML) techniques to nonlinear dynamical systems. In particular, we demonstrate how to build a suitable ML framework for addressing two specific objectives of relevance: prediction of future evolution of a system and unveiling from given time-series data the analytical form of the underlying dynamics. This article is written in a pedagogical style appropriate for a course in nonlinear dynamics or machine learning.
C1 [Roy, Sayan] IISER Bhopal, Dept Phys, Bhopal, India.
   [Rana, Debanjan] IISER Bhopal, Dept Chem, Bhopal, India.
RP Roy, S (corresponding author), Dept Phys, Bhopal Bypass Rd, Bhauri 462066, Madhya Pradesh, India.; Rana, D (corresponding author), Dept Chem, Bhopal Bypass Rd, Bhauri 462066, Madhya Pradesh, India.
EM sayanr16@iiserbac.in; debanjan16@iiserb.ac.in
NR 11
TC 0
Z9 0
U1 4
U2 5
PU SPRINGER INDIA
PI NEW DELHI
PA 7TH FLOOR, VIJAYA BUILDING, 17, BARAKHAMBA ROAD, NEW DELHI, 110 001,
   INDIA
SN 0971-8044
EI 0973-712X
J9 RESONANCE
JI Resonance
PD JUL
PY 2021
VL 26
IS 7
BP 953
EP 970
DI 10.1007/s12045-021-1194-0
PG 18
WC Education, Scientific Disciplines
WE Emerging Sources Citation Index (ESCI)
SC Education & Educational Research
GA TS6XG
UT WOS:000679789700007
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Sagar, S
   Keke, C
AF Sagar, Sharma
   Keke, Chen
TI Confidential machine learning on untrusted platforms: a survey
SO CYBERSECURITY
LA English
DT Article
DE Confidential computing; Cryptographic protocols; Machine learning
ID PRIVACY; ALGORITHMS; SIMULATION; CLOUD
AB With the ever-growing data and the need for developing powerful machine learning models, data owners increasingly depend on various untrusted platforms (e.g., public clouds, edges, and machine learning service providers) for scalable processing or collaborative learning. Thus, sensitive data and models are in danger of unauthorized access, misuse, and privacy compromises. A relatively new body of research confidentially trains machine learning models on protected data to address these concerns. In this survey, we summarize notable studies in this emerging area of research. With a unified framework, we highlight the critical challenges and innovations in outsourcing machine learning confidentially. We focus on the cryptographic approaches for confidential machine learning (CML), primarily on model training, while also covering other directions such as perturbation-based approaches and CML in the hardware-assisted computing environment. The discussion will take a holistic way to consider a rich context of the related threat models, security assumptions, design principles, and associated trade-offs amongst data utility, cost, and confidentiality.
C1 [Sagar, Sharma; Keke, Chen] Marquette Univ, Northwestern Mutual Data Sci, Dept Comp Sci, Milwaukee, WI 53233 USA.
   [Sagar, Sharma; Keke, Chen] Marquette Univ, Trustworthy & Intelligent Comp Lab, Dept Comp Sci, Milwaukee, WI 53233 USA.
   [Sagar, Sharma] HP Inc, Palo Alto, CA USA.
RP Keke, C (corresponding author), Marquette Univ, Northwestern Mutual Data Sci, Dept Comp Sci, Milwaukee, WI 53233 USA.; Keke, C (corresponding author), Marquette Univ, Trustworthy & Intelligent Comp Lab, Dept Comp Sci, Milwaukee, WI 53233 USA.
EM keke.chen@marquette.edu
FU National Science FoundationNational Science Foundation (NSF) [1245847];
   National Institute of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [1R43AI136357-01A1]
FX This work is partially supported by the National Science Foundation
   under grant no. 1245847 and the National Institute of Health under grant
   no. 1R43AI136357-01A1.
NR 103
TC 1
Z9 1
U1 1
U2 1
PU SPRINGERNATURE
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND
EI 2523-3246
J9 CYBERSECURITY
JI Cybersecurity
PD SEP 1
PY 2021
VL 4
IS 1
AR 30
DI 10.1186/s42400-021-00092-8
PG 19
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA UL0WR
UT WOS:000692382100001
PM 34805760
OA Green Published, gold, Green Submitted
DA 2022-04-17
ER

PT J
AU Namkung, J
AF Namkung, Junghyun
TI Machine learning methods for microbiome studies
SO JOURNAL OF MICROBIOLOGY
LA English
DT Article
DE machine learning; microbiome; supervised; unsupervised; deep learning;
   semi-supervised
ID AUTISM SPECTRUM DISORDER; GUT MICROBIOTA; MULTIPLE IMPUTATION; OBESITY;
   CLASSIFICATION; ASSOCIATION; COMMUNITIES; COMPLEX; TOOLS
AB Researches on the microbiome have been actively conducted worldwide and the results have shown human gut bacterial environment significantly impacts on immune system, psychological conditions, cancers, obesity, and metabolic diseases. Thanks to the development of sequencing technology, microbiome studies with large number of samples are eligible on an acceptable cost nowadays. Large samples allow analysis of more sophisticated modeling using machine learning approaches to study relationships between microbiome and various traits. This article provides an overview of machine learning methods for non-data scientists interested in the association analysis of microbiomes and host phenotypes. Once genomic feature of microbiome is determined, various analysis methods can be used to explore the relationship between microbiome and host phenotypes that include penalized regression, support vector machine (SVM), random forest, and artificial neural network (ANN). Deep neural network methods are also touched. Analysis procedure from environment setup to extract analysis results are presented with Python programming language.
C1 [Namkung, Junghyun] SK Telecom, Data Analyt CoE, Data R&D Ctr, Seoul 04539, South Korea.
RP Namkung, J (corresponding author), SK Telecom, Data Analyt CoE, Data R&D Ctr, Seoul 04539, South Korea.
EM jh.namkung@gmail.com
RI namkung, junghyun/AAM-6647-2020
NR 60
TC 19
Z9 20
U1 9
U2 52
PU MICROBIOLOGICAL  SOCIETY KOREA
PI SEOUL
PA KOREA SCIENCE & TECHNOLOGY CENTER 803, 635-4 YEOGSAM-DONG, KANGNAM-KU,
   SEOUL 135-703, SOUTH KOREA
SN 1225-8873
EI 1976-3794
J9 J MICROBIOL
JI J. Microbiol.
PD MAR
PY 2020
VL 58
IS 3
BP 206
EP 216
DI 10.1007/s12275-020-0066-8
PG 11
WC Microbiology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Microbiology
GA KU0GB
UT WOS:000519389300004
PM 32108316
DA 2022-04-17
ER

PT J
AU Mishra, A
   Reddy, US
AF Mishra, Abinash
   Reddy, U. Srinivasulu
TI Machine learning approach for wart treatment selection: prominence on
   performance assessment
SO NETWORK MODELING AND ANALYSIS IN HEALTH INFORMATICS AND BIOINFORMATICS
LA English
DT Article
DE Machine learning; Warts; Cryotherapy; Immunotherapy; Fuzzy rough set;
   Feature selection
ID CLASSIFICATION; PREDICTION; ALGORITHM; FRAMEWORK; SYSTEM
AB Warts are benign tumors, caused by human papillomavirus (HPV). The present study mainly emphasis on the selection of suitable methods for the removal of a common and plantar wart. There are numerous wart treatment methods for this disease, among them cryotherapy and immunotherapy are well-known approaches. Identifying the suitable wart treatment method manually is quite challenging. Moreover, existing machine learning (ML) techniques show a poor prediction accuracy towards the selection of wart treatment method, however, the prediction accuracy is not satisfactory and can be further improved. To achieve the same, the current study utilizes the advantage of fuzzy rough set based feature selection (FRFS) to generate the most optimal informative feature space, which in turn makes the ML algorithms more accurate and leads to a better prognosis. The proposed FRFS based Naive Bayes and FRFS based CART models outperform from the existing model in terms of prediction accuracy.
C1 [Mishra, Abinash; Reddy, U. Srinivasulu] Natl Inst Technol, Dept Comp Applicat, Machine Learning & Data Analyt Lab, Tiruchirappalli 620015, India.
RP Reddy, US (corresponding author), Natl Inst Technol, Dept Comp Applicat, Machine Learning & Data Analyt Lab, Tiruchirappalli 620015, India.
EM usreddy@nitt.edu
RI Uyyala, Srinivasulu Reddy/AAD-4228-2020
OI Uyyala, Srinivasulu Reddy/0000-0002-6478-3839; MISHRA,
   ABINASH/0000-0002-2212-9599
FU Ministry of Human Resource and Development [405117002]
FX We would like to thank the Ministry of Human Resource and Development
   (Grant number 405117002) for providing financial support. We express our
   sincere thanks to the machine learning and data analytics lab, National
   Institute of Technology, Tiruchirappalli, for providing the
   infrastructure facility.
NR 27
TC 2
Z9 2
U1 0
U2 4
PU SPRINGERNATURE
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND
SN 2192-6662
EI 2192-6670
J9 NETW MODEL ANAL HLTH
JI Netw. Model. Anal. Health
PD JUN 3
PY 2020
VL 9
IS 1
AR 37
DI 10.1007/s13721-020-00246-7
PG 14
WC Mathematical & Computational Biology
WE Emerging Sources Citation Index (ESCI)
SC Mathematical & Computational Biology
GA LU4MT
UT WOS:000537731800001
DA 2022-04-17
ER

PT J
AU Webb, ME
   Fluck, A
   Magenheim, J
   Malyn-Smith, J
   Waters, J
   Deschenes, M
   Zagami, J
AF Webb, Mary E.
   Fluck, Andrew
   Magenheim, Johannes
   Malyn-Smith, Joyce
   Waters, Juliet
   Deschenes, Michelle
   Zagami, Jason
TI Machine learning for human learners: opportunities, issues, tensions and
   threats
SO ETR&D-EDUCATIONAL TECHNOLOGY RESEARCH AND DEVELOPMENT
LA English
DT Article
DE Machine learning; Human learning; Deep learning; Explainability;
   Accountability
ID NEURAL-NETWORKS; DEEP
AB Machine learning systems are infiltrating our lives and are beginning to become important in our education systems. This article, developed from a synthesis and analysis of previous research, examines the implications of recent developments in machine learning for human learners and learning. In this article we first compare deep learning in computers and humans to examine their similarities and differences. Deep learning is identified as a sub-set of machine learning, which is itself a component of artificial intelligence. Deep learning often depends on backwards propagation in weighted neural networks, so is non-deterministic-the system adapts and changes through practical experience or training. This adaptive behaviour predicates the need for explainability and accountability in such systems. Accountability is the reverse of explainability. Explainability flows through the system from inputs to output (decision) whereas accountability flows backwards, from a decision to the person taking responsibility for it. Both explainability and accountability should be incorporated in machine learning system design from the outset to meet social, ethical and legislative requirements. For students to be able to understand the nature of the systems that may be supporting their own learning as well as to act as responsible citizens in contemplating the ethical issues that machine learning raises, they need to understand key aspects of machine learning systems and have opportunities to adapt and create such systems. Therefore, some changes are needed to school curricula. The article concludes with recommendations about machine learning for teachers, students, policymakers, developers and researchers.
C1 [Webb, Mary E.] Kings Coll London, Sch Educ Commun & Soc, IT & Educ, Franklin Wilkins Bldg,Waterloo Bridge Wing, London SE1 9NN, England.
   [Fluck, Andrew] Univ Tasmania, Launceston, Tas, Australia.
   [Magenheim, Johannes] Univ Paderborn, Paderborn, Germany.
   [Malyn-Smith, Joyce] Educ Dev Ctr EDC, Waltham, MA USA.
   [Waters, Juliet] Kids Code Jeunesse, Montreal, PQ, Canada.
   [Deschenes, Michelle] Laval Univ, Quebec City, PQ, Canada.
   [Zagami, Jason] Griffith Univ, Gold Coast, Australia.
RP Webb, ME (corresponding author), Kings Coll London, Sch Educ Commun & Soc, IT & Educ, Franklin Wilkins Bldg,Waterloo Bridge Wing, London SE1 9NN, England.
EM mary.webb@kcl.ac.uk
OI Webb, Mary/0000-0002-4409-5940; Deschenes, Michelle/0000-0002-8804-5160
NR 67
TC 5
Z9 5
U1 17
U2 32
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1042-1629
EI 1556-6501
J9 ETR&D-EDUC TECH RES
JI ETR&D-Educ. Tech. Res. Dev.
PD AUG
PY 2021
VL 69
IS 4
SI SI
BP 2109
EP 2130
DI 10.1007/s11423-020-09858-2
EA NOV 2020
PG 22
WC Education & Educational Research
WE Social Science Citation Index (SSCI)
SC Education & Educational Research
GA UR1XK
UT WOS:000590917300001
OA Green Published, hybrid, Green Accepted
DA 2022-04-17
ER

PT J
AU Gimenez, NL
   Grau, MM
   Centelles, RP
   Freitag, F
AF Llisterri Gimenez, Nil
   Monfort Grau, Marc
   Pueyo Centelles, Roger
   Freitag, Felix
TI On-Device Training of Machine Learning Models on Microcontrollers with
   Federated Learning
SO ELECTRONICS
LA English
DT Article
DE machine learning; keyword spotting; embedded systems; federated learning
AB Recent progress in machine learning frameworks has made it possible to now perform inference with models using cheap, tiny microcontrollers. Training of machine learning models for these tiny devices, however, is typically done separately on powerful computers. This way, the training process has abundant CPU and memory resources to process large stored datasets. In this work, we explore a different approach: training the machine learning model directly on the microcontroller and extending the training process with federated learning. We implement this approach for a keyword spotting task. We conduct experiments with real devices to characterize the learning behavior and resource consumption for different hyperparameters and federated learning configurations. We observed that in the case of training locally with fewer data, more frequent federated learning rounds more quickly reduced the training loss but involved a cost of higher bandwidth usage and longer training time. Our results indicate that, depending on the specific application, there is a need to determine the trade-off between the requirements and the resource usage of the system.
C1 [Llisterri Gimenez, Nil; Monfort Grau, Marc; Pueyo Centelles, Roger; Freitag, Felix] Univ Politecn Catalunya UPC, Dept Arquitectura Comp, Barcelona 08034, Spain.
RP Freitag, F (corresponding author), Univ Politecn Catalunya UPC, Dept Arquitectura Comp, Barcelona 08034, Spain.
EM nil.llisterri@estudiantat.upc.edu; marc.monfort@upc.edu;
   roger.pueyo@upc.edu; felix.freitag@upc.edu
OI Pueyo Centelles, Roger/0000-0002-3133-0657
FU Spanish GovernmentSpanish GovernmentEuropean Commission
   [PID2019-106774RB-C21, PCI2019-111851-2, PCI2019-111850-2];  [DiPET
   CHIST-ERA]
FX This work has received funding from the Spanish Government under
   contracts PID2019-106774RB-C21, PCI2019-111851-2 (LeadingEdge
   CHIST-ERA), PCI2019-111850-2 (DiPET CHIST-ERA).
NR 20
TC 0
Z9 0
U1 1
U2 1
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2079-9292
J9 ELECTRONICS-SWITZ
JI Electronics
PD FEB
PY 2022
VL 11
IS 4
AR 573
DI 10.3390/electronics11040573
PG 15
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Physics
GA ZL4HP
UT WOS:000763639500001
OA gold
DA 2022-04-17
ER

PT J
AU Aslam, SM
   Jilani, AK
   Sultana, J
   Almutairi, L
AF Aslam, Shabnam Mohamed
   Jilani, Abdul Khader
   Sultana, Jabeen
   Almutairi, Laila
TI Feature Evaluation of Emerging E-Learning Systems Using Machine
   Learning: An Extensive Survey
SO IEEE ACCESS
LA English
DT Article
DE Electronic learning; Hidden Markov models; Machine learning;
   Classification algorithms; Support vector machines; Data models;
   Clustering algorithms; Machine learning survey; ML techniques;
   e-learning; evaluation
ID PERFORMANCE PREDICTION; STUDENTS PERFORMANCE; NETWORKS; RECOGNITION;
   STRATEGIES; MODEL
AB As of late, with the progression of AI and man-made brainpower, there has been a developing spotlight on versatile e-learning. As all ways to deal with e-learning lose their allure and the level of online courses builds, they move towards more customized versatile learning so as to collaborate with students and achieve better learning results. The schools focus on the examination, mindfulness, and arranging techniques that infuse innovation into the vision and educational program. E-learning issues are a standard examination issue for us all. The motivation behind this research analysis is to separate the potential outcomes of assessing e-learning models utilizing AI strategies such as Supervised, Semi Supervised, Reinforced Learning advances by investigating upsides and downsides of various methods organization. The literature review methodology is to review the cross sectional impacts of e-learning and Machine learning algorithms from existing literatures from the year 1993 to 2020 and to assess the essentialness of e-learning features to optimize the e-learning models with available Machine learning techniques from peer-inspected journals, capable destinations, and books. Second, it legitimizes the chances of e-learning structures introduction, and changes demonstrated through AI and Machine Learning algorithms. This examination assists in providing helpful new highlights to analysts, researchers and academicians. It gives an exhaustive structure of existing e-learning frameworks for the most recent innovations identified with learning framework capacities and learning tasks to envision ML research openings in appropriate spaces. The survey paper identifies and demonstrates the important role of different types of e-learning features such as Individual pertinent feature, Course pertinent feature, Context pertinent feature and Technology pertinent feature in framework performance tuning. The performance of Machine Learning algorithms to optimize the features of E-Learning models were reviewed in previous literatures and Support Vector Machine technique was found to be the one of the best to predict the input and output parameters of e-learning models and it is found that Fuzzy C Means, Deep Learning algorithms are producing better results for Big Data sets.
C1 [Aslam, Shabnam Mohamed] Majmaah Univ, Dept Informat Technol, Coll Comp & Informat Sci, Al Majmaah 11952, Saudi Arabia.
   [Jilani, Abdul Khader] Majmaah Univ, Dept Comp Sci, Coll Comp & Informat Sci, Al Majmaah 11952, Saudi Arabia.
   [Sultana, Jabeen; Almutairi, Laila] Majmaah Univ, Dept Comp Engn, Coll Comp & Informat Sci, Al Majmaah 11952, Saudi Arabia.
RP Aslam, SM (corresponding author), Majmaah Univ, Dept Informat Technol, Coll Comp & Informat Sci, Al Majmaah 11952, Saudi Arabia.
EM s.aslam@mu.edu.sa
OI Aslam, Shabnam/0000-0001-9015-7551; Sultana, Jabeen/0000-0001-7214-0035
FU Majmaah University's Deanship of Scientic Research [1439-58]
FX The work of Shabnam Mohamed Aslam and Abdul Khader Jilani was supported
   by the Majmaah University's Deanship of Scienti~c Research under Project
   1439-58.
NR 111
TC 3
Z9 3
U1 10
U2 18
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 69573
EP 69587
DI 10.1109/ACCESS.2021.3077663
PG 15
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Telecommunications
GA SC1OX
UT WOS:000650450900001
OA gold
DA 2022-04-17
ER

PT C
AU Lundgard, A
AF Lundgard, Alan
GP Assoc Comp Machinery
TI Measuring Justice in Machine Learning
SO FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS,
   ACCOUNTABILITY, AND TRANSPARENCY
LA English
DT Proceedings Paper
CT ACM Conference on Fairness, Accountability, and Transparency (FAT)
CY JAN 27-30, 2020
CL Barcelona, SPAIN
SP Assoc Comp Machinery
DE Justice; machine learning; philosophy; operationalization; disability;
   distributive justice; capability; measure; fairness; bias;
   discrimination
AB How can we build more just machine learning systems? To answer this question, we need to know both what justice is and how to tell whether one system is more or less just than another. That is, we need both a definition and a measure of justice. Theories of distributive justice hold that justice can be measured (in part) in terms of the fair distribution of benefits and burdens across people in society. Recently, the field known as fair machine learning has turned to John Rawls's theory of distributive justice for inspiration and operationalization. However, philosophers known as capability theorists have long argued that Rawls's theory uses the wrong measure of justice, thereby encoding biases against people with disabilities. If these theorists are right, is it possible to operationalize Rawls's theory in machine learning systems without also encoding its biases? In this paper, I draw on examples from fair machine learning to suggest that the answer to this question is no: the capability theorists' arguments against Rawls's theory carry over into machine learning systems. But capability theorists don't only argue that Rawls's theory uses the wrong measure, they also offer an alternative measure. Which measure of justice is right? And has fair machine learning been using the wrong one?
C1 [Lundgard, Alan] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
RP Lundgard, A (corresponding author), MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
EM lundgard@mit.edu
NR 0
TC 1
Z9 1
U1 1
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6936-7
PY 2020
BP 680
EP 680
DI 10.1145/3351095.3372838
PG 1
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Ethics
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Social Sciences - Other Topics
GA BQ8FJ
UT WOS:000620151400004
OA Green Submitted, Green Published
DA 2022-04-17
ER

PT J
AU Yu, Y
   Wang, RB
   Teo, RD
AF Yu, Yue
   Wang, Ruobing
   Teo, Ruijie D.
TI Machine Learning Approaches for Metalloproteins
SO MOLECULES
LA English
DT Article
DE metalloproteins; metalloenzymes; machine learning; deep learning;
   protein structure; protein function; protein stability; inhibitor
   design; cleavage sites
ID METAL-BINDING SITES; PROTEINS; PREDICTION; DESIGN; IDENTIFICATION;
   ENZYMES; MODEL; IONS; TOOL
AB Metalloproteins are a family of proteins characterized by metal ion binding, whereby the presence of these ions confers key catalytic and ligand-binding properties. Due to their ubiquity among biological systems, researchers have made immense efforts to predict the structural and functional roles of metalloproteins. Ultimately, having a comprehensive understanding of metalloproteins will lead to tangible applications, such as designing potent inhibitors in drug discovery. Recently, there has been an acceleration in the number of studies applying machine learning to predict metalloprotein properties, primarily driven by the advent of more sophisticated machine learning algorithms. This review covers how machine learning tools have consolidated and expanded our comprehension of various aspects of metalloproteins (structure, function, stability, ligand-binding interactions, and inhibitors). Future avenues of exploration are also discussed.
C1 [Yu, Yue] Duke Kunshan Univ, Div Nat & Appl Sci, Kunshan 215316, Jiangsu, Peoples R China.
   [Yu, Yue] Duke Univ, Dept Phys, Durham, NC 27708 USA.
   [Wang, Ruobing; Teo, Ruijie D.] Duke Univ, Dept Chem, Durham, NC 27708 USA.
   [Teo, Ruijie D.] Univ N Carolina, UNC Eshelman Sch Pharm, Chapel Hill, NC 27599 USA.
RP Teo, RD (corresponding author), Duke Univ, Dept Chem, Durham, NC 27708 USA.; Teo, RD (corresponding author), Univ N Carolina, UNC Eshelman Sch Pharm, Chapel Hill, NC 27599 USA.
EM yy241@duke.edu; ruobing.wang@duke.edu; rjteo@unc.edu
RI Teo, Ruijie Darius/J-6044-2014
OI Teo, Ruijie Darius/0000-0003-2203-9662
NR 73
TC 0
Z9 0
U1 4
U2 4
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1420-3049
J9 MOLECULES
JI Molecules
PD FEB
PY 2022
VL 27
IS 4
AR 1277
DI 10.3390/molecules27041277
PG 14
WC Biochemistry & Molecular Biology; Chemistry, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Chemistry
GA ZM4AK
UT WOS:000764302200001
PM 35209064
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Kayhan, V
AF Kayhan, Varol
TI When to Use Machine Learning: A Course Assignment
SO COMMUNICATIONS OF THE ASSOCIATION FOR INFORMATION SYSTEMS
LA English
DT Article
DE Machine Learning; Course Assignment
AB The number of institutions that offer machine learning courses continues to increase. However, supplementary materials that help instructors teach these courses fail to address an important step in the machine learning process; that is, conceptualizing a problem using a valid input-output relationship. To address this issue, I first review frameworks in extant work before proposing a decision flow. After discussing steps in the decision flow, I present a course assignment that reinforces the concepts in the decision flow. I conclude by discussing the lessons learned after using this assignment in a graduate course at a university in the United States.
C1 [Kayhan, Varol] Univ S Florida, Sch Informat Syst & Management, Tampa, FL 33620 USA.
RP Kayhan, V (corresponding author), Univ S Florida, Sch Informat Syst & Management, Tampa, FL 33620 USA.
EM vkayhan@usf.edu
NR 40
TC 0
Z9 0
U1 0
U2 0
PU ASSOC INFORMATION SYSTEMS
PI ATLANTA
PA GEORGIA STATE UNIV, 35 BROAD STREET, STE 916-917, ATLANTA, GA 30303 USA
SN 1529-3181
J9 COMMUN ASSOC INF SYS
JI Commun. Assoc. Inf. Syst.
PY 2022
VL 50
BP 122
EP 142
DI 10.17705/1CAIS.05005
PG 22
WC Computer Science, Information Systems
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA ZU9EW
UT WOS:000770142300005
DA 2022-04-17
ER

PT C
AU Kianpour, M
   Wen, SF
AF Kianpour, Mazaher
   Wen, Shao-Fang
BE Bi, Y
   Bhatia, R
   Kapoor, S
TI Timing Attacks on Machine Learning: State of the Art
SO INTELLIGENT SYSTEMS AND APPLICATIONS, VOL 1
SE Advances in Intelligent Systems and Computing
LA English
DT Proceedings Paper
CT Intelligent Systems Conference (IntelliSys)
CY SEP 05-06, 2019
CL London, ENGLAND
DE Adversarial machine learning; Timing attacks; Manipulation; Learning
   models
ID SECURITY; ROBUST
AB Machine learning plays a significant role in today's business sectors and governments, in which it is becoming more utilized as tools to help in decision making and automation process. However, these tools are not inherently robust and secure, and could be vulnerable to adversarial modification and cause false classification or risk in the system security. As such, the field of adversarial machine learning has emerged to study vulnerabilities of machine learning models and algorithms, and make them secure against adversarial manipulation. In this paper, we present the recently proposed taxonomy for attacks on machine learning and draw distinctions between other taxonomies. Moreover, this paper brings together the state of the art in theory and practice needed for decision timing attacks on machine learning and defense strategies against them. Considering the increasing research interest in this field, we hope this study provides readers with the essential knowledge to successfully engage in research and practice of machine learning in adversarial environment.
C1 [Kianpour, Mazaher; Wen, Shao-Fang] Norwegian Univ Sci & Technol, Gjovik, Norway.
RP Kianpour, M (corresponding author), Norwegian Univ Sci & Technol, Gjovik, Norway.
EM mazaher.kianpour@ntnu.no; shao-fang.wen@ntnu.no
OI Kianpour, Mazaher/0000-0003-2804-4630
NR 33
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2194-5357
EI 2194-5365
BN 978-3-030-29516-5; 978-3-030-29515-8
J9 ADV INTELL SYST COMP
PY 2020
VL 1037
BP 111
EP 125
DI 10.1007/978-3-030-29516-5_10
PG 15
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR2DE
UT WOS:000637312900010
DA 2022-04-17
ER

PT J
AU Ri, J
   Kim, H
AF Ri, JongHyok
   Kim, Hun
TI G-mean based extreme learning machine for imbalance learning
SO DIGITAL SIGNAL PROCESSING
LA English
DT Article
DE Extreme learning machine; Imbalance learning; Optimization; G-mean
ID ALGORITHM
AB Although extreme learning machine (ELM) provides better generalization performance at a much faster learning speed than traditional learning algorithms, the classical ELM can not obtain ideal results for the imbalanced data problem. In this paper, in order to conquer the learning capability of the classical ELM for an imbalance data learning, we define a new cost function of ELM optimization problem based on G-mean widely used as evaluation metric in imbalance data learning. We perform experiments on standard classification datasets which consist of 58 binary datasets and 11 multi-class datasets with the different degrees of the imbalance ratio. Experimental results show that proposed algorithm can improve the classification performance significantly compared with other state-of-the-art methods. We also demonstrate that our proposed algorithm can achieve high accuracy in representation learning by performing experiments on YouTube-8M with feature representation from convolutional neural networks. Statistical results indicate that the proposed approach not only outperforms the classical ELM, but also yields better or at least competitive results compared with several state-of-the-art class imbalance learning approaches. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Ri, JongHyok] Kim Il Sung Univ, Inst Informat Technol, Pyongyang, North Korea.
   [Kim, Hun] Kim Il Sung Univ, Sch Informat Sci, Pyongyang, North Korea.
RP Ri, J (corresponding author), Kim Il Sung Univ, Inst Informat Technol, Pyongyang, North Korea.
EM tech2@ryongnamsan.edu.kp
NR 37
TC 8
Z9 9
U1 3
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1051-2004
EI 1095-4333
J9 DIGIT SIGNAL PROCESS
JI Digit. Signal Prog.
PD MAR
PY 2020
VL 98
AR 102637
DI 10.1016/j.dsp.2019.102637
PG 9
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA KF7OO
UT WOS:000509428700010
DA 2022-04-17
ER

PT J
AU Jasner, YY
   Belogolovski, A
   Ben-Itzhak, M
   Koren, O
   Louzoun, Y
AF Jasner, Yoel Y.
   Belogolovski, Anna
   Ben-Itzhak, Meirav
   Koren, Omry
   Louzoun, Yoram
TI Microbiome Preprocessing Machine Learning Pipeline
SO FRONTIERS IN IMMUNOLOGY
LA English
DT Article
DE pipeline; machine learning; 16S; OTU; ASV; feature selection
AB Background 16S sequencing results are often used for Machine Learning (ML) tasks. 16S gene sequences are represented as feature counts, which are associated with taxonomic representation. Raw feature counts may not be the optimal representation for ML. Methods We checked multiple preprocessing steps and tested the optimal combination for 16S sequencing-based classification tasks. We computed the contribution of each step to the accuracy as measured by the Area Under Curve (AUC) of the classification. Results We show that the log of the feature counts is much more informative than the relative counts. We further show that merging features associated with the same taxonomy at a given level, through a dimension reduction step for each group of bacteria improves the AUC. Finally, we show that z-scoring has a very limited effect on the results. Conclusions The prepossessing of microbiome 16S data is crucial for optimal microbiome based Machine Learning. These preprocessing steps are integrated into the MIPMLP - Microbiome Preprocessing Machine Learning Pipeline, which is available as a stand-alone version at: https://github.com/louzounlab/microbiome/tree/master/Preprocess or as a service at http://mip-mlp.math.biu.ac.il/Home Both contain the code, and standard test sets.
C1 [Jasner, Yoel Y.; Belogolovski, Anna; Ben-Itzhak, Meirav; Louzoun, Yoram] Bar Ilan Univ, Dept Math, Ramat Gan, Israel.
   [Koren, Omry] Bar Ilan Univ, Azrieli Fac Med, Ramat Gan, Israel.
RP Louzoun, Y (corresponding author), Bar Ilan Univ, Dept Math, Ramat Gan, Israel.
EM louzouy@math.biu.ac.il
FU Food IoT grant; Bar Ilan DSI grant
FX OK and YL acknowledge the Food IoT grant and the Bar Ilan DSI grant. We
   further thank Dr Roni Shoval for the Mucositis data used here.
NR 32
TC 0
Z9 0
U1 0
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-3224
J9 FRONT IMMUNOL
JI Front. Immunol.
PD JUN 18
PY 2021
VL 12
AR 677870
DI 10.3389/fimmu.2021.677870
PG 11
WC Immunology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Immunology
GA TC8SW
UT WOS:000668909500001
PM 34220823
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Saito, M
   Ohsato, T
   Yamanaka, S
AF Saito, Miho
   Ohsato, Takaya
   Yamanaka, Suguru
TI An empirical evaluation of machine learning performance in corporate
   sales growth prediction
SO JSIAM LETTERS
LA English
DT Article
DE sales growth; classification; machine learning
ID SUPPORT VECTOR MACHINES; PROBABILISTIC CLASSIFIER
AB Corporate performance prediction has attracted considerable research interest in the investment and financial risk management fields. This study comprehensively examines the ability of machine learning algorithms to integrate analysis of sales growth prediction, with specific focus on random forest, weighted random forest, gradient boosting decision tree, and support vector machine, as well as a least-squares probabilistic classifier. We carried out an experimental comparison study over a dataset comprising real corporate data on the effectiveness of these five machine-learning algorithms. The results showed sufficient performance for some machine-learning algorithms.
C1 [Saito, Miho] Aoyama Gakuin Univ, Grad Sch Sci & Engn, Chuo Ku, 5-10-1 Fuchinobe, Sagamihara, Kanagawa 2325258, Japan.
   [Ohsato, Takaya] Shiga Univ, Ctr Data Sci Educ & Res, 1-1-1 Banba, Hikone, Shiga 5228522, Japan.
   [Yamanaka, Suguru] Aoyama Gakuin Univ, Coll Sci & Engn, Chuo Ku, 5-10-1 Fuchinobe, Sagamihara, Kanagawa 2325258, Japan.
   [Yamanaka, Suguru] Tokyo Inst Technol, Inst Innovat Res, Midori Ku, 4259 Nagatsutacho, Yokohama, Kanagawa 2268503, Japan.
RP Yamanaka, S (corresponding author), Aoyama Gakuin Univ, Coll Sci & Engn, Chuo Ku, 5-10-1 Fuchinobe, Sagamihara, Kanagawa 2325258, Japan.; Yamanaka, S (corresponding author), Tokyo Inst Technol, Inst Innovat Res, Midori Ku, 4259 Nagatsutacho, Yokohama, Kanagawa 2268503, Japan.
EM syamanaka@gem.aoyama.ac.jp
FU JSPS KAKENHIMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) [JP18K12818];
   Center for TDB Advanced Data Analysis and Modeling, Tokyo Institute of
   Technology
FX Teikoku Databank, Ltd. supported our research by providing data related
   to Japanese business firms and by financially supporting the Center for
   TDB Advanced Data Analysis and Modeling, Tokyo Institute of Technology
   for academic research purposes. This work was partially supported by
   JSPS KAKENHI (Grant Number JP18K12818).
NR 22
TC 0
Z9 0
U1 1
U2 2
PU JAPAN SOC INDUSTRIAL & APPLIED MATHEMATICS-JSIAM
PI TOKYO
PA JAPAN SOC INDUSTRIAL & APPLIED MATHEMATICS-JSIAM, TOKYO, 00000, JAPAN
SN 1883-0609
EI 1883-0617
J9 JSIAM LETT
JI JSIAM Lett.
PY 2021
VL 13
BP 25
EP 28
PG 4
WC Mathematics, Applied
WE Emerging Sources Citation Index (ESCI)
SC Mathematics
GA SM2FD
UT WOS:000657424800001
DA 2022-04-17
ER

PT J
AU Zhang, SW
   Su, Q
   Chen, Q
AF Zhang, Shuwen
   Su, Qiang
   Chen, Qin
TI Application of Machine Learning in Animal Disease Analysis and
   Prediction
SO CURRENT BIOINFORMATICS
LA English
DT Review
DE Machine learning; animal disease; supervised learning; unsupervised
   learning; prediction; ensemble learning
ID PRINCIPAL COMPONENT ANALYSIS; RISK-FACTORS; CLINICAL-DIAGNOSIS;
   FEATURE-SELECTION; NEURAL-NETWORKS; MOUTH-DISEASE; IDENTIFICATION;
   EPIDEMIC; SUPPORT; INFORMATION
AB Major animal diseases pose a great threat to animal husbandry and human beings. With the deepening of globalization and the abundance of data resources, the prediction and analysis of animal diseases by using big data are becoming more and more important. The focus of machine learning is to make computers how to learn from data and use the learned experience to analyze and predict. Firstly, this paper introduces the animal epidemic situation and machine learning. Then it briefly introduces the application of machine learning in animal disease analysis and prediction. Machine learning is mainly divided into supervised learning and unsupervised learning. Supervised learning includes support vector machines, naive bayes, decision trees, random forests, logistic regression, artificial neural networks, deep learning, and AdaBoost. Unsupervised learning has maximum expectation algorithm, principal component analysis hierarchical clustering algorithm and maxent. Through the discussion of this paper, people have a clearer concept of machine learning and an understanding of its application prospect in animal diseases.
C1 [Zhang, Shuwen; Chen, Qin] Shanghai Univ, Sch Life Sci, Shanghai 200444, Peoples R China.
   [Su, Qiang] Comp Ctr Guangxi, Nanning, Guangxi, Peoples R China.
   [Su, Qiang] Duke Univ, Sch Med, Dept Populat Hlth Sci, Durham, NC 27710 USA.
RP Chen, Q (corresponding author), Shanghai Univ, Sch Life Sci, Shanghai 200444, Peoples R China.; Su, Q (corresponding author), Comp Ctr Guangxi, Nanning, Guangxi, Peoples R China.
EM chenqincc@staff.shu.edu.cn; q.su@outlook.com
FU National Key Research and Development Program of China [2016YFD0501101]
FX The present study was supported by The National Key Research and
   Development Program of China (2016YFD0501101).
NR 126
TC 0
Z9 0
U1 18
U2 18
PU BENTHAM SCIENCE PUBL LTD
PI SHARJAH
PA EXECUTIVE STE Y-2, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB
   EMIRATES
SN 1574-8936
EI 2212-392X
J9 CURR BIOINFORM
JI Curr. Bioinform.
PY 2021
VL 16
IS 7
BP 972
EP 982
DI 10.2174/1574893615999200728195613
PG 11
WC Biochemical Research Methods; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Mathematical & Computational Biology
GA XI8TE
UT WOS:000726375800010
DA 2022-04-17
ER

PT J
AU Lee, YE
   Kim, BK
   Bae, JH
   Kim, KC
AF Lee, Yong Eun
   Kim, Bok-Kyung
   Bae, Jun-Hee
   Kim, Kyung Chun
TI Misalignment Detection of a Rotating Machine Shaft Using a Support
   Vector Machine Learning Algorithm
SO INTERNATIONAL JOURNAL OF PRECISION ENGINEERING AND MANUFACTURING
LA English
DT Article
DE SVM; Machine learning; Rotating machine; AI; Fault detection
AB Fault diagnosis for rotating machinery is important for reliability and safety, and shaft misalignment is one of the most common causes of mechanical vibration or shaft failure. In this study, we detected defects caused by misalignment of the shaft axis in rotating machinery using an artificial intelligence machine learning technique for fault recognition. Unlike other methods that focus on the time domain, we changed vibration data in the time domain to the power spectrum component value in the frequency domain. Then, the power spectrum values were classified using principle component analysis (PCA). Based on the results, defects are determined using a machine learning technique that uses a support vector machine (SVM). The results show that defects can be quickly determined from only vibration data about normal and abnormal states. By using the proposed pre-processing method, the machine learning framework based on vibration data can be effectively applied to diagnosis not only shaft defects but also faults of other rotating machines such as motors and engines
C1 [Lee, Yong Eun; Kim, Kyung Chun] Pusan Natl Univ, Sch Mech Engn, Pusan 46241, South Korea.
   [Lee, Yong Eun; Kim, Bok-Kyung; Bae, Jun-Hee] Intown Co Ltd, 401,21,Centum 6 Ro, Pusan 08592, South Korea.
RP Kim, KC (corresponding author), Pusan Natl Univ, Sch Mech Engn, Pusan 46241, South Korea.
EM kckim@pusan.ac.kr
OI Kim, Kyung Chun/0000-0002-7943-9774
FU National Research Foundation of Korea (NRF) - Korean government (MSIT)
   [2020R1A5A8018822]
FX This study was conducted jointly by Intown Co., Ltd, and the School of
   Mechanical Engineering at Pusan National University. Partial support was
   also obtained from the National Research Foundation of Korea (NRF)
   grant, which is also funded by the Korean government (MSIT) (No.
   2020R1A5A8018822).
NR 20
TC 1
Z9 1
U1 6
U2 13
PU KOREAN SOC PRECISION ENG
PI SEOUL
PA RM 306, KWANGMYUNG BLDG, 5-4 NONHYUN-DONG, KANGNAM-GU, SEOUL, 135-010,
   SOUTH KOREA
SN 2234-7593
EI 2005-4602
J9 INT J PRECIS ENG MAN
JI Int. J. Precis. Eng. Manuf.
PD MAR
PY 2021
VL 22
IS 3
BP 409
EP 416
DI 10.1007/s12541-020-00462-1
EA FEB 2021
PG 8
WC Engineering, Manufacturing; Engineering, Mechanical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA QL4EK
UT WOS:000613602600003
DA 2022-04-17
ER

PT S
AU Grimmer, J
   Roberts, ME
   Stewart, BM
AF Grimmer, Justin
   Roberts, Margaret E.
   Stewart, Brandon M.
BE Levi, M
   Rosenblum, NL
TI Machine Learning for Social Science: An Agnostic Approach
SO ANNUAL REVIEW OF POLITICAL SCIENCE, VOL 24, 2021
SE Annual Review of Political Science
LA English
DT Article; Book Chapter
DE machine learning; text as data; research design
ID PUBLIC-OPINION; MODEL; TEXT
AB Social scientists are now in an era of data abundance, and machine learning tools are increasingly used to extract meaning from data sets both massive and small. We explain how the inclusion of machine learning in the social sciences requires us to rethink not only applications of machine learning methods but also best practices in the social sciences. In contrast to the traditional tasks for machine learning in computer science and statistics, when machine learning is applied to social scientific data, it is used to discover new concepts, measure the prevalence of those concepts, assess causal effects, and make predictions. The abundance of data and resources facilitates the move away from a deductive social science to a more sequential, interactive, and ultimately inductive approach to inference. We explain how an agnostic approach to machine learning methods focused on the social science tasks facilitates progress across a wide range of questions.
C1 [Grimmer, Justin] Stanford Univ, Dept Polit Sci, Stanford, CA 94305 USA.
   [Grimmer, Justin] Stanford Univ, Hoover Inst, Stanford, CA 94305 USA.
   [Roberts, Margaret E.] Univ Calif San Diego, Dept Polit Sci, La Jolla, CA 92093 USA.
   [Roberts, Margaret E.] Univ Calif San Diego, Halicioglu Data Sci Inst, La Jolla, CA 92093 USA.
   [Stewart, Brandon M.] Princeton Univ, Dept Sociol, Princeton, NJ 08540 USA.
   [Stewart, Brandon M.] Princeton Univ, Off Populat Res, Princeton, NJ 08540 USA.
RP Grimmer, J (corresponding author), Stanford Univ, Dept Polit Sci, Stanford, CA 94305 USA.; Grimmer, J (corresponding author), Stanford Univ, Hoover Inst, Stanford, CA 94305 USA.
EM jgrimmer@stanford.edu; meroberts@ucsd.edu; bms4@princeton.edu
FU Eunice Kennedy Shriver National Institute of Child Health and Human
   Development of the National Institutes of HealthUnited States Department
   of Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   Eunice Kennedy Shriver National Institute of Child Health & Human
   Development (NICHD) [P2CHD047879]
FX We thank Chad Hazlett and David Stasavage for comments on an earlier
   draft and Naoki Egami and Christian Fong for collaboration on related
   work. Research reported in this publication was supported by the Eunice
   Kennedy Shriver National Institute of Child Health and Human Development
   of the National Institutes of Health under award number P2CHD047879.
NR 111
TC 12
Z9 12
U1 8
U2 14
PU ANNUAL REVIEWS
PI PALO ALTO
PA 4139 EL CAMINO WAY, PO BOX 10139, PALO ALTO, CA 94303-0897 USA
SN 1094-2939
EI 1545-1577
J9 ANNU REV POLIT SCI
JI Annu. Rev. Polit. Sci.
PY 2021
VL 24
BP 395
EP 419
DI 10.1146/annurev-polisci-053119-015921
PG 25
WC Political Science
WE Book Citation Index – Social Sciences & Humanities (BKCI-SSH); Social Science Citation Index (SSCI)
SC Government & Law
GA BR4RE
UT WOS:000652490700019
OA hybrid
DA 2022-04-17
ER

PT C
AU Gao, JC
   Wang, HY
   Shen, HY
AF Gao, Jiechao
   Wang, Haoyu
   Shen, Haiying
GP IEEE
TI Machine Learning Based Workload Prediction in Cloud Computing
SO 2020 29TH INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATIONS AND
   NETWORKS (ICCCN 2020)
SE IEEE International Conference on Computer Communications and Networks
LA English
DT Proceedings Paper
CT 29th International Conference on Computer Communications and Networks
   (ICCCN)
CY AUG 03-06, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Commun Soc
DE Cloud Computing; Machine learning; Workload Prediction
AB As a widely used IT service, more and more companies shift their services to cloud datacenters. It is important for cloud service providers (CSPs) to provide cloud service resources with high elasticity and cost-effectiveness and then achieve good quality of service (QoS) for their clients. However, meeting QoS with cost-effective resource is a challenging problem for CSPs because the workloads of Virtual Machines (VMs) experience variation over time. It is highly necessary to provide an accurate VMs workload prediction method for resource provisioning to efficiently manage cloud resources. In this paper, we first compare the performance of representative state-of-the-art workload prediction methods. We suggest a method to conduct the prediction a certain time before the predicted time point in order to allow sufficient time for task scheduling based on predicted workload. To further improve the prediction accuracy, we introduce a clustering based workload prediction method, which first clusters all the tasks into several categories and then trains a prediction model for each category respectively. The trace-driven experiments based on Google cluster trace demonstrates that our clustering based workload prediction methods outperform other comparison methods and improve the prediction accuracy to around 90% both in CPU and memory.
C1 [Gao, Jiechao; Wang, Haoyu; Shen, Haiying] Univ Virginia, Dept Comp Sci, Charlottesville, VA 22903 USA.
RP Gao, JC (corresponding author), Univ Virginia, Dept Comp Sci, Charlottesville, VA 22903 USA.
EM jg5ycn@virginia.edu; hw8c@virginia.edu; hs6ms@virginia.edu
RI Gao, Jiechao/AAV-1830-2021
OI Gao, Jiechao/0000-0003-0628-1416
FU U.S. NSFNational Science Foundation (NSF) [NSF-1827674, CCF-1822965,
   OAC-1724845, CNS-1733596]; Microsoft Research Faculty Fellowship
   [8300751]; AWS Machine Learning Research Awards
FX This research was supported in part by U.S. NSF grants NSF-1827674,
   CCF-1822965, OAC-1724845, CNS-1733596, Microsoft Research Faculty
   Fellowship 8300751, and AWS Machine Learning Research Awards.
NR 45
TC 40
Z9 40
U1 1
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1095-2055
BN 978-1-7281-6607-0
J9 IEEE IC COMP COM NET
PY 2020
PG 9
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Telecommunications
GA BR0BY
UT WOS:000627816700114
DA 2022-04-17
ER

PT J
AU Fang, Q
   Zhang, WZ
   Wang, XT
AF Fang, Qiang
   Zhang, Wenzhuo
   Wang, Xitong
TI Visual Navigation Using Inverse Reinforcement Learning and an Extreme
   Learning Machine
SO ELECTRONICS
LA English
DT Article
DE visual navigation; inverse reinforcement learning (IRL); extreme
   learning machine (ELM); deep learning; A3C
AB In this paper, we focus on the challenges of training efficiency, the designation of reward functions, and generalization in reinforcement learning for visual navigation and propose a regularized extreme learning machine-based inverse reinforcement learning approach (RELM-IRL) to improve the navigation performance. Our contributions are mainly three-fold: First, a framework combining extreme learning machine with inverse reinforcement learning is presented. This framework can improve the sample efficiency and obtain the reward function directly from the image information observed by the agent and improve the generation for the new target and the new environment. Second, the extreme learning machine is regularized by multi-response sparse regression and the leave-one-out method, which can further improve the generalization ability. Simulation experiments in the AI-THOR environment showed that the proposed approach outperformed previous end-to-end approaches, thus, demonstrating the effectiveness and efficiency of our approach.
C1 [Fang, Qiang; Zhang, Wenzhuo; Wang, Xitong] Natl Univ Def Technol, Coll Intelligence Sci & Technol, Changsha 410073, Peoples R China.
RP Fang, Q (corresponding author), Natl Univ Def Technol, Coll Intelligence Sci & Technol, Changsha 410073, Peoples R China.
EM qiangfang@nudt.edu.cn; doublezore00@163.com; Xitongwang2021@163.com
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61703418, 61825305]
FX This work was supported by the National Natural Science Foundation of
   China (Grant Nos. 61703418 and 61825305).
NR 33
TC 0
Z9 0
U1 10
U2 15
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2079-9292
J9 ELECTRONICS-SWITZ
JI Electronics
PD AUG
PY 2021
VL 10
IS 16
AR 1997
DI 10.3390/electronics10161997
PG 21
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Physics
GA UF9HF
UT WOS:000688876500001
OA gold
DA 2022-04-17
ER

PT J
AU Gokdemir, A
   Calhan, A
AF Gokdemir, Ali
   Calhan, Ali
TI Deep learning and machine learning based anomaly detection in internet
   of things environments
SO JOURNAL OF THE FACULTY OF ENGINEERING AND ARCHITECTURE OF GAZI
   UNIVERSITY
LA English
DT Article
DE IoT; Machine learning; Deep learning; Anomaly; IoT security
ID ATTACKS; SCHEME
AB Graphical/Tabular Abstract Classical machine learning and deep learning were compared in detecting attacks on IoT environments. Due to its success in anomaly detection in the literature, Support Vector Machines (SVM) and Naive Bayes (NB) algorithms from classical machine learning algorithms were preferred. As a deep learning algorithm, the Long Short-Term Memory (LSTM) algorithm, which is mostly used in fields such as natural language processing and text processing, and which has very few studies in anomaly detection, has been chosen. With the LSTM algorithm, higher values were obtained in accuracy and f1 scores. Figure A. Proposed system model for anomaly detection in IoT environments with LSTM-SVM-NB algorithms Purpose: As the use of Internet of Things (IoT) systems has become widespread, cyber-attacks against these systems have also increased. Cyber-attacks occurring in IoT environments can include different types of attacks, such as the inability of their devices to serve, corruption, data capture, modification, or deletion. In this study, it is tried to predict duplication, interception, and modification attacks in Message Queuing Telemetry Transport (MQTT) messages using an IoT dataset with artificial intelligence techniques. Theory and Methods: In this study, compared to the performance metrics of SVM and NB, which are machine learning algorithms, and LSTM, which is a deep learning algorithm. Results: Experimental results show that the LSTM algorithm can be used in anomaly detection in the cyber security area, apart from natural language processing and text processing, which are the areas widely used in the literature. Besides, it was concluded that the LSTM algorithm achieved higher accuracy than the classical machine learning algorithms. Conclusion: In this paper, a comparison of deep learning and machine learning algorithms for anomaly detection in IoT environments is made. The results show that the LSTM algorithm, gives more effective results in anomaly detection than classical machine learning algorithms, but has some disadvantages in terms of working time.
C1 [Gokdemir, Ali] Zonguldak Vocat & Tech Anatolian High Sch, Dept Informat Technol, TR-67030 Zonguldak, Turkey.
   [Calhan, Ali] Duzce Univ, Engn Fac, Dept Comp Engn, TR-81620 Duzce, Turkey.
RP Gokdemir, A (corresponding author), Zonguldak Vocat & Tech Anatolian High Sch, Dept Informat Technol, TR-67030 Zonguldak, Turkey.
EM aligokdemir@gmail.com; alicalhan@duzce.edu.tr
NR 40
TC 0
Z9 0
U1 0
U2 0
PU GAZI UNIV, FAC ENGINEERING ARCHITECTURE
PI ANKARA
PA BAYAR BULVARI, MALTEPE, ANKARA, 06570, TURKEY
SN 1300-1884
EI 1304-4915
J9 J FAC ENG ARCHIT GAZ
JI J. Fac. Eng. Archit. Gazi Univ.
PY 2022
VL 37
IS 4
BP 1945
EP 1956
DI 10.17341/gazimmfd.962375
PG 12
WC Engineering, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA ZQ7YQ
UT WOS:000767316300017
OA gold, Green Submitted
DA 2022-04-17
ER

PT J
AU Papadopoulos, P
   Abramson, W
   Hall, AJ
   Pitropakis, N
   Buchanan, WJ
AF Papadopoulos, Pavlos
   Abramson, Will
   Hall, Adam J.
   Pitropakis, Nikolaos
   Buchanan, William J.
TI Privacy and Trust Redefined in Federated Machine Learning
SO MACHINE LEARNING AND KNOWLEDGE EXTRACTION
LA English
DT Article
DE trust; machine learning; federated learning; decentralised identifiers;
   verifiable credentials
ID SYSTEMS
AB A common privacy issue in traditional machine learning is that data needs to be disclosed for the training procedures. In situations with highly sensitive data such as healthcare records, accessing this information is challenging and often prohibited. Luckily, privacy-preserving technologies have been developed to overcome this hurdle by distributing the computation of the training and ensuring the data privacy to their owners. The distribution of the computation to multiple participating entities introduces new privacy complications and risks. In this paper, we present a privacy-preserving decentralised workflow that facilitates trusted federated learning among participants. Our proof-of-concept defines a trust framework instantiated using decentralised identity technologies being developed under Hyperledger projects Aries/Indy/Ursa. Only entities in possession of Verifiable Credentials issued from the appropriate authorities are able to establish secure, authenticated communication channels authorised to participate in a federated learning workflow related to mental health data.
C1 [Papadopoulos, Pavlos; Abramson, Will; Hall, Adam J.; Pitropakis, Nikolaos; Buchanan, William J.] Edinburgh Napier Univ, Sch Comp, Blockpass ID Lab, Edinburgh EH10 5DT, Midlothian, Scotland.
   [Pitropakis, Nikolaos] Eight Bells LTD, CY-2002 Nicosia, Cyprus.
RP Papadopoulos, P (corresponding author), Edinburgh Napier Univ, Sch Comp, Blockpass ID Lab, Edinburgh EH10 5DT, Midlothian, Scotland.
EM pavlos.papadopoulos@napier.ac.uk; will.abramson@napier.ac.uk;
   adam.hall@napier.ac.uk; N.Pitropakis@napier.ac.uk;
   B.Buchanan@napier.ac.uk
RI Buchanan, William/F-2240-2015; Papadopoulos, Pavlos/AAC-4693-2021
OI Buchanan, William/0000-0003-0809-3523; Papadopoulos,
   Pavlos/0000-0001-5927-6026; Pitropakis, Nikolaos/0000-0002-3392-9970
FU European Commission under the Horizon 2020 Program, through SANCUS
   project [952672]
FX The research leading to these results has been partially supported by
   the European Commission under the Horizon 2020 Program, through funding
   of the SANCUS project (G.A. n 952672).
NR 123
TC 6
Z9 6
U1 5
U2 6
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2504-4990
J9 MACH LEARN KNOW EXTR
JI Mach. Learn. Knowl. Extr.
PD JUN
PY 2021
VL 3
IS 2
BP 333
EP 356
DI 10.3390/make3020017
PG 24
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
WE Emerging Sources Citation Index (ESCI)
SC Computer Science; Engineering
GA RW9UK
UT WOS:000646865100001
OA Green Published, Green Submitted, gold
DA 2022-04-17
ER

PT J
AU Laguel, Y
   Pillutla, K
   Malick, J
   Harchaoui, Z
AF Laguel, Yassine
   Pillutla, Krishna
   Malick, Jerome
   Harchaoui, Zaid
TI Superquantiles at Work: Machine Learning Applications and Efficient
   Subgradient Computation
SO SET-VALUED AND VARIATIONAL ANALYSIS
LA English
DT Article
DE Superquantiles; Smoothing; Robust optimization; Machine learning
ID RISK MEASURES; OPTIMIZATION
AB R. Tyrell Rockafellar and his collaborators introduced, in a series of works, new regression modeling methods based on the notion of superquantile (or conditional value-at-risk). These methods have been influential in economics, finance, management science, and operations research in general. Recently, they have been subject of a renewed interest in machine learning, to address issues of distributional robustness and fair allocation. In this paper, we review some of these new applications of the superquantile, with references to recent developments. These applications involve nonsmooth superquantile-based objective functions that admit explicit subgradient calculations. To make these superquantile-based functions amenable to the gradient-based algorithms popular in machine learning, we show how to smooth them by infimal convolution and detail numerical procedures to compute the gradients of the smooth approximations. We put the approach into perspective by comparing it to other smoothing techniques and by illustrating it on toy examples.
C1 [Laguel, Yassine; Malick, Jerome] Univ Grenoble Alpes, LJK, Grenoble INP, CNRS, F-38000 Grenoble, France.
   [Pillutla, Krishna; Harchaoui, Zaid] Univ Washington, Seattle, WA 98195 USA.
RP Laguel, Y (corresponding author), Univ Grenoble Alpes, LJK, Grenoble INP, CNRS, F-38000 Grenoble, France.
EM yassine.laguel@univ-grenoble-alpes.fr; pillutla@cs.washington.edu;
   jerome.malick@univ-grenoble-alpes.fr; zaid@uw.edu
FU NSFNational Science Foundation (NSF) [DMS 2023166, DMS 1839371, CCF
   2019844]; MIAI - Grenoble Alpes [ANR-19-P3IA-0003]; CIFAR program
   "Learning in Machines and Brains"
FX We acknowledge support from ANR-19-P3IA-0003 (MIAI - Grenoble Alpes),
   NSF DMS 2023166, DMS 1839371, CCF 2019844, the CIFAR program "Learning
   in Machines and Brains", and faculty research awards.
NR 57
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1877-0533
EI 1877-0541
J9 SET-VALUED VAR ANAL
JI Set-Valued Var. Anal.
PD DEC
PY 2021
VL 29
IS 4
BP 967
EP 996
DI 10.1007/s11228-021-00609-w
EA DEC 2021
PG 30
WC Mathematics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Mathematics
GA YD2WU
UT WOS:000736400500001
OA Green Submitted
DA 2022-04-17
ER

PT C
AU Bohlen, M
   Sujarwo, W
AF Bohlen, Marc
   Sujarwo, Wawan
GP IEEE
TI Machine Learning in Ethnobotany
SO 2020 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS
   (SMC)
SE IEEE International Conference on Systems Man and Cybernetics Conference
   Proceedings
LA English
DT Proceedings Paper
CT IEEE International Conference on Systems, Man, and Cybernetics (SMC)
CY OCT 11-14, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Syst Man & Cybernet Soc, IEEE Brain, Intheon, Guger Technologies
DE ethnobotany; machine learning; knowledge representation; convolutional
   neural networks; local ecological knowledge; emerging economies
ID KNOWLEDGE; FOOD
AB We describe new opportunities created by bring A.I. to the field of ethnobotany. In particular we describe a novel approach to ethnobotany documentation that harnesses machine learning opportunities, specifically for the documentation of traditional ecological knowledge with mobile phones in emerging economies. Using a case study on the island of Bali as a departure point, the project maps out machine learning approaches to documentation and responds to technology and capital gradients between research contexts in the global north and south in an attempt to capture knowledge that might otherwise not be represented.
C1 [Bohlen, Marc] Univ Buffalo, Dept Art Emerging Practices Computat Media, Buffalo, NY 14260 USA.
   [Sujarwo, Wawan] Indonesian Inst Sci, Ethnobiol Res Grp Res Ctr Biol, Cibinong, West Java, Indonesia.
RP Bohlen, M (corresponding author), Univ Buffalo, Dept Art Emerging Practices Computat Media, Buffalo, NY 14260 USA.
EM marcbohlen@protonmail.com; wawan.sujarwo@lipi.go.id
FU Google faculty research grantGoogle Incorporated
FX Classifier training was supported in part by a Google faculty research
   grant.
NR 24
TC 0
Z9 0
U1 3
U2 3
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1062-922X
BN 978-1-7281-8526-2
J9 IEEE SYS MAN CYBERN
PY 2020
BP 108
EP 113
PG 6
WC Computer Science, Cybernetics; Computer Science, Information Systems
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS1DD
UT WOS:000687430600018
DA 2022-04-17
ER

PT C
AU Scurto, H
   Caramiaux, B
   Bevilacqua, F
AF Scurto, Hugo
   Caramiaux, Baptiste
   Bevilacqua, Frederic
GP ACM
TI Prototyping Machine Learning Through Diffractive Art Practice
SO PROCEEDINGS OF THE 2021 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE
   (DIS 2021)
LA English
DT Proceedings Paper
CT ACM Designing Interactive Systems Conference (DIS)
CY JUN 28-JUL 02, 2021
CL ELECTR NETWORK
SP Assoc Comp Machinery
DE Machine Learning; Art Practice; Design; Diffractive Methods
AB In this paper, we outline a diffractive practice of machine learning (ML) in the frame of material-centered interaction design. To this aim, we review related work in ML, HCI, design, new interfaces for musical expression, and computational art, and introduce two practice-based studies of music performance and robotic art based on interactive machine learning tools, with the hope of revealing the computational materiality of ML, and the potential of embodiment to craft prototypes of ML that reconfigure conceptual or technical approaches to ML. We derive five interference conditions for such art-based ML prototypes-situational whole, small data, shallow model, learnable algorithm, and somaesthetic behaviour- and describe their widening of design and engineering practices of ML prototyping. Finally, we sketch how a process of intra-active machine learning could complement that of interactive machine learning to take materiality as an entry point for ML design within HCI.
C1 [Scurto, Hugo] Sorbonne Univ, CNRS, INSERM,EnsadLab, ISIR,EnsAD PSL Univ,UMRS1158,Reflect Interact Grp, Paris, France.
   [Caramiaux, Baptiste] Sorbonne Univ, ISIR, CNRS, Paris, France.
   [Bevilacqua, Frederic] Sorbonne Univ, STMS, CNRS, IRCAM, Paris, France.
RP Scurto, H (corresponding author), Sorbonne Univ, CNRS, INSERM,EnsadLab, ISIR,EnsAD PSL Univ,UMRS1158,Reflect Interact Grp, Paris, France.
EM hugo.scurto@ensad.fr; baptiste.caramiaux@sorbonne-universite.fr;
   Frederic.Bevilacqua@ircam.fr
FU Orange's Art Direction Nods Team (Xdlab); EnsadLab's Reflective
   Interaction research group, the research laboratory of the Ecole
   nationale superieure des Arts Decoratifs
FX The authors would like to thank Jules Francoise, Riccardo Borghesi,
   Djellal Chalabi and Emmanuel Flety for their support in prototyping
   somasticks, and all members of the movA network for their precious time
   and feedback experimenting with them. The authors would also like to
   thank Elena Tosi-Brandi, Samuel Bianchini, Joffrey Becker, Florent
   Levillain, Olivain Porry, Didier Bouchon, Victor Audouze, Corentin
   Loubet, Josephine Mas, Franck Weens, Catherine Ramus, and Camille Dauhut
   for their fundamental contributions and fruitful engagement within The
   Appprentices. The latter project was supported by Orange's Art Direction
   Nods Team (Xdlab) and EnsadLab's Reflective Interaction research group,
   the research laboratory of the Ecole nationale superieure des Arts
   Decoratifs.
NR 94
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-8476-6
PY 2021
BP 2013
EP 2025
DI 10.1145/3461778.3462163
PG 13
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications; Computer Science, Theory & Methods; Ergonomics
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Engineering
GA BS6FH
UT WOS:000747486000148
OA Green Published
DA 2022-04-17
ER

PT J
AU Zhang, QL
   Hu, WF
   Liu, ZY
   Tan, JR
AF Zhang, Qianli
   Hu, Weifei
   Liu, Zhenyu
   Tan, Jianrong
TI TBM performance prediction with Bayesian optimization and automated
   machine learning
SO TUNNELLING AND UNDERGROUND SPACE TECHNOLOGY
LA English
DT Article
DE Performance prediction; Bayesian optimization; Machine learning
ID TUNNEL BORING MACHINE; PENETRATION RATE PREDICTION; LOGISTIC-REGRESSION;
   LEAST-SQUARE; ROCK; CLASSIFICATION; MODEL; TREE
AB Accurately predicting the performance of a tunnel boring machine (TBM) is important to safe and efficient tunneling. The application of machine learning algorithms to TBM performance prediction creates several challenges. Such prediction is a nontrivial task involving procedures such as data preprocessing, selection of a machine learning algorithm and optimization of the related hyperparameters. The demand for expert knowledge has restricted the application of machine learning methods to TBM performance prediction, and it is meaningful to study predicting TBM performance automatically. In this paper, we explore three approaches to TBM performance prediction using Bayesian optimization and automated machine learning (AutoML). In the first study, Bayesian optimization is used to determine the optimal hyperparameters of various machine learning algorithms, including support vector regression (SVR), decision tree, bagging tree, random forest and AdaBoost. We attain the minimum mean squared error (MSE) values of 3.135 x 10(-2) and 3.177 x 10(-2) for a decision tree and SVR, respectively. In the second approach called the neural architecture search (NAS), the optimal combination of architecture, hyperparameters and the training procedure of an artificial neural network is found in a single operation. We obtain the optimal results of 3.514 x 10(-2) and 3.237 x 10(-2) if complete and simplified NAS are used, respectively. In the third method, the best combination of a data preprocessing method, a machine learning model and the related hyperparameters is found, and an optimal MSE value of 3.148 x 10(-2) is obtained using AutoML. In all three studies, we obtain state-of-the-art prediction results that are superior to a previous best prediction result of 3.500 x 10(-2). The prediction results prove that Bayesian optimization and AutoML are powerful tools that can not only effectively predict TBM performance but also reduce the demand for expert knowledge of machine learning.
C1 [Zhang, Qianli; Hu, Weifei; Liu, Zhenyu; Tan, Jianrong] Zhejiang Univ, State Key Lab Fluid Power & Mechatron Syst, Hangzhou 310027, Peoples R China.
   [Zhang, Qianli; Hu, Weifei; Liu, Zhenyu; Tan, Jianrong] Zhejiang Univ, Sch Mech Engn, Hangzhou 310027, Peoples R China.
RP Liu, ZY (corresponding author), Zhejiang Univ, State Key Lab Fluid Power & Mechatron Syst, Hangzhou 310027, Peoples R China.
EM liuzy@zju.edu.cn
OI Zhang, Qianli/0000-0002-4353-3187
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [U1608256, 51935009, 51821093]
FX Funding: This study was supported by the National Natural Science
   Foundation of China (grant number U1608256, 51935009, 51821093).
NR 43
TC 13
Z9 14
U1 29
U2 65
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0886-7798
EI 1878-4364
J9 TUNN UNDERGR SP TECH
JI Tunn. Undergr. Space Technol.
PD SEP
PY 2020
VL 103
AR 103493
DI 10.1016/j.tust.2020.103493
PG 14
WC Construction & Building Technology; Engineering, Civil
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Construction & Building Technology; Engineering
GA MV3EV
UT WOS:000556245300037
DA 2022-04-17
ER

PT J
AU Choi, H
   Park, S
AF Choi, Hyejeong
   Park, Sejin
TI A Survey of Machine Learning-Based System Performance Optimization
   Techniques
SO APPLIED SCIENCES-BASEL
LA English
DT Review
DE deep learning; machine learning; system performance; optimization
AB Recently, the machine learning research trend expands to the system performance optimization field, where it has still been proposed by researchers based on their intuitions and heuristics. Compared to conventional major machine learning research areas such as image or speech recognition, machine learning-based system performance optimization fields are at the beginning stage. However, recent papers show that this approach is promising and has significant potential. This paper reviews 11 machine learning-based system performance optimization approaches from nine recent papers based on well-known machine learning models such as perceptron, LSTM, and RNN. This survey provides a detailed design and summarizes model, input, output, and prediction method of each approach. This paper covers various system performance areas from the data structure to essential system components of a computer system such as index structure, branch predictor, sort, and cache management. The result shows that machine learning-based system performance optimization has an important potential for future research. We expect that this paper shows a wide range of applicability of machine learning technology and provides a new perspective for system performance optimization.
C1 [Choi, Hyejeong; Park, Sejin] Keimyung Univ, Dept Comp Sci, Daegu 1095, South Korea.
RP Park, S (corresponding author), Keimyung Univ, Dept Comp Sci, Daegu 1095, South Korea.
EM hyejeong12311@gmail.com; baksejin@kmu.ac.kr
OI Park, Sejin/0000-0001-5050-3093; Choi, Hyejeong/0000-0002-2824-6382
FU National Research Foundation of Korea (NRF) - Korea government
   (MSIT)National Research Foundation of Korea [2019R1G1A1100305]
FX This research was funded by by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT) (No.
   2019R1G1A1100305).
NR 38
TC 3
Z9 3
U1 17
U2 28
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD APR
PY 2021
VL 11
IS 7
AR 3235
DI 10.3390/app11073235
PG 19
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Materials Science; Physics
GA RK6BP
UT WOS:000638379600001
OA gold
DA 2022-04-17
ER

PT J
AU Bhavsar, KA
   Abugabah, A
   Singla, J
   AlZubi, AA
   Bashir, AK
   Nikita
AF Bhavsar, Kaustubh Arun
   Abugabah, Ahed
   Singla, Jimmy
   AlZubi, Ahmad Ali
   Bashir, Ali Kashif
   Nikita
TI A Comprehensive Review on Medical Diagnosis Using Machine Learning
SO CMC-COMPUTERS MATERIALS & CONTINUA
LA English
DT Review
DE Diagnostic system; machine learning; medical diagnosis; healthcare
   applications
ID SUPPORT VECTOR MACHINE; NEURAL-NETWORKS; LOGISTIC-REGRESSION;
   PREDICTION; OVERCONFIDENCE; CLASSIFICATION; FEATURES; MODEL
AB The unavailability of sufficient information for proper diagnosis, incomplete or miscommunication between patient and the clinician, or among the healthcare professionals, delay or incorrect diagnosis, the fatigue of clinician, or even the high diagnostic complexity in limited time can lead to diagnostic errors. Diagnostic errors have adverse effects on the treatment of a patient. Unnecessary treatments increase the medical bills and deteriorate the health of a patient. Such diagnostic errors that harm the patient in various ways could be minimized using machine learning. Machine learning algorithms could be used to diagnose various diseases with high accuracy. The use of machine learning could assist the doctors in making decisions on time, and could also be used as a second opinion or supporting tool. This study aims to provide a comprehensive review of research articles published from the year 2015 to mid of the year 2020 that have used machine learning for diagnosis of various diseases. We present the various machine learning algorithms used over the years to diagnose various diseases. The results of this study show the distribution of machine learning methods by medical disciplines. Based on our review, we present future research directions that could be used to conduct further research.
C1 [Bhavsar, Kaustubh Arun; Singla, Jimmy] Lovely Profess Univ, Jalandhar 144411, Punjab, India.
   [Abugabah, Ahed] Zayed Univ, Coll Tech Innovat, Dubai, U Arab Emirates.
   [AlZubi, Ahmad Ali] King Saud Univ, Dept Comp Sci, Riyadh, Saudi Arabia.
   [Bashir, Ali Kashif] Manchester Metropolitan Univ, Dept Comp & Math, Manchester M15 6BH, Lancs, England.
   [Nikita] Lovely Profess Univ, Sch Comp Sci & Engn, Jalandhar 144411, Punjab, India.
RP Singla, J (corresponding author), Lovely Profess Univ, Jalandhar 144411, Punjab, India.
EM jimmy.21733@lpu.co.in
RI AlZubi, Ahmad Ali/ABB-4190-2020; Bashir, Ali Kashif/R-4015-2019
OI AlZubi, Ahmad Ali/0000-0001-8477-8319; Bashir, Ali
   Kashif/0000-0003-2601-9327
FU Zayed University, office of research [R17089]
FX This work was supported in part by Zayed University, office of research
   under Grant No. R17089.
NR 106
TC 4
Z9 4
U1 25
U2 35
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1546-2218
EI 1546-2226
J9 CMC-COMPUT MATER CON
JI CMC-Comput. Mat. Contin.
PY 2021
VL 67
IS 2
BP 1997
EP 2014
DI 10.32604/cmc.2021.014943
PG 18
WC Computer Science, Information Systems; Materials Science,
   Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Materials Science
GA QF2EU
UT WOS:000616713000005
OA Green Accepted, gold
DA 2022-04-17
ER

PT C
AU Qian, L
   Larson, KG
   Zelnio, E
   Warren, R
   Bush, B
   Garcia, L
   Kulkarni, T
   Latiff, S
AF Qian, Lei
   Larson, Kathleen G.
   Zelnio, Edmund
   Warren, Rik
   Bush, Bradley
   Garcia, Lukas
   Kulkarni, Trisha
   Latiff, Susan
BE Kadar, I
   Blasch, EP
   Grewe, LL
TI Auditory implicit learning in machines versus humans
SO SIGNAL PROCESSING, SENSOR/INFORMATION FUSION, AND TARGET RECOGNITION
   XXIX
SE Proceedings of SPIE
LA English
DT Proceedings Paper
CT Conference on Signal Processing, Sensor/Information Fusion, and Target
   Recognition XXIX
CY APR 27-MAY 08, 2020
CL ELECTR NETWORK
SP SPIE
DE implicit learning; machine learning; affective learning; sequential
   reasoning; auditory data; artificial grammar
ID NEGATIVE AFFECT; MOOD; JUDGMENT; EMOTION
AB We investigated the difference in performance on an implicit learning task between humans and machines in the auditory domain. Implicit learning is the process of ingesting information, such as patterns of everyday life, without being actively aware of doing so and without formal instruction. In pattern and anomaly detection, it is desirable to learn the patterns of everyday life in order to detect irregularities. In addition, we also considered how affect or emotion-like aspects interacts with this process. In our experiments, we created a synthetic pattern for both positive and negative sounds using a Markov grammar, which we then asked a machine-learning algorithm or humans to process. Results indicated that the generated pattern is a trivial task for even a simple RNN. For a similar but more complex task, humans performed significantly better under the condition of positive affect inducing sounds than they performed with negative sounds. Possibilities for the outcomes are discussed, along with other potential methods to compare human and machine implicit learning performance.
C1 [Qian, Lei; Zelnio, Edmund] Air Force Res Lab, Sensors Directorate, RYAP, 2241 Avion Circle, Wright Patterson AFB, OH 45433 USA.
   [Larson, Kathleen G.; Warren, Rik] Air Force Res Lab, 711 HPW RHCM,2255 H St, Wright Patterson AFB, OH 45433 USA.
   [Bush, Bradley] Arizona State Univ, Tempe, AZ USA.
   [Garcia, Lukas] Florida Atlantic Univ, Boca Raton, FL 33431 USA.
   [Kulkarni, Trisha] Stanford Univ, Stanford, CA 94305 USA.
   [Latiff, Susan] Northeastern Univ, Boston, MA 02115 USA.
RP Qian, L (corresponding author), Air Force Res Lab, Sensors Directorate, RYAP, 2241 Avion Circle, Wright Patterson AFB, OH 45433 USA.
FU AFRL Sensors Directorate Autonomous Technology Research Center; AFRL
   711th Human Performance Wing Repperger Internship Program
FX Bradley Bush, Lukas Garcia, and Trisha Kulkarni were supported under the
   AFRL Sensors Directorate Autonomous Technology Research Center. Susan
   Latiff was supported under the AFRL 711th Human Performance Wing
   Repperger Internship Program.
NR 56
TC 0
Z9 0
U1 1
U2 1
PU SPIE-INT SOC OPTICAL ENGINEERING
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA
SN 0277-786X
EI 1996-756X
BN 978-1-5106-3624-8; 978-1-5106-3623-1
J9 PROC SPIE
PY 2020
VL 11423
AR 114230Q
DI 10.1117/12.2559478
PG 15
WC Engineering, Electrical & Electronic; Remote Sensing; Optics; Imaging
   Science & Photographic Technology
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering; Remote Sensing; Optics; Imaging Science & Photographic
   Technology
GA BQ4JM
UT WOS:000589963800014
DA 2022-04-17
ER

PT C
AU Fard, A
   Le, A
   Larionov, G
   Dhillon, W
   Bear, C
AF Fard, Arash
   Le, Anh
   Larionov, George
   Dhillon, Waqas
   Bear, Chuck
GP Assoc Comp Machinery
TI Vertica-ML: Distributed Machine Learning in Vertica Database
SO SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE
   ON MANAGEMENT OF DATA
LA English
DT Proceedings Paper
CT ACM SIGMOD International Conference on Management of Data (SIGMOD)
CY JUN 14-19, 2020
CL ELECTR NETWORK
SP Assoc Comp Machinery, ACM SIGMOD
DE Database; Machine learning; Big Data; Distributed Computing
AB A growing number of companies rely on machine learning as a key element for gaining a competitive edge from their collected Big Data. An in-database machine learning system can provide many advantages in this scenario, e.g., eliminating the overhead of data transfer, avoiding the maintenance costs of a separate analytical system, and addressing data security and provenance concerns. In this paper, we present our distributed machine learning subsystem within the Vertica database. This subsystem, Vertica-ML, includes machine learning functionalities with SQL API which cover a complete data science workflow as well as model management. We treat machine learning models in Vertica as first-class database objects like tables and views; therefore, they enjoy a similar mechanism for archiving and managing. We explain the architecture of the subsystem, and present a set of experiments to evaluate the performance of the machine learning algorithms implemented on top of it.
C1 [Fard, Arash; Le, Anh; Larionov, George; Dhillon, Waqas; Bear, Chuck] Vertica, Cambridge, MA 02140 USA.
RP Fard, A (corresponding author), Vertica, Cambridge, MA 02140 USA.
EM fard@microfocus.com; anh.tri.le@microfocus.com;
   george.larionov@microfocus.com; waqas.dhillon@microfocus.com;
   charles.bear@microfocus.com
NR 29
TC 4
Z9 4
U1 2
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-6735-6
PY 2020
BP 755
EP 768
DI 10.1145/3318464.3386137
PG 14
WC Computer Science, Information Systems
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR3BZ
UT WOS:000644433700051
OA Bronze
DA 2022-04-17
ER

PT J
AU Thiyagarajan, S
   Chakravarthy, T
   Arivoli, PV
AF Thiyagarajan, S.
   Chakravarthy, T.
   Arivoli, P., V
TI DIAGNOSING BREAST CANCER WITH MACHINE LEARNING ALGORITHMS
SO INTERNATIONAL JOURNAL OF LIFE SCIENCE AND PHARMA RESEARCH
LA English
DT Article
DE Breast cancer detection; Classification; Machine learning; WD; UCI
   Machine
AB Breast cancer is a type of cancer found in the breast. Cancer starts when cells begin to grow out of control. Breast cancer cells usually form as a tumor felt as a lump. Breast cancer occurs in women. It is important to find that most breast lumps are benign (good cells) and not malignant (cancerous cells). Periodic breast cancer check-ups give the disease to be diagnosed and treated prior to it causing noticeable symptoms. Machine learning automates the identification of cancerous cells and provides considerable benefits to the health care systems. Automated process provides physicians to spend less time in diagnosing and more time for diseases treatment, thus it improves the efficiency of the detection process. This research work investigate the application of machine learning methods for detecting breast cancer by using measurements of biopsied cells from women with abnormal breast masses. It uses the Wisconsin Breast Cancer Diagnostic dataset from the UCI Machine Learning Repository. Various performance estimation methods are used to validate the methods used in the work.
C1 [Thiyagarajan, S.; Chakravarthy, T.] Bharathidasan Univ, AVVM Sri Pushpam Coll Autonomous, Dept Comp Sci, Poondi 613503, Thanjavur, India.
   [Arivoli, P., V] Bharathidasan Univ, Govt Arts & Sci Coll, Dept Comp Sci, Kudavasal 612601, Thiruvarur, India.
RP Thiyagarajan, S (corresponding author), Bharathidasan Univ, AVVM Sri Pushpam Coll Autonomous, Dept Comp Sci, Poondi 613503, Thanjavur, India.
EM strprc@gmail.com; tcvarthy@gmail.com; pvatvr@gmail.com
RI S, THIYAGARAJAN/AAF-3266-2021
NR 9
TC 1
Z9 1
U1 2
U2 4
PU INT JOURNAL LIFESCIENCE & PHARMA RESEARCH
PI TAMILNADU
PA PLOT NO 10, 2 MAIN RD, RENGA NAGAR NEAR TO OLD ALPHA SCH, SATHANOOR MAIN
   RD, TIRUCHIRAPALLI, TAMILNADU, INDIA
SN 2250-0480
J9 INT J LIFE SCI PHARM
JI Int. J. Life Sci. Pharma Res.
PD JAN
PY 2020
SI 7
BP 42
EP 46
PG 5
WC Chemistry, Medicinal
WE Emerging Sources Citation Index (ESCI)
SC Pharmacology & Pharmacy
GA MR4LB
UT WOS:000553559400007
DA 2022-04-17
ER

PT J
AU Nearing, GS
   Kratzert, F
   Sampson, AK
   Pelissier, CS
   Klotz, D
   Frame, JM
   Prieto, C
   Gupta, HV
AF Nearing, Grey S.
   Kratzert, Frederik
   Sampson, Alden Keefe
   Pelissier, Craig S.
   Klotz, Daniel
   Frame, Jonathan M.
   Prieto, Cristina
   Gupta, Hoshin V.
TI What Role Does Hydrological Science Play in the Age of Machine Learning?
SO WATER RESOURCES RESEARCH
LA English
DT Editorial Material
DE Machine Learning; Deep Learning; Uncertainty; Modeling
ID FORECASTING UNCERTAINTY ASSESSMENT; INFORMATION-THEORY; SOIL-MOISTURE;
   DATA SET; BENCHMARKING; VARIABILITY; DIAGNOSTICS; INCOHERENCE; PARADIGM;
   MODELS
AB Y This paper is derived from a keynote talk given at the Google's 2020 Flood Forecasting Meets Machine Learning Workshop. Recent experiments applying deep learning to rainfall-runoff simulation indicate that there is significantly more information in large-scale hydrological data sets than hydrologists have been able to translate into theory or models. While there is a growing interest in machine learning in the hydrological sciences community, in many ways, our community still holds deeply subjective and nonevidence-based preferences for models based on a certain type of "process understanding" that has historically not translated into accurate theory, models, or predictions. This commentary is a call to action for the hydrology community to focus on developing a quantitative understanding of where and when hydrological process understanding is valuable in a modeling discipline increasingly dominated by machine learning. We offer some potential perspectives and preliminary examples about how this might be accomplished.
C1 [Nearing, Grey S.; Frame, Jonathan M.] Univ Calif Davis, Dept Land Air & Water Resources, Davis, CA 95616 USA.
   [Kratzert, Frederik; Klotz, Daniel] Johannes Kepler Univ Linz, LIT Lab, Linz, Austria.
   [Kratzert, Frederik; Klotz, Daniel] Johannes Kepler Univ Linz, Inst Machine Learning, Linz, Austria.
   [Sampson, Alden Keefe] Natel Energy Inc, Upstream Tech, Alameda, CA USA.
   [Pelissier, Craig S.] NASA, Goddard Space Flight Ctr, Ctr Climate Simulat, Greenbelt, MD USA.
   [Prieto, Cristina] Univ Cantabria, IHCantabria Inst Hidrul Ambiental, Santander, Spain.
   [Gupta, Hoshin V.] Univ Arizona, Dept Hydrol & Atmospher Sci, Tucson, AZ USA.
RP Nearing, GS (corresponding author), Univ Calif Davis, Dept Land Air & Water Resources, Davis, CA 95616 USA.
EM gsnearing@ua.edu
RI Prieto, Cristina/Y-9015-2019; Gupta, Hoshin V/D-1642-2010
OI Prieto, Cristina/0000-0002-6693-0396; Gupta, Hoshin
   V/0000-0001-9855-2839; Kratzert, Frederik/0000-0002-8897-7689
FU Google faculty research awardGoogle Incorporated; NASA Advanced
   Information Systems Technology program [80NSSC17K0541]; NASA Terrestrial
   Hydrology ProgramNational Aeronautics & Space Administration (NASA)
   [80NSSC18K0982]; Government of Cantabria through the Fnix Programme
FX Authors from the Johannes Kepler University were partially supported by
   a Google faculty research award. Grey Nearing at the University of
   Alabama was supported by the NASA Advanced Information Systems
   Technology program (award ID 80NSSC17K0541). Jonathan Frame at the
   University of Alabama was supported by the NASA Terrestrial Hydrology
   Program (award ID 80NSSC18K0982).The author from IHCantabria
   acknowledges the financial support from the Government of Cantabria
   through the Fnix Programme.
NR 108
TC 47
Z9 49
U1 36
U2 51
PU AMER GEOPHYSICAL UNION
PI WASHINGTON
PA 2000 FLORIDA AVE NW, WASHINGTON, DC 20009 USA
SN 0043-1397
EI 1944-7973
J9 WATER RESOUR RES
JI Water Resour. Res.
PD MAR
PY 2021
VL 57
IS 3
AR e2020WR028091
DI 10.1029/2020WR028091
PG 15
WC Environmental Sciences; Limnology; Water Resources
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Environmental Sciences & Ecology; Marine & Freshwater Biology; Water
   Resources
GA RG6YG
UT WOS:000635680800006
OA Green Published, Green Submitted, Bronze
DA 2022-04-17
ER

PT J
AU Xu, PC
   Chen, HM
   Li, MJ
   Lu, WC
AF Xu, Pengcheng
   Chen, Huimin
   Li, Minjie
   Lu, Wencong
TI New Opportunity: Machine Learning for Polymer Materials Design and
   Discovery
SO ADVANCED THEORY AND SIMULATIONS
LA English
DT Review; Early Access
DE machine learning; materials design and discovery; polymer; support
   vector machine; transfer learning
ID NEURAL-NETWORKS; ALGORITHMS; PREDICTION
AB Under the guidance of the material genome initiative (MGI), the use of data-driven methods to discover new materials has become an innovation of materials science. The polymer materials have been one of the most important parts in materials science for the excellent physical and chemical properties as well as corresponding complex structures. Machine learning, as the core of data-driven methods, has taken an important place in polymer materials design and discovery. In this review, the authors have introduced the applications of machine learning in the design and discovery of polymer materials. The development tendency of published papers about machine learning in polymer materials, the commonly used algorithms, the polymer descriptors, the workflow of machine learning in polymer materials, and recent progresses of machine learning in materials are summarized. Then, the detail of how to use machine learning to assist design and discovery of polymer materials is fully discussed combined with two cases. Finally, the opportunities and challenges on the future development prospects of machine learning in the field of polymer materials are proposed.
C1 [Xu, Pengcheng; Lu, Wencong] Shanghai Univ, Mat Genome Inst, Shanghai 200444, Peoples R China.
   [Chen, Huimin] Shanghai Univ, Coll Sci, Dept Math, Shanghai 200444, Peoples R China.
   [Li, Minjie; Lu, Wencong] Shanghai Univ, Coll Sci, Dept Chem, Shanghai 200444, Peoples R China.
RP Lu, WC (corresponding author), Shanghai Univ, Mat Genome Inst, Shanghai 200444, Peoples R China.; Li, MJ; Lu, WC (corresponding author), Shanghai Univ, Coll Sci, Dept Chem, Shanghai 200444, Peoples R China.
EM minjieli@shu.edu.cn; wclu@shu.edu.cn
FU National Key Research and Development Program of China [2018YFB0704400];
   Key Program of Science and Technology of Yunnan Province
   [202002AB080001-2]; Shanghai Pujiang ProgramShanghai Pujiang Program
   [21PJD024]
FX This work was supported by the National Key Research and Development
   Program of China (No. 2018YFB0704400), The Key Program of Science and
   Technology of Yunnan Province (Grant No. 202002AB080001-2), and Shanghai
   Pujiang Program (NO. 21PJD024).
NR 107
TC 0
Z9 0
U1 54
U2 54
PU WILEY-V C H VERLAG GMBH
PI WEINHEIM
PA POSTFACH 101161, 69451 WEINHEIM, GERMANY
EI 2513-0390
J9 ADV THEOR SIMUL
JI Adv. Theory Simul.
AR 2100565
DI 10.1002/adts.202100565
EA FEB 2022
PG 17
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA YX6AC
UT WOS:000754182500001
DA 2022-04-17
ER

PT J
AU Breeden, JL
AF Breeden, Joseph L.
TI A survey of machine learning in credit risk
SO JOURNAL OF CREDIT RISK
LA English
DT Article
DE machine learning; artificial intelligence; credit risk; credit scoring;
   stress testing
ID SUPPORT VECTOR MACHINE; ART CLASSIFICATION ALGORITHMS; DATA MINING
   METHODS; NEURAL-NETWORK; BANKRUPTCY PREDICTION; GENETIC ALGORITHM;
   PORTFOLIO OPTIMIZATION; FEATURE-SELECTION; SCORING MODELS; DECISION
   TREES
AB Machine learning algorithms have come to dominate several industries. After decades of resistance from examiners and auditors, machine learning is now moving from the research desk to the application stack for credit scoring and a range of other applications in credit risk. This migration is not without novel risks and challenges. Much of the research is now shifting from how best to make the models to how best to use the models in a regulator-compliant business context. This paper surveys the impressively broad range of machine learning methods and application areas for credit risk. In the process of that survey, we create a taxonomy to think about how different machine learning components are matched to create specific algorithms. The reasons for where machine learning succeeds over simple linear methods are explored through a specific lending example. Throughout, we highlight open questions, ideas for improvements and a framework for thinking about how to choose the best machine learning method for a specific problem.
C1 [Breeden, Joseph L.] Prescient Models LLC, 1600 Lena St, Santa Fe, NM 87505 USA.
RP Breeden, JL (corresponding author), Prescient Models LLC, 1600 Lena St, Santa Fe, NM 87505 USA.
EM breeden@prescientmodels.com
NR 301
TC 1
Z9 1
U1 22
U2 22
PU INCISIVE MEDIA
PI LONDON
PA HAYMARKET HOUSE, 28-29 HAYMARKET, LONDON, SW1Y 4RX, ENGLAND
SN 1744-6619
EI 1755-9723
J9 J CREDIT RISK
JI J. Credit Risk
PD SEP
PY 2021
VL 17
IS 3
BP 1
EP 62
DI 10.21314/JCR.2021.008
PG 62
WC Business, Finance
WE Social Science Citation Index (SSCI)
SC Business & Economics
GA WM2LP
UT WOS:000710922600002
DA 2022-04-17
ER

PT C
AU Baaqeel, H
   Zagrouba, R
AF Baaqeel, Hind
   Zagrouba, Rachid
GP IEEE
TI Hybrid SMS Spam Filtering System Using Machine Learning Techniques
SO 2020 21ST INTERNATIONAL ARAB CONFERENCE ON INFORMATION TECHNOLOGY (ACIT)
SE International Arab Conference on Information Technology ACIT
LA English
DT Proceedings Paper
CT 21st International Arab Conference on Information Technology (ACIT)
CY NOV 28-30, 2020
CL EGYPT
SP MISR Univ Sci & Technol, ACIT Int, IEEE
DE SMS; Spam Filtering; Supervised Machine Learning; Unsupervised Machine
   Learning; Security
AB Due to the massive proliferation of Short Message Service (SMS), Spammers got the interest to dig their way into it in the hope to reach more targets. Spam SMS can trick mobile users into giving away their confidential information which can result in severe consequences. The seriousness of this problem has raised the need to develop an accurate Spam filtration solution. Machine learning algorithms have emerged as a great tool to classify data into labels. This description fits our case perfectly as it classifies SMS into two labels: spam or ham. This paper will tackle the SMS spam filtration solutions by introducing a hybrid system using two types of machine learning techniques: supervised & unsupervised machine learning algorithms. The new hybrid system is designed to achieve better spam filtration accuracy and F-measures
C1 [Baaqeel, Hind; Zagrouba, Rachid] Imam Abdulrahman Bin Faisal Univ, Coll Comp Sci & Informat Technol, POB 1982, Dammam 31441, Saudi Arabia.
RP Baaqeel, H (corresponding author), Imam Abdulrahman Bin Faisal Univ, Coll Comp Sci & Informat Technol, POB 1982, Dammam 31441, Saudi Arabia.
EM 2190500152@iau.edu.sa; rmzagrouba@iau.edu.sa
RI Baaqeel, Hind/AAI-9102-2021; Zagrouba, Rachid/AAF-7935-2020
OI Baaqeel, Hind/0000-0002-6343-6114; Zagrouba, Rachid/0000-0001-6165-3214
NR 18
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1812-0857
EI 2075-2245
BN 978-1-7281-8855-3
J9 INT ARAB CONF INF TE
PY 2020
PG 8
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BS0HU
UT WOS:000682789800029
DA 2022-04-17
ER

PT J
AU Walther, S
   Fuerst, A
AF Walther, Simon
   Fuerst, Axel
TI Reduced Data Volumes through Hybrid Machine Learning Compared to
   Conventional Machine Learning Demonstrated on Bearing Fault
   Classification
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE intelligent sensing and perception; wear; machine learning; machine
   condition monitoring; vibration and acoustics; bearings; deep learning;
   LSTM; fault classification
ID TOOL; DIAGNOSIS
AB In some real-world problems, machine learning is faced with little data due to limited resources such as sensors, time, and budget. In this case, the conventional machine learning approach may fail or perform badly. To develop a well-functioning model with a small training set the hybrid machine learning approach, the combination of different methods can be applied. Especially in the machine industry where Industry 4.0 is one of the most important topics-including condition monitoring, predictive maintenance, and automated data analyses-data are limited and costly. In this work, the conventional and hybrid approach are compared to the application of ball bearing fault classification. The dataset contains 12 different classes (11 with faults and 1 undamaged). For each approach, two different LSTM (Long Short-Term Memory) models are developed and trained on various training sets (different sensors). The hybrid model is realised by adding physical knowledge through applying fast Fourier transformation and frequency selection to the raw data. This study shows that the additional physical knowledge in the hybrid model results in a better performance of the hybrid machine learning than the conventional.
C1 [Walther, Simon; Fuerst, Axel] Bern Univ Appl Sci, Inst Intelligent Ind Syst I3S, Dept Engn & Informat Technol, Pestalozzistr 20, Bern, Switzerland.
RP Walther, S; Fuerst, A (corresponding author), Bern Univ Appl Sci, Inst Intelligent Ind Syst I3S, Dept Engn & Informat Technol, Pestalozzistr 20, Bern, Switzerland.
EM simon.walther@bfh.ch; axel.fuerst@bfh.ch
NR 17
TC 0
Z9 0
U1 0
U2 0
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD MAR
PY 2022
VL 12
IS 5
AR 2287
DI 10.3390/app12052287
PG 16
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Materials Science; Physics
GA ZS5CT
UT WOS:000768485000001
OA gold
DA 2022-04-17
ER

PT C
AU Zellinger, W
   Wieser, V
   Kumar, M
   Brunner, D
   Shepeleva, N
   Galvez, R
   Langer, J
   Fischer, L
   Moser, B
AF Zellinger, Werner
   Wieser, Volkmar
   Kumar, Mohit
   Brunner, David
   Shepeleva, Natalia
   Galvez, Rafa
   Langer, Josef
   Fischer, Lukas
   Moser, Bernhard
BE Longo, F
   Affenzeller, M
   Padovano, A
TI On confidentiality-critical machine learning applications in industry
SO PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INDUSTRY 4.0 AND
   SMART MANUFACTURING (ISM 2020)
SE Procedia Computer Science
LA English
DT Proceedings Paper
CT 2nd International Conference on Industry 4.0 and Smart Manufacturing
   (ISM)
CY NOV 23-25, 2020
CL ELECTR NETWORK
DE machine learning; federated learning; collaborative learning; transfer
   learning; smart manufacturing
ID MECHANISM
AB Federated machine learning frameworks, which take into account confidentiality of distributed data sources are of increasing interest in smart manufacturing. However, the scope of applicability of most such frameworks is restricted in industrial settings due to limitations in the assumptions on the data sources involved. In this work, first, we shed light on the nature of this arising gap between current federated learning and requirements in industrial settings. Our discussion aims at clarifying related notions in emerging sub-disciplines of machine learning, which are partially overlapping. Second, we envision a new confidentiality-preserving approach for smart manufacturing applications based on the more general setting of transfer learning, and envision its implementation in a module-based platform. (C) 2021 The Authors. Published by Elsevier B.V.
C1 [Zellinger, Werner; Wieser, Volkmar; Kumar, Mohit; Brunner, David; Shepeleva, Natalia; Fischer, Lukas; Moser, Bernhard] Software Competence Ctr Hagenberg GmbH SCCH, Softwarepk 21, A-4232 Hagenberg, Austria.
   [Kumar, Mohit] Univ Rostock, Fac Comp Sci & Elect Engn, Univ Pl 1, D-18051 Rostock, Germany.
   [Galvez, Rafa] Katholieke Univ Leuven, Comp Secur & Ind Cryptog, Oude Markt 13, B-3000 Leuven, Belgium.
   [Langer, Josef] Ventopay GmbH, Softwarepk 37, A-4232 Hagenberg, Austria.
RP Zellinger, W (corresponding author), Software Competence Ctr Hagenberg GmbH SCCH, Softwarepk 21, A-4232 Hagenberg, Austria.
EM werner.zellinger@scch.at
RI Fischer, Lukas/E-5573-2019
OI Fischer, Lukas/0000-0001-5303-6638; , Mohit/0000-0002-7368-5157
FU Federal Ministry for Climate Action, Environment, Energy, Mobility,
   Innovation and Technology (BMK); Federal Ministry for Digital and
   Economic Affairs (BMDW); Province of Upper Austria; project AutoQual-I;
   project PRIMAL
FX The research reported in this paper has been funded by the Federal
   Ministry for Climate Action, Environment, Energy, Mobility, Innovation
   and Technology (BMK), the Federal Ministry for Digital and Economic
   Affairs (BMDW), and the Province of Upper Austria in the frame of the
   COMET-Competence Centers for Excellent Technologies Programme and the
   COMET Module S3AI managed by Austrian Research Promotion Agency FFG. We
   further acknowledge the support of the projects AutoQual-I and PRIMAL.
NR 46
TC 1
Z9 1
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0509
J9 PROCEDIA COMPUT SCI
PY 2021
VL 180
BP 734
EP 743
DI 10.1016/j.procs.2021.01.296
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods; Engineering, Manufacturing
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BR5GC
UT WOS:000655006800080
OA gold
DA 2022-04-17
ER

PT J
AU Schubbach, A
AF Schubbach, Arno
TI Judging machines: philosophical aspects of deep learning
SO SYNTHESE
LA English
DT Article
DE Deep learning; Machine learning; Artificial intelligence; Algorithm;
   Computation; Judgment; Explanation; Justification; Kant
AB Although machine learning has been successful in recent years and is increasingly being deployed in the sciences, enterprises or administrations, it has rarely been discussed in philosophy beyond the philosophy of mathematics and machine learning. The present contribution addresses the resulting lack of conceptual tools for an epistemological discussion of machine learning by conceiving of deep learning networks as 'judging machines' and using the Kantian analysis of judgments for specifying the type of judgment they are capable of. At the center of the argument is the fact that the functionality of deep learning networks is established by training and cannot be explained and justified by reference to a predefined rule-based procedure. Instead, the computational process of a deep learning network is barely explainable and needs further justification, as is shown in reference to the current research literature. Thus, it requires a new form of justification, that is to be specified with the help of Kant's epistemology.
C1 [Schubbach, Arno] Swiss Fed Inst Technol, Dept Humanities Social & Polit Sci, Zurich, Switzerland.
RP Schubbach, A (corresponding author), Swiss Fed Inst Technol, Dept Humanities Social & Polit Sci, Zurich, Switzerland.
EM arno.schubbach@phil.gess.ethz.ch
FU Swiss National Science FoundationSwiss National Science Foundation
   (SNSF)European Commission [100012_165574/1]
FX Funding was provided by Swiss National Science Foundation (Grant No.
   100012_165574/1). Research project "Concepts and Practices of
   `Darstellung' in Philosophy, Chemistry and Painting around 1800".
NR 45
TC 7
Z9 7
U1 6
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0039-7857
EI 1573-0964
J9 SYNTHESE
JI Synthese
PD FEB
PY 2021
VL 198
IS 2
BP 1807
EP 1827
DI 10.1007/s11229-019-02167-z
PG 21
WC History & Philosophy Of Science; Philosophy
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC History & Philosophy of Science; Philosophy
GA QM6FI
UT WOS:000621872500041
OA Green Submitted
DA 2022-04-17
ER

PT C
AU Sheela, KG
   Varghese, AR
AF Sheela, Gnana K.
   Varghese, Anu Rose
TI Machine Learning based Health Monitoring System
SO MATERIALS TODAY-PROCEEDINGS
LA English
DT Proceedings Paper
CT International Multi-Conference on Computing, Communication, Electrical
   and Nanotechnology (I2CN)
CY APR 25-26, 2019
CL Ettumanoor, INDIA
DE Machine learning; Electrocardiogram; Health; Cloud; Arduino
AB The research work aim to develop a Smart Health Monitoring System with machine learning system.It allows physicians to monitor patients at a distance and take periodic actions in case of necessity. A set of five parameters has been identified i.e. Electrocardiogram (ECG), Pulse rate, Pressure, Temperature and Position detection by using wearable sensors. For this the system uses two circuits. The transmitting circuit which is with the patient and the receiver circuit which is being supervised by the doctor or nurse. The system helps to identify doctors for consulting and to identify and predict diseases based on machine learning algorithms. The result shows a webpage for live monitoring and sent message to the concerned doctor. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Sheela, Gnana K.; Varghese, Anu Rose] APJ Abdul Kalam Technol Univ, Dept ECE, Thiruvananthapuram, Kerala, India.
RP Varghese, AR (corresponding author), APJ Abdul Kalam Technol Univ, Dept ECE, Thiruvananthapuram, Kerala, India.
EM vargheseanurose@gmail.com
NR 10
TC 1
Z9 1
U1 4
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2214-7853
J9 MATER TODAY-PROC
JI Mater. Today-Proc.
PY 2020
VL 24
BP 1788
EP 1794
PN 3
PG 7
WC Materials Science, Multidisciplinary
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Materials Science
GA OF3ON
UT WOS:000581121700012
DA 2022-04-17
ER

PT C
AU Jemai, F
   Hayouni, M
   Baccar, S
AF Jemai, Fatma
   Hayouni, Mohamed
   Baccar, Sahbi
GP IEEE
TI Sentiment Analysis Using Machine Learning Algorithms
SO IWCMC 2021: 2021 17TH INTERNATIONAL WIRELESS COMMUNICATIONS & MOBILE
   COMPUTING CONFERENCE (IWCMC)
SE International Wireless Communications and Mobile Computing Conference
LA English
DT Proceedings Paper
CT 17th IEEE International Wireless Communications and Mobile Computing
   Conference (IEEE IWCMC)
CY JUN 28-JUL 02, 2021
CL ELECTR NETWORK
SP IEEE, IEEE Harbin Sect, IEEE Commun Soc Harbin Chapter, Huawei
DE Machine Learning (ML); NLTK; Sentiment analysis(SA)
AB This work aims at building a classifier able of predicting the polarity of a comment while using Machine Learning (ML) algorithms. Our work is essentially divided into three tasks: data extraction, processing and modelling. In order to build our model, we use the NLTK dataset. Then, we use text mining techniques to generate and process the variables. Based on a supervised probabilistic machine learning algorithm, we tended to create a classifier to classify our tweets into positive and negative sentiments then we opt for two experiments to evaluate the performance of our model. Compered to previous reported works, we achieve greater precision.
C1 [Jemai, Fatma] Univ Jendouba, Higher Inst Comp Sci KEF, Kef, Tunisia.
   [Hayouni, Mohamed] Univ Carthage, Innovcom Res Lab, Higher Sch Commun Sup Com, Ariana, Tunisia.
   [Baccar, Sahbi] CESI Grad Sch Engn, Rouen, France.
RP Jemai, F (corresponding author), Univ Jendouba, Higher Inst Comp Sci KEF, Kef, Tunisia.
EM jemai.fatma@isikef.u-jendouba.tn; mohamed.hayouni@supcom.rnu.tn;
   dr.sahbi.baccar@ieee.org
RI Baccar, Sahbi/ABG-3887-2021
NR 9
TC 0
Z9 0
U1 6
U2 6
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2376-6492
BN 978-1-7281-8616-0
J9 INT WIREL COMMUN
PY 2021
BP 775
EP 779
DI 10.1109/IWCMC51323.2021.9498965
PG 5
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Engineering, Electrical & Electronic; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Telecommunications
GA BS2VJ
UT WOS:000707024100141
DA 2022-04-17
ER

PT C
AU Zaytar, MA
   El Amrani, C
AF Zaytar, Mohamed Akram
   El Amrani, Chaker
BE Mohamed, B
   Abdelhakim, BA
   Said, R
   Dirss, LM
   Alaoui, EA
TI Machine Learning Methods for Air Quality Monitoring
SO 3RD INTERNATIONAL CONFERENCE ON NETWORKING, INFORMATION SYSTEM &
   SECURITY (NISS'20)
LA English
DT Proceedings Paper
CT 3rd International Conference on Networking, Information System and
   Security (NISS)
CY MAR 31-APR 02, 2020
CL Marrakech, MOROCCO
DE Air Quality; Remote Sensing; Internet of Things; Machine Learning; Deep
   Learning
ID NEURAL-NETWORK; POLLUTION; ARCHITECTURE; CLIMATE
AB Machine learning algorithms, and especially deep neural networks, provide universal estimator paradigms to approximate optimal solutions for arbitrary domain-specific problems. On the other hand, environmental-related problems that are a direct result of our rapidly changing climate are, nowadays, of the highest importance. Recently, the adoption of machine learning algorithms for environmental modeling has increased, especially in time series forecasting and computer vision. In this review, we attempt to provide a unified and systematic survey of the current machine learning algorithms used to solve multiple air quality monitoring tasks. We specifically focus on air quality modeling using satellite imagery and sensor device data. Lastly, we propose future directions with neural network modeling and representation learning.
C1 [Zaytar, Mohamed Akram; El Amrani, Chaker] Fac Sci & Technol Tangier, Tangier, Morocco.
RP Zaytar, MA (corresponding author), Fac Sci & Technol Tangier, Tangier, Morocco.
EM m.zaytar@uae.ac.ma; ch.elamrani@fstt.ac.ma
NR 51
TC 0
Z9 0
U1 3
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-7634-1
PY 2020
AR 25
DI 10.1145/3386723.3387835
PG 5
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Telecommunications
GA BR3WH
UT WOS:000649337600016
DA 2022-04-17
ER

PT C
AU Dotan, R
   Milli, S
AF Dotan, Ravit
   Milli, Smitha
GP Assoc Comp Machinery
TI Value-laden Disciplinary Shifts in Machine Learning
SO FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS,
   ACCOUNTABILITY, AND TRANSPARENCY
LA English
DT Proceedings Paper
CT ACM Conference on Fairness, Accountability, and Transparency (FAT)
CY JAN 27-30, 2020
CL Barcelona, SPAIN
SP Assoc Comp Machinery
DE philosophy of science; values in science; machine learning; deep
   learning
AB As machine learning models are increasingly used for high-stakes decision making, scholars have sought to intervene to ensure that such models do not encode undesirable social and political values. However, little attention thus far has been given to how values influence the machine learning discipline as a whole. How do values influence what the discipline focuses on and the way it develops? If undesirable values are at play at the level of the discipline, then intervening on particular models will not suffice to address the problem. Instead, interventions at the disciplinary-level are required.
   This paper analyzes the discipline of machine learning through the lens of philosophy of science. We develop a conceptual framework to evaluate the process through which types of machine learning models (e.g. neural networks, support vector machines, graphical models) become predominant. The rise and fall of model-types is often framed as objective progress. However, such disciplinary shifts are more nuanced. First, we argue that the rise of a model-type is self-reinforcing-it influences the way model-types are evaluated. For example, the rise of deep learning was entangled with a greater focus on evaluations in compute-rich and data-rich environments. Second, the way model-types are evaluated encodes loaded social and political values. For example, a greater focus on evaluations in compute-rich and data-rich environments encodes values about centralization of power, privacy, and environmental concerns.
C1 [Dotan, Ravit] Univ Calif Berkeley, Philosophy Dept, Berkeley, CA 94720 USA.
   [Milli, Smitha] Univ Calif Berkeley, Comp Sci Dept, Berkeley, CA 94720 USA.
RP Dotan, R (corresponding author), Univ Calif Berkeley, Philosophy Dept, Berkeley, CA 94720 USA.
EM ravit.dotan@berkeley.edu; smilli@berkeley.edu
NR 0
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6936-7
PY 2020
BP 294
EP 294
DI 10.1145/3351095.3373157
PG 1
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Ethics
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Social Sciences - Other Topics
GA BQ8FJ
UT WOS:000620151400002
DA 2022-04-17
ER

PT J
AU Yan, LJ
   Liu, YS
AF Yan, Lijuan
   Liu, Yanshen
TI An Ensemble Prediction Model for Potential Student Recommendation Using
   Machine Learning
SO SYMMETRY-BASEL
LA English
DT Article
DE ensemble; prediction model; student performance; machine learning
ID SUPPORT VECTOR MACHINES; ACADEMIC-PERFORMANCE
AB Student performance prediction has become a hot research topic. Most of the existing prediction models are built by a machine learning method. They are interested in prediction accuracy but pay less attention to interpretability. We propose a stacking ensemble model to predict and analyze student performance in academic competition. In this model, student performance is classified into two symmetrical categorical classes. To improve accuracy, three machine learning algorithms, including support vector machine (SVM), random forest, and AdaBoost are established in the first level and then integrated by logistic regression via stacking. A feature importance analysis was applied to identify important variables. The experimental data were collected from four academic years in Hankou University. According to comparative studies on five evaluation metrics (precision, recall, F1, error, and area under the receiver operating characteristic curve (AUC) in this analysis, the proposed model generally performs better than compared models. The important variables identified from the analysis are interpretable, they can be used as guidance to select potential students.
C1 [Yan, Lijuan; Liu, Yanshen] Cent China Normal Univ, Natl Engn Res Ctr E Learning, Wuhan 430079, Peoples R China.
   [Yan, Lijuan; Liu, Yanshen] Cent China Normal Univ, Hubei Res Ctr Educ Informationizat, Wuhan 430079, Peoples R China.
RP Yan, LJ (corresponding author), Cent China Normal Univ, Natl Engn Res Ctr E Learning, Wuhan 430079, Peoples R China.; Yan, LJ (corresponding author), Cent China Normal Univ, Hubei Res Ctr Educ Informationizat, Wuhan 430079, Peoples R China.
EM yanlijuan@mails.ccnu.edu.cn; yanshenliu@mail.ccnu.edu.cn
OI Yan, Lijuan/0000-0002-2889-4662
FU Educational Informatization Research Center of Hubei, Central China
   Normal University
FX The authors are grateful to the Educational Informatization Research
   Center of Hubei, Central China Normal University for providing financial
   support and good facilities. Additionally, they are thankful to Hankou
   University for providing the data.
NR 41
TC 5
Z9 5
U1 10
U2 18
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2073-8994
J9 SYMMETRY-BASEL
JI Symmetry-Basel
PD MAY
PY 2020
VL 12
IS 5
AR 728
DI 10.3390/sym12050728
PG 17
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Science & Technology - Other Topics
GA LY0PO
UT WOS:000540226400046
OA gold
DA 2022-04-17
ER

PT C
AU Zhang, ZJ
   Cai, YM
   Gong, WY
   Liu, XB
   Cai, ZH
AF Zhang, Zijia
   Cai, Yaoming
   Gong, Wenyin
   Liu, Xiaobo
   Cai, Zhihua
GP IEEE
TI Graph Convolutional Extreme Learning Machine
SO 2020 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
LA English
DT Proceedings Paper
CT International Joint Conference on Neural Networks (IJCNN) held as part
   of the IEEE World Congress on Computational Intelligence (IEEE WCCI)
CY JUL 19-24, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Computat Intelligence Soc, Int Neural Network Soc
DE Extreme Learning Machine; Graph Convolution Network; Semi-supervised
   Classification
ID ALGORITHM; SYSTEM
AB Extreme Learning Machine (ELM) has gained lots of research interest due to its universal approximation capability and fast learning speed. However, traditional ELMs are devised for regular Euclidean data, such as 2D grid and 1D sequence, and thus don't apply to non-Euclidean data, e.g., graph-structured data. To overcome this shortcoming, this paper presents a Graph Convolutional Extreme Learning Machine (termed as GCELM) for semi-supervised classification. Technically, a random graph convolutional layer is introduced to replace the random projection of original ELM, which endues ELM with the capability of dealing with graph-structured data directly. To generate a robust graph from the raw dataset, a self-representation model is adopted to construct a weighted graph. Extensive experiments on 27 UCI datasets demonstrate that GCELM outperforms many popular semi-supervised methods, and with faster learning speed. To the best of our knowledge, this is the first work that combines graph convolution with ELM.
C1 [Zhang, Zijia; Cai, Yaoming; Gong, Wenyin; Cai, Zhihua] China Univ Geosci, Sch Comp Sci, Wuhan, Peoples R China.
   [Liu, Xiaobo] China Univ Geosci, Sch Automat, Wuhan, Peoples R China.
   [Liu, Xiaobo] Hubei Key Lab Adv Control & Intelligent Automat C, Wuhan, Peoples R China.
RP Gong, WY (corresponding author), China Univ Geosci, Sch Comp Sci, Wuhan, Peoples R China.
EM zhangzijia@cug.edu.cn; caiyaom@cug.edu.cn; wygong@cug.edu.cn;
   zhcai@cug.edu.cn; xbliu@cug.edu.cn
OI Zhang, Zijia/0000-0001-9034-009X
FU National Natural Science Foundation of China (NSFC)National Natural
   Science Foundation of China (NSFC) [61573324, 61873328, 61973285];
   National Natural Science Fund for Distinguished Young Scholars of
   ChinaNational Natural Science Foundation of China (NSFC)National Science
   Fund for Distinguished Young Scholars [61525404]; Fundamental Research
   Founds for Central Universities, China University of Geosciences (Wuhan)
   [CUG160603, 1910491T06]
FX This work was supported in part by the National Natural Science
   Foundation of China (NSFC) under Grant Nos. 61573324, 61873328, and
   61973285, the National Natural Science Fund for Distinguished Young
   Scholars of China under Grant No. 61525404, and in part by the
   Fundamental Research Founds for Central Universities, China University
   of Geosciences (Wuhan) under Grant Nos. CUG160603 and 1910491T06.
NR 31
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2161-4393
BN 978-1-7281-6926-2
J9 IEEE IJCNN
PY 2020
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ9MM
UT WOS:000626021400058
DA 2022-04-17
ER

PT J
AU Du, PJ
   Bai, XY
   Tan, K
   Xue, ZH
   Samat, A
   Xia, JS
   Li, EZ
   Su, HJ
   Liu, W
AF Du, Peijun
   Bai, Xuyu
   Tan, Kun
   Xue, Zhaohui
   Samat, Alim
   Xia, Junshi
   Li, Erzhu
   Su, Hongjun
   Liu, Wei
TI Advances of Four Machine Learning Methods for Spatial Data Handling: a
   Review
SO JOURNAL OF GEOVISUALIZATION AND SPATIAL ANALYSIS
LA English
DT Review
DE Machine learning; Remote sensing image classification; Spatial
   interpolation; Support vector machine; Ensemble learning; Deep learning;
   Semi-supervised learning; Active learning
ID HYPERSPECTRAL IMAGE CLASSIFICATION; SUPPORT VECTOR MACHINES;
   CONVOLUTIONAL NEURAL-NETWORKS; REMOTE-SENSING IMAGES; SCENE
   CLASSIFICATION; FEATURE-SELECTION; WEIGHTED REGRESSION;
   FEATURE-EXTRACTION; ENSEMBLE; SVM
AB Most machine learning tasks can be categorized into classification or regression problems. Regression and classification models are normally used to extract useful geographic information from observed or measured spatial data, such as land cover classification, spatial interpolation, and quantitative parameter retrieval. This paper reviews the progress of four advanced machine learning methods for spatial data handling, namely, support vector machine (SVM)-based kernel learning, semi-supervised and active learning, ensemble learning, and deep learning. These four machine learning modes are representative because they improve learning performances from different views, for example, feature space transform and decision function (SVM), optimized uses of samples (semi-supervised and active learning), and enhanced learning models and capabilities (ensemble learning and deep learning). For spatial data handling via machine learning that can be improved by the four machine learning models, three key elements are learning algorithms, training samples, and input features. To apply machine learning methods to spatial data handling successfully, a four-level strategy is suggested: experimenting and evaluating the applicability, extending the algorithms by embedding spatial properties, optimizing the parameters for better performance, and enhancing the algorithm by multiple means. Firstly, the advances of SVM are reviewed to demonstrate the merits of novel machine learning methods for spatial data, running the line from direct use and comparison with traditional classifiers, and then targeted improvements to address multiple class problems, to optimize parameters of SVM, and to use spatial and spectral features. To overcome the limits of small-size training samples, semi-supervised learning and active learning methods are then utilized to deal with insufficient labeled samples, showing the potential of learning from small-size training samples. Furthermore, considering the poor generalization capacity and instability of machine learning algorithms, ensemble learning is introduced to integrate the advantages of multiple learners and to enhance the generalization capacity. The typical research lines, including the combination of multiple classifiers, advanced ensemble classifiers, and spatial interpolation, are presented. Finally, deep learning, one of the most popular branches of machine learning, is reviewed with specific examples for scene classification and urban structural type recognition from high-resolution remote sensing images. By this review, it can be concluded that machine learning methods are very effective for spatial data handling and have wide application potential in the big data era.
C1 [Du, Peijun; Bai, Xuyu] Nanjing Univ, Sch Geog & Ocean Sci, Nanjing 210023, Peoples R China.
   [Du, Peijun; Bai, Xuyu] Key Lab Land Satellite Remote Sensing Applicat, Minist Nat Resources China, Nanjing 210023, Peoples R China.
   [Du, Peijun; Bai, Xuyu] Jiangsu Ctr Collaborat Innovat Geog, Informat Resource Dev & Applicat, Nanjing 210023, Peoples R China.
   [Tan, Kun] East China Normal Univ, Minist Educ, Key Lab Geog Informat Sci, Shanghai 200241, Peoples R China.
   [Xue, Zhaohui; Su, Hongjun] Hohai Univ, Sch Earth Sci & Engn, Nanjing 211100, Peoples R China.
   [Samat, Alim] Chinese Acad Sci, Xinjiang Inst Ecol & Geog, State Key Lab Desert & Oasis Ecol, Urumqi 830011, Peoples R China.
   [Xia, Junshi] RIKEN Ctr Adv Intelligence Project, Tokyo 1030027, Japan.
   [Li, Erzhu; Liu, Wei] Jiangsu Normal Univ, Sch Geog, Geomat & Planning, Xuzhou 221116, Jiangsu, Peoples R China.
RP Du, PJ (corresponding author), Nanjing Univ, Sch Geog & Ocean Sci, Nanjing 210023, Peoples R China.; Du, PJ (corresponding author), Key Lab Land Satellite Remote Sensing Applicat, Minist Nat Resources China, Nanjing 210023, Peoples R China.; Du, PJ (corresponding author), Jiangsu Ctr Collaborat Innovat Geog, Informat Resource Dev & Applicat, Nanjing 210023, Peoples R China.
EM peijun@nju.edu.cn
RI Samat, Alim/H-5309-2019
OI Samat, Alim/0000-0002-9091-6033
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41631176]
FX This study is funded by the National Natural Science Foundation of China
   (Grant No. 41631176).
NR 144
TC 39
Z9 40
U1 27
U2 35
PU SPRINGERNATURE
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND
SN 2509-8810
EI 2509-8829
J9 J GEOVIS SPAT ANAL
JI J. Geovis. Spat. Anal.
PD JUN
PY 2020
VL 4
IS 1
AR 13
DI 10.1007/s41651-020-00048-5
PG 25
WC Environmental Sciences; Geography; Geography, Physical; Remote Sensing
WE Emerging Sources Citation Index (ESCI)
SC Environmental Sciences & Ecology; Geography; Physical Geography; Remote
   Sensing
GA TE8NX
UT WOS:000670264800013
DA 2022-04-17
ER

PT J
AU Mansor, N
   Sani, NS
   Aliff, M
AF Mansor, Norsuhada
   Sani, Nor Samsiah
   Aliff, Mohd
TI Machine Learning for Predicting Employee Attrition
SO INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS
LA English
DT Article
DE Artificial neural networks; decision tree; employee attrition; machine
   learning; support vector machines
AB Employee attrition has become a focus of researchers and human resources because of the effects of poor performance on organizations regardless of geography, industry, or size. In this context, the use of machine learning classification models to predict whether an employee is likely to quit could greatly increase the human resource department's ability to intervene on time and possibly provide a remedy to the situation to prevent attrition. This study is conducted with an objective to compare the performance machine learning techniques, namely, Decision Tree (DT) classifier, Support Vector Machines (SVM) classifier, and Artificial Neural Networks (ANN) classifier, and select the best model. These machine learning techniques are compared using the IBM Human Resource Analytic Employee Attrition and Performance dataset. Preprocessing steps for the dataset used in this comparative study include data exploration, data visualization, data cleaning and reduction, data transformation, discretization, and feature selection. In this study, parameter tuning and regularization techniques to overcome overfitting issues are applied for optimization purposes. The comparative study conducted on the three classifiers found that the optimized SVM model stood as the best model that can be used to predict employee attrition with the highest accuracy percentage of 88.87% as compared to the other classification models experimented with, followed by ANN and DT.
C1 [Mansor, Norsuhada; Sani, Nor Samsiah] Univ Kebangsaan Malaysia, Ctr Artificial Intelligence Technol, Fac Informat Sci & Technol, Bangi, Malaysia.
   [Aliff, Mohd] Univ Kuala Lumpur, Qual Engn Res Cluster, Instrumentat & Control Engn, Malaysian Inst Ind Technol, Johor Baharu, Malaysia.
RP Mansor, N (corresponding author), Univ Kebangsaan Malaysia, Ctr Artificial Intelligence Technol, Fac Informat Sci & Technol, Bangi, Malaysia.
RI Sani, Nor Samsiah/AAV-9808-2020
OI Sani, Nor Samsiah/0000-0001-5802-5946
NR 32
TC 0
Z9 0
U1 5
U2 5
PU SCIENCE & INFORMATION SAI ORGANIZATION LTD
PI WEST YORKSHIRE
PA 19 BOLLING RD, BRADFORD, WEST YORKSHIRE, 00000, ENGLAND
SN 2158-107X
EI 2156-5570
J9 INT J ADV COMPUT SC
JI Int. J. Adv. Comput. Sci. Appl.
PD NOV
PY 2021
VL 12
IS 11
BP 435
EP 445
PG 11
WC Computer Science, Theory & Methods
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YA9CB
UT WOS:000738621400048
DA 2022-04-17
ER

PT J
AU Mowbray, M
   Savage, T
   Wu, CF
   Song, ZQ
   Cho, BA
   Del Rio-Chanona, EA
   Zhang, DD
AF Mowbray, Max
   Savage, Thomas
   Wu, Chufan
   Song, Ziqi
   Cho, Bovinille Anye
   Del Rio-Chanona, Ehecatl A.
   Zhang, Dongda
TI Machine learning for biochemical engineering: A review
SO BIOCHEMICAL ENGINEERING JOURNAL
LA English
DT Review
DE Machine learning; Data-driven modelling; Biochemical engineering;
   Industrial biotechnology; Digitalisation; Digital twin
ID ARTIFICIAL NEURAL-NETWORK; MICROBIAL FUEL-CELL; METAL-ORGANIC
   FRAMEWORKS; SUPPORT VECTOR MACHINE; PRINCIPLES APPROACH;
   TREATMENT-PLANT; WASTE-WATER; PREDICTION; OPTIMIZATION; PERFORMANCE
AB The field of machine learning is comprised of techniques, which have proven powerful approaches to knowledge discovery and construction of 'digital twins' in the highly dimensional, nonlinear and stochastic domains common to biochemical engineering. We review the use of machine learning within biochemical engineering over the last 20 years. The most prevalent machine learning methods are demystified, and their impact across individual biochemical engineering subfields is outlined. In doing so we provide insights into the true benefits of each technique, and obstacles for their wider deployment. Finally, core challenges into the application of machine learning in biochemical engineering are thoroughly discussed, and further insight into adoption of innovative hybrid modelling and transfer learning strategies for development of new digital biotechnologies is provided.
C1 [Mowbray, Max; Savage, Thomas; Wu, Chufan; Song, Ziqi; Cho, Bovinille Anye; Zhang, Dongda] Univ Manchester, Dept Chem Engn & Analyt Sci, Oxford Rd, Manchester M1 3BU, Lancs, England.
   [Savage, Thomas] Univ Cambridge, Dept Chem Engn & Biotechnol, Philippa Fawcett Dr, Cambridge CB3 0AS, England.
   [Del Rio-Chanona, Ehecatl A.; Zhang, Dongda] Imperial Coll London, Dept Chem Engn, South Kensington SW7 2AZ, England.
RP Zhang, DD (corresponding author), Univ Manchester, Dept Chem Engn & Analyt Sci, Oxford Rd, Manchester M1 3BU, Lancs, England.
EM dongda.zhang@manchester.ac.uk
OI Anye Cho, Bovinille/0000-0001-9803-0520; Savage,
   Thomas/0000-0001-8715-8369; Mowbray, Max/0000-0003-1398-0469
NR 183
TC 7
Z9 7
U1 33
U2 52
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1369-703X
EI 1873-295X
J9 BIOCHEM ENG J
JI Biochem. Eng. J.
PD AUG
PY 2021
VL 172
AR 108054
DI 10.1016/j.bej.2021.108054
EA MAY 2021
PG 22
WC Biotechnology & Applied Microbiology; Engineering, Chemical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biotechnology & Applied Microbiology; Engineering
GA SL4AB
UT WOS:000656859400017
OA hybrid
DA 2022-04-17
ER

PT J
AU Ramirez, CMA
   Greenop, M
   Ashton, L
   Rehman, IU
AF Meza Ramirez, Carlos A.
   Greenop, Michael
   Ashton, Lorna
   Rehman, Ihtesham Ur
TI Applications of machine learning in spectroscopy
SO APPLIED SPECTROSCOPY REVIEWS
LA English
DT Review
DE Machine learning; chemometrics; artificial intelligence; data science;
   Infrared and Raman spectroscopy
AB The way to analyze data in spectroscopy has changed substantially. At the same time, data science has evolved to the point where spectroscopy can find space to be housed, adapted and be functional. The integration of the two sciences has introduced a knowledge gap between data scientists who know about advanced machine learning techniques and spectroscopists who have a solid background in chemometrics. To reach a symbiosis, the knowledge gap requires bridging. This review article focuses on introducing data science subjects to non-specialist spectroscopists, or those unfamiliar with the subject. The article will explain concepts that are covered in machine learning, such as supervised learning, unsupervised learning, deep learning, and most importantly, the difference between machine learning and artificial intelligence. This article also includes examples of published spectroscopy research, in which some of the concepts explained here are applied. Machine learning together with spectroscopy can provide a useful, fast, and efficient tool to analyze samples of interest both for industrial and research purposes.
C1 [Meza Ramirez, Carlos A.; Greenop, Michael; Rehman, Ihtesham Ur] Univ Lancaster, Engn Dept, Lancaster, England.
   [Ashton, Lorna] Univ Lancaster, Dept Chem, Lancaster, England.
RP Rehman, IU (corresponding author), Univ Lancaster, Engn Dept, Lancaster, England.
EM i.u.rehman@lancaster.ac.uk
OI Rehman, Ihtesham/0000-0003-2502-7608
FU Consejo Nacional de Ciencia y TecnologiaConsejo Nacional de Ciencia y
   Tecnologia (CONACyT)
FX This article was funded by Consejo Nacional de Ciencia y Tecnologia.
NR 117
TC 4
Z9 4
U1 36
U2 77
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0570-4928
EI 1520-569X
J9 APPL SPECTROSC REV
JI Appl. Spectrosc. Rev.
PD NOV 26
PY 2021
VL 56
IS 8-10
BP 733
EP 763
DI 10.1080/05704928.2020.1859525
EA DEC 2020
PG 31
WC Instruments & Instrumentation; Spectroscopy
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Instruments & Instrumentation; Spectroscopy
GA WT0HQ
UT WOS:000601374000001
OA Green Accepted
DA 2022-04-17
ER

PT J
AU Garg, A
   Mago, V
AF Garg, Arunim
   Mago, Vijay
TI Role of machine learning in medical research: A survey
SO COMPUTER SCIENCE REVIEW
LA English
DT Review
DE Medical research; Machine learning; Deep learning; Medical data
ID BIG DATA; NEURAL-NETWORKS; PROMISE; CNN; PERFORMANCE; PREDICTION; FUTURE
AB Machine learning is one of the essential and effective tools in analyzing highly complex medical data. With vast amounts of medical data being generated, there is an urgent need to effectively use this data to benefit the medical and health care sectors all across the world. This survey paper presents a systematic literature review for the investigation of various machine learning techniques used for numerous medical applications which are published in highly reputable venues in recent years. Considering only the recent work, we are able to survey the current machine learning and deep learning models that are being used for medical data. This literature review identifies a clear shift of artificial intelligence techniques used in the medical domain, with deep learning methods taking precedence over machine learning methods. (C) 2021 Elsevier Inc. All rights reserved.
C1 [Garg, Arunim; Mago, Vijay] Lakehead Univ, Dept Comp Sci, Thunder Bay, ON, Canada.
RP Mago, V (corresponding author), Lakehead Univ, Dept Comp Sci, Thunder Bay, ON, Canada.
EM vmago@lakeheadu.ca
FU DaTALab at Lakehead University; Lakehead University; CASES; NOAMA
   [RP-544 C-18-19]; NSERCNatural Sciences and Engineering Research Council
   of Canada (NSERC) [RGPIN/05377-2017]
FX The authors would like to extend their gratitude to the research team in
   the DaTALab at Lakehead University for their support; in particular,
   Abhijit Rao, Dhivya Chandrasekaran and Punardeep Sikka for their
   feedback and revisions on this publication. We would also like to thank
   Lakehead University, CASES, and the financial support from NOAMA RP-544
   C-18-19 and NSERC RGPIN/05377-2017.
NR 92
TC 9
Z9 9
U1 11
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1574-0137
EI 1876-7745
J9 COMPUT SCI REV
JI Comput. Sci. Rev.
PD MAY
PY 2021
VL 40
AR 100370
DI 10.1016/j.cosrev.2021.100370
EA FEB 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SL2ZV
UT WOS:000656789000001
DA 2022-04-17
ER

PT J
AU Diaz, I
AF Diaz, Ivan
TI Machine learning in the estimation of causal effects: targeted minimum
   loss-based estimation and double/debiased machine learning
SO BIOSTATISTICS
LA English
DT Article
DE Causal inference; Double/debiased machine learning; Machine learning;
   Targeted minimum loss-based estimation
ID INDIVIDUALIZED TREATMENT RULES; INFERENCE; SELECTION; LASSO
AB In recent decades, the fields of statistical and machine learning have seen a revolution in the development of data-adaptive regression methods that have optimal performance under flexible, sometimes minimal, assumptions on the true regression functions. These developments have impacted all areas of applied and theoretical statistics and have allowed data analysts to avoid the biases incurred under the pervasive practice of parametric model misspecification. In this commentary, I discuss issues around the use of data-adaptive regression in estimation of causal inference parameters. To ground ideas, I focus on two estimation approaches with roots in semi-parametric estimation theory: targeted minimum loss-based estimation (TMLE; van der Laan and Rubin, 2006) and double/debiased machine learning (DML; Chernozhukov and others, 2018). This commentary is not comprehensive, the literature on these topics is rich, and there are many subtleties and developments which I do not address. These two frameworks represent only a small fraction of an increasingly large number of methods for causal inference using machine learning. To my knowledge, they are the only methods grounded in statistical semi-parametric theory that also allow unrestricted use of data-adaptive regression techniques.
C1 [Diaz, Ivan] Weill Cornell Med, Div Biostat, 402 East 67th St, New York, NY 10065 USA.
RP Diaz, I (corresponding author), Weill Cornell Med, Div Biostat, 402 East 67th St, New York, NY 10065 USA.
EM ild2005@med.cornell.edu
RI Díaz, Iván/ABG-1090-2021
OI Díaz, Iván/0000-0001-9056-2047
NR 26
TC 12
Z9 13
U1 9
U2 16
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 1465-4644
EI 1468-4357
J9 BIOSTATISTICS
JI Biostatistics
PD APR
PY 2020
VL 21
IS 2
BP 353
EP 358
DI 10.1093/biostatistics/kxz042
PG 6
WC Mathematical & Computational Biology; Statistics & Probability
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Mathematical & Computational Biology; Mathematics
GA NG2RF
UT WOS:000563831700024
PM 31742333
OA Bronze
DA 2022-04-17
ER

PT J
AU Raghuwanshi, BS
   Shukla, S
AF Raghuwanshi, Bhagat Singh
   Shukla, Sanyam
TI SMOTE based class-specific extreme learning machine for imbalanced
   learning
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE SMOTE; Imbalanced learning; Class-specific extreme learning machine;
   Class-specific regularization; Classification
ID CLASSIFICATION; REGRESSION
AB Imbalanced learning is one of the substantial challenging problems in the field of data mining. The datasets that have skewed class distribution pose hindrance to conventional learning methods. Conventional learning methods give the same importance to all the samples. This leads to biased accuracy, which favors the majority classes. Several classifiers have been designed to tackle the class imbalance problems. Weighted kernel-based SMOTE (WKSMOTE) is a recently proposed method, which employs the minority oversampling in kernel space to tackle the class imbalance problem. Motivated by WKSMOTE, this work proposes a novel SMOTE based class-specific extreme learning machine (SMOTE-CSELM), a variant of class-specific extreme learning machine (CS-ELM), which exploits the benefit of both the minority oversampling and the class-specific regularization. For minority oversampling, this work uses synthetic minority oversampling technique (SMOTE). It increases the significance of the minority class samples for determining the decision region of the classifiers. The proposed method has comparable computational complexity than the weighted extreme learning machine (WELM) for imbalanced learning. The extensive experimental results evaluated on the real-world benchmark datasets demonstrate the efficacy of our proposed method. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Raghuwanshi, Bhagat Singh; Shukla, Sanyam] MANIT, Dept Comp Sci & Engn, Bhopal 462003, Madhya Pradesh, India.
RP Shukla, S (corresponding author), MANIT, Dept Comp Sci & Engn, Bhopal 462003, Madhya Pradesh, India.
EM bhagat.mnit@gmail.com; sanyamshukla@gmail.com
RI Raghuwanshi, Bhagat Singh/Y-2664-2019
OI Raghuwanshi, Bhagat Singh/0000-0002-3027-7831
NR 46
TC 34
Z9 34
U1 5
U2 35
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD JAN
PY 2020
VL 187
AR 104814
DI 10.1016/j.knosys.2019.06.022
PG 17
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU4NI
UT WOS:000501653900006
DA 2022-04-17
ER

PT J
AU Ismail, NA
   Idrus, SM
   Iqbal, F
   Zin, AM
   Atan, F
   Ali, N
AF Ismail, N. A.
   Idrus, S. M.
   Iqbal, F.
   Zin, A. M.
   Atan, F.
   Ali, N.
TI Machine Learning-Based Queueing Time Analysis in XGPON
SO INTERNATIONAL JOURNAL OF NANOELECTRONICS AND MATERIALS
LA English
DT Article
DE ANN; DBA; machine learning; queueing time; XGPON
ID DYNAMIC BANDWIDTH ALLOCATION; PASSIVE OPTICAL NETWORKS; MEAN PACKET
   DELAY
AB Machine learning has been a popular approach in predicting future demand. In optical access network, machine learning can best predict bandwidth demand so as to reduce delays. This paper presented a machine learning approach to learn queueing time in XGPON given the traffic load, number of frames and packet size. Queueing time contributes to upstream delay and therefore would improve the network performance. Output R acquired from the trained ANN is close to value 1. From the trained ANN, mean squared error (MSE) shows significantly low value and this proves that machine learning-based queueing time analysis offers another dimension of delay analysis on top of numerical analysis.
C1 [Ismail, N. A.; Idrus, S. M.; Iqbal, F.; Zin, A. M.; Atan, F.] Univ Teknol Malaysia, Sch Elect Engn, Skudai 81310, Johor, Malaysia.
   [Ismail, N. A.; Zin, A. M.; Atan, F.] Univ Teknol MARA, Coll Engn, Cawangan Johor 81750, Johor, Malaysia.
   [Ali, N.] Univ Malaysia Perlis, Fac Elect Engn Technol, Perlis 02600, Malaysia.
RP Idrus, SM (corresponding author), Univ Teknol Malaysia, Sch Elect Engn, Skudai 81310, Johor, Malaysia.
EM sevia@utm.my
RI Ali, Norshamsuri N. Ali/L-8205-2016
OI Ali, Norshamsuri N. Ali/0000-0002-9348-0714
FU Ministry of Education, MalaysiaMinistry of Education, Malaysia;
   Universiti Teknologi Malaysia [08G49, 01M62]; administration of the
   University of Technology Malaysia (UTM)
FX The authors acknowledge the financial support from Ministry of
   Education, Malaysia and the administration of the University of
   Technology Malaysia (UTM) and also supported by Universiti Teknologi
   Malaysia institutional grant 08G49 and 01M62.
NR 22
TC 0
Z9 0
U1 0
U2 0
PU UNIMAP PRESS
PI PERLIS
PA 1ST FLR BANGUNAN KWSP, JALAN BUKIT LAGI, KANGAR, PERLIS, 01000, MALAYSIA
SN 1985-5761
EI 2232-1535
J9 INT J NANOELECTRON M
JI Int. J. Nanoelectron. Mater.
PD DEC
PY 2021
VL 14
SI SI
BP 157
EP 163
PG 7
WC Materials Science, Multidisciplinary
WE Emerging Sources Citation Index (ESCI)
SC Materials Science
GA ZE9JG
UT WOS:000759192400018
DA 2022-04-17
ER

PT C
AU Wang, BP
   Wang, WN
   Zhu, LK
   Liu, WJ
AF Wang, Baoping
   Wang, Wennan
   Zhu, Linkai
   Liu, Wenjian
BE Zhou, W
   Mu, Y
TI Research on Cross-Project Software Defect Prediction Based on Machine
   Learning
SO ADVANCES IN WEB-BASED LEARNING - ICWL 2021
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 20th International Conference on Web-based Learning (ICWL)
CY NOV 13-14, 2021
CL City Univ Macau, Macau, PEOPLES R CHINA
HO City Univ Macau
DE Machine learning; Software defect prediction model; Metric
AB In recent years, machine learning technology has developed vigorously. The research on software defect prediction in the field of software engineering is increasingly adopting various algorithms of machine learning. This article has carried out a systematic literature review on the field of defect prediction. First, this article studies the development process of defect prediction, from correlation to prediction model. then this article studies the development process of cross-project defect prediction based on machine learning algorithms (naive Bayes, decision tree, random forest, neural network, etc.). Finally, this paper looks forward to the research difficulties and future directions of software defect prediction, such as imbalance in classification, cost of data labeling, and cross-project data distribution.
C1 [Wang, Baoping; Wang, Wennan; Zhu, Linkai; Liu, Wenjian] City Univ Macau, Fac Data Sci, Macau, Peoples R China.
   [Zhu, Linkai] Chinese Acad Sci, Inst Software, Beijing, Peoples R China.
   [Wang, Baoping] Beijing Huayuexun Technol Co Ltd, Beijing, Peoples R China.
RP Liu, WJ (corresponding author), City Univ Macau, Fac Data Sci, Macau, Peoples R China.
EM D19092105076@cityu.mo; wwwennan@zcst.edu.cn; linkai@iscas.ac.cn;
   andylau@cityu.mo
FU Macau Foundation [MF2012]
FX The work was supported by Macau Foundation, Project number: MF2012.
NR 20
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-90785-3; 978-3-030-90784-6
J9 LECT NOTES COMPUT SC
PY 2021
VL 13103
BP 160
EP 165
DI 10.1007/978-3-030-90785-3_16
PG 6
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory & Methods;
   Education & Educational Research; Education, Scientific Disciplines
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Education & Educational Research
GA BS7MD
UT WOS:000763918500016
DA 2022-04-17
ER

PT J
AU Ren, Y
   Xu, N
   Ling, MG
   Geng, X
AF Ren, Yi
   Xu, Ning
   Ling, Miaogen
   Geng, Xin
TI Label distribution for multimodal machine learning
SO FRONTIERS OF COMPUTER SCIENCE
LA English
DT Article
DE multimodal machine learning; label distribution learning; sentiment
   analysis; disease prediction
ID FUSION
AB Multimodal machine learning (MML) aims to understand the world from multiple related modalities. It has attracted much attention as multimodal data has become increasingly available in real-world application. It is shown that MML can perform better than single-modal machine learning, since multi-modalities containing more information which could complement each other. However, it is a key challenge to fuse the multi-modalities in MML. Different from previous work, we further consider the side-information, which reflects the situation and influences the fusion of multi-modalities. We recover multimodal label distribution (MLD) by leveraging the side-information, representing the degree to which each modality contributes to describing the instance. Accordingly, a novel framework named multimodal label distribution learning (MLDL) is proposed to recover the MLD, and fuse the multimodalities with its guidance to learn an in-depth understanding of the jointly feature representation. Moreover, two versions of MLDL are proposed to deal with the sequential data. Experiments on multimodal sentiment analysis and disease prediction show that the proposed approaches perform favorably against state-of-the-art methods.
C1 [Ren, Yi; Xu, Ning; Ling, Miaogen; Geng, Xin] Southeast Univ, Dept Comp Sci & Engn, Nanjing 211189, Peoples R China.
RP Geng, X (corresponding author), Southeast Univ, Dept Comp Sci & Engn, Nanjing 211189, Peoples R China.
EM xgeng@seu.edu.cn
RI Ling, Miaogen/AAZ-6950-2021
FU National Key Research and Development Plan of China [2018AAA0100104];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [62076063]; Fundamental Research Funds for
   the Central UniversitiesFundamental Research Funds for the Central
   Universities [2242021k30056]
FX This research was supported by the National Key Research and Development
   Plan of China (2018AAA0100104), the National Natural Science Foundation
   of China (Grant No.62076063), and the Fundamental Research Funds for the
   Central Universities (2242021k30056).
NR 46
TC 0
Z9 0
U1 34
U2 47
PU HIGHER EDUCATION PRESS
PI BEIJING
PA CHAOYANG DIST, 4, HUIXINDONGJIE, FUSHENG BLDG, BEIJING 100029, PEOPLES R
   CHINA
SN 2095-2228
EI 2095-2236
J9 FRONT COMPUT SCI-CHI
JI Front.. Comput. Sci.
PD FEB
PY 2022
VL 16
IS 1
AR 161306
DI 10.1007/s11704-021-0611-6
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UP1GB
UT WOS:000695131600004
DA 2022-04-17
ER

PT J
AU Deng, TC
   Li, YG
   Chen, JR
   Liu, X
   Wang, LH
AF Deng, Tianchi
   Li, Yingguang
   Chen, Jiarui
   Liu, Xu
   Wang, Lihui
TI Informed machine learning-based machining parameter planning for
   aircraft structural parts
SO INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY
LA English
DT Article
DE Aircraft structural parts; Machining parameter planning; Informed
   machine learning; Data driven
ID CUTTING PARAMETERS; OPTIMIZATION; SYSTEM
AB Aircraft structural parts are important and high-value parts used to constitute the frame of the aircraft, and are usually produced by NC machining, where the machining parameters are significant for the machining quality, efficiency, and cost. In the process planning, there are hundreds or even thousands of machining operations that require separate machining parameters, which is a huge task for the existing optimization-based methods that rely on iterative optimizations. Due to the complex structures and high requirements, the existing expert system-based methods require plenty of additional modifications. Recently, with the development of artificial intelligence, data-driven methods are used in machining parameter planning, which mines the knowledge and rules hidden in the historical data. However, the existing data-driven models require a large amount of training data and lack interpretability. To address this issue, this paper proposes an informed machine learning method for machining parameter planning, which introduces multiple prior constraints into the data-driven model. First, the part model is represented as an attribute graph, and the cutting area of each machining operation is correlated to a subgraph, which is used to obtain the vectorized representation of machining operation that covers cutting area and process information. Then, by fitting the mapping between the vectorized machining operation and the machining parameters, the knowledge and rules are learned. Next, to introduce prior constraints into the data-driven model, the constraint loss is designed and incorporated into the original loss function. The proposed method can generate machining parameters for all the machining operations in batch, thereby greatly reducing the human interactions. In the case study, the historical processing files of aircraft structural parts are used to train the proposed model for planning cutting width, cutting depth, spindle speed, and machining feedrate. The results show that the demand for training data is reduced and the prediction accuracy is improved with prior constraints.
C1 [Deng, Tianchi; Li, Yingguang; Chen, Jiarui] Nanjing Univ Aeronaut & Astronaut, Coll Mech & Elect Engn, Nanjing, Peoples R China.
   [Liu, Xu] Nanjing Tech Univ, Sch Mech & Power Engn, Nanjing, Peoples R China.
   [Wang, Lihui] KTH Royal Inst Technol, Dept Prod Engn, Stockholm, Sweden.
RP Li, YG (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Mech & Elect Engn, Nanjing, Peoples R China.
EM liyingguang@nuaa.edu.cn
RI Wang, Lihui/O-3907-2014
OI Wang, Lihui/0000-0001-8679-8049
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [51925505]
FX This research was funded by the National Natural Science Foundation of
   China (grant number: 51925505).
NR 28
TC 1
Z9 1
U1 13
U2 13
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0268-3768
EI 1433-3015
J9 INT J ADV MANUF TECH
JI Int. J. Adv. Manuf. Technol.
PD DEC
PY 2021
VL 117
IS 11-12
BP 3563
EP 3575
DI 10.1007/s00170-021-07861-2
EA AUG 2021
PG 13
WC Automation & Control Systems; Engineering, Manufacturing
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Engineering
GA WS1RP
UT WOS:000691711900002
DA 2022-04-17
ER

PT C
AU You, LX
AF You, Lexin
GP IEEE
TI Utilizing Machine Learning to Predict Happiness Index
SO 2021 2ND INTERNATIONAL CONFERENCE ON E-COMMERCE AND INTERNET TECHNOLOGY
   (ECIT 2021)
LA English
DT Proceedings Paper
CT 2nd International Conference on E-Commerce and Internet Technology
   (ECIT)
CY MAR 05-07, 2021
CL ELECTR NETWORK
DE Machine learning; Happiness Index
AB In recent years, machine learning has become an extremely popular topic in the technology domain. A significant number of researches are trying to adopt this technology to improve the efficiency of government services. We utilize machine learning to analyze the features related to the happiness index and to make some predictions. Using the obtained dataset of the survey that collects a random number of Chinese people's happiness index and asks relevant questions, we provide several algorithms to analyze the relationship between people's happiness index and the answers to the problems they have answered. We can make predictions in the new dataset approximately consistent with the actual values by utilizing the results. In our study, we gain some important features like income, education, and health. This paper provides some novel perspectives to improve service for e-governance.
C1 [You, Lexin] Frederick Gunn Sch, Washington, CT 06793 USA.
RP You, LX (corresponding author), Frederick Gunn Sch, Washington, CT 06793 USA.
EM 22youl@frederickgunn.org
NR 5
TC 0
Z9 0
U1 5
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
BN 978-1-6654-3873-5
PY 2021
BP 233
EP 238
DI 10.1109/ECIT52743.2021.00058
PG 6
WC Business; Computer Science, Interdisciplinary Applications; Management
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Business & Economics; Computer Science
GA BR8SG
UT WOS:000672805700051
DA 2022-04-17
ER

PT C
AU Sun, ZY
   Zhou, JL
AF Sun, Zhiying
   Zhou, Jinglin
BE Sun, M
   Zhang, H
TI L-1-PLS Based on Incremental Extreme Learning Machine
SO PROCEEDINGS OF 2020 IEEE 9TH DATA DRIVEN CONTROL AND LEARNING SYSTEMS
   CONFERENCE (DDCLS'20)
LA English
DT Proceedings Paper
CT 9th IEEE Data Driven Control and Learning Systems Conference (DDCLS)
CY NOV 20-22, 2020
CL Liuzhou, PEOPLES R CHINA
SP IEEE, Chinese Assoc Automat, Tech Comm Data Driven Control Learning & Optimizat, Beijing Jiaotong Univ, Qingdao Univ, Guangxi Univ Sci & Technol, IEEE Beijing Sect, IEEE Ind Elect Soc, IEEE Computat Intelligence Soc Beijing Chapter, Chinese Assoc Automat, DCLOD
DE Partial least-square method; Extreme Learning Machine; L-1 norm;
   Regression Analysis
ID REGRESSION
AB In order to improve the accuracy of the regression model, an L-1 norm partial least square method (IELM-L-1-PLS) based on an incremental limit learning machine is proposed. The data processing process of the incremental limit learning machine is nested into the framework based on the L-1 norm partial least square method, and the original data is upgraded by extracting the hidden node output matrix in the incremental limit learning machine, and then Regression analysis was performed on the upgraded data using L-1-PLS. This method is used for experimental verification of actual data. The results show that the L-1-PLS method based on the incremental limit learning machine can perform better regression analysis on the data.
C1 [Sun, Zhiying; Zhou, Jinglin] Beijing Univ Chem Technol, Coll Informat Sci & Technol, Beijing 100029, Peoples R China.
RP Sun, ZY (corresponding author), Beijing Univ Chem Technol, Coll Informat Sci & Technol, Beijing 100029, Peoples R China.
EM iamsunzhiying@163.com; jinglinzhou@mail.buct.edu.cn
FU NSFCNational Natural Science Foundation of China (NSFC) [61473025,
   61573050]; State Key Laboratory of Management and Control for Complex
   System at Institute of Automation, CAS [20160107]
FX This work was supported in part by NSFC (Grant No. 61473025, and
   61573050), the open-project grant funded by State Key Laboratory of
   Management and Control for Complex System at Institute of Automation,
   CAS (20160107).
NR 22
TC 0
Z9 0
U1 3
U2 3
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-5922-5
PY 2020
BP 947
EP 952
PG 6
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Automation & Control Systems; Computer Science
GA BR3OP
UT WOS:000648642100165
DA 2022-04-17
ER

PT J
AU Ji, XL
   Zhao, TK
   Zhao, X
   Lu, XF
   Li, TH
AF Ji, Xianglin
   Zhao, Tingkai
   Zhao, Xin
   Lu, Xufei
   Li, Tiehu
TI Triboelectric Nanogenerator Based Smart Electronics via Machine Learning
SO ADVANCED MATERIALS TECHNOLOGIES
LA English
DT Article
DE human machine interface; machine learning; smart electronics; support
   vector machine; triboelectric nanogenerator
ID GENERATOR; ENERGY
AB With the development of artificial intelligence, it is urgent to empower traditional electronics with the ability to "think," to "analyze," and to "advise." Here, a new product concept namely triboelectric nanogenerator (TENG) based smart electronics via the automatic machine learning data analysis algorithm is proposed. In this work, a simple water processing technique is used to fabricate porous polydimethylsiloxane, together with the weaving copper mesh, forming a high sensitivity flexible TENG. The as-prepared TENG presents high sensitivity for the voice signal and handwriting signal detection with approximate to 0.2 V amplitude in the common talking and writing condition. Three words' pronunciation are recorded and the ensemble method is used as the machine learning model for the voice signal recognition with a recognition accuracy of 93.3%. To further demonstrate the possibility of applying machine learning algorithm for automatic analysis and recognition, larger database is analyzed. Twenty-six letters' handwriting signals with total 520 samples are collected and a letter fingerprint library is established for further analysis. Hierarchical clustering and similarity matrix are used to study the intrinsic relationship between letters. "Medium Gaussian support vector machine" is used as machine learning model for the 26-letter fingerprint identification with recognition accuracy of 93.5%.
C1 [Ji, Xianglin; Zhao, Tingkai; Zhao, Xin; Lu, Xufei; Li, Tiehu] Northwestern Polytech Univ, Sch Mat Sci & Engn, NPU NCP Joint Int Res Ctr Adv Nanomat & Defects E, Shaanxi Engn Lab Graphene New Carbon Mat & Applic, Xian 710072, Peoples R China.
   [Ji, Xianglin] City Univ Hong Kong, Dept Biomed Engn, Kowloon, Hong Kong 999077, Peoples R China.
   [Zhao, Xin] Northwestern Polytech Univ, Queen Mary Univ London Engn Sch, Xian 710072, Peoples R China.
RP Ji, XL; Zhao, TK (corresponding author), Northwestern Polytech Univ, Sch Mat Sci & Engn, NPU NCP Joint Int Res Ctr Adv Nanomat & Defects E, Shaanxi Engn Lab Graphene New Carbon Mat & Applic, Xian 710072, Peoples R China.; Ji, XL (corresponding author), City Univ Hong Kong, Dept Biomed Engn, Kowloon, Hong Kong 999077, Peoples R China.
EM xiangliji3-c@my.cityu.edu; ztk@nwpu.edu.cn
RI Lu, Xufei/AAJ-9503-2020; xianglin, ji/AGV-9338-2022
OI xianglin, ji/0000-0002-4294-1592; Lu, Xufei/0000-0002-5829-385X
FU Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [51672221, 51872231]; Key Industrial Innovation Chain
   Project of Shaanxi Province [2018ZDCXL-GY-08-07]; Fundamental Research
   Funds for the Central UniversitiesFundamental Research Funds for the
   Central Universities; Seed Foundation of Innovation and Creation for
   Graduate Students in Northwestern Polytechnical University [Z2018006];
   National College Students Innovation and Entrepreneurship Training
   Program [201810699094]
FX This work was financially supported by the Natural Science Foundation of
   China (51672221, 51872231), the Key Industrial Innovation Chain Project
   of Shaanxi Province (2018ZDCXL-GY-08-07), the Fundamental Research Funds
   for the Central Universities, the Seed Foundation of Innovation and
   Creation for Graduate Students in Northwestern Polytechnical University
   (Z2018006), and National College Students Innovation and
   Entrepreneurship Training Program (201810699094).
NR 22
TC 11
Z9 10
U1 16
U2 56
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN, NJ 07030 USA
SN 2365-709X
J9 ADV MATER TECHNOL-US
JI Adv. Mater. Technol.
PD FEB
PY 2020
VL 5
IS 2
AR 1900921
DI 10.1002/admt.201900921
EA JAN 2020
PG 11
WC Materials Science, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Materials Science
GA KM7CE
UT WOS:000506257600001
DA 2022-04-17
ER

PT J
AU Cheng, JM
   Jin, H
AF Cheng, Jiaming
   Jin, Hui
TI An adaptive extreme learning machine based on an active learning method
   for structural reliability analysis
SO JOURNAL OF THE BRAZILIAN SOCIETY OF MECHANICAL SCIENCES AND ENGINEERING
LA English
DT Article
DE Extreme learning machine; Structural reliability analysis; Metamodel;
   Active learning
ID RADIAL BASIS FUNCTION; SAMPLING METHOD; SUBSET SIMULATION; VECTOR
   MACHINE; NEURAL-NETWORK; ALGORITHM; DESIGN; RBF
AB The metamodel-assisted reliability method opens a promising way to achieve efficient structural reliability assessment for structures with expensive-to-evaluate simulations. The advances in machine learning promote the development of the metamodel technique over the last decades. In this study, an active learning reliability method is presented by the combination of the extreme learning machine(ELM) and an efficient sequential sampling method with the framework of the Bayesian optimization theory. To determine the hyperparameters of ELM automatically, an adaptive extreme learning machine is introduced to approximate the performance function for reliability analysis. Furthermore, a novel active learning function inspired by the ensemble learning strategy is established to select the next best sample for approximation model refinement. Correspondingly, an effective stopping criterion on the cross-validation technique is built to terminate the active learning process timely. Four problems including numerical examples and practical engineering structures are analyzed. The test results show that the proposed method provides a satisfactory failure probability estimation with fewer performance function evaluations for these different reliability problems.
C1 [Cheng, Jiaming; Jin, Hui] Southeast Univ, Sch Civil Engn, Jiangsu Key Lab Engn Mech, Nanjing, Peoples R China.
RP Jin, H (corresponding author), Southeast Univ, Sch Civil Engn, Jiangsu Key Lab Engn Mech, Nanjing, Peoples R China.
EM jinhui@seu.edu.cn
NR 58
TC 0
Z9 0
U1 11
U2 11
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1678-5878
EI 1806-3691
J9 J BRAZ SOC MECH SCI
JI J. Braz. Soc. Mech. Sci. Eng.
PD DEC
PY 2021
VL 43
IS 12
AR 546
DI 10.1007/s40430-021-03257-1
PG 19
WC Engineering, Mechanical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA WZ3UF
UT WOS:000719895200001
DA 2022-04-17
ER

PT J
AU Stevens, L
   Kao, D
   Hall, J
   Gorg, C
   Abdo, K
   Linstead, E
AF Stevens, Laura
   Kao, David
   Hall, Jennifer
   Gorg, Carsten
   Abdo, Kaitlyn
   Linstead, Erik
TI ML-MEDIC: A Preliminary Study of an Interactive Visual Analysis Tool
   Facilitating Clinical Applications of Machine Learning for Precision
   Medicine
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE data science; interactive visual analysis; data-driven medicine; machine
   learning; cloud computing
AB Accessible interactive tools that integrate machine learning methods with clinical research and reduce the programming experience required are needed to move science forward. Here, we present Machine Learning for Medical Exploration and Data-Inspired Care (ML-MEDIC), a point-and-click, interactive tool with a visual interface for facilitating machine learning and statistical analyses in clinical research. We deployed ML-MEDIC in the American Heart Association (AHA) Precision Medicine Platform to provide secure internet access and facilitate collaboration. ML-MEDIC's efficacy for facilitating the adoption of machine learning was evaluated through two case studies in collaboration with clinical domain experts. A domain expert review was also conducted to obtain an impression of the usability and potential limitations.
C1 [Stevens, Laura; Kao, David; Gorg, Carsten] Univ Colorado, Dept Cardiol, Sch Med, Aurora, CO 80045 USA.
   [Hall, Jennifer] Amer Heart Assoc, Cardiovasc Med, Inst Precis Cardiovasc Med, Dallas, TX 75231 USA.
   [Abdo, Kaitlyn; Linstead, Erik] Chapman Univ, Elect Engn & Comp Sci, Orange, CA 92866 USA.
RP Linstead, E (corresponding author), Chapman Univ, Elect Engn & Comp Sci, Orange, CA 92866 USA.
EM laura.stevens@cuanschutz.edu; david.kao@cuanschutz.edu;
   Jennifer.Hall@heart.org; carsten.goerg@cuanschutz.edu;
   kabdo@chapman.edu; linstead@chapman.edu
RI Kao, David P/K-3288-2013
OI Kao, David P/0000-0002-2832-9348; Linstead, Erik/0000-0003-0174-7002;
   Gorg, Carsten/0000-0001-5088-4201
FU American Heart Association - Machine Learning and Assistive Technology
   Lab at Chapman University
FX L.M.S. was funded by a training grant from the American Heart
   Association. The APC for the paper was funded by the Machine Learning
   and Assistive Technology Lab at Chapman University.
NR 17
TC 0
Z9 0
U1 1
U2 2
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD MAY
PY 2020
VL 10
IS 9
AR 3309
DI 10.3390/app10093309
PG 12
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Materials Science; Physics
GA LR2RC
UT WOS:000535541900322
PM 33664984
OA gold, Green Published, Green Accepted
DA 2022-04-17
ER

PT J
AU Wang, P
   Gao, RX
AF Wang, Peng
   Gao, Robert X.
TI Transfer learning for enhanced machine fault diagnosis in manufacturing
SO CIRP ANNALS-MANUFACTURING TECHNOLOGY
LA English
DT Article
DE Machine learning; Modeling; Transfer learning
AB Given its demonstrated capability in pattern recognition, Deep Learning (DL) has been increasingly investigated for advanced manufacturing. One limiting factor for successful DL applications is the availability of sufficient amount of data of relevance to the specific application. A solution is presented in this paper for crossdomain data learning and effective network training, enabled by the generalization of the DL's feature learning capability, which is independent of the specific application domains. The developed method is experimentally verified by transferring a DL model trained by non-manufacturing data to manufacturing machine condition monitoring, and transferring model among different working conditions and machines. (C) 2020 CIRP. Published by Elsevier Ltd. All rights reserved.
C1 [Wang, Peng] Univ Kentucky, Dept Elect & Comp Engn, Lexington, KY USA.
   [Wang, Peng] Univ Kentucky, Dept Mech Engn, Lexington, KY 40506 USA.
   [Gao, Robert X.] Case Western Reserve Univ, Dept Mech & Aerosp Engn, Cleveland, OH 44106 USA.
RP Gao, RX (corresponding author), Case Western Reserve Univ, Dept Mech & Aerosp Engn, Cleveland, OH 44106 USA.
EM robert.gao@case.edu
RI Gao, Robert/O-9339-2014
OI Gao, Robert/0000-0003-3595-3728
FU US National Science FoundationNational Science Foundation (NSF)
   [CMMI-1830295]
FX This work was partially supported by the US National Science Foundation
   under award CMMI-1830295.
NR 15
TC 10
Z9 10
U1 5
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0007-8506
EI 1726-0604
J9 CIRP ANN-MANUF TECHN
JI CIRP Ann-Manuf. Technol.
PY 2020
VL 69
IS 1
BP 413
EP 416
DI 10.1016/j.cirp.2020.04.074
PG 4
WC Engineering, Industrial; Engineering, Manufacturing
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA OU5YK
UT WOS:000591604000036
OA Bronze
DA 2022-04-17
ER

PT C
AU Shastri, DJ
AF Shastri, Dvijesh J.
GP Assoc Comp Machinery
TI Machine Learning for Non-Programmers
SO CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS
   IN COMPUTING SYSTEMS
LA English
DT Proceedings Paper
CT ACM CHI Conference on Human Factors in Computing Systems (CHI)
CY APR 25-30, 2020
CL Honolulu, HI
SP ACM SIGCHI, Assoc Comp Machinery
DE Machine learning; open source machine learning and data visualization
   tool called Orange
AB Machine learning (ML) for data analysis have attracted the HCI community in the recent years. Multiple prebuilt ML libraries are available for popular programming languages such as R and Python to build and evaluate ML models. However, their usage demands good programming knowledge. The proposed course relaxes the need of programming by offering the model building via an open-source data mining tool called Orange. Orange features drag-and-drop functionality which enables ML developers to focus on model building rather than worrying about coding syntax. This course introduces the complete data mining pipeline with hands-on exercises on build and evaluating ML models.
C1 [Shastri, Dvijesh J.] Univ Houston Downtown, Houston, TX 77479 USA.
RP Shastri, DJ (corresponding author), Univ Houston Downtown, Houston, TX 77479 USA.
EM shastriD@uhd.edu
NR 2
TC 0
Z9 0
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6819-3
PY 2020
DI 10.1145/3334480.3375051
PG 3
WC Computer Science, Cybernetics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ9OG
UT WOS:000626317800029
DA 2022-04-17
ER

PT J
AU Hamim, T
   Benabbou, F
   Sael, N
AF Hamim, Touria
   Benabbou, Faouzia
   Sael, Nawal
TI Survey of Machine Learning Techniques for Student Profile Modelling
SO INTERNATIONAL JOURNAL OF EMERGING TECHNOLOGIES IN LEARNING
LA English
DT Article
DE Profile modelling; Student profile; Machine learning
ID PERFORMANCE; PREDICTION; ANALYTICS; PATTERNS; SYSTEM; ENGAGEMENT;
   FAILURE
AB Developments in information technology have led to the emergence of several online platforms for educational purposes, such as e-learning platforms, e-recommendation systems, e-recruitment system, etc. These systems exploit advances in Machine Learning to provide services tailored to the needs and profile of students. In this paper, we propose a state of art on student profile modelling using machine learning techniques during last four years. We aim to analyse the most used and most efficient machine learning techniques in both online and face-to-face education context, for different objectives such as failure, dropout, orientation, academic performance, etc. and also analyse the dominant features used for each objective in order to achieve a global view of the student profile model. Decision Tree is the most used and the most efficient by most of research studies. And academic, personal identity and online behaviour are the top characteristics used for the student profile. To strengthen the survey results, an experiment was carried out, based on the application of machine learning techniques extracted from the state of art analysis, on the same datasets. Decision tree gave the highest performance, which confirms the survey results.
C1 [Hamim, Touria; Benabbou, Faouzia; Sael, Nawal] Univ Hassan 2, Fac Sci Ben MSIK, Casablanca, Morocco.
RP Hamim, T (corresponding author), Univ Hassan 2, Fac Sci Ben MSIK, Casablanca, Morocco.
EM hamimxtouria@gmail.com; faouzia.benabbou@univh2c.ma;
   saelnawal@hotmail.com
RI faouzia, benabbou/ABC-2773-2021
OI NAWAL, SAEL/0000-0002-8134-3886
NR 56
TC 3
Z9 3
U1 10
U2 16
PU KASSEL UNIV PRESS GMBH
PI KASSEL
PA DIAGONALE 10, D-34127 KASSEL, GERMANY
EI 1863-0383
J9 INT J EMERG TECHNOL
JI Int. J. Emerg. Technol. Learn.
PY 2021
VL 16
IS 4
BP 136
EP 151
DI 10.3991/ijet.v16i04.18643
PG 16
WC Education & Educational Research
WE Emerging Sources Citation Index (ESCI)
SC Education & Educational Research
GA QQ1NX
UT WOS:000624294400010
OA gold
DA 2022-04-17
ER

PT J
AU Lu, NV
   Tansuchat, R
   Yuizono, T
   Huynh, VN
AF Nhat-Vinh Lu
   Tansuchat, Roengchai
   Yuizono, Takaya
   Van-Nam Huynh
TI Incorporating Active Learning into Machine Learning Techniques for
   Sensory Evaluation of Food
SO INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS
LA English
DT Article
DE Sensory evaluation of food; Active learning; Machine learning
ID ARTIFICIAL NEURAL-NETWORK; QUALITY; MODEL
AB The sensory evaluation of food quality using a machine learning approach provides a means of measuring the quality of food products. Thus, this type of evaluation may assist in improving the composition of foods and encouraging the development of new food products. However, human intervention has been often required in order to obtain labeled data for training machine learning models used in the evaluation process, which is time-consuming and costly. This paper aims at incorporating active learning into machine learning techniques to overcome this obstacle for sensory evaluation task. In particular, three algorithms are developed for sensory evaluation of wine quality. The first algorithm called Uncertainty Model (UCM) employs an uncertainty sampling approach, while the second algorithm called Combined Model (CBM) combines support vector machine with Density-Based Spatial Clustering of Applications with Noise (DBSCAN) algorithm, and both of which are aimed at selecting the most informative samples from a large dataset for labeling during the training process so as to enhance the performance of the classification models. The third algorithm called Noisy Model (NSM) is then proposed to deal with the noisy labels during the learning process. The empirical results showed that these algorithms can achieve higher accuracies in this classification task. Furthermore, they can be applied to optimize food ingredients and the consumer acceptance in real markets. (C) 2020 The Authors. Published by Atlantis Press SARL.
C1 [Nhat-Vinh Lu; Yuizono, Takaya; Van-Nam Huynh] Japan Adv Inst Sci & Technol, Nomi, Ishikawa, Japan.
   [Nhat-Vinh Lu] Ho Chi Minh City Univ Food Ind, Ho Chi Minh City, Vietnam.
   [Tansuchat, Roengchai] Chiang Mai Univ, Fac Econ, Chiang Mai, Thailand.
RP Huynh, VN (corresponding author), Japan Adv Inst Sci & Technol, Nomi, Ishikawa, Japan.
EM huynh@jaist.ac.jp
NR 23
TC 2
Z9 2
U1 10
U2 20
PU ATLANTIS PRESS
PI PARIS
PA 29 AVENUE LAUMIERE, PARIS, 75019, FRANCE
SN 1875-6891
EI 1875-6883
J9 INT J COMPUT INT SYS
JI Int. J. Comput. Intell. Syst.
PY 2020
VL 13
IS 1
BP 655
EP 662
DI 10.2991/ijcis.d.200525.001
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NI7MJ
UT WOS:000565532900017
OA gold
DA 2022-04-17
ER

PT C
AU Marin, I
   Goga, N
AF Marin, Iuliana
   Goga, Nicolae
BE Dascalu, MI
   Rysavy, O
   Bodea, CN
   Goldstein, M
   Dukic, M
TI Hypertension Detection based on Machine Learning
SO PROCEEDINGS OF THE 6TH CONFERENCE ON THE ENGINEERING OF COMPUTER BASED
   SYSTEMS (ECBS 2019)
LA English
DT Proceedings Paper
CT 6th Conference on the Engineering of Computer Based Systems (ECBS)
CY SEP 02-03, 2019
CL Bucharest, ROMANIA
SP FILS, Univ Politehnica Bucharest, FILS, ACM Special Interest Grp Appl Comp, Assoc Comp Machinery, Univ Politehnica Bucharest, Fac Engn Foreign Langauages, Assoc Romanian Elect Elect Engineers
DE Healthcare; Electronic system; Preeclampsia; Machine learning
ID BLOOD-PRESSURE; PREGNANCY; RISK; PREECLAMPSIA; MANAGEMENT; STATEMENT;
   DISEASE
AB The paper presents the occurrence of high blood pressure for three categories of persons, namely the normal population, patients with hypertension, and pregnant women with or without hypertension and preeclampsia in the context of a proposed healthcare system. The input data is public and it is provided by the Massachusetts University Amherst and National Health and Nutrition Survey. The data have been processed using four machine learning classifiers, namely Gaussian Naive Bayes, Logistic regression, Random Forest and Support Vector Machines. The criteria of the analysis are based on the absence or occurrence of hypertension, precision, recall, F1-score and population indicators. For the analyzed cases, the persons who did not present high blood pressure have been correctly detected, while half of the cases for which hypertension was present, proved to be true. As a conclusion, the automatic detection of healthcare parameters that exceed the allowed thresholds and are determined based on machine learning proves to be important for monitoring and prevention of critical health issues of the persons who belong to diverse categories.
C1 [Marin, Iuliana] Univ Politehn Bucuresti, Fac Engn Foreign Languages, Bucharest, Romania.
   [Goga, Nicolae] Univ Groningen, Mol Dynam Grp, Groningen, Netherlands.
RP Marin, I (corresponding author), Univ Politehn Bucuresti, Fac Engn Foreign Languages, Bucharest, Romania.
EM marin.iulliana25@gmail.com; n.goga@rug.nl
RI Marin, Iuliana I./A-5214-2019; Marin, Iuliana/ABD-5644-2021
OI Marin, Iuliana I./0000-0002-7508-1429; Marin,
   Iuliana/0000-0002-7508-1429
FU Romanian National Authority for Scientific Research and Innovation,
   CCCDI - UEFISCDIConsiliul National al Cercetarii Stiintifice
   (CNCS)Unitatea Executiva pentru Finantarea Invatamantului Superior, a
   Cercetarii, Dezvoltarii si Inovarii (UEFISCDI) [59/2017, E10871]
FX This work was funded by a grant of the Romanian National Authority for
   Scientific Research and Innovation, CCCDI - UEFISCDI, project number
   59/2017, Eurostars Project E10871, i-bracelet- "Inteligent bracelet for
   blood pressure monitoring and detection of preeclampsia".
NR 26
TC 1
Z9 1
U1 0
U2 6
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-7636-5
PY 2020
DI 10.1145/3352700.3352723
PG 4
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BO7PE
UT WOS:000525376600023
DA 2022-04-17
ER

PT J
AU Barnard, AS
   Opletal, G
AF Barnard, Amanda S.
   Opletal, George
TI Selecting machine learning models for metallic nanoparticles
SO NANO FUTURES
LA English
DT Article
DE machine learning; nanoparticles; metals; gold; simulation; modelling
ID PROTEIN CORONA
AB The outcome of machine learning is influenced by the features used to describe the data, and various metrics are used to measure model performance. In this study we use five different feature sets to describe the same 4000 gold nanoparticles, and 14 different machine learning methods to compare a total of 70 high scoring models. We then use classification and regression to show which meta-features of data sets or machine learning algorithms are important when making a selection. We find that number of features, and those that are strongly correlated, determine the class of model that should be used, but overall quality is almost entirely determined by the cross-validation score, regardless of the sophistication of the algorithm.
C1 [Barnard, Amanda S.] Australian Natl Univ, Res Sch Comp Sci, Acton, ACT 2601, Australia.
   [Opletal, George] CSIRO Data61, Docklands, Vic 3008, Australia.
RP Barnard, AS (corresponding author), Australian Natl Univ, Res Sch Comp Sci, Acton, ACT 2601, Australia.
EM amanda.s.barnard@anu.edu.au
RI Barnard, Amanda/A-7340-2011
OI Barnard, Amanda/0000-0002-4784-2382
NR 35
TC 7
Z9 7
U1 8
U2 20
PU IOP PUBLISHING LTD
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
EI 2399-1984
J9 NANO FUTURES
JI Nano Futures
PD SEP
PY 2020
VL 4
IS 3
AR 035003
DI 10.1088/2399-1984/ab9c3b
PG 11
WC Nanoscience & Nanotechnology; Materials Science, Multidisciplinary;
   Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics; Materials Science; Physics
GA MV9LP
UT WOS:000556670400001
DA 2022-04-17
ER

PT J
AU Kaming, N
   Dawid, A
   Kottmann, K
   Lewenstein, M
   Sengstock, K
   Dauphin, A
   Weitenberg, C
AF Kaeming, Niklas
   Dawid, Anna
   Kottmann, Korbinian
   Lewenstein, Maciej
   Sengstock, Klaus
   Dauphin, Alexandre
   Weitenberg, Christof
TI Unsupervised machine learning of topological phase transitions from
   experimental data
SO MACHINE LEARNING-SCIENCE AND TECHNOLOGY
LA English
DT Article
DE machine learning; unsupervised learning; topological matter; Floquet
   systems
ID QUANTUM; REALIZATION; MODEL
AB Identifying phase transitions is one of the key challenges in quantum many-body physics. Recently, machine learning methods have been shown to be an alternative way of localising phase boundaries from noisy and imperfect data without the knowledge of the order parameter. Here, we apply different unsupervised machine learning techniques, including anomaly detection and influence functions, to experimental data from ultracold atoms. In this way, we obtain the topological phase diagram of the Haldane model in a completely unbiased fashion. We show that these methods can successfully be applied to experimental data at finite temperatures and to the data of Floquet systems when post-processing the data to a single micromotion phase. Our work provides a benchmark for the unsupervised detection of new exotic phases in complex many-body systems.
C1 [Kaeming, Niklas; Sengstock, Klaus; Weitenberg, Christof] Univ Hamburg, ILP Inst Laserphys, Luruper Chaussee 149, D-22761 Hamburg, Germany.
   [Dawid, Anna] Univ Warsaw, Fac Phys, Pasteura 5, PL-02093 Warsaw, Poland.
   [Dawid, Anna; Kottmann, Korbinian; Lewenstein, Maciej; Dauphin, Alexandre] Barcelona Inst Sci & Technol, ICFO Inst Ciencies Foton, Av Carl Friedrich Gauss 3, Castelldefels 08860, Barcelona, Spain.
   [Lewenstein, Maciej] ICREA, Pg Lluis Campanys 23, Barcelona 08010, Spain.
   [Sengstock, Klaus; Weitenberg, Christof] Hamburg Ctr Ultrafast Imaging, Luruper Chaussee 149, D-22761 Hamburg, Germany.
   [Sengstock, Klaus] Univ Hamburg, ZOQ Zentrum Opt Quantentechnol, Luruper Chaussee 149, D-22761 Hamburg, Germany.
RP Weitenberg, C (corresponding author), Univ Hamburg, ILP Inst Laserphys, Luruper Chaussee 149, D-22761 Hamburg, Germany.; Weitenberg, C (corresponding author), Hamburg Ctr Ultrafast Imaging, Luruper Chaussee 149, D-22761 Hamburg, Germany.
EM christof.weitenberg@physnet.uni-hamburg.de
RI Dawid, Anna/B-5390-2019; Dauphin, Alexandre/P-5999-2014; Lewenstein,
   Maciej/I-1337-2014
OI Dawid, Anna/0000-0001-9498-1732; Dauphin, Alexandre/0000-0003-4996-2561;
   Kaming, Niklas/0000-0001-7926-5797; Lewenstein,
   Maciej/0000-0002-0210-7800
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)German
   Research Foundation (DFG) [FOR 2414, 277974659]; Cluster of Excellence
   'CUI: Advanced Imaging of Matter' [390715994, EXC 2056]; ERC AdG NOQIA,
   Agencia Estatal de Investigacion [CEX2019-000910-S,
   PID2019-106901GB-I00/10.13039/501100011033]; Fundacio Privada
   CellexFoundation CELLEX; Fundacio Mir-Puig; Generalitat de Catalunya
   (AGAUR)Agencia de Gestio D'Ajuts Universitaris de Recerca Agaur
   (AGAUR)Generalitat de Catalunya [2017 SGR 1341]; CERCA program
   [QuantumCAT_U16-011424]; ERDF Operational Program of Catalonia;
   MINECO-EU QUANTERA MAQS (State Research Agency (AEI))Spanish Government
   [PCI2019-111828-2/10.13039/501100011033]; EU Horizon 2020 FET-OPEN
   OPTOLogic [899794]; National Science Centre, Poland-SymfoniaNational
   Science Centre, Poland [2016/20/W/ST4/00314]; Marie Sklodowska-Curie
   grant STRETCH [101029393]; National Science Centre, PolandNational
   Science Centre, Poland [2019/33/N/ST2/03123, 2020/36/T/ST2/00588];
   Foundation for Polish ScienceFoundation for Polish ScienceEuropean
   Commission; EU Regional Development Fund; European UnionEuropean
   Commission [713729]; la Caixa FoundationLa Caixa Foundation [100010434,
   LCF/BQ/PR20/11770012]
FX The work in Hamburg was supported by the Deutsche Forschungsgemeinschaft
   (DFG, German Research Foundation) via Research Unit FOR 2414 under
   project number 277974659 and via the Cluster of Excellence 'CUI:
   Advanced Imaging of Matter'-EXC 2056-under project number 390715994.;
   ICFO group acknowledges support from ERC AdG NOQIA, Agencia Estatal de
   Investigacion ("Severo Ochoa" Center of Excellence CEX2019-000910-S,
   Plan National FIDEUA PID2019-106901GB-I00/10.13039/501100011033, FPI),
   Fundacio Privada Cellex, Fundacio Mir-Puig, and from Generalitat de
   Catalunya (AGAUR Grant No. 2017 SGR 1341, CERCA program, QuantumCAT
   _U16-011424, co-funded by ERDF Operational Program of Catalonia
   2014-2020), MINECO-EU QUANTERA MAQS (funded by State Research Agency
   (AEI) PCI2019-111828-2/10.13039/501100011033), EU Horizon 2020 FET-OPEN
   OPTOLogic (Grant No. 899794), and the National Science Centre,
   Poland-Symfonia Grant No. 2016/20/W/ST4/00314, Marie Sklodowska-Curie
   grant STRETCH No. 101029393.; An D acknowledges the financial support
   from the National Science Centre, Poland, within the Preludium Grant No.
   2019/33/N/ST2/03123 and the Etiuda Grant No. 2020/36/T/ST2/00588 as well
   as the Foundation for Polish Science within the First Team programme
   co-financed by the EU Regional Development Fund. This project has
   received funding from the European Union's Horizon 2020 research and
   innovation programme under the Marie Sklodowska-Curie Grant Agreement
   No. 713729 (K K). Al D acknowledges the financial support from a
   fellowship granted by la Caixa Foundation (ID 100010434, fellowship code
   LCF/BQ/PR20/11770012).
NR 106
TC 9
Z9 9
U1 6
U2 8
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
EI 2632-2153
J9 MACH LEARN-SCI TECHN
JI Mach. Learn.-Sci. Technol.
PD SEP
PY 2021
VL 2
IS 3
AR 035037
DI 10.1088/2632-2153/abffe7
PG 19
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Science & Technology - Other Topics
GA TL5WK
UT WOS:000674929500001
OA Green Submitted, gold
DA 2022-04-17
ER

PT C
AU Chung, MH
   Chignell, M
   Wang, L
   Jovicic, A
   Raman, A
AF Chung, Mu-Huan
   Chignell, Mark
   Wang, Lu
   Jovicic, Alexandra
   Raman, Abhay
GP IEEE
TI Interactive Machine Learning for Data Exfiltration Detection: Active
   Learning with Human Expertise
SO 2020 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS
   (SMC)
SE IEEE International Conference on Systems Man and Cybernetics Conference
   Proceedings
LA English
DT Proceedings Paper
CT IEEE International Conference on Systems, Man, and Cybernetics (SMC)
CY OCT 11-14, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Syst Man & Cybernet Soc, IEEE Brain, Intheon, Guger Technologies
DE Explainable AI; cybersecurity; interactive machine learning; active
   learning
ID AUTOMATION
AB Data exfiltration is a serious threat to organizations. Such exfiltrations cause breach events that can lead to millions of dollars of loss. Perimeter defense is not enough by itself since successful exploits from insiders can also be very damaging. Internal network user activities need to be monitored to detect malicious actions. Automatic machine learning methods can be applied for network anomaly detection, but they create a lot of false alarms. Domain experts can identify malicious users, but they are unable to process large volumes of data. Interactive machine learning (iML) deals with this tradeoff by creating an efficient collaboration between domain experts and machine learning algorithms. Previous research in iML has focused mainly on collaboration with non-experts. The design and requirements for expertise-driven iML have yet to be delineated for cybersecurity applications. In this research, we proposed an Active Learning (AL) model trained with outputs from a liberal (outputting many false alarms as well as possible hits) anomaly detection (AD) criterion to study expert-iML collaboration in anomaly detection. The results showed that: iML in this context can prune false alarms and minimize misses; the performance/compatibility tradeoff that typically occurs in conventional machine learning updates may be less salient in iML. We suggest that compatibility between experts and algorithms can be improved by presenting information about feature relevance during the training process.
C1 [Chung, Mu-Huan; Chignell, Mark; Wang, Lu] Univ Toronto, Mech & Ind Engn, Toronto, ON, Canada.
   [Jovicic, Alexandra; Raman, Abhay] Sun Life Financial Inc, Enterprise Serv, Toronto, ON, Canada.
RP Chung, MH (corresponding author), Univ Toronto, Mech & Ind Engn, Toronto, ON, Canada.
EM mhmchung@mie.utoronto.ca; abhay.raman@sunlife.com
NR 31
TC 1
Z9 1
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1062-922X
BN 978-1-7281-8526-2
J9 IEEE SYS MAN CYBERN
PY 2020
BP 280
EP 287
PG 8
WC Computer Science, Cybernetics; Computer Science, Information Systems
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS1DD
UT WOS:000687430600044
DA 2022-04-17
ER

PT J
AU Zhu, LL
   Spachos, P
   Pensini, E
   Plataniotis, KN
AF Zhu, Lili
   Spachos, Petros
   Pensini, Erica
   Plataniotis, Konstantinos N.
TI Deep learning and machine vision for food processing: A survey
SO CURRENT RESEARCH IN FOOD SCIENCE
LA English
DT Article
DE Food processing; Machine vision; Image processing; Machine learning;
   Deep learning
ID SOLUBLE SOLIDS CONTENT; COMPUTER VISION; NONDESTRUCTIVE PREDICTION;
   INFRARED THERMOGRAPHY; AUTOMATIC DETECTION; QUALITY ASSESSMENT; FOREIGN
   OBJECTS; NEURAL-NETWORKS; IMAGE-ANALYSIS; K-MEANS
AB The quality and safety of food is an important issue to the whole society, since it is at the basis of human health, social development and stability. Ensuring food quality and safety is a complex process, and all stages of food processing must be considered, from cultivating, harvesting and storage to preparation and consumption. However, these processes are often labour-intensive. Nowadays, the development of machine vision can greatly assist researchers and industries in improving the efficiency of food processing. As a result, machine vision has been widely used in all aspects of food processing. At the same time, image processing is an important component of machine vision. Image processing can take advantage of machine learning and deep learning models to effectively identify the type and quality of food. Subsequently, follow-up design in the machine vision system can address tasks such as food grading, detecting locations of defective spots or foreign objects, and removing impurities. In this paper, we provide an overview on the traditional machine learning and deep learning methods, as well as the machine vision techniques that can be applied to the field of food processing. We present the current approaches and challenges, and the future trends.
C1 [Zhu, Lili; Spachos, Petros; Pensini, Erica] Univ Guelph, Sch Engn, Guelph, ON N1G 2W1, Canada.
   [Plataniotis, Konstantinos N.] Univ Toronto, Dept Elect & Comp Engn, Toronto, ON M5S 3G4, Canada.
RP Spachos, P (corresponding author), Univ Guelph, Sch Engn, Guelph, ON N1G 2W1, Canada.
EM petros@uoguelph.ca
FU Natural Sciences and Engineering Research Council of CanadaNatural
   Sciences and Engineering Research Council of Canada (NSERC)CGIAR
   [RGPIN/2016-04007]
FX This work was supported by the Natural Sciences and Engineering Research
   Council of Canada under Grant RGPIN/2016-04007.
NR 138
TC 11
Z9 13
U1 38
U2 49
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
EI 2665-9271
J9 CURR RES FOOD SCI
JI Curr. Res. Food Sci.
PY 2021
VL 4
BP 233
EP 249
DI 10.1016/j.crfs.2021.03.009
EA APR 2021
PG 17
WC Food Science & Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Food Science & Technology
GA XP9AJ
UT WOS:000731150400024
PM 33937871
OA gold, Green Published, Green Submitted
DA 2022-04-17
ER

PT C
AU Sukumar, D
   Zhang, J
   Tao, XH
   Wang, X
   Zhang, WB
AF Sukumar, Divya
   Zhang, Ji
   Tao, Xiaohui
   Wang, Xin
   Zhang, Wenbin
BE Webb, G
   Zhang, Z
   Tseng, VS
   Williams, G
   Vlachos, M
   Cao, L
TI Predicting Workplace Injuries Using Machine Learning Algorithms
SO 2020 IEEE 7TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND ADVANCED
   ANALYTICS (DSAA 2020)
SE Proceedings of the International Conference on Data Science and Advanced
   Analytics
LA English
DT Proceedings Paper
CT 7th IEEE International Conference on Data Science and Advanced Analytics
   (DSAA)
CY OCT 06-09, 2020
CL Univ Technol Sydney, ELECTR NETWORK
SP IEEE, IEEE Comp Soc, IEEE Computat Intelligence Soc, Amer Stat Assoc, Assoc Comp Machinery, ACM SIGKDD, China Comp Confederat, Macquarie Univ, Monash Univ, Business Events Sydney
HO Univ Technol Sydney
DE predictive modeling; machine learning; model performance
AB Predicting workplace injury using automated techniques opens newer possibilities in evidence-based research.This paper presents our preliminary research in a PhD project in predicting workplace incidents using machine learning algorithms. The analysis on the model performance using several mainstream machine learning algorithms including random forest, k-nearest neighbor and decision tree indicated that the general performance of the decision tree model was found to be statistically higher than that of the other two algorithms.
C1 [Sukumar, Divya; Zhang, Ji; Tao, Xiaohui] Univ Southern Queensland, Toowoomba, Qld, Australia.
   [Zhang, Ji] Zhejiang Lab, Hangzhou, Zhejiang, Peoples R China.
   [Wang, Xin] Southwest Petr Univ, Chengdu, Sichuan, Peoples R China.
   [Zhang, Wenbin] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
RP Zhang, J (corresponding author), Univ Southern Queensland, Toowoomba, Qld, Australia.; Zhang, J (corresponding author), Zhejiang Lab, Hangzhou, Zhejiang, Peoples R China.
FU open research grant of Shanxi Software Engineering Technology Research
   Center [2020009]
FX This work is partially supported by the open research grant of Shanxi
   Software Engineering Technology Research Center (No. 2020009).
NR 7
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
SN 2472-1573
BN 978-1-7281-8206-3
J9 PR INT CONF DATA SC
PY 2020
BP 763
EP 764
DI 10.1109/DSAA49011.2020.00104
PG 2
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Interdisciplinary Applications; Operations
   Research & Management Science; Mathematics, Applied
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Operations Research & Management Science; Mathematics
GA BR3QC
UT WOS:000648720100093
DA 2022-04-17
ER

PT C
AU Weber, T
   Winiker, C
   Hussmann, H
AF Weber, Thomas
   Winiker, Christina
   Hussmann, Heinrich
GP ACM
TI A Closer Look at Machine Learning Code
SO EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN
   COMPUTING SYSTEMS (CHI'21)
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems
CY MAY 08-13, 2021
CL ELECTR NETWORK
SP ACM SIGCHI, Assoc Comp Machinery, Bloomberg, Facebook, Google, Kyocera, Microsoft, Monash Univ, Verizon Media
DE machine learning; code reading; eye tracking
ID ARTIFICIAL-INTELLIGENCE; MEDICINE; AI
AB Software using Machine Learning algorithms is becoming ever more ubiquitous making it equally important to have good development processes and practices. Whether we can apply insights from software development research remains open though, since it is not yet clear, whether data-driven development has the same requirements as its traditional counterpart. We used eye tracking to investigate whether the code reading behaviour of developers differs between code that uses Machine Learning and code that does not. Our data shows that there are differences in what parts of the code people consider of interest and how they read it. This is a consequence of differences in both syntax and semantics of the code. This reading behaviour already shows that we cannot take existing solutions as universally applicable. In the future, methods that support Machine Learning must iterate on existing knowledge to meet the challenges of data-driven development.
C1 [Weber, Thomas; Winiker, Christina; Hussmann, Heinrich] Ludwig Maximilians Univ Munchen, Munich, Germany.
RP Weber, T (corresponding author), Ludwig Maximilians Univ Munchen, Munich, Germany.
EM thomas.weber@ifi.lmu.de; christina.winiker@stud.ifi.lmu.de;
   hussmann@ifi.lmu.de
NR 42
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-8095-9
PY 2021
DI 10.1145/3411763.3451679
PG 6
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS7DM
UT WOS:000759178501161
DA 2022-04-17
ER

PT J
AU Chen, F
   Wan, H
   Cai, H
   Cheng, G
AF Chen, Fang
   Wan, Hong
   Cai, Hua
   Cheng, Guang
TI Machine learning in/for blockchain: Future and challenges
SO CANADIAN JOURNAL OF STATISTICS-REVUE CANADIENNE DE STATISTIQUE
LA English
DT Article
DE Bitcoin; blockchain; deep learning; machine learning; reinforcement
   learning
ID HEALTH-CARE; TECHNOLOGY
AB Machine learning and blockchain are two of the most notable technologies of recent years. The first is the foundation of artificial intelligence and big data analysis, and the second has significantly disrupted the financial industry. Both technologies are data-driven, and thus there are rapidly growing interests in integrating both for more secure and efficient data sharing and analysis. In this article, we review existing research on combining machine learning and blockchain technologies and demonstrate that they can collaborate efficiently and effectively. In the end, we point out some future directions and expect more research on deeper integration of these two promising technologies.
C1 [Chen, Fang; Cai, Hua] Purdue Univ, Dept Ind Engn, W Lafayette, IN 47906 USA.
   [Wan, Hong] North Carolina State Univ, Dept Ind & Syst Engn, Raleigh, NC 27695 USA.
   [Cheng, Guang] Purdue Univ, Dept Stat, W Lafayette, IN 47906 USA.
RP Cheng, G (corresponding author), Purdue Univ, Dept Stat, W Lafayette, IN 47906 USA.
EM chengg@purdue.edu
FU National Science FoundationNational Science Foundation (NSF) [NSF
   DMS-1712907, DMS-1811812, DMS-1821183]; Office of Naval ResearchOffice
   of Naval Research [ONR N00014-18-2759]
FX Guang Cheng gratefully acknowledges the support of National Science
   Foundation (NSF DMS-1712907, DMS-1811812, DMS-1821183), and the Office
   of Naval Research (ONR N00014-18-2759).
NR 62
TC 1
Z9 1
U1 17
U2 29
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0319-5724
EI 1708-945X
J9 CAN J STAT
JI Can. J. Stat.-Rev. Can. Stat.
PD DEC
PY 2021
VL 49
IS 4
BP 1364
EP 1382
DI 10.1002/cjs.11623
EA JUN 2021
PG 19
WC Statistics & Probability
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Mathematics
GA XC7XR
UT WOS:000658046200001
OA Green Submitted
DA 2022-04-17
ER

PT C
AU Fields, MP
   Bennett, H
   Scoggins, R
AF Fields, Morris P.
   Bennett, Hollis
   Scoggins, Randy
BE Pham, T
   Solomon, L
TI Machine Learning for Source Classification Utilizing Infrasound Data
SO ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING FOR MULTI-DOMAIN OPERATIONS
   APPLICATIONS III
SE Proceedings of SPIE
LA English
DT Proceedings Paper
CT Conference on Artificial Intelligence and Machine Learning for
   Multi-Domain Operations Applications III
CY APR 12-16, 2021
CL ELECTR NETWORK
SP SPIE
DE Infrasound; Signal processing; Machine learning; Short-term Fourier
   transform; Power Spectrum Density; Gaussian Mixture Modeling; Support
   Vector Machines
AB An awareness of activities in operational environments is key to the U.S. Army's strategy and many sensors and spectral regimes are employed to this end. Advances in wide-spectrum acoustic sensors and compact high performance computational hardware have created opportunities for enhancing awareness. The Engineer Research and Development Center (ERDC) is researching infrasound sensing as a means of persistent, remote monitoring to provide battlefield a wareness. Machine learning techniques are used to identify unique signatures in the battle-space's infrasonic environment. Given the limited number of labeled data sets, unsupervised Gaussian Mixture Modeling (GMM) is applied to identify these signatures utilizing the Short-term Fourier transform (STFT) and resulting Power Spectrum Density (PSD). This study describes the process of sorting collected infrasound data into categories based on PSDs for application to GMM algorithms that identify a characteristic class labeling. Labels in relatively short time frames are then associated with features seen throughout a 24 hour cycle to produce synthetic samples. Several Support Vector Machines are trained and used to separate in-class verses outlier features in time segments of new data. Outlier counts exceeding a threshold, typically 50%, label new data segments as novel and subject to further processing. Finally, efforts a redescribed for directional focusing the array using multiple elements/sensors to localize signatures or to emphasize the signatures from different directions. GPU accelerations will be applied wherever possible to improve local bandwidth and throughput. Distribution Statement A = Unlimited distribution/public domain
C1 [Fields, Morris P.; Bennett, Hollis] US Army Engineer Res & Dev Ctr, 3909 Halls Ferry Rd, Vicksburg, MS 39180 USA.
   [Scoggins, Randy] SOL Engn Serv, Jackson, MS USA.
RP Fields, MP (corresponding author), US Army Engineer Res & Dev Ctr, 3909 Halls Ferry Rd, Vicksburg, MS 39180 USA.
EM morris.p.fields@usace.army.mil
NR 11
TC 0
Z9 0
U1 1
U2 1
PU SPIE-INT SOC OPTICAL ENGINEERING
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA
SN 0277-786X
EI 1996-756X
BN 978-1-5106-4330-7
J9 PROC SPIE
PY 2021
VL 11746
AR 117462N
DI 10.1117/12.2585847
PG 10
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA BS2PQ
UT WOS:000705912400062
DA 2022-04-17
ER

PT J
AU Bao, YQ
   Li, H
AF Bao, Yuequan
   Li, Hui
TI Machine learning paradigm for structural health monitoring
SO STRUCTURAL HEALTH MONITORING-AN INTERNATIONAL JOURNAL
LA English
DT Article
DE Structural health monitoring; machine learning; deep learning; computer
   vision; artificial intelligence
ID INDEPENDENT COMPONENT ANALYSIS; FIELD VIBRATION MODES; CIVIL
   INFRASTRUCTURE; MODAL IDENTIFICATION; FULL-FIELD; BLIND IDENTIFICATION;
   VIDEO MEASUREMENTS; COMPUTER VISION; BRIDGE; SYSTEM
AB Structural health diagnosis and prognosis is the goal of structural health monitoring. Vibration-based structural health monitoring methodology has been extensively investigated. However, the conventional vibration-based methods find it difficult to detect damages of actual structures because of a high incompleteness in the monitoring information (the number of sensors is much fewer with respect to the number of degrees of freedom of a structure), intense uncertainties in the structural conditions and monitoring systems, and coupled effects of damage and environmental actions on modal parameters. It is a truth that the performance and conditions of a structure must be embedded in the monitoring data (vehicles, wind, etc.; acceleration, displacement, cable force, strain, images, videos, etc.). Therefore, there is a need to develop completely novel structural health diagnosis and prognosis methodology based on the various monitoring data. Machine learning provides the advanced mathematical frameworks and algorithms that can help discover and model the performance and conditions of a structure through deep mining of monitoring data. Thus, machine learning takes an opportunity to establish novel machine learning paradigm for structural health diagnosis and prognosis theory termed the machine learning paradigm for structural health monitoring. This article sheds light on principles for machine learning paradigm for structural health monitoring with some examples and reviews the existing challenges and open questions in this field.
C1 [Bao, Yuequan; Li, Hui] Harbin Inst Technol, Minist Ind & Informat Technol, Key Lab Smart Prevent & Mitigat Civil Engn Disast, Harbin 150090, Peoples R China.
   [Bao, Yuequan; Li, Hui] Harbin Inst Technol, Sch Civil Engn, 202 Haihe Rd, Harbin 150090, Peoples R China.
RP Li, H (corresponding author), Harbin Inst Technol, Sch Civil Engn, 202 Haihe Rd, Harbin 150090, Peoples R China.
EM lihui@hit.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [51638007, 51921006, U1711265, 51378154,
   51678203, 51978216]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This
   research was supported by grants from the National Natural Science
   Foundation of China (Grant Nos 51638007, 51921006, U1711265, 51378154,
   51678203, and 51978216).
NR 104
TC 0
Z9 0
U1 74
U2 100
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1475-9217
EI 1741-3168
J9 STRUCT HEALTH MONIT
JI Struct. Health Monit.
PD JUL
PY 2021
VL 20
IS 4
SI SI
BP 1353
EP 1372
AR 1475921720972416
DI 10.1177/1475921720972416
EA NOV 2020
PG 20
WC Engineering, Multidisciplinary; Instruments & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Instruments & Instrumentation
GA TB2RY
UT WOS:000654535500001
DA 2022-04-17
ER

PT C
AU Botari, T
   Izbicki, R
   De Carvalho, ACPLF
AF Botari, Tiago
   Izbicki, Rafael
   de Carvalho, Andre C. P. L. F.
BE Cellier, P
   Driessens, K
TI Local Interpretation Methods to Machine Learning Using the Domain of the
   Feature Space
SO MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES, ECML PKDD 2019,
   PT I
SE Communications in Computer and Information Science
LA English
DT Proceedings Paper
CT European Conference on Machine Learning and Principles and Practice of
   Knowledge Discovery in Databases (ECML PKDD)
CY SEP 16-20, 2019
CL Wurzburg, GERMANY
SP Bosch, Fraunhofer IAIS, Huawei, ASML, IBM Res, NEC, Kreditech, McKinsey & Co, KNIME, European Res Ctr Informat Syst, Odgers Berndtson, Springer, Vogel Stiftung, German Res Fdn
DE Interpretability; Local estimation; Machine learning
ID REGRESSION
AB As machine learning becomes an important part of many real world applications affecting human lives, new requirements, besides high predictive accuracy, become important. One important requirement is transparency, which has been associated with model interpretability. Many machine learning algorithms induce models difficult to interpret, named black box. Black box models are difficult to validate. Moreover, people have difficulty to trust models that cannot be explained. Explainable artificial intelligence is an active research area. In particular for machine learning, many groups are investigating new methods able to explain black box models. These methods usually look inside the black models to explain their inner work. By doing so, they allow the interpretation of the decision making process used by black box models. Among the recently proposed model interpretation methods, there is a group, named local estimators, which are designed to explain how the label of particular instance is predicted. For such, they induce interpretable models on the neighborhood of the instance to be explained. Local estimators have been successfully used to explain specific predictions. Although they provide some degree of model interpretability, it is still not clear what is the best way to implement and apply them. Open questions include: how to best define the neighborhood of an instance? How to control the trade-off between the accuracy of the interpretation method and its interpretability? How to make the obtained solution robust to small variations on the instance to be explained? To answer these questions, we propose and investigate two strategies: (i) using data instance properties to provide improved explanations, and (ii) making sure that the neighborhood of an instance is properly defined by taking the geometry of the domain of the feature space into account. We evaluate these strategies in a regression task and present experimental results that show that they can improve local explanations.
C1 [Botari, Tiago; de Carvalho, Andre C. P. L. F.] Univ Sao Paulo, Inst Math & Comp Sci, Sao Carlos, SP, Brazil.
   [Izbicki, Rafael] Univ Fed Sao Carlos, Dept Stat, Sao Carlos, SP, Brazil.
RP Botari, T (corresponding author), Univ Sao Paulo, Inst Math & Comp Sci, Sao Carlos, SP, Brazil.
EM tiagobotari@gmail.com; rafaelizbicki@gmail.com; andre@icmc.usp.br
RI Ponce Carvalho, André Carlos de Leon Ferreira de/A-6321-2008
OI Ponce Carvalho, André Carlos de Leon Ferreira de/0000-0002-4765-6459
FU CAPESCoordenacao de Aperfeicoamento de Pessoal de Nivel Superior
   (CAPES); Sao Paulo Research Foundation (FAPESP)Fundacao de Amparo a
   Pesquisa do Estado de Sao Paulo (FAPESP) [2017/061617]; FAPESPFundacao
   de Amparo a Pesquisa do Estado de Sao Paulo (FAPESP) [2017/03363,
   2019/11321-9]; CNPqConselho Nacional de Desenvolvimento Cientifico e
   Tecnologico (CNPQ) [06943/2017-4]; CeMEAI -Center for Mathematical
   Sciences Applied to Industry from Sao Paulo Research Foundation (FAPESP)
   [2013/07375-0]
FX The authors would like to thank CAPES and CNPq (Brazilian Agencies) for
   their financial support. T.B. acknowledges support by Grant 2017/061617,
   Sao Paulo Research Foundation (FAPESP). R. I. acknowledges support by
   Grant 2017/03363 (FAPESP), 2019/11321-9 (FAPESP), and Grant
   306943/2017-4 (CNPq). The authors acknowledge Grant 2013/07375-0 -CeMEAI
   -Center for Mathematical Sciences Applied to Industry from Sao Paulo
   Research Foundation (FAPESP). T.B. thanks Rafael Amatte Bizao and
   Frederik Hvilshoj for review and comments.
NR 31
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1865-0929
EI 1865-0937
BN 978-3-030-43823-4; 978-3-030-43822-7
J9 COMM COM INF SC
PY 2020
VL 1167
BP 241
EP 252
DI 10.1007/978-3-030-43823-4_21
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Interdisciplinary Applications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS4ET
UT WOS:000718585100021
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Lucas, TCD
AF Lucas, Tim C. D.
TI A translucent box: interpretable machine learning in ecology
SO ECOLOGICAL MONOGRAPHS
LA English
DT Review
DE interpretable machine learning; machine learning; model interpretation;
   phylogenetic regression; random effects; Random Forest
ID LIFE-HISTORY; LITTER SIZE; SPECIES DISTRIBUTIONS; VARIABLE SELECTION; R
   PACKAGE; REGRESSION; PREDICTION; MODELS; PHYLOGENIES; ALGORITHMS
AB Machine learning has become popular in ecology but its use has remained restricted to predicting, rather than understanding, the natural world. Many researchers consider machine learning algorithms to be a black box. These models can, however, with careful examination, be used to inform our understanding of the world. They are translucent boxes. Furthermore, the interpretation of these models can be an important step in building confidence in a model or in a specific prediction from a model. Here I review a number of techniques for interpreting machine learning models at the level of the system, the variable, and the individual prediction as well as methods for handling non-independent data. I also discuss the limits of interpretability for different methods and demonstrate these approaches using a case example of understanding litter sizes in mammals.
C1 [Lucas, Tim C. D.] Univ Oxford, Big Data Inst, Old Rd Campus, Oxford OX3 7LF, England.
RP Lucas, TCD (corresponding author), Univ Oxford, Big Data Inst, Old Rd Campus, Oxford OX3 7LF, England.
EM timcdlucas@gmail.com
OI Lucas, Tim/0000-0003-4694-8107
FU Bill and Melinda Gates FoundationBill & Melinda Gates Foundation
FX Thanks go to Katrina Ross, Penelope Hancock, and the Malaria Atlas
   Project journal club for comments on earlier drafts of the paper. I
   acknowledge Tristan Cordier and an anonymous reviewer for their useful
   and considered comments. I would also like to thank Bure Park Nature
   Reserve, Bicester, where I drafted this manuscript on many walks getting
   my son to sleep. T. Lucas was supported by grants from the Bill and
   Melinda Gates Foundation.
NR 99
TC 18
Z9 18
U1 22
U2 48
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0012-9615
EI 1557-7015
J9 ECOL MONOGR
JI Ecol. Monogr.
PD NOV
PY 2020
VL 90
IS 4
DI 10.1002/ecm.1422
EA SEP 2020
PG 17
WC Ecology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Environmental Sciences & Ecology
GA OP4SN
UT WOS:000573712500001
OA hybrid
DA 2022-04-17
ER

PT C
AU Sokolov, M
   Herndon, N
AF Sokolov, Mark
   Herndon, Nic
BE DeMarsico, M
   DiBaja, GS
   Fred, A
TI Predicting Malware Attacks using Machine Learning and AutoAI
SO PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION
   APPLICATIONS AND METHODS (ICPRAM)
LA English
DT Proceedings Paper
CT 10th International Conference on Pattern Recognition Applications and
   Methods (ICPRAM)
CY FEB 04-06, 2021
CL ELECTR NETWORK
DE Malware; Kaggle; LGBM; AutoAI; Machine Learning
AB Machine learning is one of the fastest-growing fields and its application to cybersecurity is increasing. In order to protect people from malicious attacks, several machine learning algorithms have been used to predict them. In addition, with the increase of malware threats in our world, a lot of companies use AutoAI to help protect their systems. However, when a dataset is large and sparse, conventional machine learning algorithms and AutoAI don't generate the best results. In this paper, we propose an Ensemble of Light Gradient Boosted Machines to predict malware attacks on computing systems. We use a dataset provided by Microsoft to show that this proposed method achieves an increase in accuracy over AutoAI.
C1 [Sokolov, Mark; Herndon, Nic] East Carolina Univ, Greenville, NC 27858 USA.
RP Sokolov, M (corresponding author), East Carolina Univ, Greenville, NC 27858 USA.
OI Herndon, Nic/0000-0001-9712-148X
NR 16
TC 0
Z9 0
U1 1
U2 2
PU SCITEPRESS
PI SETUBAL
PA AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL
BN 978-989-758-486-2
PY 2021
BP 295
EP 301
DI 10.5220/0010264902950301
PG 7
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR6PY
UT WOS:000662835900034
OA hybrid
DA 2022-04-17
ER

PT J
AU Ulas, M
   Aydur, O
   Gurgenc, T
   Ozel, C
AF Ulas, Mustafa
   Aydur, Osman
   Gurgenc, Turan
   Ozel, Cihan
TI Surface roughness prediction of machined aluminum alloy with wire
   electrical discharge machining by different machine learning algorithms
SO JOURNAL OF MATERIALS RESEARCH AND TECHNOLOGY-JMR&T
LA English
DT Article
DE Wire electrical discharge machining; Surface roughness; Aluminum alloy;
   Machine learning; Support vector regression; Extreme learning machine
ID SUPPORT VECTOR REGRESSION; ARTIFICIAL NEURAL-NETWORK; RESIDUAL-STRESSES;
   EDM; PARAMETERS; WEIRS; WEDM; TIME
AB Aluminum alloys are preferred in aviation, aerospace and automotive industries because of their high strength and durability compared to their lightness. Precision production of parts is very important in such industries. Therefore, precision machining of aluminum, which is difficult to manufacture with traditional methods, with non-traditional methods such as wire electrical discharge machining (WEDM), is a very popular approach. Surface roughness has an impact on the important properties of materials such as strength, wear resistance and fatigue strength. Experimental determination of surface roughness of surfaces machined with WEDM is time consuming and costly. These cost and time losses can be eliminated by predicted surface roughness with machine learning algorithms. In this study, Al7075 aluminum alloy was machined with different parameters (voltage, pulse-on-time, dielectric pressure and wire feed) with WEDM. Each parameter is at 3 levels, so 81 experiments were carried out. The surface roughness of the machined surfaces was measured by surface profilometer. The lowest surface roughness was 2.490 mu m machined at 8 V voltage, 8 mu s pulse on-time, 25 bar dielectric pressure and 2 mm/min wire feed. The experiments for machining of Al7075 via WEDM were modeled by machine learning methods. Four different models of two different methods were used for the prediction of surface roughness values of machined samples with WEDM. These models were ELM, W-ELM, SVR and Q-SVR. All of the models were applied to the data set and the W-ELM model was the best performing model with the value of 0.9720 R-2. Thus, the W-ELM model has excellent potential in manufacturing industry which produced parts with WEDM. (C) 2020 The Author(s). Published by Elsevier B.V.
C1 [Ulas, Mustafa; Aydur, Osman] Firat Univ, Software Engn, TR-23119 Elazig, Turkey.
   [Gurgenc, Turan] Firat Univ, Automot Engn, TR-23119 Elazig, Turkey.
   [Ozel, Cihan] Firat Univ, Mech Engn, TR-23119 Elazig, Turkey.
RP Gurgenc, T (corresponding author), Firat Univ, Automot Engn, TR-23119 Elazig, Turkey.; Ozel, C (corresponding author), Firat Univ, Mech Engn, TR-23119 Elazig, Turkey.
EM mustafaulas@firat.edu.tr; 182137101@firat.edu.tr; tgurgenc@firat.edu.tr;
   cozel@firat.edu.tr
RI Gürgenç, Turan/V-8472-2018; Ulas, Mustafa/K-7017-2018
OI Ulas, Mustafa/0000-0002-0096-9693
FU Firat University Research FundFirat University [FUBAPMF.19.52]
FX The authors thank the Firat University Research Fund (FUBAPMF.19.52) for
   their financial contribution to this research. All the Matlab scripts of
   related algorithms in the article are coded ourselves. The used Matlab
   platform is licenced by Firat University.
NR 56
TC 14
Z9 14
U1 11
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2238-7854
EI 2214-0697
J9 J MATER RES TECHNOL
JI J. Mater. Res. Technol-JMRT
PD NOV-DEC
PY 2020
VL 9
IS 6
BP 12512
EP 12524
DI 10.1016/j.jmrt.2020.08.098
PG 13
WC Materials Science, Multidisciplinary; Metallurgy & Metallurgical
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Materials Science; Metallurgy & Metallurgical Engineering
GA PQ3VK
UT WOS:000606474600006
OA gold
DA 2022-04-17
ER

PT J
AU He, LS
   Guo, HW
   Jin, YB
   Zhuang, XY
   Rabczuk, T
   Li, Y
AF He, Liangshu
   Guo, Hongwei
   Jin, Yabin
   Zhuang, Xiaoying
   Rabczuk, Timon
   Li, Yan
TI Machine-learning-driven on-demand design of phononic beams
SO SCIENCE CHINA-PHYSICS MECHANICS & ASTRONOMY
LA English
DT Article
DE phononic crystals; elastic metamaterials; topological insulators;
   machine learning; reinforcement learning
ID DEEP NEURAL-NETWORKS; INVERSE DESIGN; PHASE; OPTIMIZATION; CRYSTALS
AB The development of phononic crystals, especially their interaction with topological insulators, allows exploration of the anomalous properties of acoustic/elastic waves for various applications. However, rapidly and inversely exploring the geometry of specific targets remains a major challenge. In this work, we show how machine learning can address this challenge by studying phononic crystal beams using two different inverse design schemes. We first develop the theory of phononic beams using the transfer matrix method. Then, we use the reinforcement learning algorithm to effectively and inversely design the structural parameters to maximize the bandgap width. Furthermore, we employ the tandem-architecture neural network to solve the training-difficulty problem caused by inconsistent data and complete the task of inverse structure design with the targeted topological properties. The two inverse-design schemes have different adaptabilities, and both are characterized by high efficiency and stability. This work provides deep insights into the combination of machine learning, topological property, and phononic crystals and offers a reliable platform for rapidly and inversely designing complex material and structure properties.
C1 [He, Liangshu; Jin, Yabin; Li, Yan] Tongji Univ, Sch Aerosp Engn & Appl Mech, Shanghai 200092, Peoples R China.
   [Guo, Hongwei; Zhuang, Xiaoying] Leibniz Univ Hannover, Inst Photon, Dept Math & Phys, D-30167 Hannover, Germany.
   [Zhuang, Xiaoying] Tongji Univ, Coll Civil Engn, Dept Geotech Engn, Shanghai 200092, Peoples R China.
   [Rabczuk, Timon] Bauhaus Univ Weimar, Inst Struct Mech, D-99423 Weimar, Germany.
RP Jin, YB; Li, Y (corresponding author), Tongji Univ, Sch Aerosp Engn & Appl Mech, Shanghai 200092, Peoples R China.
EM 083623jinyabin@tongji.edu.cn; liyan@tongji.edu.cn
RI Zhuang, Xiaoying/G-4754-2011
OI Zhuang, Xiaoying/0000-0001-6562-2618
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [11902223]; Shanghai Pujiang ProgramShanghai
   Pujiang Program [19PJ1410100]; Program for Professors of Special
   Appointment (Eastern Scholar) at Shanghai Institutions of Higher
   Learning; Fundamental Research Funds for the Central
   UniversitiesFundamental Research Funds for the Central Universities;
   Shanghai Municipal Peak Discipline Program [2019010106]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 11902223), the Shanghai Pujiang Program (Grant No.
   19PJ1410100), the Program for Professors of Special Appointment (Eastern
   Scholar) at Shanghai Institutions of Higher Learning, the Fundamental
   Research Funds for the Central Universities, and Shanghai Municipal Peak
   Discipline Program (Grant No. 2019010106).
NR 55
TC 1
Z9 1
U1 36
U2 36
PU SCIENCE PRESS
PI BEIJING
PA 16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100717, PEOPLES R CHINA
SN 1674-7348
EI 1869-1927
J9 SCI CHINA PHYS MECH
JI Sci. China-Phys. Mech. Astron.
PD JAN
PY 2022
VL 65
IS 1
AR 214612
DI 10.1007/s11433-021-1787-x
PG 12
WC Physics, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Physics
GA XF4DP
UT WOS:000724023100001
DA 2022-04-17
ER

PT J
AU Olea, JLM
   Nesbit, J
AF Olea, Jose Luis Montiel
   Nesbit, James
TI (Machine) learning parameter regions
SO JOURNAL OF ECONOMETRICS
LA English
DT Article
DE Machine learning; Supervised learning; Set-identified models; Structural
   vector autoregressions
AB How many random points from an identified set, a confidence set, or a highest posterior density set suffice to describe them? This paper argues that taking random draws from a parameter region in order to approximate its shape is a supervised learning problem (analogous to sampling pixels of an image to recognize it). Misclassification error - a common criterion in machine learning - provides an off-the-shelf tool to assess the quality of a given approximation. We say a parameter region can be learned if there is an algorithm that yields a misclassification error of at most epsilon with probability at least 1 - delta, regardless of the sampling distribution. We show that learning a parameter region is possible if and only if its potential shapes are not too complex. Moreover, the tightest band that contains a d-dimensional parameter region is always learnable from the inside (in a sense we make precise), with at least max {(1 - epsilon) ln (1/delta), (3/16)d}/epsilon draws, but at most min{2d ln(2d/delta), exp(1)(2d+ln(1/delta))}/epsilon. These bounds grow linearly in the dimension of the parameter region, and are uniform with respect to its true shape. We illustrate the usefulness of our results using structural vector autoregressions. We show how many orthogonal matrices are necessary/sufficient to evaluate the impulse responses' identified set and how many 'shotgun plots' to report when conducting joint inference on impulse responses. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Olea, Jose Luis Montiel] Columbia Univ, Dept Econ, 420 West 118th St, New York, NY 10027 USA.
   [Nesbit, James] NYU, Dept Econ, 19 W 4th St,6th Floor, New York, NY 10012 USA.
RP Olea, JLM (corresponding author), Columbia Univ, Dept Econ, 420 West 118th St, New York, NY 10027 USA.
EM jm4474@columbia.edu; jmn425@nyu.edu
OI Montiel Olea, Jose Luis/0000-0002-1037-1628
NR 41
TC 0
Z9 0
U1 5
U2 7
PU ELSEVIER SCIENCE SA
PI LAUSANNE
PA PO BOX 564, 1001 LAUSANNE, SWITZERLAND
SN 0304-4076
EI 1872-6895
J9 J ECONOMETRICS
JI J. Econom.
PD MAY
PY 2021
VL 222
IS 1
BP 716
EP 744
DI 10.1016/j.jeconom.2020.06.008
EA MAR 2021
PN C
PG 29
WC Economics; Mathematics, Interdisciplinary Applications; Social Sciences,
   Mathematical Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Business & Economics; Mathematics; Mathematical Methods In Social
   Sciences
GA RE4WV
UT WOS:000634157300006
DA 2022-04-17
ER

PT J
AU Nakaura, T
   Higaki, T
   Awai, K
   Ikeda, O
   Yamashita, Y
AF Nakaura, Takeshi
   Higaki, Toru
   Awai, Kazuo
   Ikeda, Osamu
   Yamashita, Yasuyuki
TI A primer for understanding radiology articles about machine learning and
   deep learning
SO DIAGNOSTIC AND INTERVENTIONAL IMAGING
LA English
DT Review
DE Machine learning; Deep learning; Tomography; X-ray computed; Magnetic
   resonance imaging
ID APPROXIMATE; RADIOMICS; ALGORITHM; BENIGN; IMAGES
AB The application of machine learning and deep learning in the field of imaging is rapidly growing. Although the principles of machine and deep learning are unfamiliar to the majority of clinicians, the basics are not so complicated. One of the major issues is that commentaries written by experts are difficult to understand, and are not primarily written for clinicians. The purpose of this article was to describe the different concepts behind machine learning, radiomics, and deep learning to make clinicians more familiar with these techniques. (C) 2020 Societe francaise de radiologie. Published by Elsevier Masson SAS. All rights reserved.
C1 [Nakaura, Takeshi; Ikeda, Osamu; Yamashita, Yasuyuki] Japan Kumamoto Univ, Grad Sch Med Sci, Dept Diagnost Radiol, Chuo Ku, 1-1-1 Honjo, Kumamoto 8608556, Japan.
   [Higaki, Toru; Awai, Kazuo] Hiroshima Univ, Dept Diagnost Radiol, Minami Ku, 1-2-3 Kasumi, Hiroshima 7348551, Japan.
   [Higaki, Toru; Awai, Kazuo] Hiroshima Univ, Dept Radiol, Minami Ku, 1-2-3 Kasumi, Hiroshima 7348551, Japan.
RP Nakaura, T (corresponding author), Japan Kumamoto Univ, Grad Sch Med Sci, Dept Diagnost Radiol, Chuo Ku, 1-1-1 Honjo, Kumamoto 8608556, Japan.
EM kff00712@nifty.com
OI Nakaura, Takeshi/0000-0002-9010-0341; Higaki, Toru/0000-0003-0631-7271
NR 41
TC 21
Z9 21
U1 9
U2 10
PU ELSEVIER MASSON, CORP OFF
PI PARIS
PA 65 CAMILLE DESMOULINS CS50083 ISSY-LES-MOULINEAUX, 92442 PARIS, FRANCE
SN 2211-5684
J9 DIAGN INTERV IMAG
JI Diagn. Interv. Imaging
PD DEC
PY 2020
VL 101
IS 12
BP 765
EP 770
DI 10.1016/j.diii.2020.10.001
PG 6
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA PA2ZV
UT WOS:000595502700002
PM 33121910
OA Bronze
DA 2022-04-17
ER

PT C
AU Huber, M
   Raidl, GR
AF Huber, Marc
   Raidl, Guenther R.
BE Nicosia, G
   Ojha, V
   LaMalfa, E
   LaMalfa, G
   Jansen, G
   Pardalos, PM
   Giuffrida, G
   Umeton, R
TI Learning Beam Search: Utilizing Machine Learning to Guide Beam Search
   for Solving Combinatorial Optimization Problems
SO MACHINE LEARNING, OPTIMIZATION, AND DATA SCIENCE (LOD 2021), PT II
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 7th International Conference on Machine Learning, Optimization, and Data
   Science (LOD) / 1st Symposium on Artificial Intelligence and
   Neuroscience (ACAIN)
CY OCT 04-08, 2021
CL ELECTR NETWORK
DE Beam search; Combinatorial optimization; Machine learning; Longest
   common subsequence problem
ID LONGEST COMMON SUBSEQUENCE; ALGORITHM
AB Beam search (BS) is a well-known incomplete breadth-first-search variant frequently used to find heuristic solutions to hard combinatorial optimization problems. Its key ingredient is a guidance heuristic that estimates the expected length (cost) to complete a partial solution. While this function is usually developed manually for a specific problem, we propose a more general Learning Beam Search (LBS) that uses a machine learning model for guidance. Learning is performed by utilizing principles of reinforcement learning: LBS generates training data on its own by performing nested BS calls on many representative randomly created problem instances. The general approach is tested on two specific problems, the longest common subsequence problem and the constrained variant thereof. Results on established sets of benchmark instances indicate that the BS with models trained via LBS is highly competitive. On many instances new so far best solutions could be obtained, making the approach a new state-of-the-art method for these problems and documenting the high potential of this general framework.
C1 [Huber, Marc; Raidl, Guenther R.] TU Wien, Inst Log & Computat, Algorithms & Complex Grp, Vienna, Austria.
RP Huber, M (corresponding author), TU Wien, Inst Log & Computat, Algorithms & Complex Grp, Vienna, Austria.
EM mhuber@ac.tuwien.ac.at; raidl@ac.tuwien.ac.at
FU Doctoral Program "Vienna Graduate School on Computational Optimization",
   Austrian Science Foundation (FWF)Austrian Science Fund (FWF) [W1260N35]
FX This project is partially funded by the Doctoral Program "Vienna
   Graduate School on Computational Optimization", Austrian Science
   Foundation (FWF), grant W1260N35.
NR 29
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-95470-3; 978-3-030-95469-7
J9 LECT NOTES COMPUT SC
PY 2022
VL 13164
BP 283
EP 298
DI 10.1007/978-3-030-95470-3_22
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS8JO
UT WOS:000772650800022
DA 2022-04-17
ER

PT J
AU Baur, T
   Heimerl, A
   Lingenfelser, F
   Wagner, J
   Valstar, MF
   Schuller, B
   Andre, E
AF Baur, Tobias
   Heimerl, Alexander
   Lingenfelser, Florian
   Wagner, Johannes
   Valstar, Michel F.
   Schuller, Bjoern
   Andre, Elisabeth
TI eXplainable Cooperative Machine Learning with NOVA
SO KUNSTLICHE INTELLIGENZ
LA English
DT Article
DE Annotation; Cooperative machine learning; Explainable AI
ID EMOTIONAL SPEECH; COEFFICIENT
AB In the following article, we introduce a novel workflow, which we subsume under the term "explainable cooperative machine learning" and show its practical application in a data annotation and model training tool called NOVA. The main idea of our approach is to interactively incorporate the 'human in the loop' when training classification models from annotated data. In particular, NOVA offers a collaborative annotation backend where multiple annotators join their workforce. A main aspect is the possibility of applying semi-supervised active learning techniques already during the annotation process by giving the possibility to pre-label data automatically, resulting in a drastic acceleration of the annotation process. Furthermore, the user-interface implements recent eXplainable AI techniques to provide users with both, a confidence value of the automatically predicted annotations, as well as visual explanation. We show in an use-case evaluation that our workflow is able to speed up the annotation process, and further argue that by providing additional visual explanations annotators get to understand the decision making process as well as the trustworthiness of their trained machine learning models.
C1 [Baur, Tobias; Heimerl, Alexander; Lingenfelser, Florian; Wagner, Johannes; Schuller, Bjoern; Andre, Elisabeth] Augsburg Univ, Univ Str 6a, Augsburg, Germany.
   [Valstar, Michel F.] Univ Nottingham, Nottingham, England.
RP Baur, T (corresponding author), Augsburg Univ, Univ Str 6a, Augsburg, Germany.
EM baur@hcm-lab.de
RI Andre, Elisabeth/AAW-4960-2021
FU Projekt DEAL; DFGGerman Research Foundation (DFG)European Commission
   [392401413]
FX Open Access funding provided by Projekt DEAL. This work has received
   funding DFG under Project Number 392401413, DEEP.
NR 67
TC 4
Z9 4
U1 1
U2 3
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 0933-1875
EI 1610-1987
J9 KUNSTL INTELL
JI Kunstl. Intell.
PD JUN
PY 2020
VL 34
IS 2
SI SI
BP 143
EP 164
DI 10.1007/s13218-020-00632-3
EA JAN 2020
PG 22
WC Computer Science, Artificial Intelligence
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA LU4WK
UT WOS:000507933200001
OA hybrid, Green Published
DA 2022-04-17
ER

PT J
AU Lawson, CE
   Marti, JM
   Radivojevic, T
   Jonnalagadda, SVR
   Gentz, R
   Hillson, NJ
   Peisert, S
   Kim, J
   Simmons, BA
   Petzold, CJ
   Singer, SW
   Mukhopadhyay, A
   Tanjore, D
   Dunn, JG
   Martin, HG
AF Lawson, Christopher E.
   Marti, Jose Manuel
   Radivojevic, Tijana
   Jonnalagadda, Sai Vamshi R.
   Gentz, Reinhard
   Hillson, Nathan J.
   Peisert, Sean
   Kim, Joonhoon
   Simmons, Blake A.
   Petzold, Christopher J.
   Singer, Steven W.
   Mukhopadhyay, Aindrila
   Tanjore, Deepti
   Dunn, Joshua G.
   Martin, Hector Garcia
TI Machine learning for metabolic engineering: A review
SO METABOLIC ENGINEERING
LA English
DT Review
DE Machine Learning; Metabolic Engineering; Synthetic Biology; Deep
   Learning
ID DEEP NEURAL-NETWORKS; SYNTHETIC BIOLOGY; PROCESS TRENDS; INTEGRATED
   APPROACH; SCALE-DOWN; DESIGN; MODEL; OPTIMIZATION; GUIDE; REPRESENTATION
AB Machine learning provides researchers a unique opportunity to make metabolic engineering more predictable. In this review, we offer an introduction to this discipline in terms that are relatable to metabolic engineers, as well as providing in-depth illustrative examples leveraging omics data and improving production. We also include practical advice for the practitioner in terms of data management, algorithm libraries, computational resources, and important non-technical issues. A variety of applications ranging from pathway construction and optimization, to genetic editing optimization, cell factory testing, and production scale-up are discussed. Moreover, the promising relationship between machine learning and mechanistic models is thoroughly reviewed. Finally, the future perspectives and most promising directions for this combination of disciplines are examined.
C1 [Lawson, Christopher E.; Marti, Jose Manuel; Radivojevic, Tijana; Jonnalagadda, Sai Vamshi R.; Gentz, Reinhard; Hillson, Nathan J.; Peisert, Sean; Simmons, Blake A.; Petzold, Christopher J.; Singer, Steven W.; Mukhopadhyay, Aindrila; Tanjore, Deepti; Martin, Hector Garcia] Lawrence Berkeley Natl Lab, Biol Syst & Engn, Berkeley, CA 94720 USA.
   [Lawson, Christopher E.; Marti, Jose Manuel; Radivojevic, Tijana; Jonnalagadda, Sai Vamshi R.; Gentz, Reinhard; Hillson, Nathan J.; Kim, Joonhoon; Simmons, Blake A.; Petzold, Christopher J.; Singer, Steven W.; Mukhopadhyay, Aindrila; Martin, Hector Garcia] Joint BioEnergy Inst, Emeryville, CA 94608 USA.
   [Marti, Jose Manuel; Radivojevic, Tijana; Jonnalagadda, Sai Vamshi R.; Hillson, Nathan J.; Simmons, Blake A.; Petzold, Christopher J.; Martin, Hector Garcia] DOE Agile BioFoundry, Emeryville, CA 94608 USA.
   [Martin, Hector Garcia] Basque Ctr Appl Math, Bilbao 48009, Spain.
   [Kim, Joonhoon] Pacific Northwest Natl Lab, Richland, WA 99354 USA.
   [Tanjore, Deepti] Adv Biofuels & Bioprod Proc Dev Unit, Emeryville, CA 94608 USA.
   [Mukhopadhyay, Aindrila; Martin, Hector Garcia] Lawrence Berkeley Natl Lab, Environm Genom & Syst Biol Div, Berkeley, CA USA.
   [Dunn, Joshua G.] Ginkgo Bioworks, Boston, MA 02210 USA.
   [Gentz, Reinhard; Peisert, Sean] Lawrence Berkeley Natl Lab, Computat Res Div, Berkeley, CA 94720 USA.
   [Peisert, Sean] Univ Calif Davis, Davis, CA 95616 USA.
RP Martin, HG (corresponding author), Lawrence Berkeley Natl Lab, Biol Syst & Engn, Berkeley, CA 94720 USA.
EM hgmartin@lbl.gov
RI Mukhopadhyay, Aindrila/AAW-7257-2021; Simmons, Blake/N-6022-2016; Kim,
   Joonhoon/E-6253-2012; Garcia Martin, Hector/B-5357-2009
OI Simmons, Blake/0000-0002-1332-1810; Kim, Joonhoon/0000-0002-7425-1828;
   Lawson, Christopher/0000-0002-3473-1640; Marti, Jose
   Manuel/0000-0002-1902-9749; Peisert, Sean/0000-0003-3566-9719;
   Radivojevic, Tijana/0000-0002-7165-2909; Petzold,
   Christopher/0000-0002-8270-5228; Garcia Martin,
   Hector/0000-0002-4556-9685
FU U.S. Department of Energy, Energy Efficiency and Renewable Energy,
   Bioenergy Technologies OfficeUnited States Department of Energy (DOE)
   [DE-AC02-05CH11231]; U.S. Department of Energy, Office of ScienceUnited
   States Department of Energy (DOE) [DE-AC02-05CH11231]; Basque Government
   through the BERC 2014-2017 programBasque Government; Spanish Ministry of
   Economy and Competitiveness MINECO: BCAM Severo Ochoa excellence
   accreditationSpanish Government [SEV-2013-0323]
FX This work was part of the the Agile BioFoundry (http://agilebiofo
   undry.org) and the DOE Joint BioEnergy Institute (http://www.jbei.org),
   supported by the U.S. Department of Energy, Energy Efficiency and
   Renewable Energy, Bioenergy Technologies Office, and the Office of
   Science, through contract DE-AC02-05CH11231 between Lawrence Berkeley
   National Laboratory and the U.S. Department of Energy. The United States
   Government retains and the publisher, by accepting the article for
   publication, acknowledges that the United States Government retains a
   nonexclusive, paid-up, irrevocable, worldwide license to publish or
   reproduce the published form of this manuscript, or allow others to do
   so, for United States Government purposes. The Department of Energy will
   provide public access to these results of federally sponsored research
   in accordance with the DOE Public Access Plan
   (http://energy.gov/downloads/doe-public-access-plan).This research is
   also supported by the Basque Government through the BERC 2014-2017
   program and by the Spanish Ministry of Economy and Competitiveness
   MINECO: BCAM Severo Ochoa excellence accreditation SEV-2013-0323.
NR 254
TC 21
Z9 22
U1 58
U2 85
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1096-7176
EI 1096-7184
J9 METAB ENG
JI Metab. Eng.
PD JAN
PY 2021
VL 63
SI SI
BP 34
EP 60
DI 10.1016/j.ymben.2020.10.005
EA JAN 2021
PG 27
WC Biotechnology & Applied Microbiology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Biotechnology & Applied Microbiology
GA PZ8KJ
UT WOS:000612991100004
PM 33221420
OA hybrid, Green Published
HC Y
HP N
DA 2022-04-17
ER

PT J
AU Heisey, KL
   Walker, AM
   Xie, K
   Abrams, JM
   Barbour, DL
AF Heisey, Katherine L.
   Walker, Alexandra M.
   Xie, Kevin
   Abrams, Jenna M.
   Barbour, Dennis L.
TI Dynamically Masked Audiograms With Machine Learning Audiometry
SO EAR AND HEARING
LA English
DT Article
DE Audiogram; Audiology; Audiometry; Estimation; Machine learning;
   Psychoacoustics; Psychophysics
ID PURE-TONE; INTERAURAL ATTENUATION; MASKING; CONDUCTION; THRESHOLD
AB Objectives:
   When one ear of an individual can hear significantly better than the other ear, evaluating the worse ear with loud probe tones may require delivering masking noise to the better ear to prevent the probe tones from inadvertently being heard by the better ear. Current masking protocols are confusing, laborious, and time consuming. Adding a standardized masking protocol to an active machine learning audiogram procedure could potentially alleviate all of these drawbacks by dynamically adapting the masking as needed for each individual. The goal of this study is to determine the accuracy and efficiency of automated machine learning masking for obtaining true hearing thresholds.
   Design:
   Dynamically masked automated audiograms were collected for 29 participants between the ages of 21 and 83 (mean 43, SD 20) with a wide range of hearing abilities. Normal-hearing listeners were given unmasked and masked machine learning audiogram tests. Listeners with hearing loss were given a standard audiogram test by an audiologist, with masking stimuli added as clinically determined, followed by a masked machine learning audiogram test. The hearing thresholds estimated for each pair of techniques were compared at standard audiogram frequencies (i.e., 0.25, 0.5, 1, 2, 4, 8 kHz).
   Results:
   Masked and unmasked machine learning audiogram threshold estimates matched each other well in normal-hearing listeners, with a mean absolute difference between threshold estimates of 3.4 dB. Masked machine learning audiogram thresholds also matched well the thresholds determined by a conventional masking procedure, with a mean absolute difference between threshold estimates for listeners with low asymmetry and high asymmetry between the ears, respectively, of 4.9 and 2.6 dB. Notably, out of 6200 masked machine learning audiogram tone deliveries for this study, no instances of tones detected by the nontest ear were documented. The machine learning methods were also generally faster than the manual methods, and for some listeners, substantially so.
   Conclusions:
   Dynamically masked audiograms achieve accurate true threshold estimates and reduce test time compared with current clinical masking procedures. Dynamic masking is a compelling alternative to the methods currently used to evaluate individuals with highly asymmetric hearing, yet can also be used effectively and efficiently for anyone.
C1 [Heisey, Katherine L.; Walker, Alexandra M.; Xie, Kevin; Abrams, Jenna M.; Barbour, Dennis L.] Washington Univ, Dept Biomed Engn, Lab Sensory Neurosci & Neuroengn, St Louis, MO 63110 USA.
   [Walker, Alexandra M.; Abrams, Jenna M.] Washington Univ, Sch Med, Dept Otolaryngol, Program Audiol & Commun Sci, St Louis, MO 63110 USA.
   [Xie, Kevin] Washington Univ, Dept Comp Sci & Engn, St Louis, MO 63110 USA.
RP Barbour, DL (corresponding author), Washington Univ, Dept Biomed Engn, One Brookings Dr,Campus Box 1097, St Louis, MO 63130 USA.
OI Xie, Kevin/0000-0003-1849-2085
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [UL1 TR002345]; NSFNational Science
   Foundation (NSF) [DGE-1745038]
FX Funding for this project was provided by NIH UL1 TR002345 and NSF grant
   DGE-1745038.
NR 37
TC 2
Z9 2
U1 1
U2 3
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0196-0202
EI 1538-4667
J9 EAR HEARING
JI Ear Hear.
PD NOV-DEC
PY 2020
VL 41
IS 6
BP 1692
EP 1702
DI 10.1097/AUD.0000000000000891
PG 11
WC Audiology & Speech-Language Pathology; Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Audiology & Speech-Language Pathology; Otorhinolaryngology
GA OI1PD
UT WOS:000583058600025
PM 33136643
OA Green Accepted
DA 2022-04-17
ER

PT C
AU Gupta, N
   Mujumdar, S
   Patel, H
   Masuda, S
   Panwar, N
   Bandyopadhyay, S
   Mehta, S
   Guttula, S
   Afzal, S
   Mittal, RS
   Munigala, V
AF Gupta, Nitin
   Mujumdar, Shashank
   Patel, Hima
   Masuda, Satoshi
   Panwar, Naveen
   Bandyopadhyay, Sambaran
   Mehta, Sameep
   Guttula, Shanmukha
   Afzal, Shazia
   Mittal, Ruhi Sharma
   Munigala, Vitobha
GP ASSOC COMP MACHINERY
TI Data Quality for Machine Learning Tasks
SO KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE
   DISCOVERY & DATA MINING
LA English
DT Proceedings Paper
CT 27th ACM SIGKDD International Conference on Knowledge Discovery and Data
   Mining (KDD)
CY AUG 14-18, 2021
CL ELECTR NETWORK
SP Assoc Comp Machinery, ACM SIGMOD, ACM SIGKDD
DE data quality; machine learning; quality metrics
AB The quality of training data has a huge impact on the efficiency, accuracy and complexity of machine learning tasks. Data remains susceptible to errors or irregularities that may be introduced during collection, aggregation or annotation stage. This necessitates profiling and assessment of data to understand its suitability for machine learning tasks and failure to do so can result in inaccurate analytics and unreliable decisions. While researchers and practitioners have focused on improving the quality of models, there are limited efforts towards improving the data quality.
   Assessing the quality of the data across intelligently designed metrics and developing corresponding transformation operations to address the quality gaps helps to reduce the effort of a data scientist for iterative debugging of the ML pipeline to improve model performance [4, 11, 12]. This tutorial highlights the importance of analysing data quality in terms of its value for ML applications. Finding the data quality issues in data helps different personas like data stewards, data scientists, subject matter experts, or machine learning scientists to get relevant data insights and take remedial actions to rectify any issue. This tutorial surveys all the important data quality related approaches for structured, unstructured and spatio-temporal domains discussed in literature, focusing on the intuition behind them, highlighting their strengths and similarities, and illustrates their applicability to real-world problems. Finally we will discuss the interesting work IBM Research is doing in this space.
C1 [Gupta, Nitin; Mujumdar, Shashank; Patel, Hima; Panwar, Naveen; Bandyopadhyay, Sambaran; Mehta, Sameep; Guttula, Shanmukha; Afzal, Shazia; Mittal, Ruhi Sharma; Munigala, Vitobha] IBM Res, New Delhi, India.
   [Masuda, Satoshi] IBM Res, Tokyo, Japan.
RP Gupta, N (corresponding author), IBM Res, New Delhi, India.
EM ngupta47@in.ibm.com; shamujum@in.ibm.com; himapatel@in.ibm.com;
   smasuda@jp.ibm.com; naveen.panwar@in.ibm.com; sambband@in.ibm.com;
   sameepmehta@in.ibm.com; shagutt1@in.ibm.com; shaafzal@in.ibm.com;
   ruhi.sharma@in.ibm.com; vmunig10@in.ibm.com
NR 24
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-8332-5
PY 2021
BP 4040
EP 4041
DI 10.1145/3447548.3470817
PG 2
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS6LU
UT WOS:000749556804016
DA 2022-04-17
ER

PT J
AU Ma, J
AF Ma, Jun
TI Supervised and semi-supervised twin parametric-margin regularized
   extreme learning machine
SO PATTERN ANALYSIS AND APPLICATIONS
LA English
DT Article
DE Extreme learning machine; Semi-supervised learning; Laplacian twin
   extreme learning machine; Manifold regularization; Successive
   over-relaxation technology
ID SUPPORT VECTOR MACHINE; SUCCESSIVE OVERRELAXATION; TSVM
AB Twin extreme learning machine (TELM) has attracted considerable attention and achieved great success in the machine learning field. However, its performance will be severely affected when outliers exist in the dataset since TELM does not consider heteroscedasticity in practical applications. To improve the performance of TELM, a novel learning framework called twin parametric-margin extreme learning machine (TPMELM) was proposed. Further, to enhance the classification performance of our TPMELM in a semi-supervised learning setting, a Laplacian TPMELM (Lap-TPMELM) was developed by introducing manifold regularization into TPMELM. Using the geometric information of the marginal distribution embedded in unlabeled samples, Lap-TPMELM can effectively construct a more reasonable classifier. The TPMELM and Lap-TPMELM are suitable for many situations, especially when the data has heteroscedastic error structure. Moreover, the TPMELM and Lap-TPMELM are helpful in clarifying theoretical interpretation of parameters which control the bounds on proportions of support vectors and boundary errors. An efficient technique (successive over-relaxation, SOR) is applied in TPMELM and Lap-TPMELM, respectively. Experimental results show the effectiveness and reliability of the proposed methods.
C1 [Ma, Jun] China Agr Univ, Coll Informat & Elect Engn, Beijing 100083, Peoples R China.
RP Ma, J (corresponding author), China Agr Univ, Coll Informat & Elect Engn, Beijing 100083, Peoples R China.
EM jun_ma1990@yeah.net
RI Ma, Jun/U-7033-2019
OI Ma, Jun/0000-0002-5263-1870
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [11471010, 11271367]
FX This work was partially supported by the National Natural Science
   Foundation of China (Grant Nos. 11471010 and 11271367).
NR 35
TC 2
Z9 2
U1 0
U2 15
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1433-7541
EI 1433-755X
J9 PATTERN ANAL APPL
JI Pattern Anal. Appl.
PD NOV
PY 2020
VL 23
IS 4
BP 1603
EP 1626
DI 10.1007/s10044-020-00880-x
EA APR 2020
PG 24
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NJ1DV
UT WOS:000528158100001
DA 2022-04-17
ER

PT C
AU Goldsteen, A
   Ezov, G
   Shmelkin, R
   Moffie, M
   Farkash, A
AF Goldsteen, Abigail
   Ezov, Gilad
   Shmelkin, Ron
   Moffie, Micha
   Farkash, Ariel
BE GarciaAlfaro, J
   MunozTapia, JL
   NavarroArribas, G
   Soriano, M
TI Anonymizing Machine Learning Models
SO DATA PRIVACY MANAGEMENT, CRYPTOCURRENCIES AND BLOCKCHAIN TECHNOLOGY,
   ESORICS 2021
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 26th European Symposium on Research in Computer Security (ESORICS) /
   16th Data Privacy Management International Workshop (DPM) / 5th
   International Workshop on Cryptocurrencies and Blockchain Technology
   (CBT)
CY OCT 04-08, 2021
CL ELECTR NETWORK
SP Inst Mines Telecom, Inst Polytechnique Paris, Univ Autonoma Barcelona, Univ Politecnica Catalunya, UNESCO Chair Data Privacy, Cybercat, Inria, IRT SYSTEMX, Bandit
DE GDPR; Anonymization; k-anonymity; Compliance; Privacy; Machine learning
AB There is a known tension between the need to analyze personal data to drive business and the need to preserve the privacy of data subjects. Many data protection regulations, including the EU General Data Protection Regulation (GDPR) and the California Consumer Protection Act (CCPA), set out strict restrictions and obligations on the collection and processing of personal data. Moreover, machine learning models themselves can be used to derive personal information, as demonstrated by recent membership and attribute inference attacks. Anonymized data, however, is exempt from the obligations set out in these regulations. It is therefore desirable to be able to create models that are anonymized, thus also exempting them from those obligations, in addition to providing better protection against attacks.
   Learning on anonymized data typically results in significant degradation in accuracy. In this work, we propose a method that is able to achieve better model accuracy by using the knowledge encoded within the trained model, and guiding our anonymization process to minimize the impact on the model's accuracy, a process we call accuracy-guided anonymization. We demonstrate that by focusing on the model's accuracy rather than generic information loss measures, our method outperforms state of the art k-anonymity methods in terms of the achieved utility, in particular with high values of k and large numbers of quasi-identifiers.
   We also demonstrate that our approach has a similar, and sometimes even better ability to prevent membership inference attacks as approaches based on differential privacy, while averting some of their drawbacks such as complexity, performance overhead and model-specific implementations. In addition, since our approach does not rely on making modifications to the training algorithm, it can even work with "blackbox" models where the data owner does not have full control over the training process, or within complex machine learning pipelines where it may be difficult to replace existing learning algorithms with new ones. This makes model-guided anonymization a legitimate substitute for such methods and a practical approach to creating privacy-preserving models.
C1 [Goldsteen, Abigail; Ezov, Gilad; Shmelkin, Ron; Moffie, Micha; Farkash, Ariel] Haifa Univ Campus, IBM Res Haifa, Haifa, Israel.
RP Goldsteen, A (corresponding author), Haifa Univ Campus, IBM Res Haifa, Haifa, Israel.
EM abigailt@il.ibm.com; Gilad.Ezov@ibm.com; ronsh@il.ibm.com;
   moffie@il.ibm.com; arielf@il.ibm.com
NR 29
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-93944-1; 978-3-030-93943-4
J9 LECT NOTES COMPUT SC
PY 2022
VL 13140
BP 121
EP 136
DI 10.1007/978-3-030-93944-1_8
PG 16
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS6XW
UT WOS:000754558600008
OA Green Submitted
DA 2022-04-17
ER

PT C
AU Nila, C
   Apostol, I
   Patriciu, V
AF Nila, Constantin
   Apostol, Ioana
   Patriciu, Victor
GP IEEE
TI Machine learning approach to quick incident response
SO 2020 13TH INTERNATIONAL CONFERENCE ON COMMUNICATIONS (COMM)
LA English
DT Proceedings Paper
CT 13th International Conference on Communications (COMM)
CY JUN 18-20, 2020
CL ELECTR NETWORK
SP IEEE, Politehnica Univ Bucharest, Mil Tech Acad Ferdinand I, Academia Stiinte Tehnice
DE machine learning; incident response; cybersecurity
AB Tracking the evolution from the first DARPA set designed for IDS ML solutions, more than twenty years later, it can be noticed, that every time a new cybersecurity problem is discovered, unconsidered by previous solutions, a higher-level system is developed to solve it. Training on data specific to the defended system is more effective than training on publicly available datasets. This fact is arguable for the security solutions reviewed, but it is sure for solutions dedicated to incident response and forensics operations. This paper's objective is to design a machine learning-based schema for triage solutions used in quick incident response. More precisely, we evaluated the applicability of machine learning techniques for classifying unknown web access logs.
C1 [Nila, Constantin; Apostol, Ioana; Patriciu, Victor] Mil Tech Acad Ferdinand I, MTA, Comp Sci Dept, Bucharest, Romania.
   [Nila, Constantin] CERT RO, Romanian Natl Comp Secur Incident Response Team, Digital Forens & RnD, Bucharest, Romania.
RP Nila, C (corresponding author), Mil Tech Acad Ferdinand I, MTA, Comp Sci Dept, Bucharest, Romania.; Nila, C (corresponding author), CERT RO, Romanian Natl Comp Secur Incident Response Team, Digital Forens & RnD, Bucharest, Romania.
EM ctinnil@protonmail.com
RI Apostol, Ioana/AAP-7307-2021; Nila, Constantin/ABF-6175-2021
OI Nila, Constantin/0000-0002-1462-6237
FU Romanian Ministry of Research and Innovation, CCCDI -
   UEFISCDI/Avant-garde Technology Hub for Advanced Security (ATLAS),
   within PNCDI IIIConsiliul National al Cercetarii Stiintifice
   (CNCS)Unitatea Executiva pentru Finantarea Invatamantului Superior, a
   Cercetarii, Dezvoltarii si Inovarii (UEFISCDI)
   [PN-III-P1-1.2-PCCDI-2017-0272]
FX This work was supported by a grant of the Romanian Ministry of Research
   and Innovation, CCCDI - UEFISCDI, project number
   PN-III-P1-1.2-PCCDI-2017-0272/Avant-garde Technology Hub for Advanced
   Security (ATLAS), within PNCDI III.
NR 27
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-5611-8
PY 2020
BP 291
EP 296
PG 6
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Telecommunications
GA BQ6NO
UT WOS:000612723900051
DA 2022-04-17
ER

PT C
AU Al-Hammouri, S
   Fora, M
   Ibbini, M
AF Al-Hammouri, Sajidah
   Fora, Malak
   Ibbini, Mohammed
GP IEEE
TI Extreme Learning Machine for Melanoma Classification
SO 2021 IEEE JORDAN INTERNATIONAL JOINT CONFERENCE ON ELECTRICAL
   ENGINEERING AND INFORMATION TECHNOLOGY (JEEIT)
LA English
DT Proceedings Paper
CT IEEE Jordan International Joint Conference on Electrical Engineering and
   Information Technology (JEEIT)
CY NOV 16-17, 2021
CL JORDAN
SP IEEE, IEEE Jordan Sect, IEEE Reg 8, Jordan Engineers Assoc, Atypon
DE Melanoma; Features Extraction; Classification; Extreme Learning Machine
   (ELM); SVM; KNN
ID SYSTEM
AB Melanoma is considered the most dangerous type of skin cancer worldwide. Early detection of this cancer type plays an important role in the treatment process. Many invasive methods such as shaving were used for taking a biopsy from the patients for diagnosis. However, nowadays image processing techniques combined with machine learning can play a significant role in the diagnosis of medical images in a non-invasive way. To this end, this study aims to use machine learning algorithms for the early diagnosis and treatment of this type of cancer. Methodologically, the steps involved in this study are preprocessing of melanoma images, segmentation, features extraction, and then classification using the extreme learning machine (ELM) classifier. To the best of our knowledge, this classifier has not been used before for such types of images. This study aims to test the efficacy of using ELM in classifying these types of images compared with other common types of Machine learning algorithms such as Random Forest, support vector machine (SVM), and K-nearest neighbor (KNN). Promising results were obtained from ELM with an accuracy of 97%, 91% using 11 features, and 5 features, respectively.
C1 [Al-Hammouri, Sajidah; Fora, Malak; Ibbini, Mohammed] Jordan Univ Sci & Technol, Biomed Engn Dept, Irbid, Jordan.
RP Al-Hammouri, S (corresponding author), Jordan Univ Sci & Technol, Biomed Engn Dept, Irbid, Jordan.
EM sfalhammouri18@eng.just.edu.jo; mafora18@eng.just.edu.jo;
   mohib@just.edu.jo
NR 28
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-6654-4293-0
PY 2021
BP 114
EP 119
DI 10.1109/JEEIT53412.2021.9634135
PG 6
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BS7NW
UT WOS:000765316500020
DA 2022-04-17
ER

PT J
AU Liu, XB
   Hu, QB
   Cai, YM
   Cai, ZH
AF Liu, Xiaobo
   Hu, Qiubo
   Cai, Yaoming
   Cai, Zhihua
TI Extreme Learning Machine-Based Ensemble Transfer Learning for
   Hyperspectral Image Classification
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Ensemble learning; extreme learning machine; hyperspectral image
   classification; transfer learning
ID ADAPTATION; EXTRACTION
AB Although the extreme learning machine (ELM) has been successfully applied to hyperspectral image (HSI) classification, the development of the ELM is restricted by insufficient training data. In this article, we propose a novel extreme learning machine-based ensemble transfer learning algorithm for hyperspectral image classification named TL-ELM. TL-ELM not only retains the input weights and hidden biases of the ELM learned from the target domain, but also utilizes instances in the source domain to iteratively adjust the output weights of the ELM, which are used as the weights of the training models, and then ensembles the training models with their weights for the final classification. In experiments, we choose different regions in northern Italy, namely, Pavia University and Pavia Centre, as the source dataset and target dataset, respectively, and through a comparison with other transfer learning algorithms, we demonstrate that our proposed TL-ELM algorithm is superior on HSI classification tasks with only a few labeled data points in the target domain. Furthermore, we set Pavia University as the source dataset and Pavia Centre as the target dataset to demonstrate that our proposed method can effectively transfer useful instances between different HSIs.
C1 [Liu, Xiaobo] China Univ Geosci, Sch Automat, Wuhan 430074, Peoples R China.
   [Liu, Xiaobo] China Univ Geosci, Key Lab Adv Control & Intelligent Automat Complex, Wuhan 430074, Peoples R China.
   [Liu, Xiaobo] Minist Educ, Key Lab Geol Survey & Evaluat, Wuhan 430074, Peoples R China.
   [Hu, Qiubo; Cai, Yaoming; Cai, Zhihua] China Univ Geosci, Sch Comp Sci, Wuhan 430074, Peoples R China.
   [Cai, Zhihua] Qinzhou Univ, Beibu Gulf Big Data Resources Utilisat Lab, Qinzhou 535000, Peoples R China.
RP Cai, ZH (corresponding author), China Univ Geosci, Sch Comp Sci, Wuhan 430074, Peoples R China.
EM xbliu@cug.edu.cn; 1208966760@qq.com; caiyaomxc@outlook.com;
   zhcai@cug.edu.cn
RI Cai, Yaoming/AAF-5458-2020
OI Cai, Yaoming/0000-0002-2609-3036; Liu, Xiaobo/0000-0001-8298-7715
FU National Nature Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61973285, 61873249, 61773355]; National
   Nature Science Foundation of Hubei Province [2018CFB528]; Opening Fund
   of the Ministry of Education Key Laboratory of Geological Survey and
   Evaluation [CUG2019ZR10]; Fundamental Research Funds for the Central
   UniversitiesFundamental Research Funds for the Central Universities
   [CUGL170222]
FX This work was supported in part by the National Nature Science
   Foundation of China under Grant 61973285, Grant 61873249, and Grant
   61773355, in part by the National Nature Science Foundation of Hubei
   Province under Grant 2018CFB528, in part by the Opening Fund of the
   Ministry of Education Key Laboratory of Geological Survey and Evaluation
   under Grant CUG2019ZR10, and in part by the Fundamental Research Funds
   for the Central Universities under Grant CUGL170222.
NR 45
TC 6
Z9 6
U1 8
U2 22
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PY 2020
VL 13
BP 3892
EP 3902
DI 10.1109/JSTARS.2020.3006879
PG 11
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA ML2KR
UT WOS:000549301900006
OA gold
DA 2022-04-17
ER

PT J
AU Sun, SL
   Cao, ZH
   Zhu, H
   Zhao, J
AF Sun, Shiliang
   Cao, Zehui
   Zhu, Han
   Zhao, Jing
TI A Survey of Optimization Methods From a Machine Learning Perspective
SO IEEE TRANSACTIONS ON CYBERNETICS
LA English
DT Article
DE Machine learning; Optimization methods; Stochastic processes; Machine
   learning algorithms; Linear programming; Task analysis; Approximate
   Bayesian inference; deep neural network (DNN); machine learning;
   optimization method; reinforcement learning (RL)
ID QUASI-NEWTON METHODS; DERIVATIVE-FREE OPTIMIZATION; ALGORITHM; NETWORK;
   CONVEX; SYSTEM
AB Machine learning develops rapidly, which has made many theoretical breakthroughs and is widely applied in various fields. Optimization, as an important part of machine learning, has attracted much attention of researchers. With the exponential growth of data amount and the increase of model complexity, optimization methods in machine learning face more and more challenges. A lot of work on solving optimization problems or improving optimization methods in machine learning has been proposed successively. The systematic retrospect and summary of the optimization methods from the perspective of machine learning are of great significance, which can offer guidance for both developments of optimization and machine learning research. In this article, we first describe the optimization problems in machine learning. Then, we introduce the principles and progresses of commonly used optimization methods. Finally, we explore and give some challenges and open problems for the optimization in machine learning.
C1 [Sun, Shiliang; Cao, Zehui; Zhu, Han; Zhao, Jing] East China Normal Univ, Sch Comp Sci & Technol, Shanghai 200062, Peoples R China.
RP Zhao, J (corresponding author), East China Normal Univ, Sch Comp Sci & Technol, Shanghai 200062, Peoples R China.
EM shiliangsun@gmail.com; jzhao@cs.ecnu.edu.cn
FU NSFCNational Natural Science Foundation of China (NSFC) [61673179];
   Shanghai Sailing Program [17YF1404600]
FX This work was supported in part by NSFC under Project 61673179, and in
   part by Shanghai Sailing Program under Grant 17YF1404600.
NR 152
TC 58
Z9 59
U1 172
U2 296
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2267
EI 2168-2275
J9 IEEE T CYBERNETICS
JI IEEE T. Cybern.
PD AUG.
PY 2020
VL 50
IS 8
BP 3668
EP 3681
DI 10.1109/TCYB.2019.2950779
PG 14
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Computer Science, Cybernetics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA MK5FE
UT WOS:000548811800021
PM 31751262
OA Green Submitted
DA 2022-04-17
ER

PT C
AU Bhatt, U
   Xiang, A
   Sharma, S
   Weller, A
   Taly, A
   Jia, YH
   Ghosh, J
   Puri, R
   Moura, JMF
   Eckersley, P
AF Bhatt, Umang
   Xiang, Alice
   Sharma, Shubham
   Weller, Adrian
   Taly, Ankur
   Jia, Yunhan
   Ghosh, Joydeep
   Puri, Ruchir
   Moura, Jose M. F.
   Eckersley, Peter
GP Assoc Comp Machinery
TI Explainable Machine Learning in Deployment
SO FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS,
   ACCOUNTABILITY, AND TRANSPARENCY
LA English
DT Proceedings Paper
CT ACM Conference on Fairness, Accountability, and Transparency (FAT)
CY JAN 27-30, 2020
CL Barcelona, SPAIN
SP Assoc Comp Machinery
DE machine learning; explainability; transparency; deployed systems;
   qualitative study
ID PREDICTIONS; DECISIONS; FEATURES; MODELS
AB Explainable machine learning offers the potential to provide stakeholders with insights into model behavior by using various methods such as feature importance scores, counterfactual explanations, or influential training data. Yet there is little understanding of how organizations use these methods in practice. This study explores how organizations view and use explainability for stakeholder consumption. We find that, currently, the majority of deployments are not for end users affected by the model but rather for machine learning engineers, who use explainability to debug the model itself. There is thus a gap between explainability in practice and the goal of transparency, since explanations primarily serve internal stakeholders rather than external ones. Our study synthesizes the limitations of current explainability techniques that hamper their use for end users. To facilitate end user interaction, we develop a framework for establishing clear goals for explainability. We end by discussing concerns raised regarding explainability.
C1 [Bhatt, Umang; Moura, Jose M. F.] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
   [Bhatt, Umang; Xiang, Alice; Eckersley, Peter] Partnership AI, Pittsburgh, PA 15213 USA.
   [Bhatt, Umang; Weller, Adrian] Univ Cambridge, Cambridge, England.
   [Bhatt, Umang; Weller, Adrian] Leverhulme CFI, Cambridge, England.
   [Sharma, Shubham; Ghosh, Joydeep] Univ Texas Austin, Austin, TX 78712 USA.
   [Weller, Adrian] Alan Turing Inst, London, England.
   [Taly, Ankur] Fiddler Labs, London, England.
   [Jia, Yunhan] Baidu, Beijing, Peoples R China.
   [Ghosh, Joydeep] CognitiveScale, Beijing, Peoples R China.
   [Puri, Ruchir] IBM Res, Mountain View, CA USA.
RP Bhatt, U (corresponding author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.; Bhatt, U (corresponding author), Partnership AI, Pittsburgh, PA 15213 USA.; Bhatt, U (corresponding author), Univ Cambridge, Cambridge, England.; Bhatt, U (corresponding author), Leverhulme CFI, Cambridge, England.
FU DeepMind via the Leverhulme Centre for the Future of Intelligence (CFI);
   Partnership on AI research fellowship; David MacKay Newton research
   fellowship at Darwin College; Alan Turing Institute under EPSRCUK
   Research & Innovation (UKRI)Engineering & Physical Sciences Research
   Council (EPSRC) [EP/N510129/1, TU/B/000074]; Leverhulme Trust via CFI
FX UB acknowledges support from DeepMind via the Leverhulme Centre for the
   Future of Intelligence (CFI) and the Partnership on AI research
   fellowship. AWacknowledges support from the David MacKay Newton research
   fellowship at Darwin College, The Alan Turing Institute under EPSRC
   grant EP/N510129/1 & TU/B/000074, and the Leverhulme Trust via CFI.
NR 70
TC 51
Z9 52
U1 6
U2 9
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-6936-7
PY 2020
BP 648
EP 657
DI 10.1145/3351095.3375624
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Ethics
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Social Sciences - Other Topics
GA BQ8FJ
UT WOS:000620151400078
OA Green Submitted, Bronze
DA 2022-04-17
ER

PT J
AU Borith, T
   Bakhit, S
   Nasridinov, A
   Yoo, KH
AF Borith, Taing
   Bakhit, Sadirbaev
   Nasridinov, Aziz
   Yoo, Kwan-Hee
TI Prediction of Machine Inactivation Status Using Statistical Feature
   Extraction and Machine Learning
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE statistical feature extraction; machine learning; machine non-active
   state
ID NEAREST-NEIGHBOR RULE; FAULT-DETECTION; TIME
AB In modern manufacturing, the detection and prediction of machine anomalies, i.e., the inactive state of the machine during operation, is an important issue. Accurate inactive state detection models for factory machines can result in increased productivity. Moreover, they can guide engineers in implementing appropriate maintenance actions, which can prevent catastrophic failures and minimize economic losses. In this paper, we present a novel two-step data-driven method for the non-active detection of industry machines. First, we propose a feature extraction approach that aims to better distinguish the pattern of the active state and non-active state of the machine by multiple statistical analyses, such as reliability, time-domain, and frequency-domain analyses. Next, we construct a method to detect the active and non-active status of an industrial machine by applying various machine learning methods. The performance evaluation with a real-world dataset from the automobile part manufacturer demonstrates the proposed method achieves high accuracy.
C1 [Borith, Taing; Bakhit, Sadirbaev; Nasridinov, Aziz; Yoo, Kwan-Hee] Chungbuk Natl Univ, Dept Comp Sci, Cheongju 28644, South Korea.
RP Yoo, KH (corresponding author), Chungbuk Natl Univ, Dept Comp Sci, Cheongju 28644, South Korea.
EM tborith@gmail.com; sadirbaev@cbnu.ac.kr; aziz@chungbuk.ac.kr;
   khyoo@cbnu.ac.kr
FU Technology Innovation Program - Ministry of Trade, Industry & Energy
   (MOTIE, Korea) [2004367]; MSIT (Ministry of Science and ICT), Korea,
   under the Grand Information Technology Research Center support program
   [IITP-2020-0-01462]
FX This research was supported by the Technology Innovation Program
   (2004367, development of cloud big data platform for the innovative
   manufacturing in ceramic industry) funded by the Ministry of Trade,
   Industry & Energy (MOTIE, Korea) and by the MSIT (Ministry of Science
   and ICT), Korea, under the Grand Information Technology Research Center
   support program (IITP-2020-0-01462) supervised by the IITP (Institute
   for Information & communications Technology Planning & Evaluation)
NR 34
TC 2
Z9 2
U1 1
U2 3
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD NOV
PY 2020
VL 10
IS 21
AR 7413
DI 10.3390/app10217413
PG 18
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Materials Science; Physics
GA OQ6AO
UT WOS:000588864000001
OA gold
DA 2022-04-17
ER

PT J
AU Wang, P
   Fan, E
   Wang, P
AF Wang, Pin
   Fan, En
   Wang, Peng
TI Comparative analysis of image classification algorithms based on
   traditional machine learning and deep learning
SO PATTERN RECOGNITION LETTERS
LA English
DT Article
DE Traditional machine learning; Deep learning; Support vector machines;
   Convolutional neural networks
AB Image classification is a hot research topic in today's society and an important direction in the field of image processing research. SVM is a very powerful classification model in machine learning. CNN is a type of feedforward neural network that includes convolution calculation and has a deep structure. It is one of the representative algorithms of deep learning. Taking SVM and CNN as examples, this paper compares and analyzes the traditional machine learning and deep learning image classification algorithms. This study found that when using a large sample mnist dataset, the accuracy of SVM is 0.88 and the accuracy of CNN is 0.98; when using a small sample COREL1000 dataset, the accuracy of SVM is 0.86 and the accuracy of CNN is 0.83. The experimental results in this paper show that traditional machine learning has a better solution effect on small sample data sets, and deep learning framework has higher recognition accuracy on large sample data sets. (C) 2020 Published by Elsevier B.V.
C1 [Wang, Pin] Shenzhen Polytech, Sch Mech & Elect Engn, Shenzhen 518055, Guangdong, Peoples R China.
   [Fan, En] Shaoxing Univ, Dept Comp Sci & Engn, Shaoxing 312000, Zhejiang, Peoples R China.
   [Wang, Peng] Chinese Acad Sci, Garden Ctr, South China Bot Garden, Guangzhou 510650, Guangdong, Peoples R China.
RP Fan, E (corresponding author), Shaoxing Univ, Dept Comp Sci & Engn, Shaoxing 312000, Zhejiang, Peoples R China.
EM wangpin@vip.qq.com; efan@szu.edu.cn; wangpin@vip.qq.com
NR 25
TC 30
Z9 30
U1 29
U2 47
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8655
EI 1872-7344
J9 PATTERN RECOGN LETT
JI Pattern Recognit. Lett.
PD JAN
PY 2021
VL 141
BP 61
EP 67
DI 10.1016/j.patrec.2020.07.042
PG 7
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PQ7UZ
UT WOS:000606751200009
HC Y
HP N
DA 2022-04-17
ER

PT J
AU Quabeck, S
   Shangguan, W
   Scharfenstein, D
   De Doncker, RW
AF Quabeck, Stefan
   Shangguan, Wenbo
   Scharfenstein, Daniel
   De Doncker, Rik W.
TI Detection of Broken Rotor Bars in Induction Machines using Machine
   Learning Methods
SO IEEJ JOURNAL OF INDUSTRY APPLICATIONS
LA English
DT Article
DE induction machine; broken rotor bar; fault detection; machine learning
ID FAULT-DETECTION; DIAGNOSIS
AB Induction machines are used in a wide range of industrial applications due to their simplicity, ruggedness, and low price. Despite their robustness, induction machines eventually fail due to a variety of mechanisms. Most faults exhibit specific frequency components in the motor current spectrum, which allows for fault detection. Many classical fault detection methods have been developed for grid-connected machines with relatively fixed operating points. In inverter-driven machines with a wide operating range, these methods cannot reliably detect and classify faults. Machine learning methods have been successfully used for various classification tasks. This study therefore combines classical fault detection approaches with various fault classification algorithms to reliably detect induction machine faults over a wide operating range.
   The developed fault classification method is evaluated using steady-state measurements on an inverter-fed 5.5 kW induction machine. The algorithm shows promising fault detection and classification capabilities, achieving an accuracy of 97.4% over a wide load range.
C1 [Quabeck, Stefan; Shangguan, Wenbo; Scharfenstein, Daniel; De Doncker, Rik W.] Rhein Westfal TH Aachen, Inst Power Elect & Elect Drives ISEA, Jagerstr 17-19, D-52066 Aachen, Germany.
RP Quabeck, S (corresponding author), Rhein Westfal TH Aachen, Inst Power Elect & Elect Drives ISEA, Jagerstr 17-19, D-52066 Aachen, Germany.
EM stefan.quabeck@isea.rwth-aachen.de
FU European Regional Development FundEuropean Commission [EFRE-0800811]
FX The work for this paper has been funded by the European Regional
   Development Fund (EFRE-0800811).
NR 20
TC 0
Z9 0
U1 1
U2 1
PU INST ELECTRICAL ENGINEERS JAPAN
PI TOKYP
PA INST ELECTRICAL ENGINEERS JAPAN, TOKYP, 00000, JAPAN
SN 2187-1094
EI 2187-1108
J9 IEEJ J IND APPL
JI IEEJ J. Ind. Appl.
PY 2021
VL 10
IS 6
SI SI
BP 688
EP 693
DI 10.1541/ieejjia.21000651
PG 6
WC Engineering, Electrical & Electronic
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA WQ2CP
UT WOS:000713628300013
OA gold
DA 2022-04-17
ER

PT C
AU Turtletaub, I
   Li, G
   Ibrahim, M
   Franzon, P
AF Turtletaub, Isaac
   Li, George
   Ibrahim, Mohannad
   Franzon, Paul
GP ACM
TI Application of Quantum Machine Learning to VLSI Placement
SO PROCEEDINGS OF THE 2020 ACM/IEEE 2ND WORKSHOP ON MACHINE LEARNING FOR
   CAD (MLCAD '20)
LA English
DT Proceedings Paper
CT 2nd ACM/IEEE Workshop on Machine Learning for CAD (MLCAD)
CY NOV 16-20, 2020
CL ELECTR NETWORK
SP IEEE, Assoc Comp Machinery, ACM Special Interest Grp Design Automat, IEEE Council Elect Design Automat
DE Quantum Machine Learning; Balanced Min-Cut; Variational Quantum
   Eigensolver; Recursive Partitioning Placement
AB Considerable advances in quantum computing with functioning noisy, near-term devices have allowed for the application space to grow as a emerging field for problems with large solution spaces. However, current quantum hardware is limited in scale and noisy in generated data, necessitating hybrid quantum-classical solutions for viability of results and convergence. A quantum backend generates data for classical algorithms to optimize control parameters with, creating a hybrid quantum-classical computing loop. VLSI placement problems have shown potential for utilization, where traditionally heuristic solutions such as Kernighan-Lin (KL) are used. The Variational Quantum Eigensolver (VQE) is used to formulate a recursive Balanced Min-Cut (BMC) algorithm, and we suggest that quantum machine learning techniques can lower error rates and allow for faster convergence to an optimal solution.
C1 [Turtletaub, Isaac; Li, George; Ibrahim, Mohannad; Franzon, Paul] North Carolina State Univ, Raleigh, NC 27695 USA.
RP Turtletaub, I (corresponding author), North Carolina State Univ, Raleigh, NC 27695 USA.
EM iturtle@ncsu.edu; gpli@ncsu.edu; mmibrah2@ncsu.edu; paulf@ncsu.edu
OI , Mohannad/0000-0001-7776-8905; Franzon, Paul/0000-0002-6048-5770
FU National Science FoundationNational Science Foundation (NSF)
   [CNS-1624770]; CAEML IUCRC
FX This work was funded in part by the National Science Foundation as an
   REU supplement to NSF Award, CNS-1624770, the CAEML IUCRC. Access to the
   IBM Q Network was obtained through the IBM Q Hub at NC State.
NR 20
TC 0
Z9 0
U1 1
U2 2
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-7519-1
PY 2020
BP 61
EP 66
DI 10.1145/3380446.3430644
PG 6
WC Computer Science, Artificial Intelligence; Engineering, Manufacturing;
   Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BR8CI
UT WOS:000670756800013
DA 2022-04-17
ER

PT J
AU Tahir, GA
   Loo, CK
AF Tahir, Ghalib Ahmed
   Loo, Chu Kiong
TI An Open-Ended Continual Learning for Food Recognition Using Class
   Incremental Extreme Learning Machines
SO IEEE ACCESS
LA English
DT Article
DE Food recognition; deep learning; open-ended continual learning; class
   incremental extreme learning machine; adaptive class incremental extreme
   learning machine; adaptive reduced class incremental kernel extreme
   learning machine
ID CLASSIFICATION; FEATURES
AB State-of-the-art deep learning models for food recognition do not allow data incremental learning and often suffer from catastrophic interference problems during the class incremental learning. This is an important issue in food recognition since real-world food datasets are open-ended and dynamic, involving a continuous increase in food samples and food classes. Model retraining is often carried out to cope with the dynamic nature of the data, but this demands high-end computational resources and significant time. This paper proposes a new open-ended continual learning framework by employing transfer learning on deep models for feature extraction, Relief F for feature selection, and a novel adaptive reduced class incremental kernel extreme learning machine (ARCIKELM) for classification. Transfer learning is beneficial due to the high generalization ability of deep learning features. Relief F reduces computational complexity by ranking and selecting the extracted features. The novel ARCIKELM classifier dynamically adjusts network architecture to reduce catastrophic forgetting. It addresses domain adaptation problems when new samples of the existing class arrive. To conduct comprehensive experiments, we evaluated the model against four standard food benchmarks and a recently collected Pakistani food dataset. Experimental results show that the proposed framework learns new classes incrementally with less catastrophic inference and adapts domain changes while having competitive classification performance.
C1 [Tahir, Ghalib Ahmed; Loo, Chu Kiong] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur 50603, Malaysia.
RP Loo, CK (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur 50603, Malaysia.
EM ckloo.um@um.edu.my
RI Loo, Chu Kiong/AAI-5093-2021; Loo, Chu Kiong/F-4360-2011
OI Loo, Chu Kiong/0000-0001-7867-2665; Loo, Chu Kiong/0000-0001-7867-2665
FU Grand Challenge Grant - HTM (Wellness) [GC003A-14HTM]; University of
   Malaya, IIRG [IIRG002C-19HWB]; University of Malaya, International
   Collaboration Fund for project Developmental Cognitive Robot with
   Continual Lifelong Learning [IF0318M1006]; MESTECC, Malaysia
   [ONRG-NICOP-N62909-18-1-2086]; ONRG Grant [ONRG-NICOP-N62909-18-1-2086];
   Office of Naval and Research Global, U.K. [IF017-2018]
FX This work was supported in part by the Grand Challenge Grant - HTM
   (Wellness) under Grant GC003A-14HTM, in part by the University of
   Malaya, IIRG under Grant under Grant IIRG002C-19HWB, in part by the
   University of Malaya, International Collaboration Fund for project
   Developmental Cognitive Robot with Continual Lifelong Learning under
   Grant IF0318M1006, in part by the MESTECC, Malaysia and ONRG Grant under
   Project ONRG-NICOP-N62909-18-1-2086, and in part by the Office of Naval
   and Research Global, U.K., under Grant IF017-2018.
NR 59
TC 10
Z9 10
U1 6
U2 18
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 82328
EP 82346
DI 10.1109/ACCESS.2020.2991810
PG 19
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA ML5JL
UT WOS:000549502200054
OA gold
DA 2022-04-17
ER

PT J
AU Sun, P
   Yang, LM
AF Sun, Ping
   Yang, Liming
TI Generalized eigenvalue extreme learning machine for classification
SO APPLIED INTELLIGENCE
LA English
DT Article; Early Access
DE Generalized eigenvalue; Extreme learning machine; Inter-class graph;
   Non-parallel separating hyperplanes
ID SUPPORT VECTOR MACHINE; SVM
AB Extreme learning machine (ELM) has attracted widespread attention due to its simple, quick and good performance. In this work, in order to deal with cross data quickly and efficiently, we first propose generalized eigenvalue proximal extreme learning machine (GEPELM). It takes the form of ratio into consideration to seek for two non-parallel separating hyperplanes in ELM feature space, each of which is close to the samples of its own class and far away from the others simultaneously. Then generalized eigenvalue algorithm is adopted to solve, which incurs GEPELM to enjoy faster calculation speed than TELM. Further, improved generalized eigenvalue proximal extreme learning machine (IGEPELM) is proposed, which uses minus instead of ratio to avoid singular value phenomenon and further mitigate the computational burden by solving two standard eigenvalue problems. To further improve classification performance, generalized eigenvalue proximal extreme learning machine based on inter-class graph (GGEPELM) is proposed, which incorporates the geometric structure information of dissimilar samples into the guideline of GEPELM. In addition, the proposed classifiers are all extended to kernel ELM framework to handle non-linear data more precisely. Moreover, Sherman-Morrison-Woodbury formula is utilized to reduce time complexity of matrix inversion. Simultaneously, a quick solution strategy is incorporated into GEPELMs and GGEPELMs to mitigate the burden of solving large-scale problems. The numerical simulations are carried out on three databases including a benchmark database, an artificial database and a practical application database, which demonstrates the proposed classifiers enjoy high computational speed, good generalization performance and insensitivity to parameters.
C1 [Sun, Ping; Yang, Liming] China Agr Univ, Coll Sci, Beijing 100083, Peoples R China.
RP Yang, LM (corresponding author), China Agr Univ, Coll Sci, Beijing 100083, Peoples R China.
EM cauyanglm@163.com
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [11471010, 11271367]
FX This work was supported in part by National Natural Science Foundation
   of China (No11471010, No 11271367). Moreover, the authors thank the
   referees and editor for their constructive comments to improve the
   paper.
NR 46
TC 0
Z9 0
U1 6
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
DI 10.1007/s10489-021-02654-2
EA SEP 2021
PG 30
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UP5LX
UT WOS:000695422500002
DA 2022-04-17
ER

PT C
AU Zhang, W
   Wu, YQ
   Lin, YG
   Ma, LN
   Han, KF
   Chen, Y
   Liu, C
AF Zhang, Wen
   Wu, Yanqun
   Lin, Yonggang
   Ma, Lina
   Han, Kaifeng
   Chen, Yu
   Liu, Chen
GP IEEE
TI Underwater Target Detection Based on Machine Learning
SO 2020 IEEE 3RD INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND
   SIGNAL PROCESSING (ICICSP 2020)
LA English
DT Proceedings Paper
CT 3rd IEEE International Conference on Information Communication and
   Signal Processing (ICICSP)
CY SEP 12-15, 2020
CL ELECTR NETWORK
SP IEEE, Saitama Univ, Middlesex Univ, Leuphana Univ Luneburg
DE machine learning; deep learning; bad channel detection; beamforming;
   classification; target tracking; source localization
ID LOCALIZATION
AB Underwater target detection is an important part of acoustic signal processing. It is mainly composed of bad channel detection, beamforming, classification, tracking and localization. In this paper, the possibility of realizing bad channel detection, classification, tracking and localization based on Machine Learning or Deep Learning was explored. And they were all implemented separately and successfully using Machine Learning or Deep Learning.
C1 [Zhang, Wen; Wu, Yanqun; Lin, Yonggang; Ma, Lina; Han, Kaifeng; Chen, Yu; Liu, Chen] Natl Univ Def Technol, Coll Meteorol & Oceanol, Changsha 410073, Peoples R China.
RP Zhang, W (corresponding author), Natl Univ Def Technol, Coll Meteorol & Oceanol, Changsha 410073, Peoples R China.
EM zhangwen06@nudt.edu.cn; yqwu_nudt@163.com; min_c7@nudt.edu.cn;
   hankaifeng@nudt.edu.cn; chenyunudt@163.com
NR 17
TC 0
Z9 0
U1 17
U2 21
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-8823-2
PY 2020
BP 210
EP 214
PG 5
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BR0UG
UT WOS:000630910300043
DA 2022-04-17
ER

PT J
AU Ding, KX
   Lev, B
   Peng, X
   Sun, T
   Vasarhelyi, MA
AF Ding, Kexing
   Lev, Baruch
   Peng, Xuan
   Sun, Ting
   Vasarhelyi, Miklos A.
TI Machine learning improves accounting estimates: evidence from insurance
   payments
SO REVIEW OF ACCOUNTING STUDIES
LA English
DT Article
DE Machine learning; Accounting estimates
ID INSURER RESERVE ERROR
AB Managerial estimates are ubiquitous in accounting: most balance sheet and income statement items are based on estimates; some, such as the pension and employee stock options expenses, derive from multiple estimates. These estimates are affected by objective estimation errors as well as by managerial manipulation, thereby harming the reliability and relevance of financial reports. We show that machine learning can substantially improve managerial estimates. Specifically, using insurance companies' data on loss reserves (future customer claims) estimates and realizations, we document that the loss estimates generated by machine learning were superior to actual managerial estimates reported in financial statements in four out of five insurance lines examined. Our evidence suggests that machine learning techniques can be highly useful to managers and auditors in improving accounting estimates, thereby enhancing the usefulness of financial information to investors.
C1 [Ding, Kexing; Peng, Xuan] Southwestern Univ Finance & Econ, Newark, NJ USA.
   [Ding, Kexing; Peng, Xuan; Vasarhelyi, Miklos A.] Rutgers State Univ, New Brunswick, NJ 07102 USA.
   [Lev, Baruch] NYU, Stern Sch Business, New York, NY USA.
   [Sun, Ting] Coll New Jersey, Ewing Township, NJ USA.
RP Vasarhelyi, MA (corresponding author), Rutgers State Univ, New Brunswick, NJ 07102 USA.
EM dingkx@swufe.edu.cn; blev@stern.nyu.edu; pengxuan@swufe.edu.cn;
   sunt@tcnj.edu; miklosv@business.rutgers.edu
OI vasarhelyi, miklos/0000-0003-3205-476X
FU Rutgers Continuous Auditing Research Lab
FX The authors would like to thank Richard Sloan (editor), Patricia Dechow,
   Stephen Ryan, Jeremy Bertomeu (our discussant at the 2019 RAST Annual
   Conference), Russell Lundholm, Richard Crowley, Ganapathi
   Narayanamoorthy, Alexander Kogan, Michael Alles, two anonymous referees,
   and conference participants at RAST 2019 Annual Conference for helpful
   comments. All authors contributed equally to this work. Kexing Ding and
   Xuan Peng are thankful to Rutgers Continuous Auditing Research Lab for
   financial support.
NR 40
TC 9
Z9 10
U1 21
U2 59
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-6653
EI 1573-7136
J9 REV ACCOUNT STUD
JI Rev. Account. Stud.
PD SEP
PY 2020
VL 25
IS 3
BP 1098
EP 1134
DI 10.1007/s11142-020-09546-9
EA JUL 2020
PG 37
WC Business, Finance
WE Social Science Citation Index (SSCI)
SC Business & Economics
GA OB1TV
UT WOS:000546724700001
DA 2022-04-17
ER

PT C
AU Pardede, HF
   Suryawati, E
   Krisnandi, D
   Yuwana, RS
   Zilvan, V
AF Pardede, Hilman F.
   Suryawati, Endang
   Krisnandi, Dikdik
   Yuwana, R. Sandra
   Zilvan, Vicky
GP IEEE
TI Machine Learning Based Plant Diseases Detection: A Review
SO 2020 INTERNATIONAL CONFERENCE ON RADAR, ANTENNA, MICROWAVE, ELECTRONICS,
   AND TELECOMMUNICATIONS (ICRAMET): FOSTERING INNOVATION THROUGH ICTS FOR
   SUSTAINABLE SMART SOCIETY
LA English
DT Proceedings Paper
CT International Conference on Radar, Antenna, Microwave, Electronics, and
   Telecommunications (ICRAMET)
CY NOV 18-20, 2020
CL ELECTR NETWORK
SP LIPI, IEEE Indonesia Sect, Indonesian Inst Sci, Res Ctr Elect & Telecommunicat, Indonesian Inst Sci, Res Ctr Informat, Indonesian Inst Sci
DE machine learning; deep learning; plant diseases; feature extraction;
   agriculture
AB Currently, applying machine learning technologies for management and monitoring of agricultural products are gaining significant interests. One of them is for plant diseases detection. Plant diseases are major cause of crop losses. The existence of automatic plant diseases detection is essential to predict the plant diseases as early as possible, and hence, reducing the crop losses. In this paper, we presents a review of advancement of machine learning technologies for plant diseases detection. Various approaches have been proposed in the field. In this review, we group them into two: works that focus on finding good features for shallow machine learning architectures such as SVM, those that focus on applying deep architectures of machine learning such as deep convolutional neural networks (CNN). For the later, we observe that the works either applied CNN as classifier or as feature learning. Our survey shows that while (CNN), have become the lead technologies in the field, replacing shallow architectures like SVM, many challenges still remain. First is the issue of robustness against environmental conditions. Second in on how to deal large variety of data and diseases with limited number of data.
C1 [Pardede, Hilman F.; Suryawati, Endang; Krisnandi, Dikdik; Yuwana, R. Sandra; Zilvan, Vicky] Indonesian Inst Sci, Res Ctr Informat, Bandung, Indonesia.
RP Pardede, HF (corresponding author), Indonesian Inst Sci, Res Ctr Informat, Bandung, Indonesia.
EM hilm001@lipi.go.id; enda029@lipi.go.id; dikd003@lipi.go.id;
   rade014@lipi.go.id; vick001@lipi.go.id
NR 62
TC 1
Z9 1
U1 3
U2 3
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-8922-2
PY 2020
BP 212
EP 217
PG 6
WC Engineering, Electrical & Electronic; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering; Telecommunications
GA BS4DO
UT WOS:000717636400044
DA 2022-04-17
ER

PT J
AU Kwekha-Rashid, AS
   Abduljabbar, HN
   Alhayani, B
AF Kwekha-Rashid, Ameer Sardar
   Abduljabbar, Heamn N.
   Alhayani, Bilal
TI Coronavirus disease (COVID-19) cases analysis using machine-learning
   applications
SO APPLIED NANOSCIENCE
LA English
DT Article; Early Access
DE COVID-19; Artificial intelligence AI; Machine learning; Machine learning
   tasks; Supervised and un-supervised learning
ID PREDICTION; ALGORITHMS
AB Today world thinks about coronavirus disease that which means all even this pandemic disease is not unique. The purpose of this study is to detect the role of machine-learning applications and algorithms in investigating and various purposes that deals with COVID-19. Review of the studies that had been published during 2020 and were related to this topic by seeking in Science Direct, Springer, Hindawi, and MDPI using COVID-19, machine learning, supervised learning, and unsupervised learning as keywords. The total articles obtained were 16,306 overall but after limitation; only 14 researches of these articles were included in this study. Our findings show that machine learning can produce an important role in COVID-19 investigations, prediction, and discrimination. In conclusion, machine learning can be involved in the health provider programs and plans to assess and triage the COVID-19 cases. Supervised learning showed better results than other Unsupervised learning algorithms by having 92.9% testing accuracy. In the future recurrent supervised learning can be utilized for superior accuracy.
C1 [Kwekha-Rashid, Ameer Sardar] Univ Sulaimani, Coll Adm & Econ, Business Informat Technol, Sulaimaniya, Iraq.
   [Abduljabbar, Heamn N.] Salahaddin Univ, Coll Educ, Phys Dept, Shaqlawa, Iraq.
   [Abduljabbar, Heamn N.] Univ Putra Malaysia UPM, Dept Radiol & Imaging, Fac Med & Hlth Sci, Seri Kembangan, Malaysia.
   [Alhayani, Bilal] Yildiz Tech Univ, Elect & Commun Dept, Istanbul, Turkey.
RP Kwekha-Rashid, AS (corresponding author), Univ Sulaimani, Coll Adm & Econ, Business Informat Technol, Sulaimaniya, Iraq.
EM ameer.rashid@univsul.edu.iq; heamn.abduljabbar@su.edu.krd;
   bilalabed1978@gmail.com
RI Alhayani, Bilal/AAM-1142-2020; rashid, ameer/AAR-2610-2021; Kwekha
   Rashid, Ameer Sardar/AAQ-9112-2021
OI Alhayani, Bilal/0000-0001-9309-3573; rashid, ameer/0000-0003-1422-1878;
   Kwekha Rashid, Ameer Sardar/0000-0003-1422-1878
NR 38
TC 54
Z9 54
U1 30
U2 34
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 2190-5509
EI 2190-5517
J9 APPL NANOSCI
JI Appl. Nanosci.
DI 10.1007/s13204-021-01868-7
EA MAY 2021
PG 13
WC Nanoscience & Nanotechnology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA SF7WO
UT WOS:000652961400002
PM 34036034
OA Bronze, Green Published
HC Y
HP N
DA 2022-04-17
ER

PT J
AU Liyew, CM
   Melese, HA
AF Liyew, Chalachew Muluken
   Melese, Haileyesus Amsaya
TI Machine learning techniques to predict daily rainfall amount
SO JOURNAL OF BIG DATA
LA English
DT Article
DE Machine learning; MLR; RF; XGBoost; Rainfall prediction
AB Predicting the amount of daily rainfall improves agricultural productivity and secures food and water supply to keep citizens healthy. To predict rainfall, several types of research have been conducted using data mining and machine learning techniques of different countries' environmental datasets. An erratic rainfall distribution in the country affects the agriculture on which the economy of the country depends on. Wise use of rainfall water should be planned and practiced in the country to minimize the problem of the drought and flood occurred in the country. The main objective of this study is to identify the relevant atmospheric features that cause rainfall and predict the intensity of daily rainfall using machine learning techniques. The Pearson correlation technique was used to select relevant environmental variables which were used as an input for the machine learning model. The dataset was collected from the local meteorological office at Bahir Dar City, Ethiopia to measure the performance of three machine learning techniques (Multivariate Linear Regression, Random Forest, and Extreme Gradient Boost). Root mean squared error and Mean absolute Error methods were used to measure the performance of the machine learning model. The result of the study revealed that the Extreme Gradient Boosting machine learning algorithm performed better than others.
C1 [Liyew, Chalachew Muluken; Melese, Haileyesus Amsaya] Bahir Dar Univ, Bahir Dar Inst Technol, Bahir Dar, Ethiopia.
RP Liyew, CM (corresponding author), Bahir Dar Univ, Bahir Dar Inst Technol, Bahir Dar, Ethiopia.
EM chalachewsweet@gmail.com
NR 19
TC 0
Z9 0
U1 3
U2 3
PU SPRINGERNATURE
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND
EI 2196-1115
J9 J BIG DATA-GER
JI J. Big Data
PD DEC 7
PY 2021
VL 8
IS 1
AR 153
DI 10.1186/s40537-021-00545-4
PG 11
WC Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XL7OH
UT WOS:000728330600001
OA Green Submitted, gold
DA 2022-04-17
ER

PT J
AU Dogan, A
   Birant, D
AF Dogan, Alican
   Birant, Derya
TI Machine learning and data mining in manufacturing
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Review
DE Machine learning; Data mining; Manufacturing; Classification; Clustering
AB Manufacturing organizations need to use different kinds of techniques and tools in order to fulfill their foundation goals. In this aspect, using machine learning (ML) and data mining (DM) techniques and tools could be very helpful for dealing with challenges in manufacturing. Therefore, in this paper, a comprehensive literature review is presented to provide an overview of how machine learning techniques can be applied to realize manufacturing mechanisms with intelligent actions. Furthermore, it points to several significant research questions that are unanswered in the recent literature having the same target. Our survey aims to provide researchers with a solid understanding of the main approaches and algorithms used to improve manufacturing processes over the past two decades. It presents the previous ML studies and recent advances in manufacturing by grouping them under four main subjects: scheduling, monitoring, quality, and failure. It comprehensively discusses existing solutions in manufacturing according to various aspects, including tasks (i.e., clustering, classification, regression), algorithms (i.e., support vector machine, neural network), learning types (i.e., ensemble learning, deep learning), and performance metrics (i.e., accuracy, mean absolute error). Furthermore, the main steps of knowledge discovery in databases (KDD) process to be followed in manufacturing applications are explained in detail. In addition, some statistics about the current state are also given from different perspectives. Besides, it explains the advantages of using machine learning techniques in manufacturing, expresses the ways to overcome certain challenges, and offers some possible further research directions.
C1 [Dogan, Alican] Dokuz Eylul Univ, Grad Sch Nat & Appl Sci, Izmir, Turkey.
   [Birant, Derya] Dokuz Eylul Univ, Dept Comp Engn, Izmir, Turkey.
RP Birant, D (corresponding author), Dokuz Eylul Univ, Dept Comp Engn, Izmir, Turkey.
EM alican.dogan@deu.edu.tr; derya@cs.deu.edu.tr
RI Birant, Derya/U-6211-2017; 于, 于增臣/AAH-4657-2021
OI Birant, Derya/0000-0003-3138-0432; 
NR 127
TC 36
Z9 36
U1 156
U2 307
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD MAR 15
PY 2021
VL 166
AR 114060
DI 10.1016/j.eswa.2020.114060
PG 22
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA PE7DI
UT WOS:000598522500014
HC Y
HP N
DA 2022-04-17
ER

PT C
AU Nguyen, CV
   Das, SR
   He, J
   Yue, SH
   Hanumaiah, V
   Ragot, X
   Zhang, L
AF Nguyen, Cuong, V
   Das, Sanjiv R.
   He, John
   Yue, Shenghua
   Hanumaiah, Vinay
   Ragot, Xavier
   Zhang, Li
BE Chan, WK
   Claycomb, B
   Takakura, H
   Yang, JJ
   Teranishi, Y
   Towey, D
   Segura, S
   Shahriar, H
   Reisman, S
   Ahamed, SI
TI Multimodal Machine Learning for Credit Modeling
SO 2021 IEEE 45TH ANNUAL COMPUTERS, SOFTWARE, AND APPLICATIONS CONFERENCE
   (COMPSAC 2021)
SE Proceedings International Computer Software and Applications Conference
LA English
DT Proceedings Paper
CT 45th Annual International IEEE-Computer-Society Computers, Software, and
   Applications Conference (COMPSAC)
CY JUL 12-16, 2021
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc
DE credit ratings; multimodal; machine learning; long-form text
ID FINANCIAL RATIOS; PREDICTION; TEXT
AB Credit ratings are traditionally generated using models that use financial statement data and market data, which is tabular (numeric and categorical). Practitioner and academic models do not include text data. Using an automated approach to combine long-form text from SEC filings with the tabular data, we show how multimodal machine learning using stack ensembling and bagging can generate more accurate rating predictions. This paper demonstrates a methodology to use big data to extend tabular data models, which have been used by the ratings industry for decades, to the class of multimodal machine learning models.
C1 [Nguyen, Cuong, V] Amazon Web Serv, Pasadena, CA 91125 USA.
   [Das, Sanjiv R.] AWS, Palo Alto, CA 94303 USA.
   [Das, Sanjiv R.] Santa Clara Univ, Palo Alto, CA 94303 USA.
   [He, John; Yue, Shenghua; Hanumaiah, Vinay] Amazon Web Serv, Palo Alto, CA 94303 USA.
   [Ragot, Xavier] Amazon Web Serv, San Francisco, CA 94111 USA.
   [Zhang, Li] Amazon Web Serv, New York, NY 10001 USA.
RP Nguyen, CV (corresponding author), Amazon Web Serv, Pasadena, CA 91125 USA.
EM nguycuo@amazon.com; sanjivda@amazon.com; hezhijia@amazon.com;
   yuesheng@amazon.com; vinayha@amazon.com; xragot@amazon.com;
   lzhangza@amazon.com
NR 30
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
SN 0730-3157
BN 978-1-6654-2463-9
J9 P INT COMP SOFTW APP
PY 2021
BP 1754
EP 1759
DI 10.1109/COMPSAC51774.2021.00262
PG 6
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS2RI
UT WOS:000706529000251
DA 2022-04-17
ER

PT C
AU Zhao, QL
   Sun, JW
   Ren, HJ
   Sun, GD
AF Zhao, Quanling
   Sun, Jiawei
   Ren, Hongjia
   Sun, Guodong
GP IEEE
TI Machine-Learning Based TCP Security Action Prediction
SO 2020 5TH INTERNATIONAL CONFERENCE ON MECHANICAL, CONTROL AND COMPUTER
   ENGINEERING (ICMCCE 2020)
LA English
DT Proceedings Paper
CT 5th International Conference on Mechanical, Control and Computer
   Engineering (ICMCCE)
CY DEC 25-27, 2020
CL Harbin, PEOPLES R CHINA
SP Xijing Univ, Acad Exchange Informat Ctr
DE TCP Security Action; Firewalls; Machine Learning; Ensemble learning;
   Prediction; Cyber Security
AB With the continuous growth of Internet technology and the increasingly broadening applications of The Internet, network security incidents as well as cyber-attacks are also showing a growing trend. Consequently, computer network security is becoming increasingly important. TCP firewall is a computer network security system, and it allows or denies the transmission of data according to specific rules for providing security for the computer network. Traditional firewalls rely on network administrators to set security rules for them, and network administrators sometimes need to choose to allow and deny packets to keep computer networks secure. However, due to the huge amount of data on the Internet, network administrators have a huge task. Therefore, it is particularly important to solve this problem by using the machine learning method of computer technology. This study aims to predict TCP security action based on the TCP transmission characteristics dataset provided by UCI machine learning repository by implementing machine learning models such as neural network, support vector machine (SVM), AdaBoost, and Logistic regression. Processes including evaluating various models and interpretability analysis. By utilizing the idea of ensemble-learning, the final result has an accuracy score of over 98%.
C1 [Zhao, Quanling] Santa Monica Coll, Comp Sci Dept, Santa Monica, CA 90405 USA.
   [Sun, Jiawei] Univ Nottingham Ningbo China, Dept Elect & Elect Engn, Ningbo, Peoples R China.
   [Ren, Hongjia] Chengdu Univ, Sch Tourism & Culture Ind, Chengdu, Peoples R China.
   [Sun, Guodong] Northwest Univ, Sch Informat Sci & Technol, Xian, Peoples R China.
RP Zhao, QL (corresponding author), Santa Monica Coll, Comp Sci Dept, Santa Monica, CA 90405 USA.
EM qlzhao0304@gmail.com
NR 7
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-6654-2314-4
PY 2020
BP 1325
EP 1329
DI 10.1109/ICMCCE51767.2020.00291
PG 5
WC Automation & Control Systems; Engineering, Electrical & Electronic;
   Engineering, Mechanical
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Automation & Control Systems; Engineering
GA BR9HD
UT WOS:000675598100282
DA 2022-04-17
ER

PT J
AU Chen, JM
AF Chen, James Ming
TI An Introduction to Machine Learning for Panel Data
SO INTERNATIONAL ADVANCES IN ECONOMIC RESEARCH
LA English
DT Editorial Material
DE Machine learning; Bias-variance tradeoff; Decision trees; Random
   forests; Extra trees; XGBoost; Learning ensembles; Boosting; Support
   vector machines; Neural networks
AB Machine learning has dramatically expanded the range of tools for evaluating economic panel data. This paper applies a variety of machine-learning methods to the Boston housing dataset, an iconic proving ground for machine learning. Though machine learning often lacks the overt interpretability of linear regression, methods based on decision trees score the relative importance of dataset features. In addition to addressing the theoretical tradeoff between bias and variance, this paper discusses practices rarely followed in traditional economics: the splitting of data into training, validation, and test sets; the scaling of data; and the preference for retaining all data. The choice between traditional and machine-learning methods hinges on practical rather than mathematical considerations. In settings emphasizing interpretative clarity through the scale and sign of regression coefficients, machine learning may best play an ancillary role. Wherever predictive accuracy is paramount, however, or where heteroskedasticity or high dimensionality might impair the clarity of linear methods, machine learning can deliver superior results.
C1 [Chen, James Ming] Michigan State Univ, Justin Smith Morrill Chair Law, E Lansing, MI 48824 USA.
   [Chen, James Ming] Silver Leaf Capital LLC, New York, NY 91324 USA.
RP Chen, JM (corresponding author), Michigan State Univ, Justin Smith Morrill Chair Law, E Lansing, MI 48824 USA.; Chen, JM (corresponding author), Silver Leaf Capital LLC, New York, NY 91324 USA.
EM chenjame@law.msu.edu
RI Chen, James/AAN-6668-2021
OI Chen, James/0000-0001-9824-174X
NR 47
TC 4
Z9 4
U1 9
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1083-0898
EI 1573-966X
J9 INT ADV ECON RES
JI Int. Adv. Econ. Res.
PD FEB
PY 2021
VL 27
IS 1
BP 1
EP 16
DI 10.1007/s11294-021-09815-6
EA MAR 2021
PG 16
WC Economics
WE Emerging Sources Citation Index (ESCI)
SC Business & Economics
GA SF9DM
UT WOS:000625545300001
DA 2022-04-17
ER

PT J
AU Merkin, A
   Krishnamurthi, R
   Medvedev, ON
AF Merkin, Alexander
   Krishnamurthi, Rita
   Medvedev, Oleg N.
TI Machine learning, artificial intelligence and the prediction of dementia
SO CURRENT OPINION IN PSYCHIATRY
LA English
DT Review
DE artificial intelligence; cognitive impairment; dementia; machine
   learning
ID METHODOLOGY
AB Purpose of review Artificial intelligence and its division machine learning are emerging technologies that are increasingly applied in medicine. Artificial intelligence facilitates automatization of analytical modelling and contributes to prediction, diagnostics and treatment of diseases. This article presents an overview of the application of artificial intelligence in dementia research. Recent findings Machine learning and its branch Deep Learning are widely used in research to support in diagnosis and prediction of dementia. Deep Learning models in certain tasks often result in better accuracy of detection and prediction of dementia than traditional machine learning methods, but they are more costly in terms of run times and hardware requirements. Both machine learning and Deep Learning models have their own strengths and limitations. Currently, there are few datasets with limited data available to train machine learning models. There are very few commercial applications of machine learning in medical practice to date, mostly represented by mobile applications, which include questionnaires and psychometric assessments with limited machine learning data processing. Application of machine learning technologies in detection and prediction of dementia may provide an advantage to psychiatry and neurology by promoting a better understanding of the nature of the disease and more accurate evidence-based processes that are reproducible and standardized.
C1 [Merkin, Alexander; Krishnamurthi, Rita] Auckland Univ Technol, Auckland, New Zealand.
   [Medvedev, Oleg N.] Univ Waikato, Sch Psychol, Hamilton, New Zealand.
RP Merkin, A (corresponding author), Auckland Univ Technol, Natl Inst Stroke & Appl Neurosci, Fac Hlth & Environm Sci, Private Bag 92006, Auckland 1142, New Zealand.
EM amerkin@aut.ac.nz
RI Medvedev, Oleg N./AAO-8339-2020
OI Medvedev, Oleg N./0000-0002-2167-5002
NR 55
TC 0
Z9 0
U1 25
U2 25
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0951-7367
EI 1473-6578
J9 CURR OPIN PSYCHIATR
JI Curr. Opin. Psychiatr.
PD MAR
PY 2022
VL 35
IS 2
BP 123
EP 129
DI 10.1097/YCO.0000000000000768
PG 7
WC Psychiatry
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Psychiatry
GA YN6PS
UT WOS:000747379200007
PM 34861656
DA 2022-04-17
ER

PT J
AU Kumar, V
   Recupero, DR
   Riboni, D
   Helaoui, R
AF Kumar, Vivek
   Recupero, Diego Reforgiato
   Riboni, Daniele
   Helaoui, Rim
TI Ensembling Classical Machine Learning and Deep Learning Approaches for
   Morbidity Identification From Clinical Notes
SO IEEE ACCESS
LA English
DT Article
DE Medical services; Feature extraction; Deep learning; Task analysis;
   Sociology; Biomedical imaging; Training; Deep learning; machine
   learning; multimorbidity; natural language processing; classifiers; word
   embeddings; healthcare
ID TEXT CLASSIFICATION; FEATURE-SELECTION; HEALTH-CARE; PREDICTION;
   CHALLENGES
AB The past decade has seen an explosion of the amount of digital information generated within the healthcare domain. Digital data exist in the form of images, video, speech, transcripts, electronic health records, clinical records, and free-text. Analysis and interpretation of healthcare data is a daunting task, and it demands a great deal of time, resources, and human effort. In this paper, we focus on the problem of co-morbidity recognition from patient's clinical records. To this aim, we employ both classical machine learning and deep learning approaches. We use word embeddings and bag-of-words representations, coupled with feature selection techniques. The goal of our work is to develop a classification system to identify whether a certain health condition occurs for a patient by studying his/her past clinical records. In more detail, we have used pre-trained word2vec, domain-trained, GloVe, fastText, and universal sentence encoder embeddings to tackle the classification of sixteen morbidity conditions within clinical records. We have compared the outcomes of classical machine learning and deep learning approaches with the employed feature representation methods and feature selection methods. We present a comprehensive discussion of the performances and behaviour of the employed classical machine learning and deep learning approaches. Finally, we have also used ensemble learning techniques over a large number of combinations of classifiers to improve the single model performance. For our experiments, we used the n2c2 natural language processing research dataset, released by Harvard Medical School. The dataset is in the form of clinical notes that contain patient discharge summaries. Given the unbalancedness of the data and their small size, the experimental results indicate the advantage of the ensemble learning technique with respect to single classifier models. In particular, the ensemble learning technique has slightly improved the performances of single classification models but has greatly reduced the variance of predictions stabilizing the accuracies (i.e., the lower standard deviation in comparison with single classifiers). In real-life scenarios, our work can be employed to identify with high accuracy morbidity conditions of patients by feeding our tool with their current clinical notes. Moreover, other domains where classification is a common problem might benefit from our approach as well.
C1 [Kumar, Vivek; Recupero, Diego Reforgiato; Riboni, Daniele] Univ Cagliari, Dept Math & Comp Sci, I-09124 Cagliari, Italy.
   [Helaoui, Rim] Philips Res, Personal Hlth Dept, NL-5656 Eindhoven, Netherlands.
RP Kumar, V (corresponding author), Univ Cagliari, Dept Math & Comp Sci, I-09124 Cagliari, Italy.
EM vivek.kumar@unica.it
RI Kumar, Vivek/A-9955-2019
OI Kumar, Vivek/0000-0003-3958-4704; Riboni, Daniele/0000-0002-0695-2040;
   Reforgiato Recupero, Diego/0000-0001-8646-6183
FU EU's Marie Curie training network PhilHumans-Personal Health Interfaces
   Leveraging Human-Machine Natural Interactions [812882]
FX This work was supported by the EU's Marie Curie training network
   PhilHumans-Personal Health Interfaces Leveraging Human~Machine Natural
   Interactions under Agreement 812882.
NR 65
TC 13
Z9 13
U1 3
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 7107
EP 7126
DI 10.1109/ACCESS.2020.3043221
PG 20
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA PS8VH
UT WOS:000608201100001
OA gold, Green Submitted
DA 2022-04-17
ER

PT J
AU Liu, LBA
   Chen, C
   Wang, B
AF Liu, Lanbiao
   Chen, Chen
   Wang, Bo
TI Predicting financial crises with machine learning methods
SO JOURNAL OF FORECASTING
LA English
DT Article; Early Access
DE causality; early warning system; financial crises; machine learning
ID EARLY WARNING SYSTEMS; SOVEREIGN DEBT CRISES; EMERGING MARKETS; CURRENCY
   CRISES; BANKING CRISES; INDICATORS; ENSEMBLES
AB Countries must establish an effective early warning system to predict financial crises in order to avoid their catastrophic effects. To this end, we construct early warning systems based on the logistic model and seven machine learning methods, and we also use the Shapley value decomposition and Shapley regression to explore the causality of the machine learning methods. By comparing the performance of different early warning models in out-of-sample tests, we find that the machine learning models, especially the random forest, gradient boosting decision tree, and ensemble models, outperform the logistic model in terms of providing early predictions of financial crises. In addition, the Shapley value can be used to find more effective predictive indicators and analyze the causes of risks in different countries to a certain extent, enabling policymakers to supplement the policy toolbox to deal with such crises. Thus, we suggest that machine learning methods should be considered when establishing early warning systems to predict financial crises in the future.
C1 [Liu, Lanbiao; Chen, Chen; Wang, Bo] Nankai Univ, Sch Finance, Tianjin, Peoples R China.
RP Wang, B (corresponding author), Nankai Univ, Sch Finance, Tianjin, Peoples R China.
EM nkwangbo@nankai.edu.cn
OI Chen, Chen/0000-0002-9166-3699
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [71873070]; National Social Science
   Foundation Major Project of China [17ZDA074]
FX National Natural Science Foundation of China, Grant/Award Number:
   71873070; National Social Science Foundation Major Project of China,
   Grant/Award Number: 17ZDA074
NR 73
TC 0
Z9 0
U1 15
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0277-6693
EI 1099-131X
J9 J FORECASTING
JI J. Forecast.
DI 10.1002/for.2840
EA JAN 2022
PG 40
WC Economics; Management
WE Social Science Citation Index (SSCI)
SC Business & Economics
GA YJ2EZ
UT WOS:000744349800001
DA 2022-04-17
ER

PT J
AU Wu, ZX
   Zhu, MF
   Kang, Y
   Leung, ELH
   Lei, TL
   Shen, C
   Jiang, DJ
   Wang, Z
   Cao, DS
   Hou, TJ
AF Wu, Zhenxing
   Zhu, Minfeng
   Kang, Yu
   Leung, Elaine Lai-Han
   Lei, Tailong
   Shen, Chao
   Jiang, Dejun
   Wang, Zhe
   Cao, Dongsheng
   Hou, Tingjun
TI Do we need different machine learning algorithms for QSAR modeling? A
   comprehensive assessment of 16 machine learning algorithms on 14 QSAR
   data sets
SO BRIEFINGS IN BIOINFORMATICS
LA English
DT Article
DE QSAR; machine learning; XGBoost; support vector machine; ensemble
   learning
ID COMPOUND CLASSIFICATION; VALIDATION; PREDICTION; SELECTION; CLASSIFIERS;
   MOLECULES; CHEMISTRY; CHEMICALS; NETWORKS; KERNEL
AB Although a wide variety of machine learning (ML) algorithms have been utilized to learn quantitative structure-activity relationships (QSARs), there is no agreed single best algorithm for QSAR learning. Therefore, a comprehensive understanding of the performance characteristics of popular ML algorithms used in QSAR learning is highly desirable. In this study, five linear algorithms [linear function Gaussian process regression (linear-GPR), linear function support vector machine (linear-SVM), partial least squares regression (PLSR), multiple linear regression (MLR) and principal component regression (PCR)], three analogizers [radial basis function support vector machine (rbf-SVM), K-nearest neighbor (KNN) and radial basis function Gaussian process regression (rbf-GPR)], six symbolists [extreme gradient boosting (XGBoost), Cubist, random forest (RF), multiple adaptive regression splines (MARS), gradient boosting machine (GBM), and classification and regression tree (CART)] and two connectionists [principal component analysis artificial neural network (pca-ANN) and deep neural network (DNN)] were employed to learn the regression-based QSAR models for 14 public data sets comprising nine physicochemical properties and five toxicity endpoints. The results show that rbf-SVM, rbf-GPR, XGBoost and DNN generally illustrate better performances than the other algorithms. The overall performances of different algorithms can be ranked from the best to the worst as follows: rbf-SVM>XGBoost > rbf-GPR>Cubist > GBM>DNN>RF>pca-ANN>MARS > linear-GPR approximate to KNN>linear-SVM approximate to PLSR > CART approximate to PCR approximate to MLR. In terms of prediction accuracy and computational efficiency, SVM and XGBoost are recommended to the regression learning for small data sets, and XGBoost is an excellent choice for large data sets. We then investigated the performances of the ensemble models by integrating the predictions of multiple ML algorithms. The results illustrate that the ensembles of two or three algorithms in different categories can indeed improve the predictions of the best individual ML algorithms.
   [GRAPHICS]
C1 [Wu, Zhenxing; Kang, Yu; Lei, Tailong; Shen, Chao; Jiang, Dejun; Wang, Zhe] Zhejiang Univ, Coll Pharmaceut Sci, Hangzhou Inst Innovat Med, Hangzhou 310058, Zhejiang, Peoples R China.
   [Zhu, Minfeng; Cao, Dongsheng] Cent South Univ, Xiangya Sch Pharmaceut Sci, Changsha 410004, Hunan, Peoples R China.
   [Leung, Elaine Lai-Han] Macau Univ Sci & Technol, Macau Inst Appl Res Med & Hlth, State Key Lab Qual Res Chinese Med, Macau, Peoples R China.
   [Hou, Tingjun] Zhejiang Univ, Coll Pharmaceut Sci, Hangzhou, Zhejiang, Peoples R China.
RP Hou, TJ (corresponding author), Zhejiang Univ, Coll Pharmaceut Sci, Hangzhou Inst Innovat Med, Hangzhou 310058, Zhejiang, Peoples R China.; Cao, DS (corresponding author), Cent South Univ, Xiangya Sch Pharmaceut Sci, Changsha 410004, Hunan, Peoples R China.
EM oriental-cds@163.com; tingjunhou@zju.edu.cn
RI Shen, Chao/AAV-2938-2020; Lei, Tailong/A-9606-2017
OI Shen, Chao/0000-0003-2783-5529; Lei, Tailong/0000-0003-2067-1787
FU Key R&D Program of Zhejiang Province [2020C03010]; National Natural
   Science Foundation of ChinaNational Natural Science Foundation of China
   (NSFC) [21575128, 81773632]; Leading Talent of 'Ten Thousand
   Plan'-National High-Level Talents Special Support Plan; Zhejiang
   Provincial Natural Science Foundation of ChinaNatural Science Foundation
   of Zhejiang Province [LZ19H300001]
FX Key R&D Program of Zhejiang Province (2020C03010), National Natural
   Science Foundation of China (21575128, 81773632), Leading Talent of `Ten
   Thousand Plan'-National High-Level Talents Special Support Plan and
   Zhejiang Provincial Natural Science Foundation of China (LZ19H300001).
NR 55
TC 9
Z9 9
U1 33
U2 57
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 1467-5463
EI 1477-4054
J9 BRIEF BIOINFORM
JI Brief. Bioinform.
PD JUL
PY 2021
VL 22
IS 4
AR bbaa321
DI 10.1093/bib/bbaa321
PG 17
WC Biochemical Research Methods; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Mathematical & Computational Biology
GA WK1AV
UT WOS:000709466800087
PM 33313673
DA 2022-04-17
ER

PT J
AU Chmiel, M
   Walter, F
   Wenner, M
   Zhang, Z
   McArdell, BW
   Hibert, C
AF Chmiel, Malgorzata
   Walter, Fabian
   Wenner, Michaela
   Zhang, Zhen
   McArdell, Brian W.
   Hibert, Clement
TI Machine Learning Improves Debris Flow Warning
SO GEOPHYSICAL RESEARCH LETTERS
LA English
DT Article
DE debris flows; detection; environmental seismology; machine learning;
   natural hazards
AB Automatic identification of debris flow signals in continuous seismic records remains a challenge. To tackle this problem, we use machine learning, which can be applied to continuous real-time data. We show that a machine learning model based on the random forest algorithm recognizes different stages of debris flow formation and propagation at the Illgraben torrent, Switzerland, with an accuracy exceeding 90 %. In contrast to typical debris flow detection requiring instrumentation installed in the torrent, our approach provides a significant gain in warning times of tens of minutes to hours. For real-time data from 2020, our detector raises alarms for all 13 independently confirmed Illgraben events, giving no false alarms. We suggest that our seismic machine-learning detector is a critical step toward the next generation of debris-flow warning, which increases warning times using simpler instrumentation compared to existing operational systems.
C1 [Chmiel, Malgorzata; Walter, Fabian; Wenner, Michaela; Zhang, Zhen] Swiss Fed Inst Technol, Lab Hydraul Hydrol & Glaciol, Zurich, Switzerland.
   [Walter, Fabian; Wenner, Michaela; McArdell, Brian W.] Swiss Fed Inst Forest Snow & Landscape Res, Zurich, Switzerland.
   [Zhang, Zhen] Chinese Acad Sci, Inst Mt Hazards & Environm, Key Lab Mt Hazards & Surface Proc, Chengdu, Peoples R China.
   [Zhang, Zhen] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Hibert, Clement] Univ Strasbourg, EOST, Inst Phys Globe Strasbourg, Strasbourg, France.
RP Chmiel, M (corresponding author), Swiss Fed Inst Technol, Lab Hydraul Hydrol & Glaciol, Zurich, Switzerland.
EM chmielm@ee.ethz.ch
RI Walter, Fabian/B-7490-2014
OI Walter, Fabian/0000-0001-6952-2761; Zhang, Zhen/0000-0002-1739-1234;
   Chmiel, Malgorzata/0000-0002-5573-9801
FU WSL; Canton Valais; Swiss Military
FX Seismometer installation was funded by WSL and the Canton Valais and
   supported by the Swiss Military. The authors thank Christoph Graf for
   explanations on Illgraben debris flows and John Clinton, Roman Racine,
   Stefan Wiemer, the Swiss Seismological Service and its electronic
   laboratory (ELAB) for technical support. The authors also thank the
   Associate Editor and the two anonymous reviewers for their useful
   comments and suggestions that allowed us to improve the manuscript.
NR 48
TC 6
Z9 6
U1 17
U2 31
PU AMER GEOPHYSICAL UNION
PI WASHINGTON
PA 2000 FLORIDA AVE NW, WASHINGTON, DC 20009 USA
SN 0094-8276
EI 1944-8007
J9 GEOPHYS RES LETT
JI Geophys. Res. Lett.
PD FEB 16
PY 2021
VL 48
IS 3
AR e2020GL090874
DI 10.1029/2020GL090874
PG 11
WC Geosciences, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Geology
GA QK0FZ
UT WOS:000620058900025
OA Green Published, hybrid
DA 2022-04-17
ER

PT J
AU Alexander, FJ
   Ang, J
   Bilbrey, JA
   Balewski, J
   Casey, T
   Chard, R
   Choi, J
   Choudhury, S
   Debusschere, B
   DeGennaro, AM
   Dryden, N
   Ellis, JA
   Foster, I
   Cardona, CG
   Ghosh, S
   Harrington, P
   Huang, YZ
   Jha, S
   Johnston, T
   Kagawa, A
   Kannan, R
   Kumar, N
   Liu, ZC
   Maruyama, N
   Matsuoka, S
   McCarthy, E
   Mohd-Yusof, J
   Nugent, P
   Oyama, Y
   Proffen, T
   Pugmire, D
   Rajamanickam, S
   Ramakrishniah, V
   Schram, M
   Seal, SK
   Sivaraman, G
   Sweeney, C
   Tan, L
   Thakur, R
   Van Essen, B
   Ward, L
   Welch, P
   Wolf, M
   Xantheas, SS
   Yager, KG
   Yoo, S
   Yoon, BJ
AF Alexander, Francis J.
   Ang, James
   Bilbrey, Jenna A.
   Balewski, Jan
   Casey, Tiernan
   Chard, Ryan
   Choi, Jong
   Choudhury, Sutanay
   Debusschere, Bert
   DeGennaro, Anthony M.
   Dryden, Nikoli
   Ellis, J. Austin
   Foster, Ian
   Cardona, Cristina Garcia
   Ghosh, Sayan
   Harrington, Peter
   Huang, Yunzhi
   Jha, Shantenu
   Johnston, Travis
   Kagawa, Ai
   Kannan, Ramakrishnan
   Kumar, Neeraj
   Liu, Zhengchun
   Maruyama, Naoya
   Matsuoka, Satoshi
   McCarthy, Erin
   Mohd-Yusof, Jamaludin
   Nugent, Peter
   Oyama, Yosuke
   Proffen, Thomas
   Pugmire, David
   Rajamanickam, Sivasankaran
   Ramakrishniah, Vinay
   Schram, Malachi
   Seal, Sudip K.
   Sivaraman, Ganesh
   Sweeney, Christine
   Tan, Li
   Thakur, Rajeev
   Van Essen, Brian
   Ward, Logan
   Welch, Paul
   Wolf, Michael
   Xantheas, Sotiris S.
   Yager, Kevin G.
   Yoo, Shinjae
   Yoon, Byung-Jun
TI Co-design Center for Exascale Machine Learning Technologies (ExaLearn)
SO INTERNATIONAL JOURNAL OF HIGH PERFORMANCE COMPUTING APPLICATIONS
LA English
DT Article
DE Machine learning; exascale computing; reinforcement learning; active
   learning; high-performance computing for machine learning; machine
   learning for high-performance computing
ID MOLECULES
AB Rapid growth in data, computational methods, and computing power is driving a remarkable revolution in what variously is termed machine learning (ML), statistical learning, computational learning, and artificial intelligence. In addition to highly visible successes in machine-based natural language translation, playing the game Go, and self-driving cars, these new technologies also have profound implications for computational and experimental science and engineering, as well as for the exascale computing systems that the Department of Energy (DOE) is developing to support those disciplines. Not only do these learning technologies open up exciting opportunities for scientific discovery on exascale systems, they also appear poised to have important implications for the design and use of exascale computers themselves, including high-performance computing (HPC) for ML and ML for HPC. The overarching goal of the ExaLearn co-design project is to provide exascale ML software for use by Exascale Computing Project (ECP) applications, other ECP co-design centers, and DOE experimental facilities and leadership class computing facilities.
C1 [Alexander, Francis J.; DeGennaro, Anthony M.; Jha, Shantenu; Kagawa, Ai; Tan, Li; Yager, Kevin G.; Yoo, Shinjae; Yoon, Byung-Jun] Brookhaven Natl Lab, POB 5000,Bldg 725,Brookhaven Ave, Upton, NY 11973 USA.
   [Ang, James; Bilbrey, Jenna A.; Choudhury, Sutanay; Ghosh, Sayan; Huang, Yunzhi; Johnston, Travis; Kannan, Ramakrishnan; Kumar, Neeraj; Schram, Malachi; Seal, Sudip K.; Xantheas, Sotiris S.] Pacific Northwest Natl Lab, Richland, WA USA.
   [Balewski, Jan; Harrington, Peter; Nugent, Peter] Lawrence Berkeley Natl Lab, Berkeley, CA USA.
   [Casey, Tiernan; Debusschere, Bert; Ellis, J. Austin; Rajamanickam, Sivasankaran; Wolf, Michael] Sandia Natl Labs, POB 5800, Albuquerque, NM 87185 USA.
   [Chard, Ryan; Foster, Ian; Liu, Zhengchun; Thakur, Rajeev; Ward, Logan] Argonne Natl Lab, Lemont, IL USA.
   [Choi, Jong; Cardona, Cristina Garcia; Proffen, Thomas; Pugmire, David] Oak Ridge Natl Lab, Oak Ridge, TN USA.
   [Dryden, Nikoli; Maruyama, Naoya; McCarthy, Erin; Oyama, Yosuke] Lawrence Livermore Natl Lab, Livermore, CA USA.
   [Dryden, Nikoli] Swiss Fed Inst Technol, Zurich, Switzerland.
   [Matsuoka, Satoshi] RIKEN Ctr Computat Sci, Kobe, Hyogo, Japan.
   [Matsuoka, Satoshi; Oyama, Yosuke] Tokyo Inst Technol, Tokyo, Japan.
   [McCarthy, Erin] Univ Oregon, Eugene, OR 97403 USA.
   [Mohd-Yusof, Jamaludin; Ramakrishniah, Vinay; Sweeney, Christine; Welch, Paul] Los Almos Natl Lab, Los Alamos, NM USA.
RP Alexander, FJ (corresponding author), Brookhaven Natl Lab, POB 5000,Bldg 725,Brookhaven Ave, Upton, NY 11973 USA.
EM falexander@bnl.gov
RI Ward, Logan/I-9526-2019
OI Ward, Logan/0000-0002-1323-5939; /0000-0001-9056-9855; Pugmire,
   David/0000-0003-0647-2634
FU Exascale Computing Project [17-SC-20-SC]; National Nuclear Security
   AdministrationNational Nuclear Security Administration; JSPS KAKENHI,
   JapanMinistry of Education, Culture, Sports, Science and Technology,
   Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for
   Scientific Research (KAKENHI) [JP18J22858]; Energy Research Scientific
   Computing Center (NERSC) DOE Office of Science User Facilities
   [DE-AC02-06CH11357, DE-AC05-00OR22725, DE-AC52-07NA27344,
   DE-AC02-05CH11231]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This
   research is supported by the Exascale Computing Project (17-SC-20-SC), a
   collaborative effort of U.S. Department of Energy Office of Science and
   the National Nuclear Security Administration. A portion of the research
   was supported by JSPS KAKENHI Grant Number JP18J22858, Japan. The
   research has used resources of the Argonne and Oak Ridge Leadership
   Computing Facilities, Livermore Computing Facility, and Energy Research
   Scientific Computing Center (NERSC) DOE Office of Science User
   Facilities supported under Contracts DE-AC0206CH11357, DE-AC05-00OR22725
   and DE-AC52-07NA27344 (LLNL-JRNL-XXXXXX), DE-AC02-05CH11231,
   respectively.
NR 60
TC 1
Z9 1
U1 7
U2 8
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1094-3420
EI 1741-2846
J9 INT J HIGH PERFORM C
JI Int. J. High Perform. Comput. Appl.
PD NOV
PY 2021
VL 35
IS 6
SI SI
BP 598
EP 616
AR 10943420211029302
DI 10.1177/10943420211029302
EA SEP 2021
PG 19
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XG8HM
UT WOS:000703195500001
DA 2022-04-17
ER

PT C
AU Hamdan, S
   Almajali, S
   Ayyash, M
AF Hamdan, Salam
   Almajali, Sufyan
   Ayyash, Moussa
GP IEEE
TI Comparison study between conventional machine learning and distributed
   multi-task learning models
SO 2020 21ST INTERNATIONAL ARAB CONFERENCE ON INFORMATION TECHNOLOGY (ACIT)
SE International Arab Conference on Information Technology ACIT
LA English
DT Proceedings Paper
CT 21st International Arab Conference on Information Technology (ACIT)
CY NOV 28-30, 2020
CL EGYPT
SP MISR Univ Sci & Technol, ACIT Int, IEEE
DE Internet of things; Edge computing; conventional machine learning;
   distributed learning; multi-task learning
AB Applying machine learning in IoT devices is a challenge due to various reasons, such as the tremendous amount of data generated from IoT, the limitation of IoT devices' resources, and the non-IID nature of IoT data. On the other hand, transferring the generated IoT data to the cloud to train machine learning models consumes a lot of Bandwidth. Applying the distributed learning aspect in IoT large-scale deployments solves such issues, by employing edge computing devices as local cloud models in each location. This solution enhances the network overhead and helps in obtaining general models. However, this comes at the expense of the accuracy of the generated models. This paper provides a comparison study between applying a conventional machine learning model with a distributed multi-task learning model and discusses the factors that affect the distributed multi-task learning model.
C1 [Hamdan, Salam; Almajali, Sufyan] Princess Sumaya Univ Technol, Dept Comp Sci, Amman, Jordan.
   [Ayyash, Moussa] Chicago State Univ, Dept Informat Studies, Chicago, IL USA.
RP Hamdan, S (corresponding author), Princess Sumaya Univ Technol, Dept Comp Sci, Amman, Jordan.
EM s.hamdan@psut.edu.jo; s.almajali@psut.edu.jo; mayyash@csu.edu
RI ALMAJALI, SUFYAN/AAI-5175-2020
OI ALMAJALI, SUFYAN/0000-0001-9076-3519
NR 32
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1812-0857
EI 2075-2245
BN 978-1-7281-8855-3
J9 INT ARAB CONF INF TE
PY 2020
PG 5
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BS0HU
UT WOS:000682789800052
DA 2022-04-17
ER

PT C
AU Olari, V
   Cvejoski, K
   Eide, O
AF Olari, Viktoriya
   Cvejoski, Kostadin
   Eide, Oyvind
GP Assoc Advancement Artificial Intelligence
TI Introduction to Machine Learning with Robots and Playful Learning
SO THIRTY-FIFTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, THIRTY-THIRD
   CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE AND THE
   ELEVENTH SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE
SE AAAI Conference on Artificial Intelligence
LA English
DT Proceedings Paper
CT 35th AAAI Conference on Artificial Intelligence / 33rd Conference on
   Innovative Applications of Artificial Intelligence / 11th Symposium on
   Educational Advances in Artificial Intelligence
CY FEB 02-09, 2021
CL ELECTR NETWORK
SP Assoc Advancement Artificial Intelligence
AB Inspired by explanations of machine learning concepts in children's books, we developed an approach to introduce supervised, unsupervised, and reinforcement learning using a block-based programming language in combination with the benefits of educational robotics. Instead of using blocks as high-end APIs to access AI cloud services or to reproduce the machine learning algorithms, we use them as a means to put the student "in the algorithm's shoes." We adapt the training of neural networks, Q-learning, and k-means algorithms to a design and format suitable for children and equip the students with hands-on tools for playful experimentation. The children learn about direct supervision by modifying the weights in the neural networks and immediately observing the effects on the simulated robot. Following the ideas of constructionism, they experience how the algorithms and underlying machine learning concepts work in practice. We conducted and evaluated this approach with students in primary, middle, and high school. All the age groups perceived the topics to be very easy to moderately hard to grasp. Younger students experienced direct supervision as challenging, whereas they found Q-learning and k-means algorithms much more accessible. Most high-school students could cope with all the topics without particular difficulties.
C1 [Olari, Viktoriya; Eide, Oyvind] Univ Cologne, Dept Digital Humanities, D-50923 Cologne, Germany.
   [Olari, Viktoriya; Cvejoski, Kostadin] Fraunhofer IAIS, D-53757 St Augustin, Germany.
   [Eide, Oyvind] Univ Cologne, Ctr Data & Simulat Sci, D-50923 Cologne, Germany.
RP Olari, V (corresponding author), Univ Cologne, Dept Digital Humanities, D-50923 Cologne, Germany.; Olari, V (corresponding author), Fraunhofer IAIS, D-53757 St Augustin, Germany.
EM viktoriya.olari@iais.fraunhofer.de;
   kostadin.cvejoski@iais.fraunhofer.de; oeide@uni-koeln.de
FU Competence Center for Machine Learning Rhine-Ruhr (ML2R) - Federal
   Ministry of Education and Research of Germany [01\S18038B]
FX This research is supported by the Competence Center for Machine Learning
   Rhine-Ruhr (ML2R), which is funded by the Federal Ministry of Education
   and Research of Germany (grant no. 01|S18038B).
NR 39
TC 0
Z9 0
U1 1
U2 1
PU ASSOC ADVANCEMENT ARTIFICIAL INTELLIGENCE
PI PALO ALTO
PA 2275 E BAYSHORE RD, STE 160, PALO ALTO, CA 94303 USA
SN 2159-5399
EI 2374-3468
BN 978-1-57735-866-4
J9 AAAI CONF ARTIF INTE
PY 2021
VL 35
BP 15630
EP 15639
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Education, Scientific Disciplines
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Education & Educational Research
GA BS0DR
UT WOS:000681269807042
DA 2022-04-17
ER

PT J
AU Wu, P
   Hu, QR
   Tong, XW
   Wu, M
AF Wu, Peng
   Hu, Qi-rui
   Tong, Xing-wei
   Wu, Min
TI Learning Causal Effect Using Machine Learning with Application to
   China's Typhoon
SO ACTA MATHEMATICAE APPLICATAE SINICA-ENGLISH SERIES
LA English
DT Article
DE causal effect; matching; machine learning
ID PROPENSITY SCORE ESTIMATION; MATCHING ESTIMATORS; REMOVE BIAS;
   REGRESSION; SUBCLASSIFICATION; ADJUSTMENT
AB Matching is a routinely used technique to balance covariates and thereby alleviate confounding bias in causal inference with observational data. Most of the matching literatures involve the estimating of propensity score with parametric model, which heavily depends on the model specification. In this paper, we employ machine learning and matching techniques to learn the average causal effect. By comparing a variety of machine learning methods in terms of propensity score under extensive scenarios, we find that the ensemble methods, especially generalized random forests, perform favorably with others. We apply all the methods to the data of tropical storms that occurred on the mainland of China since 1949.
C1 [Wu, Peng; Hu, Qi-rui; Tong, Xing-wei] Beijing Normal Univ, Sch Stat, Beijing 100875, Peoples R China.
   [Wu, Min] Hubei Univ Sci & Technol, Sch Math & Stat, Xianning 437000, Hubei, Peoples R China.
RP Tong, XW (corresponding author), Beijing Normal Univ, Sch Stat, Beijing 100875, Peoples R China.
EM xweitong@bnu.edu.cn
OI Hu, Qirui/0000-0002-4846-3886
FU National Key Research and Development Program of China [2017YFA0604903];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [11671338, 11971064]
FX This paper is supported by the National Key Research and Development
   Program of China Grant 2017YFA0604903 and National Natural Science
   Foundation of China Grant (Nos. 11671338, 11971064).
NR 44
TC 0
Z9 0
U1 6
U2 16
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 0168-9673
EI 1618-3932
J9 ACTA MATH APPL SIN-E
JI Acta Math. Appl. Sin.-Engl. Ser.
PD JUL
PY 2020
VL 36
IS 3
BP 702
EP 713
DI 10.1007/s10255-020-0960-1
PG 12
WC Mathematics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Mathematics
GA NJ0YM
UT WOS:000565769700015
DA 2022-04-17
ER

PT C
AU Fri, C
   Elouahbi, R
AF Fri, Chakir
   Elouahbi, Rachid
BE Elmohajir, M
   AlAchhab, M
   Elmohajir, BE
   Ane, BK
   Jellouli, I
TI Machine Learning and Deep Learning applications in E-learning Systems :
   A Literature Survey using Topic Modeling Approach
SO 2020 6TH IEEE CONGRESS ON INFORMATION SCIENCE AND TECHNOLOGY (IEEE
   CIST'20)
SE Colloquium in Information Science and Technology
LA English
DT Proceedings Paper
CT 6th IEEE International Congress on Information Science and Technology
   (IEEE CiSt)
CY JUN 05-12, 2021
CL Innov.org, Agadir, MOROCCO
SP IEEE, IEEE Morocco Sect, IEEE Morocco Comp Commun Joint Chapter, IEEE African Council, IEEE Reg 8
HO Innov.org
DE E-Learning; Machine Learning; Deep Learning; Topic Modeling; Latent
   Dirichlet Allocation
AB E-learning has been one of the major trends in education and its becoming an attracting topic in the field of artificial intelligence and its subfields like machine learning and deep learning, that are considered the most promising technologies in our era where its application score is almost unlimited. Many researchers are showing interest in the topic with significant research results. The aim of this paper is to extract the applications of machine learning and deep learning in E-learning systems. In this work we collected research papers from five research databases: Springer Link, Science Direct, Scopus, IEEE Digital Library, and Web of Science for a topic modeling application using a machine learning technique known as Latent Dirichlet Allocation (LDA).
C1 [Fri, Chakir; Elouahbi, Rachid] Moulay Ismail Univ Meknes, Fac Sci, Dept Math & Comp Sci, Meknes, Morocco.
RP Fri, C (corresponding author), Moulay Ismail Univ Meknes, Fac Sci, Dept Math & Comp Sci, Meknes, Morocco.
EM chakir.fri@gmail.com; elouahbi@yahoo.fr
NR 23
TC 0
Z9 0
U1 4
U2 4
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2327-185X
BN 978-1-7281-6646-9
J9 COLLOQ INF SCI TECH
PY 2020
BP 267
EP 273
DI 10.1109/CIST49399.2021.9357253
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Information Science & Library Science
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Information Science & Library Science
GA BR5TS
UT WOS:000657322100046
DA 2022-04-17
ER

PT J
AU Zheng, WD
   Liu, HP
   Wang, BW
   Sun, FC
AF Zheng, Wendong
   Liu, Huaping
   Wang, Bowen
   Sun, Fuchun
TI Cross-modal learning for material perception using deep extreme learning
   machine
SO INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS
LA English
DT Article
DE Cross-modal matching; Material perception; Correlation learning; Deep
   extreme learning machine
ID CANONICAL CORRELATION-ANALYSIS; TACTILE PERCEPTION; REPRESENTATIONS;
   RECOGNITION; NETWORK; FUSION
AB The material property of an object's surface is critical for the tasks of robotic manipulation or interaction with its surrounding environment. Tactile sensing can provide rich information about the material characteristics of an object's surface. Hence, it is important to convey and interpret tactile information of material properties to the users during interaction. In this paper, we propose a visual-tactile cross-modal retrieval framework to convey tactile information of surface material for perceptual estimation. In particular, we use tactile information of a new unknown surface material to retrieve perceptually similar surface from an available surface visual sample set. For the proposed framework, we develop a deep cross-modal correlation learning method, which incorporates the high-level nonlinear representation of deep extreme learning machine and class-paired correlation learning of cluster canonical correlation analysis. Experimental results on the publicly available dataset validate the effectiveness of the proposed framework and the method.
C1 [Zheng, Wendong; Wang, Bowen] Hebei Univ Technol, Sch Elect Engn, Key Lab Electromagnet Field & Elect Apparat Relia, State Key Lab Reliabil & Intelligence Elect Equip, Tianjin, Peoples R China.
   [Liu, Huaping; Sun, Fuchun] Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China.
   [Liu, Huaping; Sun, Fuchun] Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol, State Key Lab Intelligent Technol & Syst, Beijing, Peoples R China.
RP Liu, HP (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China.; Liu, HP (corresponding author), Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol, State Key Lab Intelligent Technol & Syst, Beijing, Peoples R China.
EM hpliu@tsinghua.edu.cn
NR 38
TC 0
Z9 0
U1 4
U2 27
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-8071
EI 1868-808X
J9 INT J MACH LEARN CYB
JI Int. J. Mach. Learn. Cybern.
PD APR
PY 2020
VL 11
IS 4
BP 813
EP 823
DI 10.1007/s13042-019-00962-1
PG 11
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KT0WK
UT WOS:000518731400006
DA 2022-04-17
ER

PT C
AU Monjalet, F
   Leibovici, T
AF Monjalet, Florent
   Leibovici, Thomas
BE Weiland, M
   Juckeland, G
   Alam, S
   Jagode, H
TI Predicting File Lifetimes with Machine Learning
SO HIGH PERFORMANCE COMPUTING: ISC HIGH PERFORMANCE 2019 INTERNATIONAL
   WORKSHOPS
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 34th International Conference on High Performance Computing (ISC High
   Performance)
CY JUN 16-20, 2019
CL Frankfurt, GERMANY
DE Machine learning; Deep learning; HSM; Data placement
AB In this article, we show how machine learning methods, namely random forests and convolutional neural networks, can be used to predict file lifetimes from their absolute path with a high reliability in an HPC filesystem context. The file lifetime is defined in this article as the time between the creation of the file and the last time it is read. Such results can be applied to the design of smart data placement policies, especially for hierarchical storage systems.
C1 [Monjalet, Florent; Leibovici, Thomas] CEA DAM, Ollainville, France.
RP Monjalet, F (corresponding author), CEA DAM, Ollainville, France.
EM florent.monjalet@cea.fr; thomas.leibovici@cea.fr
NR 5
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-34356-9; 978-3-030-34355-2
J9 LECT NOTES COMPUT SC
PY 2020
VL 11887
BP 288
EP 299
DI 10.1007/978-3-030-34356-9_23
PG 12
WC Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ6PM
UT WOS:000612971700023
DA 2022-04-17
ER

PT J
AU He, JJ
   Li, JJ
   Liu, CB
   Wang, CX
   Zhang, Y
   Wen, C
   Xue, DZ
   Cao, JL
   Su, YJ
   Qiao, LJ
   Bai, Y
AF He, Jingjin
   Li, Junjie
   Liu, Chuanbao
   Wang, Changxin
   Zhang, Yan
   Wen, Cheng
   Xue, Dezhen
   Cao, Jiangli
   Su, Yanjing
   Qiao, Lijie
   Bai, Yang
TI Machine learning identified materials descriptors for ferroelectricity
SO ACTA MATERIALIA
LA English
DT Article
DE Ferroelectricity; Machine learning; Materials descriptors
ID FIELD-INDUCED STRAIN; ELECTRIC-FIELD; ENERGY; CERAMICS; PEROVSKITES;
   PIEZOELECTRICITY; TRANSITIONS; ANTIMONY; SEARCH; DESIGN
AB With aid of good materials descriptors, machine learning algorithms are able to accelerate the design of new materials and uncover underlying mechanisms. In the present study, we adopt machine learning methods to discover the most important materials descriptors for properties of ferroelectric materials. A regression study, in typical BaTiO3-based and K1/2Na1/2NbO3-based lead-free ceramics and lead-contained PbMg1/3Nb2/3TiO3-PbTiO3 ceramics, screens out three important materials descriptors determining ferroelectricity from 46 potential descriptors. The three descriptors of Matyonov-Batsanov electronegativity, ratio of valence electron number to nominal charge and core electron distance (Schubert) are confirmed to be dominant as well in classification of perovskite compounds into antiferroelectrics or not. The classification based on these descriptors exhibit an excellent accuracy of 96%, much higher than that of traditional criterion (89%) using tolerance factor and Pauling electronegativity. Furthermore, we propose a machine learning strategy based on our descriptors to predict the phase coexistence. The prediction probability after bootstrapping provides an effective approach to distinguish the phase boundaries and predict the phase ratio of coexisted phases. In all, we identified materials descriptors for ferroelectric materials, which is helpful to reveal the structure-property relationship of ferroelectric materials and guide the design of better ferroelectricity and piezoelectricity. (C) 2021 Acta Materialia Inc. Published by Elsevier Ltd. All rights reserved.
C1 [He, Jingjin; Li, Junjie; Wang, Changxin; Zhang, Yan; Wen, Cheng; Su, Yanjing; Qiao, Lijie; Bai, Yang] Univ Sci & Technol Beijing, Beijing Adv Innovat Ctr Mat Genome Engn, Beijing 100083, Peoples R China.
   [He, Jingjin; Li, Junjie; Wang, Changxin; Zhang, Yan; Wen, Cheng; Cao, Jiangli; Su, Yanjing; Qiao, Lijie; Bai, Yang] Univ Sci & Technol Beijing, Inst Adv Mat & Technol, Beijing 100083, Peoples R China.
   [Liu, Chuanbao] Univ Sci & Technol Beijing, Sch Mat Sci & Technol, Beijing 100083, Peoples R China.
   [Xue, Dezhen] Xi An Jiao Tong Univ, State Key Lab Mech Behav Mat, Xian 710049, Peoples R China.
RP Bai, Y (corresponding author), Univ Sci & Technol Beijing, Beijing Adv Innovat Ctr Mat Genome Engn, Beijing 100083, Peoples R China.; Bai, Y (corresponding author), Univ Sci & Technol Beijing, Inst Adv Mat & Technol, Beijing 100083, Peoples R China.; Xue, DZ (corresponding author), Xi An Jiao Tong Univ, State Key Lab Mech Behav Mat, Xian 710049, Peoples R China.
EM xuedezhen@xjtu.edu.cn; baiy@mater.ustb.edu.cn
RI Li, Junjie/Q-3362-2018; Yang, Bai/B-9012-2009
OI Li, Junjie/0000-0002-7205-0301; Yang, Bai/0000-0002-6917-256X; Wen,
   Cheng/0000-0002-7179-8430
FU National Key Research and Development Program of China [2016YFB0700505];
   Beijing Natural Science FoundationBeijing Natural Science Foundation
   [2192032]; Fundamental Research Funds for the Central
   UniversitiesFundamental Research Funds for the Central Universities
   [FRFAT19012]; 111 ProjectMinistry of Education, China - 111 Project
   [B170 0 03]
FX This work was supported by grants from National Key Research and
   Development Program of China (2016YFB0700505) , Beijing Natural Science
   Foundation (2192032) , Fundamental Research Funds for the Central
   Universities (FRFAT19012) , and 111 Project (B170 0 03) .
NR 48
TC 3
Z9 3
U1 46
U2 79
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 1359-6454
EI 1873-2453
J9 ACTA MATER
JI Acta Mater.
PD MAY 1
PY 2021
VL 209
AR 116815
DI 10.1016/j.actamat.2021.116815
EA MAR 2021
PG 9
WC Materials Science, Multidisciplinary; Metallurgy & Metallurgical
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Materials Science; Metallurgy & Metallurgical Engineering
GA RP2TS
UT WOS:000641587000004
DA 2022-04-17
ER

PT J
AU Ullal, MS
   Hawaldar, IT
   Soni, R
   Nadeem, M
AF Ullal, Mithun S.
   Hawaldar, Iqbal Thonse
   Soni, Rashmi
   Nadeem, Mohammed
TI The Role of Machine Learning in Digital Marketing
SO SAGE OPEN
LA English
DT Article
DE AI; deep learning; digital marketing; machine learning
ID SOCIAL MEDIA; REGRESSION-MODELS; INNOVATION; STRATEGIES
AB Artificial Intelligence has been under researched. Machines with deep learning abilities can take digital marketing to new heights with their Artificial Intelligence making all the difference. This research aims to identify the outcomes from the study of Indian customer's responses across varying demographics to machines and their abilities to sell, which will well be the future of digital marketing. We find that software developers need to build the architecture is partnership with digital marketers who use machines with deep learning by taking attitude of the customers, behavior and choices into consideration. This will unlock huge benefits to the companies as accurate information about customers will be easily available to the marketers in future. How the machines are going to perform under various conditions are explained using a causal model using regression models. SPSS version 24 and R software were used for analysing the data and data regarding the customer's behaviors, their choices and emotions are collected and based on fuzzy-set qualitative comparative analysis (fsQCA) approach how they can be influenced to use the services of the machine, fsQCA is used to compare case oriented and variable oriented quantitative analysis.
C1 [Ullal, Mithun S.] Manipal Acad Higher Educ, Manipal, India.
   [Hawaldar, Iqbal Thonse] Kingdom Univ, Sanad, Bahrain.
   [Soni, Rashmi] Somaiya Vidyavihar Univ, Mumbai, Maharashtra, India.
   [Nadeem, Mohammed] Univ San Francisco, San Francisco, CA USA.
RP Soni, R (corresponding author), Somaiya Vidyavihar Univ, KJ Somaiya Inst Management, Cabin 83,SIMSR Bldg First Floor, Mumbai 400077, Maharashtra, India.
EM rashmi.soni@somaiya.edu
RI Hawaldar, Iqbal Thonse/H-6260-2018
OI Hawaldar, Iqbal Thonse/0000-0001-7181-2493
NR 68
TC 1
Z9 1
U1 20
U2 20
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 2158-2440
J9 SAGE OPEN
JI SAGE Open
PD OCT
PY 2021
VL 11
IS 4
AR 21582440211050394
DI 10.1177/21582440211050394
PG 12
WC Social Sciences, Interdisciplinary
WE Social Science Citation Index (SSCI)
SC Social Sciences - Other Topics
GA WJ7LM
UT WOS:000709222100001
DA 2022-04-17
ER

PT J
AU Qin, JM
   Wang, C
   Zou, QH
   Sun, YB
   Chen, B
AF Qin, Jiongming
   Wang, Cong
   Zou, Qinhong
   Sun, Yubin
   Chen, Bin
TI Active learning with extreme learning machine for online imbalanced
   multiclass classification
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Active learning; Extreme learning machine; Multiclass imbalanced
   classification; Query strategy; Class incremental
ID ALGORITHM; ELM; REGRESSION; ACCURATE; ENSEMBLE; NETWORK
AB Active learning (AL) can significantly reduce the cost of labeling instances. Extreme learning machine (ELM) has low computational cost, extremely fast training speed and strong generalization ability. Previous studies have shown that the combination of them can generate efficient learning models. Nevertheless, these researches did not focus on multiclass imbalanced data. Cold start may occur and the performance of classifier is also reduced due to the imbalanced distribution of categories. Moreover, there is no framework for processing stream-based data. To address these problems, an improved framework called AL for class incremental and weighted sequential ELM (AI-WSELM) is proposed in this paper, and its advantages are as follows: (1) similarity query and margin sampling were used to alleviate cold start and select uncertain instances, respectively, (2) an improved weighting strategy was used to tackle stream-based multiclass imbalanced distribution, (3) a class incremental mechanism was added to deal with new categories appeared in the subsequent batches, and (4) AI-WSELM greatly reduced the cost of labeling samples when ensuring classification performance. The simulation results show that the proposed model has satisfactory performance compared to the existing ELMs and the other related algorithms, which indicates the feasibility and effectiveness of AI-WSELM. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Qin, Jiongming; Wang, Cong; Zou, Qinhong; Sun, Yubin; Chen, Bin] Southwest Univ, Coll Elect & Informat Engn, Chongqing Key Lab Nonlinear Circuits & Intelligen, Chongqing 400715, Peoples R China.
RP Chen, B (corresponding author), Southwest Univ, Coll Elect & Informat Engn, Chongqing Key Lab Nonlinear Circuits & Intelligen, Chongqing 400715, Peoples R China.
EM as1163244027@email.swu.edu.cn; wc2039@email.swu.edu.cn;
   zqhzqh@email.swu.edu.cn; syb2019@email.swu.edu.cn; chenbin121@swu.edu.cn
FU National Nature Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61801400, 61703348]; JSPS, Japan
   KAKENHIMinistry of Education, Culture, Sports, Science and Technology,
   Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for
   Scientific Research (KAKENHI) [JP18F18392];  [XDJK2018C021]
FX This study was supported by the National Nature Science Foundation of
   China No. 61801400, No. 61703348, Central Uni-versities under Grant
   numbers XDJK2018C021, and JSPS, Japan KAKENHI Grant Number JP18F18392.
   At the same time , we also thank the UCI machine learning repository and
   the donators for sharing the datasets.
NR 41
TC 1
Z9 1
U1 11
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD NOV 14
PY 2021
VL 231
AR 107385
DI 10.1016/j.knosys.2021.107385
EA AUG 2021
PG 15
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WA3KZ
UT WOS:000702789300006
DA 2022-04-17
ER

PT J
AU Jiang, HL
   Li, Q
   Jiang, Y
   Shen, GB
   Sinnott, R
   Tian, C
   Xu, MW
AF Jiang, Huiling
   Li, Qing
   Jiang, Yong
   Shen, GengBiao
   Sinnott, Richard
   Tian, Chen
   Xu, Mingwei
TI When machine learning meets congestion control: A survey and comparison
SO COMPUTER NETWORKS
LA English
DT Article
DE Congestion control; Machine learning; Reinforcement learning;
   Learning-based
ID TCP ENHANCEMENT; REINFORCEMENT; NETWORKS; MANAGEMENT; ALGORITHM;
   FAIRNESS
AB Machine learning has seen a significant surge and uptake across many diverse applications. The high flexibility, adaptability, and computing capabilities it provides extend traditional approaches used in multiple fields including network operation and management. Numerous surveys have explored machine learning algorithms in the context of networking, such as traffic engineering, performance optimization, and network security. Many machine learning approaches focus on clustering, classification, regression, and reinforcement learning. The innovation of this research, and the contribution of this paper lies in the detailed summary and comparison of learning-based congestion control approaches. Compared with traditional congestion control algorithms which are typically rule-based, capabilities to learn from historical experience are highly desirable. From the literature, it is observed that reinforcement learning is a crucial trend among learning-based congestion control algorithms. In this paper, we explore the performance of reinforcement learning-based congestion control algorithms and present current problems with reinforcement learning-based congestion control algorithms. Moreover, we outline challenges and trends related to learning-based congestion control algorithms.
C1 [Jiang, Huiling] Tsinghua Univ, Tsinghua Berkeley Shenzhen Inst, Shenzhen 518055, Peoples R China.
   [Jiang, Huiling; Li, Qing; Jiang, Yong] PCL Res Ctr Networks & Commun, Peng Cheng Lab, Shenzhen 518055, Peoples R China.
   [Li, Qing] Southern Univ Sci & Technol, Inst Future Networks, Shenzhen 518055, Peoples R China.
   [Jiang, Yong; Shen, GengBiao; Xu, Mingwei] Tsinghua Univ, Comp Sci & Technol, Beijing 100091, Peoples R China.
   [Sinnott, Richard] Univ Melbourne, Sch Comp & Informat Syst, Melbourne, Vic 3004, Australia.
   [Tian, Chen] Nanjing Univ, Comp Sci, Nanjing 210093, Peoples R China.
RP Li, Q (corresponding author), PCL Res Ctr Networks & Commun, Peng Cheng Lab, Shenzhen 518055, Peoples R China.; Li, Q (corresponding author), Southern Univ Sci & Technol, Inst Future Networks, Shenzhen 518055, Peoples R China.
EM jiang-hl19@mails.tsinghua.edu.cn; liq8@sustech.edu.cn;
   jiangy@sz.tsinghua.edu.cn; sgb16@mails.tsinghua.edu.cn;
   rsinnott@unimelb.edu.cn; tianchen@nju.edu.cn; xumw@tsinghua.edu.cn
FU Guangdong Province Key Area RD Program [2018B010113001]; National
   Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [61972189, LZC0019]; Shenzhen Key Lab of Software
   Defined Networking [ZDSYS20140509172959989]
FX This work is supported by Guangdong Province Key Area R&D Program under
   grant No. 2018B010113001, National Natural Science Foundation of China
   under grant No. 61972189, the project "PCL Future GreaterBay Area
   Network Facilities for Largescale Experiments and Applications (LZC0019)
   "and the Shenzhen Key Lab of Software Defined Networking under grant No.
   ZDSYS20140509172959989.
NR 126
TC 5
Z9 5
U1 9
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1389-1286
EI 1872-7069
J9 COMPUT NETW
JI Comput. Netw.
PD JUN 19
PY 2021
VL 192
AR 108033
DI 10.1016/j.comnet.2021.108033
EA APR 2021
PG 28
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Engineering, Electrical & Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA US6VE
UT WOS:000697563900010
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Fiorucci, M
   Khoroshiltseva, M
   Pontil, M
   Traviglia, A
   Del Bue, A
   James, S
AF Fiorucci, Marco
   Khoroshiltseva, Marina
   Pontil, Massimiliano
   Traviglia, Arianna
   Del Bue, Alessio
   James, Stuart
TI Machine Learning for Cultural Heritage: A Survey
SO PATTERN RECOGNITION LETTERS
LA English
DT Article
DE Artificial Intelligence; Machine Learning; Cultural Heritage; Digital
   Humanities
ID ARCHAEOLOGICAL SITE; CLASSIFICATION; RECOGNITION; REGRESSION
AB The application of Machine Learning (ML) to Cultural Heritage (CH) has evolved since basic statistical approaches such as Linear Regression to complex Deep Learning models. The question remains how much of this actively improves on the underlying algorithm versus using it within a 'black box' setting. We survey across ML and CH literature to identify the theoretical changes which contribute to the algorithm and in turn them suitable for CH applications. Alternatively, and most commonly, when there are no changes, we review the CH applications, features and pre/post-processing which make the algorithm suitable for its use. We analyse the dominant divides within ML, Supervised, Semi-supervised and Unsupervised, and reflect on a variety of algorithms that have been extensively used. From such an analysis, we give a critical look at the use of ML in CH and consider why CH has only limited adoption of ML. (C) 2020 The Authors. Published by Elsevier B.V.
C1 [Fiorucci, Marco; Khoroshiltseva, Marina; Traviglia, Arianna; James, Stuart] Ist Italiano Tecnol IIT, Ctr Cultural Heritage Technol CCHT, Genoa, Italy.
   [Pontil, Massimiliano] Ist Italiano Tecnol IIT, Computat Stat & Machine Learning, Genoa, Italy.
   [Del Bue, Alessio; James, Stuart] Ist Italiano Tecnol IIT, Visual Geometry & Modelling VGM Lab, Genoa, Italy.
RP Fiorucci, M (corresponding author), Ist Italiano Tecnol IIT, Ctr Cultural Heritage Technol CCHT, Genoa, Italy.
EM marco.fiorucci@iit.it
RI James, Stuart/U-2795-2019; FIORUCCI, MARCO/N-6474-2016
OI James, Stuart/0000-0002-2649-2133; FIORUCCI, MARCO/0000-0003-1013-5147;
   Traviglia, Arianna/0000-0002-4508-1540
FU European Union's Horizon 2020 research and innovation programme [870743]
FX Partially supported by the European Union's Horizon 2020 research and
   innovation programme under grant agreement No 870743.
NR 58
TC 40
Z9 41
U1 6
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8655
EI 1872-7344
J9 PATTERN RECOGN LETT
JI Pattern Recognit. Lett.
PD MAY
PY 2020
VL 133
BP 102
EP 108
DI 10.1016/j.patrec.2020.02.017
PG 7
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA LT5RZ
UT WOS:000537129300014
OA Green Published, hybrid
DA 2022-04-17
ER

PT J
AU Xu, C
   Liu, XL
   Wang, EZ
   Wang, SJ
AF Xu, Chen
   Liu, Xiaoli
   Wang, Enzhi
   Wang, Sijing
TI Prediction of tunnel boring machine operating parameters using various
   machine learning algorithms
SO TUNNELLING AND UNDERGROUND SPACE TECHNOLOGY
LA English
DT Article
DE TBM; Operating parameters; Machine learning algorithms; CNN; LSTM
ID RECURRENT NEURAL-NETWORKS; INTELLIGENCE; REGRESSION; MODEL
AB The operating parameters of a tunnel boring machine (TBM) reflect its geological conditions and working status and are accordingly critical data for ensuring safe and efficient tunnel construction. The accurate prediction of the advance rate, rotation speed, thrust, and torque indicators based on the operating parameters can guide the control and application of a TBM. In this study, we analyzed the relationships between the TBM operating parameters and daily collected TBM data. We used the smoothing method and outlier detection to process this data, and determined the stable values of four different TBM indicators in the ascending phase of a complete TBM operational segment. Then, we evaluated the application of five different statistical and ensemble machine learning methods (Bayesian ridge regression (BR), nearest neighbors regression, random forests, gradient tree boosting (GTB), and support vector machine) and two different deep neural networks (a convolutional neural network (CNN) and long short-term memory network (LSTM)) to establish prediction models. The GTB method provided the best prediction accuracy and the BR method provided the least calculation time of the five different statistical and ensemble machine learning methods evaluated. The LSTM method provided a higher prediction accuracy than the CNN model. The ensemble machine learning methods were found to be the most accurate for the relatively limited data sets used in this study, suggesting that sufficient data must be present before the advantages of deep neural networks can be truly realized. The successful application of statistical, ensemble, and deep neural network machine learning methods to predict TBM indicators in this study suggests the promise of machine learning in this application.
C1 [Xu, Chen; Liu, Xiaoli; Wang, Enzhi; Wang, Sijing] Tsinghua Univ, State Key Lab Hydrosci & Engn, Beijing 100084, Peoples R China.
   [Liu, Xiaoli; Wang, Enzhi; Wang, Sijing] Tsinghua Univ, Sanjiangyuan Collaborat Innovat Ctr, Beijing 100084, Peoples R China.
   [Wang, Sijing] Chinese Acad Sci, Inst Geol & Geophys, Beijing 100029, Peoples R China.
RP Liu, XL (corresponding author), Tsinghua Univ, State Key Lab Hydrosci & Engn, Beijing 100084, Peoples R China.; Liu, XL (corresponding author), Tsinghua Univ, Sanjiangyuan Collaborat Innovat Ctr, Beijing 100084, Peoples R China.
EM xiaoli.liu@tsinghua.edu.cn
RI Liu, Xiaoli/AAI-6339-2020
FU National Key Research and Development Plan [2018YFC1504902]; National
   Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [52079068, 51479094, 41772246]; National Program on Key
   Basic Research Project (973 Program)National Basic Research Program of
   China [2015CB058100]
FX The National Key Research and Development Plan (Grant No.
   2018YFC1504902), and the National Natural Science Foundation of China
   (Grant No. 52079068, 51479094, 41772246) are gratefully acknowledged.
   The data are from the National Program on Key Basic Research Project
   (973 Program) (Grant No. 2015CB058100).
NR 44
TC 6
Z9 6
U1 31
U2 70
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0886-7798
EI 1878-4364
J9 TUNN UNDERGR SP TECH
JI Tunn. Undergr. Space Technol.
PD MAR
PY 2021
VL 109
AR 103699
DI 10.1016/j.tust.2020.103699
PG 12
WC Construction & Building Technology; Engineering, Civil
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Construction & Building Technology; Engineering
GA PZ0JP
UT WOS:000612427700004
DA 2022-04-17
ER

PT J
AU Ivascu, CF
AF Ivascu, Codrut-Florin
TI Option pricing using Machine Learning
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Machine Learning; Option pricing; Nonparametric methods; Implied
   parameters
ID HEDGING DERIVATIVE SECURITIES; NEURAL-NETWORKS; STOCHASTIC VOLATILITY;
   BLACK-SCHOLES; MODELS
AB This paper examines the option pricing performance of the most popular Machine Learning algorithms. The classic parametrical models suffer from several limitations in term of computational power required for parametric calibration and unrealistic economical and statistical assumptions. Therefore, a data driven approach based on non-parametric models is are well justified. Most of the previous researchers focus especially on the neural networks method (NN), the other algorithms being unexplored. Beside NN, this paper also analyses the performance of the Support Vector Regressions and Genetic Algorithms and propose three other Decision Tree methods, respectively Random Forest, XGBoost and LightGMB. In order to emphasize the power of this algorithms, a comparison with classical methods like Black-Scholes and Corrado-Su with both historical and implied parameters have been conducted. The analyzes were performed on European call options who have as underlying asset the WTI crude oil future contracts. Machine Learning algorithms outperform by a great margin the classical approaches regardless of the moneyness and the maturity of the contracts.
C1 [Ivascu, Codrut-Florin] Bucharest Univ Econ Studies, 5-7 Moxa St, Bucharest, Romania.
RP Ivascu, CF (corresponding author), Bucharest Univ Econ Studies, 5-7 Moxa St, Bucharest, Romania.
EM ivascu_codrut@yahoo.com
RI Ivascu, Codrut/ABF-7428-2021
NR 41
TC 3
Z9 3
U1 22
U2 64
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD JAN
PY 2021
VL 163
AR 113799
DI 10.1016/j.eswa.2020.113799
PG 7
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Operations Research & Management Science
GA OG8GL
UT WOS:000582115400017
DA 2022-04-17
ER

PT J
AU Thakur, S
   Sharma, A
   Kaur, G
   Singh, G
AF Thakur, Shipra
   Sharma, Atul
   Kaur, Gagandeep
   Singh, Gurpreet
TI MACHINE LEARNING: A PARADIGM SHIFT IN INDUSTRIAL SECTOR
SO ADVANCES AND APPLICATIONS IN MATHEMATICAL SCIENCES
LA English
DT Article
DE Machine learning; artificial intelligence; telecommunication; industrial
   sector etc.
ID FEATURE-SELECTION; ALGORITHM; PREDICTION
AB In the era of technology machine learning is the most emerging application of artificial intelligence. An industrial sector is the backbone of the development of any country and implementation of Machine learning is improving and dramatically changing the industrial sector. Machine learning has produced a paradigm shift from traditional to modern approaches in industrial sector. The main purpose of this research paper is to attain competitive advantage and analyse the benefits of adopting machine learning in industrial sector for the better growth and development. Machine learning is making its space in various industrial sectors such as automobile industry, chemical industry, aerospace manufacturing and telecommunications etc. This paper is based on the secondary study. The data for concluding the topic is taken from various research papers, books, internet, journals etc.
C1 [Thakur, Shipra; Kaur, Gagandeep; Singh, Gurpreet] Chandigarh Grp Coll, Comp Sci & Engn, Coll Engn, Landran, India.
   [Sharma, Atul] Chandigarh Univ, Comp Sci & Engn Dept, Gharuan, Mohali, India.
RP Thakur, S (corresponding author), Chandigarh Grp Coll, Comp Sci & Engn, Coll Engn, Landran, India.
EM shipra.4390@cgc.edu.in; Rattan.3atul@gmail.com;
   gagandeep.4421@cgc.edu.in; gurpreet.3529@cgc.edu.in
RI Kaur, Gagandeep/AAE-5289-2021
NR 21
TC 0
Z9 0
U1 3
U2 5
PU MILI PUBL
PI ALLAHABAD
PA 422B CHAK RAGHUNATH, NEAR RAILWAY CROSSING, ALLAHABAD, 211 008, INDIA
SN 0974-6803
J9 ADV APPL MATH SCI
JI Adv. Appl. Math. Sci.
PD APR
PY 2020
VL 19
IS 6
BP 509
EP 515
PG 7
WC Mathematics
WE Emerging Sources Citation Index (ESCI)
SC Mathematics
GA PP7DF
UT WOS:000606018100007
DA 2022-04-17
ER

PT C
AU Wibirama, S
   Sidhawara, AGP
   Pritalia, GL
   Adji, TB
AF Wibirama, Sunu
   Sidhawara, A. G. Pradnya
   Pritalia, Generosa Lukhayu
   Adji, Teguh Bharata
GP IEEE
TI A Survey of Learning Style Detection Method using Eye-Tracking and
   Machine Learning in Multimedia Learning
SO 2020 INTERNATIONAL SYMPOSIUM ON COMMUNITY-CENTRIC SYSTEMS (CCS)
LA English
DT Proceedings Paper
CT International Symposium on Community-Centric Systems (CcS)
CY SEP 23-26, 2020
CL Tokyo, JAPAN
DE learning style; cognitive style; eye-tracking; multimedia learning;
   machine learning
ID COGNITIVE-STYLE; TECHNOLOGY
AB Current utilization of multimedia learning environment focuses on student-centered approach. This approach is based on a theory stating that learning styles affect individuals in information processing. Based on prior works, there are three main approaches to distinguish learning styles: conventional approach-such as interview and self-reporting, artificial-intelligence-based approach, and sensor-based approach. Unfortunately, there is no comparative analysis that addresses strengths and limitations of these approaches. Thus, there is no information on how and when to use these approaches appropriately. To address this limitation, we present a brief literature review of several studies in distinguishing learning styles, including their strengths and limitations. We also present insights on potential methods of detecting learning styles in multimedia learning based on eye movement data and machine learning algorithms. Our paper is useful as a guideline for developing intelligent e-learning systems based on eye tracking and machine learning.
C1 [Wibirama, Sunu; Sidhawara, A. G. Pradnya; Pritalia, Generosa Lukhayu; Adji, Teguh Bharata] Univ Gadjah Mada, Fac Engn, Dept Elect & Informat Engn, Yogyakarta 55281, Indonesia.
RP Wibirama, S (corresponding author), Univ Gadjah Mada, Fac Engn, Dept Elect & Informat Engn, Yogyakarta 55281, Indonesia.
EM sunu@ugm.ac.id; aloysius.gonzaga@mail.ugm.ac.id;
   generosalukhayu@mail.ugm.ac.id; adji@ugm.ac.id
NR 50
TC 2
Z9 2
U1 2
U2 3
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-8741-9
PY 2020
PG 6
WC Computer Science, Cybernetics; Engineering, Biomedical; Robotics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Robotics
GA BQ9OK
UT WOS:000626320900021
DA 2022-04-17
ER

PT J
AU Ding, YH
   Hua, LS
   Li, SL
AF Ding, Yuhan
   Hua, Lisha
   Li, Shunlei
TI Research on computer vision enhancement in intelligent robot based on
   machine learning and deep learning
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Machine learning; Deep learning; Robotics; Machine vision
AB The stable operation of intelligent robots requires the effective support of machine vision technology. In order to improve the effect of robot machine vision recognition, based on deep learning, this paper, under the guidance of machine learning ideas, proposes a target detection framework that combines target recognition and target tracking based on the efficiency advantages of the KCF visual tracking algorithm. Moreover, this paper designs a vision system based on a high-resolution color camera and TOF depth camera. In addition, by modeling the coordinate conversion relationship of the same object in the camera coordinate system of two cameras, the projection relationship of the depth map collected by the TOF camera to the pixel coordinate system of the high-resolution color camera is determined. In addition, this paper designs experiments to verify the performance of the model. The research results show that the method proposed in this paper has a certain effect.
C1 [Ding, Yuhan] Univ Bologna, Fac Ingn, I-40121 Bologna, Italy.
   [Hua, Lisha] City Univ Hong Kong, Mech Engn, Hong Kong 999077, Peoples R China.
   [Li, Shunlei] Tsinghua Univ, State Key Lab Tribol, Beijing 100084, Peoples R China.
RP Hua, LS (corresponding author), Univ Bologna, Fac Ingn, I-40121 Bologna, Italy.
EM lishahua3c@my.cityu.edu.hk
NR 26
TC 2
Z9 2
U1 12
U2 37
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD FEB
PY 2022
VL 34
IS 4
SI SI
BP 2623
EP 2635
DI 10.1007/s00521-021-05898-8
EA MAR 2021
PG 13
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YV1BC
UT WOS:000631777400002
DA 2022-04-17
ER

PT J
AU Shuaibi, M
   Sivakumar, S
   Chen, RQ
   Ulissi, ZW
AF Shuaibi, Muhammed
   Sivakumar, Saurabh
   Chen, Rui Qi
   Ulissi, Zachary W.
TI Enabling robust offline active learning for machine learning potentials
   using simple physics-based priors
SO MACHINE LEARNING-SCIENCE AND TECHNOLOGY
LA English
DT Article
DE machine learning potentials; molecular simulations; neural networks;
   active learning; physics priors
AB Machine learning surrogate models for quantum mechanical simulations have enabled the field to efficiently and accurately study material and molecular systems. Developed models typically rely on a substantial amount of data to make reliable predictions of the potential energy landscape or careful active learning (AL) and uncertainty estimates. When starting with small datasets, convergence of AL approaches is a major outstanding challenge which has limited most demonstrations to online AL. In this work we demonstrate a Delta-machine learning (ML) approach that enables stable convergence in offline AL strategies by avoiding unphysical configurations with initial datasets as little as a single data point. We demonstrate our framework's capabilities on a structural relaxation, transition state calculation, and molecular dynamics simulation, with the number of first principle calculations being cut down anywhere from 70%-90%. The approach is incorporated and developed alongside AMPtorch, an open-source ML potential package, along with interactive Google Colab notebook examples.
C1 [Shuaibi, Muhammed; Sivakumar, Saurabh; Chen, Rui Qi; Ulissi, Zachary W.] Carnegie Mellon Univ, Dept Chem Engn, Pittsburgh, PA 15213 USA.
RP Ulissi, ZW (corresponding author), Carnegie Mellon Univ, Dept Chem Engn, Pittsburgh, PA 15213 USA.
EM zulissi@andrew.cmu.edu
FU U.S. Department of Energy, Office of Science, Basic Energy Sciences
   AwardUnited States Department of Energy (DOE) [DE-FOA-0001912]
FX We acknowledge the support from the U.S. Department of Energy, Office of
   Science, Basic Energy Sciences Award #DE-FOA-0001912. Additionally, we
   thank Andrew Peterson and A J Medford for their thoughtful discussions.
NR 45
TC 6
Z9 6
U1 1
U2 6
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
EI 2632-2153
J9 MACH LEARN-SCI TECHN
JI Mach. Learn.-Sci. Technol.
PD JUN
PY 2021
VL 2
IS 2
AR 025007
DI 10.1088/2632-2153/abcc44
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Science & Technology - Other Topics
GA SR2MX
UT WOS:000660878600001
OA gold, Green Submitted
DA 2022-04-17
ER

PT J
AU Rodrigues, IR
   Neto, SRD
   Kelner, J
   Sadok, D
   Endo, PT
AF Rodrigues, Iago Richard
   da Silva Neto, Sebastiao Rogerio
   Kelner, Judith
   Sadok, Djamel
   Endo, Patricia Takako
TI Convolutional Extreme Learning Machines: A Systematic Review
SO INFORMATICS-BASEL
LA English
DT Review
DE convolutional extreme learning machine; deep learning; multimedia
   analysis
ID LOCAL RECEPTIVE-FIELDS; GENERIC OBJECT RECOGNITION; IMAGE
   CLASSIFICATION; NEURAL-NETWORK; MODELS
AB Much work has recently identified the need to combine deep learning with extreme learning in order to strike a performance balance with accuracy, especially in the domain of multimedia applications. When considering this new paradigm-namely, the convolutional extreme learning machine (CELM)-we present a systematic review that investigates alternative deep learning architectures that use the extreme learning machine (ELM) for faster training to solve problems that are based on image analysis. We detail each of the architectures that are found in the literature along with their application scenarios, benchmark datasets, main results, and advantages, and then present the open challenges for CELM. We followed a well-structured methodology and established relevant research questions that guided our findings. Based on 81 primary studies, we found that object recognition is the most common problem that is solved by CELM, and CCN with predefined kernels is the most common CELM architecture proposed in the literature. The results from experiments show that CELM models present good precision, convergence, and computational performance, and they are able to decrease the total processing time that is required by the learning process. The results presented in this systematic review are expected to contribute to the research area of CELM, providing a good starting point for dealing with some of the current problems in the analysis of computer vision based on images.
C1 [Rodrigues, Iago Richard; Kelner, Judith; Sadok, Djamel] Univ Fed Pernambuco UFPE, Ctr Informat, BR-50670420 Recife, PE, Brazil.
   [da Silva Neto, Sebastiao Rogerio; Endo, Patricia Takako] Univ Pernambuco UPE, Programa Posgrad Engn Computacao, BR-50050000 Recife, PE, Brazil.
RP Rodrigues, IR (corresponding author), Univ Fed Pernambuco UFPE, Ctr Informat, BR-50670420 Recife, PE, Brazil.; Endo, PT (corresponding author), Univ Pernambuco UPE, Programa Posgrad Engn Computacao, BR-50050000 Recife, PE, Brazil.
EM irrs@cin.ufpe.br; srsn@ecomp.poli.br; jk@cin.ufpe.br; jamel@cin.ufpe.br;
   patricia.endo@upe.br
RI Rodrigues Silva, Iago Richard/AAX-3739-2021; Sadok, Djamel F
   Hadj/AAR-8550-2021
OI Rodrigues Silva, Iago Richard/0000-0002-8242-9059; Sadok, Djamel F
   Hadj/0000-0001-5378-4732; Rogerio da Silva Neto,
   Sebastiao/0000-0001-8109-697X; Endo, Patricia Takako/0000-0002-9163-5583
FU Conselho Nacional de Desenvolvimento Cientifico e Tecnologico
   (CNPq)Conselho Nacional de Desenvolvimento Cientifico e Tecnologico
   (CNPQ); Coordenacao de Aperfeicoamento de Pessoal de Nivel
   Superior-Brasil (CAPES)Coordenacao de Aperfeicoamento de Pessoal de
   Nivel Superior (CAPES); Fundacao de Amparo a Ciencia e Tecnologia de
   Pernambuco (FACEPE)Fundacao de Amparo a Ciencia e Tecnologia do Estado
   de Pernambuco (FACEPE)
FX This work was supported by the Conselho Nacional de Desenvolvimento
   Cientifico e Tecnologico (CNPq), the CoordenacAo de Aperfeicoamento de
   Pessoal de Nivel Superior-Brasil (CAPES) and FundacAo de Amparo a
   Ciencia e Tecnologia de Pernambuco (FACEPE).
NR 132
TC 0
Z9 0
U1 4
U2 6
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2227-9709
J9 INFORMATICS-BASEL
JI Informatics-Basel
PD JUN
PY 2021
VL 8
IS 2
AR 33
DI 10.3390/informatics8020033
PG 33
WC Computer Science, Interdisciplinary Applications
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA SX4UF
UT WOS:000665201100001
OA gold
DA 2022-04-17
ER

PT J
AU Monaco, A
   Pantaleo, E
   Amoroso, N
   Lacalamita, A
   Lo Giudice, C
   Fonzino, A
   Fosso, B
   Picardi, E
   Tangaro, S
   Pesole, G
   Bellotti, R
AF Monaco, Alfonso
   Pantaleo, Ester
   Amoroso, Nicola
   Lacalamita, Antonio
   Lo Giudice, Claudio
   Fonzino, Adriano
   Fosso, Bruno
   Picardi, Ernesto
   Tangaro, Sabina
   Pesole, Graziano
   Bellotti, Roberto
TI A primer on machine learning techniques for genomic applications
SO COMPUTATIONAL AND STRUCTURAL BIOTECHNOLOGY JOURNAL
LA English
DT Review
DE Machine learning; Deep learning; Genomics
ID FEATURE-SELECTION; GENE-EXPRESSION; GENERATION; CLASSIFICATION;
   REGRESSION; FUTURE
AB High throughput sequencing technologies have enabled the study of complex biological aspects at single nucleotide resolution, opening the big data era. The analysis of large volumes of heterogeneous "omic" data, however, requires novel and efficient computational algorithms based on the paradigm of Artificial Intelligence. In the present review, we introduce and describe the most common machine learning methodologies, and lately deep learning, applied to a variety of genomics tasks, trying to emphasize capabilities, strengths and limitations through a simple and intuitive language. We highlight the power of the machine learning approach in handling big data by means of a real life example, and underline how described methods could be relevant in all cases in which large amounts of multimodal genomic data are available. (C) 2021 The Authors. Published by Elsevier B.V. on behalf of Research Network of Computational and Structural Biotechnology.
C1 [Monaco, Alfonso; Amoroso, Nicola; Tangaro, Sabina; Bellotti, Roberto] Ist Nazl Fis Nucl INFN, Sez Bari, Via A Orabona 4, I-70125 Bari, Italy.
   [Pantaleo, Ester; Bellotti, Roberto] Univ Bari Aldo Moro, Dipartimento Interateneo Fis M Merlin, Via G Amendola 173, I-70125 Bari, Italy.
   [Amoroso, Nicola] Univ Bari Aldo Moro, Dipartimento Farm Sci Farmaco, Via A Orabona 4, I-70125 Bari, Italy.
   [Lacalamita, Antonio] Natl Inst Gastroenterol S de Bellis, Res Hosp, I-70013 Bari, Italy.
   [Lo Giudice, Claudio; Fonzino, Adriano; Picardi, Ernesto; Pesole, Graziano] Univ Bari Aldo Moro, Dipartimento Biosci Biotecnol & Biofarmaceut, Via A Orabona 4, I-70125 Bari, Italy.
   [Fosso, Bruno; Picardi, Ernesto; Pesole, Graziano] CNR, Ist Biomembrane Bioenerget & Biotecnol Mol, Via G Amendola 122-O, I-70126 Bari, Italy.
   [Tangaro, Sabina] Univ Bari Aldo Moro, Dipartimento Sci Suolo Pianta & Alimenti, Via G Amendola 165, I-70125 Bari, Italy.
RP Picardi, E (corresponding author), Univ Bari Aldo Moro, Dipartimento Biosci Biotecnol & Biofarmaceut, Via A Orabona 4, I-70125 Bari, Italy.
EM ernesto.picardi@uniba.it
RI Fosso, Bruno/P-1538-2018; Monaco, Alfonso/AGA-5911-2022; Picardi,
   Ernesto/A-5863-2015
OI Fosso, Bruno/0000-0003-2324-086X; Monaco, Alfonso/0000-0002-5968-8642;
   Tangaro, Sabina/0000-0002-1372-3916; Picardi,
   Ernesto/0000-0002-6549-0114; Lo Giudice, Claudio/0000-0003-3609-8938;
   Amoroso, Nicola/0000-0003-0211-0783; Lacalamita,
   Antonio/0000-0002-1013-3793; Pantaleo, Ester/0000-0001-8407-9032
FU Italian node of ELIXIR (ELIXIRIIB: the Italian Infrastructure for
   Bioinformatics)
FX This work was supported by the Italian node of ELIXIR (ELIXIRIIB: the
   Italian Infrastructure for Bioinformatics). We also thank Maria Rosa
   Mirizzi, Barbara De Marzo, Annarita Armenise and Laura Marra for
   technical assistance.
NR 81
TC 0
Z9 0
U1 5
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2001-0370
J9 COMPUT STRUCT BIOTEC
JI Comp. Struct. Biotechnol. J..
PY 2021
VL 19
BP 4345
EP 4359
DI 10.1016/j.csbj.2021.07.021
EA AUG 2021
PG 15
WC Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology
GA TZ5ON
UT WOS:000684521800004
PM 34429852
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Albaradei, S
   Thafar, M
   Alsaedi, A
   Van Neste, C
   Gojobori, T
   Essack, M
   Gao, X
AF Albaradei, Somayah
   Thafar, Maha
   Alsaedi, Asim
   Van Neste, Christophe
   Gojobori, Takashi
   Essack, Magbubah
   Gao, Xin
TI Machine learning and deep learning methods that use omics data for
   metastasis prediction
SO COMPUTATIONAL AND STRUCTURAL BIOTECHNOLOGY JOURNAL
LA English
DT Review
DE Cancer; Metastasis; Machine learning; Deep learning; Artificial
   intelligence
ID CANCER; NORMALIZATION; CLASSIFIER; TRANSITION; ALGORITHM; NETWORKS;
   INVASION
AB Knowing metastasis is the primary cause of cancer-related deaths, incentivized research directed towards unraveling the complex cellular processes that drive the metastasis. Advancement in technology and specifically the advent of high-throughput sequencing provides knowledge of such processes. This knowledge led to the development of therapeutic and clinical applications, and is now being used to pre-dict the onset of metastasis to improve diagnostics and disease therapies. In this regard, predicting metastasis onset has also been explored using artificial intelligence approaches that are machine learn-ing, and more recently, deep learning-based. This review summarizes the different machine learning and deep learning-based metastasis prediction methods developed to date. We also detail the different types of molecular data used to build the models and the critical signatures derived from the different methods. We further highlight the challenges associated with using machine learning and deep learning methods, and provide suggestions to improve the predictive performance of such methods. (c) 2021 The Authors. Published by Elsevier B.V. on behalf of Research Network of Computational and Structural Biotechnology.
C1 [Albaradei, Somayah; Thafar, Maha; Van Neste, Christophe; Gojobori, Takashi; Essack, Magbubah; Gao, Xin] King Abdullah Univ Sci & Technol KAUST, Comp Elect & Math Sci & Engn Div CEMSE, Computat Biosci Res Ctr CBRC, Thuwal 239556900, Saudi Arabia.
   [Albaradei, Somayah] King Abdulaziz Univ, Fac Comp & Informat Technol, Jeddah, Saudi Arabia.
   [Thafar, Maha] Taif Univ, Collage Computers & Informat Technol, At Taif, Saudi Arabia.
   [Alsaedi, Asim] King Saud bin Abdulaziz Univ Hlth Sci, Jeddah, Saudi Arabia.
   [Thafar, Maha] King Abdul Aziz Med City, Jeddah, Saudi Arabia.
   [Gojobori, Takashi] King Abdullah Univ Sci & Technol KAUST, Biol & Environm Sci & Engn Div BESE, Thuwal 239556900, Saudi Arabia.
RP Essack, M; Gao, X (corresponding author), King Abdullah Univ Sci & Technol KAUST, Comp Elect & Math Sci & Engn Div CEMSE, Computat Biosci Res Ctr CBRC, Thuwal 239556900, Saudi Arabia.
EM magbubah.essack@kaust.edu.sa; xin.gao@kaust.edu.sa
RI Gao, Xin/D-5487-2013
OI Gao, Xin/0000-0002-7108-3574; Thafar, Maha/0000-0003-0539-7361;
   Albaradei, Somayah/0000-0003-4317-2358
FU King Abdullah University of Science and Technology (KAUST)King Abdullah
   University of Science & Technology [BAS/1/1059-01-01, BAS/1/1624-01-01,
   FCC/1/1976-20-01, FCC/1/1976-26-01]
FX The research reported in this publication was supported by King Abdullah
   University of Science and Technology (KAUST) through the Awards Nos.
   BAS/1/1059-01-01, BAS/1/1624-01-01, FCC/1/1976-20-01, and
   FCC/1/1976-26-01.
NR 89
TC 4
Z9 4
U1 14
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2001-0370
J9 COMPUT STRUCT BIOTEC
JI Comp. Struct. Biotechnol. J..
PY 2021
VL 19
BP 5008
EP 5018
DI 10.1016/j.csbj.2021.09.001
EA SEP 2021
PG 11
WC Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology
GA WC6SV
UT WOS:000704386800009
PM 34589181
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Odevci, BB
   Emsen, E
   Aydin, MN
AF Odevci, B. B.
   Emsen, E.
   Aydin, M. N.
TI Machine learning algorithms for lamb survival
SO COMPUTERS AND ELECTRONICS IN AGRICULTURE
LA English
DT Article
DE Machine learning algorithms; Lamb survival
ID BIRTH-WEIGHT; NEONATAL LAMB; BEHAVIOR; DISCRIMINATION; COLOSTRUM; SHEEP;
   WOOL
AB Lamb survival is influenced by the culmination of a sequence of often interrelated events including genetics, physiology, behaviour and nutrition, with the environment providing an overarching complication. Machine learning algorithms offer great flexibility with regard to problems of complex interactions among variables. The objective of this study was to use machine learning algorithms to identify factors affecting the lamb survival in high altitudes and cold climates. Lambing records were obtained from three native breed of sheep (Awassi = 50, Morkaraman = 50, Tuj = 50) managed in semi intensive systems. The data set included 193 spring born lambs out of which 106 lambs were sired by indigenous rams (n = 10), and 87 lambs were sired by Romanov Rams (n = 10).
   Factors included were dam body weight at lambing, age of dam, litter size at birth, maternal and lamb be-haviors, and lamb sex. Individual and cohort data were combined into an original dataset containing 1351 event records from 193 individual lambs and 750 event records from 150 individual ewes. Classification algorithms applied for lamb survival were Bayesian Methods, Artificial Neural Networks, Support Vector Machine and Decision Trees. Variables were categorized for lamb survival, lamb behavior, and mothering ability. Random-Forest performed very well in their classification of the mothering ability while SMO was found best in predicting lamb behavior. REPtree tree visualization showed that grooming behavior is the first determinant for mothering ability. Classification Trees performed best in lamb survival. Our results showed that Classification Trees clearly outperform others in all traits included in this study.
C1 [Odevci, B. B.; Aydin, M. N.] Kadir Has Univ, Management Informat Syst, TR-34083 Istanbul, Turkey.
   [Emsen, E.] Ataturk Univ, Dept Anim Sci, TR-25240 Erzurum, Turkey.
RP Emsen, E (corresponding author), Ataturk Univ, Dept Anim Sci, TR-25240 Erzurum, Turkey.
NR 44
TC 0
Z9 0
U1 4
U2 11
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0168-1699
EI 1872-7107
J9 COMPUT ELECTRON AGR
JI Comput. Electron. Agric.
PD MAR
PY 2021
VL 182
AR 105995
DI 10.1016/j.compag.2021.105995
EA FEB 2021
PG 7
WC Agriculture, Multidisciplinary; Computer Science, Interdisciplinary
   Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Agriculture; Computer Science
GA RC2LI
UT WOS:000632635700004
DA 2022-04-17
ER

PT J
AU Cencer, MM
   Moore, JS
   Assary, RS
AF Cencer, Morgan M.
   Moore, Jeffrey S.
   Assary, Rajeev S.
TI Machine learning for polymeric materials: an introduction
SO POLYMER INTERNATIONAL
LA English
DT Review; Early Access
DE machine learning; polymers; informatics; inverse design
ID INVERSE DESIGN; MATERIALS INFORMATICS; PREDICTION; DISCOVERY;
   REPRESENTATION; OPPORTUNITIES; OPTIMIZATION; LIBRARY; SYSTEM; TIME
AB Polymers are incredibly versatile materials and have become ubiquitous. Increasingly, researchers are using data science and polymer informatics to design new materials and understand their structure-property relationships. Polymer informatics is an emerging field. While there are many useful tools and databases available, many are not widely utilized. Herein, we introduce the field of polymer informatics and discuss some of the available databases and tools. We cover how to share polymer data, approaches for preparing a dataset for machine learning and recent applications of machine learning to polymer property prediction and polymer synthesis. (c) 2021 Society of Industrial Chemistry.
C1 [Cencer, Morgan M.; Moore, Jeffrey S.] Univ Illinois, Dept Chem, Urbana, IL USA.
   [Cencer, Morgan M.; Assary, Rajeev S.] Argonne Natl Lab, Mat Sci Div, Lemont, IL 60439 USA.
   [Cencer, Morgan M.; Moore, Jeffrey S.] Univ Illinois, Beckman Inst Adv Sci & Technol, Urbana, IL USA.
RP Assary, RS (corresponding author), Argonne Natl Lab, Mat Sci Div, Lemont, IL 60439 USA.
EM assary@anl.gov
OI Cencer, Morgan/0000-0003-2806-8317; Surendran Assary,
   Rajeev/0000-0002-9571-3307; Moore, Jeffrey/0000-0001-5841-6269
FU CDAC funding via AI for Electrochemistry program
FX We acknowledge UChicago/Argonne, CDAC funding via AI for
   Electrochemistry program. The authors thank Dorothy Loudermilk for
   assistance in making figures.
NR 105
TC 0
Z9 0
U1 41
U2 41
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0959-8103
EI 1097-0126
J9 POLYM INT
JI Polym. Int.
DI 10.1002/pi.6345
EA DEC 2021
PG 6
WC Polymer Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Polymer Science
GA XQ9SP
UT WOS:000731881000001
DA 2022-04-17
ER

PT J
AU Clement, CL
   Kauwe, SK
   Sparks, TD
AF Clement, Conrad L.
   Kauwe, Steven K.
   Sparks, Taylor D.
TI Benchmark AFLOW Data Sets for Machine Learning
SO INTEGRATING MATERIALS AND MANUFACTURING INNOVATION
LA English
DT Article
DE AFLOW; Benchmark data sets; Machine learning; Materials informatics
AB Materials informatics is increasingly finding ways to exploit machine learning algorithms. Techniques such as decision trees, ensemble methods, support vector machines, and a variety of neural network architectures are used to predict likely material characteristics and property values. Supplemented with laboratory synthesis, applications of machine learning to compound discovery and characterization represent one of the most promising research directions in materials informatics. A shortcoming of this trend, in its current form, is a lack of standardized materials data sets on which to train, validate, and test model effectiveness. Applied machine learning research depends on benchmark data to make sense of its results. Fixed, predetermined data sets allow for rigorous model assessment and comparison. Machine learning publications that do not refer to benchmarks are often hard to contextualize and reproduce. In this data descriptor article, we present a collection of data sets of different material properties taken from the AFLOW database. We describe them, the procedures that generated them, and their use as potential benchmarks. We provide a compressed ZIP file containing the data sets and a GitHub repository of associated Python code. Finally, we discuss opportunities for future work incorporating the data sets and creating similar benchmark collections.
C1 [Clement, Conrad L.; Kauwe, Steven K.; Sparks, Taylor D.] Univ Utah, Dept Mat Sci & Engn, Salt Lake City, UT 84112 USA.
RP Sparks, TD (corresponding author), Univ Utah, Dept Mat Sci & Engn, Salt Lake City, UT 84112 USA.
EM sparks@eng.utah.edu
RI Sparks, Taylor/I-4927-2019
OI Sparks, Taylor/0000-0001-8020-7711
FU NSF CAREER AwardNational Science Foundation (NSF)NSF - Office of the
   Director (OD) [DMR 1651668]
FX The authors gratefully acknowledge support from the NSF CAREER Award DMR
   1651668. The authors thank the creators of AFLOW for the creation of the
   database and for making its contents available for this article. In
   addition, the authors express their gratitude to the open-source
   software community, for developing the excellent tools used in this
   research, including Python and the pandas, numpy, matplotlib, and
   sklearn Python libraries, among others.
NR 22
TC 10
Z9 10
U1 2
U2 6
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 2193-9764
EI 2193-9772
J9 INTEGR MATER MANUF I
JI Integr. Mater. Manuf. Innov.
PD JUN
PY 2020
VL 9
IS 2
BP 153
EP 156
DI 10.1007/s40192-020-00174-4
PG 4
WC Engineering, Manufacturing; Materials Science, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Materials Science
GA MC6YY
UT WOS:000543431000001
DA 2022-04-17
ER

PT J
AU Boman, M
   Downs, J
   Karali, A
   Pawlby, S
AF Boman, Magnus
   Downs, Johnny
   Karali, Abubakrelsedik
   Pawlby, Susan
TI Toward Learning Machines at a Mother and Baby Unit
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE learning machine; machine learning; multi-modal learning; mental health;
   maternal unresponsiveness; mind-mindedness
ID FACIAL EXPRESSION; RECOGNITION; HEALTH
AB Agnostic analyses of unique video material from a Mother and Baby Unit were carried out to investigate the usefulness of such analyses to the unit. The goal was to improve outcomes: the health of mothers and their babies. The method was to implement a learning machine that becomes more useful over time and over task. A feasible set-up is here described, with the purpose of producing intelligible and useful results to healthcare professionals at the unit by means of a vision processing pipeline, grouped together with multi-modal capabilities of handling annotations and audio. Algorithmic bias turned out to be an obstacle that could only partly be handled by modern pipelines for automated feature analysis. The professional use of complex quantitative scoring for various mental health-related assessments further complicated the automation of laborious tasks. Activities during the MBU stay had previously been shown to decrease psychiatric symptoms across diagnostic groups. The implementation and first set of experiments on a learning machine for the unit produced the first steps toward explaining why this is so, in turn enabling decision support to staff about what to do more and what to do less of.
C1 [Boman, Magnus; Karali, Abubakrelsedik] KTH Royal Inst Technol, Sch Elect Engn & Comp Sci, Dept Software & Comp Syst, Stockholm, Sweden.
   [Downs, Johnny] Kings Coll London, Natl Inst Hlth Res, Maudsley Biomed Res Ctr, Child & Adolescent Psychiat Psychol Med & Integra, London, England.
   [Karali, Abubakrelsedik] NVIDIA Corp, London, England.
   [Pawlby, Susan] South London & Maudsley Natl Hlth Serv Trust, Bethlem Royal Hosp, Channi Kumar Mother & Baby Unit, London, England.
RP Boman, M (corresponding author), KTH Royal Inst Technol, Sch Elect Engn & Comp Sci, Dept Software & Comp Syst, Stockholm, Sweden.
EM mab@kth.se; susan.pawlby@kcl.ac.uk
RI Downs, Johnny/AAC-8287-2021
OI Downs, Johnny/0000-0002-8061-295X
FU RISE AI; Swedish Research CouncilSwedish Research CouncilEuropean
   Commission; Erling-Persson Family Foundation; MRCUK Research &
   Innovation (UKRI)Medical Research Council UK (MRC) [MR/L017105/1]
   Funding Source: UKRI
FX The project funding came largely from RISE AI, thanks to Daniel Gillblad
   and Bjorn Hovstadius. MB would like to acknowledge financial support for
   learning machines research from the Swedish Research Council and the
   Erling-Persson Family Foundation.
NR 42
TC 0
Z9 0
U1 2
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD NOV 13
PY 2020
VL 11
AR 567310
DI 10.3389/fpsyg.2020.567310
PG 9
WC Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Psychology
GA OV8BL
UT WOS:000592428000001
PM 33281668
OA gold, Green Published
DA 2022-04-17
ER

PT C
AU Khasanova, AM
   Pasechnik, MO
AF Khasanova, Adelya M.
   Pasechnik, Margarita O.
GP IEEE
TI Social Media Analysis with Machine Learning
SO PROCEEDINGS OF THE 2021 IEEE CONFERENCE OF RUSSIAN YOUNG RESEARCHERS IN
   ELECTRICAL AND ELECTRONIC ENGINEERING (ELCONRUS)
SE IEEE NW Russia Young Researchers in Electrical and Electronic
   Engineering Conference
LA English
DT Proceedings Paper
CT IEEE Conference of Russian Young Researchers in Electrical and
   Electronic Engineering (ElConRus)
CY JAN 26-28, 2021
CL Saint Petersburg Electrotechn Univ, RUSSIA
SP IEEE
HO Saint Petersburg Electrotechn Univ
DE clustering; k-means; social media; machine learning; text mining
AB Social networks have revolutionized the world. We all display personal information on social networks, thereby leaving a digital footprint on the Internet. The analysis of personal information can help companies conduct interviews, as it will give employers a full picture of a person, with a description of his/her personality and social behavior. Among the main problems of the analysis conducted there were the effective working groups formation and the allocation of deviant behavior based on the analysis of information from personal profiles on the social network VKontakte. In the course of this study, the data was collected, pre-processed, analyzed. After that users were organized into groups using machine learning and deep machine learning techniques. The analysis of data from users' social networks was carried out using neural networks and other machine learning methods, the K-means clustering algorithm being used for clustering users by interests.
C1 [Khasanova, Adelya M.] Natl Res Nucl Univ MEPhI, Higher Engn Sch, Moscow, Russia.
   [Pasechnik, Margarita O.] Natl Res Nucl Univ MEPhI, Dept Comp Syst & Technol, Moscow, Russia.
RP Khasanova, AM (corresponding author), Natl Res Nucl Univ MEPhI, Higher Engn Sch, Moscow, Russia.
EM AMKhasanova@mephi.ru; MOPasechnik@mephi.ru
NR 6
TC 0
Z9 0
U1 3
U2 4
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2376-6557
BN 978-1-6654-0476-1
J9 IEEE NW RUSS YOUNG
PY 2021
BP 32
EP 35
DI 10.1109/ElConRus51938.2021.9396713
PG 4
WC Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering
GA BR7SJ
UT WOS:000669709800007
DA 2022-04-17
ER

PT C
AU Vaccaro, L
   Sansonetti, G
   Micarelli, A
AF Vaccaro, Lorenzo
   Sansonetti, Giuseppe
   Micarelli, Alessandro
BA Murgante, B
BF Murgante, B
BE Gervasi, O
   Misra, S
   Garau, C
   Blecic, I
   Taniar, D
   Apduhan, BO
   Rocha, AMAC
   Tarantino, E
   Torre, CM
   Karaca, Y
TI Automated Machine Learning: Prospects and Challenges
SO COMPUTATIONAL SCIENCE AND ITS APPLICATIONS, ICCSA 2020, PART IV
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 20th International Conference on Computational Science and Its
   Applications (ICCSA)
CY JUL 01-04, 2020
CL ELECTR NETWORK
SP Univ Cagliari, Univ Perugia, Univ Basilicata, Monash Univ, Kyushu Sangyo Univ, Univ Minho, Springer Int Publishing AG, Comp Open Access Journal, IEEE Italy Sect, IEEE GRSS, Ctr N Italy Chapter, IEEE Comp Soc, Italy Sect, Sci Assoc Transport Infrastructures, Regione Sardegna
DE Automated Machine Learning; Meta Learning; Neural Architecture Search;
   Reinforcement learning
ID RECOMMENDATION
AB The State of the Art of the young field of Automated Machine Learning (AutoML) is held by the connectionist approach. Several techniques of such an inspiration have recently shown promising results in automatically designing neural network architectures. However, apart from back-propagation, only a few applications of other learning techniques are used for these purposes. The back-propagation process takes advantage of specific optimization techniques that are best suited to specific application domains (e.g., Computer Vision and Natural Language Processing). Hence, the need for a more general learning approach, namely, a basic algorithm able to make inference in different contexts with distinct properties. In this paper, we deal with the problem from a scientific and epistemological point of view. We believe that this is needed to fully understand the mechanisms and dynamics underlying human learning. To this aim, we define some elementary inference operations and show how modern architectures can be built by a combination of those elementary methods. We analyze each method in different settings and find the best-suited application context for each learning algorithm. Furthermore, we discuss experimental findings and compare them with human learning. The discrepancy is particularly evident between supervised and unsupervised learning. Then, we determine which elementary learning rules are best suited for unsupervised systems, and, finally, we propose some improvements in reinforcement learning architectures.
C1 [Vaccaro, Lorenzo; Sansonetti, Giuseppe; Micarelli, Alessandro] Roma Tre Univ, Dept Engn, Via Vasca Navale 79, I-00146 Rome, Italy.
RP Sansonetti, G (corresponding author), Roma Tre Univ, Dept Engn, Via Vasca Navale 79, I-00146 Rome, Italy.
EM lor.vaccaro1@stud.uniroma3.it; gsansone@dia.uniroma3.it;
   micarel@dia.uniroma3.it
OI Sansonetti, Giuseppe/0000-0003-4953-1390
NR 33
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-58811-3; 978-3-030-58810-6
J9 LECT NOTES COMPUT SC
PY 2020
VL 12252
BP 119
EP 134
DI 10.1007/978-3-030-58811-3_9
PG 16
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods; Mathematics, Applied
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Mathematics
GA BS4SN
UT WOS:000722380600009
DA 2022-04-17
ER

PT J
AU Zhang, F
   Chen, Z
   Zhang, CY
   Zhou, AC
   Zhai, JD
   Du, XY
AF Zhang, Feng
   Chen, Zheng
   Zhang, Chenyang
   Zhou, Amelie Chi
   Zhai, Jidong
   Du, Xiaoyong
TI An Efficient Parallel Secure Machine Learning Framework on GPUs
SO IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS
LA English
DT Article
DE Machine learning; Servers; Graphics processing units; Acceleration;
   Machine learning algorithms; Optimization; Task analysis; Two-party
   computation; GPU acceleration; secure training; secure inference;
   machine learning
AB Machine learning is widely used in our daily lives. Large amounts of data have been continuously produced and transmitted to the cloud for model training and data processing, which raises a problem: how to preserve the security of the data. Recently, a secure machine learning system named SecureML has been proposed to solve this issue using two-party computation. However, due to the excessive computation expenses of two-party computation, the secure machine learning is about 2x slower than the original machine learning methods. Previous work on secure machine learning mostly focused on novel protocols or improving accuracy, while the performance metric has been ignored. In this article, we propose a GPU-based framework ParSecureML to improve the performance of secure machine learning algorithms based on two-party computation. The main challenges of developing ParSecureML lie in the complex computation patterns, frequent intra-node data transmission between CPU and GPU, and complicated inter-node data dependence. To handle these challenges, we propose a series of novel solutions, including profiling-guided adaptive GPU utilization, fine-grained double pipeline for intra-node CPU-GPU cooperation, and compressed transmission for inter-node communication. Moreover, we integrate architecture specific optimizations, such as Tensor Cores, into ParSecureML. As far as we know, this is the first GPU-based secure machine learning framework. Compared to the state-of-the-art framework, ParSecureML achieves an average of 33.8x speedup. ParSecureML can also be applied to inferences, which achieves 31.7x speedup on average.
C1 [Zhang, Feng; Chen, Zheng; Zhang, Chenyang; Du, Xiaoyong] Renmin Univ China, Key Lab Data Engn & Knowledge Engn MOE, Beijing 100872, Peoples R China.
   [Zhang, Feng; Chen, Zheng; Zhang, Chenyang; Du, Xiaoyong] Renmin Univ China, Sch Informat, Beijing 100872, Peoples R China.
   [Zhou, Amelie Chi] Shenzhen Univ, Guangdong Prov Engn Ctr China Made High Performan, Shenzhen 518061, Peoples R China.
   [Zhai, Jidong] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
RP Du, XY (corresponding author), Renmin Univ China, Key Lab Data Engn & Knowledge Engn MOE, Beijing 100872, Peoples R China.; Du, XY (corresponding author), Renmin Univ China, Sch Informat, Beijing 100872, Peoples R China.; Zhai, JD (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
EM fengzhang@ruc.edu.cn; chenzheng123@ruc.edu.cn; chenyangzhang@ruc.edu.cn;
   chi.zhou@szu.edu.cn; zhaijidong@tsinghua.edu.cn; duyong@ruc.edu.cn
RI Zhang, Feng/X-6906-2019
OI Zhang, Feng/0000-0003-1983-7321; Zhang, Chenyang/0000-0002-7627-6359
FU National R&D Program of China [2020AAA0105200]; National Natural Science
   Foundation of ChinaNational Natural Science Foundation of China (NSFC)
   [U20A20226, 61802412, 61802260, 61972403, 61732014]; Beijing Natural
   Science FoundationBeijing Natural Science Foundation [4202031, L192027];
   Beijing Academy of Artificial Intelligence (BAAI); Tsinghua
   UniversityPeking Union Medical College Hospital Initiative Scientific
   Research Program; Shenzhen Science and Technology Foundation
   [JCYJ20180305125737520]; Tencent "Rhinoceros Birds" project of
   Scientific Research Foundation for Young Teachers of Shenzhen University
FX This work was supported by the National R&D Program of China under Grant
   2020AAA0105200, in part by the National Natural Science Foundation of
   China under Grant U20A20226, Grant 61802412, Grant 61802260, Grant
   61972403, and Grant 61732014, in part by the Beijing Natural Science
   Foundation under Grant 4202031 and Grant L192027, in part by the Beijing
   Academy of Artificial Intelligence (BAAI), and in part by the Tsinghua
   UniversityPeking Union Medical College Hospital Initiative Scientific
   Research Program. The work of Amelie Chi Zhou was also supported by the
   Shenzhen Science and Technology Foundation under Grant
   JCYJ20180305125737520 and a Tencent "Rhinoceros Birds" project of
   Scientific Research Foundation for Young Teachers of Shenzhen
   University.
NR 70
TC 2
Z9 2
U1 4
U2 35
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1045-9219
EI 1558-2183
J9 IEEE T PARALL DISTR
JI IEEE Trans. Parallel Distrib. Syst.
PD SEPT 1
PY 2021
VL 32
IS 9
BP 2262
EP 2276
DI 10.1109/TPDS.2021.3059108
PG 15
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RE9HL
UT WOS:000634461100001
DA 2022-04-17
ER

PT C
AU Tryhuba, A
   Boyarchuk, V
   Try-hub, I
   Ftoma, O
   Padyuka, R
   Rudynets, M
AF Tryhuba, Anatoliy
   Boyarchuk, Vitaliy
   Try-hub, Inna
   Ftoma, Oksana
   Padyuka, Roman
   Rudynets, Mykola
BE Emmerich, M
   Lytvyn, V
   Vysotska, V
   BastoFernandes, V
   Lytvynenko, V
TI Forecasting the Risk of the Resource Demand for Dairy Farms Basing on
   Machine Learning
SO MOMLET+DS 2020: MODERN MACHINE LEARNING TECHNOLOGIES AND DATA SCIENCE
   WORKSHOP
SE CEUR Workshop Proceedings-Series
LA English
DT Proceedings Paper
CT 2nd International Workshop on Modern Machine Learning Technologies and
   Data Science (MoMLeT+DS)
CY JUN 02-03, 2020
CL ELECTR NETWORK
SP Leiden Univ, Leiden Inst Adv Comp Sci, Lviv Polytechn Natl Univ, Montfort Univ, Comp Sci, Univ Inst Lisbon, Kherson Natl Tech Univ, Lesya Ukrainka Eastern European Natl Univ, SoftServe, Lviv IT Cluster, Perfectial, Skelia, Fortifier, Envion Software, PI MINDS, SSA Group, SYTOSS
DE Forecasting; risk; resources; dairy farms; machine learning; model
AB The work supplies analysis of the conditions of use of the intellectual systems of support for managerial decision making in agrarian production. The authors argue the expediency of forecasting the risk of the resource demand for dairy farms on the base of application of machine learning tools. In the article, the authors propose the approach to forecasting the risk of the resource demand for dairy farms, which is based on machine learning and suggests fulfilment of eight stages. The approach peculiarity is that formation of the bases of data and knowledge is completed with consideration of the features of the set project environment. It is argued that computer modeling of the case branch secures system consideration of the variable factors of costs for fodder production and its market price. The proposed approach creates a basis for improvement of quality and accelerated formation of the database for forecasting the resource reserve basing on machine learning. Referring to the developed approach and computer program in the Python language, the authors substantiate a base of knowledge. The knowledge base is represented by the tendencies of a change of the forecasted figures of the risk of the resource demand for dairy farms in the set project environment. The computer modeling is conducted on the example of Zabolottsi amalgamated territorial community in Brody district of Lviv region. The obtained figures of the limits and tendencies of a change of the volume of the reserve of hay, made of perennial herbs, and field area for its growing serve as markers for conducting machine learning with a teacher. The further research should be conducted concerning the choice of a method and development of an algorithm of machine learning for forecasting the risk of the resource demand for dairy farms.
C1 [Tryhuba, Anatoliy; Boyarchuk, Vitaliy; Try-hub, Inna; Ftoma, Oksana; Padyuka, Roman] Lviv Natl Agr Univ, UA-80381 Dubliany, Lviv Region, Ukraine.
   [Rudynets, Mykola] Lutsk Natl Tech Univ, Lvivska Str 75, UA-43018 Lutsk, Ukraine.
RP Tryhuba, A (corresponding author), Lviv Natl Agr Univ, UA-80381 Dubliany, Lviv Region, Ukraine.
EM trianamik@gmail.com; rudinetc@meta.ua
RI Boiarchuk, Oksana/AAY-9308-2021; Tryhuba, Anatoliy/ABD-6623-2021
OI Boiarchuk, Oksana/0000-0003-3165-1669; 
NR 24
TC 1
Z9 1
U1 0
U2 1
PU RWTH AACHEN
PI Aachen
PA Ahornstr. 55, Aachen, *, GERMANY
SN 1613-0073
J9 CEUR WORKSHOP PROCEE
PY 2020
VL 2631
PG 14
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Operations Research & Management Science
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Operations Research & Management Science
GA BR6TX
UT WOS:000664104800025
DA 2022-04-17
ER

PT J
AU Gao, CC
   Min, X
   Fang, MH
   Tao, TY
   Zheng, XH
   Liu, YG
   Wu, XW
   Huang, ZH
AF Gao, Chaochao
   Min, Xin
   Fang, Minghao
   Tao, Tianyi
   Zheng, Xiaohong
   Liu, Yangai
   Wu, Xiaowen
   Huang, Zhaohui
TI Innovative Materials Science via Machine Learning
SO ADVANCED FUNCTIONAL MATERIALS
LA English
DT Review; Early Access
DE data-driven; machine learning; materials discovery; materials science;
   performances prediction; perspective
ID DENSITY-FUNCTIONAL THEORY; NEURAL-NETWORK; DIMENSIONALITY REDUCTION;
   THERMODYNAMIC STABILITY; CRYSTAL-STRUCTURES; DESIGN; PERFORMANCE;
   PREDICTION; DATABASE; SEARCH
AB Nowadays, the research on materials science is rapidly entering a phase of data-driven age. Machine learning, one of the most powerful data-driven methods, have been being applied to materials discovery and performances prediction with undoubtedly tremendous application foreground. Herein, the challenges and current progress of machine learning are summarized in materials science, the design strategies are classified and highlighted, and possible perspectives are proposed for the future development. It is hoped this review can provide important scientific guidance for innovating materials science and technology via machine learning in the future.
C1 [Gao, Chaochao; Min, Xin; Fang, Minghao; Zheng, Xiaohong; Liu, Yangai; Wu, Xiaowen; Huang, Zhaohui] China Univ Geosci Beijing, Sch Mat Sci & Technol, Natl Lab Mineral Mat, Beijing Key Lab Mat Utilizat Nonmetall Minerals &, Beijing 100083, Peoples R China.
   [Tao, Tianyi; Zheng, Xiaohong] Chinese Acad Sci, Inst Proc Engn, Div Environm Technol & Engn, Beijing 100190, Peoples R China.
RP Min, X; Huang, ZH (corresponding author), China Univ Geosci Beijing, Sch Mat Sci & Technol, Natl Lab Mineral Mat, Beijing Key Lab Mat Utilizat Nonmetall Minerals &, Beijing 100083, Peoples R China.
EM minx@cugb.edu.cn; huang118@cugb.edu.cn
FU National Key R&D Program of China [2018YFC1901500]
FX This work was supported by the National Key R&D Program of China (No.
   2018YFC1901500).
NR 186
TC 5
Z9 5
U1 137
U2 142
PU WILEY-V C H VERLAG GMBH
PI WEINHEIM
PA POSTFACH 101161, 69451 WEINHEIM, GERMANY
SN 1616-301X
EI 1616-3028
J9 ADV FUNCT MATER
JI Adv. Funct. Mater.
AR 2108044
DI 10.1002/adfm.202108044
EA OCT 2021
PG 14
WC Chemistry, Multidisciplinary; Chemistry, Physical; Nanoscience &
   Nanotechnology; Materials Science, Multidisciplinary; Physics, Applied;
   Physics, Condensed Matter
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Science & Technology - Other Topics; Materials Science;
   Physics
GA WA6LO
UT WOS:000702995500001
DA 2022-04-17
ER

PT J
AU Dockes, J
   Varoquaux, G
   Poline, JB
AF Dockes, Jerome
   Varoquaux, Gael
   Poline, Jean-Baptiste
TI Preventing dataset shift from breaking machine-learning biomarkers
SO GIGASCIENCE
LA English
DT Review
DE biomarker; machine learning; generalization; dataset shift
ID COVARIATE SHIFT; BIAS; VALIDATION; INFERENCE; SPECTRUM; SEX
AB Machine learning brings the hope of finding new biomarkers extracted from cohorts with rich biomedical measurements. A good biomarker is one that gives reliable detection of the corresponding condition. However, biomarkers are often extracted from a cohort that differs from the target population. Such a mismatch, known as a dataset shift, can undermine the application of the biomarker to new individuals. Dataset shifts are frequent in biomedical research, e.g., because of recruitment biases. When a dataset shift occurs, standard machine-learning techniques do not suffice to extract and validate biomarkers. This article provides an overview of when and how dataset shifts break machine-learning-extracted biomarkers, as well as detection and correction strategies.
C1 [Dockes, Jerome; Varoquaux, Gael; Poline, Jean-Baptiste] McGill Univ, 845 Sherbrooke St W, Montreal, PQ H3A 0G4, Canada.
   [Varoquaux, Gael] INRIA, Rocquencourt, France.
RP Dockes, J (corresponding author), McGill Univ, Neuro Montreal Neurol Inst Hosp, Fac Med & Hlth Sci, NeuroDataSci ORIGAMI Lab,McConnell Brain Imaging, 845 Sherbrooke St W, Montreal, PQ H3A 0G4, Canada.
EM jerome@dockes.org
FU National Institutes of Health (NIH)United States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USA [NIH-NIBIB P41
   EB019936, NIH-NIMH R01 MH083320, NIH RF1 MH120021]; National Institute
   Of Mental HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   of Mental Health (NIMH) [R01MH096906]; Canada First Research Excellence
   Fund; Brain Canada Foundation; Montreal Neurological Institute; Agence
   Nationale de la RechercheFrench National Research Agency (ANR)European
   Commission [ANR-17-CE23-0018]
FX This work was partially funded by the National Institutes of Health
   (NIH) NIH-NIBIB P41 EB019936 (ReproNim) NIH-NIMH R01 MH083320
   (CANDIShare) and NIH RF1 MH120021 (NIDM), the National Institute Of
   Mental Health under Award Number R01MH096906 (Neurosynth), the Canada
   First Research Excellence Fund, awarded to McGill University for the
   Healthy Brains for Healthy Lives initiative and the Brain Canada
   Foundation with support from Health Canada, Health Canada, through the
   Canada Brain Research Fund in partnership with the Montreal Neurological
   Institute. This work made used of the NeuroHub platform.This work was
   funded by Agence Nationale de la Recherche project DirtyData
   -ANR-17-CE23-0018
NR 80
TC 1
Z9 1
U1 4
U2 4
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 2047-217X
J9 GIGASCIENCE
JI GigaScience
PD SEP
PY 2021
VL 10
IS 9
AR giab055
DI 10.1093/gigascience/giab055
EA SEP 2021
PG 11
WC Biology; Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Science & Technology - Other
   Topics
GA WI7DK
UT WOS:000708517600002
PM 34585237
OA Green Published, gold, Green Submitted
DA 2022-04-17
ER

PT C
AU Abirami, RN
   Vincent, PMDR
AF Abirami, R. Nandhini
   Vincent, P. M. Durai Raj
BE Das, KN
   Bansal, JC
   Deep, K
   Nagar, AK
   Pathipooranam, P
   Naidu, RC
TI Cardiac Arrhythmia Detection Using Ensemble of Machine Learning
   Algorithms
SO SOFT COMPUTING FOR PROBLEM SOLVING, SOCPROS 2018, VOL 2
SE Advances in Intelligent Systems and Computing
LA English
DT Proceedings Paper
CT 8th International Conference on Soft Computing for Problem Solving
   (SocProS)
CY DEC 17-19, 2018
CL Vellore Inst Technol, Vellore, INDIA
HO Vellore Inst Technol
DE Electrocardiogram; Machine learning; Cardiac arrhythmia and
   classification
AB An ECG signal is a bioelectrical signal which records the electrical activity of the heart. ECG signals are used as the parameter for detecting various heart diseases. Cardiac arrhythmia can be detected using ECG signals. Arrhythmia is a condition in which the rhythm of the heart is irregular, too slow or too fast. The data for this work is obtained from the University of California, Irvine machine learning repository. The data obtained from the repository is preprocessed. Feature selection is made, and machine learning models are applied to the preprocessed data. Finally, data is classified into two classes, namely normal and arrhythmia. Feature selections were made to optimize the performance of machine learning algorithms. Features with more number of missing values and which showed no variation for all the instances have been deleted. Accuracy achieved using ensemble of machine learning algorithms is 85%. The objective of this research is to design a robust machine learning algorithm to predict cardiac arrhythmia. The prediction of cardiac arrhythmia is performed using ensemble of machine learning algorithms. This is to boost the accuracy achieved by individual machine learning algorithms. The technique of combining two or more machine learning models to improve the accuracy of the results is called ensemble prediction. More accurate results can be achieved using ensemble methods than the results achieved using single machine learning model.
C1 [Abirami, R. Nandhini; Vincent, P. M. Durai Raj] Vellore Inst Technol, Vellore, Tamil Nadu, India.
RP Abirami, RN (corresponding author), Vellore Inst Technol, Vellore, Tamil Nadu, India.
EM nandhini.raj25@gmail.com
RI Vincent, P.M. Durai Raj/S-6371-2019
OI Vincent, P.M. Durai Raj/0000-0002-7598-1363; R, Nandhini
   Abirami/0000-0001-8610-9629
NR 18
TC 1
Z9 1
U1 3
U2 4
PU SPRINGER-VERLAG SINGAPORE PTE LTD
PI SINGAPORE
PA 152 BEACH ROAD, #21-01/04 GATEWAY EAST, SINGAPORE, 189721, SINGAPORE
SN 2194-5357
EI 2194-5365
BN 978-981-15-0184-5; 978-981-15-0183-8
J9 ADV INTELL SYST
PY 2020
VL 1057
BP 475
EP 487
DI 10.1007/978-981-15-0184-5_41
PG 13
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR1ES
UT WOS:000631850100041
DA 2022-04-17
ER

PT C
AU Ndou, N
   Ajoodha, R
   Jadhav, A
AF Ndou, Ndiatenda
   Ajoodha, Ritesh
   Jadhav, Ashwini
BE Chakrabarti, S
   Paul, R
   Gill, B
   Gangopadhyay, M
   Poddar, S
TI Music Genre Classification: A Review of Deep-Learning and Traditional
   Machine-Learning Approaches
SO 2021 IEEE INTERNATIONAL IOT, ELECTRONICS AND MECHATRONICS CONFERENCE
   (IEMTRONICS)
LA English
DT Proceedings Paper
CT IEEE International IOT, Electronics and Mechatronics Conference
   (IEMTRONICS)
CY APR 21-24, 2021
CL ELECTR NETWORK
SP IEEE, Inst Engn & Management, IEEE Vancouver Sect, IEEE Toronto Sect, SMART, Univ Engn & Management
DE machine-learning; deep-learning; music genre classification; CNN; MFCC
AB This research provides a comparative study of the genre classification performance of deep-learning and traditional machine-learning models. Furthermore, we investigate the performance of machine-learning models implemented on three-second duration features, to that of those implemented on thirty-seconds duration features.
   We present the categories of features utilized for automatic genre classification and implement Information Gain Ranking algorithm to determine the features most contributing to the correct classification of a music piece. Machine-learning models and Convolutional Neural Network (CNN) were then trained and tested on ten GTZAN dataset genres. The k-Nearest Neighbours (kNN) provided the best classification accuracy at 92.69% on three-seconds duration input features.
C1 [Ndou, Ndiatenda; Ajoodha, Ritesh] Univ Witwatersrand, Sch Comp Sci & Appl Math, Johannesburg, South Africa.
   [Jadhav, Ashwini] Univ Witwatersrand, Fac Sci, Johannesburg, South Africa.
RP Ndou, N (corresponding author), Univ Witwatersrand, Sch Comp Sci & Appl Math, Johannesburg, South Africa.
EM ndiatenda.ndou@students.wits.ac.za; ritesh.ajoodha@wits.ac.za;
   ashwini.jadhav@wits.ac.za
OI Ajoodha, Dr. Ritesh/0000-0002-6443-8592
FU National Research Foundation of South AfricaNational Research Foundation
   - South Africa [121835]
FX This work is based on the research supported in part by the National
   Research Foundation of South Africa (Grant number: 121835).
NR 21
TC 0
Z9 0
U1 4
U2 4
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-6654-4067-7
PY 2021
BP 581
EP 586
DI 10.1109/IEMTRONICS52119.2021.9422487
PG 6
WC Engineering, Electrical & Electronic; Engineering, Mechanical;
   Operations Research & Management Science
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering; Operations Research & Management Science
GA BR9HG
UT WOS:000675601600095
DA 2022-04-17
ER

PT J
AU Ramos, G
   Meek, C
   Simard, P
   Suh, J
   Ghorashi, S
AF Ramos, Gonzalo
   Meek, Christopher
   Simard, Patrice
   Suh, Jina
   Ghorashi, Soroush
TI Interactive machine teaching: a human-centered approach to building
   machine-learned models
SO HUMAN-COMPUTER INTERACTION
LA English
DT Article
DE Intelligent UI; user programming; interaction; industrial design;
   interactive machine learning
ID DECISION-MAKING
AB Modern systems can augment people's capabilities by using machine-learned models to surface intelligent behaviors. Unfortunately, building these models remains challenging and beyond the reach of non-machine learning experts. We describe interactive machine teaching (IMT) and its potential to simplify the creation of machine-learned models. One of the key characteristics of IMT is its iterative process in which the human-in-the-loop takes the role of a teacher teaching a machine how to perform a task. We explore alternative learning theories as potential theoretical foundations for IMT, the intrinsic human capabilities related to teaching, and how IMT systems might leverage them. We argue that IMT processes that enable people to leverage these capabilities have a variety of benefits, including making machine learning methods accessible to subject-matter experts and the creation of semantic and debuggable machine learning (ML) models. We present an integrated teaching environment (ITE) that embodies principles from IMT, and use it as a design probe to observe how non-ML experts do IMT and as the basis of a system that helps us study how to guide teachers. We explore and highlight the benefits and challenges of IMT systems. We conclude by outlining six research challenges to advance the field of IMT.
C1 [Ramos, Gonzalo; Meek, Christopher; Suh, Jina] Microsoft Res, Redmond, WA USA.
   [Simard, Patrice; Ghorashi, Soroush] Microsoft, Redmond, WA USA.
RP Ramos, G (corresponding author), 10809 NE 45th St, Kirkland, WA 98033 USA.
EM gonzo.ramos@gmail.com; meek@microsoft.com; patrice@microsoft.com;
   jinsuh@microsoft.com; sorgh@microsoft.com
NR 90
TC 10
Z9 10
U1 6
U2 19
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0737-0024
EI 1532-7051
J9 HUM-COMPUT INTERACT
JI Hum.-Comput. Interact.
PD NOV 1
PY 2020
VL 35
IS 5-6
BP 413
EP 451
DI 10.1080/07370024.2020.1734931
EA MAY 2020
PG 39
WC Computer Science, Cybernetics; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NF1QA
UT WOS:000532109400001
DA 2022-04-17
ER

PT J
AU Mouchtaris, D
   Sofianos, E
   Gogas, P
   Papadimitriou, T
AF Mouchtaris, Dimitrios
   Sofianos, Emmanouil
   Gogas, Periklis
   Papadimitriou, Theophilos
TI Forecasting Natural Gas Spot Prices with Machine Learning
SO ENERGIES
LA English
DT Article
DE natural gas; spot price; machine learning; forecasting
AB The ability to accurately forecast the spot price of natural gas benefits stakeholders and is a valuable tool for all market participants in the competitive gas market. In this paper, we attempt to forecast the natural gas spot price 1, 3, 5, and 10 days ahead using machine learning methods: support vector machines (SVM), regression trees, linear regression, Gaussian process regression (GPR), and ensemble of trees. These models are trained with a set of 21 explanatory variables in a 5-fold cross-validation scheme with 90% of the dataset used for training and the remaining 10% used for testing the out-of-sample generalization ability. The results show that these machine learning methods all have different forecasting accuracy for every time frame when it comes to forecasting natural gas spot prices. However, the bagged trees (belonging to the ensemble of trees method) and the linear SVM models have superior forecasting performance compared to the rest of the models.
C1 [Mouchtaris, Dimitrios] Aristotle Univ Thessaloniki, Fac Sci, Thessaloniki 54124, Greece.
   [Sofianos, Emmanouil; Gogas, Periklis; Papadimitriou, Theophilos] Democritus Univ Thrace, Dept Econ, Komotini 69100, Greece.
RP Sofianos, E (corresponding author), Democritus Univ Thrace, Dept Econ, Komotini 69100, Greece.
EM dimmoucht@gmail.com; esofiano@econ.duth.gr; pgkogkas@econ.duth.gr;
   papadimi@econ.duth.gr
RI Sofianos, Emmanouil/AAD-8300-2020; Gogas, Periklis/N-8162-2014
OI Sofianos, Emmanouil/0000-0001-8820-6529; Gogas,
   Periklis/0000-0002-5134-3869
FU European Union (European Social Fund-ESF)European Social Fund
   (ESF)European Commission [MIS-5000432]
FX This research is co-financed by Greece and the European Union (European
   Social FundESF) through the Operational Programme "Human Resources
   Development, Education and Lifelong Learning" in the context of the
   project "Strengthening Human Resources Research Potential via Doctorate
   Research" (MIS-5000432), implemented by the State Scholarships
   Foundation (IK gamma ).
NR 18
TC 0
Z9 0
U1 11
U2 13
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1996-1073
J9 ENERGIES
JI Energies
PD SEP
PY 2021
VL 14
IS 18
AR 5782
DI 10.3390/en14185782
PG 13
WC Energy & Fuels
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Energy & Fuels
GA UW5VI
UT WOS:000700222800001
OA gold
DA 2022-04-17
ER

PT C
AU Ahmed, MS
   Ishikawa, F
   Sugiyama, M
AF Ahmed, Md Sohel
   Ishikawa, Fuyuki
   Sugiyama, Mahito
BE Devanbu, P
   Cohen, M
   Zimmermann, T
TI Testing Machine Learning Code using Polyhedral Region
SO PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE
   ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE
   ENGINEERING (ESEC/FSE '20)
LA English
DT Proceedings Paper
CT 28th ACM Joint Meeting on European Software Engineering Conference and
   Symposium on the Foundations of Software Engineering (ESEC/FSE)
CY NOV 08-13, 2020
CL ELECTR NETWORK
SP Assoc Comp Machinery, ACM SIGSOFT
DE Machine learning code; Testing; Mutation Analysis; Polyhedral region;
   Lasso
ID SELECTION
AB To date, although machine learning has been successful in various practical applications, generic methods of testing machine learning code have not been established yet. Here we present a new approach to test machine learning code using the possible input region obtained as a polyhedron. If an ML system generates different output for multiple input in the polyhedron, it is ensured that there exists a bug in the code. This property is known as one of theoretical fundamentals in statistical inference, for example, sparse regression models such as the lasso, and a wide range of machine learning algorithms satisfy this polyhedral condition, to which our testing procedure can be applied. We empirically show that the existence of bugs in lasso code can be effectively detected by our method in the mutation testing framework.
C1 [Ahmed, Md Sohel; Ishikawa, Fuyuki; Sugiyama, Mahito] Natl Inst Informat, Tokyo, Japan.
RP Ahmed, MS (corresponding author), Natl Inst Informat, Tokyo, Japan.
EM sohel@nii.ac.jp; f-ishikawa@nii.ac.jp; mahito@nii.ac.jp
FU JST MIRAI Grant [JPMJMI18BB]; Council for Science, Technology and
   Innovation (CSTI), Cross-ministerial Strategic Innovation Promotion
   Program (SIP), "Materials Integration for revolutionary design system of
   structural materials" (Funding agency: JST); JST, PRESTO, Japan
   [JPMJPR1855]
FX This work was supported by JST MIRAI Grant No. JPMJMI18BB; Council for
   Science, Technology and Innovation (CSTI), Crossministerial Strategic
   Innovation Promotion Program (SIP), "Materials Integration for
   revolutionary design system of structural materials" (Funding agency:
   JST; SA and MS); and JST, PRESTO Grant No. JPMJPR1855, Japan (MS).
NR 21
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-7043-1
PY 2020
BP 1533
EP 1536
DI 10.1145/3368089.3417043
PG 4
WC Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS5YR
UT WOS:000744432100132
OA Bronze
DA 2022-04-17
ER

PT J
AU Kwon, B
   Ejaz, F
   Hwang, LK
AF Kwon, Beomjin
   Ejaz, Faizan
   Hwang, Leslie K.
TI Machine learning for heat transfer correlations
SO INTERNATIONAL COMMUNICATIONS IN HEAT AND MASS TRANSFER
LA English
DT Article
DE Heat transfer correlation; Machine learning; Random forests; Variable
   rib roughness
ID FLOW
AB This paper explores machine learning approach as a heat transfer correlation. Machine learning significantly reduces the effort to develop multi-variable heat transfer correlations, and is capable of readily expanding the parameter domain. Random forests algorithm is used to predict the convection heat transfer coefficients for a high-order nonlinear heat transfer problem, i.e., convection in a cooling channel integrated with variable rib roughness. For 243 different rib array geometries, numerical simulations are performed to train and test ML model based on six input features. Machine learning model predicts closely to numerical simulation data with high determination of coefficient (R-2), e.g., R-2 > 0.966 for the testing dataset. The capability and limitation of random forests algorithm are discussed with validation dataset.
C1 [Kwon, Beomjin; Ejaz, Faizan] Arizona State Univ, Sch Engn Matter Transport & Energy, Tempe, AZ 85287 USA.
RP Kwon, B (corresponding author), Arizona State Univ, Sch Engn Matter Transport & Energy, Tempe, AZ 85287 USA.
EM kwon@asu.edu
NR 22
TC 12
Z9 12
U1 12
U2 24
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0735-1933
EI 1879-0178
J9 INT COMMUN HEAT MASS
JI Int. Commun. Heat Mass Transf.
PD JUL
PY 2020
VL 116
AR 104694
DI 10.1016/j.icheatmasstransfer.2020.104694
PG 5
WC Thermodynamics; Mechanics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Thermodynamics; Mechanics
GA MO6KI
UT WOS:000551631900057
DA 2022-04-17
ER

PT J
AU Gao, KF
   Mei, G
   Piccialli, F
   Cuomo, S
   Tu, JZ
   Huo, ZN
AF Gao, Kaifeng
   Mei, Gang
   Piccialli, Francesco
   Cuomo, Salvatore
   Tu, Jingzhi
   Huo, Zenan
TI Julia language in machine learning: Algorithms, applications, and open
   issues
SO COMPUTER SCIENCE REVIEW
LA English
DT Review
DE Julia language; Machine learning; Supervised learning; Unsupervised
   learning; Deep learning; Artificial neural networks
ID COMPUTER VISION; OBJECT DETECTION; THINGS IOT; INTERNET; MODEL; ICA;
   EXTRACTION; TOOLBOX; IMAGERY; TRENDS
AB Machine learning is driving development across many fields in science and engineering. A simple and efficient programming language could accelerate applications of machine learning in various fields. Currently, the programming languages most commonly used to develop machine learning algorithms include Python, MATLAB, and C/C ++. However, none of these languages well balance both efficiency and simplicity. The Julia language is a fast, easy-to-use, and open-source programming language that was originally designed for high-performance computing, which can well balance the efficiency and simplicity. This paper summarizes the related research work and developments in the applications of the Julia language in machine learning. It first surveys the popular machine learning algorithms that are developed in the Julia language. Then, it investigates applications of the machine learning algorithms implemented with the Julia language. Finally, it discusses the open issues and the potential future directions that arise in the use of the Julia language in machine learning. (c) 2020 The Authors. Published by Elsevier Inc.
C1 [Gao, Kaifeng; Mei, Gang; Tu, Jingzhi; Huo, Zenan] China Univ Geosci Beijing, Sch Engn & Technol, Beijing 100083, Peoples R China.
   [Piccialli, Francesco; Cuomo, Salvatore] Univ Naples Federico II, Dept Math & Applicat R Caccioppoli, Naples, Italy.
RP Mei, G (corresponding author), China Univ Geosci Beijing, Sch Engn & Technol, Beijing 100083, Peoples R China.; Piccialli, F; Cuomo, S (corresponding author), Univ Naples Federico II, Dept Math & Applicat R Caccioppoli, Naples, Italy.
EM gang.mei@cugb.edu.cn; francesco.piccialli@unina.it;
   salvatore.cuomo@unina.it
RI Piccialli, Francesco/ABC-2457-2020; Mei, Gang/C-9124-2016; Cuomo,
   Salvatore/Q-1365-2016
OI Piccialli, Francesco/0000-0002-5179-2496; Mei, Gang/0000-0003-0026-5423;
   Cuomo, Salvatore/0000-0003-4128-2588; Huo, Zenan/0000-0003-3750-1709
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [11602235]; Fundamental Research Funds for
   China Central Universities [2652018091]; Major Project for Science and
   Technology [2020AA002]
FX This research was jointly supported by the National Natural Science
   Foundation of China (11602235), the Fundamental Research Funds for China
   Central Universities (2652018091), and the Major Project for Science and
   Technology (2020AA002). The authors would like to thank the editor and
   the reviewers for their valuable comments.
NR 115
TC 8
Z9 8
U1 10
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1574-0137
EI 1876-7745
J9 COMPUT SCI REV
JI Comput. Sci. Rev.
PD AUG
PY 2020
VL 37
AR 100254
DI 10.1016/j.cosrev.2020.100254
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NA4JD
UT WOS:000559782300004
OA Green Submitted, hybrid
DA 2022-04-17
ER

PT C
AU Xie, WT
   Wu, P
AF Xie, Wentao
   Wu, Peng
BE Wang, GJ
   Ko, R
   Bhuiyan, MZA
   Pan, Y
TI Fairness Testing of Machine Learning Models Using Deep Reinforcement
   Learning
SO 2020 IEEE 19TH INTERNATIONAL CONFERENCE ON TRUST, SECURITY AND PRIVACY
   IN COMPUTING AND COMMUNICATIONS (TRUSTCOM 2020)
SE IEEE International Conference on Trust Security and Privacy in Computing
   and Communications
LA English
DT Proceedings Paper
CT 19th IEEE International Conference on Trust, Security and Privacy in
   Computing and Communications (IEEE TrustCom)
CY DEC 29-JAN 01, 2020-2021
CL Guangzhou, PEOPLES R CHINA
SP IEEE, IEEE Comp Soc
DE fairness testing; black-box testing; deep reinforcement learning; test
   data generation; machine learning models
AB Machine learning models play an important role for decision-making systems in areas such as hiring, insurance, and predictive policing. However, it still remains a challenge to guarantee their trustworthiness. Fairness is one of the most critical properties of these machine learning models, while individual discriminatory cases may break the trustworthiness of these systems severely. In this paper, we present a systematic approach of testing the fairness of a machine learning model, with individual discriminatory inputs generated automatically in an adaptive manner based on the state-of-the-art deep reinforcement learning techniques. Our approach can explore and exploit the input space efficiently, and find more individual discriminatory inputs within less time consumption. Case studies with typical benchmark models demonstrate the effectiveness and efficiency of our approach, compared to the state-of-the-art black-box fairness testing approaches.
C1 [Wu, Peng] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China.
   [Xie, Wentao; Wu, Peng] Univ Chinese Acad Sci, Beijing, Peoples R China.
RP Wu, P (corresponding author), Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China.; Wu, P (corresponding author), Univ Chinese Acad Sci, Beijing, Peoples R China.
EM xiewt@ios.ac.cn; wp@ios.ac.cn
FU National Key R&D Program of China [2017YFB0801900, GJHZ1844]
FX We thank the anonymous referees for their valuable comments. This work
   is partially supported by the National Key R&D Program of China under
   the Grant No. 2017YFB0801900, and the CAS-INRIA Joint Research Program
   under the Grant No. GJHZ1844.
NR 30
TC 0
Z9 0
U1 3
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
SN 2324-898X
BN 978-1-6654-0392-4
J9 IEEE INT CONF TRUST
PY 2020
BP 121
EP 128
DI 10.1109/TrustCom50675.2020.00029
PG 8
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Theory & Methods; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Telecommunications
GA BR8DU
UT WOS:000671077600015
DA 2022-04-17
ER

PT J
AU Tosun, O
   Eryigit, R
AF Tosun, Olcay
   Eryigit, Recep
TI Improved online sequential extreme learning machine: OS-CELM
SO TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES
LA English
DT Article
DE Machine learning; extreme learning machine (ELM); constrained extreme
   learning machine (CELM); online sequential CELM (OS-CELM)
ID CLASSIFICATION; ALGORITHM; ELM
AB Online learning methods (OLM) have been gaining traction as a solution to classification problems because of rapid renewal and fast growth in volume of available data. ELM-based sequential learning (OS-ELM) is one of the most frequently used online learning methodologies partly due to fast training algorithm but suffers from inefficient use of its hidden layers due to the random assignment of the parameters of those layers. In this study, we propose an improved online learning model called online sequential constrained extreme learning machine (OS-CELM), which replaces the random assignment of those parameters with better generalization performance using the CELM method based on the distance between classes. We compare the performance and training times of OS-ELM, ELM, and the proposed models for four different data sets. The results indicate that the proposed model has better generalization and accuracy performance.
C1 [Tosun, Olcay; Eryigit, Recep] Ankara Univ, Dept Comp Engn, Ankara, Turkey.
RP Tosun, O (corresponding author), Ankara Univ, Dept Comp Engn, Ankara, Turkey.
EM olcaytosun@gmail.com
OI Eryigit, Recep/0000-0002-4282-6340
NR 29
TC 0
Z9 0
U1 6
U2 6
PU TUBITAK SCIENTIFIC & TECHNICAL RESEARCH COUNCIL TURKEY
PI ANKARA
PA ATATURK BULVARI NO 221, KAVAKLIDERE, ANKARA, 00000, TURKEY
SN 1300-0632
EI 1303-6203
J9 TURK J ELECTR ENG CO
JI Turk. J. Electr. Eng. Comput. Sci.
PY 2021
VL 29
IS 7
BP 3092
EP 3106
DI 10.3906/elk-2103-122
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XH2JW
UT WOS:000725268200007
OA Bronze
DA 2022-04-17
ER

PT J
AU Wang, CZ
   Kong, LW
   Jiang, JJ
   Lai, YC
AF Wang, Cheng-Zhen
   Kong, Ling-Wei
   Jiang, Junjie
   Lai, Ying-Cheng
TI Machine learning-based approach to GPS antijamming
SO GPS SOLUTIONS
LA English
DT Article
DE GPS; Antijamming; Machine learning; Reservoir computing
ID DEEP NEURAL-NETWORKS; CHAOTIC SYSTEMS
AB A challenging and outstanding problem in applications that involve or rely on GPS signals is to mitigate jamming. We develop a machine learning-based antijamming framework for GPS signals. Three types of jamming signals are considered: continuous wave interference, chirp and pulse jamming. In addition, white Gaussian noise is assumed to be present. From the point of view of communication, information is encoded in the coarse/acquisition (C/A) code. Multiplying the jammed signal by a sinusoidal wave and integrating over one C/A code period leads to a jammed C/A code signal. To mitigate jamming, we study three types of machine learning methods: reservoir computing (echo state network), multi-layer perceptron, and long short-term memory networks (RNNs). A machine can be trained to learn and predict the signal directly or learn and predict jamming where the real signal can be obtained by removing the jammed component from the total received signal. For a high-frequency carrier (e.g., the standard 1575.42 MHz L1 carrier), learning and prediction can be made computationally efficiently on the C/A code signal. The main result is that machine learning can be effective for predicting and extracting weak GPS signals even in a strongly jammed/noisy environment where the jamming amplitude is three orders of magnitude stronger than the GPS signal. We find that the reservoir computing scheme is stable and performs well for all three types of jamming. The multi-layer perceptron is better for predicting the jamming signal than the GPS signal itself, and the long short-term memory networks work well but only for certain jamming types. In particular, with the direct signal prediction method, the bit error rate (BER) associated with reservoir computing (RC) remains at near-zero values (less than 1%) even for jamming signal ratio (JSR) up to 60 dB for the three types of jamming. The multi-layer perceptron (MLP) method breaks down when the JSR is larger than 20 dB for continuous wave interference (CWI) and pulse jamming, 45 dB for chirp jamming. The long short-term memory (LSTM) can perform very well for the chirp jamming with a near zero error rate and give BER larger than 10% when the JSR is around 40 dB for the CWI and pulse jamming. For the jamming prediction method (indirect method), these three machine learning methods perform well, with near-zero BER (less than 1%). Overall, the RC scheme is stable and performs well for three types of jamming. Besides, RC is fast compared to LSTM method, with much less running time.
C1 [Wang, Cheng-Zhen; Kong, Ling-Wei; Jiang, Junjie; Lai, Ying-Cheng] Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85287 USA.
   [Lai, Ying-Cheng] Arizona State Univ, Dept Phys, Tempe, AZ 85287 USA.
RP Lai, YC (corresponding author), Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85287 USA.; Lai, YC (corresponding author), Arizona State Univ, Dept Phys, Tempe, AZ 85287 USA.
EM Ying-Cheng.Lai@asu.edu
RI Jiang, Junjie/AAI-2214-2019
OI Lai, Ying-Cheng/0000-0002-0723-733X; Kong, Ling-Wei/0000-0002-8921-1642;
   Wang, Cheng-Zhen/0000-0002-1383-2354; Jiang, Junjie/0000-0003-2930-7770
FU Vannevar Bush Faculty Fellowship program - Basic Research Office of the
   Assistant Secretary of Defense for Research and Engineering; Office of
   Naval ResearchOffice of Naval Research [N00014-16-1-2828]
FX We thank Dr. Arje Nachman from Air Force Office of Scientific Research
   for motivating us to study the problem of GPS antijamming. This work was
   supported by the Vannevar Bush Faculty Fellowship program sponsored by
   the Basic Research Office of the Assistant Secretary of Defense for
   Research and Engineering and funded by the Office of Naval Research
   through Grant No. N00014-16-1-2828.
NR 32
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1080-5370
EI 1521-1886
J9 GPS SOLUT
JI GPS Solut.
PD JUL
PY 2021
VL 25
IS 3
AR 115
DI 10.1007/s10291-021-01154-7
PG 12
WC Remote Sensing
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Remote Sensing
GA SV0LD
UT WOS:000663518200001
DA 2022-04-17
ER

PT C
AU Price, SR
   Young, CH
   Maschmann, MR
   Price, SR
AF Price, Stanton R.
   Young, Christina H.
   Maschmann, Matthew R.
   Price, Steven R.
GP IEEE
TI Aiding Material Design Through Machine Learning
SO 2020 IEEE APPLIED IMAGERY PATTERN RECOGNITION WORKSHOP (AIPR): TRUSTED
   COMPUTING, PRIVACY, AND SECURING MULTIMEDIA
SE IEEE Applied Imagery Pattern Recognition Workshop
LA English
DT Proceedings Paper
CT IEEE Applied Imagery Pattern Recognition Workshop (AIPR)
CY OCT 13-15, 2020
CL ELECTR NETWORK
SP IEEE
DE genetic algorithms; machine learning; material design and discovery;
   neural networks
AB Machine learning is a field that has been around for decades whose impact and presence continues to increase across scientific and commercial communities. However, until recently, machine learning has not been thought of as a viable methodology that could significantly aid novel material discovery and design. That is, machine learning-aided material design and/or discovery is an emerging research topic, but one that holds immense potential. Such a system could, theoretically, be used to discover novel materials or surfaces that possess desirable properties across the electromagnetic spectrum under specific conditions. Herein, we present our preliminary machine learning-based framework for novel material design and discovery. We emphasize that our proposed framework is in its infancy; however, it is laying the foundation for the discovery of fundamental theories and knowledge for this novel technology. Baseline elementary experiments are presented as a proof-of-concept to show the feasibility of our proposed framework for the task of material design. Specifically, we put forth a multi-stage machine learning framework for new material discovery considering material surface geometries for predicting object signatures in the X band. Our proposed multi-stage framework is structured as follows: 1) a deep neural network (NN) is trained for predicting the time response scattered from an object based upon surface geometries (micro-feature spacing, height, etc.); and 2) a genetic algorithm is used to search for the optimal surface geometry configuration whose predicted scattered response (closely) matches that of a desired object response in the X band.
C1 [Price, Stanton R.; Young, Christina H.] US Army Engineer Res & Dev Ctr, Vicksburg, MS 39180 USA.
   [Maschmann, Matthew R.] Univ Missouri, Mech & Aerosp Engn Dept, Columbia, MO 65211 USA.
   [Price, Steven R.] Mississippi Coll, Dept Elect Engn, Clinton, MS 39056 USA.
RP Price, SR (corresponding author), US Army Engineer Res & Dev Ctr, Vicksburg, MS 39180 USA.
RI Maschmann, Matthew/AAT-8047-2021
OI Maschmann, Matthew/0000-0002-0740-6228
FU US Army Engineer Research and Development CenterUnited States Department
   of Defense
FX This work was funded and managed by the US Army Engineer Research and
   Development Center. Permission was granted by the Director of the
   Geotechnical and Structures Laboratory to publish this information.
   Distribution Statement A: Approved for public release; distribution is
   unlimited.
NR 11
TC 0
Z9 0
U1 2
U2 3
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1550-5219
BN 978-1-7281-8243-8
J9 IEEE APP IMG PAT
PY 2020
DI 10.1109/AIPR50011.2020.9425116
PG 5
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Imaging Science & Photographic Technology
GA BR9HA
UT WOS:000675595400015
DA 2022-04-17
ER

PT J
AU Kato, N
   Mao, BM
   Tang, FX
   Kawamoto, Y
   Liu, JJ
AF Kato, Nei
   Mao, Bomin
   Tang, Fengxiao
   Kawamoto, Yuichi
   Liu, Jiajia
TI Ten Challenges in Advancing Machine Learning Technologies toward 6G
SO IEEE WIRELESS COMMUNICATIONS
LA English
DT Article
DE Machine learning; 5G mobile communication; Machine learning algorithms;
   Measurement; Security; Physical layer
ID DEEP; RECOGNITION
AB As the 5G standard is being completed, academia and industry have begun to consider a more developed cellular communication technique, 6G, which is expected to achieve high data rates up to 1 Tb/s and broad frequency bands of 100 GHz to 3 THz. Besides the significant upgrade of the key communication metrics, Artificial Intelligence (AI) has been envisioned by many researchers as the most important feature of 6G, since the state-of-the-art machine learning technique has been adopted as the top solution in many extremely complex scenarios. Network intelligentization will be the new trend to address the challenges of exponentially increasing number of connected heterogeneous devices. However, compared with the application of machine learning in other fields, such as computer games, current research on intelligent networking still has a long way to go to realize the automatically- configured cellular communication systems. Various problems in terms of communication system, machine learning architectures, and computation efficiency should be addressed for the full use of this technique in 6G. In this paper, we analyze machine learning techniques and introduce 10 most critical challenges in advancing the intelligent 6G system.
C1 [Kato, Nei; Mao, Bomin; Tang, Fengxiao; Kawamoto, Yuichi] Tohoku Univ, Grad Sch Informat Sci, Sendai, Miyagi, Japan.
   [Liu, Jiajia] Northwestern Polytech Univ, Sch Cybersecur, Xian, Peoples R China.
RP Kato, N (corresponding author), Tohoku Univ, Grad Sch Informat Sci, Sendai, Miyagi, Japan.
RI Tang, Fengxiao/ABD-9673-2021; KATO, NEI/T-5892-2019; tang,
   fengxiao/T-5881-2019
OI KATO, NEI/0000-0001-8769-302X; tang, fengxiao/0000-0003-2414-4802; Mao,
   Bomin/0000-0001-7780-5972
NR 14
TC 76
Z9 76
U1 24
U2 73
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1536-1284
EI 1558-0687
J9 IEEE WIREL COMMUN
JI IEEE Wirel. Commun.
PD JUN
PY 2020
VL 27
IS 3
BP 96
EP 103
DI 10.1109/MWC.001.1900476
PG 8
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Engineering, Electrical & Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA MC0CC
UT WOS:000542963900016
HC Y
HP N
DA 2022-04-17
ER

PT J
AU Scantamburlo, T
AF Scantamburlo, Teresa
TI Non-empirical problems in fair machine learning
SO ETHICS AND INFORMATION TECHNOLOGY
LA English
DT Article
DE Machine learning; Fairness; Empirical approach; Assessment of machine
   learning
ID PREDICTION
AB The problem of fair machine learning has drawn much attention over the last few years and the bulk of offered solutions are, in principle, empirical. However, algorithmic fairness also raises important conceptual issues that would fail to be addressed if one relies entirely on empirical considerations. Herein, I will argue that the current debate has developed an empirical framework that has brought important contributions to the development of algorithmic decision-making, such as new techniques to discover and prevent discrimination, additional assessment criteria, and analyses of the interaction between fairness and predictive accuracy. However, the same framework has also suggested higher-order issues regarding the translation of fairness into metrics and quantifiable trade-offs. Although the (empirical) tools which have been developed so far are essential to address discrimination encoded in data and algorithms, their integration into society elicits key (conceptual) questions such as: What kind of assumptions and decisions underlies the empirical framework? How do the results of the empirical approach penetrate public debate? What kind of reflection and deliberation should stakeholders have over available fairness metrics? I will outline the empirical approach to fair machine learning, i.e. how the problem is framed and addressed, and suggest that there are important non-empirical issues that should be tackled. While this work will focus on the problem of algorithmic fairness, the lesson can extend to other conceptual problems in the analysis of algorithmic decision-making such as privacy and explainability.
C1 [Scantamburlo, Teresa] Ca Foscari Univ Venice, European Ctr Living Technol, Dorsoduro 3911,Calle Crosera, I-30123 Venice, Italy.
RP Scantamburlo, T (corresponding author), Ca Foscari Univ Venice, European Ctr Living Technol, Dorsoduro 3911,Calle Crosera, I-30123 Venice, Italy.
EM teresa.scantamburlo@unive.it
OI Scantamburlo, Teresa/0000-0002-3769-8874
FU Universita Ca' Foscari Venezia within the CRUI-CARE Agreement; project A
   European AI On Demand Platform and Ecosystem (AI4EU) H2020-ICT-26
   [825619]
FX Open access funding provided by Universita Ca' Foscari Venezia within
   the CRUI-CARE Agreement. The research was supported by the project A
   European AI On Demand Platform and Ecosystem (AI4EU) H2020-ICT-26 under
   (Grant 825619).
NR 42
TC 0
Z9 0
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1388-1957
EI 1572-8439
J9 ETHICS INF TECHNOL
JI Ethics Inf. Technol.
PD DEC
PY 2021
VL 23
IS 4
BP 703
EP 712
DI 10.1007/s10676-021-09608-9
EA AUG 2021
PG 10
WC Ethics; Information Science & Library Science; Philosophy
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Social Sciences - Other Topics; Information Science & Library Science;
   Philosophy
GA XK3BT
UT WOS:000681514200001
OA hybrid
DA 2022-04-17
ER

PT J
AU Wang, ZH
   Brenning, A
AF Wang, Zhihao
   Brenning, Alexander
TI Active-Learning Approaches for Landslide Mapping Using Support Vector
   Machines
SO REMOTE SENSING
LA English
DT Article
DE active learning; landslide modelling; support vector machine; machine
   learning
ID REMOTE-SENSING IMAGES; SOUTHERN ECUADOR; SUSCEPTIBILITY; PREDICTION;
   INFORMATION; DERIVATIVES; VALIDATION; MODELS; ANDES; AREA
AB Ex post landslide mapping for emergency response and ex ante landslide susceptibility modelling for hazard mitigation are two important application scenarios that require the development of accurate, yet cost-effective spatial landslide models. However, the manual labelling of instances for training machine learning models is time-consuming given the data requirements of flexible data-driven algorithms and the small percentage of area covered by landslides. Active learning aims to reduce labelling costs by selecting more informative instances. In this study, two common active-learning strategies, uncertainty sampling and query by committee, are combined with the support vector machine (SVM), a state-of-the-art machine-learning technique, in a landslide mapping case study in order to assess their possible benefits compared to simple random sampling of training locations. By selecting more "informative" instances, the SVMs with active learning based on uncertainty sampling outperformed both random sampling and query-by-committee strategies when considering mean AUROC (area under the receiver operating characteristic curve) as performance measure. Uncertainty sampling also produced more stable performances with a smaller AUROC standard deviation across repetitions. In conclusion, under limited data conditions, uncertainty sampling reduces the amount of expert time needed by selecting more informative instances for SVM training. We therefore recommend incorporating active learning with uncertainty sampling into interactive landslide modelling workflows, especially in emergency response settings, but also in landslide susceptibility modelling.
C1 [Wang, Zhihao; Brenning, Alexander] Friedrich Schiller Univ Jena, Dept Geog, Loebdergraben 32, D-07743 Jena, Germany.
RP Wang, ZH (corresponding author), Friedrich Schiller Univ Jena, Dept Geog, Loebdergraben 32, D-07743 Jena, Germany.
EM zhihao.wang@uni-jena.de; alexander.brenning@uni-jena.de
RI ; Brenning, Alexander/E-6022-2011
OI Wang, Zhihao/0000-0001-6342-5784; Brenning,
   Alexander/0000-0001-6640-679X
FU China Scholarship Council PhD scholarshipChina Scholarship Council
FX Z.W. was funded through a China Scholarship Council PhD scholarship,
   which is gratefully acknowledged.
NR 74
TC 3
Z9 3
U1 9
U2 14
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JUL
PY 2021
VL 13
IS 13
AR 2588
DI 10.3390/rs13132588
PG 16
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA TG3AP
UT WOS:000671281200001
OA gold
DA 2022-04-17
ER

PT J
AU de Farias, A
   de Almeida, SLR
   Delijaicov, S
   Seriacopi, V
   Bordinassi, EC
AF de Farias, Adalto
   de Almeida, Sergio Luiz Rabelo
   Delijaicov, Sergio
   Seriacopi, Vanessa
   Bordinassi, Ed Claudio
TI Simple machine learning allied with data-driven methods for monitoring
   tool wear in machining processes
SO INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY
LA English
DT Article
DE Machine learning; Deep learning; Data-driven; Tool wear; Machining
ID PREDICTION; ONLINE
AB The aim of this work was to identify the occurrence of machine tool wear in carbide inserts applied in a machine turning center with two steel materials. Through the data collected with an open-source communication protocol during machining, eighty trials of twenty runs each were performed using central composite design experiments, resulting in a data set of eighty lines for each tested material. The data set consisted of forty lines with the tool wear condition and forty lines without. Machining parameters were set to be in the range of the usual industrial values. The cutting parameters in the machining process were cutting speed, feed rate, cutting depth, and cutting fluid applied in the abundance condition and without cutting fluid (dry machining). The collected data were the spindle motor load,X-axis motor load, andZ-axis motor load in terms of the percentage used. AISI P20 and AISI 1045 steels workpieces were tested with both new and worn inserts, and a flank tool wear of 0.3 mm was artificially induced by machining with the same material before the data collecting experiment. Two approaches were used in order to analyze the data and create the machine learning process (MLP), in a prior analysis. The collected data set was tested without any previous treatment, with an optimal linear associative memory (OLAM) neural network, and the results showed 65% correct answers in predicting tool wear, considering 3/4 of the data set for training and 1/4 for validating. For the second approach, statistical data mining methods (DMM) and data-driven methods (DDM), known as a self-organizing deep learning method, were employed in order to increase the success ratio of the model. Both DMM and DDM applied along with the MLP OLAM neural network showed an increase in hitting the right answers to 93.8%. This model can be useful in machine monitoring using Industry 4.0 concepts, where one of the key challenges in machining components is finding the appropriate moment for a tool change.
C1 [de Farias, Adalto; Seriacopi, Vanessa; Bordinassi, Ed Claudio] Inst Maua Tecnol, Ctr Univ, Dept Mech Engn, Praca Maua 01, BR-09580900 Sao Caetano do Sul, Brazil.
   [de Farias, Adalto; Delijaicov, Sergio; Bordinassi, Ed Claudio] FEI, Ctr Univ, Dept Mech Engn, Ave Humberto de Alencar Castelo Branco 3972, BR-09580901 Sao Bernardo Do Campo, Brazil.
   [de Almeida, Sergio Luiz Rabelo] Univ Presbiteriana Mackenzie, Dept Mech Engn, R Consolacao,930 Consolacao, BR-01302907 Sao Paulo, SP, Brazil.
RP Bordinassi, EC (corresponding author), Inst Maua Tecnol, Ctr Univ, Dept Mech Engn, Praca Maua 01, BR-09580900 Sao Caetano do Sul, Brazil.; Bordinassi, EC (corresponding author), FEI, Ctr Univ, Dept Mech Engn, Ave Humberto de Alencar Castelo Branco 3972, BR-09580901 Sao Bernardo Do Campo, Brazil.
EM ecb@maua.br
RI de Farias, Adalto/T-7421-2019; Seriacopi, Vanessa/P-5304-2014;
   Bordinassi, Ed Claudio/AAW-6867-2020
OI Seriacopi, Vanessa/0000-0002-1903-867X; Bordinassi, Ed
   Claudio/0000-0002-3915-3077; de Farias, Adalto/0000-0002-6780-2804;
   Delijaicov, Sergio/0000-0001-5621-9536
NR 36
TC 6
Z9 6
U1 5
U2 28
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0268-3768
EI 1433-3015
J9 INT J ADV MANUF TECH
JI Int. J. Adv. Manuf. Technol.
PD AUG
PY 2020
VL 109
IS 9-12
BP 2491
EP 2501
DI 10.1007/s00170-020-05785-x
EA AUG 2020
PG 11
WC Automation & Control Systems; Engineering, Manufacturing
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Engineering
GA NB8LH
UT WOS:000554439100001
DA 2022-04-17
ER

PT C
AU Alqudah, N
   Yaseen, Q
AF Alqudah, Nour
   Yaseen, Qussai
BE Shakshuki, E
   Yasar, A
TI Machine Learning for Traffic Analysis: A Review
SO 11TH INTERNATIONAL CONFERENCE ON AMBIENT SYSTEMS, NETWORKS AND
   TECHNOLOGIES (ANT) / THE 3RD INTERNATIONAL CONFERENCE ON EMERGING DATA
   AND INDUSTRY 4.0 (EDI40) / AFFILIATED WORKSHOPS
SE Procedia Computer Science
LA English
DT Proceedings Paper
CT 11th International Conference on Ambient Systems, Networks and
   Technologies (ANT) / 3rd International Conference on Emerging Data and
   Industry 4.0 (EDI)
CY APR 06-09, 2020
CL Warsaw, POLAND
DE traffic analysis; machine learning; network security
AB Traffic analysis has many purposes such as evaluating the performance and security of network operations and management. Therefore, network traffic analysis is considered vital for improving networks operation and security. This paper discusses different machine learning approaches for traffic analysis. Increased network traffic and the development of artificial intelligence require new ways to detect intrusions, analyze malware behavior, and categorize Internet traffic and other security aspects. Machine learning (ML) shows effective capabilities in solving network problems. A review of the techniques used in the traffic analysis is presented in this paper. (C) 2020 The Authors. Published by Elsevier B.V.
C1 [Alqudah, Nour; Yaseen, Qussai] Jordan Univ Sci & Technol, Dept Comp Informat Syst, Irbid, Jordan.
RP Alqudah, N (corresponding author), Jordan Univ Sci & Technol, Dept Comp Informat Syst, Irbid, Jordan.
EM nsalqudah18@cit.just.edu.jo
NR 32
TC 4
Z9 4
U1 8
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0509
J9 PROCEDIA COMPUT SCI
PY 2020
VL 170
BP 911
EP 916
DI 10.1016/j.procs.2020.03.111
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ2ZA
UT WOS:000582714500123
OA gold
DA 2022-04-17
ER

PT S
AU Chicco, D
   Faultless, T
AF Chicco, Davide
   Faultless, Trent
BE Wong, KC
TI Brief Survey on Machine Learning in Epistasis
SO EPISTASIS: Methods and Protocols
SE Methods in Molecular Biology
LA English
DT Article; Book Chapter
DE Machine learning; Epistasis; Gene-gene interactions; Survey; Review;
   Overview
ID FLAVONOID BIOSYNTHETIC-PATHWAY; COLOR; ROSE
AB In biology, the term "epistasis" indicates the effect of the interaction of a gene with another gene. A gene can interact with an independently sorted gene, located far away on the chromosome or on an entirely different chromosome, and this interaction can have a strong effect on the function of the two genes. These changes then can alter the consequences of the biological processes, influencing the organism's phenotype. Machine learning is an area of computer science that develops statistical methods able to recognize patterns from data. A typical machine learning algorithm consists of a training phase, where the model learns to recognize specific trends in the data, and a test phase, where the trained model applies its learned intelligence to recognize trends in external data. Scientists have applied machine learning to epistasis problems multiple times, especially to identify gene-gene interactions from genome-wide association study (GWAS) data. In this brief survey, we report and describe the main scientific articles published in data mining and epistasis. Our article confirms the effectiveness of machine learning in this genetics subfield.
C1 [Chicco, Davide] Krembil Res Inst, Toronto, ON, Canada.
   [Faultless, Trent] Toronto Gen Hosp, Toronto, ON, Canada.
RP Chicco, D (corresponding author), Krembil Res Inst, Toronto, ON, Canada.
RI Chicco, Davide/C-7058-2017
OI Chicco, Davide/0000-0001-9655-7142
NR 59
TC 0
Z9 0
U1 0
U2 2
PU HUMANA PRESS INC
PI TOTOWA
PA 999 RIVERVIEW DR, STE 208, TOTOWA, NJ 07512-1165 USA
SN 1064-3745
EI 1940-6029
BN 978-1-0716-0947-7; 978-1-0716-0946-0
J9 METHODS MOL BIOL
JI Methods Mol. Biol.
PY 2021
VL 2212
BP 169
EP 179
DI 10.1007/978-1-0716-0947-7_11
D2 10.1007/978-1-0716-0947-7
PG 11
WC Biochemical Research Methods; Biochemistry & Molecular Biology; Genetics
   & Heredity
WE Book Citation Index – Science (BKCI-S)
SC Biochemistry & Molecular Biology; Genetics & Heredity
GA BS2WA
UT WOS:000707157200012
PM 33733356
DA 2022-04-17
ER

PT C
AU Ferreira, LA
   Guimaraes, FG
   Silva, R
AF Ferreira, Leonardo Augusto
   Guimaraes, Frederico Gadelha
   Silva, Rodrigo
GP IEEE
TI Applying Genetic Programming to Improve Interpretability in Machine
   Learning Models
SO 2020 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC)
SE IEEE Congress on Evolutionary Computation
LA English
DT Proceedings Paper
CT IEEE Congress on Evolutionary Computation (CEC) as part of the IEEE
   World Congress on Computational Intelligence (IEEE WCCI)
CY JUL 19-24, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Computat Intelligence Soc
DE Interpretability; Machine Learning; Genetic Programming; Explainability
AB Explainable Artificial Intelligence (or xAI) has become an important research topic in the fields of Machine Learning and Deep Learning. In this paper, we propose a Genetic Programming (GP) based approach, name Genetic Programming Explainer (GPX), to the problem of explaining decisions computed by AI systems. The method generates a noise set located in the neighborhood of the point of interest, whose prediction should be explained, and fits a local explanation model for the analyzed sample. The tree structure generated by GPX provides a comprehensible analytical, possibly non-linear, expression which reflects the local behavior of the complex model. We considered three machine learning techniques that can be recognized as complex black-box models: Random Forest, Deep Neural Network and Support Vector Machine in twenty data sets for regression and classifications problems. Our results indicate that the GPX is able to produce more accurate understanding of complex models than the state of the art. The results validate the proposed approach as a novel way to deploy GP to improve interpretability.
C1 [Ferreira, Leonardo Augusto; Guimaraes, Frederico Gadelha] Univ Fed Minas Gerais, UFMG, Dept Elect Engn, Machine Intelligence & Data Sci MINDS Lab, BR-31270000 Belo Horizonte, MG, Brazil.
   [Silva, Rodrigo] Univ Fed Ouro Preto, UFOP, Dept Comp Sci, BR-35400000 Ouro Preto, MG, Brazil.
RP Ferreira, LA (corresponding author), Univ Fed Minas Gerais, UFMG, Dept Elect Engn, Machine Intelligence & Data Sci MINDS Lab, BR-31270000 Belo Horizonte, MG, Brazil.
EM leauferreira@cpdee.ufmg.br; fredericoguimaraes@ufmg.br;
   rodrigo.silva@ufop.edu.br
OI V. Ferreira, Ana/0000-0003-4140-248X
FU National Council for Scientific and Technological Development
   (CNPq)Conselho Nacional de Desenvolvimento Cientifico e Tecnologico
   (CNPQ); Coordination for the Improvement of Higher Education
   (CAPES)Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior
   (CAPES); Foundation for Research of the State of Minas Gerais (FAPEMIG,
   in Portuguese)Fundacao de Amparo a Pesquisa do Estado de Minas Gerais
   (FAPEMIG)
FX This work has been supported by the Brazilian agencies (i) National
   Council for Scientific and Technological Development (CNPq); (ii)
   Coordination for the Improvement of Higher Education (CAPES) and (iii)
   Foundation for Research of the State of Minas Gerais (FAPEMIG, in
   Portuguese).
NR 34
TC 0
Z9 0
U1 1
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-6929-3
J9 IEEE C EVOL COMPUTAT
PY 2020
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic; Mathematical &
   Computational Biology; Operations Research & Management Science
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Mathematical & Computational Biology;
   Operations Research & Management Science
GA BS2NK
UT WOS:000703998201010
DA 2022-04-17
ER

PT J
AU Liu, XY
   Ge, Q
   Chen, XH
   Li, JY
   Chen, YK
AF Liu, Xingye
   Ge, Qiang
   Chen, Xiaohong
   Li, Jingye
   Chen, Yangkang
TI Extreme learning machine for multivariate reservoir characterization*
SO JOURNAL OF PETROLEUM SCIENCE AND ENGINEERING
LA English
DT Article
DE Reservoir characterization; Facies; Reservoir properties; Machine
   learning; Extreme learning machine
ID NEURAL-NETWORKS; REGULARIZATION; INVERSION; PRESTACK; OPTIMIZATION;
   DROPOUT; PHYSICS; SCHEME
AB Reservoir characterization is one of the most important tasks in oil and gas field exploration and development. Different parameters reflect the relevant information of oil and gas fields from diversified aspects. We design a new reservoir characterization framework by introducing extreme learning machine (ELM) that is one of the state-of-the-art methods in machine learning. It is a single hidden layer feedforward neural (SLFN) network, while the input weight and the bias value of the hidden layer are randomly assigned and kept fixed for simplifying the calculation. Based on ELM, we achieve simultaneous prediction of multiple reservoir parameters (including lithofacies, porosity, shale content and saturation etc.) only through one training step. In order to combat overfitting when the number of hidden nodes is inappropriate or the training samples are inadequate, we extend the method by using biased dropout and dropconnect operations to regularize ELM. We describe the new method in detail and analyze its performance with varying input parameters. It is evaluated on well and seismic datasets by exploiting elastic attributes as training input. Compared with traditional SLFN-based method, ELMbased method uses less computational resources and costs less time on training without losing accuracy. The biased dropout and dropconnect operations further enhance the generalization ability.
C1 [Liu, Xingye] Xian Univ Sci & Technol, Coll Geol & Environm, Shaanxi Prov Key Lab Geol Support Coal Green Expl, Xian 710054, Peoples R China.
   [Ge, Qiang] Petrochina Res Inst Petr Explorat & Dev, Dept Geophys Technol, Beijing 100083, Peoples R China.
   [Chen, Xiaohong; Li, Jingye] China Univ Petr, Coll Geophys, Beijing 102249, Peoples R China.
   [Chen, Yangkang] Zhejiang Univ, Sch Earth Sci, Hangzhou 310027, Zhejiang, Peoples R China.
RP Liu, XY (corresponding author), Xian Univ Sci & Technol, Coll Geol & Environm, Shaanxi Prov Key Lab Geol Support Coal Green Expl, Xian 710054, Peoples R China.
EM lwxwyh506673@126.com; geqiang69@petrochina.com.cn; chenxh@cup.edu.cn;
   lijingye@cup.edu.cn; chenyk2016@gmail.com
RI Liu, Xingye/AGH-2572-2022; Ge, Qiang/AFX-2081-2022
OI Liu, Xingye/0000-0002-9193-1075
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41774129, 41874123, 41904116]; Natural
   Science Basic Research Program of Shaanxi Province [2021JQ561]
FX This work is financially supported by the National Natural Science
   Foundation of China (41774129, 41874123, 41904116) , and the Natural
   Science Basic Research Program of Shaanxi Province (2021JQ561) .
NR 52
TC 1
Z9 1
U1 3
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0920-4105
EI 1873-4715
J9 J PETROL SCI ENG
JI J. Pet. Sci. Eng.
PD OCT
PY 2021
VL 205
AR 108869
DI 10.1016/j.petrol.2021.108869
EA APR 2021
PG 19
WC Energy & Fuels; Engineering, Petroleum
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Energy & Fuels; Engineering
GA TD0OL
UT WOS:000669035400005
DA 2022-04-17
ER

PT J
AU Vaccaro, L
   Sansonetti, G
   Micarelli, A
AF Vaccaro, Lorenzo
   Sansonetti, Giuseppe
   Micarelli, Alessandro
TI An Empirical Review of Automated Machine Learning
SO COMPUTERS
LA English
DT Article
DE automated machine learning; meta learning; neural architecture search;
   reinforcement learning
ID RECOMMENDATION; NETWORK
AB In recent years, Automated Machine Learning (AutoML) has become increasingly important in Computer Science due to the valuable potential it offers. This is testified by the high number of works published in the academic field and the significant efforts made in the industrial sector. However, some problems still need to be resolved. In this paper, we review some Machine Learning (ML) models and methods proposed in the literature to analyze their strengths and weaknesses. Then, we propose their use-alone or in combination with other approaches-to provide possible valid AutoML solutions. We analyze those solutions from a theoretical point of view and evaluate them empirically on three Atari games from the Arcade Learning Environment. Our goal is to identify what, we believe, could be some promising ways to create truly effective AutoML frameworks, therefore able to replace the human expert as much as possible, thereby making easier the process of applying ML approaches to typical problems of specific domains. We hope that the findings of our study will provide useful insights for future research work in AutoML.
C1 [Vaccaro, Lorenzo; Sansonetti, Giuseppe; Micarelli, Alessandro] Roma Tre Univ, Dept Engn, I-00146 Rome, Italy.
RP Sansonetti, G (corresponding author), Roma Tre Univ, Dept Engn, I-00146 Rome, Italy.
EM lor.vaccaro1@stud.uniroma3.it; gsansone@dia.uniroma3.it;
   micarel@dia.uniroma3.it
OI Sansonetti, Giuseppe/0000-0003-4953-1390; micarelli,
   alessandro/0000-0002-0495-5272
NR 70
TC 1
Z9 1
U1 6
U2 13
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 2073-431X
J9 COMPUTERS
JI Computers
PD JAN
PY 2021
VL 10
IS 1
AR 11
DI 10.3390/computers10010011
PG 27
WC Computer Science, Interdisciplinary Applications
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA PX1HW
UT WOS:000611115200001
OA gold, Green Published
DA 2022-04-17
ER

PT J
AU Li, JM
   Wu, WF
   Xue, D
AF Li, Jingmei
   Wu, Weifei
   Xue, Di
TI Research on transfer learning algorithm based on support vector machine
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Machine learning; support vector machine; transfer learning;
   classification
ID CONVEX
AB Transfer learning is a new machine learning algorithm. It solves problems in different but related target domains by utilizing the knowledge in existing data. Based on the classical SVM algorithm and transfer learning, a selective transfer learning support vector machine (STL-SVM) algorithm is proposed in this paper. First, STL-SVM uses the maximum mean discrepancy to measure the weight vector of the source domain samples relative to the target domain, and selects samples from the source domain according to each weight to avoid negative transfer. Then, the knowledge in the source domain is learned by the approximate extreme point support vector at the minimum training data cost. Finally, the object function is constructed by the obtained knowledge and the soft-margin SVM. In the constraint conditions of the objective function, the learned knowledge that is highly correlated with the target domain is selected, and further, the phenomenon of negative transfer is avoided in principle. STL-SVM solves the problem of negative transfer, and has considerable advantages in training time efficiency compared with the existing algorithms. The experimental results on artificial and real datasets show the effectiveness of the proposed algorithm.
C1 [Li, Jingmei; Wu, Weifei; Xue, Di] Harbin Engn Univ, Coll Comp Sci & Technol, Harbin, Heilongjiang, Peoples R China.
RP Wu, WF (corresponding author), Harbin Engn Univ, Coll Comp Sci & Technol, Harbin, Heilongjiang, Peoples R China.
EM wuweifei@hrbeu.edu.cn
FU National Key Research and Development Plan of China [2016YFB 0801004]
FX This work was supported by National Key Research and Development Plan of
   China (2016YFB 0801004).
NR 37
TC 2
Z9 2
U1 7
U2 13
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PY 2020
VL 38
IS 4
BP 4091
EP 4106
DI 10.3233/JIFS-190055
PG 16
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LP9NH
UT WOS:000534641700055
DA 2022-04-17
ER

PT J
AU Ouyang, TH
   Shen, X
AF Ouyang, Tinghui
   Shen, Xun
TI Representation learning based on hybrid polynomial approximated extreme
   learning machine
SO APPLIED INTELLIGENCE
LA English
DT Article; Early Access
DE Representation learning; Extreme-learning-machine-based autoencoder;
   Polynomials approximation; Feature reconstruction; Dimension reduction
ID DIMENSIONALITY
AB As an effective algorithm in feature learning, autoencoder (AE) and its variants have been widely applied in machine learning. To overcome the expensive time consumption in backpropagation learning and parameters iterative tuning, extreme learning machine (ELM) is combined with AE, developed as ELM-based AE (ELM-AE) in unsupervised feature learning. However, random projection of ELM makes the learned features not stable for the final target recognition. On the other hand, considering to enhance high-order nonlinear expression in ELM-AE, common methods increase the computation overhead. Therefore, this paper proposes to construct a new ELM-AE based on approximation of hybrid high-order polynomial functions. The proposed model will keep fast learning speed by linearization of the high-order nonlinear expression, be robust to random projection issue, and learn discriminative features for pattern recognition. Two feature learning application scenarios, feature reconstruction and dimension reduction, are discussed based on different ELM-AE models. Experiments on publicly available datasets including small and large datasets demonstrate the proposed model's feasibility and superiority in feature learning.
C1 [Ouyang, Tinghui] Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB, Canada.
   [Shen, Xun] Tokyo Univ Agr & Technol, Dept Mech Syst Engn, Tokyo, Japan.
RP Ouyang, TH (corresponding author), Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB, Canada.
EM touyang@ualberta.ca; shenxun@go.tuat.ac.jp
RI Ouyang, Tinghui/AAQ-9593-2020; Ouyang, Tinghui/ABE-1516-2021
OI Ouyang, Tinghui/0000-0002-9234-9132
NR 31
TC 0
Z9 0
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
DI 10.1007/s10489-021-02915-0
EA OCT 2021
PG 16
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WM8QD
UT WOS:000711342900001
DA 2022-04-17
ER

PT J
AU Nasir, T
   Asmael, M
   Zeeshan, Q
   Solyali, D
AF Nasir, Tauqir
   Asmael, Mohammed
   Zeeshan, Qasim
   Solyali, Davut
TI Applications of Machine Learning to Friction Stir Welding Process
   Optimization
SO JURNAL KEJURUTERAAN
LA English
DT Article
DE Machine learning; Artificial Neural Network; Support Vector Machine;
   ANFIS; Response Surface Methodology
ID ARTIFICIAL NEURAL-NETWORK; BUILDING ENERGY-CONSUMPTION; SUPPORT VECTOR
   MACHINE; ALUMINUM-ALLOY; TENSILE-STRENGTH; MECHANICAL-PROPERTIES;
   PROCESS PARAMETERS; JOINT STRENGTH; PREDICTION; ANFIS
AB Machine learning (ML) is a branch of artificial intelligent which involve the study and development of algorithm for computer to learn from data. A computational method used in machine learning to learn or get directly information from data without relying on a prearranged model equation. The applications of ML applied in the domains of all industries. In the field of manufacturing the ability of ML approach is utilized to predict the failure before occurrence. FSW and FSSW is an advanced form of friction welding and it is a solid state joining technique which is mostly used to weld the dissimilar alloys. FSW, FSSW has become a dominant joining method in aerospace, railway and ship building industries. It observed that the number of applications of machine learning increased in FSW, FSSW process which sheared the Machine-learning approaches like, artificial Neural Network (ANN), Regression model (RSM), Support Vector Machine (SVM) and Adaptive Neuro-Fuzzy Inference System (ANFIS). The main purpose of this study is to review and summarize the emerging research work of machine learning techniques in FSW and FSSW. Previous researchers demonstrate that the Machine Learning applications applied to predict the response of FSW and FSSW process. The prediction in error percentage in result of ANN and RSM model in overall is less than 5%. In comparison between ANN/RSM the obtain result shows that ANN is provide better and accurate than RSM. In application of SVM algorithm the prediction accuracy found 100% for training and testing process.
C1 [Nasir, Tauqir; Asmael, Mohammed; Zeeshan, Qasim] Eastern Mediterranean Univ, Dept Mech Engn, Fac Engn, Mersin 10, Gazimagusa, North Cyprus, Turkey.
   [Solyali, Davut] Eastern Mediterranean Univ, Elect Vehicle Dev Ctr, Mersin 10, Gazimagusa, North Cyprus, Turkey.
RP Asmael, M (corresponding author), Eastern Mediterranean Univ, Dept Mech Engn, Fac Engn, Mersin 10, Gazimagusa, North Cyprus, Turkey.
EM Mohammed.asmael@emu.edu.tr
RI Nasir, Tauqir/AAT-1812-2020; Asmael, Mohammed/I-5510-2015; Solyalı,
   Davut/AAM-7051-2020; Zeeshan, Qasim/Q-3181-2019
OI Nasir, Tauqir/0000-0002-4339-0059; Asmael, Mohammed/0000-0003-2853-0460;
   Solyalı, Davut/0000-0002-7489-8883; Zeeshan, Qasim/0000-0001-5488-8082
NR 88
TC 11
Z9 11
U1 5
U2 12
PU UKM PRESS
PI SELANGOR
PA BANGI, SELANGOR, 43600, MALAYSIA
SN 0128-0198
EI 2289-7526
J9 J KEJURUTER
JI J. Kejuruter.
PD MAY
PY 2020
VL 32
IS 2
BP 171
EP 186
DI 10.17576/jkukm-2020-32(2)-01
PG 16
WC Engineering, Multidisciplinary
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA LP9LZ
UT WOS:000534638300001
DA 2022-04-17
ER

PT J
AU Kulmanov, M
   Smaili, FZ
   Gao, X
   Hoehndorf, R
AF Kulmanov, Maxat
   Smaili, Fatima Zohra
   Gao, Xin
   Hoehndorf, Robert
TI Semantic similarity and machine learning with ontologies
SO BRIEFINGS IN BIOINFORMATICS
LA English
DT Review
DE machine learning; semantic similarity; ontology; knowledge
   representation; neuro-symbolic integration
ID GENE ONTOLOGY; HIERARCHICAL-CLASSIFICATION; WEB; PRIORITIZATION;
   INTERACTOME; PHENOTYPE; SEQUENCE; FEATURES; WALKING; TOOL
AB Ontologies have long been employed in the life sciences to formally represent and reason over domain knowledge and they are employed in almost every major biological database. Recently, ontologies are increasingly being used to provide background knowledge in similarity-based analysis and machine learning models. The methods employed to combine ontologies and machine learning are still novel and actively being developed. We provide an overview over the methods that use ontologies to compute similarity and incorporate them in machine learning methods; in particular, we outline how semantic similarity measures and ontology embeddings can exploit the background knowledge in ontologies and how ontologies can provide constraints that improve machine learning models. The methods and experiments we describe are available as a set of executable notebooks, and we also provide a set of slides and additional resources at https://github.com/bio-ontology-research-group/machine-learning-with-ontologies.
C1 [Kulmanov, Maxat] King Abdullah Univ Sci & Technol, Comp Sci Bioontol Res Grp, Thuwal, Saudi Arabia.
   [Smaili, Fatima Zohra; Gao, Xin; Hoehndorf, Robert] King Abdullah Univ Sci & Technol, Comp Sci, Thuwal, Saudi Arabia.
   [Hoehndorf, Robert] King Abdullah Univ Sci & Technol, Bioontol Res Grp, Thuwal, Saudi Arabia.
   [Gao, Xin] King Abdullah Univ Sci & Technol, Computat Biosci Res Ctr, Thuwal, Saudi Arabia.
   [Gao, Xin] King Abdullah Univ Sci & Technol, Struct & Funct Bioinformat Grp, Thuwal, Saudi Arabia.
RP Hoehndorf, R (corresponding author), King Abdullah Univ Sci & Technol, Comp Elect & Math Sci & Engn Div, 4700 KAUST, Thuwal 23955, Saudi Arabia.
EM robert.hoehndorf@kaust.edu.sa
RI Hoehndorf, Robert/H-6127-2019; Gao, Xin/D-5487-2013
OI Hoehndorf, Robert/0000-0001-8149-5890; Kulmanov,
   Maxat/0000-0003-1710-1820; Smaili, Fatima Zohra/0000-0001-6439-0659;
   Gao, Xin/0000-0002-7108-3574
FU King Abdullah University of Science and Technology, Office of Sponsored
   ResearchKing Abdullah University of Science & Technology
   [URF/1/3454-01-01, URF/1/3790-0101, FCC/1/1976-04, FCC/1/1976-06,
   FCC/1/1976-17, FCC/1/1976-18, FCC/1/1976-23, FCC/1/1976-25,
   FCC/1/1976-26, URF/1/3450-01]
FX This work was supported by funding from King Abdullah University of
   Science and Technology, Office of Sponsored Research under award no.
   URF/1/3454-01-01, URF/1/3790-0101, FCC/1/1976-04, FCC/1/1976-06,
   FCC/1/1976-17, FCC/1/1976-18, FCC/1/1976-23, FCC/1/1976-25,
   FCC/1/1976-26 and URF/1/3450-01.
NR 142
TC 12
Z9 12
U1 12
U2 13
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 1467-5463
EI 1477-4054
J9 BRIEF BIOINFORM
JI Brief. Bioinform.
PD JUL
PY 2021
VL 22
IS 4
AR bbaa199
DI 10.1093/bib/bbaa199
PG 18
WC Biochemical Research Methods; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Mathematical & Computational Biology
GA WK1AV
UT WOS:000709466800001
PM 33049044
OA Green Published, hybrid
DA 2022-04-17
ER

PT J
AU Convy, I
   Huggins, W
   Liao, HR
   Whaley, KB
AF Convy, Ian
   Huggins, William
   Liao, Haoran
   Birgitta Whaley, K.
TI Mutual information scaling for tensor network machine learning
SO MACHINE LEARNING-SCIENCE AND TECHNOLOGY
LA English
DT Article
DE area law; mutual information; tensor network machine learning
ID MATRIX PRODUCT STATES; RENORMALIZATION-GROUP; ENTROPY
AB Tensor networks have emerged as promising tools for machine learning, inspired by their widespread use as variational ansatze in quantum many-body physics. It is well known that the success of a given tensor network ansatz depends in part on how well it can reproduce the underlying entanglement structure of the target state, with different network designs favoring different scaling patterns. We demonstrate here how a related correlation analysis can be applied to tensor network machine learning, and explore whether classical data possess correlation scaling patterns similar to those found in quantum states, which might indicate the best network to use for a given dataset. We utilize mutual information (MI) as measure of correlations in classical data, and show that it can serve as a lower-bound on the entanglement needed for a probabilistic tensor network classifier. We then develop a logistic regression algorithm to estimate the MI between bipartitions of data features, and verify its accuracy on a set of Gaussian distributions designed to mimic different correlation patterns. Using this algorithm, we characterize the scaling patterns in the Modified National Institute of Standards and Technology and Tiny Images datasets, and find clear evidence of boundary-law scaling in the latter. This quantum-inspired classical analysis offers insight into the design of tensor networks that are best suited for specific learning tasks.
C1 [Convy, Ian; Huggins, William; Birgitta Whaley, K.] Univ Calif Berkeley, Dept Chem, Berkeley, CA 94720 USA.
   [Liao, Haoran] Univ Calif Berkeley, Dept Phys, Berkeley, CA 94720 USA.
   [Convy, Ian; Huggins, William; Liao, Haoran; Birgitta Whaley, K.] Univ Calif Berkeley, Berkeley Quantum Informat & Computat Ctr, Berkeley, CA 94720 USA.
   [Huggins, William] Google Quantum AI, Mountain View, CA USA.
RP Convy, I (corresponding author), Univ Calif Berkeley, Dept Chem, Berkeley, CA 94720 USA.; Convy, I (corresponding author), Univ Calif Berkeley, Berkeley Quantum Informat & Computat Ctr, Berkeley, CA 94720 USA.
EM ian_convy@berkeley.edu
OI Convy, Ian/0000-0003-1818-2677
FU US Department of Energy, Office of Science, Office of Advanced
   Scientific Computing Research, Quantum Algorithm Teams ProgramUnited
   States Department of Energy (DOE) [DE-AC02-05CH11231]; Siemens
   #FutureMakers Fellowship [045695]; National Aeronautics and Space
   Administration through the Aeronautics Research Mission Directorate
   [80NSSC19K1123]; Molecular Graphics and Computation Facility at the
   University of California, BerkeleyUniversity of California System
   [S10OD023532]
FX I C was supported by the US Department of Energy, Office of Science,
   Office of Advanced Scientific Computing Research, Quantum Algorithm
   Teams Program, under Contract Number DE-AC02-05CH11231. W H was
   supported by Siemens #FutureMakers Fellowship 045695. H L was supported
   by the National Aeronautics and Space Administration under
   Grant/Contract/Agreement No. 80NSSC19K1123 issued through the
   Aeronautics Research Mission Directorate. Computational resources were
   provided by the Molecular Graphics and Computation Facility at the
   University of California, Berkeley (NIH Grant S10OD023532).
NR 60
TC 0
Z9 0
U1 1
U2 1
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
EI 2632-2153
J9 MACH LEARN-SCI TECHN
JI Mach. Learn.-Sci. Technol.
PD MAR 1
PY 2022
VL 3
IS 1
AR 015017
DI 10.1088/2632-2153/ac44a9
PG 21
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Science & Technology - Other Topics
GA YJ6LX
UT WOS:000744644300001
PM 35211672
OA Green Submitted, gold
DA 2022-04-17
ER

PT J
AU Ali, N
   Ghazal, TM
   Ahmed, A
   Abbas, S
   Khan, MA
   Alzoubi, HM
   Farooq, U
   Ahmad, M
   Khan, MA
AF Ali, Naeem
   Ghazal, Taher M.
   Ahmed, Alia
   Abbas, Sagheer
   Khan, M. A.
   Alzoubi, Haitham M.
   Farooq, Umar
   Ahmad, Munir
   Khan, Muhammad Adnan
TI Fusion-Based Supply Chain Collaboration Using Machine Learning
   Techniques
SO INTELLIGENT AUTOMATION AND SOFT COMPUTING
LA English
DT Article
DE Business intelligence; k-nearest neighbor; machine learning; simulation;
   supply chain collaboration; support vector machine
ID SYSTEM; OPTIMIZATION; PREDICTION; BEHAVIOR; NETWORK; MODEL
AB Supply Chain Collaboration is the network of various entities that work cohesively to make up the entire process. The supply chain organizations' success is dependent on integration, teamwork, and the communication of information. Every day, supply chain and business players work in a dynamic setting. They must balance competing goals such as process robustness, risk reduction, vulnerability reduction, real financial risks, and resilience against just-in-time and cost-efficiency. Decision-making based on shared information in Supply Chain Collaboration constitutes the recital and competitiveness of the collective process. Supply Chain Collaboration has prompted companies to implement the perfect data analytics functions (e.g., data science, predictive analytics, and big data) to improve supply chain operations and, eventually, efficiency. Simulation and modeling are powerful methods for analyzing, investigating, examining, observing and evaluating real-world industrial and logistic processes in this sce-nario. Fusion-based Machine learning provides a platform that may address the issues/limitations of Supply Chain Collaboration. Compared to the Classical prob-able data fusion techniques, the fused Machine learning method may offer a strong computing ability and prediction. In this scenario, the machine learning-based Supply Chain Collaboration model has been proposed to evaluate the pro-pensity of the decision-making process to increase the efficiency of the Supply Chain Collaboration.
C1 [Ali, Naeem; Ahmed, Alia] Natl Coll Business Adm & Econ, Sch Business Adm, Lahore 54000, Pakistan.
   [Ghazal, Taher M.] Univ Kebansaan Malaysia UKM, Fac Informat Sci & Technol, Ctr Cyber Secur, Bangi 43600, Selangor, Malaysia.
   [Ghazal, Taher M.] Skyline Univ Coll, Sch Informat Technol, Univ City Sharjah 1797, Sharjah, U Arab Emirates.
   [Abbas, Sagheer; Ahmad, Munir] Natl Coll Business Adm & Econ, Sch Comp Sci, Lahore 54000, Pakistan.
   [Khan, M. A.] Riphah Int Univ, Riphah Sch Comp & Innovat, Fac Comp, Lahore Campus, Lahore 54000, Pakistan.
   [Alzoubi, Haitham M.] Skyline Univ Coll, Sch Business, Univ City Sharjah 1797, Sharjah, U Arab Emirates.
   [Farooq, Umar] Lahore Garrison Univ, Dept Comp Sci, Lahore, Pakistan.
   [Khan, Muhammad Adnan] Gachon Univ, Dept Software, Pattern Recognit & Machine Learning Lab, Seongnam 13120, Gyeonggido, South Korea.
RP Khan, MA (corresponding author), Gachon Univ, Dept Software, Pattern Recognit & Machine Learning Lab, Seongnam 13120, Gyeonggido, South Korea.
EM adnan@gachon.ac.kr
RI Alzoubi, Haitham M./A-9678-2018; Ghazal, Taher M./AAS-7443-2021
OI Alzoubi, Haitham M./0000-0003-3178-4007; Ghazal, Taher
   M./0000-0003-0672-7924
NR 35
TC 0
Z9 0
U1 23
U2 23
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1079-8587
EI 2326-005X
J9 INTELL AUTOM SOFT CO
JI Intell. Autom. Soft Comput.
PY 2022
VL 31
IS 3
BP 1671
EP 1687
DI 10.32604/iasc.2022.019892
PG 17
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA WK7JK
UT WOS:000709899600002
OA hybrid
DA 2022-04-17
ER

PT J
AU Tan, ZH
   Tan, P
   Jiang, Y
   Zhou, ZH
AF Tan, Zhi-Hao
   Tan, Peng
   Jiang, Yuan
   Zhou, Zhi-Hua
TI Multi-label optimal margin distribution machine
SO MACHINE LEARNING
LA English
DT Article; Proceedings Paper
CT 11th Asian Conference on Machine Learning (ACML)
CY NOV 17-19, 2019
CL Nagoya, JAPAN
DE Optimal margin distribution machine; Multi-label learning; Support
   vector machine; Margin theory
ID SUPPORT VECTOR MACHINE
AB Multi-label support vector machine (Rank-SVM) is a classic and effective algorithm for multi-label classification. The pivotal idea is to maximize the minimum margin of label pairs, which is extended from SVM. However, recent studies disclosed that maximizing the minimum margin does not necessarily lead to better generalization performance, and instead, it is more crucial to optimize the margin distribution. Inspired by this idea, in this paper, we first introduce margin distribution to multi-label learning and propose multi-label Optimal margin Distribution Machine (mlODM), which optimizes the margin mean and variance of all label pairs efficiently. Extensive experiments in multiple multi-label evaluation metrics illustrate that mlODM outperforms SVM-style multi-label methods. Moreover, empirical study presents the best margin distribution and verifies the fast convergence of our method.
C1 [Tan, Zhi-Hao; Tan, Peng; Jiang, Yuan; Zhou, Zhi-Hua] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210023, Peoples R China.
RP Jiang, Y (corresponding author), Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210023, Peoples R China.
EM tanzh@lamda.nju.edu.cn; tanp@lamda.nju.edu.cn; jiangy@lamda.nju.edu.cn;
   zhouzh@lamda.nju.edu.cn
NR 41
TC 6
Z9 6
U1 4
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0885-6125
EI 1573-0565
J9 MACH LEARN
JI Mach. Learn.
PD MAR
PY 2020
VL 109
IS 3
SI SI
BP 623
EP 642
DI 10.1007/s10994-019-05837-8
PG 20
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA KT6ZG
UT WOS:000519163100009
OA Bronze
DA 2022-04-17
ER

PT J
AU Dib, MAD
   Ribeiro, B
   Prates, P
AF Dib, Mario Alberto da Silveira
   Ribeiro, Bernardete
   Prates, Pedro
TI Federated Learning as a Privacy-Providing Machine Learning for Defect
   Predictions in Smart Manufacturing
SO SMART AND SUSTAINABLE MANUFACTURING SYSTEMS
LA English
DT Article
DE machine learning; federated learning; supervised learning; data privacy;
   defects prediction
ID SPRINGBACK PREDICTION; FINITE-ELEMENT
AB In this work, the federated learning methodology is applied to predict defects in sheet metal forming processes exposed to sources of scatter in the material properties and process parameters. Numerical simulations of the U-channel forming process were performed to analyze springback for three types of sheet steel materials. The datasets of different clients are used to train a single machine learning model. With this approach, multiple parties would simultaneously train a machine learning model on their combined data by training the models locally on the client nodes and progressively improving the learning model through interaction with the central server. This way the industrial peers have no access to the others local data in a centralized server. The predictive performance achieved is similar to a standard centralized learning method, offering competitive results of collaborative machine learning in industrial environment.
C1 [Dib, Mario Alberto da Silveira] Univ Coimbra CISUC, Ctr Informat & Syst, Polo 2, P-3030290 Coimbra, Portugal.
   [Ribeiro, Bernardete] Univ Coimbra CISUC, Ctr Informat & Syst, Dept Informat Engn, Polo 2, P-3030290 Coimbra, Portugal.
   [Prates, Pedro] Univ Coimbra, Dept Mech Engn, Ctr Mech Engn Mat & Proc CEMMPRE, Polo 2, P-3030788 Coimbra, Portugal.
RP Dib, MAD (corresponding author), Univ Coimbra CISUC, Ctr Informat & Syst, Polo 2, P-3030290 Coimbra, Portugal.
EM mariodib@outlook.com
RI Ribeiro, Bernardete/A-8010-2016; Prates, Pedro/A-8250-2013
OI Ribeiro, Bernardete/0000-0002-9770-7672; Prates,
   Pedro/0000-0001-7650-9362
FU FEDER funds through the program COMPETE (Programa Operacional Factores
   de Competitividade); national funds through FCT (Fundacao para a Ciencia
   e a Tecnologia) [UIDB/00285/2020, UIDB/00326/2020]; POCIEuropean
   Commission [PTDC/EMEEME/31243/2017, PTDC/EME-EME/31216/2017]; Portuguese
   National Innovation Agency (ANI) [POCI-01-0247-FEDER-017762]
FX This research is sponsored by FEDER funds through the program COMPETE
   (Programa Operacional Factores de Competitividade) and by national funds
   through FCT (Fundacao para a Ciencia e a Tecnologia) under the projects
   UIDB/00285/2020 and UIDB/00326/2020; this research is also co-funded by
   POCI under the projects PTDC/EMEEME/31243/2017 (RDFORMING) and
   PTDC/EME-EME/31216/2017 (EZ-SHEET) and by the Portuguese National
   Innovation Agency (ANI) under project POCI-01-0247-FEDER-017762
   (SAFEFORMING). The authors are grateful to the anonymous reviewers for
   their constructive input. All supports are gratefully acknowledged.
NR 40
TC 0
Z9 0
U1 4
U2 11
PU AMER SOC TESTING MATERIALS
PI W CONSHOHOCKEN
PA 100 BARR HARBOR DR, W CONSHOHOCKEN, PA 19428-2959 USA
SN 2520-6478
EI 2572-3928
J9 SMART SUSTAIN MANUF
JI Smart Sustain. Manuf. Syst.
PY 2021
VL 5
IS 1
BP 1
EP 17
DI 10.1520/SSMS20200029
PG 17
WC Engineering, Manufacturing
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA PW8LT
UT WOS:000610920300001
DA 2022-04-17
ER

PT J
AU Hamed, MA
   Khafagy, MH
   Badry, RM
AF Hamed, Mohamed A.
   Khafagy, Mohammed H.
   Badry, Rasha M.
TI Fuel Consumption Prediction Model using Machine Learning
SO INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS
LA English
DT Article
DE Fuel consumption; machine learning; support vector machine; feature
   weight; feature selection; on-board diagnostic
AB In the paper, we are enhancing the accuracy of the fuel consumption prediction model with Machine Learning to minimize Fuel Consumption. This will lead to an economic improvement for the business and satisfy the domain needs. We propose a machine learning model to predict vehicle fuel consumption. The proposed model is based on the Support Vector Machine algorithm. The Fuel Consumption estimation is given as a function of Mass Air Flow, Vehicle Speed, Revolutions Per Minute, and Throttle Position Sensor features. The proposed model is applied and tested on a vehicle's On-Board Diagnostics Dataset. The observations were conducted on 18 features. Results achieved a higher accuracy with an R-Squared metric value of 0.97 than other related work using the same Support Vector Machine regression algorithm. We concluded that the Support Vector Machine has a great effect when used for fuel consumption prediction purposes. Our model can compete with other Machine Learning algorithms for the same purpose which will help manufacturers find more choices for successful Fuel Consumption Prediction models.
C1 [Hamed, Mohamed A.; Khafagy, Mohammed H.; Badry, Rasha M.] Fayoum Univ, Dept Informat Syst, Fac Comp & Informat, Al Fayyum 63514, Egypt.
RP Hamed, MA (corresponding author), Fayoum Univ, Dept Informat Syst, Fac Comp & Informat, Al Fayyum 63514, Egypt.
NR 31
TC 0
Z9 0
U1 1
U2 1
PU SCIENCE & INFORMATION SAI ORGANIZATION LTD
PI WEST YORKSHIRE
PA 19 BOLLING RD, BRADFORD, WEST YORKSHIRE, 00000, ENGLAND
SN 2158-107X
EI 2156-5570
J9 INT J ADV COMPUT SC
JI Int. J. Adv. Comput. Sci. Appl.
PD NOV
PY 2021
VL 12
IS 11
BP 406
EP 414
PG 9
WC Computer Science, Theory & Methods
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YA9CB
UT WOS:000738621400045
DA 2022-04-17
ER

PT J
AU Hassaine, A
   Salimi-Khorshidi, G
   Canoy, D
   Rahimi, K
AF Hassaine, Abdelaali
   Salimi-Khorshidi, Gholamreza
   Canoy, Dexter
   Rahimi, Kazem
TI Untangling the complexity of multimorbidity with machine learning
SO MECHANISMS OF AGEING AND DEVELOPMENT
LA English
DT Article
DE Machine learning; Deep learning; Multimorbidity; Electronic health
   records; Phenotyping
ID INDEPENDENT COMPONENT ANALYSIS; CARE; CONCORDANT; PROFILE; IMPACT
AB The prevalence of multimorbidity has been increasing in recent years, posing a major burden for health care delivery and service. Understanding its determinants and impact is proving to be a challenge yet it offers new opportunities for research to go beyond the study of diseases in isolation. In this paper, we review how the field of machine learning provides many tools for addressing research challenges in multimorbidity. We highlight recent advances in promising methods such as matrix factorisation, deep learning, and topological data analysis and how these can take multimorbidity research beyond cross-sectional, expert-driven or confirmatory approaches to gain a better understanding of evolving patterns of multimorbidity. We discuss the challenges and opportunities of machine learning to identify likely causal links between previously poorly understood disease associations while giving an estimate of the uncertainty on such associations. We finally summarise some of the challenges for wider clinical adoption of machine learning research tools and propose some solutions.
C1 [Hassaine, Abdelaali; Salimi-Khorshidi, Gholamreza; Canoy, Dexter; Rahimi, Kazem] Univ Oxford, Oxford Martin Sch, Deep Med, Oxford, England.
   [Hassaine, Abdelaali; Canoy, Dexter; Rahimi, Kazem] Oxford Univ Hosp NHS Fdn Trust, NIHR Oxford Biomed Res Ctr, Oxford, England.
   [Hassaine, Abdelaali; Salimi-Khorshidi, Gholamreza; Canoy, Dexter; Rahimi, Kazem] Univ Oxford, Nuffield Dept Womens & Reprod Hlth, Oxford, England.
RP Rahimi, K (corresponding author), Univ Oxford, Oxford Martin Sch, Deep Med, Oxford, England.
EM kazem.rahimi@wrh.ox.ac.uk
RI Rahimi, Kazem/AAA-4250-2022; Rahimi, Kazem/Q-1279-2015
OI Rahimi, Kazem/0000-0002-4807-4610
FU Oxford Martin School (OMS); National Institute for Health Research
   (NIHR)Oxford Biomedical Research Centre (BRC)National Institute for
   Health Research (NIHR); PEAK Urban programme - UKRI's Global Challenge
   Research Fund [ES/P011055/1]; British Heart FoundationBritish Heart
   Foundation [PG/18/65/33872]; ESRCUK Research & Innovation (UKRI)Economic
   & Social Research Council (ESRC) [ES/P011055/1] Funding Source: UKRI
FX This research was funded by the Oxford Martin School (OMS); supported by
   the National Institute for Health Research (NIHR)Oxford Biomedical
   Research Centre (BRC) and the PEAK Urban programme, funded by UKRI's
   Global Challenge Research Fund, Grant Ref: ES/P011055/1. KR and DC
   received support from the British Heart Foundation grant ref:
   PG/18/65/33872. The views expressed are those of the authors and not
   necessarily those of the OMS, the UK National Health Service (NHS), the
   NIHR or the Department of Health and Social Care.
NR 92
TC 9
Z9 9
U1 4
U2 5
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0047-6374
EI 1872-6216
J9 MECH AGEING DEV
JI Mech. Ageing Dev.
PD SEP
PY 2020
VL 190
AR 111325
DI 10.1016/j.mad.2020.111325
PG 12
WC Cell Biology; Geriatrics & Gerontology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Cell Biology; Geriatrics & Gerontology
GA NO3NQ
UT WOS:000569392800001
PM 32768443
OA Green Published, hybrid
DA 2022-04-17
ER

PT J
AU Hu, ZC
   Bhattacharya, S
   Butte, AJ
AF Hu, Zicheng
   Bhattacharya, Sanchita
   Butte, Atul J.
TI Application of Machine Learning for Cytometry Data
SO FRONTIERS IN IMMUNOLOGY
LA English
DT Review
DE cytometry; cyTOF; machine learning; predictive modeling; flow cytometry
ID FLOW-CYTOMETRY; AUTOMATED IDENTIFICATION; MASS CYTOMETRY; CELLS;
   VISUALIZATION; EXPRESSION; DIAGNOSIS; IMMUNE; TOOL
AB Modern cytometry technologies present opportunities to profile the immune system at a single-cell resolution with more than 50 protein markers, and have been widely used in both research and clinical settings. The number of publicly available cytometry datasets is growing. However, the analysis of cytometry data remains a bottleneck due to its high dimensionality, large cell numbers, and heterogeneity between datasets. Machine learning techniques are well suited to analyze complex cytometry data and have been used in multiple facets of cytometry data analysis, including dimensionality reduction, cell population identification, and sample classification. Here, we review the existing machine learning applications for analyzing cytometry data and highlight the importance of publicly available cytometry data that enable researchers to develop and validate machine learning methods.
C1 [Hu, Zicheng; Bhattacharya, Sanchita; Butte, Atul J.] Univ Calif San Francisco, Bakar Computat Hlth Sci Inst, San Francisco, CA 94143 USA.
   [Hu, Zicheng] Univ Calif San Francisco, Dept Microbiol & Immunol, San Francisco, CA 94143 USA.
RP Hu, ZC (corresponding author), Univ Calif San Francisco, Bakar Computat Hlth Sci Inst, San Francisco, CA 94143 USA.; Hu, ZC (corresponding author), Univ Calif San Francisco, Dept Microbiol & Immunol, San Francisco, CA 94143 USA.
EM zicheng.hu@ucsf.edu
FU National Institute of Allergy and Infectious Diseases ImmPort
   [HHSN316201200036W];  [UH2 AI153016]
FX This work was supported by the National Institute of Allergy and
   Infectious Diseases ImmPort contract HHSN316201200036W (to AB) and
   research grant UH2 AI153016 (to ZH).
NR 48
TC 0
Z9 0
U1 5
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-3224
J9 FRONT IMMUNOL
JI Front. Immunol.
PD JAN 3
PY 2022
VL 12
AR 787574
DI 10.3389/fimmu.2021.787574
PG 8
WC Immunology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Immunology
GA YL1OK
UT WOS:000745668300001
PM 35046945
OA gold, Green Submitted, Green Published
DA 2022-04-17
ER

PT C
AU Hossain, F
   Uddin, MN
   Halder, RK
AF Hossain, Fahima
   Uddin, Mohammed Nasir
   Halder, Rajib Kumar
BE Chakrabarti, S
   Paul, R
   Gill, B
   Gangopadhyay, M
   Poddar, S
TI Analysis of Optimized Machine Learning and Deep Learning Techniques for
   Spam Detection
SO 2021 IEEE INTERNATIONAL IOT, ELECTRONICS AND MECHATRONICS CONFERENCE
   (IEMTRONICS)
LA English
DT Proceedings Paper
CT IEEE International IOT, Electronics and Mechatronics Conference
   (IEMTRONICS)
CY APR 21-24, 2021
CL ELECTR NETWORK
SP IEEE, Inst Engn & Management, IEEE Vancouver Sect, IEEE Toronto Sect, SMART, Univ Engn & Management
DE DBSCAN; Isolation Forest; Feature Selection; Classification; Machine
   Learning; Deep Learning
AB Spam and non-spam email identification are one of the most challenging tasks for both email service providers and consumers. The spammers try to spread misleading facts through irritating messages by attracting user's attention. Several spam identification-models have previously been proposed and tested but the recorded accuracy has shown that further work in this direction is needed to achieve improved accuracy, low training time, and less error rate. In this research work, we have proposed a model that classifies the e-mail into spam and ham. DBSCAN and Isolation Forest are used to identify the extreme values outside of the specific range. Heatmap, Recursive Feature Elimination, and Chi-Square feature selection techniques are used to select the effective features. The proposed model is implemented in both machine learning and deep learning to establish a comparative analysis. Multinomial Wye Bayes (MNB), Random Forest (RF), K-Nearest Neighbor (KNN), Gradient Boosting (GB) are used to introduce ensemble method in machine learning implementation. Recurrent Neural Network (RNN), Gradient Descent (GD), Artificial Neural Network (ANN) for deep learning implementation. An ensemble method is constructed to combine multiple classifiers' output. The ensemble methods allow producing better prediction accuracy compared to a single classifier. Our proposed model obtained an accuracy of 100%, AUC=100, MSE error = 0 and RMSE error = 0 for machine learning implementation and accuracy of 99%, loss value= 0.0165 for deep learning implementation based on an email spam base dataset collected from the UCI machine learning repository.
C1 [Hossain, Fahima; Uddin, Mohammed Nasir; Halder, Rajib Kumar] Jagannath Univ, Dept Comp Sci & Engn, Dhaka 1100, Bangladesh.
RP Hossain, F; Halder, RK (corresponding author), Jagannath Univ, Dept Comp Sci & Engn, Dhaka 1100, Bangladesh.
EM minda.fahima25@gmail.com; nasir.jnu.cse@gmail.com;
   rajib.cse1346@gmail.com
RI Hossain, Fahima/AFY-9680-2022; Halder, Rajib Kumar/AAQ-4151-2021
OI Halder, Rajib Kumar/0000-0002-8542-2258; Hossain,
   Fahima/0000-0001-8743-8547
NR 17
TC 2
Z9 2
U1 3
U2 3
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-6654-4067-7
PY 2021
BP 552
EP 558
DI 10.1109/IEMTRONICS52119.2021.9422508
PG 7
WC Engineering, Electrical & Electronic; Engineering, Mechanical;
   Operations Research & Management Science
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering; Operations Research & Management Science
GA BR9HG
UT WOS:000675601600090
DA 2022-04-17
ER

PT J
AU Low, WS
   Chan, CK
   Chuah, JH
   Tee, YK
   Hum, YC
   Salim, MIM
   Lai, KW
AF Low, Wan Shi
   Chan, Chow Khuen
   Chuah, Joon Huang
   Tee, Yee Kai
   Hum, Yan Chai
   Salim, Maheza Irna Mohd
   Lai, Khin Wee
TI A Review of Machine Learning Network in Human Motion Biomechanics
SO JOURNAL OF GRID COMPUTING
LA English
DT Review
DE Machine learning; Human; Motion; Biomechanics; Gait analysis
ID SUPPORT VECTOR MACHINES; HUMAN GAIT; PARKINSONS-DISEASE; BAYESIAN
   CLASSIFICATION; INERTIAL SENSORS; NEURAL-NETWORKS; CEREBRAL-PALSY;
   RECOGNITION; SYSTEM; IMAGE
AB Human motion analysis is fundamental in many real applications such as surveillance and monitoring, human-machine interface, medical motion analysis and diagnosis. With the increasing amount of data in biomechanics research, it is becoming increasingly important to automatically analyse and understand object motions from large amount of footage and sensor data. The modalities for capturing the gait data are grouped according to the sensing technology: video sequences, wearable sensors, and floor sensors, as well as the publicly available datasets. In order to extract the essence of these data and make research more efficient, modern machine learning techniques are starting to complement traditional statistical tools. The purpose of this review is to familiarise the readers with key directions of implementation of machine learning techniques for gait analysis. The essential human gait parameters are briefly reviewed, followed by a detailed review of the-state-of-the art in machine learning for the human gait analysis. The machine learning framework used for human analysis, such as support vector machine (SVM), Hidden Markov Model (HMM), Bayesian Network Classifier (BN), Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), Long-Short Term Memory (LSTM) and Generative Adversarial Networks (GANs), shall too be discussed here. Finally, the challenges and future direction of machine learning's application in motion analysis are outlined and discussed.
C1 [Low, Wan Shi; Chan, Chow Khuen; Lai, Khin Wee] Univ Malaya, Fac Engn, Biomed Engn Dept, Kuala Lumpur 50603, Malaysia.
   [Chuah, Joon Huang] Univ Malaya, Fac Engn, Elect Engn Dept, Kuala Lumpur 50603, Malaysia.
   [Tee, Yee Kai; Hum, Yan Chai] Univ Tunku Abdul Rahman, Lee Kong Chian Fac Engn & Sci, Dept Mechatron & Biomed Engn, Kajang, Selangor, Malaysia.
   [Salim, Maheza Irna Mohd] Univ Teknol Malaysia, Fac Engn, Sch Biomed Engn & Hlth Sci, Skudai, Malaysia.
RP Lai, KW (corresponding author), Univ Malaya, Fac Engn, Biomed Engn Dept, Kuala Lumpur 50603, Malaysia.
EM lai.khinwee@um.edu.my
RI Lai, Khin Wee/A-2997-2011; Tee, Yee Kai/O-1677-2015
OI Lai, Khin Wee/0000-0002-8602-0533; Tee, Yee Kai/0000-0002-0263-6358
FU Fundamental Research Grant Scheme, Ministry of Higher Education,
   Malaysia [FRGS/1/2019/TK04/UM/01/2]; University MalayaUniversiti Malaya
FX This work was supported by the Fundamental Research Grant Scheme,
   Ministry of Higher Education, Malaysia (FRGS/1/2019/TK04/UM/01/2), and
   University Malaya.
NR 179
TC 0
Z9 0
U1 24
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1570-7873
EI 1572-9184
J9 J GRID COMPUT
JI J. Comput.
PD MAR
PY 2022
VL 20
IS 1
AR 4
DI 10.1007/s10723-021-09595-7
PG 37
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XV2JA
UT WOS:000734773600002
DA 2022-04-17
ER

PT J
AU Watson-Parris, D
AF Watson-Parris, D.
TI Machine learning for weather and climate are worlds apart
SO PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY A-MATHEMATICAL PHYSICAL
   AND ENGINEERING SCIENCES
LA English
DT Article
DE machine learning; climate; climate modelling
ID MODEL; UNCERTAINTY; V1.0; INFERENCE; EMULATOR; OCEAN
AB Modem weather and climate models share a common heritage and often even components; however, they are used in different ways to answer fundamentally different questions. As such, attempts to emulate them using machine learning should reflect this. While the use of machine learning to emulate weather forecast models is a relatively new endeavour, there is a rich history of climate model emulation. This is primarily because while weather modelling is an initial condition problem, which intimately depends on the current state of the atmosphere, climate modelling is predominantly a boundary condition problem. To emulate the response of the climate to different drivers therefore, representation of the full dynamical evolution of the atmosphere is neither necessary, or in many cases, desirable. Climate scientists are typically interested in different questions also. Indeed emulating the steady-state climate response has been possible for many years and provides significant speed increases that allow solving inverse problems for e.g. parameter estimation. Nevertheless, the large datasets, non-linear relationships and limited training data make climate a domain which is rich in interesting machine learning challenges. Here, I seek to set out the current state of climate model emulation and demonstrate how, despite some challenges, recent advances in machine learning provide new opportunities for creating useful statistical models of the climate.
   This article is part of the theme issue 'Machine learning for weather and climate modelling'.
C1 [Watson-Parris, D.] Univ Oxford, Atmospher Ocean & Planetary Phys, Dept Phys, Oxford, England.
RP Watson-Parris, D (corresponding author), Univ Oxford, Atmospher Ocean & Planetary Phys, Dept Phys, Oxford, England.
EM duncan.watson-parris@physics.ox.ac.uk
OI Watson-Parris, Duncan/0000-0002-5312-4950
FU European Union's Horizon 2020 research and innovation programme iMIRACLI
   under Marie Sklodowska-Curie grant [860100]; NERC ACRUISE project
   [NE/S005390/1]; NERCUK Research & Innovation (UKRI)Natural Environment
   Research Council (NERC) [NE/S005390/1] Funding Source: UKRI
FX The author receives funding from the European Union's Horizon 2020
   research and innovation programme iMIRACLI under Marie Sklodowska-Curie
   grant agreement No 860100 and also gratefully acknowledges funding from
   the NERC ACRUISE project NE/S005390/1.
NR 71
TC 7
Z9 7
U1 11
U2 13
PU ROYAL SOC
PI LONDON
PA 6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND
SN 1364-503X
EI 1471-2962
J9 PHILOS T R SOC A
JI Philos. Trans. R. Soc. A-Math. Phys. Eng. Sci.
PD APR 5
PY 2021
VL 379
IS 2194
AR 20200098
DI 10.1098/rsta.2020.0098
PG 12
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA SA2LS
UT WOS:000649132600010
PM 33583265
OA Green Published, Bronze, Green Submitted
DA 2022-04-17
ER

PT J
AU Sakamoto, T
   Goto, T
   Fujiogi, M
   Lefor, AK
AF Sakamoto, Takashi
   Goto, Tadahiro
   Fujiogi, Michimasa
   Lefor, Alan Kawarai
TI Machine learning in gastrointestinal surgery
SO SURGERY TODAY
LA English
DT Review; Early Access
DE Artificial intelligence; Machine learning; Deep learning;
   Computer-assisted surgery; Gastrointestinal surgery
ID ARTIFICIAL NEURAL-NETWORK; GASTRIC-CANCER; RISK CALCULATOR; PREDICTION;
   VALIDATION; BIOMARKERS; DIAGNOSIS; ACCURACY; SURVIVAL; MODEL
AB Machine learning (ML) is a collection of algorithms allowing computers to learn directly from data without predetermined equations. It is used widely to analyze "big data". In gastrointestinal surgery, surgeons deal with various data such as clinical parameters, surgical videos, and pathological images, to stratify surgical risk, perform safe surgery and predict patient prognosis. In the current "big data" era, the accelerating accumulation of a large amount of data drives studies using ML algorithms. Three subfields of ML are supervised learning, unsupervised learning, and reinforcement learning. In this review, we summarize applications of ML to surgical practice in the preoperative, intraoperative, and postoperative phases of care. Prediction and stratification using ML is promising; however, the current overarching concern is the availability of ML models. Information systems that can manage "big data" and integrate ML models into electronic health records are essential to incorporate ML into daily practice. ML is fundamental technology to meaningfully process data that exceeds the capacity of the human mind to comprehend. The accelerating accumulation of a large amount of data is changing the nature of surgical practice fundamentally. Artificial intelligence (AI), represented by ML, is being incorporated into daily surgical practice.
C1 [Sakamoto, Takashi] Japanese Fdn Canc Res, Canc Inst Hosp, Gastroenterol Ctr, Dept Gastroenterol Surg,Koto Ku, 3-8-31 Ariake, Tokyo 1358550, Japan.
   [Sakamoto, Takashi; Goto, Tadahiro] Univ Tokyo, Sch Publ Hlth, Dept Clin Epidemiol & Hlth Econ, Bunkyo Ku, Tokyo 1130033, Japan.
   [Goto, Tadahiro] TXP Med Co Ltd, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1148485, Japan.
   [Fujiogi, Michimasa] Harvard Med Sch, Dept Emergency Med, Massachusetts Gen Hosp, Boston, MA 02114 USA.
   [Fujiogi, Michimasa] Univ Tokyo, Grad Sch Med, Dept Pediat Surg, Bunkyo Ku, Tokyo 1130033, Japan.
   [Lefor, Alan Kawarai] Jichi Med Univ, Dept Surg, Shimotsuke, Tochigi 3290498, Japan.
RP Sakamoto, T (corresponding author), Japanese Fdn Canc Res, Canc Inst Hosp, Gastroenterol Ctr, Dept Gastroenterol Surg,Koto Ku, 3-8-31 Ariake, Tokyo 1358550, Japan.; Sakamoto, T (corresponding author), Univ Tokyo, Sch Publ Hlth, Dept Clin Epidemiol & Hlth Econ, Bunkyo Ku, Tokyo 1130033, Japan.
EM sakamoto-kob@umin.ac.jp
RI Sakamoto, Takashi/W-5693-2019
OI Sakamoto, Takashi/0000-0001-7483-9704
NR 77
TC 1
Z9 1
U1 3
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0941-1291
EI 1436-2813
J9 SURG TODAY
JI Surg. Today
DI 10.1007/s00595-021-02380-9
EA SEP 2021
PG 13
WC Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Surgery
GA UU5TV
UT WOS:000698863300001
PM 34559310
DA 2022-04-17
ER

PT J
AU Opu, MNI
   Islam, MR
   Kabir, MA
   Hossain, MS
   Islam, MM
AF Opu, Md. Nahidul Islam
   Islam, Md. Rakibul
   Kabir, Muhammad Ashad
   Hossain, Md. Sabir
   Islam, Mohammad Mainul
TI Learn2Write: Augmented Reality and Machine Learning-Based Mobile App to
   Learn Writing
SO COMPUTERS
LA English
DT Article
DE mobile app; augmented reality; machine learning; alphabet learning;
   handwriting recognition
ID RECOGNITION; TECHNOLOGIES
AB Augmented reality (AR) has been widely used in education, particularly for child education. This paper presents the design and implementation of a novel mobile app, Learn2Write, using machine learning techniques and augmented reality to teach alphabet writing. The app has two main features: (i) guided learning to teach users how to write the alphabet and (ii) on-screen and AR-based handwriting testing using machine learning. A learner needs to write on the mobile screen in on-screen testing, whereas AR-based testing allows one to evaluate writing on paper or a board in a real world environment. We implement a novel approach to use machine learning for AR-based testing to detect an alphabet written on a board or paper. It detects the handwritten alphabet using our developed machine learning model. After that, a 3D model of that alphabet appears on the screen with its pronunciation/sound. The key benefit of our approach is that it allows the learner to use a handwritten alphabet. As we have used marker-less augmented reality, it does not require a static image as a marker. The app was built with ARCore SDK for Unity. We further evaluated and quantified the performance of our app on multiple devices.
C1 [Opu, Md. Nahidul Islam; Islam, Md. Rakibul; Hossain, Md. Sabir] Chittagong Univ Engn & Technol, Dept Comp Sci & Engn, Chottogram 4349, Bangladesh.
   [Kabir, Muhammad Ashad] Charles Sturt Univ, Sch Comp Math & Engn, Data Sci Res Unit, Bathurst, NSW 2795, Australia.
   [Islam, Mohammad Mainul] Verizon Media Australia, Sydney, NSW 2015, Australia.
RP Kabir, MA (corresponding author), Charles Sturt Univ, Sch Comp Math & Engn, Data Sci Res Unit, Bathurst, NSW 2795, Australia.
EM u1604073@student.cuet.ac.bd; u1604060@student.cuet.ac.bd;
   akabir@csu.edu.au; sabir.cse@cuet.ac.bd; sujan.cse.cuet@gmail.com
RI Hossain, Md. Sabir/AAZ-9460-2021
OI Hossain, Md. Sabir/0000-0003-4545-6872; Kabir, Muhammad
   Ashad/0000-0002-6798-6535
NR 41
TC 0
Z9 0
U1 2
U2 2
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 2073-431X
J9 COMPUTERS
JI Computers
PD JAN
PY 2022
VL 11
IS 1
AR 4
DI 10.3390/computers11010004
PG 12
WC Computer Science, Interdisciplinary Applications
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YN3NW
UT WOS:000747169000001
OA gold
DA 2022-04-17
ER

PT J
AU Seo, W
   Kim, N
   Lee, SK
   Park, SM
AF Seo, Wonju
   Kim, Namho
   Lee, Sang-Kyu
   Park, Sung-Min
TI Machine learning-based analysis of adolescent gambling factors
SO JOURNAL OF BEHAVIORAL ADDICTIONS
LA English
DT Article
DE adolescents; problem gambling; machine learning-based analysis method;
   feature engineering
ID GAMBLERS
AB Background and aims: Problem gambling among adolescents has recently attracted attention because of easy access to gambling in online environments and its serious effects on adolescent lives. We proposed a machine learning-based analysis method for predicting the degree of problem gambling. Methods: Of the 17,520 respondents in the 2018 National Survey on Youth Gambling Problems dataset (collected by the Korea Center on Gambling Problems), 5,045 students who had gambled in the past 3 months were included in this study. The Gambling Problem Severity Scale was used to provide the binary label information. After the random forest-based feature selection method, we trained four models: random forest (RF), support vector machine (SVM), extra trees (ETs), and ridge regression. Results: The online gambling behavior in the past 3 months, experience of winning money or goods, and gambling of personal relationship were three factors exhibiting the high feature importance. All four models demonstrated an area under the curve (AUC) of >0.7; ET showed the highest AUC (0.755), RF demonstrated the highest accuracy (71.8%), and SVM showed the highest F1 score (0.507) on a testing set. Discussion: The results indicate that machine learning models can convey meaningful information to support predictions regarding the degree of problem gambling. Conclusion: Machine learning models trained using important features showed moderate accuracy in a large-scale Korean adolescent dataset. These findings suggest that the method will help screen adolescents at risk of problem gambling. We believe that expandable machine learning-based approaches will become more powerful as more datasets are collected.
C1 [Seo, Wonju; Kim, Namho; Park, Sung-Min] Pohang Univ Sci & Technol, Dept Creat IT Engn, 77 Cheongam Ro, Pohang 37673, South Korea.
   [Lee, Sang-Kyu] Hallym Univ, Coll Med, Dept Psychol, 1 Hallymdaehak Gil, Chunchon 24252, South Korea.
RP Park, SM (corresponding author), Pohang Univ Sci & Technol, Dept Creat IT Engn, 77 Cheongam Ro, Pohang 37673, South Korea.; Lee, SK (corresponding author), Hallym Univ, Coll Med, Dept Psychol, 1 Hallymdaehak Gil, Chunchon 24252, South Korea.
EM skmind@hallym.ac.kr; sungminpark@postech.ac.kr
OI Park, Sung-Min/0000-0002-8359-8110
FU Ministry of Science and ICT (MSIT), Korea, under the ICT Consilience
   Creative program [IITP-2020-2011-1-00783]; Basic Science Research
   Program through the National Research Foundation of Korea (NRF) -
   Ministry of Science and ICT [NRF-2017R1A5A1015596]; Technology
   Innovation Program - Ministry of Trade, Industry and Energy (MOTIE,
   Korea) [20001841]; National Research Foundation of Korea (NRF) - Korea
   government (MSIT) [2020R1A2C2005385]
FX This research was supported by the Ministry of Science and ICT (MSIT),
   Korea, under the ICT Consilience Creative program
   (IITP-2020-2011-1-00783) supervised by the Institute for Information and
   communications Technology Promotion (IITP), the Basic Science Research
   Program through the National Research Foundation of Korea (NRF) funded
   by the Ministry of Science and ICT (NRF-2017R1A5A1015596), the
   Technology Innovation Program (or Industrial Strategic Technology
   Development Program, 20001841, Development of System for Intelligent
   ContextAware Wearable Service based on Machine Learning) funded By the
   Ministry of Trade, Industry and Energy (MOTIE, Korea), and National
   Research Foundation of Korea (NRF) grant funded by the Korea government
   (MSIT) (No. 2020R1A2C2005385). The funding sources had no role in the
   study design, collection, analysis or interpretation of the data,
   writing the manuscript, or the decision to submit the paper for
   publication.
NR 46
TC 0
Z9 0
U1 2
U2 5
PU AKADEMIAI KIADO ZRT
PI BUDAPEST
PA BUDAFOKI UT 187-189-A-3, H-1117 BUDAPEST, HUNGARY
SN 2062-5871
EI 2063-5303
J9 J BEHAV ADDICT
JI J. Behav. Addict.
PD SEP
PY 2020
VL 9
IS 3
BP 734
EP 743
DI 10.1556/2006.2020.00063
PG 10
WC Psychiatry
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Psychiatry
GA OA0WH
UT WOS:000577516600018
PM 33011712
OA gold, Green Accepted
DA 2022-04-17
ER

PT J
AU Bhavsar, KA
   Singla, J
   Al-Otaibi, YD
   Song, OY
   Bin Zikriya, Y
   Bashir, AK
AF Bhavsar, Kaustubh Arun
   Singla, Jimmy
   Al-Otaibi, Yasser D.
   Song, Oh-Young
   Bin Zikriya, Yousaf
   Bashir, Ali Kashif
TI Medical Diagnosis Using Machine Learning: A Statistical Review
SO CMC-COMPUTERS MATERIALS & CONTINUA
LA English
DT Review
DE Decision making; disease diagnosis; machine learning; medical
   disciplines
ID SUPPORT VECTOR MACHINE; ARTIFICIAL-INTELLIGENCE; PREDICTION;
   CLASSIFICATION
AB Decision making in case of medical diagnosis is a complicated process. A large number of overlapping structures and cases, and distractions, tiredness, and limitations with the human visual system can lead to inappropriate diagnosis. Machine learning (ML) methods have been employed to assist clinicians in overcoming these limitations and in making informed and correct decisions in disease diagnosis. Many academic papers involving the use of machine learning for disease diagnosis have been increasingly getting published. Hence, to determine the use of ML to improve the diagnosis in varied medical disciplines, a systematic review is conducted in this study. To carry out the review, six different databases are selected. Inclusion and exclusion criteria are employed to limit the research. Further, the eligible articles are classified depending on publication year, authors, type of articles, research objective, inputs and outputs, problem and research gaps, and findings and results. Then the selected articles are analyzed to show the impact of ML methods in improving the disease diagnosis. The findings of this study show the most used ML methods and the most common diseases that are focused on by researchers. It also shows the increase in use of machine learning for disease diagnosis over the years. These results will help in focusing on those areas which are neglected and also to determine various ways in which ML methods could be employed to achieve desirable results.
C1 [Bhavsar, Kaustubh Arun; Singla, Jimmy] Lovely Profess Univ, Jalandhar 144411, Punjab, India.
   [Al-Otaibi, Yasser D.] King Abdulaziz Univ, Fac Comp & Informat Technol Rabigh, Dept Informat Syst, Jeddah 21589, Saudi Arabia.
   [Song, Oh-Young] Sejong Univ, Software Dept, Seoul 05006, South Korea.
   [Bin Zikriya, Yousaf] Yeungnam Univ, Dept Informat & Commun Engn, Gyongsan 38541, South Korea.
   [Bashir, Ali Kashif] Manchester Metropolitan Univ, Dept Comp & Math, Manchester M15 6BH, Lancs, England.
RP Song, OY (corresponding author), Sejong Univ, Software Dept, Seoul 05006, South Korea.
EM oysong@sejong.edu
RI Bashir, Ali Kashif/R-4015-2019; Al-Otaibi, Yasser D./S-5822-2018
OI Bashir, Ali Kashif/0000-0003-2601-9327; Al-Otaibi, Yasser
   D./0000-0002-1464-8401
FU MSIT (Ministry of Science and ICT), Korea, under the ITRC (Information
   Technology Research Center) support program [IITP-2020-2016-0-00312];
   MSIP (Ministry of Science, ICT & Future Planning), Korea [2015-0-00938]
FX This research was supported in part by the MSIT (Ministry of Science and
   ICT), Korea, under the ITRC (Information Technology Research Center)
   support program (IITP-2020-2016-0-00312) supervised by the IITP
   (Institute for Information & Communications Technology Planning &
   Evaluation), and in part by the MSIP (Ministry of Science, ICT & Future
   Planning), Korea, under the National Program for Excellence in SW)
   (2015-0-00938) supervised by the IITP (Institute for Information &
   communications Technology Planning & Evaluation).
NR 80
TC 4
Z9 4
U1 12
U2 19
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1546-2218
EI 1546-2226
J9 CMC-COMPUT MATER CON
JI CMC-Comput. Mat. Contin.
PY 2021
VL 67
IS 1
BP 107
EP 125
DI 10.32604/cmc.2021.014604
PG 19
WC Computer Science, Information Systems; Materials Science,
   Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Materials Science
GA PT3EC
UT WOS:000608499100006
OA Green Accepted, gold
DA 2022-04-17
ER

PT J
AU Cai, JJ
AF Cai, Jianjun
TI Ship Electronic Information Identification Technology Based on Machine
   Learning
SO JOURNAL OF COASTAL RESEARCH
LA English
DT Article
DE Machine learning; electronic information; ship; identification
AB Aiming at the problem of low signal accuracy in the traditional electronic information recognition technology which is affected by noise, this paper proposes the research of ship electronic information recognition technology based on machine learning. On the basis of the designed WIFI radio frequency communication circuit, the BP neural network in machine learning technology is used to process the ship electronic information through training and learning. At the same time, the support vector classifier is trained to identify the ship electronic information. The experimental results show that: compared with the traditional ship electronic information recognition technology, the designed ship electronic information recognition technology based on machine learning has less noise in the signal and higher signal accuracy, indicating that the ship electronic information recognition technology based on machine learning is more suitable for the actual ship electronic information recognition.
C1 [Cai, Jianjun] Wuxi Inst Technol, Sch Internet Things Engn, Wuxi 214121, Jiangsu, Peoples R China.
RP Cai, JJ (corresponding author), Wuxi Inst Technol, Sch Internet Things Engn, Wuxi 214121, Jiangsu, Peoples R China.
EM cjj7894560@163.com
FU Top-notch Academic Programs Project of Jiangsu Higher Education
   Institutions [PPZY2015C240]
FX The study was supported by "The Top-notch Academic Programs Project of
   Jiangsu Higher Education Institutions (Grant No. PPZY2015C240)".
NR 13
TC 1
Z9 1
U1 8
U2 21
PU COASTAL EDUCATION & RESEARCH FOUNDATION
PI COCONUT CREEK
PA 5130 NW 54TH STREET, COCONUT CREEK, FL 33073 USA
SN 0749-0208
EI 1551-5036
J9 J COASTAL RES
JI J. Coast. Res.
PD SUM
PY 2020
SI 103
BP 770
EP 774
DI 10.2112/SI103-159.1
PG 5
WC Environmental Sciences; Geography, Physical; Geosciences,
   Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Environmental Sciences & Ecology; Physical Geography; Geology
GA MD1FK
UT WOS:000543720600159
DA 2022-04-17
ER

PT C
AU Takeshi, N
AF Takeshi, Nagata
BE Duan, B
   Umeda, K
   Hwang, W
TI Fast Blind Deconvolution with Simple Machine Learning
SO PROCEEDINGS OF THE SEVENTH ASIA INTERNATIONAL SYMPOSIUM ON MECHATRONICS,
   VOL II
SE Lecture Notes in Electrical Engineering
LA English
DT Proceedings Paper
CT 7th Asia International Symposium on Mechatronics (AISM)
CY SEP 19-22, 2019
CL Hangzhou, PEOPLES R CHINA
SP Chinese Inst Elect, Japan Socr Precis Engn, Hangzhou Dianzi Univ
DE Machine learning; Debulurring; Blind deconvolution
ID REGRESSION
AB We show that very fast deblurring can be achieved with simple machine learning. The most difficult step in deblurring is the estimation of the blur kernel. We show that we can estimate the blur kernel by recognizing the object.
C1 [Takeshi, Nagata] Mizuho Informat & Res Inst Inc MHIR, Informat & Commun Res Div, Tokyo, Japan.
RP Takeshi, N (corresponding author), Mizuho Informat & Res Inst Inc MHIR, Informat & Commun Res Div, Tokyo, Japan.
EM takeshinagata@mizuho-ir.co.jp
NR 14
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER-VERLAG SINGAPORE PTE LTD
PI SINGAPORE
PA 152 BEACH ROAD, #21-01/04 GATEWAY EAST, SINGAPORE, 189721, SINGAPORE
SN 1876-1100
EI 1876-1119
BN 978-981-32-9441-7; 978-981-32-9440-0
J9 LECT NOTES ELECTR EN
PY 2020
VL 589
BP 967
EP 975
DI 10.1007/978-981-32-9441-7_99
PG 9
WC Automation & Control Systems; Engineering, Electrical & Electronic;
   Engineering, Mechanical; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Automation & Control Systems; Engineering; Telecommunications
GA BQ6PT
UT WOS:000612991300099
DA 2022-04-17
ER

PT J
AU Virkkunen, I
   Koskinen, T
   Jessen-Juhler, O
   Rinta-aho, J
AF Virkkunen, Iikka
   Koskinen, Tuomas
   Jessen-Juhler, Oskari
   Rinta-aho, Jari
TI Augmented Ultrasonic Data for Machine Learning
SO JOURNAL OF NONDESTRUCTIVE EVALUATION
LA English
DT Article
DE Machine learning; NDT; Ultrasonic inspection; Data augmentation; Virtual
   flaws
ID NEURAL-NETWORK; FLAW-CLASSIFICATION; DEFECT DETECTION; SYSTEM; CRACKS
AB Flaw detection in non-destructive testing, especially for complex signals like ultrasonic data, has thus far relied heavily on the expertise and judgement of trained human inspectors. While automated systems have been used for a long time, these have mostly been limited to using simple decision automation, such as signal amplitude threshold. The recent advances in various machine learning algorithms have solved many similarly difficult classification problems, that have previously been considered intractable. For non-destructive testing, encouraging results have already been reported in the open literature, but the use of machine learning is still very limited in NDT applications in the field. Key issue hindering their use, is the limited availability of representative flawed data-sets to be used for training. In the present paper, we develop modern, deep convolutional network to detect flaws from phased-array ultrasonic data. We make extensive use of data augmentation to enhance the initially limited raw data and to aid learning. The data augmentation utilizes virtual flaws-a technique, that has successfully been used in training human inspectors and is soon to be used in nuclear inspection qualification. The results from the machine learning classifier are compared to human performance. We show, that using sophisticated data augmentation, modern deep learning networks can be trained to achieve human-level performance.
C1 [Virkkunen, Iikka] Aalto Univ, Espoo, Finland.
   [Koskinen, Tuomas; Jessen-Juhler, Oskari; Rinta-aho, Jari] VTT Tech Res Ctr Finland Ltd, Espoo, Finland.
RP Virkkunen, I (corresponding author), Aalto Univ, Espoo, Finland.
EM iikka.virkkunen@aalto.fi
OI Virkkunen, Iikka/0000-0002-6096-3939
NR 39
TC 15
Z9 15
U1 13
U2 19
PU SPRINGER/PLENUM PUBLISHERS
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0195-9298
EI 1573-4862
J9 J NONDESTRUCT EVAL
JI J. Nondestruct. Eval.
PD MAR
PY 2021
VL 40
IS 1
AR 4
DI 10.1007/s10921-020-00739-5
PG 11
WC Materials Science, Characterization & Testing
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Materials Science
GA PN1LP
UT WOS:000604248200001
OA Green Submitted, Green Accepted, hybrid
DA 2022-04-17
ER

PT J
AU Salas-Rueda, RA
AF Salas-Rueda, Ricardo-Adan
TI Perception of students on blended learning considering data science and
   machine learning
SO CAMPUS VIRTUALES
LA English
DT Article
DE blended learning; higher education; Data science; Machine learning;
   Technology; ICT
ID ONLINE; ENVIRONMENT; CLASSROOM; QUALITY; INQUIRY; DESIGN
AB This quantitative research aims to analyze the impact of audiovisual contents, discussion forums and online evaluations in the blended learning modality through data science and machine learning. The sample is composed of 106 students from the careers of Administration, Commerce, Accounting, Marketing and Systems. The results of machine learning (linear regression) indicate that audiovisual contents, discussion forums and online evaluations in the blended learning modality positively influence the teaching-learning process. on the other hand, data science identified 3 predictive models on the use of blended learning by means of the decision tree technique. This research recommends the incorporation of the blended learning modality during the planning and organization of school courses in order to develop the competencies of the students. finally, blended learning represents an alternative to improve teaching-learning conditions in the 21st century through the performance of synchronous and asynchronous school activities.
C1 [Salas-Rueda, Ricardo-Adan] Univ Nacl Autonoma Mexico, Mexico City, DF, Mexico.
RP Salas-Rueda, RA (corresponding author), Univ Nacl Autonoma Mexico, Mexico City, DF, Mexico.
EM ricardo.salas@icat.unam.mx
NR 35
TC 1
Z9 1
U1 8
U2 11
PU RED UNIV CAMPUS VIRTUALES
PI HUELVA
PA AVENIDA DE MARZO, HUELVA, 21071, SPAIN
SN 2255-1514
J9 CAMPUS VIRTUALES
JI Campus Virtuales
PD MAR
PY 2020
VL 9
IS 1
BP 125
EP 135
PG 11
WC Education & Educational Research
WE Emerging Sources Citation Index (ESCI)
SC Education & Educational Research
GA KY4UO
UT WOS:000522564400011
DA 2022-04-17
ER

PT J
AU Mashrur, A
   Luo, W
   Zaidi, NA
   Robles-Kelly, A
AF Mashrur, Akib
   Luo, Wei
   Zaidi, Nayyar A.
   Robles-Kelly, Antonio
TI Machine Learning for Financial Risk Management: A Survey
SO IEEE ACCESS
LA English
DT Article
DE Machine learning; deep learning; financial risk management; financial
   risk management taxonomy; risk analysis; artificial intelligence in
   finance
ID CREDIT CARD FRAUD; STOCK-MARKET PREDICTION; SUPPORT VECTOR MACHINES;
   STOCHASTIC MORTALITY; NEURAL-NETWORKS; DECISION TREE; BLACK-BOX;
   VOLATILITY; MODELS; INSURANCE
AB Financial risk management avoids losses and maximizes profits, and hence is vital to most businesses. As the task relies heavily on information-driven decision making, machine learning is a promising source for new methods and technologies. In recent years, we have seen increasing adoption of machine learning methods for various risk management tasks. Machine-learning researchers, however, often struggle to navigate the vast and complex domain knowledge and the fast-evolving literature. This paper fills this gap, by providing a systematic survey of the rapidly growing literature of machine learning research for financial risk management. The contributions of the paper are four-folds: First, we present a taxonomy of financial-risk-management tasks and connect them with relevant machine learning methods. Secondly, we highlight significant publications in the past decade. Thirdly, we identify major challenges being faced by researchers in this area. And finally, we point out emerging trends and promising research directions.
C1 [Mashrur, Akib; Luo, Wei; Zaidi, Nayyar A.; Robles-Kelly, Antonio] Deakin Univ, Sch Informat Technol, Geelong, Vic 3216, Australia.
RP Mashrur, A (corresponding author), Deakin Univ, Sch Informat Technol, Geelong, Vic 3216, Australia.
EM amashrur@deakin.edu.au
RI Luo, Wei/A-6043-2011
OI Luo, Wei/0000-0002-4711-7543; Mashrur, Akib/0000-0002-4404-7471; Zaidi,
   Nayyar/0000-0003-4024-2517
NR 235
TC 4
Z9 4
U1 44
U2 67
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 203203
EP 203223
DI 10.1109/ACCESS.2020.3036322
PG 21
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Telecommunications
GA OS8XM
UT WOS:000590441600001
OA gold
DA 2022-04-17
ER

PT C
AU Rawat, D
AF Rawat, Danda
BE Pham, T
   Solomon, L
TI Secure and Trustworthy Machine Learning/Artificial Intelligence for
   Multi-Domain Operations
SO ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING FOR MULTI-DOMAIN OPERATIONS
   APPLICATIONS III
SE Proceedings of SPIE
LA English
DT Proceedings Paper
CT Conference on Artificial Intelligence and Machine Learning for
   Multi-Domain Operations Applications III
CY APR 12-16, 2021
CL ELECTR NETWORK
SP SPIE
DE Secure AI/ML; ML/AI Assurance; Trustworthy AI/ML; Multi Domain
   Operation; Resilient AI
ID BLOCKCHAIN; VEHICLES
AB Machine Learning (ML) algorithms and Artificial Intelligence (AI) systems have already had an immense impact on our society as they have shown to be able to create machine cognition comparable to or even better than human cognition for some applications. ML algorithms are now regarded as very useful for data-driven applications including resilient multi-domain operations. However, ML algorithms and AI systems can be controlled, dodged, biased, and misled through flawed learning models and input data, they need robust security features and trust. Furthermore, ML algorithms and AI systems add challenges when we have (unlabeled/labeled) sparse/small data or big data for training and evaluation. It is very important to design, evaluate and test ML algorithms and AI systems that produce reliable, robust, trustworthy, explainable, and fair/unbiased outcomes to make them acceptable and reliable in mission critical multi-domain operations. ML algorithms rely on data and work on the principle of "Garbage In, Garbage Out," which means that if the input data to learning model is corrupted or compromised, the outcomes of the ML/AI would not be optimal, reliable and trustworthy. This paper focuses on achieving secure and trustworthy machine learning and artificial intelligence operations using context aware selection of learning models and blockchain for multi-domain battlefield operations.
C1 [Rawat, Danda] Howard Univ, Ctr Excellence AI ML CoE AI ML, Dept Elect Engn & Comp Sci, Washington, DC 20059 USA.
RP Rawat, D (corresponding author), Howard Univ, Ctr Excellence AI ML CoE AI ML, Dept Elect Engn & Comp Sci, Washington, DC 20059 USA.
EM danda.rawat@howard.edu
RI Rawat, Danda B./B-2973-2012
OI Rawat, Danda B./0000-0003-3638-3464
FU DoD Center of Excellence in AI and Machine Learning (CoE-AIML) at Howard
   University [W911NF-20-2-0277]; U.S. Army Research LaboratoryUnited
   States Department of DefenseUS Army Research Laboratory (ARL)
FX This work was supported in part by the DoD Center of Excellence in AI
   and Machine Learning (CoE-AIML) at Howard University under Contract
   Number W911NF-20-2-0277 with the U.S. Army Research Laboratory. However,
   any opinion, finding, and conclusions or recommendations expressed in
   this material are those of the author and do not necessarily reflect the
   views of the funding agency.
NR 47
TC 0
Z9 0
U1 10
U2 10
PU SPIE-INT SOC OPTICAL ENGINEERING
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA
SN 0277-786X
EI 1996-756X
BN 978-1-5106-4330-7
J9 PROC SPIE
PY 2021
VL 11746
AR 1174609
DI 10.1117/12.2592860
PG 11
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA BS2PQ
UT WOS:000705912400004
DA 2022-04-17
ER

PT J
AU Zhang, KY
   Wang, JW
   Liu, TY
   Luo, YF
   Loh, XJ
   Chen, XD
AF Zhang, Kaiyi
   Wang, Jianwu
   Liu, Tianyi
   Luo, Yifei
   Loh, Xian Jun
   Chen, Xiaodong
TI Machine Learning-Reinforced Noninvasive Biosensors for Healthcare
SO ADVANCED HEALTHCARE MATERIALS
LA English
DT Review
DE clinical practice; data processing; food safety; machine learning;
   noninvasive biosensors; physiology
ID CONVOLUTIONAL NEURAL-NETWORK; ELECTRONIC NOSE; COLORIMETRIC BIOSENSOR;
   FOOD QUALITY; BLOOD-FLOW; LOW-COST; AGE; DISEASE; BREATH; SYSTEM
AB The emergence and development of noninvasive biosensors largely facilitate the collection of physiological signals and the processing of health-related data. The utilization of appropriate machine learning algorithms improves the accuracy and efficiency of biosensors. Machine learning-reinforced biosensors are started to use in clinical practice, health monitoring, and food safety, bringing a digital revolution in healthcare. Herein, the recent advances in machine learning-reinforced noninvasive biosensors applied in healthcare are summarized. First, different types of noninvasive biosensors and physiological signals collected are categorized and summarized. Then machine learning algorithms adopted in subsequent data processing are introduced and their practical applications in biosensors are reviewed. Finally, the challenges faced by machine learning-reinforced biosensors are raised, including data privacy and adaptive learning capability, and their prospects in real-time monitoring, out-of-clinic diagnosis, and onsite food safety detection are proposed.
C1 [Zhang, Kaiyi; Wang, Jianwu; Liu, Tianyi; Luo, Yifei; Chen, Xiaodong] Nanyang Technol Univ, Sch Mat Sci & Engn, Innovat Ctr Flexible Devices iFLEX, Max Planck NTU Joint Lab Artificial Senses, 50 Nanyang Ave, Singapore 639798, Singapore.
   [Luo, Yifei; Loh, Xian Jun; Chen, Xiaodong] ASTAR, Inst Mat Res & Engn, 2 Fusionopolis Way,Innovis 08-03, Singapore 138634, Singapore.
RP Chen, XD (corresponding author), Nanyang Technol Univ, Sch Mat Sci & Engn, Innovat Ctr Flexible Devices iFLEX, Max Planck NTU Joint Lab Artificial Senses, 50 Nanyang Ave, Singapore 639798, Singapore.; Chen, XD (corresponding author), ASTAR, Inst Mat Res & Engn, 2 Fusionopolis Way,Innovis 08-03, Singapore 138634, Singapore.
EM chenxd@ntu.edu.sg
RI Chen, Xiaodong/A-4537-2009; Luo, Yifei/AAU-4334-2021; Loh, Xian
   Jun/H-6260-2013
OI Chen, Xiaodong/0000-0002-3312-1664; Luo, Yifei/0000-0002-4454-6318; Loh,
   Xian Jun/0000-0001-8118-6502
FU Agency for Science, Technology and Research (A*STAR) under its AME
   Programmatic Funding SchemeAgency for Science Technology & Research
   (ASTAR) [A18A1b0045]; National Research Foundation (NRF), Prime
   Minister's Office, Singapore, under its NRF InvestigatorshipNational
   Research Foundation, Singapore [NRF-NRFI2017-07]; Singapore Ministry of
   EducationMinistry of Education, Singapore [MOE2019-T2-2-022]
FX The authors thank the financial support from the Agency for Science,
   Technology and Research (A*STAR) under its AME Programmatic Funding
   Scheme (project no. A18A1b0045), the National Research Foundation (NRF),
   Prime Minister's Office, Singapore, under its NRF Investigatorship
   (NRF-NRFI2017-07), and Singapore Ministry of Education
   (MOE2019-T2-2-022).
NR 212
TC 4
Z9 4
U1 31
U2 46
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 2192-2640
EI 2192-2659
J9 ADV HEALTHC MATER
JI Adv. Healthc. Mater.
PD SEP
PY 2021
VL 10
IS 17
SI SI
AR 2100734
DI 10.1002/adhm.202100734
EA JUN 2021
PG 18
WC Engineering, Biomedical; Nanoscience & Nanotechnology; Materials
   Science, Biomaterials
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Science & Technology - Other Topics; Materials Science
GA UP6FN
UT WOS:000664988000001
PM 34165240
DA 2022-04-17
ER

PT C
AU Benevento, G
   De Prisco, R
   Guarino, A
   Lettieri, N
   Malandrino, D
   Zaccagnino, R
AF Benevento, Gerardo
   De Prisco, Roberto
   Guarino, Alfonso
   Lettieri, Nicola
   Malandrino, Delfina
   Zaccagnino, Rocco
BE Banissi, E
   Khosrow-Shahi, F
   Ursyn, A
   Bannatyne, MWM
   Pires, JM
   Datia, N
   Nazemi, K
   Kovalerchuk, B
   Counsell, J
   Agapiou, A
   Vrcelj, Z
   Chau, HW
   Li, MB
   Nagy, G
   Laing, R
   Francese, R
   Sarfraz, M
   Bouali, F
   Venturini, G
   Trutschl, M
   Cvek, U
   Muller, H
   Nakayama, M
   Temperini, M
   DiMascio, T
   Sciarrone, F
   Rossano, V
   Dorner, R
   Caruccio, L
   Vitiello, A
   Huang, WD
   Risi, M
   Erra, U
   Andonie, R
   Ahmad, MA
   Figueiras, A
   Cuzzocrea, A
   Mabakane, MS
TI Human-Machine Teaming in Music: anchored narrative-graph Visualization
   and Machine Learning
SO 2020 24TH INTERNATIONAL CONFERENCE INFORMATION VISUALISATION (IV 2020)
SE IEEE International Conference on Information Visualization
LA English
DT Proceedings Paper
CT 24th International Conference Information Visualisation (IV)
CY SEP 07-11, 2020
CL ELECTR NETWORK
DE Interactive Visualization; Machine Learning; Music analysis
ID INTERACTIVE VISUALIZATION
AB During the traditional music analysis process, stylistic rules usually have to be deduced directly from examples of compositions or past performance. In such cases, musicians create external representations of a music style domain as source for reflection, inspiration and collaboration. However, due to the large number of music examples, creating such representations can be essential, but at the same time, slow and costly.
   In this paper, we show that interactive visualization and machine learning could aid in supporting and enhancing musician cognition and team-based collaboration. Specifically, we propose an approach to this problem which: (1) allows musicians to visually externalize their evolving mental models of a music domain, in the form of thematically organized anchored pairs. i.e., (narrative, graph), each one corresponding to a specific music pattern, and (2) uses such pairs to develop a music style classification system based on machine learning, as support for musicians during their activities (composition, performance). To this end, we introduce a novel graph representation of music stylistic patterns and discuss the advantages of linking such a representation to machine learning. Results of a preliminary study involving 10 musicians provided us with overall positive feedback about the effectiveness of our approach as well as further directions to explore.
C1 [Benevento, Gerardo; De Prisco, Roberto; Guarino, Alfonso; Malandrino, Delfina; Zaccagnino, Rocco] Univ Salerno, Comp Sci Dept, I-84084 Fisciano, SA, Italy.
   [Lettieri, Nicola] Natl Inst Publ Policy Anal, I-00198 Rome, Italy.
RP Benevento, G (corresponding author), Univ Salerno, Comp Sci Dept, I-84084 Fisciano, SA, Italy.
EM g.benevento7@studenti.unisa.it; robdep@unisa.it; alguarino@unisa.it;
   n.lettieri@inapp.org; dmalandrino@unisa.it; rzaccagnino@unisa.it
OI Malandrino, Delfina/0000-0003-2693-0196; Zaccagnino,
   Rocco/0000-0002-9089-5957
NR 20
TC 1
Z9 1
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1550-6037
EI 2375-0138
BN 978-1-7281-9134-8
J9 IEEE INT CONF INF VI
PY 2020
BP 559
EP 564
DI 10.1109/IV51561.2020.00095
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Interdisciplinary Applications; Computer
   Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS3JO
UT WOS:000712013300085
DA 2022-04-17
ER

PT J
AU Lee, TR
   Teh, JS
   Jamil, N
   Yan, JLS
   Chen, JG
AF Lee, Ting Rong
   Teh, Je Sen
   Jamil, Norziana
   Yan, Jasy Liew Suet
   Chen, Jiageng
TI Lightweight Block Cipher Security Evaluation Based on Machine Learning
   Classifiers and Active S-Boxes
SO IEEE ACCESS
LA English
DT Article
DE Ciphers; Cryptography; Security; Deep learning; Machine learning
   algorithms; Neural networks; Training; Active S-boxes; block cipher;
   cryptanalysis; machine learning; differential cryptanalysis; lightweight
   cryptography; TWINE
AB Machine learning has recently started to gain the attention of cryptographic researchers, notably in block cipher cryptanalysis. Most of these machine learning-based approaches are black box attacks that are cipher-specific. Thus, more research is required to understand the capabilities and limitations of machine learning when being used to evaluate block cipher security. We contribute to this body of knowledge by investigating the capability of linear and nonlinear machine learning classifiers in evaluating block cipher security. We frame block cipher security evaluation as a classification problem, whereby the machine learning models attempt to classify a given block cipher output as secure or insecure based on the number of active S-boxes. We also train the machine learning models with common block cipher features such as truncated differences, the number of rounds, and permutation pattern. Various experiments were performed on small-scale (4-branch) generalized Feistel ciphers to identify the best performing machine learning model for the given security evaluation problem. Results show that nonlinear machine learning models outperform linear models, achieving a prediction accuracy of up to 93% when evaluating inputs from ciphers that they have seen before during training. When evaluating inputs from other unseen ciphers, nonlinear models again outperformed linear models with an accuracy of up to 71%. We then showcase the feasibility of our approach when used to evaluate a real-world 16-branch generalized Feistel cipher, TWINE. By training the best performing nonlinear classifiers (k-nearest neighbour and decision tree) using data from other similar ciphers, the nonlinear classifiers achieved a 74% accuracy when evaluating differential data generated from TWINE. In addition, the trained classifiers were capable of generalizing to a larger number of rounds than they were trained for. Our findings showcase the feasibility of using simple machine learning classifiers as a security evaluation tool to assess block cipher security.
C1 [Lee, Ting Rong; Teh, Je Sen; Yan, Jasy Liew Suet] Univ Sains Malaysia, Sch Comp Sci, Gelugor 11800, Malaysia.
   [Jamil, Norziana] Univ Tenaga Nas, Dept Comp, Coll Comp & Informat, Kajang 43000, Malaysia.
   [Chen, Jiageng] Cent China Normal Univ, Sch Comp Sci, Wuhan 430079, Peoples R China.
RP Teh, JS (corresponding author), Univ Sains Malaysia, Sch Comp Sci, Gelugor 11800, Malaysia.; Jamil, N (corresponding author), Univ Tenaga Nas, Dept Comp, Coll Comp & Informat, Kajang 43000, Malaysia.
EM jesen_teh@usm.my; norziana@uniten.edu.my
RI LIEW, JASY SUET YAN/R-3953-2016; Teh, Je Sen/B-7368-2018
OI LIEW, JASY SUET YAN/0000-0001-7362-7507; Teh, Je
   Sen/0000-0001-5571-4148; , Norziana/0000-0002-7363-1466
FU Uniten BOLD2025 Research Grant 2019; Uniten BOLD Publication Fund 2021
FX This work was supported in part by the Uniten BOLD2025 Research Grant
   2019 titled ``A design of machine learning approach to cryptanalyze
   lightweight block ciphers,'' and in part by the Uniten BOLD Publication
   Fund 2021.
NR 28
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 134052
EP 134064
DI 10.1109/ACCESS.2021.3116468
PG 13
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA WC2NJ
UT WOS:000704098300001
OA gold
DA 2022-04-17
ER

PT C
AU Ramezani, SB
   Sommers, A
   Manchukonda, HK
   Rahimi, S
   Amirlatifi, A
AF Ramezani, Somayeh Bakhtiari
   Sommers, Alexander
   Manchukonda, Harish Kumar
   Rahimi, Shahram
   Amirlatifi, Amin
GP IEEE
TI Machine Learning Algorithms in Quantum Computing: A Survey
SO 2020 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
LA English
DT Proceedings Paper
CT International Joint Conference on Neural Networks (IJCNN) held as part
   of the IEEE World Congress on Computational Intelligence (IEEE WCCI)
CY JUL 19-24, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Computat Intelligence Soc, Int Neural Network Soc
DE Machine Learning; Quantum Computing; Algorithms
ID MECHANICS
AB Machine Learning (ML) aims at designing models that learn from previous experience, without being explicitly formulated. Applications of machine learning are inexhaustible, including recognizing patterns, predicting future trends and making decisions, and they are capable of handling sizable quantities of multi-dimensional data in the form of large vectors and tensors. To perform these operations on classical computers, however, requires vast time and computational resources. Unlike the classical computers that rely on computations using binary bits, Quantum Computers (QC) benefit from qubits which can hold combinations of 0 and 1 at the same time via superposition and entanglement. This makes QCs powerful at handling and post processing large tensors, making them a prime target for implementing ML algorithms. While several models used for ML on QCs are based on concepts from their classical computing counterparts, utilization of the QC's potential has made them the superior of the two. This paper presents an overview of the current state of knowledge in application of ML on QC, and evaluates the speed up, and complexity advantages of using quantum machines.
C1 [Ramezani, Somayeh Bakhtiari; Sommers, Alexander; Manchukonda, Harish Kumar; Rahimi, Shahram] Mississippi State Univ, Dept Comp Sci & Engn, Starkville, MS 39762 USA.
   [Amirlatifi, Amin] Mississippi State Univ, Dave C Swaim Sch Chem Eng, Starkville, MS USA.
RP Ramezani, SB (corresponding author), Mississippi State Univ, Dept Comp Sci & Engn, Starkville, MS 39762 USA.
EM sb3182@msstate.edu; ams1988@msstate.edu; hm1089@msstate.edu;
   sr2002@msstate.edu; aa2340@msstate.edu
RI Bakhtiari Ramezani, Somayeh/ABB-2172-2021; ramezani,
   somayeh/AAE-6110-2022
OI Bakhtiari Ramezani, Somayeh/0000-0002-5230-8723; ramezani,
   somayeh/0000-0002-8247-5637
NR 70
TC 1
Z9 1
U1 0
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2161-4393
BN 978-1-7281-6926-2
J9 IEEE IJCNN
PY 2020
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ9MM
UT WOS:000626021408093
DA 2022-04-17
ER

PT C
AU Simons, J
   Bhatti, SA
   Weller, A
AF Simons, Joshua
   Bhatti, Sophia Adams
   Weller, Adrian
GP ASSOC COMP MACHINERY
TI Machine Learning and the Meaning of Equal Treatment
SO AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND
   SOCIETY
LA English
DT Proceedings Paper
CT 4th AAAI/ACM Conference on AI, Ethics, and Society (AIES)
CY MAY 19-21, 2021
CL ELECTR NETWORK
SP AAAI, Assoc Comp Machinery, ACM SIGAI
DE equal treatment; fairness; philosophy; politics; machine learning
ID DISPARATE IMPACT; DATA PROTECTION; NEUTRALITY; PATHWAYS
AB Approaches to non-discrimination are generally informed by two principles: striving for equality of treatment, and advancing various notions of equality of outcome. We consider when and why there are trade-offs in machine learning between respecting formalistic interpretations of equal treatment and advancing equality of outcome. Exploring a hypothetical discrimination suit against Facebook, we argue that interpretations of equal treatment which require blindness to difference may constrain how machine learning can be deployed to advance equality of outcome. When machine learning models predict outcomes that are unevenly distributed across racial groups, using those models to advance racial justice will often require deliberately taking race into account.
   We then explore the normative stakes of this tension. We describe three pragmatic policy options underpinned by distinct interpretations and applications of equal treatment. A status quo approach insists on blindness to difference, permitting the design of machine learning models that compound existing patterns of disadvantage. An industry-led approach would specify a narrow set of domains in which institutions were permitted to use protected characteristics to actively reduce inequalities of outcome. A government-led approach would impose positive duties that require institutions to consider how best to advance equality of outcomes and permit the use of protected characteristics to achieve that goal. We argue that while machine learning offers significant possibilities for advancing racial justice and outcome-based equality, harnessing those possibilities will require a shift in the normative commitments that underpin the interpretation and application of equal treatment in non-discrimination law and the governance of machine learning.
C1 [Simons, Joshua] Harvard Univ, Cambridge, MA 02138 USA.
   [Bhatti, Sophia Adams] Wavelength Law, Cambridge, England.
   [Weller, Adrian] Univ Cambridge, Cambridge, England.
   [Weller, Adrian] Alan Turing Inst, London, England.
RP Simons, J (corresponding author), Harvard Univ, Cambridge, MA 02138 USA.
FU EPSRCUK Research & Innovation (UKRI)Engineering & Physical Sciences
   Research Council (EPSRC) [EP/N510129/1, TU/B/000074, EP/V025379/1];
   Leverhulme Trust via the CFI
FX Adrian Weller acknowledges support from a Turing AI Fellowship under
   grant EP/V025379/1, The Alan Turing Institute under EPSRC grant
   EP/N510129/1 and TU/B/000074, and the Leverhulme Trust via the CFI.
NR 102
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-8473-5
PY 2021
BP 956
EP 966
DI 10.1145/3461702.3462556
PG 11
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS7UX
UT WOS:000767973400105
OA Bronze
DA 2022-04-17
ER

PT C
AU Tai, YF
   Sun, ZY
   Yao, ZX
AF Tai, Yifan
   Sun, Zhenyu
   Yao, Zixuan
GP IEEE
TI CONTENT-BASED RECOMMENDATION USING MACHINE LEARNING
SO 2021 IEEE 31ST INTERNATIONAL WORKSHOP ON MACHINE LEARNING FOR SIGNAL
   PROCESSING (MLSP)
SE IEEE International Workshop on Machine Learning for Signal Processing
LA English
DT Proceedings Paper
CT IEEE 31st International Workshop on Machine Learning for Signal
   Processing (MLSP)
CY OCT 25-28, 2021
CL ELECTR NETWORK
SP IEEE
DE Recommender System; User Profile; Content-based Recommendation; LSTM;
   Machine Learning
ID SYSTEM
AB Currently,the user profile based online recommender system has become a hit both in research and engineering domain. Accurately capturing users' profile is the key of recommendation. Recently, lots of researches on user profile extraction have been launched, including content-based recommendation. To better capture users' profiles, a three-step profiling method is adopted in this work. (1) Purchase item prediction is made based on Logistic Regression. (2) Purchase category prediction is made based on support vector machine (SVM), and (3) User's rating prediction is made based on convolutional neural network (CNN) and Long Short-Term Memory (LSTM). This work outperformed the baseline model on the user dataset collected from Amazon. So, in conclusion, the work has the ability of giving reasonable recommendation for users who would like to purchase online. In the future, the video signal processing techniques will also be taken under consideration to capture users' face expression for better recommendation.
C1 [Tai, Yifan] Hefei Univ Technol, Hefei, Anhui, Peoples R China.
   [Sun, Zhenyu] Univ Sci & Technol Beijing, Beijing, Peoples R China.
   [Yao, Zixuan] Johns Hopkins Univ, Baltimore, MD USA.
RP Tai, YF (corresponding author), Hefei Univ Technol, Hefei, Anhui, Peoples R China.
EM tyf88525319@outlook.com; szy2267246060@163.com; zyao5@jhu.edu
NR 20
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2161-0363
BN 978-1-7281-6338-3
J9 IEEE INT WORKS MACH
PY 2021
DI 10.1109/MLSP52302.2021.9596525
PG 4
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BS7MI
UT WOS:000764097000088
DA 2022-04-17
ER

PT J
AU Jeon, HK
   Kim, JS
   Kim, BJ
   Kim, WJ
AF Jeon, Hang-Kyu
   Kim, Ji-Sun
   Kim, Bong-Ju
   Kim, Won-Jin
TI A study on the fault diagnosis of rotating machine by machine learning
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF KOREA
LA Korean
DT Article
DE Rotating machine; Machine learning; Artificial neural network; Genetic
   algorithm; Fault diagnosis
ID GENETIC ALGORITHM
AB In this study, a rotating machine that can reproduce normal condition and 8 fault conditions were produced, and vibration data was acquired. Feature is calculated from the acquired data, and accuracy is analyzed through fault diagnosis using artificial neural networks and genetic algorithms. In order to achieve optimal timing and higher accuracy, features by three domains were applied to the fault diagnosis. The learning number was selected as a setting variable. As a result of the rotating machine fault diagnosis, high precision was found in the frequency domain than in others, and precise fault diagnoses were accomplished through all of 10 operations, at the learning number of 5000 and 8000. Given the efficiency of time, it was estimated to be the most efficient when the number of learning was 5000.
C1 [Kim, Won-Jin] Keimyung Univ, Dept Mech & Automot Engn, 1095 Dalgubeol Daero, Daegu 42601, South Korea.
RP Kim, WJ (corresponding author), Keimyung Univ, Dept Mech & Automot Engn, 1095 Dalgubeol Daero, Daegu 42601, South Korea.
EM wjkim@kmu.ac.kr
NR 10
TC 0
Z9 0
U1 0
U2 0
PU ACOUSTICAL SOC KOREA
PI SEOUL
PA 2077, NAMBUSUNHWAN-RO, DONGJAK-GU, SEOUL, 07025, SOUTH KOREA
SN 1225-4428
EI 2287-3775
J9 J ACOUST SOC KOREA
JI J. Acoust. Soc. Korea
PY 2020
VL 39
IS 4
BP 263
EP 269
DI 10.7776/ASK.2020.39.4.263
PG 7
WC Acoustics
WE Emerging Sources Citation Index (ESCI)
SC Acoustics
GA OZ1OR
UT WOS:000594704500005
DA 2022-04-17
ER

PT J
AU Talwani, S
   Alhazmi, K
   Singla, J
   Alyamani, HJ
   Bashir, AK
AF Talwani, Suruchi
   Alhazmi, Khaled
   Singla, Jimmy
   Alyamani, Hasan J.
   Bashir, Ali Kashif
TI Allocation and Migration of Virtual Machines Using Machine Learning
SO CMC-COMPUTERS MATERIALS & CONTINUA
LA English
DT Article
DE Cloud computing; VM allocation; VM migration; machine learning
ID ENERGY-EFFICIENT; PERFORMANCE
AB Cloud computing promises the advent of a new era of service boosted by means of virtualization technology. The process of virtualization means creation of virtual infrastructure, devices, servers and computing resources needed to deploy an application smoothly. This extensively practiced technology involves selecting an efficient Virtual Machine (VM) to complete the task by transferring applications from Physical Machines (PM) to VM or from VM to VM. The whole process is very challenging not only in terms of computation but also in terms of energy and memory. This research paper presents an energy aware VM allocation and migration approach to meet the challenges faced by the growing number of cloud data centres. Machine Learning (ML) based Artificial Bee Colony (ABC) is used to rank the VM with respect to the load while considering the energy efficiency as a crucial parameter. The most efficient virtual machines are further selected and thus depending on the dynamics of the load and energy, applications are migrated from one VM to another. The simulation analysis is performed in Matlab and it shows that this research work results in more reduction in energy consumption as compared to existing studies.
C1 [Talwani, Suruchi; Singla, Jimmy] Lovely Profess Univ, Sch Comp Sci & Engn, Phagwara, Punjab, India.
   [Alhazmi, Khaled] King Abdulaziz City Sci & Technol KACST, Commun & Informat Technol Res Inst, Natl Ctr Robot & Internet Things Technol, Riyadh 11442, Saudi Arabia.
   [Alyamani, Hasan J.] King Abdulaziz Univ, Fac Comp & Informat Technol Rabigh, Dept Informat Syst, Rabigh 21911, Saudi Arabia.
   [Bashir, Ali Kashif] Manchester Metropolitan Univ, Dept Comp & Math, Manchester M15 6BH, Lancs, England.
RP Alhazmi, K (corresponding author), King Abdulaziz City Sci & Technol KACST, Commun & Informat Technol Res Inst, Natl Ctr Robot & Internet Things Technol, Riyadh 11442, Saudi Arabia.
EM khazmi@kacst.edu.sa
RI Alyamani, Hasan/AAS-6721-2021
OI Alyamani, Hasan/0000-0003-0522-4348
NR 40
TC 0
Z9 0
U1 3
U2 3
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1546-2218
EI 1546-2226
J9 CMC-COMPUT MATER CON
JI CMC-Comput. Mat. Contin.
PY 2022
VL 70
IS 2
BP 3349
EP 3364
DI 10.32604/cmc.2022.020473
PG 16
WC Computer Science, Information Systems; Materials Science,
   Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Materials Science
GA WE9VA
UT WOS:000705964000040
OA gold
DA 2022-04-17
ER

PT C
AU Lad, R
   Metkewar, PS
AF Lad, Rashmi
   Metkewar, P. S.
GP IEEE
TI Review of Machine Learning Classifier Toolbox of Neuroimaging Data
SO 2020 IEEE PUNE SECTION INTERNATIONAL CONFERENCE (PUNECON)
LA English
DT Proceedings Paper
CT 3rd IEEE-Pune-Section International Conference (PuneCon)
CY DEC 16-18, 2020
CL Vishwakarma Inst Technol, Pune, INDIA
SP IEEE Pune Sect
HO Vishwakarma Inst Technol
DE Classification; fMRI; machine learning; MATLAB; Python
AB Machine learning and artificial neural network is a growing field in medical imaging or neuroimaging in the present decade. Structural and functional neuroimaging is involved in the investigation of diagnosis of brain tumor and mental illness. To acquire the knowledge from previous experience and perception is called learning. Supervised and unsupervised machine learning algorithm also works on the same principles. It trains neuroimaging techniques like fMRI, EEG, MEG & PET data to extract features from the existing information and then predicts or makes decision that are useful for diagnoses in the medical field. The objective of this study is to give overview of machine learning toolbox that is used for analyzing the neuroimaging data without the deep knowledge of programming languages. These entire machine learning tools helps the experts, researchers for further investigation in the field of neuroimaging data.
C1 [Lad, Rashmi; Metkewar, P. S.] Symbiosis Int Deemed Univ, Symbiosis Inst Comp Studies & Res SICSR, Pune, Maharashtra, India.
   [Lad, Rashmi] MIT Arts Commerce & Sci Coll, Pune, Maharashtra, India.
RP Lad, R (corresponding author), Symbiosis Int Deemed Univ, Symbiosis Inst Comp Studies & Res SICSR, Pune, Maharashtra, India.; Lad, R (corresponding author), MIT Arts Commerce & Sci Coll, Pune, Maharashtra, India.
EM lad.rashmi11@gmail.com; dy.director@sicsr.ac.in
NR 25
TC 0
Z9 0
U1 1
U2 4
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-9600-8
PY 2020
BP 175
EP 179
DI 10.1109/PuneCon50868.2020.9362360
PG 5
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR9OH
UT WOS:000679159900033
DA 2022-04-17
ER

PT J
AU Du, AX
   Emam, S
   Gniadecki, R
AF Du, Amy X.
   Emam, Sepideh
   Gniadecki, Robert
TI Review of Machine Learning in Predicting Dermatological Outcomes
SO FRONTIERS IN MEDICINE
LA English
DT Review
DE artificial intelligence; machine learning; dermatology; prediction;
   clinical outcomes
ID CLASSIFICATION; OPPORTUNITIES; IMAGES
AB Artificial intelligence is a broad branch of computer science that has garnered significant interest in the field of medicine because of its problem solving, decision making and pattern recognition abilities. Machine learning, a subset of artificial intelligence, hones in on the ability of computers to receive data and learn for themselves, manipulating algorithms as they organize the information they are processing. Dermatology is at a particular advantage in the implementation of machine learning due to the availability of large clinical image databases that can be used for machine training and interpretation. While numerous studies have implemented machine learning in the diagnostic aspect of dermatology, less research has been conducted on the use of machine learning in predicting long-term outcomes in skin disease, with only a few studies published to date. Such an approach would assist physicians in selecting the best treatment methods, save patients' time, reduce treatment costs and improve the quality of treatment overall by reducing the amount of trial-and-error in the treatment process. In this review, we aim to provide a brief and relevant introduction to basic artificial intelligence processes, and to consolidate and examine the published literature on the use of machine learning in predicting clinical outcomes in dermatology.
C1 [Du, Amy X.; Gniadecki, Robert] Univ Alberta, Fac Med & Dent, Div Dermatol, Edmonton, AB, Canada.
   [Emam, Sepideh] Univ Alberta, Informat Serv & Technol, Edmonton, AB, Canada.
RP Du, AX (corresponding author), Univ Alberta, Fac Med & Dent, Div Dermatol, Edmonton, AB, Canada.
EM xdu@ualberta.ca
NR 34
TC 5
Z9 5
U1 1
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2296-858X
J9 FRONT MED-LAUSANNE
JI Front. Med.
PD JUN 12
PY 2020
VL 7
AR 266
DI 10.3389/fmed.2020.00266
PG 6
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA MD3HU
UT WOS:000543863100001
PM 32596246
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Hashmani, MA
   Jameel, SM
   Rehman, M
   Inoue, A
AF Hashmani, Manzoor Ahmed
   Jameel, Syed Muslim
   Rehman, Mobashar
   Inoue, Atsushi
TI Concept Drift Evolution In Machine Learning Approaches: A Systematic
   Literature Review
SO INTERNATIONAL JOURNAL ON SMART SENSING AND INTELLIGENT SYSTEMS
LA English
DT Review
DE Big data analysis; Concept drift; Nonstationary environment; Adaptive
   machine learning; Online learning
ID STREAMING DATA; ONLINE; CLASSIFICATION; ENSEMBLES; ELM
AB Concept Drift's issue is a decisive problem of online machine learning, which causes massive performance degradation in the analysis. The Concept Drift is observed when data's statistical properties vary at a different time step and deteriorate the trained model's accuracy and make them ineffective. However, online machine learning has significant importance to fulfill the demands of the current computing revolution. Moreover, it is essential to understand the existing Concept Drift handling techniques to determine their associated pitfalls and propose robust solutions. This study attempts to summarize and clarify the empirical pieces of evidence of the Concept Drift issue and assess its applicability to meet the current computing revolution. Also, this study provides a few possible research directions and practical implications of Concept Drift handling.
C1 [Hashmani, Manzoor Ahmed] Univ Teknol PETRONAS, UTP High Performance Cloud Comp Ctr HPC3, Ctr Res Data Sci CERDAS,UTP, Inst Elect & Elect Engineers IEEE,Dept Comp & Inf, Perak, Malaysia.
   [Jameel, Syed Muslim] Univ Teknol PETRONAS, Dept Comp & Informat Sci, Perak, Malaysia.
   [Rehman, Mobashar] Univ Tunku Abdul Rahman Perak, Fac Informat & Commun Technol FICT, Perak, Malaysia.
   [Inoue, Atsushi] Eastern Washington Univ, Dept Comp Sci, Cheney, WA 99004 USA.
RP Jameel, SM (corresponding author), Univ Teknol PETRONAS, Dept Comp & Informat Sci, Perak, Malaysia.
EM muslim_16000370@utp.edu.my
OI Hashmani, Manzoor/0000-0002-6617-8149
FU Universiti Teknologi PETRONAS (UTP), Malaysia, as a part of the research
   project "Correlation between Concept Drift Parameters and Performance of
   Deep Learning Models: Towards Fully Adaptive Deep Learning Models" under
   the Fundamental Research Grant Scheme [FRGS/1/2018/ICT02/UTP/02/2]
FX This research study is conducted in Universiti Teknologi PETRONAS (UTP),
   Malaysia, as a part of the research project "Correlation between Concept
   Drift Parameters and Performance of Deep Learning Models: Towards Fully
   Adaptive Deep Learning Models" under the Fundamental Research Grant
   Scheme (FRGS) Ministry of Education (MoE) Malaysia (Grant Reference:
   FRGS/1/2018/ICT02/UTP/02/2).
NR 81
TC 0
Z9 0
U1 5
U2 9
PU INT JOURNAL SMART SENSING & INTELLIGENT SYSTEMS
PI PALMERSTON
PA INT JOURNAL SMART SENSING & INTELLIGENT SYSTEMS, PALMERSTON, 00000, NEW
   ZEALAND
SN 1178-5608
J9 INT J SMART SENS INT
JI Int. J. Smart Sens. Intell. Syst.
PD JAN
PY 2020
VL 13
IS 1
DI 10.21307/ijssis-2020-029
PG 16
WC Engineering, Electrical & Electronic
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA QM0GB
UT WOS:000621456000016
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Hertel, L
   Collado, J
   Sadowski, P
   Ott, J
   Baldi, P
AF Hertel, Lars
   Collado, Julian
   Sadowski, Peter
   Ott, Jordan
   Baldi, Pierre
TI Sherpa: Robust hyperparameter optimization for machine learning
SO SOFTWAREX
LA English
DT Article
DE Hyperparameter optimization; Machine learning; Deep neural networks
AB Sherpa is a hyperparameter optimization library for machine learning models. It is specifically designed for problems with computationally expensive, iterative function evaluations, such as the hyperparameter tuning of deep neural networks. With Sherpa, scientists can quickly optimize hyperparameters using a variety of powerful and interchangeable algorithms. Sherpa can be run on either a single machine or in parallel on a cluster. Finally, an interactive dashboard enables users to view the progress of models as they are trained, cancel trials, and explore which hyperparameter combinations are working best. Sherpa empowers machine learning practitioners by automating the more tedious aspects of model tuning. Its source code and documentation are available at https://github.com/sherpaai/sherpa. (C) 2020 The Author(s). Published by Elsevier B.V.
C1 [Hertel, Lars] Univ Calif Irvine, Dept Stat, Donald Bren Sch Informat & Comp Sci, Bren Hall 2019, Irvine, CA 92697 USA.
   [Collado, Julian; Ott, Jordan; Baldi, Pierre] Univ Calif Irvine, Dept Comp Sci, Donald Bren Sch Informat & Comp Sci, 3019 Donald Bren Hall, Irvine, CA 92697 USA.
   [Sadowski, Peter] Univ Hawaii Manoa, Informat & Comp Sci, 1680 East West Rd, Honolulu, HI 96822 USA.
RP Hertel, L (corresponding author), Univ Calif Irvine, Dept Stat, Donald Bren Sch Informat & Comp Sci, Bren Hall 2019, Irvine, CA 92697 USA.
EM lhertel@uci.edu; colladou@uci.edu; peter.sadowski@hawaii.edu;
   jott1@uci.edu; pfbaldi@ics.uci.edu
OI Sadowski, Peter/0000-0002-7354-5461
FU National Science Foundation, USANational Science Foundation (NSF)
   [1633631, 1839429]; NVIDIA, USA
FX We would like to thank Amin Tavakoli, Christine Lee, Gregor Urban, and
   Siwei Chen for helping test the software and providing useful feedback,
   and Yuzo Kanomata for computing support. This work was in part supported
   by the National Science Foundation, USA under grant number 1633631 to JC
   and 1839429 to PB. We also wish to acknowledge a hardware grant from
   NVIDIA, USA.
NR 47
TC 15
Z9 15
U1 6
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2352-7110
J9 SOFTWAREX
JI SoftwareX
PD JUL-DEC
PY 2020
VL 12
AR 100591
DI 10.1016/j.softx.2020.100591
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PH8TA
UT WOS:000600676600053
OA gold, Green Submitted
DA 2022-04-17
ER

PT J
AU Khakpour, A
   Colomo-Palacios, R
AF Khakpour, Alireza
   Colomo-Palacios, Ricardo
TI Convergence of Gamification and Machine Learning: A Systematic
   Literature Review
SO TECHNOLOGY KNOWLEDGE AND LEARNING
LA English
DT Review
DE Gamification; Machine learning; Learning; Personalization; Behavioral
   change; Systematic literature review
ID RECOGNITION; PERFORMANCE; GAME
AB Recent developments in human-computer interaction technologies raised the attention towards gamification techniques, that can be defined as using game elements in a non-gaming context. Furthermore, advancement in machine learning (ML) methods and its potential to enhance other technologies, resulted in the inception of a new era where ML and gamification are combined. This new direction thrilled us to conduct a systematic literature review in order to investigate the current literature in the field, to explore the convergence of these two technologies, highlighting their influence on one another, and the reported benefits and challenges. The results of the study reflect the various usage of this confluence, mainly in, learning and educational activities, personalizing gamification to the users, behavioral change efforts, adapting the gamification context and optimizing the gamification tasks. Adding to that, data collection for machine learning by gamification technology and teaching machine learning with the help of gamification were identified. Finally, we point out their benefits and challenges towards streamlining future research endeavors.
C1 [Khakpour, Alireza; Colomo-Palacios, Ricardo] Ostfold Univ Coll, Fac Comp Sci, BRA Veien 4, N-1757 Halden, Norway.
RP Khakpour, A (corresponding author), Ostfold Univ Coll, Fac Comp Sci, BRA Veien 4, N-1757 Halden, Norway.
EM alireza.khakpour@hiof.no; ricardo.colomo-palacios@hiof.no
OI Khakpour, Alireza/0000-0003-1961-1269
FU Ostfold University College
FX Open Access funding provided by Ostfold University College.
NR 75
TC 3
Z9 3
U1 9
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 2211-1662
EI 2211-1670
J9 TECHNOL KNOWL LEARN
JI Technol. Knowl. Learn.
PD SEP
PY 2021
VL 26
IS 3
BP 597
EP 636
DI 10.1007/s10758-020-09456-4
EA JUL 2020
PG 40
WC Education & Educational Research
WE Emerging Sources Citation Index (ESCI)
SC Education & Educational Research
GA TS7MK
UT WOS:000547799000001
OA Green Published, hybrid
DA 2022-04-17
ER

PT C
AU Abidi, SMR
   Ni, JY
   Ge, S
   Wang, XM
   Ding, H
   Zhu, WH
   Zhang, W
AF Abidi, Syed Muhammad Raza
   Ni, Jianyue
   Ge, Sen
   Wang Xiangmeng
   Ding, Hu
   Zhu, Wenhao
   Zhang, Wu
BE Pan, Z
   Wang, X
TI Demystifying help-seeking students interacting multimodal learning
   environment under machine learning regime
SO ELEVENTH INTERNATIONAL CONFERENCE ON GRAPHICS AND IMAGE PROCESSING
   (ICGIP 2019)
SE Proceedings of SPIE
LA English
DT Proceedings Paper
CT 11th International Conference on Graphics and Image Processing (ICGIP)
CY OCT 12-14, 2019
CL Zhejiang Gongshang Univ, Hangzhou, PEOPLES R CHINA
SP Sichuan Univ, Coll Comp Sci, Ocean Univ China, Univ Portsmouth, Zhejiang Gongshang Univ, Sch Comp & Informat Sci
HO Zhejiang Gongshang Univ
DE Machine learning; multimodal learning; help-seeking; virtual learning
   environment (VLE); e-learning; educational sustainability
AB Help-seeking students are those who seek academic help during the assignment or course. Classifying help-seeking students in a virtual learning environment (VLE) is a challenging task for the instructor because the student is not physically present. In this study, machine learning techniques and statistical methods were used to detect the help-seeking student by analyzing the student logs data in an e-learning system. We determined that which factors are associated with help-seeking behavior of the students. We found that late submitted, and low assessment score students need more help in solving the course assignment. Also, the result shows that Decision Tree (DT), and Fast Large Margin (FLM) is high accuracy predictive machine learning models as compared to Support Vector Machine (SVM), and Logistic Regression (LR) finding the help-seeking students in a course and instructors can easily categorize the students who seek help, disseminate personalized feedback to those students accordingly, and also embrace the sustainable environment for education.
C1 [Abidi, Syed Muhammad Raza; Ni, Jianyue; Ge, Sen; Wang Xiangmeng; Zhu, Wenhao; Zhang, Wu] Shanghai Univ, Sch Comp Engn & Sci, Shanghai, Peoples R China.
   [Ding, Hu; Zhang, Wu] Shanghai Univ, Shanghai Inst Appl Math & Mech, Shanghai, Peoples R China.
RP Zhang, W (corresponding author), Shanghai Univ, Sch Comp Engn & Sci, Shanghai, Peoples R China.; Zhang, W (corresponding author), Shanghai Univ, Shanghai Inst Appl Math & Mech, Shanghai, Peoples R China.
EM wzhang@shu.edu.cn
RI Ding, Hu/C-7240-2009; Abidi, Syed Muhammad Raza/Q-4896-2019
OI Ding, Hu/0000-0003-4301-1108; Abidi, Syed Muhammad
   Raza/0000-0001-8808-0882
FU Shanghai Municipal Education CommissionShanghai Municipal Education
   Commission (SHMEC) [2019-01-07-00-09-E00018]
FX The effort of this paper was supported by the "Program of Shanghai
   Municipal Education Commission (No. 2019-01-07-00-09-E00018)."
NR 15
TC 1
Z9 1
U1 0
U2 2
PU SPIE-INT SOC OPTICAL ENGINEERING
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA
SN 0277-786X
EI 1996-756X
BN 978-1-5106-3524-1
J9 PROC SPIE
PY 2020
VL 11373
AR 113732V
DI 10.1117/12.2557066
PG 7
WC Computer Science, Theory & Methods; Optics; Imaging Science &
   Photographic Technology
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Optics; Imaging Science & Photographic Technology
GA BP0JH
UT WOS:000534529600102
DA 2022-04-17
ER

PT C
AU Somogyi, N
   Kovesdan, G
AF Somogyi, Norbert
   Kovesdan, Gabor
GP IEEE
TI Software Modernization Using Machine Learning Techniques
SO 2021 IEEE 19TH WORLD SYMPOSIUM ON APPLIED MACHINE INTELLIGENCE AND
   INFORMATICS (SAMI 2021)
LA English
DT Proceedings Paper
CT 19th IEEE World Symposium on Applied Machine Intelligence and
   Informatics (SAMI)
CY JAN 21-23, 2021
CL SLOVAKIA
SP IEEE, Tech Univ Kosice, Obuda Univ, Univ Res & Innovat Ctr, Obuda Univ, Antal Bejczy Ctr Intelligent Robot, Elfa Ltd, Slovak Acad Sci, SMC TC Computat Cybernet, IEEE Czechoslovak Sect, Computat Intelligence Chapter, IEEE Hungary Sect, IEEE Joint Chapter IES & RAS, IEEE Control Syst Chapter, IEEE SMC Chapter, IEEE SMC Soc
DE code modernization; static analysis; machine learning
AB As software engineering techniques and practices continuously evolve, programs created with an older technology stack become harder and more costly to maintain. These software are often referred to as legacy code. Naturally, the need arises to make use of the newer and more effective technologies, making the legacy code easier to maintain and operate. However, companies rarely allocate the necessary resources to manually re-implement these systems as that would be highly time-consuming and extremely costly to spend exclusively for maintenance purposes. Thus, various code modernization approaches have been proposed and tools have been created to reduce the cost of re-implementation by semi-automatically translating legacy systems into a modern, more advantageous environment. However, the source and target languages may be so different in nature that making the generated code feel as natural as possible is often difficult. These linguistic differences frequently impose the emulation of certain features between the two languages, which may prove too difficult to automatically handle using conventional static analysis of the source code. To this end, in this paper we propose the novel method of using machine learning techniques to teach the transformer on how to effectively handle cases that would otherwise be very error-prone in practice. This way, the transformation tool can achieve both a high level of automation and the ability to generate precise, error free code.
C1 [Somogyi, Norbert; Kovesdan, Gabor] Budapest Univ Technol & Econ, Dept Automat & Appl Informat, Budapest, Hungary.
RP Somogyi, N (corresponding author), Budapest Univ Technol & Econ, Dept Automat & Appl Informat, Budapest, Hungary.
EM somogyin@edu.bme.hu; kovesdan.gabor@vik.bme.hu
FU National Research, Development and Innovation Fund of Hungary under the
   Centre for Higher Education and Industrial Cooperation - Research
   infrastructure development (FIEK 16) funding scheme [FIEK
   16-1-2016-0007]
FX Project no. FIEK 16-1-2016-0007 has been implemented with the support
   provided from the National Research, Development and Innovation Fund of
   Hungary, financed under the Centre for Higher Education and Industrial
   Cooperation -Research infrastructure development (FIEK 16) funding
   scheme.
NR 13
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-8053-3
PY 2021
BP 361
EP 365
DI 10.1109/SAMI50585.2021.9378659
PG 5
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR8FY
UT WOS:000671855400062
DA 2022-04-17
ER

PT J
AU Simsek, E
AF Simsek, Ergun
TI Machine Learning Exercises on 1-D Electromagnetic Inversion
SO IEEE TRANSACTIONS ON ANTENNAS AND PROPAGATION
LA English
DT Article
DE Permittivity; Electromagnetics; Receiving antennas; Transmitting
   antennas; Machine learning; Antenna measurements; Antennas; Deep
   learning; electromagnetic inversion; machine learning; optimization
ID SUPERVISED DESCENT METHOD; NEURAL-NETWORK; DESIGN; MODEL
AB This work aims to enhance our fundamental understanding of how the measurement setup that is used to generate training and testing data sets affects the accuracy of the machine learning algorithms that attempt to solve electromagnetic inversion problems solely from data. A systematic study is carried out on a 1-D semi-inverse electromagnetic problem, which is estimating the electrical permittivity values of a planarly layered medium with fixed layer thicknesses assuming different receiver-transmitter antenna combinations in terms of location and numbers. The accuracy of the solutions obtained with four machine learning methods, including neural networks, is compared with a physics-based solver deploying the Nelder-Mead simplex method to achieve the inversion iteratively. Numerical results show that: 1) deep-learning outperforms the other machine learning techniques implemented in this study; 2) increasing the number of antennas and placing them as close as possible to the domain of interest increase inversion accuracy; 3) for neural networks, training data sets created on random grids lead to more efficient learning than the training data sets created on uniform grids; and 4) multifrequency training and testing with a few antennas can achieve more accurate inversion than single-frequency setups deploying several antennas.
C1 [Simsek, Ergun] Univ Maryland, Dept Comp Sci & Elect Engn, Baltimore, MD 21250 USA.
RP Simsek, E (corresponding author), Univ Maryland, Dept Comp Sci & Elect Engn, Baltimore, MD 21250 USA.
EM simsek@umbc.edu
RI Simsek, Ergun/B-2811-2009
OI Simsek, Ergun/0000-0001-9075-7071
NR 30
TC 0
Z9 0
U1 16
U2 16
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-926X
EI 1558-2221
J9 IEEE T ANTENN PROPAG
JI IEEE Trans. Antennas Propag.
PD OCT
PY 2021
VL 69
IS 10
BP 6797
EP 6805
DI 10.1109/TAP.2021.3069519
PG 9
WC Engineering, Electrical & Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Telecommunications
GA WC2VC
UT WOS:000704118400065
OA Green Published
DA 2022-04-17
ER

PT J
AU Cilluffo, G
   Fasola, S
   Ferrante, G
   Malizia, V
   Montalbano, L
   La Grutta, S
AF Cilluffo, Giovanna
   Fasola, Salvatore
   Ferrante, Giuliana
   Malizia, Velia
   Montalbano, Laura
   La Grutta, Stefania
TI Machine Learning: An Overview and Applications in Pharmacogenetics
SO GENES
LA English
DT Review
DE pharmacogenetics; supervised machine learning; unsupervised machine
   learning
ID ALGORITHMS; MODELS
AB This narrative review aims to provide an overview of the main Machine Learning (ML) techniques and their applications in pharmacogenetics (such as antidepressant, anti-cancer and warfarin drugs) over the past 10 years. ML deals with the study, the design and the development of algorithms that give computers capability to learn without being explicitly programmed. ML is a sub-field of artificial intelligence, and to date, it has demonstrated satisfactory performance on a wide range of tasks in biomedicine. According to the final goal, ML can be defined as Supervised (SML) or as Unsupervised (UML). SML techniques are applied when prediction is the focus of the research. On the other hand, UML techniques are used when the outcome is not known, and the goal of the research is unveiling the underlying structure of the data. The increasing use of sophisticated ML algorithms will likely be instrumental in improving knowledge in pharmacogenetics.
C1 [Cilluffo, Giovanna; Fasola, Salvatore; Malizia, Velia; Montalbano, Laura; La Grutta, Stefania] CNR, Inst Biomed Res & Innovat, I-90146 Palermo, Italy.
   [Ferrante, Giuliana] Univ Verona, Dept Surg Sci Dent Gynecol & Pediat, Pediat Div, I-37134 Verona, Italy.
RP Cilluffo, G (corresponding author), CNR, Inst Biomed Res & Innovat, I-90146 Palermo, Italy.
EM salvatore.fasola@irib.cnr.it; salvatore.fasola@irib.cnr.it;
   giuliana.ferrante@univr.it; velia.malizia@irib.cnr.it;
   laura.montalbano@irib.cnr.it; stefania.lagrutta@irib.cnr.it
RI Cilluffo, Giovanna/AAC-6724-2019; Fasola, Salvatore/W-2372-2018
OI Cilluffo, Giovanna/0000-0003-4305-3981; Fasola,
   Salvatore/0000-0002-5378-5505; La Grutta, Stefania/0000-0001-8026-0715
NR 37
TC 0
Z9 0
U1 5
U2 5
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2073-4425
J9 GENES-BASEL
JI Genes
PD OCT
PY 2021
VL 12
IS 10
AR 1511
DI 10.3390/genes12101511
PG 12
WC Genetics & Heredity
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Genetics & Heredity
GA WP0WF
UT WOS:000712862000001
PM 34680905
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Lavric, A
   Popa, V
   Takahashi, H
   Yousefi, S
AF Lavric, Alexandru
   Popa, Valentin
   Takahashi, Hidenori
   Yousefi, Siamak
TI Detecting Keratoconus From Corneal Imaging Data Using Machine Learning
SO IEEE ACCESS
LA English
DT Article
DE Machine learning; Machine learning algorithms; Diseases; Computational
   modeling; Cornea; Surfaces; Imaging; Keratoconus; machine learning;
   corneal imaging data; data mining; support vector machine
ID CLASSIFICATION; MODEL
AB Keratoconus affects approximately one in 2,000 individuals worldwide. It is typically associated with the decrease in visual acuity. Given its wide prevalence, there is an unmet need for the development of new tools that can diagnose the disease at an early stage in order to prevent disease progression and vision loss. The aim of this study is to develop and test a machine learning algorithm that can detect keratoconus at early stages. We applied several machine learning algorithms to detect keratoconus and then tested the algorithms using real world medical data, including corneal topography, elevation, and pachymetry parameters collected from OCT-based topography instruments from several corneal clinics in Japan. We implemented 25 different machine learning models in Matlab and achieved a range of 62% to 94.0% accuracy. The highest accuracy level of 94% was obtained by a support vector machine (SVM) algorithm using a subset of eight corneal parameters with the highest discriminating power. The proposed model may aid physicians in assessing corneal status and detecting keratoconus, which is otherwise challenging through subjective evaluations, particularly at the preclinical and early stages of the disease. The algorithm can be integrated into corneal imaging devices or used as a stand-alone-software for cornea assessment and detecting early stage keratoconus.
C1 [Lavric, Alexandru; Popa, Valentin] Stefan Cel Mare Univ, Fac Elect Engn & Comp Sci, Suceava 720229, Romania.
   [Popa, Valentin] Stefan Cel Mare Univ, MANSID Integrated Ctr, Suceava 720229, Romania.
   [Takahashi, Hidenori] Jichi Med Univ, Dept Ophthalmol, Shimotsuke, Tochigi 3290498, Japan.
   [Yousefi, Siamak] Univ Tennessee, Ctr Hlth Sci, Dept Ophthalmol, Memphis, TN 38163 USA.
   [Yousefi, Siamak] Univ Tennessee, Ctr Hlth Sci, Dept Genet Genom & Informat, Memphis, TN 38163 USA.
RP Lavric, A (corresponding author), Stefan Cel Mare Univ, Fac Elect Engn & Comp Sci, Suceava 720229, Romania.
EM lavric@eed.usv.ro
OI popa, valentin/0000-0003-2437-6689; Lavric,
   Alexandru/0000-0001-7734-4854; Yousefi, Siamak/0000-0001-8633-5730
FU Romanian Ministry of Research and Innovation, CCCDI-UEFISCDI within
   PNCDI III [PN-III-P1-1.2-PCCDI-2017-0776, 36 PCCDI/15.03.2018]
FX This work was supported by a grant of the Romanian Ministry of Research
   and Innovation, CCCDI-UEFISCDI, project number
   PN-III-P1-1.2-PCCDI-2017-0776/No. 36 PCCDI/15.03.2018, within PNCDI III.
NR 18
TC 7
Z9 8
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 149113
EP 149121
DI 10.1109/ACCESS.2020.3016060
PG 9
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA ND7GP
UT WOS:000562071500001
OA gold
DA 2022-04-17
ER

PT J
AU Malavika, G
   Rajathi, N
   Vanitha, V
   Parameswari, P
AF Malavika, G.
   Rajathi, N.
   Vanitha, V.
   Parameswari, P.
TI Heart Disease Prediction Using Machine Learning Algorithms
SO BIOSCIENCE BIOTECHNOLOGY RESEARCH COMMUNICATIONS
LA English
DT Article
DE CLASSIFICATION ACCURACY; HEART DISEASE; MACHINE LEARNING
AB The rapidly growing field of data analysis plays a significant role in healthcare. The healthcare industry has become big business. The healthcare sector produces enormous amounts of data every day. This data helps to extract the hidden information, which is useful to predict disease at the earlier. In medical field, predicting heart disease is treated as one of the intricate tasks. Therefore, there is a necessity to develop a decision support system to forecast the cardio vascular disease in a patient. Machine learning plays a vital part in disease prediction. In this paper, various machine learning methods were used to predict the heart disease and their performances were compared. The results obtained show the superiority of the Random forest algorithm.
C1 [Malavika, G.; Rajathi, N.; Vanitha, V.] Kumaraguru Coll Technol, Dept Informat Technol, Coimbatore, Tamil Nadu, India.
   [Parameswari, P.] Kumaraguru Coll Technol, Dept MCA, Coimbatore, Tamil Nadu, India.
RP Rajathi, N (corresponding author), Kumaraguru Coll Technol, Dept Informat Technol, Coimbatore, Tamil Nadu, India.
EM rajathi.in.it@kct.ac.in
NR 11
TC 0
Z9 0
U1 9
U2 11
PU SOC SCIENCE & NATURE
PI BHOPAL
PA C-52 HOUSING BOARD COLONY, KOHE FIZA, BHOPAL, MADHYA PRADESH 462 001,
   INDIA
SN 0974-6455
J9 BIOSCI BIOTECH RES C
JI Biosci. Biotechnol. Res. Commun.
PY 2020
VL 13
IS 11
SI SI
BP 24
EP 27
DI 10.21786/bbrc/13.11/6
PG 4
WC Biotechnology & Applied Microbiology
WE Emerging Sources Citation Index (ESCI)
SC Biotechnology & Applied Microbiology
GA RN0XA
UT WOS:000640077900006
OA Green Submitted, Bronze
DA 2022-04-17
ER

PT J
AU Chen, J
   Katchova, AL
   Zhou, CX
AF Chen, Jian
   Katchova, Ani L.
   Zhou, Chenxi
TI Agricultural loan delinquency prediction using machine learning methods
SO INTERNATIONAL FOOD AND AGRIBUSINESS MANAGEMENT REVIEW
LA English
DT Article
DE agricultural credit; forecasting; machine learning; logistic regression
ID FINANCIAL STRESS; NEURAL-NETWORKS; BANK FAILURES; PERFORMANCE;
   REGRESSION; SELECTION; MODEL
AB The recent economic downturn in the agricultural sector that started in 2013 has caused some concerns for farmers' repayment capacity, which raises the need for precise prediction of financial stress in the agricultural sector. Machine learning has been shown to improve predictions with large financial data, however, its application remains limited in the agricultural sector. In this study, we approximate financial stress by agricultural loan delinquency, and predict it by employing a logistic regression and several machine learning methods. The main datasets include the Call Reports and Summary of Deposits from the Federal Deposit Insurance Corporation (FDIC). Our results show that ensemble learning methods have the best performance in prediction accuracy, with improvement of 26 percentage points at most and that the Naive Bayes classifier is the best method to maintain the lowest cost from false predictions when the failure of identifying potentially high-risk loans is very costly. From the perspective of banks, while there are important benefits to using machine learning, the bank-level costs arc also important considerations that may lead to different choices of machine learning methods.
C1 [Chen, Jian; Katchova, Ani L.] Ohio State Univ, Dept Agr Environm & Dev Econ, 2120 Fyffe Rd,250 Ag Admin Bldg, Columbus, OH 43210 USA.
   [Zhou, Chenxi] Ohio State Univ, Dept Stat, Cockins Hall,Room 305E,1958 Neil Ave, Columbus, OH 43210 USA.
RP Katchova, AL (corresponding author), Ohio State Univ, Dept Agr Environm & Dev Econ, 2120 Fyffe Rd,250 Ag Admin Bldg, Columbus, OH 43210 USA.
EM katchova.1@osu.edu
NR 45
TC 0
Z9 0
U1 6
U2 9
PU WAGENINGEN ACADEMIC PUBLISHERS
PI WAGENINGEN
PA PO BOX 220, WAGENINGEN, 6700 AE, NETHERLANDS
SN 1559-2448
J9 INT FOOD AGRIBUS MAN
JI Int. Food Agribus. Manag. Rev.
PY 2021
VL 24
IS 5
BP 797
EP 812
DI 10.22434/IFAMR2020.0019
PG 16
WC Agricultural Economics & Policy
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Agriculture
GA TI3ZW
UT WOS:000672736900004
OA gold, Green Published
DA 2022-04-17
ER

PT J
AU Kushwaha, S
   Bahl, S
   Bagha, AK
   Parmar, KS
   Javaid, M
   Haleem, A
   Singh, RP
AF Kushwaha, Shashi
   Bahl, Shashi
   Bagha, Ashok Kumar
   Parmar, Kulwinder Singh
   Javaid, Mohd
   Haleem, Abid
   Singh, Ravi Pratap
TI Significant Applications of Machine Learning for COVID-19 Pandemic
SO JOURNAL OF INDUSTRIAL INTEGRATION AND MANAGEMENT-INNOVATION AND
   ENTREPRENEURSHIP
LA English
DT Article
DE Machine learning; algorithms; applications; COVID-19; coronavirus
ID DECISION-SUPPORT-SYSTEM; FEATURE SPACE THEORY; OF-THE-ART;
   ARTIFICIAL-INTELLIGENCE; HEALTH-CARE; CLASSIFICATION; INDUSTRY;
   TECHNOLOGIES; DIAGNOSIS; ALGORITHM
AB Machine learning is an innovative approach that has extensive applications in prediction. This technique needs to be applied for the COVID-19 pandemic to identify patients at high risk, their death rate, and other abnormalities. It can be used to understand the nature of this virus and further predict the upcoming issues. This literature-based review is done by searching the relevant papers on machine learning for COVID-19 from the databases of SCOPUS, Academia, Google Scholar, PubMed, and ResearchGate. This research attempts to discuss the significance of machine learning in resolving the COVID-19 pandemic crisis. This paper studied how machine learning algorithms and methods can be employed to fight the COVID-19 virus and the pandemic. It further discusses the primary machine learning methods that are helpful during the COVID-19 pandemic. We further identified and discussed algorithms used in machine learning and their significant applications. Machine learning is a useful technique, and this can be witnessed in various areas to identify the existing drugs, which also seems advantageous for the treatment of COVID-19 patients. This learning algorithm creates interferences out of unlabeled input datasets, which can be applied to analyze the unlabeled data as an input resource for COVID-19. It provides accurate and useful features rather than a traditional explicitly calculation-based method. Further, this technique is beneficial to predict the risk in healthcare during this COVID-19 crisis. Machine learning also analyses the risk factors as per age, social habits, location, and climate.
C1 [Kushwaha, Shashi; Bagha, Ashok Kumar] Dr BR Ambedkar Natl Inst Technol, Dept Mech Engn, Jalandhar 144011, Punjab, India.
   [Bahl, Shashi] IK Gujral Punjab Tech Univ, Dept Mech Engn, Hoshiarpur Campus, Hoshiarpur 146001, India.
   [Parmar, Kulwinder Singh] IK Gujral Punjab Tech Univ, Dept Math Sci, Hoshiarpur Campus, Hoshiarpur 146001, India.
   [Javaid, Mohd; Haleem, Abid] Jamia Millia Islamia, Dept Mech Engn, New Delhi 110025, India.
   [Singh, Ravi Pratap] Dr BR Ambedkar Natl Inst Technol, Dept Ind & Prod Engn, Jalandhar 144011, Punjab, India.
RP Bahl, S (corresponding author), IK Gujral Punjab Tech Univ, Dept Mech Engn, Hoshiarpur Campus, Hoshiarpur 146001, India.
EM ssk.shashi24@gmail.com; shashi.bahl@ptu.ac.in; baghaak@nitj.ac.in;
   kulmaths@gmail.com; mohdjavaid0786@gmail.com; haleem.abid@gmail.com;
   singhrp@nitj.ac.in
RI Bahl, Shashi/AAP-8412-2021; Haleem, Abid/G-4761-2012; Parmar, Kulwinder
   Singh/B-1583-2014; Javaid, Mohd/AAD-7090-2022; Bagha, Ashok
   Kumar/Y-1298-2019
OI Parmar, Kulwinder Singh/0000-0002-7589-7364; Bagha, Ashok
   Kumar/0000-0003-1455-9115; Bahl, Shashi/0000-0001-9294-8226
NR 142
TC 31
Z9 31
U1 8
U2 23
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 2424-8622
EI 2424-8630
J9 J IND INTEGR MANAG
JI J. Ind. Integr. Manag.
PD DEC
PY 2020
VL 5
IS 4
BP 453
EP 479
DI 10.1142/S2424862220500268
PG 27
WC Management
WE Emerging Sources Citation Index (ESCI)
SC Business & Economics
GA PK8EY
UT WOS:000602672200005
DA 2022-04-17
ER

PT C
AU Ma, ZR
   Huang, YY
   Lu, JZ
AF Ma Zhongrui
   Huang Yuanyuan
   Lu Jiazhong
GP IEEE
TI TROJAN TRAFFIC DETECTION BASED ON MACHINE LEARNING
SO 2020 17TH INTERNATIONAL COMPUTER CONFERENCE ON WAVELET ACTIVE MEDIA
   TECHNOLOGY AND INFORMATION PROCESSING (ICCWAMTIP)
SE International Computer Conference on Wavelet Active Media Technology and
   Information Processing
LA English
DT Proceedings Paper
CT 17th IEEE International Computer Conference on Wavelet Active Media
   Technology and Information Processing (ICCWAMTIP)
CY DEC 18-20, 2020
CL Univ Elect Sci & Technol China, Chengdu, PEOPLES R CHINA
SP IEEE, Natl Nat Sci Fdn China, Natl High Technol Res & Dev Program China, China Int Talent Exchange Fdn, IEEE Chengdu Sect
HO Univ Elect Sci & Technol China
DE Trojan detection; Traffic analysis; Machine learning; Network behavior
   analysis
AB At present, most Trojan detection methods are based on the features of host and code. Such methods have certain limitations and lag. This paper analyzes the network behavior features and network traffic of several typical Trojans such as Zeus and Weasel, and proposes a Trojan traffic detection algorithm based on machine learning. First, model different machine learning algorithms and use Random Forest algorithm to extract features for Trojan behavior and communication features. Then identify and detect Trojans' traffic. The accuracy is as high as 95.1%. Comparing the detection of different machine learning algorithms, experiments show that our algorithm has higher accuracy, which is helpful and useful for identifying Trojan.
C1 [Ma Zhongrui; Huang Yuanyuan; Lu Jiazhong] Chengdu Univ Informat Technol, Sch Cybersecur, Chengdu 610225, Sichuan, Peoples R China.
RP Lu, JZ (corresponding author), Chengdu Univ Informat Technol, Sch Cybersecur, Chengdu 610225, Sichuan, Peoples R China.
EM 2020121052@stu.cuit.edu.cn; hy@cuit.edu.cn; ljz@cuit.edu.cn
NR 7
TC 0
Z9 0
U1 3
U2 3
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2576-8972
EI 2576-8964
BN 978-0-7381-4259-3
J9 I COMP CONF WAVELET
PY 2020
BP 157
EP 160
DI 10.1109/ICCWAMTIP51612.2020.9317515
PG 4
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR4RN
UT WOS:000652587200024
DA 2022-04-17
ER

PT J
AU Wan, ZY
   Xia, X
   Lo, D
   Murphy, GC
AF Wan, Zhiyuan
   Xia, Xin
   Lo, David
   Murphy, Gail C.
TI How does Machine Learning Change Software Development Practices?
SO IEEE TRANSACTIONS ON SOFTWARE ENGINEERING
LA English
DT Article
DE Software; Interviews; Data models; Machine learning; Testing; Task
   analysis; Software engineering; Software engineering; machine learning;
   practitioner; empirical study
AB Adding an ability for a system to learn inherently adds uncertainty into the system. Given the rising popularity of incorporating machine learning into systems, we wondered how the addition alters software development practices. We performed a mixture of qualitative and quantitative studies with 14 interviewees and 342 survey respondents from 26 countries across four continents to elicit significant differences between the development of machine learning systems and the development of non-machine-learning systems. Our study uncovers significant differences in various aspects of software engineering (e.g., requirements, design, testing, and process) and work characteristics (e.g., skill variety, problem solving and task identity). Based on our findings, we highlight future research directions and provide recommendations for practitioners.
C1 [Wan, Zhiyuan] Zhejiang Univ, Ningbo Res Inst, Coll Comp Sci & Technol, Hangzhou 310058, Peoples R China.
   [Wan, Zhiyuan] Univ British Columbia, Dept Comp Sci, Vancouver, BC V6T 1Z4, Canada.
   [Xia, Xin] Monash Univ, Fac Informat Technol, Clayton, Vic 3800, Australia.
   [Lo, David] Singapore Management Univ, Sch Informat Syst, Singapore 188065, Singapore.
   [Murphy, Gail C.] Univ British Columbia, Dept Comp Sci, Vancouver, BC V6T 1Z4, Canada.
RP Xia, X (corresponding author), Monash Univ, Fac Informat Technol, Clayton, Vic 3800, Australia.
EM wanzhiyuan@zju.edu.cn; xin.xia@monash.edu; davidlo@smu.edu.sg;
   murphy@cs.ubc.ca
RI Xia, Xin/AAD-6217-2022
FU National Key Research and Development Program of China [2018YFB1003904]
FX The authors would like to thank all interviewees for their participation
   and survey participants for responding to our survey. This research was
   partially supported by the National Key Research and Development Program
   of China (2018YFB1003904).
NR 38
TC 16
Z9 16
U1 5
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0098-5589
EI 1939-3520
J9 IEEE T SOFTWARE ENG
JI IEEE Trans. Softw. Eng.
PD SEPT 1
PY 2021
VL 47
IS 9
BP 1857
EP 1871
DI 10.1109/TSE.2019.2937083
PG 15
WC Computer Science, Software Engineering; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UR3QY
UT WOS:000696667700006
OA Green Accepted
DA 2022-04-17
ER

PT C
AU Sekhar, CH
   Rao, KV
AF Sekhar, C. H.
   Rao, K. Venkata
BE Smys, S
   Senjyu, T
   Lafata, P
TI A Study: Machine Learning and Deep Learning Approaches for Intrusion
   Detection System
SO SECOND INTERNATIONAL CONFERENCE ON COMPUTER NETWORKS AND COMMUNICATION
   TECHNOLOGIES, ICCNCT 2019
SE Lecture Notes on Data Engineering and Communications Technologies
LA English
DT Proceedings Paper
CT 2nd International Conference on Computer Networks and Communication
   Technologies (ICCNCT)
CY MAY 23-24, 2019
CL Coimbatore, INDIA
DE Intrude; Intrusion Detection; Machine Learning; Deep Learning
AB System security is one of the real worries of the difficult time. With the fast advancement and monstrous utilization of web over the previous decade, the vulnerabilities of system security have turned into an important issue. Interruption identification framework is utilized to distinguish unapproved get to and uncommon assaults over the verified systems. High volume, assortment and fast of information produced in the system have made the information examination procedure to identify assaults by conventional strategies extremely troublesome. To comprehend the present status of usage of Machine and Deep learning methods for tackling the interruption recognition issues, this study paper listing out the related examinations in the continuous period focusing. This overview paper gives the various models of the detection system and briefly on Machine and Deep learning algorithms.
C1 [Sekhar, C. H.; Rao, K. Venkata] Vignans Inst Informat Technol, Dept Comp Sci & Engn, Visakhapatnam, Andhra Pradesh, India.
RP Sekhar, CH (corresponding author), Vignans Inst Informat Technol, Dept Comp Sci & Engn, Visakhapatnam, Andhra Pradesh, India.
EM sekhar1203@gmail.com; vrkoduganti@gmail.com
OI , Dr. Venkata Rao Koduganti/0000-0002-1633-7236
NR 9
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2367-4512
BN 978-3-030-37051-0; 978-3-030-37050-3
J9 LECT NOTE DATA ENG
PY 2020
VL 44
BP 845
EP 849
DI 10.1007/978-3-030-37051-0_94
PG 5
WC Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Telecommunications
GA BR5NB
UT WOS:000656462300093
DA 2022-04-17
ER

PT C
AU Alsaffar, D
   Alfahhad, A
   Alqhtani, B
   Alamri, L
   Alansari, S
   Alqahtani, N
   Alboaneen, DA
AF Alsaffar, Dalia
   Alfahhad, Amjad
   Alqhtani, Bashaier
   Alamri, Lama
   Alansari, Shahad
   Alqahtani, Nada
   Alboaneen, Dabiah A.
BE Hassanien, AE
   Shaalan, K
   Tolba, MF
TI Machine and Deep Learning Algorithms for Twitter Spam Detection
SO PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON ADVANCED INTELLIGENT
   SYSTEMS AND INFORMATICS 2019
SE Advances in Intelligent Systems and Computing
LA English
DT Proceedings Paper
CT 5th International Conference on Advanced Intelligent Systems and
   Informatics (AISI)
CY OCT 26-28, 2019
CL Cairo, EGYPT
DE Classification; Machine learning; Deep learning; Twitter; Spam
AB Twitter allows users to send short text-based messages with up to 280 characters which is called "tweets". The reputation of Twitter attracts the spammers to spread malevolent programming through URLs attached in tweets. Twitter spam has become a critical problem. Spam refers to a variety of prohibited behaviours that violate the Twitter rules. In this paper, different machine and deep learning algorithms are used to detect if the tweet is spammer or not. The performance of six machine learning algorithms, namely Random Forest (RF), Naive Bayes (NB), Bayesian Network (BN), Support Vector Machine (SVM), K-Nearest Neighbour (KNN), and Multi-Layer Perceptron (MLP) and one deep learning algorithm which is Recurrent Neural Network (RNN) are evaluated. Different test options are used, namely cross validation and percentage split tests. Results show that RF predicts the best result with lowest error rate and highest classification accuracy rate with different test options comparing to all algorithms.
C1 [Alsaffar, Dalia; Alfahhad, Amjad; Alqhtani, Bashaier; Alamri, Lama; Alansari, Shahad; Alqahtani, Nada; Alboaneen, Dabiah A.] Imam Abdulrahman Bin Faisal Univ, Coll Sci & Humanities, Comp Dept, POB 31961, Jubail Ind City, Saudi Arabia.
RP Alboaneen, DA (corresponding author), Imam Abdulrahman Bin Faisal Univ, Coll Sci & Humanities, Comp Dept, POB 31961, Jubail Ind City, Saudi Arabia.
EM Dabuainain@iau.edu.sa
RI Alboaneen, Dabiah A./AAC-8424-2019
OI Alboaneen, Dabiah A./0000-0003-2215-9963; Alfahhad,
   Amjad/0000-0003-4384-1419; Alamri, Lama/0000-0001-7479-6601
NR 17
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2194-5357
EI 2194-5365
BN 978-3-030-31129-2; 978-3-030-31128-5
J9 ADV INTELL SYST
PY 2020
VL 1058
BP 483
EP 491
DI 10.1007/978-3-030-31129-2_44
PG 9
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Computer Science, Cybernetics; Computer Science, Information Systems;
   Computer Science, Software Engineering; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Automation & Control Systems; Computer Science; Engineering
GA BP9HL
UT WOS:000569375900044
DA 2022-04-17
ER

PT J
AU Alsmadi, I
   Aljaafari, N
   Nazzal, M
   Alhamed, S
   Sawalmeh, AH
   Vizcarra, CP
   Khreishah, A
   Anan, M
   Algosaibi, A
   Al-Naeem, MA
   Aldalbahi, A
   Al-Humam, A
AF Alsmadi, Izzat
   Aljaafari, Nura
   Nazzal, Mahmoud
   Alhamed, Shadan
   Sawalmeh, Ahmad H.
   Vizcarra, Conrado P.
   Khreishah, Abdallah
   Anan, Muhammad
   Algosaibi, Abdulelah
   Al-Naeem, Mohammed Abdulaziz
   Aldalbahi, Adel
   Al-Humam, Abdulaziz
TI Adversarial Machine Learning in Text Processing: A Literature Survey
SO IEEE ACCESS
LA English
DT Article
DE Generators; Training; Security; Market research; Machine learning
   algorithms; Generative adversarial networks; Adversarial machine
   learning; Adversarial machine learning; generative adversarial networks;
   GAN; text generation
ID NETWORKS; ALGORITHM
AB Machine learning algorithms represent the intelligence that controls many information systems and applications around us. As such, they are targeted by attackers to impact their decisions. Text created by machine learning algorithms has many types of applications, some of which can be considered malicious especially if there is an intention to present machine-generated text as human-generated. In this paper, we surveyed major subjects in adversarial machine learning for text processing applications. Unlike adversarial machine learning in images, text problems and applications are heterogeneous. Thus, each problem can have its own challenges. We focused on some of the evolving research areas such as: malicious versus genuine text generation metrics, defense against adversarial attacks, and text generation models and algorithms. Our study showed that as applications of text generation will continue to grow in the near future, the type and nature of attacks on those applications and their machine learning algorithms will continue to grow as well. Literature survey indicated an increasing trend in using pre-trained models in machine learning. Word/sentence embedding models and transformers are examples of those pre-trained models. Adversarial models may utilize same or similar pre-trained models as well. In another trend related to text generation models, literature showed effort to develop universal text perturbations to be used in both black-and white-box attack settings. Literature showed also using conditional GANs to create latent representation for writing types. This usage will allow for a seamless lexical and grammatical transition between various writing styles. In text generation metrics, research trends showed developing successful automated or semi-automated assessment metrics that may include human judgement. Literature showed also research trends of designing and developing new memory models that increase performance and memory utilization efficiency without validating real-time constraints. Many research efforts evaluate different defense model approaches and algorithms. Researchers evaluated different types of targeted attacks, and methods to distinguish human versus machine generated text.
C1 [Alsmadi, Izzat] Texas A&M Univ, Dept Comp & Cyber Secur, College Stn, TX 77843 USA.
   [Aljaafari, Nura; Alhamed, Shadan; Vizcarra, Conrado P.; Algosaibi, Abdulelah; Aldalbahi, Adel; Al-Humam, Abdulaziz] King Faisal Univ, Dept Comp Sci, Al Hufuf 31982, Saudi Arabia.
   [Nazzal, Mahmoud; Khreishah, Abdallah] New Jersey Inst Technol, Newark Coll Engn, Dept Elect & Comp Engn, Newark, NJ 07102 USA.
   [Sawalmeh, Ahmad H.] Northern Border Univ, Comp Sci Dept, Ar Ar 73222, Saudi Arabia.
   [Sawalmeh, Ahmad H.] Northern Border Univ, Remote Sensing Unit, Ar Ar 91431, Saudi Arabia.
   [Anan, Muhammad] Alfaisal Univ, Coll Engn, Software Engn Dept, Riyadh 11533, Saudi Arabia.
   [Al-Naeem, Mohammed Abdulaziz] King Faisal Univ, Coll Comp Sci & Informat Technol, Dept Comp Networks & Commun, Al Hufuf 31982, Saudi Arabia.
RP Alsmadi, I (corresponding author), Texas A&M Univ, Dept Comp & Cyber Secur, College Stn, TX 77843 USA.
EM ialsmadi@tamusa.edu
RI Sawalmeh, Ahmad/AAZ-9563-2020; Alsmadi, Izzat/F-5669-2011
OI Sawalmeh, Ahmad/0000-0002-7040-8963; Alsmadi, Izzat/0000-0001-7832-5081
FU Deputyship for Research and Innovation, Ministry of Education, Saudi
   Arabia [1120]
FX This work was supported by the Deputyship for Research and Innovation,
   Ministry of Education, Saudi Arabia, under Project 1120.
NR 180
TC 0
Z9 0
U1 4
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2022
VL 10
BP 17043
EP 17077
DI 10.1109/ACCESS.2022.3146405
PG 35
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Telecommunications
GA ZB2RN
UT WOS:000756695700001
OA gold
DA 2022-04-17
ER

PT J
AU Unceta, I
   Nin, J
   Pujol, O
AF Unceta, Irene
   Nin, Jordi
   Pujol, Oriol
TI Copying Machine Learning Classifiers
SO IEEE ACCESS
LA English
DT Article
DE Training data; Machine learning; Data models; Training; Buildings;
   Production; Predictive models; Applied machine learning; classification;
   copying; differential replication; fidelity
AB We study copying of machine learning classifiers, an agnostic technique to replicate the decision behavior of any classifier. We develop the theory behind the problem of copying, highlighting its properties, and propose a framework to copy the decision behavior of any classifier using no prior knowledge of its parameters or training data distribution. We validate this framework through extensive experiments using data from a series of well-known problems. To further validate this concept, we use three different use cases where desiderata such as interpretability, fairness or productivization constrains need to be addressed. Results show that copies can be exploited to enhance existing solutions and improve them adding new features and characteristics.
C1 [Unceta, Irene] BBVA Data & Analyt, Barcelona 08018, Spain.
   [Unceta, Irene; Pujol, Oriol] Univ Barcelona, Dept Math & Comp Sci, Barcelona 08007, Spain.
   [Nin, Jordi] Univ Ramon Llull, ESADE, Dept Operat Innovat & Data Sci, Sant Cugat Del Valles 08172, Spain.
RP Unceta, I (corresponding author), BBVA Data & Analyt, Barcelona 08018, Spain.; Unceta, I (corresponding author), Univ Barcelona, Dept Math & Comp Sci, Barcelona 08007, Spain.
EM irene.unceta@bbvadata.com
RI Unceta, Irene/AAO-3995-2021; Pujol, Oriol/F-7146-2016
OI Unceta, Irene/0000-0002-7422-1493; Pujol, Oriol/0000-0001-7573-009X;
   Nin, Jordi/0000-0002-9659-2762
FU Spanish Project (MICINN) [PID2019-105093GB-I00]; AGAUR of the
   Generalitat de CatalunyaAgencia de Gestio D'Ajuts Universitaris de
   Recerca Agaur (AGAUR) [2017-DI-25]
FX This work was supported in part by the Spanish Project (MICINN) under
   Grant PID2019-105093GB-I00, and in part by the AGAUR of the Generalitat
   de Catalunya through the Industrial Ph.D., under Grant 2017-DI-25.
NR 78
TC 5
Z9 5
U1 3
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 160268
EP 160284
DI 10.1109/ACCESS.2020.3020638
PG 17
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA NP4RK
UT WOS:000570164700001
OA Green Submitted, gold, Green Published
DA 2022-04-17
ER

PT C
AU Gisi, J
AF Gisi, Joshua
BE Devanbu, P
   Cohen, M
   Zimmermann, T
TI Synthesizing Correct Code for Machine Learning Programs
SO PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE
   ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE
   ENGINEERING (ESEC/FSE '20)
LA English
DT Proceedings Paper
CT 28th ACM Joint Meeting on European Software Engineering Conference and
   Symposium on the Foundations of Software Engineering (ESEC/FSE)
CY NOV 08-13, 2020
CL ELECTR NETWORK
SP Assoc Comp Machinery, ACM SIGSOFT
DE autoML; Machine Learning; Program Synthesis; Sketch
AB Success using machine learning (ML) in numerous fields has created a new class of users, who are not experts in the data science domain but want to use ML as a means to solve their inference problems. Various automatic machine learning (AutoML) approaches attempt to make ML solutions accessible to such users. In this work, we present a system that automatically synthesizes correct code within the context of the user's data using sketching. In sketching, insight is determined through a partial program; a sketch expresses the high-level structure of implementation but leaves holes in place of the low-level details. We use meta-learning on meta-features to approximately solve holes. We observe that the sketch-based approach is more expressive, easier to implement, and easier to optimize than existing AutoML frameworks. Our initial results are very promising. Our approach uses fewer resources and still produces comparable results to existing techniques.
C1 [Gisi, Joshua] North Dakota State Univ, Dept Elect & Comp Engn, Fargo, ND 58105 USA.
RP Gisi, J (corresponding author), North Dakota State Univ, Dept Elect & Comp Engn, Fargo, ND 58105 USA.
EM Joshua.Gisi@ndsu.edu
FU College of Engineering at NDSU [FAR0032069]
FX This work was funded by the College of Engineering at NDSU and NDEPSCoR
   grant no. FAR0032069. I would like to thank Dr. Malik,
   Muhammad-Usman-Sarwar, and Sarim-Zafar who assisted me.
NR 10
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-7043-1
PY 2020
BP 1701
EP 1703
DI 10.1145/3368089.3418780
PG 3
WC Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS5YR
UT WOS:000744432100169
DA 2022-04-17
ER

PT J
AU Cohen-Karlik, E
   Awida, Z
   Bergman, A
   Eshed, S
   Nestor, O
   Kadashev, M
   Ben Yosef, S
   Saed, H
   Mansour, Y
   Globerson, A
   Neumann, D
   Gabet, Y
AF Cohen-Karlik, Edo
   Awida, Zamzam
   Bergman, Ayelet
   Eshed, Shahar
   Nestor, Omer
   Kadashev, Michelle
   Ben Yosef, Sapir
   Saed, Hussam
   Mansour, Yishay
   Globerson, Amir
   Neumann, Drorit
   Gabet, Yankel
TI Quantification of Osteoclasts in Culture, Powered by Machine Learning
SO FRONTIERS IN CELL AND DEVELOPMENTAL BIOLOGY
LA English
DT Article
DE osteoclasts; automatic quantification of osteoclasts; machine learning;
   object detection; deep learning; convolutional neural network (CNN);
   deep neural networks (DNN); artificial intelligence
ID BONE; RESORPTION
AB In vitro osteoclastogenesis is a central assay in bone biology to study the effect of genetic and pharmacologic cues on the differentiation of bone resorbing osteoclasts. To date, identification of TRAP+ multinucleated cells and measurements of osteoclast number and surface rely on a manual tracing requiring specially trained lab personnel. This task is tedious, time-consuming, and prone to operator bias. Here, we propose to replace this laborious manual task with a completely automatic process using algorithms developed for computer vision. To this end, we manually annotated full cultures by contouring each cell, and trained a machine learning algorithm to detect and classify cells into preosteoclast (TRAP+ cells with 1-2 nuclei), osteoclast type I (cells with more than 3 nuclei and less than 15 nuclei), and osteoclast type II (cells with more than 15 nuclei). The training usually requires thousands of annotated samples and we developed an approach to minimize this requirement. Our novel strategy was to train the algorithm by working at "patch-level" instead of on the full culture, thus amplifying by >20-fold the number of patches to train on. To assess the accuracy of our algorithm, we asked whether our model measures osteoclast number and area at least as well as any two trained human annotators. The results indicated that for osteoclast type I cells, our new model achieves a Pearson correlation (r) of 0.916 to 0.951 with human annotators in the estimation of osteoclast number, and 0.773 to 0.879 for estimating the osteoclast area. Because the correlation between 3 different trained annotators ranged between 0.948 and 0.958 for the cell count and between 0.915 and 0.936 for the area, we can conclude that our trained model is in good agreement with trained lab personnel, with a correlation that is similar to inter-annotator correlation. Automation of osteoclast culture quantification is a useful labor-saving and unbiased technique, and we suggest that a similar machine-learning approach may prove beneficial for other morphometrical analyses.
C1 [Cohen-Karlik, Edo; Bergman, Ayelet; Eshed, Shahar; Nestor, Omer; Mansour, Yishay; Globerson, Amir] Tel Aviv Univ, Blavatnik Sch Comp Sci, Tel Aviv, Israel.
   [Awida, Zamzam; Kadashev, Michelle; Ben Yosef, Sapir; Saed, Hussam; Neumann, Drorit] Tel Aviv Univ, Sackler Fac Med, Dept Cell & Dev Biol, Tel Aviv, Israel.
   [Gabet, Yankel] Tel Aviv Univ, Sackler Fac Med, Dept Anat & Anthropol, Tel Aviv, Israel.
RP Globerson, A (corresponding author), Tel Aviv Univ, Blavatnik Sch Comp Sci, Tel Aviv, Israel.; Neumann, D (corresponding author), Tel Aviv Univ, Sackler Fac Med, Dept Cell & Dev Biol, Tel Aviv, Israel.; Gabet, Y (corresponding author), Tel Aviv Univ, Sackler Fac Med, Dept Anat & Anthropol, Tel Aviv, Israel.
EM gamir@tauex.tau.ac.il; histo6@tauex.tau.aa.il; yankel@tauex.tau.ac.il
OI Neumann, Drorit/0000-0002-4805-7511
FU Yandex Machine Learning Initiative at Tel Aviv University, an Israel
   Science Foundation (ISF) [1086/17, 343/17]; Dotan Hemato-oncology Fund;
   Cancer Biology Research Center, Tel Aviv University
FX This work was supported by the Yandex Machine Learning Initiative at Tel
   Aviv University, an Israel Science Foundation (ISF) Grant No. 1086/17 to
   YG and Grant No. 343/17 to DN and by a grant from the Dotan
   Hemato-oncology Fund, the Cancer Biology Research Center, Tel Aviv
   University to DN and YG.
NR 37
TC 1
Z9 1
U1 2
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 2296-634X
J9 FRONT CELL DEV BIOL
JI Front. Cell. Dev. Biol.
PD MAY 25
PY 2021
VL 9
AR 674710
DI 10.3389/fcell.2021.674710
PG 11
WC Cell Biology; Developmental Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Cell Biology; Developmental Biology
GA SO2IN
UT WOS:000658801100001
PM 34113621
OA gold, Green Published
DA 2022-04-17
ER

PT C
AU Tao, YD
   Coltey, E
   Wang, TY
   Alonso, M
   Shyu, ML
   Chen, SC
   Alhaffar, H
   Elias, A
   Bogosian, B
   Vassigh, S
AF Tao, Yudong
   Coltey, Erik
   Wang, Tianyi
   Alonso, Miguel, Jr.
   Shyu, Mei-Ling
   Chen, Shu-Ching
   Alhaffar, Hadi
   Elias, Albert
   Bogosian, Biayna
   Vassigh, Shahin
GP IEEE
TI Confidence Estimation Using Machine Learning in Immersive Learning
   Environments
SO THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND
   RETRIEVAL (MIPR 2020)
LA English
DT Proceedings Paper
CT IEEE 3rd International Conference on Multimedia Information Processing
   and Retrieval (IEEE MIPR)
CY AUG 06-08, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, Huawei Cloud, Hisense, Kuaishou Technol, NEC
DE immersive learning; confidence estimation; immersive environment; deep
   neural network; machine learning
ID VIRTUAL-REALITY
AB As the development of Virtual Reality and Augmented Reality (VR/AR) technology rapidly advances, learning in an artificial immersive environment becomes increasingly feasible. Such emerging technology not only facilitates and promotes an efficient learning process, but also reduces the cost of access to learning materials and environments. Current research mainly focuses on the development of immersive learning environments and the adaptive learning methods based on interactions between trainees and the environment. However, valuable human biometric data available in immersive environments, such as eye gaze and controller pose, have not been explored and utilized to help understand the affective state of the trainees. In this paper, we propose a machine-learning based research framework to estimate trainees' confidence about their decisions in immersive learning environments. Using this framework, we designed an experiment to collect biometric data from a multiple-choice question and answer session in an immersive learning environment. This includes collecting answers from 10 participants on 35 questions and their self-reported confidence in their answers. A Long Short-Term Memory neural network model was used to analyze the data and estimate the confidence with 85.6% accuracy.
C1 [Tao, Yudong; Shyu, Mei-Ling] Univ Miami, Dept Elect & Comp Engn, Coral Gables, FL 33124 USA.
   [Coltey, Erik; Wang, Tianyi; Alonso, Miguel, Jr.; Chen, Shu-Ching] Florida Int Univ, Sch Comp & Infoimat Sci, Miami, FL 33199 USA.
   [Alhaffar, Hadi; Elias, Albert; Bogosian, Biayna; Vassigh, Shahin] Florida Int Univ, Coll Commun Architecture & Arts, Miami, FL 33199 USA.
RP Tao, YD (corresponding author), Univ Miami, Dept Elect & Comp Engn, Coral Gables, FL 33124 USA.
EM yxt128@miami.edu; ecolt003@cs.fiu.edu; wtian002@cs.fiu.edu;
   malonsoj@cs.fiu.edu; shyu@miami.edu; chens@cs.fiu.edu; halhaffa@fiu.edu;
   aelias@fiu.edu; bbogosia@fiu.edu; svassigh@fiu.edu
RI Tao, Yudong/AAB-9101-2019
OI Tao, Yudong/0000-0002-0116-3878
FU NSFNational Science Foundation (NSF) [OIA-1937019]; USDA NIFAUnited
   States Department of Agriculture (USDA) [2017-67018-26229]
FX This research was partially supported by NSF OIA-1937019 and USDA NIFA
   2017-67018-26229.
NR 24
TC 2
Z9 2
U1 3
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
BN 978-1-7281-4272-2
PY 2020
BP 247
EP 252
DI 10.1109/MIPR49039.2020.00058
PG 6
WC Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ8TZ
UT WOS:000621665600050
DA 2022-04-17
ER

PT J
AU Shetty, S
   Musa, M
   Bredart, X
AF Shetty, Shekar
   Musa, Mohamed
   Bredart, Xavier
TI Bankruptcy Prediction Using Machine Learning Techniques
SO JOURNAL OF RISK AND FINANCIAL MANAGEMENT
LA English
DT Article
DE bankruptcy; deep learning; support vector machine; extreme gradient
   boosting; SMEs
ID FINANCIAL RATIOS; DISCRIMINANT-ANALYSIS; CORPORATE BANKRUPTCY; VARIABLE
   SELECTION; MODELS
AB In this study, we apply several advanced machine learning techniques including extreme gradient boosting (XGBoost), support vector machine (SVM), and a deep neural network to predict bankruptcy using easily obtainable financial data of 3728 Belgian Small and Medium Enterprises (SME's) during the period 2002-2012. Using the above-mentioned machine learning techniques, we predict bankruptcies with a global accuracy of 82-83% using only three easily obtainable financial ratios: the return on assets, the current ratio, and the solvency ratio. While the prediction accuracy is similar to several previous models in the literature, our model is very simple to implement and represents an accurate and user-friendly tool to discriminate between bankrupt and non-bankrupt firms.
C1 [Shetty, Shekar] Lamar Univ, Coll Business Adm, Beaumont, TX 77705 USA.
   [Musa, Mohamed] Gulf Univ Sci & Technol, Dept Math & Nat Sci, Coll Arts & Sci, Mishref 32093, Kuwait.
   [Bredart, Xavier] Univ Mons, Warocque Sch Business & Econ, B-7000 Mons, Belgium.
RP Shetty, S (corresponding author), Lamar Univ, Coll Business Adm, Beaumont, TX 77705 USA.
EM xyshetty@gmail.com; musa.m@gust.edu.kw; xavier.bredart@umons.ac.be
NR 41
TC 0
Z9 0
U1 7
U2 7
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 1911-8066
EI 1911-8074
J9 J RISK FINANC MANAG
JI J. Risk Financ. Manag.
PD JAN
PY 2022
VL 15
IS 1
AR 35
DI 10.3390/jrfm15010035
PG 10
WC Business, Finance
WE Emerging Sources Citation Index (ESCI)
SC Business & Economics
GA ZB6CH
UT WOS:000756927300001
OA gold
DA 2022-04-17
ER

PT J
AU Thada, A
   Panchal, S
   Dubey, A
   Rao, LB
AF Thada, Ayush
   Panchal, Shreyash
   Dubey, Ashutosh
   Rao, Lokavarapu Bhaskara
TI Machine learning based frequency modelling
SO MECHANICAL SYSTEMS AND SIGNAL PROCESSING
LA English
DT Article
DE Machine learning; Non-parametric statistics; Frequency; Cracked beam;
   Design of experiment; Experimental bias
ID CRACK LOCATION; FREE-VIBRATION; BEAM; IDENTIFICATION; GAME
AB Detection of cracks in structures has always been an important research topic in the industrial domain closely associated with aerospace, mechanical, marine and civil engineering. The presence of the cracks alters the dynamic response properties. Hence, it becomes crucial to locate these cracks in the structures to avoid any catastrophic failures and maintain structural integrity and performance. The study's objective is to propose two distinct statistical procedures for conducting the machine learning experiment for modelling the frequency and show the effect of experiment design on the results. In the study, the predictive performance of machine learning models and their ensembles is compared within each experiment design and between two experimental designs for the task of prediction of first six natural frequencies of a fixed ended cracked beam. The study highlights the significance of more than one experimental design to reduce the confirmation bias in the research and discusses the proposed methods' generalizability over the different modelling constraints and modelling parameters. The study also discusses a real-world implementation of the learned machine learning models from the perspective of Bayesian optimization. (C) 2021 Elsevier Ltd. All rights reserved.
C1 [Thada, Ayush] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai Campus,Vandalur Kelambakkam Rd, Chennai 600127, Tamil Nadu, India.
   [Panchal, Shreyash; Dubey, Ashutosh; Rao, Lokavarapu Bhaskara] Vellore Inst Technol, Sch Mech Engn, Chennai Campus,Vandalur Kelambakkam Rd, Chennai 600127, Tamil Nadu, India.
RP Rao, LB (corresponding author), Vellore Inst Technol, Sch Mech Engn, Chennai Campus,Vandalur Kelambakkam Rd, Chennai 600127, Tamil Nadu, India.
EM bhaskarlokavarapu@gmail.com
RI Bhaskara Rao, Lokavarapu/M-1886-2017
OI Bhaskara Rao, Lokavarapu/0000-0002-3509-2406; Thada,
   Ayush/0000-0002-0923-4503
NR 33
TC 2
Z9 2
U1 1
U2 9
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0888-3270
EI 1096-1216
J9 MECH SYST SIGNAL PR
JI Mech. Syst. Signal Proc.
PD NOV
PY 2021
VL 160
AR 107915
DI 10.1016/j.ymssp.2021.107915
EA APR 2021
PG 16
WC Engineering, Mechanical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA TE5SS
UT WOS:000670073400006
DA 2022-04-17
ER

PT J
AU Guo, LH
AF Guo, Lihua
TI Extreme Learning Machine with Elastic Net Regularization
SO INTELLIGENT AUTOMATION AND SOFT COMPUTING
LA English
DT Article
DE Extreme learning machine; elastic net; regularized regression
AB Compared with deep neural learning, the extreme learning machine (ELM) can be quickly converged without iteratively tuning hidden nodes. Inspired by this merit, an extreme learning machine with elastic net regularization (ELM-EN) is proposed in this paper. The elastic net is a regularization method that combines LASSO and ridge penalties. This regulartation can keep a balance between system stability and solution's sparsity. Moreover, an excellent optimization method, i.e., accelerated proximal gradient, is used to find the minimum of the system optimization function. Various datasets from UCI repository and two facial expression image datasets are used to validate the efficiency of our system. Final experimental results indicate that our ELM-EN requires less training tine than multi-layer perceptron, and can achieve higher recognition accuracy than ELM and sparse ELM.
C1 [Guo, Lihua] South China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510641, Peoples R China.
RP Guo, LH (corresponding author), South China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510641, Peoples R China.
EM guolihua@scut.edu.cn
FU Natural Science Foundation of Guangdong ProvinceNational Natural Science
   Foundation of Guangdong Province [2015A030313210]; Science and
   Technology Program of Guangzhou [201707010141]
FX THIS work was supported by This work is supported by Natural Science
   Foundation of Guangdong Province (No.2015A030313210), Science and
   Technology Program of Guangzhou (No.201707010141).
NR 13
TC 2
Z9 2
U1 4
U2 9
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1079-8587
EI 2326-005X
J9 INTELL AUTOM SOFT CO
JI Intell. Autom. Soft Comput.
PY 2020
VL 26
IS 3
BP 421
EP 427
DI 10.32604/iasc.2020.013918
PG 7
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA OS0ZT
UT WOS:000589894100004
OA hybrid
DA 2022-04-17
ER

PT J
AU Hie, BL
   Yang, KK
AF Hie, Brian L.
   Yang, Kevin K.
TI Adaptive machine learning for protein engineering
SO CURRENT OPINION IN STRUCTURAL BIOLOGY
LA English
DT Article
DE Machine learning; Protein engineering; Model-based optimization;
   Adaptive sampling; Bayesian optimization; Gaussian process
ID NEURAL-NETWORK; UNCERTAINTY; FITNESS; DESIGN; MODEL; DNA
AB Machine-learning models that learn from data to predict how protein sequence encodes function are emerging as a useful protein engineering tool. However, when using these models to suggest new protein designs, one must deal with the vast combinatorial complexity of protein sequences. Here, we review how to use a sequence-to-function machine-learning surrogate model to select sequences for experimental measurement. First, we discuss how to select sequences through a single round of machine-learning optimization. Then, we discuss sequential optimization, where the goal is to discover optimized sequences and improve the model across multiple rounds of training, optimization, and experimental measurement.
C1 [Hie, Brian L.] Stanford Univ, Dept Biochem, Sch Med, Stanford, CA 94305 USA.
   [Hie, Brian L.] Stanford Univ, Stanford ChEM H, Stanford, CA 94305 USA.
   [Yang, Kevin K.] Microsoft Res New England, Cambridge, MA 02142 USA.
RP Yang, KK (corresponding author), Microsoft Res New England, Cambridge, MA 02142 USA.
EM yang.kevin@microsoft.com
OI Yang, Kevin/0000-0001-9045-6826; Hie, Brian/0000-0003-3224-8142
FU Stanford Science Fellows program
FX The authors thank Nicholas Bhattacharya and Sam Sinai for helpful
   com-ments and discussion. B.L.H. acknowledges the support of the
   Stanford Science Fellows program.
NR 74
TC 1
Z9 1
U1 3
U2 3
PU CURRENT BIOLOGY LTD
PI LONDON
PA 84 THEOBALDS RD, LONDON WC1X 8RR, ENGLAND
SN 0959-440X
EI 1879-033X
J9 CURR OPIN STRUC BIOL
JI Curr. Opin. Struct. Biol.
PD FEB
PY 2022
VL 72
BP 145
EP 152
DI 10.1016/j.sbi.2021.11.002
PG 8
WC Biochemistry & Molecular Biology; Cell Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Cell Biology
GA ZS8SS
UT WOS:000768730600017
PM 34896756
OA Green Submitted, hybrid
DA 2022-04-17
ER

PT J
AU Martinez, RT
   Bestard, GA
   Silva, AMA
   Alfaro, SCA
AF Martinez, Rogfel Thompson
   Bestard, Guillermo Alvarez
   Silva, Alysson Martins Almeida
   Alfaro, Sadek C. Absi
TI Analysis of GMAW process with deep learning and machine learning
   techniques
SO JOURNAL OF MANUFACTURING PROCESSES
LA English
DT Article
DE Deep learning; Dynamic droplet volume; GMAW process; Machine learning
AB GMAW (Gas Metal Arc Welding) is widely applied industrially in ferrous and non-ferrous materials. The interrelation of its initial and final parameters of GMAW process has a non-linear behavior. This is one of the main problems that researchers have to model the GMAW process. Arc parameters capture is difficult due to image process time with the most classic image analysis techniques. Presenting the arc parameters in a model is of high importance because they reflect the disturbances that occur in the GMAW process. Current advances in image processing and computational model predictions areas, help to optimize processes and save costs. These techniques can obtain good results in welding analysis. Deep Learning techniques obtain excellent results in the classification of complex images. Moreover, a machine learning technique can contribute to the predictive model, using the arc parameters obtained in the image processing with deep learning technique. This research aims to develop a framework for weld bead geometry prediction of GMAW process, joining two machine learning techniques. The results obtained demonstrated the effectiveness of these algorithms to predict GMAW process and its potential for real-time analysis.
C1 [Martinez, Rogfel Thompson] Univ Brasilia, Postgrad Program Mechatron Syst PPMEC, Student Grant CAPES, Brasilia, DF, Brazil.
   [Silva, Alysson Martins Almeida; Alfaro, Sadek C. Absi] Univ Brasilia, Dept Mech Engn, Brasilia, DF, Brazil.
   [Bestard, Guillermo Alvarez] Univ Brasilia, Elect Engn, Campus Gama, Brasilia, DF, Brazil.
RP Martinez, RT (corresponding author), Univ Brasilia, Postgrad Program Mechatron Syst PPMEC, Student Grant CAPES, Brasilia, DF, Brazil.
EM rogfel.thompson@aluno.unb.br; guillermo@unb.br; alyssonmartins@unb.br;
   sadek@unb.br
RI Alfaro, Sadek Crisostomo Absi/A-4545-2008; Martínez, Rogfel
   Thompson/AAL-2177-2021
OI Alfaro, Sadek Crisostomo Absi/0000-0002-0361-0555; Martínez, Rogfel
   Thompson/0000-0002-0605-6561; Alvarez Bestard,
   Guillermo/0000-0001-6659-441X; Silva, Alysson/0000-0001-6474-5691
NR 75
TC 6
Z9 6
U1 9
U2 22
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1526-6125
EI 2212-4616
J9 J MANUF PROCESS
JI J. Manuf. Process.
PD FEB
PY 2021
VL 62
BP 695
EP 703
DI 10.1016/j.jmapro.2020.12.052
EA JAN 2021
PG 9
WC Engineering, Manufacturing
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA QE8TF
UT WOS:000616477300001
DA 2022-04-17
ER

PT J
AU Udeshi, S
   Chattopadhyay, S
AF Udeshi, Sakshi
   Chattopadhyay, Sudipta
TI Grammar Based Directed Testing of Machine Learning Systems
SO IEEE TRANSACTIONS ON SOFTWARE ENGINEERING
LA English
DT Article
DE Machine learning; Grammar; Robustness; Systematics; Test pattern
   generators; Natural language processing; Software testing; machine
   learning; natural language processing
ID ROBUSTNESS
AB The massive progress of machine learning has seen its application over a variety of domains in the past decade. But how do we develop a systematic, scalable and modular strategy to validate machine-learning systems? We present, to the best of our knowledge, the first approach, which provides a systematic test framework for machine-learning systems that accepts grammar-based inputs. Our Ogma approach automatically discovers erroneous behaviours in classifiers and leverages these erroneous behaviours to improve the respective models. Ogma leverages inherent robustness properties present in any well trained machine-learning model to direct test generation and thus, implementing a scalable test generation methodology. To evaluate our Ogma approach, we have tested it on three real world natural language processing (NLP) classifiers. We have found thousands of erroneous behaviours in these systems. We also compare Ogma with a random test generation approach and observe that Ogma is more effective than such random test generation by up to 489 percent.
C1 [Udeshi, Sakshi; Chattopadhyay, Sudipta] Singapore Univ Technol & Design, Singapore 487372, Singapore.
RP Udeshi, S (corresponding author), Singapore Univ Technol & Design, Singapore 487372, Singapore.
EM sakshi_udeshi@mymail.sutd.edu.sg; sudipta_chattopadhyay@sutd.edu.sg
OI Chattopadhyay, Sudipta/0000-0002-4843-5391
FU Ministry of Education, SingaporeMinistry of Education, Singapore
FX The first author is supported by the President's Graduate Fellowship
   funded by the Ministry of Education, Singapore.
NR 36
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0098-5589
EI 1939-3520
J9 IEEE T SOFTWARE ENG
JI IEEE Trans. Softw. Eng.
PD NOV 1
PY 2021
VL 47
IS 11
BP 2487
EP 2503
DI 10.1109/TSE.2019.2953066
PG 17
WC Computer Science, Software Engineering; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW2QE
UT WOS:000717767100011
OA Green Submitted
DA 2022-04-17
ER

PT J
AU McHugh, CM
   Large, MM
AF McHugh, Catherine M.
   Large, Matthew M.
TI Can machine-learning methods really help predict suicide?
SO CURRENT OPINION IN PSYCHIATRY
LA English
DT Review
DE artificial intelligence; machine learning; prediction; suicidal
   behaviour; suicide
ID RISK-ASSESSMENT; SELF-HARM; REGRESSION; PEOPLE
AB Purpose of review
   In recent years there has been interest in the use of machine learning in suicide research in reaction to the failure of traditional statistical methods to produce clinically useful models of future suicide. The current review summarizes recent prediction studies in the suicide literature including those using machine learning approaches to understand what value these novel approaches add.
   Recent findings
   Studies using machine learning to predict suicide deaths report area under the curve that are only modestly greater than, and sensitivities that are equal to, those reported in studies using more conventional predictive methods. Positive predictive value remains around 1% among the cohort studies with a base rate that was not inflated by case-control methodology.
   Summary
   Machine learning or artificial intelligence may afford opportunities in mental health research and in the clinical care of suicidal patients. However, application of such techniques should be carefully considered to avoid repeating the mistakes of existing methodologies. Prediction studies using machine-learning methods have yet to make a major contribution to our understanding of the field and are unproven as clinically useful tools.
C1 [McHugh, Catherine M.] Univ Sydney, Brain & Mind Ctr, Mallett St, Camperdown, NSW 2050, Australia.
   [Large, Matthew M.] Univ New South Wales, Sch Psychiat, Sydney, NSW, Australia.
RP McHugh, CM (corresponding author), Univ Sydney, Brain & Mind Ctr, Mallett St, Camperdown, NSW 2050, Australia.
EM catherine.mchugh@sydney.edu.au
FU RANZCP New Investigator Grant
FX M. acknowledges the support of the RANZCP New Investigator Grant in
   contributing to this work.
NR 41
TC 11
Z9 11
U1 7
U2 11
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0951-7367
EI 1473-6578
J9 CURR OPIN PSYCHIATR
JI Curr. Opin. Psychiatr.
PD JUL
PY 2020
VL 33
IS 4
BP 369
EP 374
DI 10.1097/YCO.0000000000000609
PG 6
WC Psychiatry
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Psychiatry
GA QJ0PG
UT WOS:000619392200011
PM 32250986
DA 2022-04-17
ER

PT J
AU Sharma, M
   Kumar, CJ
   Deka, A
AF Sharma, Mayuri
   Kumar, Chandan Jyoti
   Deka, Aniruddha
TI Early diagnosis of rice plant disease using machine learning techniques
SO ARCHIVES OF PHYTOPATHOLOGY AND PLANT PROTECTION
LA English
DT Article
DE Deep learning; machine learning; rice disease diagnosis; transfer
   learning
ID NITROGEN NUTRITION STATUS; DIGITAL CAMERA; LEAF; CLASSIFICATION;
   RECOGNITION
AB There is an incredible progress in machine learning applications in the field of agricultural research. Detection of various diseases, deficiencies, and factors impacting crops' productivity is one of the major ongoing research in this field. This paper considers various machine learning and deep learning techniques (transfer learning) for rice disease detection. In this study three different rice diseases viz. bacterial blight, rice blast, and brown spot are considered. A detailed comparative analysis of the results indicates the superiority of transfer learning techniques over conventional machine learning techniques. It is observed that InceptionResNetV2 achieves the best result followed by XceptionNet. This work can be incorporated in assisting the farmers for early diagnosis of rice disease so that future course of action may be taken on time. For future studies, efforts should be directed to work with bigger datasets so as to generalize the findings of the experiment.
C1 [Sharma, Mayuri] Assam Rajiv Gandhi Univ Cooperat Management, Dept Comp Sci Engn, Dicial Dhulia Gaon 785665, Assam, India.
   [Kumar, Chandan Jyoti] Cotton Univ, Dept Comp Sci & IT, Gauhati, Assam, India.
   [Deka, Aniruddha] Assam Royal Global Univ, Dept Comp Sci Engn & IT, Gauhati, Assam, India.
RP Sharma, M (corresponding author), Assam Rajiv Gandhi Univ Cooperat Management, Dept Comp Sci Engn, Dicial Dhulia Gaon 785665, Assam, India.
EM mayurisarmah71@gmail.com
OI Sharma, Mayuri/0000-0003-3282-2765
NR 65
TC 1
Z9 1
U1 4
U2 4
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0323-5408
EI 1477-2906
J9 ARCH PHYTOPATH PLANT
JI Arch. Phytopathol. Plant Protect.
PD FEB 3
PY 2022
VL 55
IS 3
BP 259
EP 283
DI 10.1080/03235408.2021.2015866
EA DEC 2021
PG 25
WC Plant Sciences
WE Emerging Sources Citation Index (ESCI)
SC Plant Sciences
GA YU2BB
UT WOS:000732559000001
DA 2022-04-17
ER

PT J
AU Feehan, R
   Montezano, D
   Slusky, JSG
AF Feehan, Ryan
   Montezano, Daniel
   Slusky, Joanna S. G.
TI Machine learning for enzyme engineering, selection and design
SO PROTEIN ENGINEERING DESIGN & SELECTION
LA English
DT Review
DE deep learning; enzyme design; enzyme engineering; machine learning
ID PREDICTION; SEQUENCE; OPTIMIZATION; EVOLUTION; DATABASE; NETWORK; MODELS
AB Machine learning is a useful computational tool for large and complex tasks such as those in the field of enzyme engineering, selection and design. In this review, we examine enzyme-related applications of machine learning. We start by comparing tools that can identify the function of an enzyme and the site responsible for that function. Then we detail methods for optimizing important experimental properties, such as the enzyme environment and enzyme reactants. We describe recent advances in enzyme systems design and enzyme design itself. Throughout we compare and contrast the data and algorithms used for these tasks to illustrate how the algorithms and data can be best used by future designers.
C1 [Feehan, Ryan; Montezano, Daniel; Slusky, Joanna S. G.] Univ Kansas, Ctr Computat Biol, 2030 Becker Dr, Lawrence, KS 66047 USA.
   [Slusky, Joanna S. G.] Univ Kansas, Dept Mol Biosci, 1200 Sunnyside Ave, Lawrence, KS 66045 USA.
RP Slusky, JSG (corresponding author), Univ Kansas, Ctr Computat Biol, 2030 Becker Dr, Lawrence, KS 66047 USA.; Slusky, JSG (corresponding author), Univ Kansas, Dept Mol Biosci, 1200 Sunnyside Ave, Lawrence, KS 66045 USA.
EM slusky@ku.edu
FU National Institute of General Medical Sciences award [DP2GM128201]
FX We gratefully acknowledge helpful discussions with Meghan W. Franklin as
   well as funding from National Institute of General Medical Sciences
   award DP2GM128201.
NR 69
TC 0
Z9 0
U1 44
U2 53
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 1741-0126
EI 1741-0134
J9 PROTEIN ENG DES SEL
JI Protein Eng. Des. Sel.
PD JUL 23
PY 2021
VL 34
DI 10.1093/protein/gzab019
PG 10
WC Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology
GA US5TD
UT WOS:000697490500001
DA 2022-04-17
ER

PT J
AU Moor, M
   Rieck, B
   Horn, M
   Jutzeler, CR
   Borgwardt, K
AF Moor, Michael
   Rieck, Bastian
   Horn, Max
   Jutzeler, Catherine R.
   Borgwardt, Karsten
TI Early Prediction of Sepsis in the ICU Using Machine Learning: A
   Systematic Review
SO FRONTIERS IN MEDICINE
LA English
DT Review
DE sepsis; machine learning; onset prediction; early detection; systematic
   review
ID INTENSIVE-CARE-UNIT; SEPTIC SHOCK; MORTALITY; DEFINITIONS; PERFORMANCE;
   BIOMARKERS; GUIDELINE; AGREEMENT
AB Background: Sepsis is among the leading causes of death in intensive care units (ICUs) worldwide and its recognition, particularly in the early stages of the disease, remains a medical challenge. The advent of an affluence of available digital health data has created a setting in which machine learning can be used for digital biomarker discovery, with the ultimate goal to advance the early recognition of sepsis.
   Objective: To systematically review and evaluate studies employing machine learning for the prediction of sepsis in the ICU.
   Data Sources: Using Embase, Google Scholar, PubMed/Medline, Scopus, and Web of Science, we systematically searched the existing literature for machine learning-driven sepsis onset prediction for patients in the ICU.
   Study Eligibility Criteria: All peer-reviewed articles using machine learning for the prediction of sepsis onset in adult ICU patients were included. Studies focusing on patient populations outside the ICU were excluded.
   Study Appraisal and Synthesis Methods: A systematic review was performed according to the PRISMA guidelines. Moreover, a quality assessment of all eligible studies was performed.
   Results: Out of 974 identified articles, 22 and 21 met the criteria to be included in the systematic review and quality assessment, respectively. A multitude of machine learning algorithms were applied to refine the early prediction of sepsis. The quality of the studies ranged from "poor" (satisfying <= 40% of the quality criteria) to "very good" (satisfying >= 90% of the quality criteria). The majority of the studies (n = 19, 86.4%) employed an offline training scenario combined with a horizon evaluation, while two studies implemented an online scenario (n = 2, 9.1%). The massive inter-study heterogeneity in terms of model development, sepsis definition, prediction time windows, and outcomes precluded a meta-analysis. Last, only two studies provided publicly accessible source code and data sources fostering reproducibility.
   Limitations: Articles were only eligible for inclusion when employing machine learning algorithms for the prediction of sepsis onset in the ICU. This restriction led to the exclusion of studies focusing on the prediction of septic shock, sepsis-related mortality, and patient populations outside the ICU.
   Conclusions and Key Findings: A growing number of studies employs machine learning to optimize the early prediction of sepsis through digital biomarker discovery. This review, however, highlights several shortcomings of the current approaches, including low comparability and reproducibility. Finally, we gather recommendations how these challenges can be addressed before deploying these models in prospective analyses.
   Systematic Review Registration Number: CRD42020200133.
C1 [Moor, Michael; Rieck, Bastian; Horn, Max; Jutzeler, Catherine R.; Borgwardt, Karsten] Eidgenoss TH Zurich ETH Zurich, Machine Learning & Computat Biol Lab, Dept Biosyst Sci & Engn, Basel, Switzerland.
   [Moor, Michael; Rieck, Bastian; Horn, Max; Jutzeler, Catherine R.; Borgwardt, Karsten] SIB Swiss Inst Bioinformat, Lausanne, Switzerland.
RP Moor, M (corresponding author), Eidgenoss TH Zurich ETH Zurich, Machine Learning & Computat Biol Lab, Dept Biosyst Sci & Engn, Basel, Switzerland.; Moor, M (corresponding author), SIB Swiss Inst Bioinformat, Lausanne, Switzerland.
EM michael.moor@bsse.ethz.ch
RI Rieck, Bastian/J-7507-2019
OI Rieck, Bastian/0000-0003-4335-0302; Borgwardt,
   Karsten/0000-0001-7221-2393
FU Strategic Focal Area Personalized Health and Related Technologies (PHRT)
   of the ETH Domain [2017-110]; Swiss National Science FoundationSwiss
   National Science Foundation (SNSF)European Commission [PZ00P3186101];
   Alfried Krupp Prize for Young University Teachers of the Alfried Krupp
   von Bohlen und Halbach-Stiftung
FX This project was supported by the Strategic Focal Area Personalized
   Health and Related Technologies (PHRT) of the ETH Domain for the
   SPHN/PHRT Driver Project Personalized Swiss Sepsis Study (Borgwardt,
   #2017-110) and the Swiss National Science Foundation (Ambizione Grant,
   PZ00P3186101, Jutzeler). Moreover, this work was funded in part by the
   Alfried Krupp Prize for Young University Teachers of the Alfried Krupp
   von Bohlen und Halbach-Stiftung (KB). The funders had no role in study
   design, data collection and analysis, decision to publish, or
   preparation of the manuscript.
NR 75
TC 6
Z9 6
U1 15
U2 24
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2296-858X
J9 FRONT MED-LAUSANNE
JI Front. Med.
PD MAY 28
PY 2021
VL 8
AR 607952
DI 10.3389/fmed.2021.607952
PG 18
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA SQ0OE
UT WOS:000660059900001
PM 34124082
OA Green Published, Green Submitted, gold
DA 2022-04-17
ER

PT C
AU Bose, B
   Priya, J
   Welekar, S
   Gao, ZY
AF Bose, Bipasa
   Priya, Jyotsna
   Welekar, Sonam
   Gao, Zeyu
BE Hu, J
   Min, G
   Georgalas, N
   Zhao, Z
   Hao, F
   Miao, W
TI Hemp Disease Detection and Classification Using Machine Learning and
   Deep Learning
SO 2020 IEEE INTL SYMP ON PARALLEL & DISTRIBUTED PROCESSING WITH
   APPLICATIONS, INTL CONF ON BIG DATA & CLOUD COMPUTING, INTL SYMP SOCIAL
   COMPUTING & NETWORKING, INTL CONF ON SUSTAINABLE COMPUTING &
   COMMUNICATIONS (ISPA/BDCLOUD/SOCIALCOM/SUSTAINCOM 2020)
SE IEEE International Symposium on Parallel and Distributed Processing with
   Applications
LA English
DT Proceedings Paper
CT 18th IEEE Int Symp on Parallel and Distributed Proc with Applicat (ISPA)
   / 10th IEEE Int Conf on Big Data and Cloud Comp (BDCloud) / IEEE Int
   Symp on Social Comp and Networking (SocialCom) / IEEE Int Conf on
   Sustainable Comp and Commun (SustainCom)
CY DEC 17-19, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, IEEE Tech Comm Scalable Comp
DE Deep learning; feature extraction; hemp disease detection and
   classification; machine learning; model training; smart agriculture;
   transfer learning
AB Hemp is a multipurpose plant that has industrial as well as medicinal value. The plant is easy to grow, maintain, and suitable under any climate. However, just like other plants, Hemp diseases affect plant growth and cause a significant economic loss in hemp production. With the rapid advancement of artificial intelligence and machine learning technology, researchers have started using data-driven machine learning approaches in smart agriculture and farming. Plant disease detection and classification is an application of the smart agriculture technique. This paper focuses on hemp disease detection and classification by proposing one SVM-based machine learning model and three deep learning ensemble models. The focused hemp diseases include Hemp Powdery Mildew, Hemp Leaf Spot, Hemp Bud Rot, and Hemp Nutrient Deficiency. The paper uses pre-trained deep learning ensemble models with transfer learning. It reports comparative evaluation results of the three deep learning ensemble models with an SVM-based model with manual feature extraction. The evaluation results from different models show as high as 98% accuracy with strong application potential.
C1 [Bose, Bipasa] San Jose State Univ, Dept Biomed Engn, San Jose, CA 95192 USA.
   [Priya, Jyotsna; Welekar, Sonam; Gao, Zeyu] San Jose State Univ, Dept Comp Engn, San Jose, CA 95192 USA.
RP Gao, ZY (corresponding author), San Jose State Univ, Dept Comp Engn, San Jose, CA 95192 USA.
EM bipasa.bose@sjsu.edu; jyotsna.priya@sjsu.edu; sonam.welekar@sjsu.edu;
   jerry.gao@sjsu.edu
NR 24
TC 0
Z9 0
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
SN 2158-9178
BN 978-1-6654-1485-2
J9 IEEE INT SYMP PARAL
PY 2020
BP 762
EP 769
DI 10.1109/ISPA-BDCloud-SocialCom-SustainCom51426.2020.00121
PG 8
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Interdisciplinary Applications; Computer
   Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS0RK
UT WOS:000684021500095
DA 2022-04-17
ER

PT J
AU Chin, K
   Hellebrekers, T
   Majidi, C
AF Chin, Keene
   Hellebrekers, Tess
   Majidi, Carmel
TI Machine Learning for Soft Robotic Sensing and Control
SO ADVANCED INTELLIGENT SYSTEMS
LA English
DT Article
DE control; machine learning; neural networks; sensing; soft robotics
ID DESIGN; MOTION
AB Herein, the progress of machine learning methods in the field of soft robotics, specifically in the applications of sensing and control, is outlined. Data-driven methods such as machine learning are especially suited to systems with governing functions that are unknown, impractical or impossible to represent analytically, or computationally intractable to integrate into real-world solutions. Function approximation with careful formulation of the machine learning architecture enables the encoding of dynamic behavior and nonlinearities, with the added potential to address hysteresis and nonstationary behavior. Supervised learning and reinforcement learning in simulation and on a wide variety of physical robotic systems have shown promising results for the use of empirical data-driven methods as a solution to contemporary soft robotics problems.
C1 [Chin, Keene; Hellebrekers, Tess; Majidi, Carmel] Carnegie Mellon Univ, Dept Mech Engn, Pittsburgh, PA 15213 USA.
RP Majidi, C (corresponding author), Carnegie Mellon Univ, Dept Mech Engn, Pittsburgh, PA 15213 USA.
EM cmajidi@andrew.cmu.edu
OI Majidi, Carmel/0000-0002-6469-9645
FU National Science Foundation (NSF) Graduate Research Fellowship Program
   (GRFP)National Science Foundation (NSF)NSF - Office of the Director (OD)
   [DGE 1252522]; National Oceanographic Partnership Program (NOPP)
   [N000141812843]
FX This work was in part supported by the National Science Foundation (NSF)
   Graduate Research Fellowship Program (GRFP) under Grant No. DGE 1252522
   and the National Oceanographic Partnership Program (NOPP) under Grant
   No. N000141812843 (PM: Dr. Reginald Beach). Any opinions, findings, and
   conclusions or recommendations expressed in this material are those of
   the author(s) and do not necessarily reflect the views of the NSF or
   NOPP.
NR 54
TC 33
Z9 33
U1 11
U2 13
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
EI 2640-4567
J9 ADV INTELL SYST-GER
JI Adv. Intell. Syst.
PD JUN
PY 2020
VL 2
IS 6
SI SI
AR 1900171
DI 10.1002/aisy.201900171
PG 8
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Robotics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science; Robotics
GA TE1KT
UT WOS:000669776700006
OA gold
DA 2022-04-17
ER

PT J
AU Paltun, BG
   Kaski, S
   Mamitsuka, H
AF Paltun, Betul Guvenc
   Kaski, Samuel
   Mamitsuka, Hiroshi
TI Machine learning approaches for drug combination therapies
SO BRIEFINGS IN BIOINFORMATICS
LA English
DT Review
DE machine learning; drug combination therapy; personalized medicine;
   bioinformatics; data integration
ID SMALL MOLECULES; TARGET NETWORK; CANCER; PREDICTION; DATABASE; SYNERGY;
   GENES; QUANTIFICATION; SIGNATURES; DISCOVERY
AB Drug combination therapy is a promising strategy to treat complex diseases such as cancer and infectious diseases. However, current knowledge of drug combination therapies, especially in cancer patients, is limited because of adverse drug effects, toxicity and cell line heterogeneity. Screening new drug combinations requires substantial efforts since considering all possible combinations between drugs is infeasible and expensive. Therefore, building computational approaches, particularly machine learning methods, could provide an effective strategy to overcome drug resistance and improve therapeutic efficacy. In this review, we group the state-of-the-art machine learning approaches to analyze personalized drug combination therapies into three categories and discuss each method in each category. We also present a short description of relevant databases used as a benchmark in drug combination therapies and provide a list of well-known, publicly available interactive data analysis portals. We highlight the importance of data integration on the identification of drug combinations. Finally, we address the advantages of combining multiple data sources on drug combination analysis by showing an experimental comparison.
C1 [Kaski, Samuel; Mamitsuka, Hiroshi] Aalto Univ, Espoo 02150, Finland.
   [Mamitsuka, Hiroshi] Kyoto Univ, Inst Chem Res, Bioinformat Ctr, Uji 6110011, Japan.
   [Paltun, Betul Guvenc] Aalto Univ, Probabilist Machine Learning Grp, Espoo, Finland.
   [Kaski, Samuel] Univ Manchester, Manchester, Lancs, England.
   [Kaski, Samuel] Finnish Ctr Artificial Intelligence FCAI, Helsinki, Finland.
   [Kaski, Samuel] ELLIS Unit Helsinki, Helsinki, Finland.
RP Paltun, BG (corresponding author), Helsinki Inst Informat Technol HIIT, Dept Comp Sci, Espoo 02150, Finland.; Paltun, BG; Mamitsuka, H (corresponding author), Aalto Univ, Espoo 02150, Finland.; Mamitsuka, H (corresponding author), Kyoto Univ, Inst Chem Res, Bioinformat Ctr, Uji 6110011, Japan.; Mamitsuka, H (corresponding author), Alato Univ, Dept Comp Sci, Espoo 02150, Finland.
EM betul.guvenc@aalto.fi; mami@kuicr.kyoto-u.ac.jp
RI Kaski, Samuel/B-6684-2008
OI Kaski, Samuel/0000-0003-1925-9154
FU JST ACCELJapan Science & Technology Agency (JST) [JPMJAC1503]; MEXT
   KakenhiMinistry of Education, Culture, Sports, Science and Technology,
   Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for
   Scientific Research (KAKENHI) [16H02868, 19H04169]; Academy of
   FinlandAcademy of Finland [315896]; Finnish Center for Artificial
   Intelligence FCAI [320181]
FX H.M. has been supported in part by JST ACCEL (JPMJAC1503); MEXT Kakenhi
   (16H02868, 19H04169). Academy of Finland (315896); and the Finnish
   Center for Artificial Intelligence FCAI (320181).
NR 79
TC 0
Z9 0
U1 22
U2 27
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 1467-5463
EI 1477-4054
J9 BRIEF BIOINFORM
JI Brief. Bioinform.
PD NOV
PY 2021
VL 22
IS 6
AR bbab293
DI 10.1093/bib/bbab293
EA AUG 2021
PG 16
WC Biochemical Research Methods; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Mathematical & Computational Biology
GA XT0ZO
UT WOS:000733325700163
PM 34368832
OA Green Published, hybrid
DA 2022-04-17
ER

PT C
AU Ye, Z
AF Ye, Zhou
GP ASSOC COMP MACHINERY
TI Integration of Machine Learning with MEC for Intelligent Applications
SO IPMV 2021: PROCEEDINGS OF 2021 3RD INTERNATIONAL CONFERENCE ON IMAGE
   PROCESSING AND MACHINE VISION (IPMV 2021)
LA English
DT Proceedings Paper
CT 3rd International Conference on Image Processing and Machine Vision
   (IPMV)
CY MAY 22-24, 2021
CL ELECTR NETWORK
DE Edge Computing; Mobile Computing; Machine learning; Best Of-floading
   Decision; Intelligent Applications
AB In recent years, telecom operators and large companies are eager to obtain value from the edge of the network, and the priority of cloud computing has been transferred from the center to the edge. In addition, with the comprehensive deployment of 5G base station (BS), the number of 5G users has been largely increased. For 5G users, they expect to have a better experience of high bandwidth and low latency. Thus, the Mobile Edge Computing (MEC) came into being. MEC brings the capability from the center to the edge of the mobile network. Requests and data of User equipment (UE) has been underlined in MEC. These requests and data will be analyzed and disposed at the edge without being uploaded to the cloud center, which diminishes the latency efficiently. Besides, with the help of machine learning, MEC can show a better performance. This paper is aimed at studying superiorities of MEC itself and integration of machine learning with MEC, and intelligent applications they will bring. This paper first discusses the concept and architecture of MEC, then the advantages of MEC are listed. Next, the improvements of integration of machine learning with MEC and the intelligent applications which employ these technologies will be introduced. Finally, the deficiencies and future research trend of MEC will be discussed. After that, conclusion can be drought that MEC augment the performance of speed, security and privacy, energy saving and reliability. Furthermore, integration of machine learning with MEC can provide better resource management and offloading decision.
C1 [Ye, Zhou] Nanjing Univ Posts & Telecommun, Sch Internet Things, Nanjing 210000, Peoples R China.
RP Ye, Z (corresponding author), Nanjing Univ Posts & Telecommun, Sch Internet Things, Nanjing 210000, Peoples R China.
EM b18060413@njupt.edu.cn
NR 13
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-9004-0
PY 2021
BP 82
EP 87
DI 10.1145/3469951.3469966
PG 6
WE Conference Proceedings Citation Index - Science (CPCI-S)
GA BS8CE
UT WOS:000770804100015
DA 2022-04-17
ER

PT C
AU Hakola, AM
   Polonen, I
AF Hakola, Anna-Maria
   Polonen, Ilkka
BE Bruzzone, L
   Bovolo, F
   Santi, E
TI Minimal learning machine in hyperspectral imaging classification
SO IMAGE AND SIGNAL PROCESSING FOR REMOTE SENSING XXVI
SE Proceedings of SPIE
LA English
DT Proceedings Paper
CT Conference on Image and Signal Processing for Remote Sensing XXVI
CY SEP 21-25, 2020
CL ELECTR NETWORK
SP SPIE
DE Hyperspectral Imaging; Minimal Learning Machine; Classification;
   Principal Component Analysis; Distance Learning
ID RANDOM FOREST; SELECTION; CLASSIFIERS; TRENDS
AB A hyperspectral (HS) image is typically a stack of frames, where each frame represents the intensity of a different wavelength of light. Each spatial pixel has a spectrum. In the classification of the HS image, each spectrum is classified pixel-by-pixel. In some of the real-time applications, the amount of the HS image data causes performance challenges. Those issues relate to the platforms (e.g. drones) payload restrictions, the issues of the available energy and to the complexity of the machine learning models.
   In this study, we introduce the minimal learning machine (MLM) as a computationally cheap training and classification machine learning method for the hyperspectral imaging classification. MLM is a distance-based method that utilizes mapping between input and and output distances. Input distance is a distance between the training set and its subset R. Output distance is corresponding distances between the label values of the training set and the subset R. We propose a training point selection framework, which reduces the number of data points in the R by selecting the points class-by-class, in the direction of the principal components of each class.
   We test MLM's performance against four other classification machine learning methods: Random Forest, Artificial Neural Network, Support Vector Machine and Nearest Neighbours classifier with three known hyperspectral data sets. As the main outcomes, we will show how the performance is affected by the size of the subset R. We compare our subset selection method MLM's performance to the random selection MLM's performance. Results show that MLM is an computationally efficient way to train large training sets. MLM reduces the complexity of the analysis and provides computational benefits against other models. Proposed framework offers tools that can improve the MLM's classification time and the accuracy rate compared to the MLM with randomly picked training points.
C1 [Hakola, Anna-Maria; Polonen, Ilkka] Univ Jyvaskyla, Fac Informat Technol, Jyvaskyla 40100, Finland.
RP Hakola, AM (corresponding author), Univ Jyvaskyla, Fac Informat Technol, Jyvaskyla 40100, Finland.
EM anna.m.hakola@jyu.fi; ilkka.polonen@jyu.fi
RI Raita-Hakola, Anna-Maria/AAB-4937-2022; Pölönen, Ilkka/AAS-8665-2021;
   Pölönen, Ilkka/AAF-4636-2019
OI Pölönen, Ilkka/0000-0002-5129-7364; 
FU Jane and Aatos Erkko Foundation [170015]; Academy of FinlandAcademy of
   Finland [327862]
FX This study is partly funded by Jane and Aatos Erkko Foundation (Grant
   No. 170015) and Academy of Finland (Grant No. 327862).
NR 26
TC 0
Z9 0
U1 1
U2 2
PU SPIE-INT SOC OPTICAL ENGINEERING
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA
SN 0277-786X
EI 1996-756X
BN 978-1-5106-3880-8
J9 PROC SPIE
PY 2020
VL 11533
AR 115330R
DI 10.1117/12.2573578
PG 19
WC Remote Sensing; Optics; Imaging Science & Photographic Technology
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Remote Sensing; Optics; Imaging Science & Photographic Technology
GA BQ9JO
UT WOS:000625211400021
OA Green Accepted
DA 2022-04-17
ER

PT C
AU Vachhani, H
   Obiadat, MS
   Thakkar, A
   Shah, V
   Sojitra, R
   Bhatia, J
   Tanwar, S
AF Vachhani, Hrishikesh
   Obiadat, Mohammad S.
   Thakkar, Arkesh
   Shah, Vyom
   Sojitra, Raj
   Bhatia, Jitendra
   Tanwar, Sudeep
BE Raj, JS
   Bashar, A
   Ramson, SRJ
TI Machine Learning Based Stock Market Analysis: A Short Survey
SO INNOVATIVE DATA COMMUNICATION TECHNOLOGIES AND APPLICATION
SE Lecture Notes on Data Engineering and Communications Technologies
LA English
DT Proceedings Paper
CT International Conference on Innovative Data Communication Technologies
   and Application (ICIDCA)
CY OCT 17-18, 2019
CL Coimbatore, INDIA
DE Stock market prediction; Machine Learning; Stock analysis
ID PREDICTION; DEEP
AB Finance is one of the pioneering industries that started using Machine Learning (ML), a subset of Artificial Intelligence (AI) in the early 80s for market prediction. Since then, major firms and hedge funds have adopted machine learning for stock prediction, portfolio optimization, credit lending, stock betting, etc. In this paper, we survey all the different approaches of machine learning that can be incorporated in applied finance. The major motivation behind ML is to draw out the specifics from the available data from different sources and to forecast from it. Different machine learning algorithms has their abilities for predictions and are heavily depended on the number and quality of parameters as input features. This work attempts to provide an extensive and objective walkthrough in the direction of applicability of the machine learning algorithms for financial or stock market prediction.
C1 [Vachhani, Hrishikesh; Thakkar, Arkesh; Shah, Vyom; Sojitra, Raj; Bhatia, Jitendra] GTU, Vishwakarma Govt Engn Coll, Ahmadabad, Gujarat, India.
   [Obiadat, Mohammad S.] Univ Sharjah, Coll Comp & Informat, Sharjah, U Arab Emirates.
   [Obiadat, Mohammad S.] Univ Jordan, King Abdullah II Sch IT, Amman, Jordan.
   [Obiadat, Mohammad S.] Univ Sci & Technol Beijing, Beijing, Peoples R China.
   [Obiadat, Mohammad S.] Al Balqa Appl Univ, Coll Engn, Al Salt, Jordan.
   [Tanwar, Sudeep] Nirma Univ, Inst Technol, Dept Comp Sci & Engn, Ahmadabad, Gujarat, India.
RP Obiadat, MS (corresponding author), Univ Sharjah, Coll Comp & Informat, Sharjah, U Arab Emirates.; Obiadat, MS (corresponding author), Univ Jordan, King Abdullah II Sch IT, Amman, Jordan.; Obiadat, MS (corresponding author), Univ Sci & Technol Beijing, Beijing, Peoples R China.; Obiadat, MS (corresponding author), Al Balqa Appl Univ, Coll Engn, Al Salt, Jordan.; Tanwar, S (corresponding author), Nirma Univ, Inst Technol, Dept Comp Sci & Engn, Ahmadabad, Gujarat, India.
EM hrishikeshvachhani@gmail.com; m.s.obaidat@ieee.org;
   arkesh.thakar14@gmail.com; shahvyom18@gmail.com; rajsojitra79@gmail.com;
   jitendrabbhatia@gmail.com; sudeep.tanwar@nirmauni.ac.in
RI Tanwar, Sudeep/AAI-6709-2020
OI Tanwar, Sudeep/0000-0002-1776-4651
NR 38
TC 3
Z9 3
U1 11
U2 20
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2367-4512
BN 978-3-030-38040-3; 978-3-030-38039-7
J9 LECT NOTE DATA ENG
PY 2020
VL 46
BP 12
EP 26
DI 10.1007/978-3-030-38040-3_2
PG 15
WC Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Telecommunications
GA BR5WO
UT WOS:000657957000002
DA 2022-04-17
ER

PT J
AU Zhao, YW
   Fan, Z
   Du, ZD
   Zhi, T
   Li, L
   Guo, Q
   Liu, SL
   Xu, ZW
   Chen, TS
   Chen, YJ
AF Zhao, Yongwei
   Fan, Zhe
   Du, Zidong
   Zhi, Tian
   Li, Ling
   Guo, Qi
   Liu, Shaoli
   Xu, Zhiwei
   Chen, Tianshi
   Chen, Yunji
TI Machine Learning Computers With Fractal von Neumann Architecture
SO IEEE TRANSACTIONS ON COMPUTERS
LA English
DT Article
DE Machine learning; Computers; Fractals; Programming; Computer
   architecture; Graphics processing units; Matrix decomposition; Machine
   learning; architecture; neural networks; programming efficiency
AB Machine learning techniques are pervasive tools for emerging commercial applications and many dedicated machine learning computers on different scales have been deployed in embedded devices, servers, and data centers. Currently, most machine learning computer architectures still focus on optimizing performance and energy efficiency instead of programming productivity. However, with the fast development in silicon technology, programming productivity, including programming itself and software stack development, becomes the vital reason instead of performance and power efficiency that hinders the application of machine learning computers. In this article, we propose Cambricon-F, which is a series of homogeneous, sequential, multi-layer, layer-similar, and machine learning computers with same ISA. A Cambricon-F machine has a fractal von Neumann architecture to iteratively manage its components: it is with von Neumann architecture and its processing components (sub-nodes) are still Cambricon-F machines with von Neumann architecture and the same ISA. Since different Cambricon-F instances with different scales can share the same software stack on their common ISA, Cambricon-Fs can significantly improve the programming productivity. Moreover, we address four major challenges in Cambricon-F architecture design, which allow Cambricon-F to achieve a high efficiency. We implement two Cambricon-F instances at different scales, i.e., Cambricon-F100 and Cambricon-F1. Compared to GPU based machines (DGX-1 and 1080Ti), Cambricon-F instances achieve 2.82x, 5.14x better performance, 8.37x, 11.39x better efficiency on average, with 74.5, 93.8 percent smaller area costs, respectively. We further propose Cambricon-FR, which enhances the Cambricon-F machine learning computers to flexibly and efficiently support all the fractal operations with a reconfigurable fractal instruction set architecture. Compared to the Cambricon-F instances, Cambricon-FR machines achieve 1.96x, 2.49x better performance on average. Most importantly, Cambricon-FR computers are able to save the code length with a factor of 5.83, thus significantly improving the programming productivity.
C1 [Zhao, Yongwei; Fan, Zhe; Du, Zidong; Zhi, Tian; Guo, Qi; Liu, Shaoli; Xu, Zhiwei; Chen, Tianshi; Chen, Yunji] Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing 100190, Peoples R China.
   [Zhao, Yongwei; Fan, Zhe; Xu, Zhiwei; Chen, Yunji] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Zhao, Yongwei; Fan, Zhe; Du, Zidong; Zhi, Tian; Liu, Shaoli; Chen, Tianshi] Cambricon Technol, Beijing, Peoples R China.
   [Li, Ling] Chinese Acad Sci, Inst Software, Beijing 100190, Peoples R China.
   [Chen, Yunji] CAS Ctr Excellence Brain Sci & Intelligence Techn, Shanghai Res Ctr Brian Sci & Brain Inspired Intel, Inst Brain Intelligence Technol, Zhangjiang Lab BIT,ZfLab, Beijing, Peoples R China.
RP Du, ZD (corresponding author), Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing 100190, Peoples R China.
EM zhaoyongwei@ict.ac.cn; fanzhe@ict.ac.cn; duzidong@ict.ac.cn;
   zhitian@ict.ac.cn; liling@iscas.ac.cn; guoqi@ict.ac.cn;
   liushaoli@ict.ac.cn; zxu@ict.ac.cn; chentianshi@ict.ac.cn; cyj@ict.ac.cn
OI zhao, yong wei/0000-0002-5503-4457; Xu, Zhiwei/0000-0002-1480-7265
FU National Key Research and Development Program of China [2017YFB1003101,
   2018AAA0103300, 2017YFA0700900, 2017YFA0700902, 2017YFA0700901]; NSF of
   ChinaNational Natural Science Foundation of China (NSFC) [61732007,
   61432016, 61532016, 61672491, 61602441, 61602446, 61732002, 61702478,
   61732020]; Beijing Natural Science FoundationBeijing Natural Science
   Foundation [JQ18013]; National Science and Technology Major Project
   [2018ZX01031102]; Transformation and Transfer of Scientific and
   Technological Achievements of Chinese Academy of Sciences [KFJ-HGZX013];
   Key Research Projects in Frontier Science of Chinese Academy of Sciences
   [QYZDB-SSW-JSC001]; Strategic Priority Research Program of Chinese
   Academy of Science [XDB32050200, XDC01020000]; Standardization Research
   Project of Chinese Academy of Sciences [BZ201800001]; Beijing Academy of
   Aritificial Intelligence (BAAI); Beijing Nova Program of Science and
   Technology [Z191100001119093]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2017YFB1003101, Grant
   2018AAA0103300, Grant 2017YFA0700900, Grant 2017YFA0700902, and Grant
   2017YFA0700901, in part by the NSF of China (under Grant 61732007, Grant
   61432016, Grant 61532016, Grant 61672491, Grant 61602441, Grant
   61602446, Grant 61732002, Grant 61702478, and Grant 61732020), in part
   by Beijing Natural Science Foundation (JQ18013), in part by National
   Science and Technology Major Project (2018ZX01031102), in part by the
   Transformation and Transfer of Scientific and Technological Achievements
   of Chinese Academy of Sciences (KFJ-HGZX013), in part by Key Research
   Projects in Frontier Science of Chinese Academy of Sciences
   (QYZDB-SSW-JSC001), in part by Strategic Priority Research Program of
   Chinese Academy of Science (XDB32050200, XDC01020000), in part by the
   Standardization Research Project of Chinese Academy of Sciences
   (BZ201800001), in part by the Beijing Academy of Aritificial
   Intelligence (BAAI), and in part by the Beijing Nova Program of Science
   and Technology (Z191100001119093).
NR 65
TC 0
Z9 0
U1 4
U2 16
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0018-9340
EI 1557-9956
J9 IEEE T COMPUT
JI IEEE Trans. Comput.
PD JUL 1
PY 2020
VL 69
IS 7
BP 998
EP 1014
DI 10.1109/TC.2020.2982159
PG 17
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MB9XF
UT WOS:000542950100007
DA 2022-04-17
ER

PT C
AU Ketsbaia, L
   Issac, B
   Chen, XM
AF Ketsbaia, Lida
   Issac, Biju
   Chen, Xiaomin
BE Wang, GJ
   Ko, R
   Bhuiyan, MZA
   Pan, Y
TI Detection of Hate Tweets using Machine Learning and Deep Learning
SO 2020 IEEE 19TH INTERNATIONAL CONFERENCE ON TRUST, SECURITY AND PRIVACY
   IN COMPUTING AND COMMUNICATIONS (TRUSTCOM 2020)
SE IEEE International Conference on Trust Security and Privacy in Computing
   and Communications
LA English
DT Proceedings Paper
CT 19th IEEE International Conference on Trust, Security and Privacy in
   Computing and Communications (IEEE TrustCom)
CY DEC 29-JAN 01, 2020-2021
CL Guangzhou, PEOPLES R CHINA
SP IEEE, IEEE Comp Soc
DE Hate Speech; CNN; Machine Learning; Word2Vec; Doc2Vec
AB Cyberbullying has become a highly problematic occurrence due to its potential of anonymity and its ease for others to join in the harassment of victims. The distancing effect that technological devices have, has led to cyberbullies say and do harsher things compared to what is typical in a traditional face-to-face bullying situation. Given the great importance of the problem, detection is becoming a key area of cyberbullying research. Therefore, it is highly necessary for a framework to accurately detect new cyberbullying instances automatically. To review the machine learning and deep learning approaches, two datasets were used. The first dataset was provided by the University of Maryland consisting of over 30,000 tweets, whereas the second dataset was based on the article 'Automated Hate Speech Detection and the Problem of Offensive Language' by Davidson et al., containing roughly 25,000 tweets. The paper explores machine learning approaches using word embeddings such as DBOW (Distributed Bag of Words) and DMM (Distributed Memory Mean) and the performance of Word2vec Convolutional Neural Networks (CNNs) to classify online hate.
C1 [Ketsbaia, Lida; Issac, Biju; Chen, Xiaomin] Northumbria Univ, Comp & Informat Sci, Newcastle Upon Tyne, Tyne & Wear, England.
RP Ketsbaia, L (corresponding author), Northumbria Univ, Comp & Informat Sci, Newcastle Upon Tyne, Tyne & Wear, England.
EM lida.ketsbaia@northumbria.ac.uk; biju.issac@northumbria.ac.uk;
   xaiomin.chen@northumbria.ac.uk
RI Issac, Biju/E-2465-2011
OI Issac, Biju/0000-0002-1109-8715
NR 41
TC 0
Z9 0
U1 3
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
SN 2324-898X
BN 978-1-6654-0392-4
J9 IEEE INT CONF TRUST
PY 2020
BP 751
EP 758
DI 10.1109/TrustCom50675.2020.00103
PG 8
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Theory & Methods; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Telecommunications
GA BR8DU
UT WOS:000671077600089
OA Green Accepted
DA 2022-04-17
ER

PT C
AU Tverdokhlib, Y
   Andrunyk, V
   Chyrun, L
   Chyrun, L
   Antonyuk, N
   Dyyak, I
   Naum, O
   Uhryn, D
   Basto-Fernandes, V
AF Tverdokhlib, Yurii
   Andrunyk, Vasyl
   Chyrun, Liliya
   Chyrun, Lyubomyr
   Antonyuk, Nataliya
   Dyyak, Ivan
   Naum, Olch
   Uhryn, Dmytro
   Basto-Fernandes, Vitor
BE Emmerich, M
   Lytvyn, V
   Vysotska, V
   BastoFernandes, V
   Lytvynenko, V
TI Analysis and Estimation of Popular Places in Online Tourism Based on
   Machine Learning Technology
SO MOMLET+DS 2020: MODERN MACHINE LEARNING TECHNOLOGIES AND DATA SCIENCE
   WORKSHOP
SE CEUR Workshop Proceedings-Series
LA English
DT Proceedings Paper
CT 2nd International Workshop on Modern Machine Learning Technologies and
   Data Science (MoMLeT+DS)
CY JUN 02-03, 2020
CL ELECTR NETWORK
SP Leiden Univ, Leiden Inst Adv Comp Sci, Lviv Polytechn Natl Univ, Montfort Univ, Comp Sci, Univ Inst Lisbon, Kherson Natl Tech Univ, Lesya Ukrainka Eastern European Natl Univ, SoftServe, Lviv IT Cluster, Perfectial, Skelia, Fortifier, Envion Software, PI MINDS, SSA Group, SYTOSS
DE Online Tourism; Popular Places; Machine Learning
AB This article discusses and compares some machine-learning regression methods for developing a prognostic model that predicts the daily number of visitors in different areas (tourist places) of India. Visitor reviews from holidayiq.com are used as data. The main features of the selected data set are described.
C1 [Tverdokhlib, Yurii; Andrunyk, Vasyl; Chyrun, Liliya] Lviv Polytech Natl Univ, Lvov, Ukraine.
   [Chyrun, Lyubomyr; Antonyuk, Nataliya; Dyyak, Ivan] Ivan Frank Natl Univ Lviv, Lvov, Ukraine.
   [Antonyuk, Nataliya] Univ Opole, Opole, Poland.
   [Naum, Olch] Drohobych Ivan Frank State Pedag Univ, Drogobych, Ukraine.
   [Uhryn, Dmytro] Chernivtsi Philosoph & Legal Lyceum, Chernovtsy, Ukraine.
   [Basto-Fernandes, Vitor] Univ Inst Lisbon, Lisbon, Portugal.
RP Tverdokhlib, Y (corresponding author), Lviv Polytech Natl Univ, Lvov, Ukraine.
EM yurii.tverdokhlib.sa.2017@lpnu.ua; vasyl.a.andrunyk@lpnu.ua;
   Lyubomyr.Chyrun@lnu.edu.ua; nantonyk@yahoo.com; ivan.dyyak@lnu.edu.ua6;
   oleh.naum@gmail.com; ugrund38@gmail.com
RI Basto-Fernandes, Vitor/N-1891-2016; Chyrun, Lyubomyr/ABD-2429-2020;
   Andrunyk, Vasyl/R-6912-2019
OI Basto-Fernandes, Vitor/0000-0003-4269-5114; Andrunyk,
   Vasyl/0000-0003-0697-7384
NR 61
TC 0
Z9 0
U1 0
U2 0
PU RWTH AACHEN
PI Aachen
PA Ahornstr. 55, Aachen, *, GERMANY
SN 1613-0073
J9 CEUR WORKSHOP PROCEE
PY 2020
VL 2631
PG 14
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Operations Research & Management Science
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Operations Research & Management Science
GA BR6TX
UT WOS:000664104800034
DA 2022-04-17
ER

PT S
AU Morgan, D
   Jacobs, R
AF Morgan, Dane
   Jacobs, Ryan
BE Clarke, DR
TI Opportunities and Challenges for Machine Learning in Materials Science
SO ANNUAL REVIEW OF MATERIALS RESEARCH, VOL 50, 2020
SE Annual Review of Materials Research
LA English
DT Review; Book Chapter
DE machine learning; materials informatics; materials science; model
   assessment; applicability domain; model errors; materials discovery;
   materials design; artificial intelligence
ID ARTIFICIAL-INTELLIGENCE; MATERIALS DISCOVERY; MATERIALS DESIGN;
   PREDICTIONS; ROBOT; TEXT; PERSPECTIVES; INFORMATICS; UNCERTAINTY;
   PERFORMANCE
AB Advances in machine learning have impacted myriad areas of materials science, such as the discovery of novel materials and the improvement ofmolecular simulations, with likely many more important developments to come. Given the rapid changes in this field, it is challenging to understand both the breadth of opportunities and the best practices for their use. In this review, we address aspects of both problems by providing an overview of the areas in which machine learning has recently had significant impact in materials science, and then we provide amore detailed discussion on determining the accuracy and domain of applicability of some common types of machine learning models. Finally, we discuss some opportunities and challenges for the materials community to fully utilize the capabilities of machine learning.
C1 [Morgan, Dane; Jacobs, Ryan] Univ Wisconsin, Dept Mat Sci & Engn, 1509 Univ Ave, Madison, WI 53706 USA.
RP Morgan, D (corresponding author), Univ Wisconsin, Dept Mat Sci & Engn, 1509 Univ Ave, Madison, WI 53706 USA.
EM ddmorgan@wisc.edu; rjacobs3@wisc.edu
RI Morgan, Dane D/B-7972-2008
OI Morgan, Dane D/0000-0002-4911-0046
FU US National Science Foundation through the Software Infrastructure for
   Sustained Innovation (SI2)National Science Foundation (NSF) [1148011];
   Designing Materials to Revolutionize and Engineer our Future
   (DMREF)National Science Foundation (NSF)NSF - Directorate for Computer &
   Information Science & Engineering (CISE) [1728933]; Cyberinfrastructure
   for Sustained Scientific Innovation (CSSI) [1931298]; University of
   Wisconsin-Madison Materials Research Science and Engineering Center
   [DMR-1720415]
FX The authors gratefully acknowledge support of this research by the US
   National Science Foundation through the Software Infrastructure for
   Sustained Innovation (SI2) award number 1148011, which supported aspects
   of the machine learning tools and data used in this work; Designing
   Materials to Revolutionize and Engineer our Future (DMREF) award number
   1728933, which supported aspects of the understanding of model
   development and fitting and relevant collaborations; Cyberinfrastructure
   for Sustained Scientific Innovation (CSSI) award number 1931298, which
   supported exploration of band gap models and machine learning
   infrastructure; and the University of Wisconsin-Madison Materials
   Research Science and Engineering Center (DMR-1720415), which supported
   projects related to QSAR/QSPR that informed this work.
NR 169
TC 26
Z9 26
U1 74
U2 138
PU ANNUAL REVIEWS
PI PALO ALTO
PA 4139 EL CAMINO WAY, PO BOX 10139, PALO ALTO, CA 94303-0897 USA
SN 1531-7331
EI 1545-4118
BN 978-0-8243-1750-8
J9 ANNU REV MATER RES
JI Ann. Rev. Mater. Res.
PY 2020
VL 50
BP 71
EP 103
DI 10.1146/annurev-matsci-070218010015
PG 33
WC Materials Science, Multidisciplinary
WE Book Citation Index – Science (BKCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Materials Science
GA BQ4MC
UT WOS:000590407100004
DA 2022-04-17
ER

PT J
AU Shevchik, S
   Kenhagho, HN
   Le-Quang, T
   Faivre, N
   Meylan, B
   Guzman, R
   Cattin, PC
   Zam, A
   Wasmer, K
AF Shevchik, Sergey
   Nguendon Kenhagho, Herve
   Le-Quang, Tri
   Faivre, Neige
   Meylan, Bastian
   Guzman, Raphael
   Cattin, Philippe C.
   Zam, Azhar
   Wasmer, Kilian
TI Machine learning monitoring for laser osteotomy
SO JOURNAL OF BIOPHOTONICS
LA English
DT Article
DE acoustic emission; laser ablation; machine learning; microphone sensor;
   tissue differentiation
ID ACOUSTIC-EMISSION; ABLATION; TISSUE; BONE
AB This work proposes a new online monitoring method for an assistance during laser osteotomy. The method allows differentiating the type of ablated tissue and the applied dose of laser energy. The setup analyzes the laser-induced acoustic emission, detected by an airborne microphone sensor. The analysis of the acoustic signals is carried out using a machine learning algorithm that is pre-trained in a supervised manner. The efficiency of the method is experimentally evaluated with several types of tissues, which are: skin, fat, muscle, and bone. Several cutting-edge machine learning frameworks are tested for the comparison with the resulting classification accuracy in the range of 84-99%. It is shown that the datasets for the training of the machine learning algorithms are easy to collect in real-life conditions. In the future, this method could assist the doctors during laser osteotomy, minimizing the damage of the nearby healthy tissues and provide cleaner pathologic tissue removal.
C1 [Shevchik, Sergey; Le-Quang, Tri; Faivre, Neige; Meylan, Bastian; Wasmer, Kilian] Empa Swiss Fed Labs Mat Sci & Technol, Lab Adv Mat Proc, CH-3602 Thun, Switzerland.
   [Nguendon Kenhagho, Herve; Zam, Azhar] Univ Basel, Dept Biomed Engn, Biomed Laser & Opt Grp, Allschwil, Switzerland.
   [Guzman, Raphael] Univ Hosp Basel, Dept Neurosurg, Basel, Switzerland.
   [Cattin, Philippe C.] Univ Basel, Dept Biomed Engn, Ctr Med Image Anal & Nav, Allschwil, Switzerland.
RP Wasmer, K (corresponding author), Empa Swiss Fed Labs Mat Sci & Technol, Lab Adv Mat Proc, CH-3602 Thun, Switzerland.
EM kilian.wasmer@empa.ch
RI Zam, Azhar/ABE-2827-2021; Zam, Azhar/K-1772-2019; Wasmer,
   Kilian/O-8430-2019
OI Zam, Azhar/0000-0001-7789-5680; Wasmer, Kilian/0000-0002-3294-3244
FU Werner Siemens Foundation
FX The authors gratefully acknowledge funding of the Werner Siemens
   Foundation through the MIRACLE (short for Minimally Invasive
   Robot-Assisted Computer-guided LaserosteotomE) project.
NR 33
TC 0
Z9 0
U1 2
U2 3
PU WILEY-V C H VERLAG GMBH
PI WEINHEIM
PA POSTFACH 101161, 69451 WEINHEIM, GERMANY
SN 1864-063X
EI 1864-0648
J9 J BIOPHOTONICS
JI J. Biophotonics
PD APR
PY 2021
VL 14
IS 4
AR e202000352
DI 10.1002/jbio.202000352
EA JAN 2021
PG 11
WC Biochemical Research Methods; Biophysics; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Biophysics; Optics
GA RM8LL
UT WOS:000606674200001
PM 33369169
OA Green Accepted
DA 2022-04-17
ER

PT J
AU Peterson, GGC
   Brgoch, J
AF Peterson, Gordon G. C.
   Brgoch, Jakoah
TI Materials discovery through machine learning formation energy
SO JOURNAL OF PHYSICS-ENERGY
LA English
DT Review
DE machine learning; intermetallics; neural network; support vector
   machine; random forrest; phase diagram; materials informatics
ID DENSITY-FUNCTIONAL THEORY; AB-INITIO; PREDICTIONS; MOLECULES; NETWORKS;
   DESIGN; MODELS; SPACE
AB The budding field of materials informatics has coincided with a shift towards artificial intelligence to discover new solid-state compounds. The steady expansion of repositories for crystallographic and computational data has set the stage for developing data-driven models capable of predicting a bevy of physical properties. Machine learning methods, in particular, have already shown the ability to identify materials with near ideal properties for energy-related applications by screening crystal structure databases. However, examples of the data-guided discovery of entirely new, never-before-reported compounds remain limited. The critical step for determining if an unknown compound is synthetically accessible is obtaining the formation energy and constructing the associated convex hull. Fortunately, this information has become widely available through density functional theory (DFT) data repositories to the point that they can be used to develop machine learning models. In this Review, we discuss the specific design choices for developing a machine learning model capable of predicting formation energy, including the thermodynamic quantities governing material stability. We investigate several models presented in the literature that cover various possible architectures and feature sets and find that they have succeeded in uncovering new DFT-stable compounds and directing materials synthesis. To expand access to machine learning models for synthetic solid-state chemists, we additionally present MatLearn. This web-based application is intended to guide the exploration of a composition diagram towards regions likely to contain thermodynamically accessible inorganic compounds. Finally, we discuss the future of machine-learned formation energy and highlight the opportunities for improved predictive power toward the synthetic realization of new energy-related materials.
C1 [Peterson, Gordon G. C.; Brgoch, Jakoah] Univ Houston, Dept Chem, Houston, TX 77204 USA.
   [Brgoch, Jakoah] Univ Houston, Texas Ctr Superconduct, Houston, TX 77204 USA.
RP Brgoch, J (corresponding author), Univ Houston, Dept Chem, Houston, TX 77204 USA.; Brgoch, J (corresponding author), Univ Houston, Texas Ctr Superconduct, Houston, TX 77204 USA.
EM jbrgoch@uh.edu
OI Peterson, Gordon/0000-0003-3638-8652
FU University of Houston Division of Research through a High Priority Area
   Research Seed Grant; National Science FoundationNational Science
   Foundation (NSF) [DMR-1847701]; Welch FoundationThe Welch Foundation
   [E-1981]; Texas Center for Superconductivity at the University of
   Houston (TcSUH)
FX The authors gratefully acknowledge the generous financial support
   provided by the University of Houston Division of Research through a
   High Priority Area Research Seed Grant. The authors also thank the
   National Science Foundation (DMR-1847701), the Welch Foundation
   (E-1981), and the Texas Center for Superconductivity at the University
   of Houston (TcSUH). The authors would also like to thank the team at
   LaPraim Digital Agency for collaborating on the development of
   MatLearn.org. The authors declare no competing financial interest.
NR 77
TC 8
Z9 8
U1 52
U2 71
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 2515-7655
J9 J PHYS-ENERGY
JI J. Phys-Energy
PD APR
PY 2021
VL 3
IS 2
AR 022002
DI 10.1088/2515-7655/abe425
PG 13
WC Energy & Fuels; Materials Science, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Energy & Fuels; Materials Science
GA QX8AQ
UT WOS:000629565800001
OA gold
DA 2022-04-17
ER

PT C
AU Khan, M
   Ibrahim, M
   Wu, NS
   Patil, R
AF Khan, Muhammad
   Ibrahim, Mohamed
   Wu, Nansong
   Patil, Rajvardhan
GP IEEE
TI Interdisciplinary Project Based Learning Approach for Machine Learning
   and Internet of Things
SO 2020 9TH IEEE INTEGRATED STEM EDUCATION CONFERENCE (ISEC 2020)
SE Integrated STEM Education Conference
LA English
DT Proceedings Paper
CT 9th IEEE Integrated STEM Education Conference (ISEC)
CY AUG 01, 2020
CL ELECTR NETWORK
SP IEEE
DE Project Based Learning; Machine Learning; Internet of Things; Problem
   Solving; Engineering Design Process
AB This paper reports on the use of an interdisciplinary project-based learning approach for undergraduate engineering education in machine/deep learning, and the internet of things (IoT). Machine learning has evolved from pattern recognition and is an important element of artificial intelligence. IoT has also seen rapid growth in multiple application domains including embedded systems, wireless sensor networks, control systems, automation, and sensors. A challenge for traditional electrical/computer engineering curriculum is to effectively educate students in these areas through hands-on activities and projects. There is a need to develop a project-based learning approach to involve undergraduate students in real-world problem solving to develop use cases of machine learning and IoT. This paper reports on the implementation of an interdisciplinary project-based learning approach followed in the undergraduate electrical/computer engineering curriculum. The students were involved in solving real-world problems through machine/deep learning. They also developed IoT applications in multiple domains to address the limitations of existing systems and to go through the engineering design process. The qualitative results indicate that the PBL approach was highly effective in improving their learning outcomes.
C1 [Khan, Muhammad] Arkansas Tech Univ, Dept Elect Engn, Russellville, AR 72801 USA.
   [Ibrahim, Mohamed] Arkansas Tech Univ, Dept Curriculum & Instruct, Russellville, AR 72801 USA.
   [Patil, Rajvardhan] Arkansas Tech Univ, Dept Comp & Informat Syst, Russellville, AR 72801 USA.
   [Wu, Nansong] Sonoma State Univ, Dept Engn Sci, Rohnert Pk, CA 94928 USA.
RP Khan, M (corresponding author), Arkansas Tech Univ, Dept Elect Engn, Russellville, AR 72801 USA.
EM mkhan3@atu.edu; mibrahim1@atu.edu; wun@sonoma.edu; rpatil@atu.edu
FU University Initiatives and Office of Undergraduate Research at Arkansas
   Tech University
FX We would like to thank the Office of Sponsored Programs and University
   Initiatives and Office of Undergraduate Research at Arkansas Tech
   University for their funding of the projects. We also appreciate the
   assistance from Drs. Charles Mebi, and Douglas Barron for lab testing of
   sensors in the WQMS project.
NR 16
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2330-331X
BN 978-1-7281-7520-1
J9 INTEGR STEM EDU CONF
PY 2020
PG 6
WC Education, Scientific Disciplines; Engineering, Multidisciplinary
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Education & Educational Research; Engineering
GA BS2CL
UT WOS:000698977100009
DA 2022-04-17
ER

PT J
AU Gotze, T
   Gurtler, M
   Witowski, E
AF Goetze, Tobias
   Guertler, Marc
   Witowski, Eileen
TI Improving CAT bond pricing models via machine learning
SO JOURNAL OF ASSET MANAGEMENT
LA English
DT Article
DE CAT bond; Machine learning; Linear regression; Risk premium
ID INSURANCE; SAMPLE; RISK; SELECTION; RETURNS
AB Enhanced machine learning methods provide an encouraging alternative to forecast asset prices by extending or generalizing the possible model specifications compared to conventional linear regression methods. Even if enhanced methods of machine learning in the literature often lead to better forecasting quality, this is not clear for small asset classes, because in small asset classes enhanced machine learning methods may potentially over-fit the in-sample data. Against this background, we compare the forecasting performance of linear regression models and enhanced machine learning methods in the market for catastrophe (CAT) bonds. We use linear regression with variable selection, penalization methods, random forests and neural networks to forecast CAT bond premia. Among the considered models, random forests exhibit the highest forecasting performance, followed by linear regression models and neural networks.
C1 [Goetze, Tobias; Guertler, Marc; Witowski, Eileen] Braunschweig Inst Technol, Dept Finance, Abt Jerusalem Str 7, D-38106 Braunschweig, Germany.
RP Gurtler, M (corresponding author), Braunschweig Inst Technol, Dept Finance, Abt Jerusalem Str 7, D-38106 Braunschweig, Germany.
EM t.goetze@tu-bs.de; marc.guertler@tu-bs.de; e.witowski@tu-bs.de
FU Projekt DEAL; Gesamtverband der deutschen Versicherungswirtschaft e.V.
FX Open Access funding provided by Projekt DEAL. We thank the Gesamtverband
   der deutschen Versicherungswirtschaft e.V. for funding this research
   project.
NR 34
TC 2
Z9 2
U1 6
U2 6
PU PALGRAVE MACMILLAN LTD
PI BASINGSTOKE
PA BRUNEL RD BLDG, HOUNDMILLS, BASINGSTOKE RG21 6XS, HANTS, ENGLAND
SN 1470-8272
EI 1479-179X
J9 J ASSET MANAG
JI J. Asset Manag.
PD SEP
PY 2020
VL 21
IS 5
BP 428
EP 446
DI 10.1057/s41260-020-00167-0
EA JUN 2020
PG 19
WC Business, Finance
WE Emerging Sources Citation Index (ESCI)
SC Business & Economics
GA NE1XR
UT WOS:000542552200001
OA hybrid
DA 2022-04-17
ER

PT J
AU Becherer, M
   Zipperle, M
   Karduck, A
AF Becherer, Marius
   Zipperle, Michael
   Karduck, Achim
TI Intelligent Choice of Machine Learning Methods for Predictive
   Maintenance of Intelligent Machines
SO COMPUTER SYSTEMS SCIENCE AND ENGINEERING
LA English
DT Article
DE Predictive Maintenance; Machine Learning; Artificial Intelligence; Smart
   Machines; Industry; Process Model
AB Machines are serviced too often or only when they fail. This can result in high costs for maintenance and machine failure. The trend of Industry 4.0 and the networking of machines opens up new possibilities for maintenance. Intelligent machines provide data that can be used to predict the ideal time of maintenance. There are different approaches to create a forecast. Depending on the method used, appropriate conditions must be created to improve the forecast. In this paper, results are compiled to give a state of the art of predictive maintenance. First, the different types of maintenance and economic relationships are explained. Then factors for the forecast are explained. Requirements for the data are collected and algorithms for machine learning are presented. Based on the relationships found, a process model is presented that shows a fast implementation of the predictive maintenance for machines.
C1 [Becherer, Marius; Zipperle, Michael; Karduck, Achim] Furtwangen Univ, Furtwangen, Germany.
RP Becherer, M (corresponding author), Furtwangen Univ, Furtwangen, Germany.
EM marius.baech@gmail.com; michael@zipperle.de; karduck@hs-furtwangen.de
NR 15
TC 5
Z9 5
U1 3
U2 11
PU C R L PUBLISHING LTD
PI LEICESTER
PA 5 WEIR RD, KIBWORTH BEAUCHAMP, LEICESTER LE8 0LQ, ENGLAND
SN 0267-6192
J9 COMPUT SYST SCI ENG
JI Comput. Syst. Sci. Eng.
PD MAR
PY 2020
VL 35
IS 2
BP 81
EP 89
PG 9
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LW2PE
UT WOS:000538985500002
DA 2022-04-17
ER

PT J
AU Akyildirim, E
   Goncu, A
   Sensoy, A
AF Akyildirim, Erdinc
   Goncu, Ahmet
   Sensoy, Ahmet
TI Prediction of cryptocurrency returns using machine learning
SO ANNALS OF OPERATIONS RESEARCH
LA English
DT Article
DE Cryptocurrency; Machine learning; Artificial neural networks; Support
   vector machine; Random forest; Logistic regression
ID LONG MEMORY; STOCK; BITCOIN; PRICE; INEFFICIENCY; EFFICIENCY; COMMODITY;
   MARKETS
AB In this study, the predictability of the most liquid twelve cryptocurrencies are analyzed at the daily and minute level frequencies using the machine learning classification algorithms including the support vector machines, logistic regression, artificial neural networks, and random forests with the past price information and technical indicators as model features. The average classification accuracy of four algorithms are consistently all above the 50% threshold for all cryptocurrencies and for all the timescales showing that there exists predictability of trends in prices to a certain degree in the cryptocurrency markets. Machine learning classification algorithms reach about 55-65% predictive accuracy on average at the daily or minute level frequencies, while the support vector machines demonstrate the best and consistent results in terms of predictive accuracy compared to the logistic regression, artificial neural networks and random forest classification algorithms.
C1 [Akyildirim, Erdinc] ETH, Dept Math, Zurich, Switzerland.
   [Akyildirim, Erdinc] Univ Zurich, Dept Banking & Finance, Zurich, Switzerland.
   [Goncu, Ahmet] Xian Jiaotong Liverpool Univ, Dept Math Sci, Suzhou 215123, Peoples R China.
   [Goncu, Ahmet] Shanghai Jiao Tong Univ, Shanghai Adv Inst Finance, Hedge Fund Res Ctr, Shanghai, Peoples R China.
   [Sensoy, Ahmet] Bilkent Univ, Fac Business Adm, TR-06800 Ankara, Turkey.
   [Akyildirim, Erdinc] Burdur Mehmet Akif Ersoy Univ, Dept Banking & Finance, Burdur, Turkey.
RP Sensoy, A (corresponding author), Bilkent Univ, Fac Business Adm, TR-06800 Ankara, Turkey.
EM Ahmet.Goncu@xjtlu.edu.cn; ahmet.sensoy@bilkent.edu.tr
OI Akyildirim, Erdinc/0000-0003-0102-4111
NR 48
TC 18
Z9 18
U1 19
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0254-5330
EI 1572-9338
J9 ANN OPER RES
JI Ann. Oper. Res.
PD FEB
PY 2021
VL 297
IS 1-2
SI SI
DI 10.1007/s10479-020-03575-y
EA APR 2020
PG 34
WC Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Operations Research & Management Science
GA PT7YX
UT WOS:000524634500002
OA Green Published
DA 2022-04-17
ER

PT J
AU Feehan, R
   Montezano, D
   Slusky, JSG
AF Feehan, Ryan
   Montezano, Daniel
   Slusky, Joanna S. G.
TI Machine learning for enzyme engineering, selection and design
SO PROTEIN ENGINEERING DESIGN & SELECTION
LA English
DT Review
DE deep learning; enzyme design; enzyme engineering; machine learning
ID PREDICTION; SEQUENCE; EVOLUTION; DATABASE; NETWORK
AB Machine learning is a useful computational tool for large and complex tasks such as those in the field of enzyme engineering, selection and design. In this review, we examine enzyme-related applications of machine learning. We start by comparing tools that can identify the function of an enzyme and the site responsible for that function. Then we detail methods for optimizing important experimental properties, such as the enzyme environment and enzyme reactants. We describe recent advances in enzyme systems design and enzyme design itself. Throughout we compare and contrast the data and algorithms used for these tasks to illustrate how the algorithms and data can be best used by future designers.
C1 [Feehan, Ryan; Montezano, Daniel; Slusky, Joanna S. G.] Univ Kansas, Ctr Computat Biol, 2030 Becker Dr, Lawrence, KS 66047 USA.
   [Slusky, Joanna S. G.] Univ Kansas, Dept Mol Biosci, 1200 Sunnyside Ave, Lawrence, KS 66045 USA.
RP Slusky, JSG (corresponding author), Univ Kansas, Ctr Computat Biol, 2030 Becker Dr, Lawrence, KS 66047 USA.; Slusky, JSG (corresponding author), Univ Kansas, Dept Mol Biosci, 1200 Sunnyside Ave, Lawrence, KS 66045 USA.
EM slusky@ku.edu
FU National Institute of General Medical SciencesUnited States Department
   of Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute of General Medical Sciences (NIGMS) [DP2GM128201]
FX We gratefully acknowledge helpful discussions with Meghan W. Franklin as
   well as funding from National Institute of General Medical Sciences
   award DP2GM128201.
NR 70
TC 0
Z9 0
U1 1
U2 1
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 1741-0126
EI 1741-0134
J9 PROTEIN ENG DES SEL
JI Protein Eng. Des. Sel.
PD FEB 15
PY 2021
VL 34
AR gzab019
DI 10.1093/protein/gzab019
PG 10
WC Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology
GA ZW1UO
UT WOS:000771005300017
DA 2022-04-17
ER

PT J
AU Yan, WC
   Nie, ZQ
   Zeng, XW
   Dai, GH
   Cai, MQ
   Shen, Y
   Deng, XH
AF Yan, Weichao
   Nie, Zhongquan
   Zeng, Xunwen
   Dai, Guohong
   Cai, Mengqiang
   Shen, Yun
   Deng, Xiaohua
TI Machine-Learning-Enabled Vectorial Opto-Magnetization Orientation
SO ANNALEN DER PHYSIK
LA English
DT Article
DE magnetization; machine learning; polarization; tight focusing
ID ARRAYS; GENERATION; FIELD
AB Manipulation of light-induced magnetization has become a fundamentally hot topic with a potentially high impact for atom trapping, confocal and magnetic resonance microscopy, and data storage. The control of the magnetization orientation mainly relies on the direct methods composed of amplitude, phase, and polarization modulations of the incident light under the tight focusing condition, leaving the achievement of arbitrary desirable 3D magnetization orientation complicated, inflexible, and inefficient. Here, a facile approach called machine learning inverse design to achieve expected vectorial opto-magnetization orientation is proposed. This pathway is time-efficient and accurate to produce the demanded incident beam for arbitrary prescribed 3D magnetization orientation. It is highlighted that the machine learning method is not only applied for magnetization orientations, but also widely used in the control of magnetization structures.
C1 [Yan, Weichao; Cai, Mengqiang; Deng, Xiaohua] Nanchang Univ, Inst Space Sci & Technol, Nanchang 330031, Jiangxi, Peoples R China.
   [Nie, Zhongquan] Taiyuan Univ Technol, Coll Phys & Optoelect, Minist Educ & Shanxi Prov, Key Lab Adv Transducers & Intelligent Control Sys, Taiyuan 030024, Peoples R China.
   [Dai, Guohong; Shen, Yun] Nanchang Univ, Sch Sci, Dept Phys, Nanchang 330031, Jiangxi, Peoples R China.
   [Zeng, Xunwen] Nanchang Univ, Informat Engn Sch, Nanchang 330031, Jiangxi, Peoples R China.
RP Nie, ZQ (corresponding author), Taiyuan Univ Technol, Coll Phys & Optoelect, Minist Educ & Shanxi Prov, Key Lab Adv Transducers & Intelligent Control Sys, Taiyuan 030024, Peoples R China.
EM niezhongquan1018@163.com
OI Zeng, Xunwen/0000-0003-3763-7825
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [12004155, 11974258, 11904152, 11604236,
   61575139, 61865009, 61927813, 60504052]; Key Research and Development
   (R&D) Projects of Shanxi Province, China [201903D121127]; Scientific and
   Technological Innovation Programs of Higher Education Institutions in
   Shanxi [2019L0151]
FX This work was supported by the National Natural Science Foundation of
   China (12004155, 11974258, 11904152, 11604236, 61575139, 61865009,
   61927813, 60504052); Key Research and Development (R&D) Projects of
   Shanxi Province, China (201903D121127); Scientific and Technological
   Innovation Programs of Higher Education Institutions in Shanxi
   (2019L0151).
NR 31
TC 0
Z9 0
U1 5
U2 5
PU WILEY-V C H VERLAG GMBH
PI WEINHEIM
PA POSTFACH 101161, 69451 WEINHEIM, GERMANY
SN 0003-3804
EI 1521-3889
J9 ANN PHYS-BERLIN
JI Ann. Phys.-Berlin
PD JAN
PY 2022
VL 534
IS 1
AR 2100287
DI 10.1002/andp.202100287
EA DEC 2021
PG 6
WC Physics, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Physics
GA YB9DQ
UT WOS:000725308100001
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Bucker, M
   Szepannek, G
   Gosiewska, A
   Biecek, P
AF Buecker, Michael
   Szepannek, Gero
   Gosiewska, Alicja
   Biecek, Przemyslaw
TI Transparency, auditability, and explainability of machine learning
   models in credit scoring
SO JOURNAL OF THE OPERATIONAL RESEARCH SOCIETY
LA English
DT Article
DE Credit scoring; machine learning; explainable machine learning; XAI
ID ART CLASSIFICATION ALGORITHMS; REJECT INFERENCE
AB A major requirement for credit scoring models is to provide a maximally accurate risk prediction. Additionally, regulators demand these models to be transparent and auditable. Thus, in credit scoring, very simple predictive models such as logistic regression or decision trees are still widely used and the superior predictive power of modern machine learning algorithms cannot be fully leveraged. Significant potential is therefore missed, leading to higher reserves or more credit defaults. This article works out different dimensions that have to be considered for making credit scoring models understandable and presents a framework for making "black box" machine learning models transparent, auditable, and explainable. Following this framework, we present an overview of techniques, demonstrate how they can be applied in credit scoring and how results compare to the interpretability of scorecards. A real world case study shows that a comparable degree of interpretability can be achieved while machine learning techniques keep their ability to improve predictive power.
C1 [Buecker, Michael] FH Munster Univ Appl Sci, Munster Sch Business, Corrensstr 25, D-48149 Munster, Germany.
   [Szepannek, Gero] HOST Stralsund Univ Appl Sci, Stralsund, Germany.
   [Gosiewska, Alicja; Biecek, Przemyslaw] Warsaw Univ Technol, Warsaw, Poland.
   [Biecek, Przemyslaw] Univ Warsaw, Warsaw, Poland.
RP Bucker, M (corresponding author), FH Munster Univ Appl Sci, Munster Sch Business, Corrensstr 25, D-48149 Munster, Germany.
EM michael.buecker@fh-muenster.de
OI Szepannek, Gero/0000-0001-8456-1283; Biecek,
   Przemyslaw/0000-0001-8423-1823; Gosiewska, Alicja/0000-0001-6563-5742;
   Bucker, Michael/0000-0003-0045-8460
NR 69
TC 5
Z9 5
U1 20
U2 29
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0160-5682
EI 1476-9360
J9 J OPER RES SOC
JI J. Oper. Res. Soc.
PD JAN 2
PY 2022
VL 73
IS 1
SI SI
BP 70
EP 90
DI 10.1080/01605682.2021.1922098
EA MAY 2021
PG 21
WC Management; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Business & Economics; Operations Research & Management Science
GA YU1JL
UT WOS:000664054400001
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Xiao, QG
   Li, CB
   Tang, Y
   Chen, XZ
AF Xiao, Qinge
   Li, Congbo
   Tang, Ying
   Chen, Xingzheng
TI Energy Efficiency Modeling for Configuration-Dependent Machining via
   Machine Learning: A Comparative Study
SO IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING
LA English
DT Article
DE Machining; Predictive models; Data models; Computational modeling;
   Tools; Machine tools; Machinery; Deep learning (DL); energy efficiency
   modeling; machine-learning (ML); machining system
ID PARAMETER OPTIMIZATION; SURFACE-ROUGHNESS; CONSUMPTION; PREDICTION;
   SYSTEM; TOOLS; PERFORMANCE; MANAGEMENT; REGRESSION; NETWORK
AB Energy efficiency modeling is of great importance to energy management and conservation for machinery enterprises. To improve the generalization ability, this article combines the machining parameters and the configuration parameters into energy efficiency models, for which machine-learning (ML) algorithms are used considering the lack of theoretical formulas. Based on the three-year data collected in a shop floor, a comparative study for two different cases is conducted with a particular focus on prediction accuracy, stability, and computational efficiency. In Case 1, only cross-sectional data are used to predict energy efficiency, ignoring the deterioration of spindle motors and cutting tools. Three traditional ML algorithms, i.e., artificial neural networks, support vector regression, and Gaussian process regression, are evaluated with the help of five error metrics. In Case 2, we construct the models in a more realistic situation that considers the dynamic aspects of spindle motor aging and tool wear. A convolutional neural network, a stacked autoencoder, a deep belief network and the aforementioned traditional ML algorithms are investigated. The comparison shows that all the models in Case 1 suffer from performance degradation, while deep learning achieves the long-term improvement in accuracy. Note to Practitioners-Energy efficiency models deliver many advantages, ranging from energy-aware machine design to process optimization. Although a large amount of works in the past focused on physics-based and experimental modeling for specific machining configurations, it can be more effective to improve the applicability of the modeling methods by involving the configuration variables into the models. Due to the uncertainties in both the machine and the operation environment, machine learning is adopted to fit the high-dimensional and high-nonlinear energy system. To the best of our knowledge, this is the first article that provides a comprehensive survey on ML-based modeling in terms of data sizes, temporal granularities, feature selection, and algorithm performance. Such a survey helps engineers quickly justify the appropriate ML methods to meet the actual requirements.
C1 [Xiao, Qinge; Li, Congbo] Chongqing Univ, State Key Lab Mech Transmiss, Chongqing 400044, Peoples R China.
   [Tang, Ying] Rowan Univ, Dept Elect & Comp Engn, Glassboro, NJ 08028 USA.
   [Tang, Ying] Qingdao Acad Intelligent Ind, Inst Intelligent Mfg, Qingdao 266000, Peoples R China.
   [Chen, Xingzheng] Southwest Univ, Coll Engn & Technol, Chongqing 400715, Peoples R China.
RP Li, CB (corresponding author), Chongqing Univ, State Key Lab Mech Transmiss, Chongqing 400044, Peoples R China.
EM xqg2974@163.com; congboli@cqu.edu.cn; tang@rowan.edu;
   chenxingzheng233@163.com
OI Li, Congbo/0000-0001-7217-3574; Tang, Ying/0000-0001-6064-1908
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [51975075]; National Key Research and
   Development Program of China [2019YFB1706103]; Fundamental Research
   Funds for the Central Universities of ChinaFundamental Research Funds
   for the Central Universities [cqu2018CDHB1B07]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 51975075, in part by the National Key
   Research and Development Program of China under Grant 2019YFB1706103,
   and in part by the Fundamental Research Funds for the Central
   Universities of China under Grant cqu2018CDHB1B07.
NR 48
TC 5
Z9 5
U1 7
U2 12
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-5955
EI 1558-3783
J9 IEEE T AUTOM SCI ENG
JI IEEE Trans. Autom. Sci. Eng.
PD APR
PY 2021
VL 18
IS 2
BP 717
EP 730
DI 10.1109/TASE.2019.2961714
PG 14
WC Automation & Control Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems
GA RK6KA
UT WOS:000638401500029
DA 2022-04-17
ER

PT J
AU Binder, M
   Pfisterer, F
   Lang, M
   Schneider, L
   Kotthoff, L
   Bischl, B
AF Binder, Martin
   Pfisterer, Florian
   Lang, Michel
   Schneider, Lennart
   Kotthoff, Lars
   Bischl, Bernd
TI mlr3pipelines-Flexible Machine Learning Pipelines in R
SO JOURNAL OF MACHINE LEARNING RESEARCH
LA English
DT Article
DE machine learning pipelines; preprocessing; automated machine learning
ID MODELS
AB Recent years have seen a proliferation of ML frameworks. Such systems make ML accessible to non-experts, especially when combined with powerful parameter tuning and AutoML techniques. Modern, applied ML extends beyond direct learning on clean data, however, and needs an expressive language for the construction of complex ML workflows beyond simple pre-and post-processing. We present mlr3pipelines, an R framework which can be used to define linear and complex non-linear ML workflows as directed acyclic graphs. The framework is part of the mlr3 ecosystem, leveraging convenient resampling, benchmarking, and tuning components.
C1 [Binder, Martin; Pfisterer, Florian; Lang, Michel; Schneider, Lennart; Bischl, Bernd] Ludwig Maximilians Univ Munchen, Dept Stat, Munich, Germany.
   [Kotthoff, Lars] Univ Wyoming, Dept Comp Sci, Laramie, WY 82071 USA.
RP Binder, M (corresponding author), Ludwig Maximilians Univ Munchen, Dept Stat, Munich, Germany.
EM MARTIN.BINDER@STAT.UNI-MUENCHEN.DE;
   FLORIAN.PFISTERER@STAT.UNI-MUENCHEN.DE;
   MICHEL.LANG@STAT.UNI-MUENCHEN.DE;
   LENNART.SCHNEIDER@STAT.UNI-MUENCHEN.DE; LARSKO@UWYO.EDU;
   BERND.BISCHL@STAT.UNI-MUENCHEN.DE
RI Kotthoff, Lars/AFV-6526-2022
OI Lang, Michel/0000-0001-9754-0393
FU German Federal Ministry of Education and Research (BMBF)Federal Ministry
   of Education & Research (BMBF) [01IS18036A]; NSFNational Science
   Foundation (NSF) [1813537]
FX This work has been funded by the German Federal Ministry of Education
   and Research (BMBF) under Grant No. 01IS18036A. LK is supported by NSF
   grant #1813537.
NR 22
TC 2
Z9 2
U1 1
U2 1
PU MICROTOME PUBL
PI BROOKLINE
PA 31 GIBBS ST, BROOKLINE, MA 02446 USA
SN 1532-4435
J9 J MACH LEARN RES
JI J. Mach. Learn. Res.
PY 2021
VL 22
PG 7
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA UW7EG
UT WOS:000700315600001
DA 2022-04-17
ER

PT J
AU Gao, ZP
   Wang, YJ
   Lu, HL
   Li, QF
   Shen, CW
   Liu, L
AF Gao, Ze-Peng
   Wang, Yong-Jia
   Lu, Hong-Liang
   Li, Qing-Feng
   Shen, Cai-Wan
   Liu, Ling
TI Machine learning the nuclear mass
SO NUCLEAR SCIENCE AND TECHNIQUES
LA English
DT Article
DE Nuclear mass; Machine learning; Binding energy; Separation energy
ID GROUND-STATE MASSES; DEFORMATIONS; ENERGY
AB Background: The masses of similar to 2500 nuclei have been measured experimentally; however, >7000 isotopes are predicted to exist in the nuclear landscape from H (Z = 1) to Og (Z = 118) based on various theoretical calculations. Exploring the mass of the remaining isotopes is a popular topic in nuclear physics. Machine learning has served as a powerful tool for learning complex representations of big data in many fields.
   Purpose: We use Light Gradient Boosting Machine (LightGBM), which is a highly efficient machine learning algorithm, to predict the masses of unknown nuclei and to explore the nuclear landscape on the neutron-rich side from learning the measured nuclear masses.
   Methods: Several characteristic quantities (e.g., mass number and proton number) are fed into the LightGBM algorithm to mimic the patterns of the residual delta(Z,A) between the experimental binding energy and the theoretical one given by the liquid-drop model (LDM), Duflo-Zucker (DZ, also dubbed DZ28) mass model, finite-range droplet model (FRDM, also dubbed FRDM2012), as well as the Weizsacker-Skyrme (WS4) model to refine these mass models.
   Results: By using the experimental data of 80% of known nuclei as the training dataset, the root mean square deviations (RMSDs) between the predicted and the experimental binding energy of the remaining 20% are approximately 0.234 +/- 0.022, 0.213 +/- 0.018, 0.170 +/- 0.011, and 0.222 +/- 0.016 MeV for the LightGBM-refined LDM, DZ model, WS4 model, and FRDM, respectively. These values are approximately 90%, 65%, 40%, and 60% smaller than those of the corresponding origin mass models. The RMSD for 66 newly measured nuclei that appeared in AME2020 was also significantly improved. The one-neutron and two-neutron separation energies predicted by these refined models are consistent with several theoretical predictions based on various physical models. In addition, the two-neutron separation energies of several newly measured nuclei (e.g., some isotopes of Ca, Ti, Pm, and Sm) predicted with LightGBM-refined mass models are also in good agreement with the latest experimental data.
   Conclusions: LightGBM can be used to refine theoretical nuclear mass models and predict the binding energy of unknown nuclei. Moreover, the correlation between the input characteristic quantities and the output can be interpreted by SHapley additive exPlanations (a popular explainable artificial intelligence tool), which may provide new insights for developing theoretical nuclear mass models.
C1 [Gao, Ze-Peng; Liu, Ling] Shenyang Normal Univ, Coll Phys Sci & Technol, Shenyang 110034, Peoples R China.
   [Gao, Ze-Peng; Wang, Yong-Jia; Li, Qing-Feng; Shen, Cai-Wan] Huzhou Univ, Sch Sci, Huzhou 313000, Peoples R China.
   [Lu, Hong-Liang] Huawei Technol Co Ltd, HiSilicon Res Dept, Shenzhen 518000, Peoples R China.
   [Li, Qing-Feng] Chinese Acad Sci, Inst Modern Phys, Lanzhou 730000, Peoples R China.
RP Wang, YJ; Li, QF (corresponding author), Huzhou Univ, Sch Sci, Huzhou 313000, Peoples R China.; Li, QF (corresponding author), Chinese Acad Sci, Inst Modern Phys, Lanzhou 730000, Peoples R China.
EM wangyongjia@zjhu.edu.cn; liqf@zjhu.edu.cn
RI Wang, Yongjia/ABC-6646-2021; Li, Qingfeng/H-1779-2014
OI Li, Qingfeng/0000-0002-8275-8100; wang, Yongjia/0000-0003-2506-0010;
   Gao, Zepeng/0000-0003-4331-7318
FU National Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [U2032145, 11875125, 12047568, 11790323, 11790325,
   12075085]; National Key Research and Development Program of China
   [2020YFE0202002]; ``Ten Thousand Talent Program'' of Zhejiang Province
   [2018R52017]
FX This work was supported in part by the National Science Foundation of
   China (Nos. U2032145, 11875125, 12047568, 11790323, 11790325, and
   12075085), the National Key Research and Development Program of China
   (No. 2020YFE0202002), and the ``Ten Thousand Talent Program'' of
   Zhejiang Province (No. 2018R52017).
NR 65
TC 1
Z9 1
U1 12
U2 12
PU SPRINGER SINGAPORE PTE LTD
PI SINGAPORE
PA #04-01 CENCON I, 1 TANNERY RD, SINGAPORE 347719, SINGAPORE
SN 1001-8042
EI 2210-3147
J9 NUCL SCI TECH
JI Nucl. Sci. Tech.
PD OCT
PY 2021
VL 32
IS 10
AR 109
DI 10.1007/s41365-021-00956-1
PG 13
WC Nuclear Science & Technology; Physics, Nuclear
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Nuclear Science & Technology; Physics
GA WE8BQ
UT WOS:000705844800002
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Brenzke, M
   Wiesen, S
   Bernert, M
   Coster, D
   Jitsev, J
   Liang, Y
   von Toussaint, U
AF Brenzke, M.
   Wiesen, S.
   Bernert, M.
   Coster, D.
   Jitsev, J.
   Liang, Y.
   von Toussaint, U.
CA ASDEX Upgrade Team
   EUROfusion MST1 Team
TI Divertor power load predictions based on machine learning
SO NUCLEAR FUSION
LA English
DT Article
DE machine learning; divertor; data analysis
ID ASDEX UPGRADE
AB Machine learning based data-driven approaches to thermal load prediction on the divertor targets of ASDEX upgrade (AUG) are presented. After selecting time averaged data from almost six years of operation of AUG and applying basic physics-motivated cuts to the data we find that we are able to train machine learning models to predict a scalar quantifying the steady state thermal loads on the outer divertor target given scalar operational parameters. With both random forest and neural network based models we manage to achieve decent agreement between the model predictions and the observed values from experiments. Furthermore, we investigate the dependencies of the models and observe that the models manage to extract trends expected from previous physics analyses.
C1 [Brenzke, M.; Wiesen, S.; Liang, Y.] Forschungszentrum Julich, Inst Energie & Klimaforsch Plasmaphys, D-52425 Julich, Germany.
   [Bernert, M.; Coster, D.; von Toussaint, U.] Max Planck Inst Plasma Phys, D-85748 Garching, Germany.
   [Jitsev, J.] Res Ctr Juelich FZJ, Juelich Supercomp Ctr JSC, Inst Adv Simulat IAS, D-52425 Julich, Germany.
RP Brenzke, M (corresponding author), Forschungszentrum Julich, Inst Energie & Klimaforsch Plasmaphys, D-52425 Julich, Germany.
EM m.brenzke@fz-juelich.de
OI Wiesen, Sven/0000-0002-3696-5475
FU Euratom research and training programme [633053]
FX This work has been carried out within the framework of the EUROfusion
   Consortium and has received funding from the Euratom research and
   training programme 2014-2018 and 2019-2020 under Grant agreement No.
   633053. The views and opinions expressed herein do not necessarily
   reflect those of the EuropeanCommission. The authors gratefully
   acknowledge the computing time granted through JARA on the supercomputer
   JURECA at Forschungszentrum Julich.
NR 30
TC 0
Z9 0
U1 1
U2 6
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 0029-5515
EI 1741-4326
J9 NUCL FUSION
JI Nucl. Fusion
PD APR
PY 2021
VL 61
IS 4
AR 046023
DI 10.1088/1741-4326/abdb94
PG 14
WC Physics, Fluids & Plasmas
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Physics
GA QY3JM
UT WOS:000629939700001
DA 2022-04-17
ER

PT J
AU Ohu, I
   Benny, PK
   Rodrigues, S
   Carlson, JN
AF Ohu, Ikechukwu
   Benny, Paul Kummannoor
   Rodrigues, Steven
   Carlson, Jestin N.
TI Applications of machine learning in acute care research
SO JOURNAL OF THE AMERICAN COLLEGE OF EMERGENCY PHYSICIANS OPEN
LA English
DT Article
DE acute care; artificial intelligence; machine learning
ID ARTIFICIAL NEURAL-NETWORKS; CLASSIFICATION; PREDICTION
AB Artificial intelligence has been successfully applied to numerous health care and non-health care-related applications and its use in emergency medicine has been expanding. Among its advantages are its speed in decision making and the opportunity for rapid, actionable deduction from unstructured data with that increases with access to larger volumes of data. Artificial intelligence algorithms are currently being applied to enable faster prognosis and diagnosis of diseases and to improve patient outcomes.(1,2) Despite the successful application of artificial intelligence, it is still fraught with limitations and "unknowns" pertaining to the fact that a model's accuracy is dependent on the amount of information available for training the model, and the understanding of the complexity presented by current artificial intelligence and machine learning algorithms is often limited in many individuals outside of those involved in the field. This paper reviews the applications of artificial intelligence and machine learning to acute care research and highlights commonly used machine learning techniques, limitations, and potential future applications.
C1 [Ohu, Ikechukwu; Benny, Paul Kummannoor; Rodrigues, Steven] Gannon Univ, Biomed Ind & Syst Engn Dept, Erie, PA USA.
   [Carlson, Jestin N.] Gannon Univ, Patient Simulat Ctr, Morosky Coll Hlth Profess, Erie, PA USA.
   [Carlson, Jestin N.] St Vincent Hosp, Dept Emergency Med, Erie, PA 16544 USA.
RP Carlson, JN (corresponding author), St Vincent Hosp, Dept Emergency Med, Allegheny Hlth Network, 232 West 25th St, Erie, PA 16544 USA.
EM jestin.carlson@ahn.org
NR 38
TC 3
Z9 3
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
EI 2688-1152
J9 JACEP OPEN
JI J. Am. Coll. Emerg. Phys. Open
PD OCT
PY 2020
VL 1
IS 5
BP 766
EP 772
DI 10.1002/emp2.12156
PG 7
WC Emergency Medicine
WE Emerging Sources Citation Index (ESCI)
SC Emergency Medicine
GA RZ6GP
UT WOS:000648695300011
PM 33145517
OA gold, Green Published
DA 2022-04-17
ER

PT C
AU Eshraghi, H
   Majidi, B
   Movaghar, A
AF Eshraghi, Hossein
   Majidi, Babak
   Movaghar, Ali
GP IEEE
TI Anomaly modelling in machine learning based navigation system of
   autonomous vehicles
SO 2020 6TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS
   (ICSPIS)
LA English
DT Proceedings Paper
CT 6th International Conference on Signal Processing and Intelligent
   Systems (ICSPIS)
CY DEC 23-24, 2020
CL Sadjad Univ, Mashhad, IRAN
HO Sadjad Univ
DE Autonamous vehicles; Deep learning; Robustness; Machine learning
AB In the past few years, autonomous navigation systems are gradually introduced to the consumer vehicles and the cars using these systems are gaining popularity. The autonomous navigation systems are using machine learning and deep learning models for visual processing of complex road scenes in various scenarios. These machine learning models are trained using numerous test rides and the process of training sometimes continues as the vehicle is navigating the streets. These machine learning models are vulnerable to anomalies which can lead to various issues for the autonomous driving systems. These issues will put the safety of the vehicle in danger. In this paper, the issue of the impact of the anomalies on the deep learning models of smart vehicles is investigated and a method for anomaly modelling in the machine learning based autonomous driving systems is presented. The presented model can increase the robustness of the autonomous vehicles.
C1 [Eshraghi, Hossein; Majidi, Babak] Khatam Univ, Dept Comp Engn, Tehran, Iran.
   [Movaghar, Ali] Sharif Univ Technol, Fac Comp Engn, Tehran, Iran.
RP Eshraghi, H (corresponding author), Khatam Univ, Dept Comp Engn, Tehran, Iran.
EM h.eshraghi@khatam.ac.ir; b.majidi@khatam.ac.ir; movaghar@sharif.edu
RI Movaghar, Ali/B-3980-2011; Majidi, Babak/AAB-2365-2019
OI Movaghar, Ali/0000-0002-6803-6750; Majidi, Babak/0000-0001-6309-6407
NR 21
TC 0
Z9 0
U1 1
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-8629-0
PY 2020
DI 10.1109/ICSPIS51611.2020.9349606
PG 6
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BR9FP
UT WOS:000675416100072
DA 2022-04-17
ER

PT J
AU Cerulli, G
AF Cerulli, Giovanni
TI Improving econometric prediction by machine learning
SO APPLIED ECONOMICS LETTERS
LA English
DT Article
DE Machine learning; ensemble methods; optimal prediction
AB We present a Machine Learning (ML) toolbox to predict targeted econometric outcomes improving prediction in two directions: (i) by cross-validatedoptimal tuning, (ii) by comparing/combining results from different learners (meta-learning). In predicting woman wage class based on her characteristics, we show that all our ML methods' predictions highly outperform standard multinomial logit ones, both in terms of mean accuracy and its standard deviation. In particular, we set out that a regularized multinomial regression obtains an average prediction accuracy almost 60% larger than that of an unregularized one. Finally, as different learners may behave differently, we show that combining them into one ensemble learner proves to preserve good predictive accuracy lowering the variance more than stand-alone approaches.
C1 [Cerulli, Giovanni] Natl Res Council Italy, Res Inst Sustainable Econ Growth, CNR, IRCRES, I-00185 Rome, Italy.
RP Cerulli, G (corresponding author), Natl Res Council Italy, Res Inst Sustainable Econ Growth, CNR, IRCRES, I-00185 Rome, Italy.
EM giovanni.cerulli@ircres.cnr.it
NR 11
TC 2
Z9 2
U1 2
U2 6
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1350-4851
EI 1466-4291
J9 APPL ECON LETT
JI Appl. Econ. Lett.
PD SEP 20
PY 2021
VL 28
IS 16
BP 1419
EP 1425
DI 10.1080/13504851.2020.1820939
EA SEP 2020
PG 7
WC Economics
WE Social Science Citation Index (SSCI)
SC Business & Economics
GA TX5PO
UT WOS:000569204400001
DA 2022-04-17
ER

PT J
AU Montiel, J
   Halford, M
   Mastelini, SM
   Bolmier, G
   Sourty, R
   Vaysse, R
   Zouitine, A
   Gomes, HM
   Read, J
   Abdessalem, T
   Bifet, A
AF Montiel, Jacob
   Halford, Max
   Mastelini, Saulo Martiello
   Bolmier, Geoffrey
   Sourty, Raphael
   Vaysse, Robin
   Zouitine, Adil
   Gomes, Heitor Murilo
   Read, Jesse
   Abdessalem, Talel
   Bifet, Albert
TI River: machine learning for streaming data in Python
SO JOURNAL OF MACHINE LEARNING RESEARCH
LA English
DT Article
DE stream learning; online learning; data stream; concept drift; supervised
   learning; unsupervised learning; Python
AB River is a machine learning library for dynamic data streams and continual learning. It provides multiple state-of-the-art learning methods, data generators/transformers, performance metrics and evaluators for different stream learning problems. It is the result from the merger of two popular packages for stream learning in Python: Creme and scikit-multiflow. River introduces a revamped architecture based on the lessons learnt from the seminal packages. River's ambition is to be the go-to library for doing machine learning on streaming data. Additionally, this open source package brings under the same umbrella a large community of practitioners and researchers. The source code is available at https://github.com/online-ml/river.
C1 [Montiel, Jacob; Gomes, Heitor Murilo; Bifet, Albert] Univ Waikato, AI Inst, Hamilton, New Zealand.
   [Montiel, Jacob; Abdessalem, Talel; Bifet, Albert] Inst Polytech Paris, Telecom Paris, LTCI, Palaiseau, France.
   [Halford, Max] Alan, Paris, France.
   [Mastelini, Saulo Martiello] Univ Sao Paulo, Inst Math & Comp Sci, Sao Carlos, Brazil.
   [Bolmier, Geoffrey] Volvo Car Corp, Gothenburg, Sweden.
   [Sourty, Raphael; Vaysse, Robin] Univ Paul Sabatier, IRIT, Toulouse, France.
   [Sourty, Raphael] Renault, Paris, France.
   [Vaysse, Robin] Univ Jean Jaures, Octogone Lordat, Toulouse, France.
   [Zouitine, Adil] IRT St Exupery, Toulouse, France.
   [Read, Jesse] Inst Polytech Paris, Ecole Polytech, LIX, Palaiseau, France.
RP Montiel, J (corresponding author), Univ Waikato, AI Inst, Hamilton, New Zealand.; Montiel, J (corresponding author), Inst Polytech Paris, Telecom Paris, LTCI, Palaiseau, France.
EM JACOB.MONTIEL@WAIKATO.AC.NZ; MAX.HALFORD@ALAN.EU; MASTELINI@USP.BR;
   GEOFFREY.BOLMIER@VOLVOCARS.COM; RAPHAEL.SOURTY@IRIT.FR;
   ROBIN.VAYSSE@IRIT.FR; ADIL.ZOUITINE@IRT-SAINTEXUPERY.COM;
   HEITOR.GOMES@WAIKATO.AC.NZ; JESSE.READ@POLYTECHNIQUE.EDU;
   TALEL.ABDESSALEM@TELECOM-PARIS.FR; ABIFET@WAIKATO.AC.NZ
NR 50
TC 3
Z9 3
U1 2
U2 2
PU MICROTOME PUBL
PI BROOKLINE
PA 31 GIBBS ST, BROOKLINE, MA 02446 USA
SN 1532-4435
J9 J MACH LEARN RES
JI J. Mach. Learn. Res.
PY 2021
VL 22
AR 110
PG 8
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA SU5GJ
UT WOS:000663165500001
DA 2022-04-17
ER

PT J
AU Shirobokov, M
   Trofimov, S
   Ovchinnikov, M
AF Shirobokov, Maksim
   Trofimov, Sergey
   Ovchinnikov, Mikhail
TI Survey of machine learning techniques in spacecraft control design
SO ACTA ASTRONAUTICA
LA English
DT Review
DE Spacecraft control; Machine learning; Neural network; Supervised
   learning; Neurodynamics; Reinforcement learning
ID TIME OPTIMAL-CONTROL; LOW-THRUST; TRAJECTORY OPTIMIZATION;
   ATTITUDE-CONTROL; FEEDBACK GUIDANCE; NEURAL-NETWORKS; MARS ENTRY; SOLAR
AB In this paper, a survey on the machine learning techniques in spacecraft control design is given. Among the applications of machine learning on the subject are the design of optimal interplanetary trajectories, the synthesis of controllers to stabilize orbital or angular motion, formation control, the design of control laws for landing on the surface of a celestial body. All the works are classified into two almost equal groups - the supervised learning (stochastic and deterministic methods) and the reinforcement learning (direct and value-based approaches). Stochastic supervised learning methods are based on stochastic optimization procedures, random initialization of neural networks weights, and stochastic nature of the obtained results. Deterministic methods are based on the Lyapunov theory; the network training is a deterministic process. The division of reinforcement learning methods into direct and value-based approaches is similar to the separation into direct and indirect methods in the optimal control theory. We discuss the main ideas, advantages, and drawbacks of the techniques and give some recommendations for future investigations. We also highlight interesting ideas and approaches in the application of machine learning methods that can be used in a broad variety of astrodynamical problems.
C1 [Shirobokov, Maksim; Trofimov, Sergey; Ovchinnikov, Mikhail] Moscow Ctr Fundamental & Appl Math, 4 Miusskaya Pl, Moscow 125047, Russia.
RP Shirobokov, M (corresponding author), Moscow Ctr Fundamental & Appl Math, 4 Miusskaya Pl, Moscow 125047, Russia.
EM shirobokov@keldysh.ru
RI Trofimov, Sergey/Q-5452-2019; Shirobokov, Maksim/S-2520-2016;
   Ovchinnikov, Mikhail/M-2210-2013
OI Trofimov, Sergey/0000-0002-2850-5292; Shirobokov,
   Maksim/0000-0002-1747-6430; Ovchinnikov, Mikhail/0000-0003-2377-4490
FU Ministry of Science and Higher Education of the Russian Federation
   [075-15-2019-1623]; Moscow Center of Fundamental and Applied Mathematics
FX This work was supported by Moscow Center of Fundamental and Applied
   Mathematics, Agreement with the Ministry of Science and Higher Education
   of the Russian Federation, No. 075-15-2019-1623.
NR 83
TC 1
Z9 1
U1 14
U2 25
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0094-5765
EI 1879-2030
J9 ACTA ASTRONAUT
JI Acta Astronaut.
PD SEP
PY 2021
VL 186
BP 87
EP 97
DI 10.1016/j.actaastro.2021.05.018
PG 11
WC Engineering, Aerospace
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA TF5KS
UT WOS:000670759300007
DA 2022-04-17
ER

PT J
AU Bhushan, S
   Burgreen, GW
   Brewer, W
   Dettwiller, ID
AF Bhushan, Shanti
   Burgreen, Greg W.
   Brewer, Wesley
   Dettwiller, Ian D.
TI Development and Validation of a Machine Learned Turbulence Model
SO ENERGIES
LA English
DT Article
DE turbulence modeling; machine learning; DNS
ID DIRECT NUMERICAL-SIMULATION; LARGE-EDDY SIMULATION; NEURAL-NETWORKS;
   BOUNDARY-LAYER; CHANNEL FLOW; PSEUDOSPECTRAL SOLVER; FLUCTUATIONS; FIELD
AB A stand-alone machine learned turbulence model is developed and applied for the solution of steady and unsteady boundary layer equations, and issues and constraints associated with the model are investigated. The results demonstrate that an accurately trained machine learned model can provide grid convergent, smooth solutions, work in extrapolation mode, and converge to a correct solution from ill-posed flow conditions. The accuracy of the machine learned response surface depends on the choice of flow variables, and training approach to minimize the overlap in the datasets. For the former, grouping flow variables into a problem relevant parameter for input features is desirable. For the latter, incorporation of physics-based constraints during training is helpful. Data clustering is also identified to be a useful tool as it avoids skewness of the model towards a dominant flow feature.
C1 [Bhushan, Shanti] Mississippi State Univ, Dept Mech Engn, Mississippi State, MS 39762 USA.
   [Bhushan, Shanti; Burgreen, Greg W.] Mississippi State Univ, Ctr Adv Vehicular Syst, Mississippi State, MS 39762 USA.
   [Brewer, Wesley] DoD High Performance Comp Modernizat Program PET, Vicksburg, MS 39180 USA.
   [Dettwiller, Ian D.] Engineer Res & Dev Ctr ERDC, Vicksburg, MS 39180 USA.
RP Bhushan, S (corresponding author), Mississippi State Univ, Dept Mech Engn, Mississippi State, MS 39762 USA.; Bhushan, S (corresponding author), Mississippi State Univ, Ctr Adv Vehicular Syst, Mississippi State, MS 39762 USA.
EM bhushan@me.msstate.edu; greg.burgreen@msstate.edu;
   wesley.brewer@gdit.com; ian.d.dettwiller@usace.army.mil
OI Burgreen, Greg/0000-0003-3953-6307
FU Engineering Research & Development Center [W912HZ-17-2-0014]; Department
   of Defense (DoD) High Performance Computing Modernization Program
   (HPCMP) under User Productivity Enhancement, Technology Transfer, and
   Training (PET) [47QFSA18K0111, ID04180146]
FX Effort at Mississippi State University was sponsored by the Engineering
   Research & Development Center under Cooperative Agreement number
   W912HZ-17-2-0014. The views and conclusions contained herein are those
   of the authors and should not be interpreted as necessarily representing
   the official policies or endorsements, either expressed or implied, of
   the Engineering Research & Development Center or the US Government. This
   material is also based upon work supported by, or in part by, the
   Department of Defense (DoD) High Performance Computing Modernization
   Program (HPCMP) under User Productivity Enhancement, Technology
   Transfer, and Training (PET) contract #47QFSA18K0111, TO#ID04180146.
NR 57
TC 2
Z9 2
U1 3
U2 8
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1996-1073
J9 ENERGIES
JI Energies
PD MAR
PY 2021
VL 14
IS 5
AR 1465
DI 10.3390/en14051465
PG 34
WC Energy & Fuels
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Energy & Fuels
GA QV7NB
UT WOS:000628152200001
OA gold
DA 2022-04-17
ER

PT J
AU Liebal, UW
   Phan, ANT
   Sudhakar, M
   Raman, K
   Blank, LM
AF Liebal, Ulf W.
   Phan, An N. T.
   Sudhakar, Malvika
   Raman, Karthik
   Blank, Lars M.
TI Machine Learning Applications for Mass Spectrometry-Based Metabolomics
SO METABOLITES
LA English
DT Review
DE machine learning; MS-based metabolomics; metabolic engineering;
   synthetic biology; metabolic flux analysis; multi-omics
ID SUPPORT VECTOR MACHINES; METABOLITE IDENTIFICATION; GENE-EXPRESSION;
   LC-MS; DATABASE; CLASSIFICATION; UNCERTAINTY; INTEGRATION; PATHWAYS;
   WORKFLOW
AB The metabolome of an organism depends on environmental factors and intracellular regulation and provides information about the physiological conditions. Metabolomics helps to understand disease progression in clinical settings or estimate metabolite overproduction for metabolic engineering. The most popular analytical metabolomics platform is mass spectrometry (MS). However, MS metabolome data analysis is complicated, since metabolites interact nonlinearly, and the data structures themselves are complex. Machine learning methods have become immensely popular for statistical analysis due to the inherent nonlinear data representation and the ability to process large and heterogeneous data rapidly. In this review, we address recent developments in using machine learning for processing MS spectra and show how machine learning generates new biological insights. In particular, supervised machine learning has great potential in metabolomics research because of the ability to supply quantitative predictions. We review here commonly used tools, such as random forest, support vector machines, artificial neural networks, and genetic algorithms. During processing steps, the supervised machine learning methods help peak picking, normalization, and missing data imputation. For knowledge-driven analysis, machine learning contributes to biomarker detection, classification and regression, biochemical pathway identification, and carbon flux determination. Of important relevance is the combination of different omics data to identify the contributions of the various regulatory levels. Our overview of the recent publications also highlights that data quality determines analysis quality, but also adds to the challenge of choosing the right model for the data. Machine learning methods applied to MS-based metabolomics ease data analysis and can support clinical decisions, guide metabolic engineering, and stimulate fundamental biological discoveries.
C1 [Liebal, Ulf W.; Phan, An N. T.; Blank, Lars M.] Rhein Westfal TH Aachen, Inst Appl Microbiol Aachen Biol & Biotechnol, Worringer Weg 1, D-52074 Aachen, Germany.
   [Sudhakar, Malvika; Raman, Karthik] Indian Inst Technol IIT Madras, Bhupat & Juoti Mehta Sch Biosci, Dept Biotechnol, Chennai 600036, Tamil Nadu, India.
   [Sudhakar, Malvika; Raman, Karthik] IIT Madras, Initiat Biol Syst Engn, Chennai 600036, Tamil Nadu, India.
   [Sudhakar, Malvika; Raman, Karthik] IIT Madras, Robert Bosch Ctr Data Sci & Artificial Intelligen, Chennai 600036, Tamil Nadu, India.
RP Liebal, UW; Blank, LM (corresponding author), Rhein Westfal TH Aachen, Inst Appl Microbiol Aachen Biol & Biotechnol, Worringer Weg 1, D-52074 Aachen, Germany.
EM Ulf.Liebal@rwth-aachen.de; an.phanl@rwth-aachen.de;
   bt15d306@smail.iitm.ac.in; kraman@iitm.ac.in; Lars.Blank@rwth-aachen.de
RI ; Raman, Karthik/A-6459-2011; Blank, Lars M./A-6761-2012
OI Liebal, Ulf/0000-0001-5172-7339; Sudhakar, Malvika/0000-0002-2442-4305;
   Raman, Karthik/0000-0002-9311-7093; THUY AN, PHAN
   NGUYEN/0000-0002-1438-416X; Blank, Lars M./0000-0003-0961-4976
FU Excellence Initiative of the German federal and state governments
   [PFSDS015]; European UnionEuropean Commission [793158]; Deutsche
   Forschungsgemeinschaft (DFG, German Research Foundation)German Research
   Foundation (DFG) [390919832]; Department of Biotechnology, Government of
   India (DBT)Department of Biotechnology (DBT) India
   [BT/PR16710/BID/7/680/2016]; Ministry of Human Resource Development
   (MHRD)Ministry of Human Resource Development (MHRD), Government of
   India; IIT Madras
FX U.W.L. acknowledges funding by the Excellence Initiative of the German
   federal and state governments (PFSDS015). A.N.T.P. has received funding
   from the European Union's Horizon 2020 research and innovation program
   under the Marie Sklodowska-Curie grant agreement No. 793158. The
   laboratory of L.M.B. is partially funded by the Deutsche
   Forschungsgemeinschaft (DFG, German Research Foundation) under Germany's
   Excellence Strategy-Exzellenzcluster 2186, `The Fuel Science Center ID:
   390919832.' M.S. and K.R. are supported by Department of Biotechnology,
   Government of India (DBT) (BT/PR16710/BID/7/680/2016), IIT Madras (KR)
   and Ministry of Human Resource Development (MHRD) (MS).
NR 139
TC 43
Z9 44
U1 33
U2 62
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2218-1989
J9 METABOLITES
JI Metabolites
PD JUN
PY 2020
VL 10
IS 6
AR 243
DI 10.3390/metabo10060243
PG 25
WC Biochemistry & Molecular Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology
GA MO5PE
UT WOS:000551576900008
PM 32545768
OA gold, Green Published
DA 2022-04-17
ER

PT J
AU Zakaria, NA
   Ismail, AR
   Ali, AY
   Khalid, NHM
   Abidin, NZ
AF Zakaria, Noor Azura
   Ismail, Amelia Ritahani
   Ali, Afrujaan Yakath
   Khalid, Nur Hidayah Mohd
   Abidin, Nadzurah Zainal
TI Software Project Estimation with Machine Learning
SO INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS
LA English
DT Article
DE Software effort estimation; project estimation; constructive cost model;
   COCOMO; machine learning
AB This project involves research about software effort estimation using machine learning algorithms. Software cost and effort estimation are crucial parts of software project development. It determines the budget, time and resources needed to develop a software project. One of the well-established software project estimation models is Constructive Cost Model (COCOMO) which was developed in the 1980s. Even though such a model is being used, COCOMO has some weaknesses and software developers still facing the problem of lack of accuracy of the effort and cost estimation. Inaccuracy in the estimated effort will affect the schedule and cost of the whole project as well. The objective of this research is to use several algorithms of machine learning to estimate the effort of software project development. The best machine learning model is chosen to compare with the COCOMO.
C1 [Zakaria, Noor Azura; Ismail, Amelia Ritahani; Ali, Afrujaan Yakath; Khalid, Nur Hidayah Mohd; Abidin, Nadzurah Zainal] Int Islamic Univ Malaysia, Kulliyyah Informat & Commun Technol, Dept Comp Sci, Kuala Lumpur, Malaysia.
RP Zakaria, NA (corresponding author), Int Islamic Univ Malaysia, Kulliyyah Informat & Commun Technol, Dept Comp Sci, Kuala Lumpur, Malaysia.
FU IIUM Research Acculturation Grant Scheme [IRAGS18-012-0013]
FX This research is funded by IIUM Research Acculturation Grant Scheme with
   the Ref: IRAGS18-012-0013.
NR 25
TC 0
Z9 0
U1 1
U2 1
PU SCIENCE & INFORMATION SAI ORGANIZATION LTD
PI WEST YORKSHIRE
PA 19 BOLLING RD, BRADFORD, WEST YORKSHIRE, 00000, ENGLAND
SN 2158-107X
EI 2156-5570
J9 INT J ADV COMPUT SC
JI Int. J. Adv. Comput. Sci. Appl.
PD JUN
PY 2021
VL 12
IS 6
BP 726
EP 734
PG 9
WC Computer Science, Theory & Methods
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA UB9TB
UT WOS:000686178900085
DA 2022-04-17
ER

PT J
AU Kyono, T
   Gilbert, FJ
   van der Schaar, M
AF Kyono, Trent
   Gilbert, Fiona J.
   van der Schaar, Mihaela
TI Improving Workflow Efficiency for Mammography Using Machine Learning
SO JOURNAL OF THE AMERICAN COLLEGE OF RADIOLOGY
LA English
DT Article
DE Breast cancer; deep learning; machine learning; mammography; radiology
ID BREAST DENSITY; AGE
AB Objective: The aim of this study was to determine whether machine learning could reduce the number of mammograms the radiologist must read by using a machine-learning classifier to correctly identify normal mammograms and to select the uncertain and abnormal examinations for radiological interpretation.
   Methods: Mammograms in a research data set from over 7,000 women who were recalled for assessment at six UK National Health Service Breast Screening Program centers were used. A convolutional neural network in conjunction with multitask learning was used to extract imaging features from mammograms that mimic the radiological assessment provided by a radiologist, the patient's nonimaging features, and pathology outcomes. A deep neural network was then used to concatenate and fuse multiple mammogram views to predict both a diagnosis and a recommendation of whether or not additional radiological assessment was needed.
   Results: Ten-fold cross-validation was used on 2,000 randomly selected patients from the data set; the remainder of the data set was used for convolutional neural network training. While maintaining an acceptable negative predictive value of 0.99, the proposed model was able to identify 34% (95% confidence interval, 25%-43%) and 91% (95% confidence interval: 88%-94%) of the negative mammograms for test sets with a cancer prevalence of 15% and 1%, respectively.
   Conclusion: Machine learning was leveraged to successfully reduce the number of normal mammograms that radiologists need to read without degrading diagnostic accuracy.
C1 [Kyono, Trent; van der Schaar, Mihaela] Univ Calif Los Angeles, Dept Comp Sci, 291 Engn 6, Los Angeles, CA 90095 USA.
   [Gilbert, Fiona J.] Univ Cambridge, Dept Radiol, Sch Clin Med, Cambridge, England.
   [Gilbert, Fiona J.] NIHR Cambridge Biomed Res Ctr, Cambridge, England.
RP Kyono, T (corresponding author), Univ Calif Los Angeles, Dept Comp Sci, 291 Engn 6, Los Angeles, CA 90095 USA.
EM tmkyono@gmail.com
OI Gilbert, Fiona/0000-0002-0124-9962
FU Department of HealthEuropean Commission [09/22/182] Funding Source:
   Medline; EPSRCUK Research & Innovation (UKRI)Engineering & Physical
   Sciences Research Council (EPSRC) [EP/N014588/1] Funding Source: UKRI
NR 30
TC 25
Z9 25
U1 1
U2 10
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 1546-1440
J9 J AM COLL RADIOL
JI J. Am. Coll. Radiol.
PD JAN
PY 2020
VL 17
IS 1
BP 56
EP 63
DI 10.1016/j.jacr.2019.05.012
PN A
PG 8
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA KB8DC
UT WOS:000506718500011
PM 31153798
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Miller, ST
   Lindner, JF
   Choudhary, A
   Sinha, S
   Ditto, WL
AF Miller, Scott T.
   Lindner, John F.
   Choudhary, Anshul
   Sinha, Sudeshna
   Ditto, William L.
TI Negotiating the separatrix with machine learning
SO IEICE NONLINEAR THEORY AND ITS APPLICATIONS
LA English
DT Article
DE machine learning; neural networks; Hamiltonian dynamics
AB Physics-informed machine learning has recently been shown to efficiently learn complex trajectories of nonlinear dynamical systems, even when order and chaos coexist. However, care must be taken when one or more variables are unbounded, such as in rotations. Here we use the framework of Hamiltonian Neural Networks (HNN) to learn the complex dynamics of nonlinear single and double pendulums, which can both librate and rotate, by mapping the unbounded phase space onto a compact cylinder. We clearly demonstrate that our approach can successfully forecast the motion of these challenging systems, capable of both bounded and unbounded motion. It is also evident that HNN can yield an energy surface that closely matches the surface generated by the true Hamiltonian function. Further we observe that the relative energy error for HNN decreases as a power law with number of training pairs, with HNN clearly outperforming conventional neural networks quantitatively.
C1 [Miller, Scott T.; Lindner, John F.; Choudhary, Anshul; Ditto, William L.] North Carolina State Univ, Phys Dept, Nonlinear Artificial Intelligence Lab, Raleigh, NC 27607 USA.
   [Lindner, John F.] Coll Wooster, Phys Dept, Wooster, OH 44691 USA.
   [Sinha, Sudeshna] Indian Inst Sci Educ & Res Mohali, Sect 81,Manauli PO, Manauli 140306, Punjab, India.
RP Sinha, S (corresponding author), Indian Inst Sci Educ & Res Mohali, Sect 81,Manauli PO, Manauli 140306, Punjab, India.
EM sudeshna@iisermohali.ac.in
OI Miller, Scott/0000-0002-9440-908X; Choudhary,
   Anshul/0000-0001-6651-5224; Ditto, William/0000-0002-7416-8012
FU ONR grant [N00014-16-1-3066]; Aeris Rising, LLC; J.C. Bose National
   Fellowship [SB/S2/JCB-013/2015]
FX This research was supported by ONR grant N00014-16-1-3066, a gift from
   United Therapeutics, and support from Aeris Rising, LLC. J.F.L. thanks
   The College of Wooster for making possible his sabbatical at NCSU. S.S.
   acknowledges support from the J.C. Bose National Fellowship (Grant No.
   SB/S2/JCB-013/2015).
NR 10
TC 1
Z9 1
U1 0
U2 0
PU IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG
PI TOKYO
PA KIKAI-SHINKO-KAIKAN BLDG, 3-5-8, SHIBA-KOEN, MINATO-KU, TOKYO, 105-0011,
   JAPAN
SN 2185-4106
J9 IEICE NONLINEAR THEO
JI IEICE Nonlinear Theory Appl.
PY 2021
VL 12
IS 2
BP 134
EP 142
DI 10.1587/nolta.12.134
PG 9
WC Mathematics, Interdisciplinary Applications
WE Emerging Sources Citation Index (ESCI)
SC Mathematics
GA RH8OV
UT WOS:000636471600004
OA gold
DA 2022-04-17
ER

PT J
AU Kim, H
   Cho, H
   Ryu, D
AF Kim, Hyeongjun
   Cho, Hoon
   Ryu, Doojin
TI Corporate Default Predictions Using Machine Learning: Literature Review
SO SUSTAINABILITY
LA English
DT Review
DE classification; default prediction; financial engineering; forecasting;
   machine learning
ID BANKRUPTCY PREDICTION; FINANCIAL RATIOS; NEURAL-NETWORKS; MODELS; RISK;
   DISTRESS; ALGORITHM; INFORMATION; ENSEMBLES; SELECTION
AB Corporate default predictions play an essential role in each sector of the economy, as highlighted by the global financial crisis and the increase in credit risk. This study reviews the corporate default prediction literature from the perspectives of financial engineering and machine learning. We define three generations of statistical models: discriminant analyses, binary response models, and hazard models. In addition, we introduce three representative machine learning methodologies: support vector machines, decision trees, and artificial neural network algorithms. For both the statistical models and machine learning methodologies, we identify the key studies used in corporate default prediction. By comparing these methods with findings from the interdisciplinary literature, our review suggests some new tasks in the field of machine learning for predicting corporate defaults. First, a corporate default prediction model should be a multi-period model in which future outcomes are affected by past decisions. Second, the stock price and the corporate value determined by the stock market are important factors to use in default predictions. Finally, a corporate default prediction model should be able to suggest the cause of default.
C1 [Kim, Hyeongjun] Yeungnam Univ, Dept Business Adm, Gyongsan 38541, South Korea.
   [Cho, Hoon] Korea Adv Inst Sci & Technol, Coll Business, Seoul 02455, South Korea.
   [Ryu, Doojin] Sungkyunkwan Univ, Coll Econ, Seoul 03063, South Korea.
RP Ryu, D (corresponding author), Sungkyunkwan Univ, Coll Econ, Seoul 03063, South Korea.
EM hkim@yu.ac.kr; hooncho@kaist.ac.kr; doojin.ryu@gmail.com
RI Ryu, Doojin/AAZ-3318-2020
OI Ryu, Doojin/0000-0002-0059-4887; Cho, Hoon/0000-0003-2322-320X; Kim,
   Hyeongjun/0000-0003-0386-005X
FU National Research Foundation of Korea (NRF) - Korea government (MSIT;
   Ministry of Science and ICT) [2019R1G1A1100196]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT; Ministry of Science
   and ICT) [No. 2019R1G1A1100196].
NR 60
TC 9
Z9 9
U1 25
U2 55
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2071-1050
J9 SUSTAINABILITY-BASEL
JI Sustainability
PD AUG
PY 2020
VL 12
IS 16
AR 6325
DI 10.3390/su12166325
PG 11
WC Green & Sustainable Science & Technology; Environmental Sciences;
   Environmental Studies
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Science & Technology - Other Topics; Environmental Sciences & Ecology
GA OC1LM
UT WOS:000578924000001
OA gold
DA 2022-04-17
ER

PT C
AU Cowan, M
   Moreau, T
   Chen, TQ
   Bornholt, J
   Ceze, L
AF Cowan, Meghan
   Moreau, Thierry
   Chen, Tianqi
   Bornholt, James
   Ceze, Luis
BE Mars, J
   Tang, L
   Xue, J
   Wu, P
TI Automatic Generation of High-Performance Quantized Machine Learning
   Kernels
SO CGO'20: PROCEEDINGS OF THE18TH ACM/IEEE INTERNATIONAL SYMPOSIUM ON CODE
   GENERATION AND OPTIMIZATION
SE International Symposium on Code Generation and Optimization
LA English
DT Proceedings Paper
CT 18th ACM/IEEE International Symposium on Code Generation and
   Optimization (CGO)
CY FEB 22-26, 2020
CL San Diego, CA
SP Assoc Comp Machinery, IEEE, ACM SIGPLAN, ACM SIGMICRO, IEEE Comp Soc, US Natl Sci Fdn, Alibaba Grp, Arm, Facebook, Google, Microsoft, Oracle, Uber, Futurewei Technologies
DE quantization; machine learning; synthesis
AB Quantization optimizes machine learning inference for resource constrained environments by reducing the precision of its computation. In the extreme, even single-bit computations can produce acceptable results at dramatically lower cost. But this ultra-low-precision quantization is difficult to exploit because extracting optimal performance requires hand-tuning both high-level scheduling decisions and low-level implementations. As a result, practitioners settle for a few predefined quantized kernels, sacrificing optimality and restricting their ability to adapt to new hardware.
   This paper presents a new automated approach to implementing quantized inference for machine learning models. We integrate the choice of how to lay out quantized values into the scheduling phase of a machine learning compiler, allowing it to be optimized in concert with tiling and parallelization decisions. After scheduling, we use program synthesis to automatically generate efficient low-level operator implementations for the desired precision and data layout. We scale up synthesis using a novel reduction sketch that exploits the structure of matrix multiplication. On a ResNet18 model, our generated code outperforms an optimized floating-point baseline by up to 3. 9x, and a state-of the-art quantized implementation by up to 16.6x.
C1 [Cowan, Meghan; Moreau, Thierry; Chen, Tianqi; Ceze, Luis] Univ Washington, Seattle, WA 98195 USA.
   [Bornholt, James] Univ Texas Austin, Austin, TX 78712 USA.
RP Cowan, M (corresponding author), Univ Washington, Seattle, WA 98195 USA.
EM cowanmeg@cs.uw.ed; moreau@cs.uw.ed; tqchen@cs.uw.edu;
   bornholt@cs.utexas.edu; luisceze@cs.uw.edu
FU NSFNational Science Foundation (NSF) [CCF-1518703]; CRISP - DARPA;
   DARPAUnited States Department of DefenseDefense Advanced Research
   Projects Agency (DARPA); Facebook PhD FellowshipFacebook Inc
FX We thank Andrew Tulloch and Yaman Umuroglu for sharing their experiences
   implementing quantized inference; Josh Fromm for his help in training
   models; and our shepherd Christophe Dubach and the anonymous reviewers
   for their helpful feedback. This work was supported in part by NSF under
   grant CCF-1518703; by CRISP, one of six centers in JUMP, a Semiconductor
   Research Corporation (SRC) program sponsored by DARPA; by gifts from
   Xilinx, Intel (under the CAPA program), Oracle, Amazon, Qualcomm, and
   other anonymous sources; and by a Facebook PhD Fellowship.
NR 44
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
SN 2164-2397
BN 978-1-4503-7047-9
J9 INT SYM CODE GENER
PY 2020
BP 305
EP 316
DI 10.1145/3368826.3377912
PG 12
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ6TS
UT WOS:000613250200024
OA Bronze
DA 2022-04-17
ER

PT J
AU Bailey, JD
   Baker, JC
   Rzeszutek, MJ
   Lanovaz, MJ
AF Bailey, Jordan D.
   Baker, Jonathan C.
   Rzeszutek, Mark J.
   Lanovaz, Marc J.
TI Machine Learning for Supplementing Behavioral Assessment
SO PERSPECTIVES ON BEHAVIOR SCIENCE
LA English
DT Article
DE Indirect assessment; Functional analysis; QABF; Machine learning
ID FUNCTIONAL-ANALYSIS; CONVERGENT VALIDITY; NEURAL-NETWORK; FUNCTION
   SCALE; CLASSIFICATION; QUESTIONS; INDIVIDUALS
AB The Questions About Behavioral Function (QABF) has a high degree of convergent validity, but there is still a lack of agreement between the results of the assessment and the results of experimental function analysis. Machine learning (ML) may improve the validity of assessments by using data to build a mathematical model for more accurate predictions. We used published QABF and subsequent functional analyses to train ML models to identify the function of behavior. With ML models, predictions can be made from indirect assessment results based on learning from results of past experimental functional analyses. In Experiment 1, we compared the results of five algorithms to the QABF criteria using a leave-one-out cross-validation approach. All five outperformed the QABF assessment on multilabel accuracy (i.e., percentage of predictions with the presence or absence of each function indicated correctly), but false negatives remained an issue. In Experiment 2, we augmented the data with 1,000 artificial samples to train and test an artificial neural network. The artificial network outperformed other models on all measures of accuracy. The results indicated that ML could be used to inform conditions that should be present in a functional analysis. Therefore, this study represents a proof-of-concept for the application of machine learning to functional assessment.
C1 [Bailey, Jordan D.] Franciscan Missionaries Our Lady Univ, Dept Psychol, Baton Rouge, LA 70808 USA.
   [Baker, Jonathan C.; Rzeszutek, Mark J.] Western Michigan Univ, Kalamazoo, MI 49008 USA.
   [Lanovaz, Marc J.] Univ Montreal, Montreal, PQ, Canada.
RP Bailey, JD (corresponding author), Franciscan Missionaries Our Lady Univ, Dept Psychol, Baton Rouge, LA 70808 USA.
EM jordan.bailey1@franu.edu
RI Lanovaz, Marc J/K-9614-2019
OI Lanovaz, Marc J/0000-0002-9023-0314; Bailey, Jordan/0000-0002-6616-6287;
   Rzeszutek, Mark/0000-0003-4555-9767
NR 65
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER INT PUBL AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2520-8969
EI 2520-8977
J9 PERSPECT BEHAV SCI
JI Perspect. Behav. Sci.
PD DEC
PY 2021
VL 44
IS 4
SI SI
BP 605
EP 619
DI 10.1007/s40614-020-00273-9
EA JAN 2021
PG 15
WC Psychology, Clinical
WE Social Science Citation Index (SSCI)
SC Psychology
GA YC8XK
UT WOS:000606204200001
PM 35098027
OA Green Published
DA 2022-04-17
ER

PT C
AU Brown, J
   Campbell, I
AF Brown, Justin
   Campbell, Ian
GP IEEE
TI Dynamic Environmental Stress Screening Using Machine Learning
SO 2020 ANNUAL RELIABILITY AND MAINTAINABILITY SYMPOSIUM (RAMS 2020)
SE Reliability and Maintainability Symposium
LA English
DT Proceedings Paper
CT Annual Reliability and Maintainability Symposium (RAMS)
CY JAN 27-30, 2020
CL Palm Springs, CA
DE ESS; Reliability; Defense acquisition; Machine Learning
AB Thermal Environmental Stress Screening (ESS) is a proven method used to detect manufacturing defects in production hardware. Numerous multi-hour cycles are performed to properly screen systems with thousands of solder connections, complex mechanical configurations, and intricate electrical designs. The current industry standard thermal ESS process is to perform a survey on the system, define the profile, and establish a set quantity of cycles to perform per system. It is also well-understood that machine learning has the capability to improve manufacturing processes [1]. In an effort to reduce test times and unnecessary stress, a Machine Learning (ML) model, based on the amount of production rework performed on the system prior to ESS, can be generated to predict the optimal amount of cycles to perform on the system. This approach improves both cost and schedule of the system under test.
C1 [Brown, Justin; Campbell, Ian] Raytheon, 13510 North Cent Expressway, Dallas, TX 75243 USA.
RP Brown, J (corresponding author), Raytheon, 13510 North Cent Expressway, Dallas, TX 75243 USA.
EM justinbrown@ieee.org; ian.campbell@raytheon.com
NR 2
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 0149-144X
BN 978-1-7281-3689-9
J9 P REL MAINT S
PY 2020
PG 5
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BQ7NZ
UT WOS:000618045900004
DA 2022-04-17
ER

PT J
AU Chittora, P
   Chaurasia, S
   Chakrabarti, P
   Kumawat, G
   Chakrabarti, T
   Leonowicz, Z
   Jasinski, M
   Jasinski, L
   Gono, R
   Jasinska, E
   Bolshev, V
AF Chittora, Pankaj
   Chaurasia, Sandeep
   Chakrabarti, Prasun
   Kumawat, Gaurav
   Chakrabarti, Tulika
   Leonowicz, Zbigniew
   Jasinski, Michal
   Jasinski, Lukasz
   Gono, Radomir
   Jasinska, Elzbieta
   Bolshev, Vadim
TI Prediction of Chronic Kidney Disease-A Machine Learning Perspective
SO IEEE ACCESS
LA English
DT Article
DE Kidney; Diseases; Classification algorithms; Machine learning
   algorithms; Support vector machines; Prediction algorithms; Machine
   learning; Chronic kidney disease; machine learning; prediction
AB Chronic Kidney Disease is one of the most critical illness nowadays and proper diagnosis is required as soon as possible. Machine learning technique has become reliable for medical treatment. With the help of a machine learning classifier algorithms, the doctor can detect the disease on time. For this perspective, Chronic Kidney Disease prediction has been discussed in this article. Chronic Kidney Disease dataset has been taken from the UCI repository. Seven classifier algorithms have been applied in this research such as artificial neural network, C5.0, Chi-square Automatic interaction detector, logistic regression, linear support vector machine with penalty L1 & with penalty L2 and random tree. The important feature selection technique was also applied to the dataset. For each classifier, the results have been computed based on (i) full features, (ii) correlation-based feature selection, (iii) Wrapper method feature selection, (iv) Least absolute shrinkage and selection operator regression, (v) synthetic minority over-sampling technique with least absolute shrinkage and selection operator regression selected features, (vi) synthetic minority over-sampling technique with full features. From the results, it is marked that LSVM with penalty L2 is giving the highest accuracy of 98.86% in synthetic minority over-sampling technique with full features. Along with accuracy, precision, recall, F-measure, area under the curve and GINI coefficient have been computed and compared results of various algorithms have been shown in the graph. Least absolute shrinkage and selection operator regression selected features with synthetic minority over-sampling technique gave the best after synthetic minority over-sampling technique with full features. In the synthetic minority over-sampling technique with least absolute shrinkage and selection operator selected features, again linear support vector machine gave the highest accuracy of 98.46%. Along with machine learning models one deep neural network has been applied on the same dataset and it has been noted that deep neural network achieved the highest accuracy of 99.6%.
C1 [Chittora, Pankaj; Chaurasia, Sandeep; Kumawat, Gaurav] Manipal Univ Jaipur, Dept Comp Sci & Engn, Jaipur 303007, Rajasthan, India.
   [Chakrabarti, Prasun] Techno India NJR Inst Technol, Dept Comp Sci Engn, Udaipur 313003, Rajasthan, India.
   [Chakrabarti, Prasun] Thu Dau Mot Univ, Engn Technol Sch, Data Analyt & Artificial Intelligence Lab, Thu Dau Mot 820000, Vietnam.
   [Chakrabarti, Tulika] Sir Padampat Singhania Univ, Dept Basic Sci Chem, Udaipur 3136022, Rajasthan, India.
   [Leonowicz, Zbigniew; Jasinski, Michal; Jasinski, Lukasz] Wroclaw Univ Sci & Technol, Dept Elect Engn Fundamentals, Fac Elect Engn, PL-50370 Wroclaw, Poland.
   [Gono, Radomir] VSB Tech Univ Ostrava, Fac Elect Engn & Comp Sci, Dept Elect Power Engn, Ostrava 70800, Czech Republic.
   [Jasinska, Elzbieta] Univ Wroclaw, Fac Law Adm & Econ, PL-50145 Wroclaw, Poland.
   [Bolshev, Vadim] Fed Sci Agroengn Ctr VIM, Lab Power Supply & Heat Supply, Moscow 109428, Russia.
RP Jasinski, M (corresponding author), Wroclaw Univ Sci & Technol, Dept Elect Engn Fundamentals, Fac Elect Engn, PL-50370 Wroclaw, Poland.
EM michal.jasinski@pwr.edu.pl
RI Gono, Radomir/D-3033-2017; Jasińska, Elzbieta/AAF-9186-2020; Jasinski,
   Michal/B-1775-2019; Bolshev, Vadim/M-8440-2018; Leonowicz,
   Zbigniew/K-8650-2017; Chaurasia, Sandeep/AAE-5763-2022
OI Gono, Radomir/0000-0003-1125-3305; Jasińska,
   Elzbieta/0000-0003-2433-3873; Jasinski, Michal/0000-0002-0983-2562;
   Bolshev, Vadim/0000-0002-5787-8581; Leonowicz,
   Zbigniew/0000-0002-2388-3710; Chittora, Pankaj/0000-0001-9047-3001
FU Chair of Electrical Engineering Fundamentals, Wroclaw University of
   Technology, Wroclaw, Poland [K38W05D02]
FX This work was funded by the Chair of Electrical Engineering Fundamentals
   (K38W05D02), Wroclaw University of Technology, Wroclaw, Poland.
NR 35
TC 7
Z9 7
U1 5
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 17312
EP 17334
DI 10.1109/ACCESS.2021.3053763
PG 23
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA QC7VC
UT WOS:000615039900001
OA Green Published, gold
DA 2022-04-17
ER

PT C
AU Prihandono, MA
   Harwahyu, R
   Sari, RF
AF Prihandono, Mohammad Agus
   Harwahyu, Ruki
   Sari, Riri Fitri
GP IEEE
TI Performance of Machine Learning Algorithms for IT Incident Management
SO 2020 11TH INTERNATIONAL CONFERENCE ON AWARENESS SCIENCE AND TECHNOLOGY
   (ICAST)
SE International Conference on Awareness Science and Technology
LA English
DT Proceedings Paper
CT 11th International Conference on Awareness Science and Technology
   (iCAST)
CY DEC 07-09, 2020
CL Qingdao, PEOPLES R CHINA
DE IT Incident; IT Service Management; machine learning; deep learning
AB Incident Management is a part of managing IT services, improving services, and achieving organizational goals. IT incidents can be learned and predicted future incidents. This research compares the factors that cause incidents using initial machine learning techniques such as Random Forest, SVM, Multilayer perceptron, and the latest machine learning techniques such as RNN, LSTM, GRU, to predict IT incidents. Grid search is used to find the optimal parameter combination. 5-fold and 10-fold Cross-validation evaluates the model's optimal performance by dividing the dataset into training data and test data. The results show that the highest accuracy of 98.866% is produced by LSTM machine learning techniques at 5-fold and 10-fold cross-validation. SVM has the lowest accuracy of 97.837% made at 5-fold and 10-fold cross-validation.
C1 [Prihandono, Mohammad Agus; Harwahyu, Ruki; Sari, Riri Fitri] Univ Indonesia, Dept Elect Engn, Kota Depok, Jawa Barat, Indonesia.
RP Prihandono, MA (corresponding author), Univ Indonesia, Dept Elect Engn, Kota Depok, Jawa Barat, Indonesia.
EM mohammad.agus81@ui.ac.id; ruki.h@ui.ac.id; riri@ui.ac.id
FU University of IndonesiaMinistry of Research and Technology of the
   Republic of Indonesia (RISTEK) [NKB 1073/UN2, RST/HKP.05.00/2020]
FX We thank the University of Indonesia for financial support for this
   research under the PUTI Prosiding Grant number NKB
   1073/UN2.RST/HKP.05.00/2020
NR 22
TC 0
Z9 0
U1 2
U2 2
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2325-5986
BN 978-1-7281-9119-5
J9 INT CONF AWARE SCI
PY 2020
DI 10.1109/ICAST51195.2020.9319487
PG 6
WC Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering
GA BR4RB
UT WOS:000652342200022
DA 2022-04-17
ER

PT J
AU Smith, R
   Dutta, S
AF Smith, Reid
   Dutta, Sandip
TI Conjugate Thermal Optimization With Unsupervised Machine Learning
SO JOURNAL OF HEAT TRANSFER-TRANSACTIONS OF THE ASME
LA English
DT Article
DE heat transfer; thermal design; optimization; transfer function; machine
   learning; unsupervised learning
ID HEAT; SYSTEM
AB With advances in additive manufacturing of metal components, commercial production of complex turbine components is becoming feasible. Thus, designers are not constrained to the limitations of conventional manufacturing methods. A new conjugate optimization technique is proposed, which is not computationally demanding and can be used when several heat transfer modes are working simultaneously. For this study, film cooling holes in the leading edge of a gas turbine airfoil are optimized without trial and error simulations. Since the machine learning technique is not dependent on thermal analysis, the optimization technique can be applied to any nonlinear problem. Film hole sizes are optimized to minimize coolant flow rate while reducing the temperature variations in the stationary vane. The technique used a transfer function based iterative optimization process with unsupervised machine learning that has been termed nonlinear optimization with replacement strategy (NORS). It uses a grading metric to replace the worst performing hole combinations with one that has been optimized with a given objective and several constraints. Optimized results show significant reductions in vertical temperature variations along the leading edge while minimizing coolant flow rate. Reduced temperature variation results in reduced thermal stresses. The finite element (FE) model and the associated correlations are not part of the unsupervised machine learning technique; therefore, the proposed optimization model can be generalized for any engineering design with multiple inputs for learning and multiple outputs for grading.
C1 [Smith, Reid] Univ Illinois, Mech Sci & Engn Dept, Champaign, IL 61801 USA.
   [Dutta, Sandip] Clemson Univ, Mech Engn Dept, Clemson, SC 29634 USA.
RP Smith, R (corresponding author), Univ Illinois, Mech Sci & Engn Dept, Champaign, IL 61801 USA.
NR 35
TC 3
Z9 3
U1 5
U2 6
PU ASME
PI NEW YORK
PA TWO PARK AVE, NEW YORK, NY 10016-5990 USA
SN 0022-1481
EI 1528-8943
J9 J HEAT TRANS-T ASME
JI J. Heat Transf.-Trans. ASME
PD MAY 1
PY 2021
VL 143
IS 5
AR 052901
DI 10.1115/1.4049842
PG 10
WC Thermodynamics; Engineering, Mechanical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Thermodynamics; Engineering
GA RI3PJ
UT WOS:000636821000004
DA 2022-04-17
ER

PT J
AU Waring, J
   Lindvall, C
   Umeton, R
AF Waring, Jonathan
   Lindvall, Charlotta
   Umeton, Renato
TI Automated machine learning: Review of the state-of-the-art and
   opportunities for healthcare
SO ARTIFICIAL INTELLIGENCE IN MEDICINE
LA English
DT Review
DE Machine learning; Deep learning; Automated machine learning; AutoML;
   Healthcare
ID BIG DATA; REPRESENTATION; ANALYTICS; PATIENT; RISK
AB Objective: This work aims to provide a review of the existing literature in the field of automated machine learning (AutoML) to help healthcare professionals better utilize machine learning models "off-the-shelf" with limited data science expertise. We also identify the potential opportunities and barriers to using AutoML in healthcare, as well as existing applications of AutoML in healthcare.
   Methods: Published papers, accompanied with code, describing work in the field of AutoML from both a computer science perspective or a biomedical informatics perspective were reviewed. We also provide a short summary of a series of AutoML challenges hosted by ChaLearn.
   Results: A review of 101 papers in the field of AutoML revealed that these automated techniques can match or improve upon expert human performance in certain machine learning tasks, often in a shorter amount of time. The main limitation of AutoML at this point is the ability to get these systems to work efficiently on a large scale, i.e. beyond small- and medium-size retrospective datasets.
   Discussion: The utilization of machine learning techniques has the demonstrated potential to improve health outcomes, cut healthcare costs, and advance clinical research. However, most hospitals are not currently deploying machine learning solutions. One reason for this is that health care professionals often lack the machine learning expertise that is necessary to build a successful model, deploy it in production, and integrate it with the clinical workflow. In order to make machine learning techniques easier to apply and to reduce the demand for human experts, automated machine learning (AutoML) has emerged as a growing field that seeks to automatically select, compose, and parametrize machine learning models, so as to achieve optimal performance on a given task and/or dataset.
   Conclusion: While there have already been some use cases of AutoML in the healthcare field, more work needs to be done in order for there to be widespread adoption of AutoML in healthcare.
C1 [Waring, Jonathan; Umeton, Renato] Dana Farber Canc Inst, Dept Informat & Analyt, Boston, MA 02215 USA.
   [Waring, Jonathan; Umeton, Renato] Harvard TH Chan Sch Publ Hlth, Dept Biostat, Boston, MA 02215 USA.
   [Lindvall, Charlotta] Dana Farber Canc Inst, Dept Pyschosocial Oncol & Palliat Care, Boston, MA 02215 USA.
   [Lindvall, Charlotta] Brigham & Womens Hosp, Dept Med, 75 Francis St, Boston, MA 02115 USA.
   [Umeton, Renato] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
RP Waring, J (corresponding author), Dana Farber Canc Inst, Dept Informat & Analyt, Boston, MA 02215 USA.
EM jonathan_waring@dfci.harvard.edu; charlotta_lindvall@dfci.harvard.edu;
   renato_umeton@dfci.harvard.edu
OI Umeton, Renato/0000-0002-5561-6932
NR 172
TC 86
Z9 88
U1 61
U2 85
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0933-3657
EI 1873-2860
J9 ARTIF INTELL MED
JI Artif. Intell. Med.
PD APR
PY 2020
VL 104
AR 101822
DI 10.1016/j.artmed.2020.101822
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Biomedical;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Medical Informatics
GA LU5OP
UT WOS:000537804900016
PM 32499001
OA hybrid
HC Y
HP N
DA 2022-04-17
ER

PT J
AU Lee, K
   Claridades, ARC
   Lee, J
AF Lee, Kangjae
   Claridades, Alexis Richard C.
   Lee, Jiyeong
TI Improving a Street-Based Geocoding Algorithm Using Machine Learning
   Techniques
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE geocoding; machine learning; address; alias
ID GIS; ADDRESSES; ACCURACY
AB Address matching is a crucial step in geocoding; however, this step forms a bottleneck for geocoding accuracy, as precise input is the biggest challenge for establishing perfect matches. Matches still have to be established despite the inevitability of incorrect address inputs such as misspellings, abbreviations, informal and non-standard names, slangs, or coded terms. Thus, this study suggests an address geocoding system using machine learning to enhance the address matching implemented on street-based addresses. Three different kinds of machine learning methods are tested to find the best method showing the highest accuracy. The performance of address matching using machine learning models is compared to multiple text similarity metrics, which are generally used for the word matching. It was proved that extreme gradient boosting with the optimal hyper-parameters was the best machine learning method with the highest accuracy in the address matching process, and the accuracy of extreme gradient boosting outperformed similarity metrics when using training data or input data. The address matching process using machine learning achieved high accuracy and can be applied to any geocoding systems to precisely convert addresses into geographic coordinates for various research and applications, including car navigation.
C1 [Lee, Kangjae; Claridades, Alexis Richard C.; Lee, Jiyeong] Univ Seoul, Dept Geoinformat, 163 Seoulsiripdae Ro, Seoul 02504, South Korea.
   [Claridades, Alexis Richard C.] Univ Philippines Diliman, Dept Geodet Engn, Quezon City 1101, Philippines.
RP Lee, J (corresponding author), Univ Seoul, Dept Geoinformat, 163 Seoulsiripdae Ro, Seoul 02504, South Korea.
EM kkooring@uos.ac.kr; uosgrad2019012@uos.ac.kr; jlee@uos.ac.kr
RI Claridades, Alexis Richard/AAZ-2483-2021
OI Claridades, Alexis Richard/0000-0001-9826-4271; Lee,
   Jiyeong/0000-0001-8229-1267; Lee, Kangjae/0000-0002-2857-6496
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2017R1D1A1B03028890]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (No. 2017R1D1A1B03028890).
NR 49
TC 4
Z9 4
U1 3
U2 10
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD AUG
PY 2020
VL 10
IS 16
AR 5628
DI 10.3390/app10165628
PG 21
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Chemistry; Engineering; Materials Science; Physics
GA NH4YJ
UT WOS:000564677100001
OA gold
DA 2022-04-17
ER

PT C
AU Painter, C
   Bastian, ND
AF Painter, Christopher
   Bastian, Nathaniel D.
BE Pham, T
   Solomon, L
TI Generating genetic engineering linked indicator datasets for machine
   learning classifier training in biosecurity
SO ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING FOR MULTI-DOMAIN OPERATIONS
   APPLICATIONS III
SE Proceedings of SPIE
LA English
DT Proceedings Paper
CT Conference on Artificial Intelligence and Machine Learning for
   Multi-Domain Operations Applications III
CY APR 12-16, 2021
CL ELECTR NETWORK
SP SPIE
DE Biosecurity; data generation; genetic engineering; BLAST;
   bioinformatics; machine learning
AB As methods and access to gene synthesis and genetic engineering have become more advanced, the fear that malicious viruses and bacteria will be designed with the express intention of causing harm to humans has received increased attention. In the event that such biological weapons are deployed, the security community needs tools to rapidly recognize the threat and identify responsible parties. Therefore, a key question is whether or not a biological threat is manmade. Currently, experts are capable of qualitatively assessing whether specific genetic sequences are natural or man-made, but few objective criteria exist for characterizing the degree to which a sequence has been engineered. Additionally, progress has recently been made on the task of attributing an engineered gene sequence to a lab-of-origin using machine learning. However, the task of analyzing naturally occurring genetic sequences so as to automatically detect outliers that may have been genetically engineered has received comparatively little attention. This work proposes a method for generating a dataset of natural and engineered sequences that can be used as an input for training machine learning classifiers to perform automatic detection of human engineering in gene sequence data.
C1 [Painter, Christopher] US Dept Def, Natl Secur Innovat Network, Washington, DC 20305 USA.
   [Bastian, Nathaniel D.] US Mil Acad, Army Cyber Inst, West Point, NY 10996 USA.
   [Painter, Christopher; Bastian, Nathaniel D.] US Dept Def, Joint Artificial Intelligence Ctr, Washington, DC 20305 USA.
RP Painter, C (corresponding author), US Dept Def, Natl Secur Innovat Network, Washington, DC 20305 USA.; Painter, C (corresponding author), US Dept Def, Joint Artificial Intelligence Ctr, Washington, DC 20305 USA.
NR 17
TC 0
Z9 0
U1 0
U2 0
PU SPIE-INT SOC OPTICAL ENGINEERING
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA
SN 0277-786X
EI 1996-756X
BN 978-1-5106-4330-7
J9 PROC SPIE
PY 2021
VL 11746
AR 1174624
DI 10.1117/12.2587844
PG 6
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA BS2PQ
UT WOS:000705912400049
DA 2022-04-17
ER

PT J
AU Bamisile, O
   Oluwasanmi, A
   Ejiyi, C
   Yimen, N
   Obiora, S
   Huang, Q
AF Bamisile, Olusola
   Oluwasanmi, Ariyo
   Ejiyi, Chukwuebuka
   Yimen, Nasser
   Obiora, Sandra
   Huang, Qi
TI Comparison of machine learning and deep learning algorithms for hourly
   global/diffuse solar radiation predictions
SO INTERNATIONAL JOURNAL OF ENERGY RESEARCH
LA English
DT Article; Early Access
DE deep learning; machine learning; prediction; renewable energy; solar
   radiation
AB Due to the advancement and wide adoption/application of solar-based technologies, the prediction of solar irradiance has attracted research attention in recent years. In this study, the predictive performance of machine learning models is compared with that of deep learning models for both global solar radiation (GSR) and diffuse solar radiation (DSR) prediction. Different studies have proposed the use of different models for solar radiation prediction. While some used machine learning models, the use of deep learning algorithms were considered by others. Although these algorithms were concluded to be appropriate for solar radiation prediction, variation in their performances brings about an intriguing quest to compare and determine the most appropriate algorithm. The three most common deep learning models in the literature namely; artificial neural network, convolutional neural network, and recurrent neural network (RNN) are considered within the scope of this study. Also, two traditional machine learning models namely polynomial regression and support vector regression (SVR) is considered as well as an ensemble machine learning model called random forest. These models have been applied to four different locations in Nigeria and the typical meteorological year data for 12 years in an hourly time step was used to train/test the model developed. Results from this study show that deep learning models have a better GSR and DSR prediction accuracy in comparison to machine learning models. However, the duration for training and testing the machine learning models (except SVR) is shorter than that of deep learning models making it more desirable for low computational applications. The application of RNN for GSR prediction in Yobe (with an r value of 0.9546 and root means square error/mean absolute error of 82.22 W/m(2)/36.52 W/m(2)) had the overall best model performance of all the models developed in this study. This study contributes to the existing literature in this field as it highlights the disparities between machine learning and deep learning algorithms application for solar radiation forecast.
C1 [Bamisile, Olusola; Huang, Qi] Univ Elect Sci & Technol China, Sch Mech & Elect Engn, Chengdu, Sichuan, Peoples R China.
   [Oluwasanmi, Ariyo; Ejiyi, Chukwuebuka] Univ Elect Sci & Technol China, Sch Software Engn, Chengdu, Peoples R China.
   [Yimen, Nasser] Univ Yaounde I, Natl Adv Sch Engn, Yaounde, Cameroon.
   [Obiora, Sandra] Univ Elect Sci & Technol China, Sch Management & Econ, Chengdu, Peoples R China.
   [Huang, Qi] Chengdu Univ Technol, Coll Nucl Technol & Automat Engn, Chengdu, Peoples R China.
RP Huang, Q (corresponding author), Univ Elect Sci & Technol China, Sch Mech & Elect Engn, Chengdu, Sichuan, Peoples R China.
EM hwong@uestc.edu.cn
RI Yimen, Nasser/AAG-5749-2022; Oluwasanmi, Ariyo/ABD-9254-2021
OI Oluwasanmi, Ariyo/0000-0001-9853-9554; Bamisile,
   Olusola/0000-0002-5154-6404; Yimen, Nasser/0000-0002-4630-3424; Ejiyi,
   Chukwuebuka Joseph/0000-0001-9139-7223
FU Sichuan Youth Science and Technology Innovation Team Fund [2017TD0009]
FX Sichuan Youth Science and Technology Innovation Team Fund, Grant/Award
   Number: 2017TD0009
NR 66
TC 6
Z9 6
U1 11
U2 30
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0363-907X
EI 1099-114X
J9 INT J ENERG RES
JI Int. J. Energy Res.
DI 10.1002/er.6529
EA FEB 2021
PG 22
WC Energy & Fuels; Nuclear Science & Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Energy & Fuels; Nuclear Science & Technology
GA QH6BJ
UT WOS:000618359200001
DA 2022-04-17
ER

PT J
AU Kharb, SS
   Antil, P
   Singh, S
   Antil, SK
   Sihag, P
   Kumar, A
AF Kharb, Sandeep Singh
   Antil, Parvesh
   Singh, Sarbjit
   Antil, Sundeep Kumar
   Sihag, Parveen
   Kumar, Anil
TI Machine Learning-Based Erosion Behavior of Silicon Carbide Reinforced
   Polymer Composites
SO SILICON
LA English
DT Article
DE Erosion; Polymer composites; Machine learning; Multi linear regression;
   Support vector machine; Silicon carbide
ID SUPPORT VECTOR MACHINE; SOLID PARTICLE EROSION; WEAR BEHAVIOR; TOOL
   WEAR; REGRESSION; EPOXY
AB The machine learning methodology is gaining immense exposure as a potential methodology for solving and modelling the machining behaviour of advanced materials. The present paper deals with the application of machining learning approach in analyzing and predicting the effect of reinforced silicon carbide (SiC) particle size on the erosion behaviour of silicon carbide reinforced polymer composites. L(27)orthogonal array was designed based on Taguchi's methodology to execute the experiments. Support vector machine (SVM) and multi-linear regression (MLR) approach were coupled with Taguchi's methodology to validate obtained optimized response characteristics. These machine learning-based SVM and MLR models are adopted to analyze the absurdity among obtained experimental results and predicted response. Out of 27 experimental runs based on experimental design, 19 experimental runs were selected for training models whereas 08 models were selected for the testing phase. Impingement angle, workpiece reinforcement, standoff distance and slurry pressure were used as input process parameters, whereas material loss was observed as response characteristics. The kernel functions, i.e. Pearson VII based universal kernel (PUK) and radial based function (RBF) kernel were used with machine learning models to obtain the best performing machine learning approach in predicting erosion behaviour of polymer composites.
C1 [Kharb, Sandeep Singh; Singh, Sarbjit] Punjab Engn Coll, Chandigarh 160012, India.
   [Antil, Parvesh; Antil, Sundeep Kumar; Kumar, Anil] CCS HAU Hisar, Coll Agr Engn & Technol, Hisar 125004, Haryana, India.
   [Sihag, Parveen] Natl Inst Technol, Kurukshetra 136119, Haryana, India.
   [Sihag, Parveen] Shoolini Univ, Solan 173229, Himachal Prades, India.
RP Antil, P (corresponding author), CCS HAU Hisar, Coll Agr Engn & Technol, Hisar 125004, Haryana, India.
EM parveshantil.pec@gmail.com
OI Singh, Sarbjit/0000-0003-4773-0791
NR 30
TC 5
Z9 5
U1 14
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1876-990X
EI 1876-9918
J9 SILICON-NETH
JI Silicon
PD APR
PY 2021
VL 13
IS 4
BP 1113
EP 1119
DI 10.1007/s12633-020-00497-z
EA MAY 2020
PG 7
WC Chemistry, Physical; Materials Science, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Materials Science
GA RJ3OH
UT WOS:000558839200002
DA 2022-04-17
ER

PT J
AU Ren, ZA
   Chen, YP
   Liu, JY
   Ding, HJ
   Wang, Q
AF Ren, Zi-Ang
   Chen, Yi-Peng
   Liu, Jing-Yang
   Ding, Hua-Jian
   Wang, Qin
TI Implementation of Machine Learning in Quantum Key Distributions
SO IEEE COMMUNICATIONS LETTERS
LA English
DT Article
DE Protocols; Training; Machine learning; Machine learning algorithms;
   Radio frequency; Security; Random forests; Quantum key distribution;
   machine learning; random forest; protocol selecting
AB In the future massive applications of quantum communication network, it is crucial to realize real-time selection of the optimal quantum key distributions (QKD) protocol for the improvement of system security and optimizing resources configuration. In principle, this can be done by utilizing algorithms such as exhaustive traversal or local search algorithm, whose time cost, however, is unbearable. Here we for the first time propose to employ machine learning methods into the selecting of optimal QKD protocol and apply random forest (RF) as an example for illustration. With the help of the easy-to-train classifier of RF, we can achieve a highly efficient optimal QKD protocols selector. Besides, we also do comparisons among RF and other machine learning methods, e.g., supporting vector machine, K-nearest neighbors algorithm, multinomial naive bayes classifier, and convolutional neural networks. Results demonstrate that, besides its advantage in efficiency, the RF classifier also excels both in preciseness and robustness with an accuracy over 98% for the testing set and an enjoyable receiver operating characteristic.
C1 [Ren, Zi-Ang; Chen, Yi-Peng; Liu, Jing-Yang; Ding, Hua-Jian; Wang, Qin] Nanjing Univ Posts & Telecommun, Broadband Wireless Commun & Sensor Network Techno, Telecommun & Networks Natl Engn Res Ctr, Minist Educ,Inst Quantum Informat & Technol, Nanjing 210003, Peoples R China.
RP Wang, Q (corresponding author), Nanjing Univ Posts & Telecommun, Broadband Wireless Commun & Sensor Network Techno, Telecommun & Networks Natl Engn Res Ctr, Minist Educ,Inst Quantum Informat & Technol, Nanjing 210003, Peoples R China.
EM qinw@njupt.edu.cn
FU National Key R&D Program of China [2018YFA0306400, 2017YFA0304100];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [12074194, 11774180, 61590932]; Top-notch
   Academic Programs Project of Jiangsu Higher Education Institutions;
   Leading-edge technology Program of Jiangsu Natural Science Foundation
   [BK20192001]; Science and Technology Innovation Training Program of
   Nanjing University of Posts and Telecommunications [SYB2020007]
FX This work is supported by the National Key R&D Program of China (Grants
   Nos. 2018YFA0306400, 2017YFA0304100), the National Natural Science
   Foundation of China (Grants Nos. 12074194, 11774180, 61590932),
   Top-notch Academic Programs Project of Jiangsu Higher Education
   Institutions, the Leading-edge technology Program of Jiangsu Natural
   Science Foundation (BK20192001), and Science and Technology Innovation
   Training Program of Nanjing University of Posts and Telecommunications
   (SYB2020007).
NR 36
TC 1
Z9 1
U1 9
U2 21
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1089-7798
EI 1558-2558
J9 IEEE COMMUN LETT
JI IEEE Commun. Lett.
PD MAR
PY 2021
VL 25
IS 3
BP 940
EP 944
DI 10.1109/LCOMM.2020.3040212
PG 5
WC Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Telecommunications
GA QW8QA
UT WOS:000628911700056
DA 2022-04-17
ER

PT C
AU Bagiroz, B
   Doruk, E
   Yildiz, O
AF Bagiroz, Beyza
   Doruk, Emre
   Yildiz, Oktay
GP IEEE
TI Machine Learning In Bioinformatics: Gene Expression And Microarray
   Studies
SO 2020 MEDICAL TECHNOLOGIES CONGRESS (TIPTEKNO)
LA English
DT Proceedings Paper
CT 2020 Medical Technologies Congress (TIPTEKNO)
CY NOV 19-20, 2020
CL ELECTR NETWORK
SP Biyomedikal ve Klinik Muhendisligi Dernegi, Izmir Ekonomi Univ, Izmir Katip Celebi Univ
DE machine learning; bioinformatics; gene expression; microarray
ID FEATURE-SELECTION; CANCER CLASSIFICATION; ALGORITHM
AB Machine learning methods used in the field of bioinformatics are a frequently used solution method in diagnosing, treating and investigating the underlying causes of diseases. In addition, it is an important field of study that allows for the ease of processing, the provision of computational power and the diversity of computational tools specific to the subject, especially in processes that require processing on gene expression and microarray data sets. In this study, an introduction has been made on the use of machine learning methods in the field of bioinformatics gene expression, and the use of machine learning methods has been exemplified by recent studies.
C1 [Bagiroz, Beyza; Doruk, Emre; Yildiz, Oktay] Gazi Univ, Comp Engn, Ankara, Turkey.
RP Bagiroz, B (corresponding author), Gazi Univ, Comp Engn, Ankara, Turkey.
EM beyzabagirozz@gmail.com; emredoruk@gazi.edu.tr; oyildiz@gazi.edu.tr
RI YILDIZ, OKTAY/AAD-6846-2020
OI YILDIZ, OKTAY/0000-0001-9155-7426; Doruk, Emre/0000-0001-8753-9698
NR 39
TC 1
Z9 1
U1 2
U2 2
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-8073-1
PY 2020
PG 4
WC Computer Science, Artificial Intelligence; Engineering, Biomedical
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BR6BI
UT WOS:000659419900105
DA 2022-04-17
ER

PT J
AU Zhang, YQ
   Yang, LJ
   He, QL
   Chen, L
AF Zhang, Ye-Qi
   Yang, Li-Juan
   He, Qi-Liang
   Chen, Liang
TI Machine learning on quantifying quantum steerability
SO QUANTUM INFORMATION PROCESSING
LA English
DT Article
DE Quantum steerability; Quantum correlations; Machine Learning; Artificial
   neural network
AB We apply the artificial neural network to quantify two-qubit steerability based on the steerable weight, which can be computed through semidefinite programming. Due to the fact that the optimal measurement strategy is unknown, it is still very difficult and time-consuming to efficiently obtain the steerability for an arbitrary quantum state. In this work, we show the method via machine learning technique which provides an effective way to quantify steerability. Furthermore, the generalization ability of the trained model is also demonstrated by applying to the Werner state and that in dephasing noise channel. Our findings provide an new way to obtain steerability efficiently and accurately, revealing effective application of the machine learning method on exploring quantum steering.
C1 [Zhang, Ye-Qi; Yang, Li-Juan; Chen, Liang] North China Elect Power Univ, Dept Math & Phys, Beijing 102206, Peoples R China.
   [He, Qi-Liang] Guizhou Normal Univ, Sch Phys & Elect, Guiyang 550001, Peoples R China.
RP Zhang, YQ (corresponding author), North China Elect Power Univ, Dept Math & Phys, Beijing 102206, Peoples R China.
EM yqzhang@ncepu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [11805065, 11504106]; Natural Science and
   Technology Foundation of Guizhou Province; Key laboratory of low
   dimensional condensed matter physics of higher educational institution
   of Guizhou province [[2016]002]; Fundamental Research Funds for the
   Central UniversitiesFundamental Research Funds for the Central
   Universities [2018072]
FX This work was supported by the National Natural Science Foundation of
   China under Grant Nos. 11805065 and 11504106, the Natural Science and
   Technology Foundation of Guizhou Province under Grant No. [2017]7343,
   the Key laboratory of low dimensional condensed matter physics of higher
   educational institution of Guizhou province (Grant No.[2016]002) and
   also by the Fundamental Research Funds for the Central Universities
   (Grant No. 2018072).
NR 33
TC 2
Z9 2
U1 5
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1570-0755
EI 1573-1332
J9 QUANTUM INF PROCESS
JI Quantum Inf. Process.
PD JUL 25
PY 2020
VL 19
IS 8
AR 263
DI 10.1007/s11128-020-02769-4
PG 13
WC Quantum Science & Technology; Physics, Multidisciplinary; Physics,
   Mathematical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Physics
GA MU8XE
UT WOS:000555949500002
DA 2022-04-17
ER

PT C
AU Chen, YT
   Chuang, YC
   Wu, AY
AF Chen, Yi-Ta
   Chuang, Yu-Chuan
   Wu, An-Yeu
GP IEEE
TI Online Extreme Learning Machine Design for the Application of Federated
   Learning
SO 2020 2ND IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE
   CIRCUITS AND SYSTEMS (AICAS 2020)
LA English
DT Proceedings Paper
CT 2nd IEEE International Conference on Artificial Intelligence Circuits
   and Systems (AICAS)
CY AUG 31-SEP 04, 2020
CL ELECTR NETWORK
SP IEEE, Inst Italiano Tecnologia, Univ Zurich, IEEE CAS, Cadence, Bosch, IBM Res, Arm, Huawei
DE Federated learning; online sequential extreme learning machine
AB In this paper, we propose a federated extreme learning machine system (Fed-ELMS) to meet the demand for federated learning scenarios. In the scenario of federated learning, data is kept on edge devices to preserve the privacy of data, while metadata, such as model parameters, are exchanged between a centralized cloud server and edge devices. Despite non-independent and identically distributed (non-IID) and imbalanced data across edge devices, we show that Fed-ELMS can still achieve comparable performance with only 3.3% accuracy loss compared to a centralized ELM trained with IID and balanced data. (a) Moreover, by quantizing input weights and biases, parameters of a model and transmission power consumption between cloud and edge are dramatically reduced. Compared With conventional neural networks (NNs) with the same transmission cost, the proposed Fed-ELMS outperforms FederatedAveraging NN (Fed- NN) by 2.3% accuracy and the fine-tuning process is 7%-33% less time-consuming. Therefore, the proposed Fed-ELMS is a promising system for edge devices to support the future trend of federated learning.
C1 [Chen, Yi-Ta; Chuang, Yu-Chuan; Wu, An-Yeu] Natl Taiwan Univ, Grad Inst Elect Engn, Taipei, Taiwan.
RP Chen, YT (corresponding author), Natl Taiwan Univ, Grad Inst Elect Engn, Taipei, Taiwan.
EM edan@access.ee.ntu.edu.tw; frankchuang@access.ee.ntu.edu.tw;
   andywu@ntu.edu.tw
FU Ministry of Science and Technology of TaiwanMinistry of Science and
   Technology, Taiwan [MOST 108-2633-E-002-001, MOST
   106-2221-E-002-205-MY3]; National Taiwan UniversityNational Taiwan
   University [NTU-108L104039]
FX This research was supported in part by the Ministry of Science and
   Technology of Taiwan (MOST 108-2633-E-002-001, MOST
   106-2221-E-002-205-MY3), National Taiwan University(NTU-108L104039).
NR 10
TC 3
Z9 3
U1 1
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-4922-6
PY 2020
BP 188
EP 192
PG 5
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BS4LZ
UT WOS:000720328700044
DA 2022-04-17
ER

PT J
AU Szielasko, K
   Wolter, B
   Tschuncky, R
   Youssef, S
AF Szielasko, Klaus
   Wolter, Bernd
   Tschuncky, Ralf
   Youssef, Sargon
TI Micromagnetic materials characterization using machine learning
SO TM-TECHNISCHES MESSEN
LA English
DT Article
DE Micromagnetic; materials characterization; mechanical properties; 3MA;
   machine learning
AB Micromagnetic materials characterization is a nondestructive means of predicting mechanical properties and stress of steel and iron products. The method is based on the circumstance that both mechanical and magnetic behaviour relate to microstructure over similar interaction mechanisms, which leads to characteristic correlations between mechanical and magnetic properties of ferromagnetic materials. The prediction of mechanical properties or stress from micromagnetic parameters represents an inverse problem commonly addressed by regression and classification approaches. Challenges for the industrial application of micromagnetic methods lie in the development of robust sensors, definition of significant features, and implementation of powerful machine learning algorithms for a reliable quantitative target value prediction by processing of the micromagnetic features. This contribution briefly explains the background of micromagnetics, describes the typical challenges experienced in practice and provides insight into latest progress in the application of machine learning to micromagnetic data.
C1 [Szielasko, Klaus; Wolter, Bernd; Tschuncky, Ralf; Youssef, Sargon] Fraunhofer Inst Zerstorungsfreie Prufverfahren, D-66123 Saarbrucken, Germany.
RP Szielasko, K (corresponding author), Fraunhofer Inst Zerstorungsfreie Prufverfahren, D-66123 Saarbrucken, Germany.
EM klaus.szielasko@izfp.fraunhofer.de; bernd.wolter@izfp.fraunofer.de;
   ralf.tschuncky@izfp.fraunhofer.de; sargon.youssef@izfp.fraunhofer.de
NR 13
TC 5
Z9 5
U1 8
U2 17
PU WALTER DE GRUYTER GMBH
PI BERLIN
PA GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY
SN 0171-8096
J9 TM-TECH MESS
JI tm-Tech. Mess.
PD JUN
PY 2020
VL 87
IS 6
BP 428
EP 437
DI 10.1515/teme-2019-0099
PG 10
WC Instruments & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Instruments & Instrumentation
GA LS2XE
UT WOS:000536251400006
DA 2022-04-17
ER

PT J
AU Islam, N
   Farhin, F
   Sultana, I
   Kaiser, MS
   Rahman, MS
   Mahmud, M
   Hosen, ASMS
   Cho, GH
AF Islam, Nahida
   Farhin, Fahiba
   Sultana, Ishrat
   Kaiser, M. Shamim
   Rahman, Md. Sazzadur
   Mahmud, Mufti
   Hosen, A. S. M. Sanwar
   Cho, Gi Hwan
TI Towards Machine Learning Based Intrusion Detection in IoT Networks
SO CMC-COMPUTERS MATERIALS & CONTINUA
LA English
DT Article
DE IoT; shallow machine learning; deep learning; data science; IDS
ID INTERNET
AB The Internet of Things (IoT) integrates billions of self-organized and heterogeneous smart nodes that communicate with each other without human intervention. In recent years, IoT based systems have been used in improving the experience in many applications including healthcare, agriculture, supply chain, education, transportation and traffic monitoring, utility services etc. However, node heterogeneity raised security concern which is one of the most complicated issues on the IoT. Implementing security measures, including encryption, access control, and authentication for the IoT devices are ineffective in achieving security. In this paper, we identified various types of IoT threats and shallow (such as decision tree (DT), random forest (RF), support vector machine (SVM)) as well as deep machine learning (deep neural network (DNN), deep belief network (DBN), long short-term memory (LSTM), stacked LSTM, bidirectional LSTM (Bi-LSTM)) based intrusion detection systems (IDS) in the IoT environment have been discussed. The performance of these models has been evaluated using five benchmark datasets such as NSL-KDD, IoTDevNet, DS2OS, IoTID20, and IoT Botnet dataset. The various performance metrics such as Accuracy, Precision, Recall, F1-score were used to evaluate the performance of shallow/deep machine learning based IDS. It has been found that deep machine learning IDS outperforms shallow machine learning in detecting IoT attacks.
C1 [Islam, Nahida; Farhin, Fahiba; Sultana, Ishrat; Kaiser, M. Shamim; Rahman, Md. Sazzadur] Jahangirnagar Univ, Inst Informat Technol, Dhaka, Bangladesh.
   [Mahmud, Mufti] Nottingham Trent Univ, Dept Comp Sci, Nottingham, England.
   [Hosen, A. S. M. Sanwar; Cho, Gi Hwan] Jeonbuk Natl Univ, Div Comp Sci & Engn, Jeonju 54896, South Korea.
RP Cho, GH (corresponding author), Jeonbuk Natl Univ, Div Comp Sci & Engn, Jeonju 54896, South Korea.
EM ghcho@jbnu.ac.kr
RI Mahmud/C-7752-2012
OI Mahmud/0000-0002-2037-8348; Farhin, Fahiba/0000-0002-5106-3461
NR 50
TC 7
Z9 7
U1 12
U2 15
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1546-2218
EI 1546-2226
J9 CMC-COMPUT MATER CON
JI CMC-Comput. Mat. Contin.
PY 2021
VL 69
IS 2
BP 1801
EP 1821
DI 10.32604/cmc.2021.018466
PG 21
WC Computer Science, Information Systems; Materials Science,
   Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Materials Science
GA TP5MB
UT WOS:000677642400021
OA gold
DA 2022-04-17
ER

PT J
AU Zakir, AQ
   Singhal, A
   Singh, G
   Pandey, P
   Sankaranarayanan, S
AF Zakir, Abdul Qadir
   Singhal, Anushka
   Singh, Gurkirat
   Pandey, Pracheesh
   Sankaranarayanan, Suresh
TI Soil utilisation prediction for farmers using machine learning
SO INTERNATIONAL JOURNAL OF SUSTAINABLE AGRICULTURAL MANAGEMENT AND
   INFORMATICS
LA English
DT Article
DE soil sample; soil analysis; soil utility; machine learning; deep
   learning
AB Soil is necessary for the growth of the plant and there is a need to know the plant that can be grown. Methods are used for soil analysis by taking soil samples in the lab. Soil indicators analyse the soil remotely from the field. The literature review indicates that no work has been done using machine learning for analysing the soil features for soil utility prediction. We have done an in-depth soil utility analysis by employing deep learning and comparing it with other machine learning models for soil utility prediction resulting in the best prediction model.
C1 [Zakir, Abdul Qadir; Singhal, Anushka; Singh, Gurkirat; Pandey, Pracheesh; Sankaranarayanan, Suresh] SRM Inst Sci & Technol, Dept Informat Technol, Chennai, Tamil Nadu, India.
RP Sankaranarayanan, S (corresponding author), SRM Inst Sci & Technol, Dept Informat Technol, Chennai, Tamil Nadu, India.
EM abdulqadirzakir@gmail.com; anushkasinghal98@gmail.com;
   gurkirat09@gmail.com; pracheeshpandey010@gmail.com;
   sureshs3@srmist.edu.in
NR 23
TC 0
Z9 0
U1 2
U2 2
PU INDERSCIENCE ENTERPRISES LTD
PI GENEVA
PA WORLD TRADE CENTER BLDG, 29 ROUTE DE PRE-BOIS, CASE POSTALE 856, CH-1215
   GENEVA, SWITZERLAND
SN 2054-5819
EI 2054-5827
J9 INT J SUST AGR MANAG
JI Int. J. Sustain. Agric. Manage. Inform.
PY 2021
VL 7
IS 1
BP 67
EP 75
PG 9
WC Agriculture, Multidisciplinary; Computer Science, Interdisciplinary
   Applications; Green & Sustainable Science & Technology
WE Emerging Sources Citation Index (ESCI)
SC Agriculture; Computer Science; Science & Technology - Other Topics
GA WL7CY
UT WOS:000710560400005
DA 2022-04-17
ER

PT C
AU Hamidi, YK
   Berrado, A
   Altan, MC
AF Hamidi, Youssef K.
   Berrado, Abdelaziz
   Altan, M. Cengiz
BA Erinc, GU
BF Erinc, GU
BE Cebeci, FC
   Menceloglu, YZ
   Unal, S
   Ulcer, Y
TI Machine Learning Applications in Polymer Composites
SO PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE OF THE POLYMER
   PROCESSING SOCIETY (PPS-35)
SE AIP Conference Proceedings
LA English
DT Proceedings Paper
CT 35th International Conference of the Polymer-Processing-Society (PPS)
CY MAY 26-30, 2019
CL TURKEY
SP Polymer Proc Soc, Sabanci Univ
DE Polymer Composites; Behavior Prediction; machine learning
ID MECHANICAL-PROPERTIES; MOISTURE ABSORPTION; ADHESION
AB The primary interest in numerous research problems in both polymer composites and Machine Learning (ML) is to develop predictive models for one or more variables of interest using relevant independent variables, or inputs. However, these two fields have often adopted different approaches, where modeling of composite behavior is often based on physics-based models and phenomenological theories. These physical models are more precise and robust, but often suffer from restricted predictive capability since they are confined to a specific set of conditions. ML models, on the other hand, can be more efficient during the design phase as they allow managing massive and high dimensional data sets to extract the best lit or a predictive behavior for the application at hand.
   In this context, material scientists would benefit from understanding and implementing some of the powerful ML methods, in order to predict or characterize a behavior of interest of a polymer composite. In this paper, we present a general methodology aimed at employing supervised machine learning models for predicting the properties of polymer composites, including thermo-mechanical properties, environmental effects such as moisture saturation level, durability, or other important behavior, based on the composite constituents, manufacturing processes, relevant process parameters, and expected life-span of the composite product.
C1 [Hamidi, Youssef K.] Univ Houston Clear Lake, Coll Sci & Engn, Mech Engn Program, Houston, TX 77058 USA.
   [Berrado, Abdelaziz] Mohamed V Univ Rabat, AMIPS, Ecole Mohammadia Ingenieurs, Rabat, Morocco.
   [Altan, M. Cengiz] Univ Oklahoma, Sch Aerosp & Mech Engn, Norman, OK 73019 USA.
RP Hamidi, YK (corresponding author), Univ Houston Clear Lake, Coll Sci & Engn, Mech Engn Program, Houston, TX 77058 USA.
EM hamidi@ou.edu; berrado@emi.ac.ma; altan@ou.edu
NR 19
TC 0
Z9 0
U1 12
U2 19
PU AMER INST PHYSICS
PI MELVILLE
PA 2 HUNTINGTON QUADRANGLE, STE 1NO1, MELVILLE, NY 11747-4501 USA
SN 0094-243X
BN 978-0-7354-1956-8
J9 AIP CONF PROC
PY 2020
VL 2205
AR 020031
DI 10.1063/1.5142946
PG 5
WC Physics, Applied; Polymer Science
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Physics; Polymer Science
GA BP5CG
UT WOS:000555285800031
OA Bronze
DA 2022-04-17
ER

PT J
AU Daoud, MS
   Aftab, S
   Ahmad, M
   Khan, MA
   Iqbal, A
   Abbas, S
   Iqbal, M
   Ihnaini, B
AF Daoud, Mohammad Sh.
   Aftab, Shabib
   Ahmad, Munir
   Khan, Muhammad Adnan
   Iqbal, Ahmed
   Abbas, Sagheer
   Iqbal, Muhammad
   Ihnaini, Baha
TI Machine Learning Empowered Software Defect Prediction System
SO INTELLIGENT AUTOMATION AND SOFT COMPUTING
LA English
DT Article
DE Software defect prediction; machine learning; artificial neural network
ID ARTIFICIAL NEURAL-NETWORK; RAINFALL PREDICTION; OPTIMIZATION; SVM
AB Production of high-quality software at lower cost has always been the main concern of developers. However, due to exponential increases in size and complexity, the development of qualitative software with lower costs is almost impossible. This issue can be resolved by identifying defects at the early stages of the development lifecycle. As a significant amount of resources are consumed in testing activities, if only those software modules are shortlisted for testing that is identified as defective, then the overall cost of development can be reduced with the assurance of high quality. An artificial neural network is considered as one of the extensively used machine-learning techniques for predicting defect-prone software modules. In this paper, a cloud-based framework for real-time software defect prediction is presented. In the proposed framework, empirical analysis is performed to compare the performance of four training algorithms of the back propagation technique on software-defect prediction: Bayesian regularization (BR), Scaled Conjugate Gradient, Broyden-Fletcher-Goldfarb-Shanno Quasi Newton, and Levenberg-Marquardt algorithms. The proposed framework also includes a fuzzy layer to identify the best training function based on performance. Publicly available cleaned versions of NASA datasets are used in this study. Various measures are used for performance evaluation including specificity, precision, recall, F-measure, an area under the receiver operating characteristic curve, accuracy, R2, and mean-square error. Two graphical user interface tools are developed in MatLab software to implement the proposed framework. The first tool is developed for comparing training functions as well as for extracting the results; the second tool is developed for the selection of the best training function using fuzzy logic. A BR training algorithm is selected by the fuzzy layer as itoutperformed the others in most of the performance measures. The accuracy of the BR training function is also compared with other widely used machine -learning techniques, from which it was found that the BR performed better among all training functions.
C1 [Daoud, Mohammad Sh.] Al Ain Univ, Coll Engn, Abu Dhabi 112612, U Arab Emirates.
   [Aftab, Shabib; Ahmad, Munir; Abbas, Sagheer; Iqbal, Muhammad] Natl Coll Business Adm & Econ, Sch Comp Sci, Lahore 54000, Pakistan.
   [Aftab, Shabib; Iqbal, Ahmed] Virtual Univ Pakistan, Dept Comp Sci, Lahore 54000, Pakistan.
   [Khan, Muhammad Adnan] Riphah Int Univ, Fac Comp, Riphah Sch Comp & Innovat, Lahore Campus, Lahore 54000, Pakistan.
   [Khan, Muhammad Adnan] Gachon Univ, Dept Software, Pattern Recognit & Machine Learning Lab, Seongnam 13557, South Korea.
   [Ihnaini, Baha] Kean Univ, Sch Comp Sci, Union, NJ 07083 USA.
   [Ihnaini, Baha] Wenzhou Kean Univ, Coll Sci & Technol, Dept Comp Sci, Wenzhou 325060, Peoples R China.
RP Khan, MA (corresponding author), Riphah Int Univ, Fac Comp, Riphah Sch Comp & Innovat, Lahore Campus, Lahore 54000, Pakistan.; Khan, MA (corresponding author), Gachon Univ, Dept Software, Pattern Recognit & Machine Learning Lab, Seongnam 13557, South Korea.
EM adnan@gachon.ac.kr
RI Ahmad, Munir/F-7482-2018
OI Ahmad, Munir/0000-0002-5240-0984; Khan, Muhammad
   Adnan/0000-0003-4854-9935; Abbas, Dr. Sagheer/0000-0001-5289-7831;
   Aftab, Shabib/0000-0002-7662-1394
NR 37
TC 0
Z9 0
U1 12
U2 13
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1079-8587
EI 2326-005X
J9 INTELL AUTOM SOFT CO
JI Intell. Autom. Soft Comput.
PY 2022
VL 31
IS 2
BP 1287
EP 1300
DI 10.32604/iasc.2022.020362
PG 14
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA UY9BD
UT WOS:000701809700002
OA hybrid
DA 2022-04-17
ER

PT J
AU Zhang, M
   Wu, QQ
   Zheng, W
   Shang, YX
   Wang, YX
AF Zhang, Ming
   Wu, Qiqi
   Zheng, Wei
   Shang, Yangxing
   Wang, Yuxing
TI A database for developing machine learning based disruption predictors
SO FUSION ENGINEERING AND DESIGN
LA English
DT Article; Proceedings Paper
CT 12th IAEA Technical Meeting on Control, Data Acquisition, and Remote
   Participation for Fusion Research (TM CODAC)
CY MAY 13-17, 2019
CL Daejeon, SOUTH KOREA
SP IAEA
DE Database; Disruption prediction; Machine learning; MongoDB
AB Machine learning based disruption prediction methods have exhibited good prediction performance with higher success rate, lower false alarm rate and earlier warning time than physical based methods. One important thing pushed recent advances in machine learning field is high-quality training data. So a database with rich set of accurate disruption related information is crucial to the development of a high performance disruption predictor. In order to develop machine learning based disruption predictors fast and iteratively on J-TEXT, a database dedicated for machine learning disruption prediction has been built. This database provides not only disruption related labels, interfaces for querying the data based on user proved filter and auto generation of training and test data, but also interface for benchmark the predictors. Its modular design allows us to plug-in various shot analysis modules which process diagnostic signals and generate different labels automatically. These modules can be scheduled and run parallel on a cluster which will speed up the shot analysis process. The generated labels are inserted into a MongoDB NoSQL database for later querying. But one major hurdle for machine learning disruption prediction is they perform un-acceptably poor on devices other than they are trained on. It requires data from many different tokamaks to possibly develop a cross machine predictor, so this database also has a data import module which reads diagnostic data from different data sources such as MDSplus and store them as HDF5 files with unified data structure on a parallel file system. It is easy to import data from different machines and provide a unified data access interface.
C1 [Zhang, Ming; Wu, Qiqi; Zheng, Wei; Wang, Yuxing] Huazhong Univ Sci & Technol, Sch Elect & Elect Engn, Int Joint Res Lab Magnet Confinement Fus & Plasma, State Key Lab Adv Electromagnet Engn & Technol, Wuhan 430074, Peoples R China.
   [Shang, Yangxing] Huazhong Univ Sci & Technol, Sch Elect & Elect Engn, Wuhan 430074, Peoples R China.
RP Zheng, W (corresponding author), Huazhong Univ Sci & Technol, Sch Elect & Elect Engn, Int Joint Res Lab Magnet Confinement Fus & Plasma, State Key Lab Adv Electromagnet Engn & Technol, Wuhan 430074, Peoples R China.
EM zhengwei@hust.edu.cn
FU National Magnetic Confinement Fusion Science Program [2015GB111002];
   National Key R&D Program of China [2017YFE0301202, 2017YFE0301803];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [11605068, 11775089, 51821005]
FX The authors are very grateful for the help of J-TEXT team. This work is
   supported by the National Magnetic Confinement Fusion Science Program
   (No. 2015GB111002), by the National Key R&D Program of China (Nos.
   2017YFE0301202, 2017YFE0301803) and the National Natural Science
   Foundation of China (Nos. 11605068, 11775089 and 51821005).
NR 12
TC 1
Z9 1
U1 2
U2 5
PU ELSEVIER SCIENCE SA
PI LAUSANNE
PA PO BOX 564, 1001 LAUSANNE, SWITZERLAND
SN 0920-3796
EI 1873-7196
J9 FUSION ENG DES
JI Fusion Eng. Des.
PD NOV
PY 2020
VL 160
AR 111981
DI 10.1016/j.fusengdes.2020.111981
PG 4
WC Nuclear Science & Technology
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Nuclear Science & Technology
GA OP5RH
UT WOS:000588143300072
DA 2022-04-17
ER

PT C
AU Hagos, DH
   Loland, M
   Yazidi, A
   Kure, O
   Engelstad, PE
AF Hagos, Desta Haileselassie
   Loland, Martin
   Yazidi, Anis
   Kure, Oivind
   Engelstad, Paal E.
GP IEEE
TI Advanced Passive Operating System Fingerprinting Using Machine Learning
   and Deep Learning
SO 2020 29TH INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATIONS AND
   NETWORKS (ICCCN 2020)
SE IEEE International Conference on Computer Communications and Networks
LA English
DT Proceedings Paper
CT 29th International Conference on Computer Communications and Networks
   (ICCCN)
CY AUG 03-06, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Commun Soc
DE Operating System; Fingerprinting; Machine Learning; Deep Learning;
   Passive Measurements
AB Securing and managing large, complex enterprise network infrastructure requires capturing and analyzing network traffic traces in real-time. An accurate passive Operating System (OS) fingerprinting plays a critical role in effective network management and cybersecurity protection. Passive fingerprinting doesn't send probes that introduce extra load to the network and hence it has a clear advantage over active fingerprinting since it also reduces the risk of triggering false alarms. This paper proposes and evaluates an advanced classification approach to passive OS fingerprinting by leveraging state-of-the-art classical machine learning and deep learning techniques. Our controlled experiments on benchmark data, emulated and realistic traffic is performed using two approaches. Through an Oracle-based machine learning approach, we found that the underlying TCP variant is an important feature for predicting the remote OS. Based on this observation, we develop a sophisticated tool for OS fingerprinting that first predicts the TCP flavor using passive traffic traces and then uses this prediction as an input feature for another machine learning algorithm for predicting the remote OS from passive measurements. This paper takes the passive fingerprinting problem one step further by introducing the underlying predicted TCP variant as a distinguishing feature. In terms of accuracy, we empirically demonstrate that accurately predicting the TCP variant has the potential to boost the evaluation performance from 84% to 94% on average across all our validation scenarios and across different types of traffic sources. We also demonstrate a practical example of this potential, by increasing the performance to 91.3% on average using a tool for TCP variant prediction in an emulated setting. To the best of our knowledge, this is the first study that explores the potential for using the knowledge of the TCP variant to significantly boost the accuracy of passive OS fingerprinting.
C1 [Hagos, Desta Haileselassie; Kure, Oivind; Engelstad, Paal E.] Univ Oslo, Dept Technol Syst, Kjeller, Norway.
   [Hagos, Desta Haileselassie; Loland, Martin; Yazidi, Anis; Engelstad, Paal E.] Oslo Metropolitan Univ, Dept Comp Sci, Oslo, Norway.
RP Hagos, DH (corresponding author), Univ Oslo, Dept Technol Syst, Kjeller, Norway.; Hagos, DH (corresponding author), Oslo Metropolitan Univ, Dept Comp Sci, Oslo, Norway.
EM destahh@ifi.uio.no; martin.loeland@gmail.com; anis.yazidi@oslomet.no;
   oivind.kure@its.uio.no; paal.engelstad@oslomet.no
NR 39
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1095-2055
BN 978-1-7281-6607-0
J9 IEEE IC COMP COM NET
PY 2020
PG 11
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Telecommunications
GA BR0BY
UT WOS:000627816700085
DA 2022-04-17
ER

PT J
AU Borch, C
AF Borch, Christian
TI Machine learning and social theory: Collective machine behaviour in
   algorithmic trading
SO EUROPEAN JOURNAL OF SOCIAL THEORY
LA English
DT Article; Early Access
DE Algorithmic trading; collective behaviour; embeddedness; interaction;
   machine learning
ID INTERACTION ORDER; FREQUENCY
AB This article examines what the rise in machine learning (ML) systems might mean for social theory. Focusing on financial markets, in which algorithmic securities trading founded on ML-based decision-making is gaining traction, I discuss the extent to which established sociological notions remain relevant or demand a reconsideration when applied to an ML context. I argue that ML systems have some capacity for agency and for engaging in forms of collective machine behaviour, in which ML systems interact with other machines. However, ML-based collective machine behaviour is irreducible to human decision-making and thereby challenges established sociological notions of financial markets (including that of embeddedness). I argue that such behaviour can nonetheless be analysed through an adaptation of sociological theories of interaction and collective behaviour.
C1 [Borch, Christian] Copenhagen Business Sch, Econ Sociol & Social Theory, Frederiksberg, Denmark.
RP Borch, C (corresponding author), Copenhagen Business Sch, Dept Management Polit & Philosophy, Porcelaenshaven 18A, DK-2000 Frederiksberg, Denmark.
EM cbo.mpp@cbs.dk
FU European Research Council (ERC) under the European Union's Horizon 2020
   research and innovation programmeEuropean Research Council (ERC)
   [725706]
FX The author disclosed receipt of the following financial support for the
   research, authorship, and/or publication of this article: This work was
   supported by the European Research Council (ERC) under the European
   Union's Horizon 2020 research and innovation programme (grant agreement
   No 725706).
NR 69
TC 1
Z9 1
U1 8
U2 8
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1368-4310
EI 1461-7137
J9 EUR J SOC THEORY
JI Eur. J. Soc. Theory
AR 13684310211056010
DI 10.1177/13684310211056010
EA NOV 2021
PG 18
WC Sociology
WE Social Science Citation Index (SSCI)
SC Sociology
GA WT4TC
UT WOS:000715857200001
DA 2022-04-17
ER

PT J
AU Hardy, L
   Lewis, AGM
AF Hardy, Lucien
   Lewis, Adam G. M.
TI Quantum computation with machine-learning-controlled quantum stuff
SO MACHINE LEARNING-SCIENCE AND TECHNOLOGY
LA English
DT Article
DE quantum computing; quantum machine learning; quantum tomography; quantum
   information theory; quantum foundations
AB We formulate the control over quantum matter, so as to perform arbitrary quantum computation, as an optimization problem. We then provide a schematic machine learning algorithm for its solution. Imagine a long strip of 'quantum stuff', endowed with certain assumed physical properties, and equipped with regularly spaced wires to provide input settings and to read off outcomes. After showing how the corresponding map from settings to outcomes can be construed as a quantum circuit, we provide a machine learning framework to tomographically 'learn' which settings implement the members of a universal gate set. To that end, we devise a loss function measuring how badly a proposed encoding has failed to implement a given circuit, and prove the existence of 'tomographically complete' circuit sets: should a given encoding minimize the loss function for each member of such a set, it also will for an arbitrary circuit. At optimum, arbitrary quantum gates, and thus arbitrary quantum programs, can be implemented using the stuff.
C1 [Hardy, Lucien; Lewis, Adam G. M.] Perimeter Inst Theoret Phys, 31 Caroline St North, Waterloo, ON N2L 2Y5, Canada.
RP Lewis, AGM (corresponding author), Perimeter Inst Theoret Phys, 31 Caroline St North, Waterloo, ON N2L 2Y5, Canada.
EM alewis@perimeterinstitute.ca
OI Lewis, Adam/0000-0002-0604-195X
FU Tensor Network Initiative at Perimeter Institute; Government of Canada
   through the Department of Innovation, Science and Economic Development
   Canada; Province of Ontario through the Ministry of Research, Innovation
   and ScienceMinistry of Research and Technology of the Republic of
   Indonesia (RISTEK)
FX A G M Lewis is supported by the Tensor Network Initiative at Perimeter
   Institute. Research at Perimeter Institute is supported by the
   Government of Canada through the Department of Innovation, Science and
   Economic Development Canada and by the Province of Ontario through the
   Ministry of Research, Innovation and Science.
NR 35
TC 0
Z9 0
U1 2
U2 3
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
EI 2632-2153
J9 MACH LEARN-SCI TECHN
JI Mach. Learn.-Sci. Technol.
PD MAR
PY 2021
VL 2
IS 1
AR 015008
DI 10.1088/2632-2153/abb215
PG 17
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Science & Technology - Other Topics
GA SQ6YW
UT WOS:000660500300013
OA gold, Green Submitted
DA 2022-04-17
ER

PT J
AU Hey, T
   Butler, K
   Jackson, S
   Thiyagalingam, J
AF Hey, Tony
   Butler, Keith
   Jackson, Sam
   Thiyagalingam, Jeyarajan
TI Machine learning and big scientific data
SO PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY A-MATHEMATICAL PHYSICAL
   AND ENGINEERING SCIENCES
LA English
DT Article
DE machine learning; materials science; atmospheric science; electron
   microscopy; image processing; AI benchmarks
ID CONVOLUTIONAL NEURAL-NETWORK; BAYESIAN CLOUD DETECTION; 2-DIMENSIONAL
   ANTIFERROMAGNETS; IMAGERY; VALIDATION; DESIGN
AB This paper reviews some of the challenges posed by the huge growth of experimental data generated by the new generation of large-scale experiments at UK national facilities at the Rutherford Appleton Laboratory (RAL) site at Harwell near Oxford. Such 'Big Scientific Data' comes from the Diamond Light Source and Electron Microscopy Facilities, the ISIS Neutron and Muon Facility and the UK's Central Laser Facility. Increasingly, scientists are now required to use advanced machine learning and other AI technologies both to automate parts of the data pipeline and to help find new scientific discoveries in the analysis of their data. For commercially important applications, such as object recognition, natural language processing and automatic translation, deep learning has made dramatic breakthroughs. Google's DeepMind has now used the deep learning technology to develop their AlphaFold tool to make predictions for protein folding. Remarkably, it has been able to achieve some spectacular results for this specific scientific problem. Can deep learning be similarly transformative for other scientific problems? After a brief review of some initial applications of machine learning at the RAL, we focus on challenges and opportunities for AI in advancing materials science. Finally, we discuss the importance of developing some realistic machine learning benchmarks using Big Scientific Data coming from several different scientific domains. We conclude with some initial examples of our 'scientific machine learning' benchmark suite and of the research challenges these benchmarks will enable. This article is part of a discussion meeting issue 'Numerical algorithms for high-performance computational science'.
C1 [Hey, Tony; Butler, Keith; Jackson, Sam; Thiyagalingam, Jeyarajan] Rutherford Appleton Lab, Sci & Technol Facil Council, Sci Comp Dept, Didcot OX11 0QX, Oxon, England.
RP Hey, T (corresponding author), Rutherford Appleton Lab, Sci & Technol Facil Council, Sci Comp Dept, Didcot OX11 0QX, Oxon, England.
EM tony.hey@stfc.ac.uk
RI Jackson, Samuel/S-9871-2019
OI Hey, Tony/0000-0001-6782-3691
FU Wave 1 of The UKRI Strategic Priorities Fund under the EPSRC GrantUK
   Research & Innovation (UKRI)Engineering & Physical Sciences Research
   Council (EPSRC) [EP/T001569/1]; Alan Turing Institute
FX This work was supported by Wave 1 of The UKRI Strategic Priorities Fund
   under the EPSRC Grant EP/T001569/1, particularly the 'AI for Science'
   theme within that grant and The Alan Turing Institute.
NR 77
TC 16
Z9 17
U1 14
U2 60
PU ROYAL SOC
PI LONDON
PA 6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND
SN 1364-503X
EI 1471-2962
J9 PHILOS T R SOC A
JI Philos. Trans. R. Soc. A-Math. Phys. Eng. Sci.
PD MAR 6
PY 2020
VL 378
IS 2166
SI SI
AR 20190054
DI 10.1098/rsta.2019.0054
PG 23
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA KD9OI
UT WOS:000508190300006
PM 31955675
OA Green Submitted, Green Published, hybrid
DA 2022-04-17
ER

PT J
AU Cui, SN
   Tseng, HH
   Pakela, J
   Ten Haken, RK
   El Naqa, I
AF Cui, Sunan
   Tseng, Huan-Hsin
   Pakela, Julia
   Ten Haken, Randall K.
   El Naqa, Issam
TI Introduction to machine and deep learning for medical physicists
SO MEDICAL PHYSICS
LA English
DT Article
DE deep learning; machine learning; medical physics
ID RADIATION-THERAPY; NEURAL-NETWORKS; BIG DATA; LOGISTIC-REGRESSION;
   CANCER; PREDICTION; RADIOTHERAPY; CLASSIFICATION; ARCHITECTURES;
   ONCOLOGY
AB Recent years have witnessed tremendous growth in the application of machine learning (ML) and deep learning (DL) techniques in medical physics. Embracing the current big data era, medical physicists equipped with these state-of-the-art tools should be able to solve pressing problems in modern radiation oncology. Here, a review of the basic aspects involved in ML/DL model building, including data processing, model training, and validation for medical physics applications is presented and discussed. Machine learning can be categorized based on the underlying task into supervised learning, unsupervised learning, or reinforcement learning; each of these categories has its own input/output dataset characteristics and aims to solve different classes of problems in medical physics ranging from automation of processes to predictive analytics. It is recognized that data size requirements may vary depending on the specific medical physics application and the nature of the algorithms applied. Data processing, which is a crucial step for model stability and precision, should be performed before training the model. Deep learning as a subset of ML is able to learn multilevel representations from raw input data, eliminating the necessity for hand crafted features in classical ML. It can be thought of as an extension of the classical linear models but with multilayer (deep) structures and nonlinear activation functions. The logic of going "deeper" is related to learning complex data structures and its realization has been aided by recent advancements in parallel computing architectures and the development of more robust optimization methods for efficient training of these algorithms. Model validation is an essential part of ML/DL model building. Without it, the model being developed cannot be easily trusted to generalize to unseen data. Whenever applying ML/DL, one should keep in mind, according to Amara's law, that humans may tend to overestimate the ability of a technology in the short term and underestimate its capability in the long term. To establish ML/DL role into standard clinical workflow, models considering balance between accuracy and interpretability should be developed. Machine learning/DL algorithms have potential in numerous radiation oncology applications, including automatizing mundane procedures, improving efficiency and safety of auto-contouring, treatment planning, quality assurance, motion management, and outcome predictions. Medical physicists have been at the frontiers of technology translation into medicine and they ought to be prepared to embrace the inevitable role of ML/DL in the practice of radiation oncology and lead its clinical implementation.
C1 [Cui, Sunan; Tseng, Huan-Hsin; Pakela, Julia; Ten Haken, Randall K.; El Naqa, Issam] Univ Michigan, Dept Radiat Oncol, Ann Arbor, MI 48103 USA.
   [Cui, Sunan; Pakela, Julia] Univ Michigan, Appl Phys Program, Ann Arbor, MI 48109 USA.
RP Cui, SN (corresponding author), Univ Michigan, Dept Radiat Oncol, Ann Arbor, MI 48103 USA.; Cui, SN (corresponding author), Univ Michigan, Appl Phys Program, Ann Arbor, MI 48109 USA.
EM sunan@umich.edu
FU NCI NIH HHSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Cancer Institute (NCI) [R01
   CA233487, R37 CA222215, P01 CA059827] Funding Source: Medline; NIH
   HHSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [R37-CA222215, R01-CA233487,
   P01-CA059827] Funding Source: Medline
NR 110
TC 19
Z9 19
U1 9
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0094-2405
EI 2473-4209
J9 MED PHYS
JI Med. Phys.
PD JUN
PY 2020
VL 47
IS 5
BP E127
EP E147
DI 10.1002/mp.14140
PG 21
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Radiology, Nuclear Medicine & Medical Imaging
GA PB0JZ
UT WOS:000596015500003
PM 32418339
OA Green Published, Green Accepted
DA 2022-04-17
ER

PT J
AU Emmanuel, T
   Maupong, T
   Mpoeleng, D
   Semong, T
   Mphago, B
   Tabona, O
AF Emmanuel, Tlamelo
   Maupong, Thabiso
   Mpoeleng, Dimane
   Semong, Thabo
   Mphago, Banyatsang
   Tabona, Oteng
TI A survey on missing data in machine learning
SO JOURNAL OF BIG DATA
LA English
DT Article
DE Missing data; Imputation; Machine learning
ID ABSOLUTE ERROR MAE; DATA IMPUTATION; MULTIPLE IMPUTATION; HOT DECK;
   CLASSIFICATION; VALUES; OPTIMIZATION; ALGORITHMS; REGRESSION; PREDICTION
AB Machine learning has been the corner stone in analysing and extracting information from data and often a problem of missing values is encountered. Missing values occur because of various factors like missing completely at random, missing at random or missing not at random. All these may result from system malfunction during data collection or human error during data pre-processing. Nevertheless, it is important to deal with missing values before analysing data since ignoring or omitting missing values may result in biased or misinformed analysis. In literature there have been several proposals for handling missing values. In this paper, we aggregate some of the literature on missing data particularly focusing on machine learning techniques. We also give insight on how the machine learning approaches work by highlighting the key features of missing values imputation techniques, how they perform, their limitations and the kind of data they are most suitable for. We propose and evaluate two methods, the k nearest neighbor and an iterative imputation method (missForest) based on the random forest algorithm. Evaluation is performed on the Iris and novel power plant fan data with induced missing values at missingness rate of 5% to 20%. We show that both missForest and the k nearest neighbor can successfully handle missing values and offer some possible future research direction.
C1 [Emmanuel, Tlamelo; Maupong, Thabiso; Mpoeleng, Dimane; Semong, Thabo; Mphago, Banyatsang; Tabona, Oteng] Botswana Int Univ Sci & Technol, Dept Comp Sci & Informat Syst, Palapye, Botswana.
RP Emmanuel, T (corresponding author), Botswana Int Univ Sci & Technol, Dept Comp Sci & Informat Syst, Palapye, Botswana.
EM tlamelo.emmanuel@studentmail.biust.ac.bw
OI Maupong, Thabiso Mphoobuile/0000-0002-0721-885X
FU Botswana International University of Science and Technology
FX This work received a grant from the Botswana International University of
   Science and Technology.
NR 177
TC 2
Z9 2
U1 17
U2 17
PU SPRINGERNATURE
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND
EI 2196-1115
J9 J BIG DATA-GER
JI J. Big Data
PD OCT 27
PY 2021
VL 8
IS 1
AR 140
DI 10.1186/s40537-021-00516-9
PG 37
WC Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WO6OH
UT WOS:000712571000001
PM 34722113
OA gold, Green Published, Green Submitted
DA 2022-04-17
ER

PT J
AU Liu, ZQ
   Gilbert, G
   Cepeda, JM
   Lysdahl, AOK
   Piciullo, L
   Hefre, H
   Lacasse, S
AF Liu, Zhongqiang
   Gilbert, Graham
   Cepeda, Jose Mauricio
   Lysdahl, Asgeir Olaf Kydland
   Piciullo, Luca
   Hefre, Heidi
   Lacasse, Suzanne
TI Modelling of shallow landslides with machine learning algorithms
SO GEOSCIENCE FRONTIERS
LA English
DT Article
DE Shallow landslide; Spatial modelling; Machine learning; GIS
ID SUPPORT VECTOR MACHINE; RANDOM FOREST; SUSCEPTIBILITY ASSESSMENT;
   NEURAL-NETWORK; DECISION TREE; PREDICTION; PERFORMANCE; DEFINITION;
   BIVARIATE; GIS
AB This paper introduces three machine learning (ML) algorithms, the 'ensemble' Random Forest (RF), the 'ensemble' Gradient Boosted Regression Tree (GBRT) and the MultiLayer Perceptron neural network (MLP) and applies them to the spatial modelling of shallow landslides near Kvam in Norway. In the development of the ML models, a total of 11 significant landslide controlling factors were selected. The controlling factors relate to the geomorphology, geology, geo-environment and anthropogenic effects: slope angle, aspect, plan curvature, profile curvature, flow accumulation, flow direction, distance to rivers, water content, saturation, rainfall and distance to roads. It is observed that slope angle was the most significant controlling factor in the ML analyses. The performance of the three ML models was evaluated quantitatively based on the Receiver Operating Characteristic (ROC) analysis. The results show that the 'ensemble' GBRT machine learning model yielded the most promising results for the spatial prediction of shallow landslides, with a 95% probability of landslide detection and 87% prediction efficiency.
C1 [Liu, Zhongqiang; Gilbert, Graham; Cepeda, Jose Mauricio; Lysdahl, Asgeir Olaf Kydland; Piciullo, Luca; Hefre, Heidi; Lacasse, Suzanne] Norwegian Geotech Inst NGI, Sognsveien 72, N-0855 Oslo, Norway.
RP Liu, ZQ (corresponding author), Norwegian Geotech Inst NGI, Sognsveien 72, N-0855 Oslo, Norway.
EM zhongqiang.liu@ngi.no
RI PICIULLO, LUCA/AAE-4527-2019
OI PICIULLO, LUCA/0000-0003-3108-1256
FU NGI; Research Council of NorwayResearch Council of Norway
FX The authors gratefully acknowledge NGI's financial support for this
   study. The funding comes in from The Research Council of Norway. The
   work did not receive any grant from other public funding agencies nor
   from the commercial or not-for-profit sectors.
NR 48
TC 26
Z9 26
U1 59
U2 86
PU CHINA UNIV GEOSCIENCES, BEIJING
PI HAIDIAN DISTRICT
PA 29 XUEYUAN RD, HAIDIAN DISTRICT, 100083, PEOPLES R CHINA
SN 1674-9871
J9 GEOSCI FRONT
JI Geosci. Front.
PD JAN
PY 2021
VL 12
IS 1
BP 385
EP 393
DI 10.1016/j.gsf.2020.04.014
PG 9
WC Geosciences, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Geology
GA PD0QZ
UT WOS:000597401000028
OA gold
HC Y
HP N
DA 2022-04-17
ER

PT J
AU Raghuwanshi, BS
   Shukla, S
AF Raghuwanshi, Bhagat Singh
   Shukla, Sanyam
TI Classifying multiclass imbalanced data using generalized class-specific
   extreme learning machine
SO PROGRESS IN ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Extreme learning machine; Generalized class-specific extreme learning
   machine; Multiclass imbalance problem; Classification
AB Learning from the imbalanced problem is among the most attractive issues in the contemporary machine learning community. However, the extensive majority of attention in this domain is given to the two-class imbalanced problems, while their much more complex multiclass counterparts are comparatively unexplored. It has been shown (Huang et al. in IEEE Trans Syst Man Cybern B (Cybern) 42(2):513-529, 2012) that extreme learning machine (ELM) achieves much better generalization performance compared to support vector machine (SVM) and least-squares support vector machine (LS-SVM) for multiclass classification problems. On this account, this work proposes a novel generalized class-specific extreme learning machine (GCS-ELM), the extension of our recently proposed, class-specific extreme learning machine (CS-ELM) to address the multiclass imbalanced problems more effectively. The proposed GCS-ELM can be applied directly to the multiclass imbalance problems. The proposed method also has reduced computational cost compared to the weighted extreme learning machine (WELM) for multiclass imbalance problems. The proposed method uses class-specific regularization coefficients, which are computed by employing class distribution. The proposed method has lower computational overhead compared to the class-specific cost regulation extreme learning machine (CCR-ELM). The proposed work is assessed by using benchmark real-world imbalanced datasets downloaded from the well-known KEEL dataset repository and synthetic datasets. The experimental results, supported by the extensive statistical analysis, demonstrate that GCS-ELM is capable to improve the generalization performance for multiclass imbalanced classification problems.
C1 [Raghuwanshi, Bhagat Singh; Shukla, Sanyam] Maulana Azad Natl Inst Technol, Dept Comp Sci & Engn, Bhopal 462003, Madhya Pradesh, India.
RP Raghuwanshi, BS (corresponding author), Maulana Azad Natl Inst Technol, Dept Comp Sci & Engn, Bhopal 462003, Madhya Pradesh, India.
EM bhagat.mnit@gmail.com; sanyamshukla@gmail.com
RI Raghuwanshi, Bhagat Singh/Y-2664-2019
OI Raghuwanshi, Bhagat Singh/0000-0002-3027-7831
NR 64
TC 0
Z9 0
U1 2
U2 5
PU SPRINGERNATURE
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND
SN 2192-6352
EI 2192-6360
J9 PROG ARTIF INTELL
JI Prog. Artif. Intell.
PD SEP
PY 2021
VL 10
IS 3
BP 259
EP 281
DI 10.1007/s13748-021-00236-4
EA MAR 2021
PG 23
WC Computer Science, Artificial Intelligence
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA TZ1NW
UT WOS:000625356600002
DA 2022-04-17
ER

PT S
AU Chen, IY
   Pierson, E
   Rose, S
   Joshi, S
   Ferryman, K
   Ghassemi, M
AF Chen, Irene Y.
   Pierson, Emma
   Rose, Sherri
   Joshi, Shalmali
   Ferryman, Kadija
   Ghassemi, Marzyeh
BE Altman, RB
TI Ethical Machine Learning in Healthcare
SO ANNUAL REVIEW OF BIOMEDICAL DATA SCIENCE, VOL 4
SE Annual Review of Biomedical Data Science
LA English
DT Article; Book Chapter
DE machine learning; bias; ethics; health; healthcare; health disparities
ID RANDOMIZED CONTROLLED-TRIALS; RACIAL/ETHNIC DISPARITIES;
   ARTIFICIAL-INTELLIGENCE; EXTERNAL VALIDITY; MENTAL-HEALTH; RACIAL BIAS;
   RISK; MORTALITY; ETHNICITY; RACE
AB The use of machine learning (ML) in healthcare raises numerous ethical concerns, especially as models can amplify existing health inequities. Here, we outline ethical considerations for equitable ML in the advancement of healthcare. Specifically, we frame ethics of ML in healthcare through the lens of social justice. We describe ongoing efforts and outline challenges in a proposed pipeline of ethical ML in health, ranging from problem selection to postdeployment considerations. We close by summarizing recommendations to address these challenges.
C1 [Chen, Irene Y.; Ghassemi, Marzyeh] MIT, Dept Elect Engn & Comp Sci, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   [Pierson, Emma] Microsoft Res, Cambridge, MA 02143 USA.
   [Rose, Sherri] Stanford Univ, Ctr Hlth Policy, Stanford, CA 94305 USA.
   [Rose, Sherri] Stanford Univ, Ctr Primary Care & Outcomes Res, Stanford, CA 94305 USA.
   [Joshi, Shalmali] Vector Inst, Toronto, ON M5G 1M1, Canada.
   [Ferryman, Kadija] NYU, Tandon Sch Engn, Dept Technol Culture & Soc, Brooklyn, NY 11201 USA.
   [Ghassemi, Marzyeh] MIT, Inst Med & Evaluat Sci, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
RP Chen, IY (corresponding author), MIT, Dept Elect Engn & Comp Sci, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
EM iychen@mit.edu
FU NIH (National Institutes of Health)United States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USA [DP2MD012722];
   CIFAR (Canadian Institute for Advanced Research) AI Chair at the Vector
   Institute; Microsoft Research grant
FX The authors thank Rediet Abebe for helpful discussions and contributions
   to an early draft and Peter Szolovits, Pang Wei Koh, Leah Pierson, Berk
   Ustun, and Tristan Naumann for useful comments and feedback. This work
   was supported in part by an NIH (National Institutes of Health)
   Director's New Innovator Award (DP2MD012722) (to S.R.), a CIFAR
   (Canadian Institute for Advanced Research) AI Chair at the Vector
   Institute (to M.G.), and a Microsoft Research grant (to M.G.).
NR 147
TC 1
Z9 1
U1 0
U2 0
PU ANNUAL REVIEWS
PI PALO ALTO
PA 4139 EL CAMINO WAY, PO BOX 10139, PALO ALTO, CA 94303-0897 USA
SN 2574-3414
J9 ANNU REV BIOMED DA S
JI Annu. Rev. Biomed. Data Sci.
PY 2021
VL 4
BP 123
EP 144
DI 10.1146/annurev-biodatasci-092820-114757
PG 22
WC Biochemical Research Methods; Mathematical & Computational Biology
WE Emerging Sources Citation Index (ESCI); Book Citation Index – Science (BKCI-S)
SC Biochemistry & Molecular Biology; Mathematical & Computational Biology
GA BR9LO
UT WOS:000677831600007
OA Green Submitted, Bronze
DA 2022-04-17
ER

PT C
AU Ojajuni, O
   Ayeni, F
   Akodu, O
   Ekanoye, F
   Adewole, S
   Ayo, T
   Misra, S
   Mbarika, V
AF Ojajuni, Opeyemi
   Ayeni, Foluso
   Akodu, Olagunju
   Ekanoye, Femi
   Adewole, Samson
   Ayo, Timothy
   Misra, Sanjay
   Mbarika, Victor
BE Gervasi, O
   Murgante, B
   Misra, S
   Garau, C
   Blecic, I
   Taniar, D
   Apduhan, BO
   Rocha, AMAC
   Tarantino, E
   Torre, CM
TI Predicting Student Academic Performance Using Machine Learning
SO COMPUTATIONAL SCIENCE AND ITS APPLICATIONS, ICCSA 2021, PT IX
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Science and Its
   Applications (ICCSA)
CY SEP 13-16, 2021
CL Cagliari, ITALY
DE Machine learning; Deep learning; Student academic performance;
   Educational data mining; Data analytics; Convolutional Neutral Networks
   (CNN)
AB The introduction of the Internet of Things (IoT), Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL), and Big Data have paved the way for research focused on improving the student learning experience and help to address challenges faced by the education system. Machine Learning technology analyzes data to recognize patterns and use them to make predictions. This paper introduces a ML model that classify and predict student academic success by utilizing supervised ML algorithms like Random Forest, Support Vector Machines, Gradient boosting, Decision Tree, Logistic Regression, Regression, Extreme Gradient Boosting (XGBoost), and Deep Learning. This paper aims to predict student's academic success based on historical data and identify the key factors that affect student academic success. Thus, the proposed approach offers a solution to predict student academic performance efficiently and accurately by comparing several ML models to the Deep Learning model. Results show that the Extreme Gradient Boosting (XGBoost) can predict student academic performance with an accuracy of 97.12%. Furthermore, results showed significant social and demographic features that affect student academic success. This study concludes that applying Machine Learning technology in the classroom will help educators identify gaps in student learning and enable early detection of underperforming students, thus empowering educators with informed decision-making.
C1 [Ojajuni, Opeyemi] Southern Univ, Dept Sci & Math Educ, Baton Rouge, LA USA.
   [Ojajuni, Opeyemi; Akodu, Olagunju; Ekanoye, Femi; Adewole, Samson; Ayo, Timothy] A&M Coll, Baton Rouge, LA USA.
   [Ayeni, Foluso] Univ Nebraska, Dept Informat Syst & Quantitat Anal, Lincoln, NE 68583 USA.
   [Akodu, Olagunju] Southern Univ, Dept Elect & Elect Engn, Baton Rouge, LA USA.
   [Ekanoye, Femi; Adewole, Samson; Ayo, Timothy] Southern Univ, Global Technol Management & Policy Res Grp, Baton Rouge, LA USA.
   [Misra, Sanjay] Covenant Univ, Dept Informat & Commun Engn, Ota, Nigeria.
   [Mbarika, Victor] East Carolina Univ, Dept Management Informat Syst, Greenville, NC 27858 USA.
RP Ayeni, F (corresponding author), Univ Nebraska, Dept Informat Syst & Quantitat Anal, Lincoln, NE 68583 USA.
EM Opeyemi_ojajuni_00@subr.edu; fayeni@unomaha.edu;
   olagunju_akodu_00@subr.edu; femi_ekanoye@subr.edu;
   oluwadamilaresam@gmail.com; timothyayo99@gmail.com;
   sanjay.misra@covenantuniversity.edu.ng; mbarikav20@ecu.edu
NR 12
TC 2
Z9 2
U1 7
U2 7
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-87013-3; 978-3-030-87012-6
J9 LECT NOTES COMPUT SC
PY 2021
VL 12957
BP 481
EP 491
DI 10.1007/978-3-030-87013-3_36
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods; Mathematics, Applied
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Mathematics
GA BS4SP
UT WOS:000722395800036
DA 2022-04-17
ER

PT J
AU Amini, S
   Elmore, R
   Oztekin, OO
   Strauss, J
AF Amini, Shahram
   Elmore, Ryan
   Oztekin, Ozde
   Strauss, Jack
TI Can machines learn capital structure dynamics?*
SO JOURNAL OF CORPORATE FINANCE
LA English
DT Article
DE Machine learning; Target leverage; Speed of leverage adjustment;
   Financing actions
ID STRUCTURE DECISIONS; INVESTMENT DECISIONS; STRUCTURE ADJUSTMENT;
   CORPORATE-FINANCE; STRUCTURE CHOICE; DETERMINANTS; FIRMS; INFORMATION
AB Yes, they can! Machine learning models predict leverage better than linear models and identify a broader set of leverage determinants. They boost the out-of-sample R2 from 36% to 56% over OLS and LASSO. The best performing model (random forests) selects market-to-book, industry median leverage, cash and equivalents, Z-Score, profitability, stock returns, and firm size as reliable predictors of market leverage. More precise target estimation yields a 10%-33% faster speed of adjustment and improves prediction of financing actions relative to linear models. Machine learning identifies uncertainty, cash flow, and macroeconomic considerations among primary drivers of leverage adjustments.
C1 [Amini, Shahram; Strauss, Jack] Univ Denver, Daniels Coll Business, Dept Finance, Denver, CO 80208 USA.
   [Elmore, Ryan] Univ Denver, Daniels Coll Business, Business Informat & Anal Dept, Denver, CO 80208 USA.
   [Oztekin, Ozde] Florida Int Univ, Coll Business, Dept Finance, Miami, FL 33199 USA.
RP Amini, S (corresponding author), Univ Denver, Daniels Coll Business, Dept Finance, Denver, CO 80208 USA.
EM shahram.amini@du.edu; ryan.elmore@du.edu; ooztekin@fiu.edu;
   jack.strauss@du.edu
RI Oztekin, Ozde/I-1719-2016
OI Oztekin, Ozde/0000-0002-1938-5639
NR 73
TC 0
Z9 0
U1 33
U2 33
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0929-1199
EI 1872-6313
J9 J CORP FINANC
JI J. Corp. Financ.
PD OCT
PY 2021
VL 70
AR 102073
DI 10.1016/j.jcorpfin.2021.102073
EA AUG 2021
PG 22
WC Business, Finance
WE Social Science Citation Index (SSCI)
SC Business & Economics
GA WC2JO
UT WOS:000704088400021
DA 2022-04-17
ER

PT J
AU Perales-Gonzalez, C
   Carbonero-Ruz, M
   Perez-Rodriguez, J
   Becerra-Alonso, D
   Fernandez-Navarro, F
AF Perales-Gonzalez, Carlos
   Carbonero-Ruz, Mariano
   Perez-Rodriguez, Javier
   Becerra-Alonso, David
   Fernandez-Navarro, Francisco
TI Negative correlation learning in the extreme learning machine framework
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Negative correlation learning; Extreme learning machine; Ensemble;
   Diversity
ID NEURAL-NETWORKS; REGRESSION; DIVERSITY; ALGORITHM; ADABOOST
AB Extreme learning machine (ELM) has shown to be a suitable algorithm for classification problems. Several ensemble meta-algorithms have been developed in order to generalize the results of ELM models. Ensemble approaches introduced in the ELM literature mainly come from boosting and bagging frameworks. The generalization of these methods relies on data sampling procedures, under the assumption that training data are heterogeneously enough to set up diverse base learners. The proposed ELM ensemble model overcomes this strong assumption by using the negative correlation learning (NCL) framework. An alternative diversity metric based on the orthogonality of the outputs is proposed. The error function formulation allows us to develop an analytical solution to the parameters of the ELM base learners, which significantly reduce the computational burden of the standard NCL ensemble method. The proposed ensemble method has been validated by an experimental study with a variety of benchmark datasets, comparing it with the existing ensemble methods in ELM. Finally, the proposed method statistically outperforms the comparison ensemble methods in accuracy, also reporting a competitive computational burden (specially if compared to the baseline NCL-inspired method).
C1 [Perales-Gonzalez, Carlos; Carbonero-Ruz, Mariano; Perez-Rodriguez, Javier; Becerra-Alonso, David; Fernandez-Navarro, Francisco] Univ Loyola Andalucia, Seville, Spain.
RP Perales-Gonzalez, C (corresponding author), Univ Loyola Andalucia, Seville, Spain.
EM cperales@uloyola.es
RI Perales-González, Carlos/V-7256-2018; Becerra-Alonso,
   David/AAG-3860-2022; Pérez-Rodríguez, Javier/ABH-3350-2020
OI Perales-González, Carlos/0000-0002-7874-913X; Fernandez-Navarro,
   Francisco/0000-0002-5599-6170; Perez Rodriguez,
   Javier/0000-0002-0437-3264
NR 70
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD SEP
PY 2020
VL 32
IS 17
BP 13805
EP 13823
DI 10.1007/s00521-020-04788-9
EA MAR 2020
PG 19
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NB5MU
UT WOS:000517702000001
DA 2022-04-17
ER

PT C
AU Sekeroglu, B
   Hasan, SS
   Abdullah, SM
AF Sekeroglu, Boran
   Hasan, Shakar Sherwan
   Abdullah, Saman Mirza
BE Arai, K
   Kapoor, S
TI Comparison of Machine Learning Algorithms for Classification Problems
SO ADVANCES IN COMPUTER VISION, VOL 2
SE Advances in Intelligent Systems and Computing
LA English
DT Proceedings Paper
CT Computer Vision Conference (CVC)
CY APR 25-26, 2019
CL Las Vegas, NV
SP Sci & Informat Org
DE Machine learning; Backpropagation; Radial Basis Function Neural Network;
   Support Vector Machine
ID NEURAL-NETWORK; HYBRID; SVM
AB Machine learning algorithms become wide tools that are used for classification and clustering of data. Several algorithms were proposed and implemented for different applications in multi-disciplinary areas. However, diversity of these algorithms makes the selection of effective algorithm difficult for specific application. Thus, comparison of benchmark algorithms is required. This paper presents preliminary results of the comparison of three different types of machine learning algorithms; Backpropagation Neural Network, Radial Basis Function Neural Network and Support Vector Machine using several numerical datasets for classification problems. Comparison is performed by considering the performance of these algorithms using obtained accuracy rates. The results show that Radial Basis Function Neural Network is superior to other considered algorithms for classification of numerical data.
C1 [Sekeroglu, Boran] Near East Univ, Dept Informat Syst Engn, TRNC, Mersin 10, Istanbul, Turkey.
   [Hasan, Shakar Sherwan] Near East Univ, Dept Software Engn, TRNC, Mersin 10, Istanbul, Turkey.
   [Abdullah, Saman Mirza] Koya Univ, Dept Software Engn, Univ Pk,Danielle Mitterrand Blvd,KOY45, Koysinjaq, Iraq.
RP Abdullah, SM (corresponding author), Koya Univ, Dept Software Engn, Univ Pk,Danielle Mitterrand Blvd,KOY45, Koysinjaq, Iraq.
EM boran.sekeroglu@neu.edu.tr; 20168731@std.neu.edu.tr;
   saman.mirza@koyauniversity.org
RI Sekeroglu, Boran/X-6510-2019
OI Sekeroglu, Boran/0000-0001-7284-1173
NR 31
TC 3
Z9 3
U1 5
U2 17
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2194-5357
EI 2194-5365
BN 978-3-030-17798-0; 978-3-030-17797-3
J9 ADV INTELL SYST
PY 2020
VL 944
BP 491
EP 499
DI 10.1007/978-3-030-17798-0_39
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BO0GJ
UT WOS:000490760000038
DA 2022-04-17
ER

PT J
AU Zhang, J
   Xiao, WD
   Li, YJ
   Zhang, S
   Zhang, ZQ
AF Zhang, Jie
   Xiao, Wendong
   Li, Yanjiao
   Zhang, Sen
   Zhang, Zhiqiang
TI Multilayer probability extreme learning machine for device-free
   localization
SO NEUROCOMPUTING
LA English
DT Article
DE Device-free localization; Extreme learning machine; Extreme learning
   machine autoencoder; Multilayer probability extreme learning machine
ID ALGORITHM; UNCERTAINTY; STRATEGY; MODEL
AB Device-free localization (DFL) is becoming one of the new techniques in wireless localization field, due to its advantage that the target to be localized does not need to attach any electronic device. One of the key issues of DFL is how to characterize the influence of the target on the wireless links, such that the target's location can be accurately estimated by analyzing the changes of the signals of the links. Most of the existing related research works usually extract the useful information from the links through manual approaches, which are labor-intensive and time-consuming. Deep learning approaches have attempted to automatically extract the useful information from the links, but the training of the conventional deep learning approaches are time-consuming, because a large number of parameters need to be fine-tuned multiple times. Motivated by the fast learning speed and excellent generalization performance of extreme learning machine (ELM), which is an emerging training approach for generalized single hidden layer feed-forward neural networks (SLFNs), this paper proposes a novel hierarchical ELM based on deep learning theory, named multilayer probability ELM (MP-ELM), for automatically extracting the useful information from the links, and implementing fast and accurate DFL. The proposed MP-ELM is stacked by ELM autoencoders, so it also keeps the very fast learning speed of ELM. In addition, considering the uncertainty and redundant links existing in DFL, MP-ELM outputs the probabilistic estimation of the target's location instead of the deterministic output. The validity of the proposed MP-ELM-based DFL is evaluated both in the indoor and the outdoor environments, respectively. Experimental results demonstrate that the proposed MP-ELM can obtain better performance compared with classic ELM, multilayer ELM (ML-ELM), hierarchical ELM (H-ELM), deep belief network (DBN), and deep Boltzmann machine (DBM). (C) 2019 Elsevier B.V. All rights reserved.
C1 [Zhang, Jie; Xiao, Wendong; Li, Yanjiao; Zhang, Sen] Univ Sci & Technol Beijing, Sch Automat & Elect Engn, Beijing 100083, Peoples R China.
   [Zhang, Jie; Xiao, Wendong; Li, Yanjiao; Zhang, Sen] Beijing Engn Res Ctr Ind Spectrum Imaging, Beijing 100083, Peoples R China.
   [Zhang, Zhiqiang] Univ Leeds, Sch Elect & Elect Engn, Leeds LS2 9JT, W Yorkshire, England.
RP Xiao, WD (corresponding author), Univ Sci & Technol Beijing, Sch Automat & Elect Engn, Beijing 100083, Peoples R China.
EM wdxiao@ustb.edu.cn
OI Zhang, Zhiqiang/0000-0003-0204-3867
FU National Key Research and Development Program of China [2017YFB1401203];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61673055, 61673056 and61773056]
FX This work is supported in part by the National Key Research and
   Development Program of China under Grant 2017YFB1401203 and the National
   Natural Science Foundation of China under Grants 61673055, 61673056
   and61773056.
NR 60
TC 13
Z9 13
U1 5
U2 35
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD JUL 5
PY 2020
VL 396
BP 383
EP 393
DI 10.1016/j.neucom.2018.11.106
PG 11
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LT1AD
UT WOS:000536806600015
OA Green Accepted
DA 2022-04-17
ER

PT C
AU Wedin, K
   Johnsson, C
   Akerman, M
   Fast-Berglund, A
   Bengtsson, V
   Alveflo, PA
AF Wedin, Kevin
   Johnsson, Christoffer
   Akerman, Magnus
   Fast-Berglund, Asa
   Bengtsson, Viktor
   Alveflo, Per-Anders
TI Automating nut tightening using Machine Learning
SO IFAC PAPERSONLINE
LA English
DT Proceedings Paper
CT 21st IFAC World Congress on Automatic Control - Meeting Societal
   Challenges
CY JUL 11-17, 2020
CL ELECTR NETWORK
SP Int Federat Automat Control, Siemens, Bayer, ABB, MathWorks, Phoenix Contact, Ifak Technol, Berlin Heart, Elsevier, De Gruyter, Tele Medi GmbH
DE Machine learning; assembly; collaborative robot
AB At the Volvo Truck assembly plant the repetitive task of nut tightening is not ideal regarding quality and ergonomic. The solution to both these issues would be to significantly increase the level of automation. However, automating this specific station requires solutions to two specific problems. The first problem is to find and identify what nuts that need to be tightened, since they are not always on the same position for this highly customized product. The second problem is that the automated solution needs to accommodate the working space which is a moving assembly line with human operators. This paper investigates how these two problems ban be solved using machine learning and collaborative robots. A realistic mockup of the assembly station has been created at Stena Industry Innovation Laboratory (SII-Lab) where all the testing has been done.
   The problem to identify the nuts to tighten is further complicated by the fact that some nuts are placed backwards for future further assembly which must be avoided. Therefore, the selected solution is to use supervised machine learning for object recognition. This way, the system can be trained to recognize both nuts that need to be tightened and those mounted backwards, and possible other objects needed. Tests have been conducted with different types of CNN (Convolutional Neural Network) algorithms. Results have been very successful, and the test setup has successfully managed to connect the whole task of identifying the correct nuts and move the collaborative robot to that specific position. Copyright (C) 2020 The Authors.
C1 [Wedin, Kevin; Johnsson, Christoffer; Akerman, Magnus; Fast-Berglund, Asa; Bengtsson, Viktor] Chalmers Univ Technol, SE-41296 Gothenburg, Sweden.
   [Alveflo, Per-Anders] Volvo Trucks Cooperat, Gothenburg, Sweden.
RP Wedin, K (corresponding author), Chalmers Univ Technol, SE-41296 Gothenburg, Sweden.
FU Swedish agency VINNOVAVinnova
FX The authors would like to acknowledge the Swedish agency VINNOVA for
   supporting the national testbed project in which this study has been
   carried out.
NR 19
TC 1
Z9 1
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2405-8963
J9 IFAC PAPERSONLINE
JI IFAC PAPERSONLINE
PY 2020
VL 53
IS 2
BP 10291
EP 10296
DI 10.1016/j.ifacol.2020.12.2763
PG 6
WC Automation & Control Systems
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Automation & Control Systems
GA SF2LQ
UT WOS:000652593100240
OA gold, Green Submitted
DA 2022-04-17
ER

PT J
AU Nagaprasad, S
   Padmaja, DL
   Qureshi, Y
   Bangare, SL
   Mishra, M
   Mazumdar, BD
AF Nagaprasad, S.
   Padmaja, D. L.
   Qureshi, Yaser
   Bangare, Sunil L.
   Mishra, Manmohan
   Mazumdar, Bireshwar Dass
TI Investigating the Impact of Machine Learning in Pharmaceutical Industry
SO JOURNAL OF PHARMACEUTICAL RESEARCH INTERNATIONAL
LA English
DT Review
DE Machine learning; consumer health; business change; cost-effective
   solutions
ID ARTIFICIAL-INTELLIGENCE; BIG DATA; DEEP; TECHNOLOGY
AB In the pharmaceutical and consumer health industries, artificial intelligence and machine learning played an important role. These technologies are critical for the identification of patients with improved intelligence applications, such as disease detection and diagnostics for clinical testing, for medicine production and predictive forecasts. In recent years, advances in numerous analysis tools and machine learning algorithms have led to novel applications for machine learning in several areas of pharmaceutical science. This paper examines the past, present, and future impacts of machine learning on several areas, including medicine design and discovery. Artificial neural networks are employed in pharmaceutical machine learning because they can reproduce nonlinear interactions typical in pharmaceutical research. Al and learning machines are examined in everyday pharmaceutical needs, industrial and regulatory insights.
C1 [Nagaprasad, S.] Tara Govt Coll A Sangareddy, Fac Comp Sci & Applicat, Dept Comp Sci & Comp Applicat, Sangareddy, Telangana, India.
   [Padmaja, D. L.] Anurag Univ, Dept IT, Majarguda, India.
   [Qureshi, Yaser] Govt Coll Khertha, Dept Zool, Khertha, Chhattisgarh, India.
   [Bangare, Sunil L.] Sinhgad Acad Engn, Dept IT, Pune, Maharashtra, India.
   [Mishra, Manmohan] United Inst Management, Dept Comp Applicat, Prayagraj 211010, India.
   [Mazumdar, Bireshwar Dass] United Univ, Prayagraj 211002, India.
RP Nagaprasad, S (corresponding author), Tara Govt Coll A Sangareddy, Fac Comp Sci & Applicat, Dept Comp Sci & Comp Applicat, Sangareddy, Telangana, India.
EM nagkanna80@gmail.com
RI Bangare, Sunil L./O-3039-2015; D, Lakshmi Padmaja/AAE-8774-2022;
   Dhyaram, Lakshmi Padmaja/AAE-2584-2022
OI Bangare, Sunil L./0000-0002-7669-6361; Dhyaram, Lakshmi
   Padmaja/0000-0001-8262-6821
NR 42
TC 0
Z9 0
U1 4
U2 4
PU SCIENCEDOMAIN INT
PI GURGAON
PA SCIENCEDOMAIN INT, GURGAON, 00000, INDIA
SN 2456-9119
J9 J PHARM RES INT
JI J. Pharm. Res. Int.
PY 2021
VL 33
IS 46A
BP 6
EP 14
AR 74285
DI 10.9734/JPRI/2021/v33i46A32834
PG 9
WC Pharmacology & Pharmacy
WE Emerging Sources Citation Index (ESCI)
SC Pharmacology & Pharmacy
GA WG7UB
UT WOS:000707199100002
OA gold
DA 2022-04-17
ER

PT J
AU Robert, A
   Gupta, A
   Shenoy, V
   Sitaram, D
   Kalambur, S
AF Robert, Andrew
   Gupta, Apaar
   Shenoy, Vinayak
   Sitaram, Dinkar
   Kalambur, Subramaniam
TI Predicting Hadoop misconfigurations using machine learning
SO SOFTWARE-PRACTICE & EXPERIENCE
LA English
DT Article
DE big data; Hadoop; machine learning; misconfiguration; prediction
AB Distributed applications are popular for heavy workloads where the resources of a single machine are not sufficient. These distributed applications come with many parameters to tune so that cluster resources can be effectively utilized. However, any misconfiguration of the available parameters may result in suboptimal performance of one or more machines in the cluster. These events may go unnoticed or can result in crashes. This problem of misconfigured parameters has no straightforward solution due to the variety of parameters and vastly different workloads being processed. In this article, we propose a methodology for machine learning-based detection of misconfigurations. We collect data mined from system resource utilization, Hadoop logs, and job-level metrics to train a model using decision tree and support vector machine. The models are used to identify whether a set of configuration parameters could result in a crash or a slowdown for a specific workload. The approach explained in this article can be extended to other distributed big data applications, such as Spark, Hive, Pig, and so on.
C1 [Robert, Andrew; Gupta, Apaar; Shenoy, Vinayak; Sitaram, Dinkar; Kalambur, Subramaniam] PES Univ, Ctr Cloud Comp & Big Data, Dept Comp Sci & Engn, Bangalore, Karnataka, India.
RP Gupta, A (corresponding author), PES Univ, Ctr Cloud Comp & Big Data, Dept Comp Sci & Engn, Bangalore, Karnataka, India.
EM apaar.gupta.13@gmail.com
NR 48
TC 0
Z9 0
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0038-0644
EI 1097-024X
J9 SOFTWARE PRACT EXPER
JI Softw.-Pract. Exp.
PD JUL
PY 2020
VL 50
IS 7
BP 1168
EP 1183
DI 10.1002/spe.2790
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LT6RF
UT WOS:000537195200006
DA 2022-04-17
ER

PT J
AU Jiang, JC
   Xiong, Y
   Zhang, ZY
   Rosen, DW
AF Jiang, Jingchao
   Xiong, Yi
   Zhang, Zhiyuan
   Rosen, David W.
TI Machine learning integrated design for additive manufacturing
SO JOURNAL OF INTELLIGENT MANUFACTURING
LA English
DT Article
DE Additive manufacturing; Design for AM; Machine learning
ID FLEXIBILITY CHARACTERISTICS; 3-DIMENSIONAL KINEMATICS; HUMAN ANKLE;
   BEHAVIOR
AB For improving manufacturing efficiency and minimizing costs, design for additive manufacturing (AM) has been accordingly proposed. The existing design for AM methods are mainly surrogate model based. Due to the increasingly available data nowadays, machine learning (ML) has been applied to medical diagnosis, image processing, prediction, classification, learning association, etc. A variety of studies have also been carried out to use machine learning for optimizing the process parameters of AM with corresponding objectives. In this paper, a ML integrated design for AM framework is proposed, which takes advantage of ML that can learn the complex relationships between the design and performance spaces. Furthermore, the primary advantage of ML over other surrogate modelling methods is the capability to model input-output relationships in both directions. That is, a deep neural network can model property-structure relationships, given structure-property input-output data. A case study was carried out to demonstrate the effectiveness of using ML to design a customized ankle brace that has a tunable mechanical performance with tailored stiffness.
C1 [Jiang, Jingchao; Xiong, Yi; Zhang, Zhiyuan; Rosen, David W.] Singapore Univ Technol & Design, Digital Mfg & Design Ctr, Singapore, Singapore.
   [Rosen, David W.] Georgia Inst Technol, GW Woodruff Sch Mech Engn, Atlanta, GA 30332 USA.
RP Rosen, DW (corresponding author), Singapore Univ Technol & Design, Digital Mfg & Design Ctr, Singapore, Singapore.; Rosen, DW (corresponding author), Georgia Inst Technol, GW Woodruff Sch Mech Engn, Atlanta, GA 30332 USA.
EM david_rosen@sutd.edu.sg
RI Xiong, Yi/H-4031-2019; Jiang, Jingchao/R-1303-2019
OI Xiong, Yi/0000-0002-0184-8607; Jiang, Jingchao/0000-0002-0446-3454;
   Rosen, David/0000-0002-7257-9395
FU Digital Manufacturing and Design (DManD) Research Center at the
   Singapore University of Technology and Design - Singapore National
   Research Foundation
FX This research was funded by Digital Manufacturing and Design (DManD)
   Research Center at the Singapore University of Technology and Design
   supported by the Singapore National Research Foundation.
NR 49
TC 15
Z9 15
U1 20
U2 55
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0956-5515
EI 1572-8145
J9 J INTELL MANUF
JI J. Intell. Manuf.
PD APR
PY 2022
VL 33
IS 4
BP 1073
EP 1086
DI 10.1007/s10845-020-01715-6
EA NOV 2020
PG 14
WC Computer Science, Artificial Intelligence; Engineering, Manufacturing
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZT9KY
UT WOS:000591977600002
DA 2022-04-17
ER

PT C
AU Chillarige, S
   Malik, A
   Amodeo, M
   Chabbra, A
   Nandakumar, B
   Redburn, R
   Esperance, NL
   Zimmerman, J
   Wheelock, A
AF Chillarige, Sameer
   Malik, Anil
   Amodeo, Martin
   Chabbra, Atul
   Nandakumar, Bharath
   Redburn, Robert
   Esperance, Nicholai L'
   Zimmerman, Jeff
   Wheelock, Adisun
GP IEEE
TI Machine Learning Driven Throughput Optimization of Volume Diagnosis
   Methodology
SO 2020 IEEE INTERNATIONAL TEST CONFERENCE INDIA (ITC INDIA)
LA English
DT Proceedings Paper
CT 4th IEEE International Test Conference India (ITC India)
CY JUL 12-14, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Bangalore Sect
DE VLSI; Machine Learning; Volume Diagnosis; yield
AB Numerous areas of VLSI Design and Automation including test and diagnosis have already started benefiting from machine learning based approaches. In this paper, we focus on application of machine learning techniques in the context of Volume Diagnosis methodology which aims at improving the yield analysis and management process. Specifically, we apply machine learning to monitor and predict throughput bottlenecks in diagnosis process that impede the pace of yield analysis. In the proposed supervised machine learning technique, diagnosis features extracted from thousands of devices are used to train a random forest regression model and features causing greatest impact on run times are predicted. This technique has resulted in identifying a class of faults (labelled "hyperactive faults") to be strongly correlated to diagnosis run time. Based on this finding, we propose improvements to volume diagnosis methodology to identify and mask hyperactive faults in advance from volume diagnosis process. Experimental results using proposed improvements on large industrial designs demonstrate up to similar to 38% reduction in volume diagnosis run time with no loss of accuracy and resolution.
C1 [Chillarige, Sameer; Malik, Anil; Amodeo, Martin; Chabbra, Atul; Nandakumar, Bharath] Cadence Design Syst, Noida, India.
   [Redburn, Robert; Esperance, Nicholai L'; Zimmerman, Jeff; Wheelock, Adisun] IBM Corp, Burlington, VT USA.
RP Chillarige, S (corresponding author), Cadence Design Syst, Noida, India.
NR 21
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-7458-7
PY 2020
BP 1
EP 8
PG 8
WC Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering
GA BS4KK
UT WOS:000719815200001
DA 2022-04-17
ER

PT J
AU Schran, C
   Thiemann, FL
   Rowe, P
   Muller, EA
   Marsalek, O
   Michaelides, A
AF Schran, Christoph
   Thiemann, Fabian L.
   Rowe, Patrick
   Muller, Erich A.
   Marsalek, Ondrej
   Michaelides, Angelos
TI Machine learning potentials for complex aqueous made
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
LA English
DT Article
DE machine learning potentials; solid-liquid systems; aqueous phase
ID LIQUID WATER; SURFACE; SIMULATIONS; INTERFACES; DYNAMICS
AB Simulation techniques based on accurate and efficient repre-sentations of potential energy surfaces are urgently needed for the understanding of complex systems such as solid-liquid interfaces. Here we present a machine learning framework that enables the efficient development and validation of models for complex aqueous systems. Instead of trying to deliver a glob-ally optimal machine learning potential, we propose to develop models applicable to specific thermodynamic state points in a simple and user-friendly process. After an initial ab initio simu-lation, a machine learning potential is constructed with minimum human effort through a data-driven active learning protocol. Such models can afterward be applied in exhaustive simulations to provide reliable answers for the scientific question at hand or to systematically explore the thermal performance of ab initio methods. We showcase this methodology on a diverse set of aqueous systems comprising bulk water with different ions in solution, water on a titanium dioxide surface, and water con -fined in nanotubes and between molybdenum disulfide sheets. Highlighting the accuracy of our approach with respect to the underlying ab initio reference, the resulting models are evalu-ated in detail with an automated validation protocol that includes structural and dynamical properties and the precision of the force prediction of the models. Finally, we demonstrate the capa-bilities of our approach for the description of water on the rutile titanium dioxide (110) surface to analyze the structure and mobility of water on this surface. Such machine learning models provide a straightforward and uncomplicated but accu-rate extension of simulation time and length scales for complex systems.
C1 [Schran, Christoph; Thiemann, Fabian L.; Rowe, Patrick; Michaelides, Angelos] Univ Cambridge, Yusuf Hamied Dept Chem, Cambridge CB2 1EW, England.
   [Schran, Christoph; Thiemann, Fabian L.; Rowe, Patrick; Michaelides, Angelos] UCL, Thomas Young Ctr, London WC1E 6BT, England.
   [Schran, Christoph; Thiemann, Fabian L.; Rowe, Patrick; Michaelides, Angelos] UCL, London Ctr Nanotechnol, London WC1E 6BT, England.
   [Schran, Christoph; Thiemann, Fabian L.; Rowe, Patrick; Michaelides, Angelos] UCL, Dept Phys & Astron, London WC1E 6BT, England.
   [Muller, Erich A.] Imperial Coll London, Sargent Ctr Proc Syst Engn, Dept Chem Engn, London SW7 2AZ, England.
   [Marsalek, Ondrej] Charles Univ Prague, Fac Math & Phys, Prague 12116 2, Czech Republic.
RP Schran, C; Michaelides, A (corresponding author), Univ Cambridge, Yusuf Hamied Dept Chem, Cambridge CB2 1EW, England.; Schran, C; Michaelides, A (corresponding author), UCL, Thomas Young Ctr, London WC1E 6BT, England.; Schran, C; Michaelides, A (corresponding author), UCL, London Ctr Nanotechnol, London WC1E 6BT, England.; Schran, C; Michaelides, A (corresponding author), UCL, Dept Phys & Astron, London WC1E 6BT, England.
EM cs2121@cam.ac.uk; am452@cam.ac.uk
OI Michaelides, Angelos/0000-0002-9169-169X; Marsalek,
   Ondrej/0000-0002-8624-8837; Thiemann, Fabian/0000-0003-2951-6740;
   Schran, Christoph/0000-0003-4595-5073
FU Alexander von Humboldt-StiftungAlexander von Humboldt Foundation;
   Operational Programme Research, Development and Education project,
   International Mobility of Researchers at Charles University (Marie
   Skodowska-Curie Individual Fellowships II) [CZ.02.2.69/0.0/0.0/18
   070/0010462]; Engineering and Physical Sciences Research Council
   (EPSRC)UK Research & Innovation (UKRI)Engineering & Physical Sciences
   Research Council (EPSRC) [EP/P020194/1, EP/T022213/1, EP/P022561/1]
FX We thank Christopher Penschke for providing the water TiO2 AIMD
   trajectory. C.S. acknowledges partial financial support from the
   Alexander von Humboldt-Stiftung. This work was partially supported by
   the Operational Programme Research, Development and Education project
   (CZ.02.2.69/0.0/0.0/18 070/0010462) , International Mobility of
   Researchers at Charles University (Marie Skodowska-Curie Individual
   Fel-lowships II) . We are grateful to the UK Materials and Molecular
   Modelling Hub for computational resources, which is partially funded by
   Engineering and Physical Sciences Research Council (EPSRC) (grants
   EP/P020194/1 and EP/T022213/1) . We are also grateful for computational
   support from the UK national high-performance computing service,
   Advanced Research Comput-ing High End Resource (ARCHER) , for which
   access was obtained via the UK Car-Parrinello consortium, funded by
   EPSRC grant reference EP/P022561/1.
NR 76
TC 5
Z9 5
U1 22
U2 27
PU NATL ACAD SCIENCES
PI WASHINGTON
PA 2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA
SN 0027-8424
J9 P NATL ACAD SCI USA
JI Proc. Natl. Acad. Sci. U. S. A.
PD SEP 13
PY 2021
VL 118
IS 38
AR e2110077118
DI 10.1073/pnas.2110077118
PG 8
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA UZ4BH
UT WOS:000702151600016
PM 34518232
OA Green Published, Green Submitted, hybrid
DA 2022-04-17
ER

PT C
AU Shobana, G
   Umamaheswari, K
AF Shobana, G.
   Umamaheswari, K.
GP IEEE
TI Forecasting by Machine Learning Techniques and Econometrics: A Review
SO PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION
   TECHNOLOGIES (ICICT 2021)
LA English
DT Proceedings Paper
CT 6th International Conference on Inventive Computation Technologies
   (ICICT)
CY JAN 20-22, 2021
CL Coimbatore, INDIA
SP IEEE, SVR Tech Campus
DE Econometrics; Economic Data; Machine Learning; Supervised; Unsupervised
AB Econometricians deal with a tremendous amount of data to derive the relationships between economic entities. When statistical techniques are applied to the economic data to determine the relative economic entities with verifiable observations, this quantitative analysis is termed Econometrics. Traditional Econometric methods employ pure statistical and mathematical concepts to analyze economic data. Applied Econometrics deals with exploring real-world observations like forecasting, fluctuating market prices, economic outcomes or results, etc. In recent years, Machine Learning models are applied to quantitative data available in almost all domains. Machine Learning Models perform very efficiently in the classification process and it is used in the field of economics to classify the economic data more accurately than traditional econometric models. In this paper, several machine learning methods that are specifically used for economic data are explored. This paper further investigates the various Supervised machine learning techniques that contribute effectively along with metrics that are involved in the analysis procedure of econometric models. This study provides deep insight into those machine learning models preferred by the Econometricians and their future implications.
C1 [Shobana, G.] Madras Christian Coll, Dept Comp Applicat, Chennai, Tamil Nadu, India.
   [Umamaheswari, K.] Bharathi Womens Coll, Dept Comp Sci, Chennai, Tamil Nadu, India.
RP Shobana, G (corresponding author), Madras Christian Coll, Dept Comp Applicat, Chennai, Tamil Nadu, India.
EM gmshobana@gmail.com; uma.tvr1981@gmail.com
RI K, Umamaheswari/AAF-6740-2021; G, Shobana/ABD-6189-2020
OI K, Umamaheswari/0000-0002-5279-6659; G, Shobana/0000-0001-7131-3141
NR 20
TC 3
Z9 3
U1 4
U2 4
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-8501-9
PY 2021
BP 1010
EP 1016
DI 10.1109/ICICT50816.2021.9358514
PG 7
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BS4RZ
UT WOS:000722293800170
DA 2022-04-17
ER

PT J
AU Cifuentes, J
   Marulanda, G
   Bello, A
   Reneses, J
AF Cifuentes, Jenny
   Marulanda, Geovanny
   Bello, Antonio
   Reneses, Javier
TI Air Temperature Forecasting Using Machine Learning Techniques: A Review
SO ENERGIES
LA English
DT Review
DE air temperature forecasting; artificial intelligence; machine learning;
   neural networks; support vector machines
ID ARTIFICIAL NEURAL-NETWORKS; SUPPORT VECTOR MACHINE; CLIMATE-CHANGE;
   SURFACE TEMPERATURES; TIME-SERIES; PREDICTION; ENSEMBLE; MODELS;
   REGRESSION; ACCURACY
AB Efforts to understand the influence of historical climate change, at global and regional levels, have been increasing over the past decade. In particular, the estimates of air temperatures have been considered as a key factor in climate impact studies on agricultural, ecological, environmental, and industrial sectors. Accurate temperature prediction helps to safeguard life and property, playing an important role in planning activities for the government, industry, and the public. The primary aim of this study is to review the different machine learning strategies for temperature forecasting, available in the literature, presenting their advantages and disadvantages and identifying research gaps. This survey shows that Machine Learning techniques can help to accurately predict temperatures based on a set of input features, which can include the previous values of temperature, relative humidity, solar radiation, rain and wind speed measurements, among others. The review reveals that Deep Learning strategies report smaller errors (Mean Square Error = 0.0017 degrees K) compared with traditional Artificial Neural Networks architectures, for 1 step-ahead at regional scale. At the global scale, Support Vector Machines are preferred based on their good compromise between simplicity and accuracy. In addition, the accuracy of the methods described in this work is found to be dependent on inputs combination, architecture, and learning algorithms. Finally, further research areas in temperature forecasting are outlined.
C1 [Cifuentes, Jenny] Univ Carlos III Madrid, Santander Big Data Inst, Getafe 28903, Spain.
   [Marulanda, Geovanny; Bello, Antonio; Reneses, Javier] Comillas Pontifical Univ, Inst Res Technol IIT, ICAI Sch Engn, Madrid 28015, Spain.
RP Marulanda, G (corresponding author), Comillas Pontifical Univ, Inst Res Technol IIT, ICAI Sch Engn, Madrid 28015, Spain.
EM jcifuent@inst.uc3m.es; geovanny.marulanda@iit.comillas.edu;
   antonio.bello@iit.comillas.edu; javier.reneses@iit.comillas.edu
RI Reneses, Javier/ABF-7460-2020; Cifuentes, Alexandra/T-5044-2019; Bello,
   Antonio/ABF-5808-2020; Marulanda, Geovanny/AAB-5299-2021; Marulanda,
   Geovanny/AAA-4221-2022; Marulanda, Geovanny/AAB-5301-2021
OI Cifuentes, Alexandra/0000-0001-7421-291X; Bello,
   Antonio/0000-0002-7675-7021; Marulanda, Geovanny/0000-0002-7799-9890;
   Marulanda, Geovanny/0000-0002-7799-9890; Reneses,
   Javier/0000-0001-5919-491X
NR 94
TC 19
Z9 19
U1 21
U2 35
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1996-1073
J9 ENERGIES
JI Energies
PD AUG
PY 2020
VL 13
IS 16
AR 4215
DI 10.3390/en13164215
PG 28
WC Energy & Fuels
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Energy & Fuels
GA NM6GI
UT WOS:000568193500001
OA gold
DA 2022-04-17
ER

PT J
AU Vartiainen, H
   Tedre, M
   Kahila, J
   Valtonen, T
AF Vartiainen, Henriikka
   Tedre, Matti
   Kahila, Juho
   Valtonen, Teemu
TI Tensions and trade-offs of participatory learning in the age of machine
   learning
SO EDUCATIONAL MEDIA INTERNATIONAL
LA English
DT Article
DE Machine learning; participatory learning; computational thinking; media
   education
ID SELF
AB While much has been written about the personal, social, and democratic benefits of networked communities and participatory learning, critics have begun to draw attention to the ubiquitous data collection and computational processes behind mass user platforms. Personal and behavioral data have become valuable material for statistical and machine learning techniques that have the potential to profile, infer, and predict people's needs, values, and behavior. As a response, researchers are calling for data literacies and computational thinking to facilitate people's capacity and volition to make informed actions in their digital world. Yet, efforts and curricula towards a greater understanding of computational mechanisms of new media ecology are sorely missing from K12-education as well as from teacher education. This paper provides an overview of tensions that teachers and educators will face when they attempt to bridge participatory learning with a more robust understanding of machine learning and algorithmic production of social and cultural practices.
C1 [Vartiainen, Henriikka; Kahila, Juho; Valtonen, Teemu] Univ Eastern Finland, Sch Appl Educ Sci & Teacher Educ, Joensuu, Finland.
   [Tedre, Matti] Univ Eastern Finland, Sch Comp, Joensuu, Finland.
RP Vartiainen, H (corresponding author), Univ Eastern Finland, Kuopio, Finland.
EM henriikka.vartiainen@uef.fi
OI Kahila, Juho/0000-0002-9913-0627
NR 58
TC 1
Z9 1
U1 3
U2 5
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0952-3987
EI 1469-5790
J9 EDUC MEDIA INT
JI Educ. Media Int.
PY 2020
VL 57
IS 4
BP 285
EP 298
DI 10.1080/09523987.2020.1848512
PG 14
WC Education & Educational Research
WE Emerging Sources Citation Index (ESCI)
SC Education & Educational Research
GA PN2MH
UT WOS:000604318300001
OA hybrid
DA 2022-04-17
ER

PT C
AU Shan, RC
   Youssef, A
AF Shan, Ruocheng
   Youssef, Abdou
BE Kamareddine, F
   Coen, CS
TI Towards Math Terms Disambiguation Using Machine Learning
SO INTELLIGENT COMPUTER MATHEMATICS (CICM 2021)
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 14th International Conference on Intelligent Computer Mathematics (CICM)
CY JUL 26-31, 2021
CL ELECTR NETWORK
DE Math-term; LATEX; Disambiguation; Mathematical equations; Machine
   Learning
AB Word disambiguation has been an important task in natural language processing. However, the problem of disambiguation is still less explored in mathematical text. Similar to natural languages, some math terms are not assigned a unique interpretation. As math text is an important part of the scientific literature, an accurate and efficient way of performing disambiguation of math terms will be a significant contribution. In this paper, we present some investigations on math-term disambiguation using machine learning. All experimental data are selected from the DLMF dataset. Our experiments consist of 3 steps: (1) create a labeled dataset of math equations (from the DLMF) where the instances are (math token, token meaning) pairs, grouped by equation; (2) build machine learning models and train them using our labeled dataset, and (3) evaluate and compare the performance of our models using different evaluation metrics. Our results show that machine learning is an effective approach to math-term disambiguation. The accuracy of our models ranges from 70% to 85%. There is potential for considerable improvements once we have much larger labeled datasets with more balanced classes.
C1 [Shan, Ruocheng; Youssef, Abdou] George Washington Univ, Washington, DC 20052 USA.
RP Shan, RC (corresponding author), George Washington Univ, Washington, DC 20052 USA.
EM shanruocheng@gwu.edu; ayoussef@gwu.edu
NR 21
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-81097-9; 978-3-030-81096-2
J9 LECT NOTES ARTIF INT
PY 2021
VL 12833
BP 90
EP 106
DI 10.1007/978-3-030-81097-9_7
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods; Mathematics, Applied; Logic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Mathematics; Science & Technology - Other Topics
GA BS2VL
UT WOS:000707054900007
DA 2022-04-17
ER

PT C
AU Wang, T
   Koch, P
   Wujek, B
   Liu, J
   Li, H
AF Wang, Tao
   Koch, Patrick
   Wujek, Brett
   Liu, Jun
   Li, Hai
GP ASSOC COMP MACHINERY
TI The Fifth International Workshop on Automation in Machine Learning
SO KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE
   DISCOVERY & DATA MINING
LA English
DT Proceedings Paper
CT 27th ACM SIGKDD International Conference on Knowledge Discovery and Data
   Mining (KDD)
CY AUG 14-18, 2021
CL ELECTR NETWORK
SP Assoc Comp Machinery, ACM SIGMOD, ACM SIGKDD
DE Machine learning; Automation; Hyperparameter Optimization; Neural
   Architecture Search
AB The Fifth International Workshop on Automation in Machine Learning aims to identify opportunities and challenges for automation in machine learning, to provide an opportunity for researchers to discuss best practices for automation in machine learning potentially leading to definition of standards, and to provide a forum for researchers to speak out and debate on different ideas in automation in machine learning. The workshop agenda includes four invited keynote speakers and four accepted paper presentations chosen from a peer review process. A panel discussion will close out the workshop to allow for an engaging and interactive exchange of thoughts and ideas on AutoML.
C1 [Wang, Tao] Stats Perform, Cary, NC 27513 USA.
   [Koch, Patrick; Wujek, Brett] SAS Inst Inc, Cary, NC USA.
   [Liu, Jun] Infina ML, Durham, NC USA.
   [Li, Hai] Duke Univ, Durham, NC USA.
RP Wang, T (corresponding author), Stats Perform, Cary, NC 27513 USA.
EM taowang.gml@gmail.com; patrick.koch@sas.com; brett.wujek@sas.com;
   jun.liu@infiniaml.com; hai.li@duke.edu
NR 0
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-8332-5
PY 2021
BP 4163
EP 4164
DI 10.1145/3447548.3469452
PG 2
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS6LU
UT WOS:000749556804078
DA 2022-04-17
ER

PT J
AU Stachl, C
   Pargent, F
   Hilbert, S
   Harari, GM
   Schoedel, R
   Vaid, S
   Gosling, SD
   Buhner, M
AF Stachl, Clemens
   Pargent, Florian
   Hilbert, Sven
   Harari, Gabriella M.
   Schoedel, Ramona
   Vaid, Sumer
   Gosling, Samuel D.
   Buehner, Markus
TI Personality Research and Assessment in the Era of Machine Learning
SO EUROPEAN JOURNAL OF PERSONALITY
LA English
DT Article
DE assessment; interpretability; machine learning; overfitting; personality
ID DIGITAL FOOTPRINTS; SOCIAL MEDIA; IRT MODELS; TRAITS; ACCURATE; STYLE
AB The increasing availability of high-dimensional, fine-grained data about human behaviour, gathered from mobile sensing studies and in the form of digital footprints, is poised to drastically alter the way personality psychologists perform research and undertake personality assessment. These new kinds and quantities of data raise important questions about how to analyse the data and interpret the results appropriately. Machine learning models are well suited to these kinds of data, allowing researchers to model highly complex relationships and to evaluate the generalizability and robustness of their results using resampling methods. The correct usage of machine learning models requires specialized methodological training that considers issues specific to this type of modelling. Here, we first provide a brief overview of past studies using machine learning in personality psychology. Second, we illustrate the main challenges that researchers face when building, interpreting, and validating machine learning models. Third, we discuss the evaluation of personality scales, derived using machine learning methods. Fourth, we highlight some key issues that arise from the use of latent variables in the modelling process. We conclude with an outlook on the future role of machine learning models in personality research and assessment.
C1 [Stachl, Clemens; Harari, Gabriella M.; Vaid, Sumer] Stanford Univ, Dept Commun, Stanford, CA 94305 USA.
   [Pargent, Florian; Schoedel, Ramona; Buehner, Markus] Ludwig Maximilians Univ Munchen, Dept Psychol Psychol Methods & Assessment, Munich, Germany.
   [Hilbert, Sven] Univ Regensburg, Fac Psychol Educ Sci & Sport Sci, Regensburg, Germany.
   [Gosling, Samuel D.] Univ Texas Austin, Dept Psychol, Austin, TX 78712 USA.
   [Gosling, Samuel D.] Univ Melbourne, Melbourne Sch Psychol Sci, Melbourne, Vic, Australia.
RP Stachl, C (corresponding author), Stanford Univ, Dept Commun, Stanford, CA 94305 USA.
EM stachl@stanford.edu
RI Stachl, Clemens/ABD-9949-2021
OI Stachl, Clemens/0000-0002-4498-3067
NR 139
TC 19
Z9 19
U1 11
U2 15
PU JOHN WILEY & SONS LTD
PI CHICHESTER
PA THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND
SN 0890-2070
EI 1099-0984
J9 EUR J PERSONALITY
JI Eur. J. Personal.
PD SEP
PY 2020
VL 34
IS 5
SI SI
BP 613
EP 631
DI 10.1002/per.2257
EA MAY 2020
PG 19
WC Psychology, Social
WE Social Science Citation Index (SSCI)
SC Psychology
GA OL4VF
UT WOS:000535945200001
OA Green Published, Green Accepted, Green Submitted
DA 2022-04-17
ER

PT C
AU Naiyer, V
   Sheetlani, J
   Singh, HP
AF Naiyer, Vaseem
   Sheetlani, Jitendra
   Singh, Harsh Pratap
BE Satapathy, SC
   Bhateja, V
   Mohanty, JR
   Udgata, SK
TI Software Quality Prediction Using Machine Learning Application
SO SMART INTELLIGENT COMPUTING AND APPLICATIONS, VOL 2
SE Smart Innovation Systems and Technologies
LA English
DT Proceedings Paper
CT 3rd International Conference on Smart Computing and Informatics (SCI)
CY DEC 21-22, 2018
CL Bhubaneswar, INDIA
SP Kalinga Inst Ind Technol, Sch Comp Engn, Kalinga Inst Ind Technol, Sch Comp Applicat, KES Int
DE Software quality; Bayesian classifier; Machine learning; Quality model;
   Genetic algorithm
AB Machine learning is one of the applications of AI which enables analysis of massive quantities of data. While it generally delivers quicker, more precise results in order to recognize profitable opportunities or hazardous risks, it may also entail additional time and resources to train it appropriately. This paper presents the survey of machine learning application in the development of software quality. Development of software quality becomes more important in real world scenario but lots of work done by various author for this. In this we discuss various machine learning techniques such as Bayesian classifier, Neural Network, decision tree and genetic algorithm etc. which helps the researchers for the better prediction of software quality.
C1 [Naiyer, Vaseem; Sheetlani, Jitendra; Singh, Harsh Pratap] Sri Satya Sai Univ Technol & Med Sci, Sehore, MP, India.
RP Sheetlani, J (corresponding author), Sri Satya Sai Univ Technol & Med Sci, Sehore, MP, India.
EM vaseemnaiyer@gmail.com; dr.jsheetlani@gmail.com
OI Sheetlani, Jitendra/0000-0002-5666-512X
NR 16
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 2190-3018
EI 2190-3026
BN 978-981-32-9690-9; 978-981-32-9689-3
J9 SMART INNOV SYST TEC
PY 2020
VL 160
BP 319
EP 327
DI 10.1007/978-981-32-9690-9_32
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BP2PT
UT WOS:000544256200032
DA 2022-04-17
ER

PT J
AU Butt, J
   Wieser, A
   Gojcic, Z
   Zhou, CF
AF Butt, Jemil
   Wieser, Andreas
   Gojcic, Zan
   Zhou, Caifa
TI Machine learning and geodesy: A survey
SO JOURNAL OF APPLIED GEODESY
LA English
DT Article
DE Geodesy; Adjustment theory; Machine learning; Hilbert spaces; Kernel
   methods
AB The goal of classical geodetic data analysis is often to estimate distributional parameters like expected values and variances based on measurements that are subject to uncertainty due to unpredictable environmental effects and instrument specific noise. Its traditional roots and focus on analytical solutions at times require strong prior assumptions regarding problem specification and underlying probability distributions that preclude successful application in practical cases for which the goal is not regression in presence of Gaussian noise.
   Machine learning methods are more flexible with respect to assumed regularity of the input and the form of the desired outputs and allow for nonparametric stochastic models at the cost of substituting easily analyzable closed form solutions by numerical schemes. This article aims at examining common grounds of geodetic data analysis and machine learning and showcases applications of algorithms for supervised and unsupervised learning to tasks concerned with optimal estimation, signal separation, danger assessment and design of measurement strategies that occur frequently and naturally in geodesy.
C1 [Butt, Jemil; Wieser, Andreas; Gojcic, Zan; Zhou, Caifa] Swiss Fed Inst Technol, Inst Geodesy & Photogrammetry, Stefano Franscini Pl 5, CH-8093 Zurich, Switzerland.
RP Butt, J (corresponding author), Swiss Fed Inst Technol, Inst Geodesy & Photogrammetry, Stefano Franscini Pl 5, CH-8093 Zurich, Switzerland.
EM jemil.butt@geod.baug.ethz.ch; andreas.wieser@geod.baug.ethz.ch;
   zan.gojcic@geod.baug.ethz.ch; caifa.zhou@geod.baug.ethz.ch
NR 35
TC 0
Z9 0
U1 0
U2 1
PU WALTER DE GRUYTER GMBH
PI BERLIN
PA GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY
SN 1862-9016
EI 1862-9024
J9 J APPL GEOD
JI J. Appl. Geod.
PD APR
PY 2021
VL 15
IS 2
BP 117
EP 133
DI 10.1515/jag-2020-0043
PG 17
WC Remote Sensing
WE Emerging Sources Citation Index (ESCI)
SC Remote Sensing
GA RJ0YE
UT WOS:000637328800003
OA Green Published
DA 2022-04-17
ER

PT J
AU Chen, LT
   Zhang, X
   Chen, A
   Yao, S
   Hu, X
   Zhou, Z
AF Chen, Letian
   Zhang, Xu
   Chen, An
   Yao, Sai
   Hu, Xu
   Zhou, Zhen
TI Targeted design of advanced electrocatalysts by machine learning
SO CHINESE JOURNAL OF CATALYSIS
LA English
DT Review
DE Electrocatalyst; Machine learning; Targeted design; Thermodynamics
   properties; Kinetic barrier
ID MOLECULAR-DYNAMICS SIMULATIONS; NEURAL-NETWORK POTENTIALS; FREE-ENERGY
   CALCULATIONS; FINDING SADDLE-POINTS; ELECTROCHEMICAL REDUCTION;
   CATALYTIC-ACTIVITY; OXYGEN REDUCTION; CO2 REDUCTION; SURFACE;
   CHEMISORPTION
AB Exploring the production and application of clean energy has always been the core of sustainable development. As a clean and sustainable technology, electrocatalysis has been receiving widespread attention. It is crucial to achieve efficient, stable and cheap electrocatalysts. However, the traditional "trial and error" method is time-consuming, laborious and costly. In recent years, with the signifi-cant increase in computing power, computations have played an important role in electrocatalyst design. Nevertheless, it is still difficult to search for advanced electrocatalysts in the vast chemical space through traditional density functional theory (DFT) computations. Fortunately, the develop-ment of machine learning and interdisciplinary integration will inject new impetus into targeted design of electrocatalysts. Machine learning is able to predict electrochemical performances with an accuracy close to DFT. Here we provide an overview of the application of machine learning in elec-trocatalyst design, including the prediction of structure, thermodynamic properties and kinetic barriers. We also discuss the potential of explicit solvent model combined with machine learning molecular dynamics in this field. Finally, the favorable circumstances and challenges are outlined for the future development of machine learning in electrocatalysis. The studies on electrochemical processes by machine learning will further realize targeted design of high-efficiency electrocata-lysts. (c) 2022, Dalian Institute of Chemical Physics, Chinese Academy of Sciences. Published by Elsevier B.V. All rights reserved.
C1 [Chen, Letian; Zhang, Xu; Chen, An; Yao, Sai; Hu, Xu; Zhou, Zhen] Nankai Univ, Inst New Energy Mat Chem, Sch Mat Sci & Engn, Renewable Energy Convers & Storage Ctr ReCast,Min, Tianjin 300350, Peoples R China.
   [Zhang, Xu; Zhou, Zhen] Zhengzhou Univ, Sch Chem Engn, Engn Res Ctr Adv Funct Mat, Mfg Minist Educ, Zhengzhou 450001, Henan, Peoples R China.
RP Zhang, X; Zhou, Z (corresponding author), Nankai Univ, Inst New Energy Mat Chem, Sch Mat Sci & Engn, Renewable Energy Convers & Storage Ctr ReCast,Min, Tianjin 300350, Peoples R China.; Zhang, X; Zhou, Z (corresponding author), Zhengzhou Univ, Sch Chem Engn, Engn Res Ctr Adv Funct Mat, Mfg Minist Educ, Zhengzhou 450001, Henan, Peoples R China.
EM zhangxu@nankai.edu.cn; zhenzhou@zzu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [91845112]; China Postdoctoral Science
   FoundationChina Postdoctoral Science Foundation [2019M660055]
FX This work was supported by the National Natural Science Foundation of
   China (91845112) and China Postdoctoral Science Foundation
   (2019M660055).
NR 167
TC 5
Z9 5
U1 54
U2 54
PU SCIENCE PRESS
PI BEIJING
PA 16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100717, PEOPLES R CHINA
SN 0253-9837
EI 1872-2067
J9 CHINESE J CATAL
JI Chin. J. Catal.
PD JAN
PY 2022
VL 43
IS 1
BP 11
EP 32
DI 10.1016/S1872-2067(21)63852-4
PG 22
WC Chemistry, Applied; Chemistry, Physical; Engineering, Chemical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering
GA XD3PP
UT WOS:000722623800003
DA 2022-04-17
ER

PT C
AU Borrero, LA
   Guette, LS
   Lopez, E
   Pineda, OB
   Castro, EB
AF Adriana Borrero, Luz
   Sanchez Guette, Lilibeth
   Lopez, Enrique
   Bonerge Pineda, Omar
   Buelvas Castro, Edgardo
BE Shakshuki, E
   Yasar, A
TI Predicting Toxicity Properties through Machine Learning
SO 11TH INTERNATIONAL CONFERENCE ON AMBIENT SYSTEMS, NETWORKS AND
   TECHNOLOGIES (ANT) / THE 3RD INTERNATIONAL CONFERENCE ON EMERGING DATA
   AND INDUSTRY 4.0 (EDI40) / AFFILIATED WORKSHOPS
SE Procedia Computer Science
LA English
DT Proceedings Paper
CT 11th International Conference on Ambient Systems, Networks and
   Technologies (ANT) / 3rd International Conference on Emerging Data and
   Industry 4.0 (EDI)
CY APR 06-09, 2020
CL Warsaw, POLAND
DE Supervised and unsupervised learning machines; support vector machine
   (SVM); artificial neural networks (ANN)
ID DRUG DISCOVERY
AB It is currently known that the high power of a drug does not fully determine its efficacy. Several properties must also be considered, including absorption, distribution, metabolism, excretion and toxicity [8]. These are the ADME-Tox properties, which are fundamental in the discovery of new effective and safe drugs. Since ignoring these properties is the main cause of failure in the development of new drugs, it is understandable that some techniques arise, such as machine learning, which apply some predictor variables as molecular characteristics to obtain models to determine some of these ADME-Tox properties. In silico models are booming because of the exorbitant expenses involved in discovering a new drug using traditional trial-and-error methods [2], and they have proven to be an effective approach to increase efficiency in drug discovery and development processes. The objective of this study is to analyze the best current machine learning techniques for predicting toxicity as an ADME-Tox property. (C) 2020 The Authors. Published by Elsevier B.V.
C1 [Adriana Borrero, Luz] Univ Costa, Barranquilla, Colombia.
   [Sanchez Guette, Lilibeth] Univ Simon Bolivar, Barranquilla, Colombia.
   [Lopez, Enrique] Corp Univ Minuto de Dios UNIMINUTO, Barranquilla, Colombia.
   [Bonerge Pineda, Omar] Univ Tecnol Centroamer UNTTEC, San Pedro Sula, Honduras.
   [Buelvas Castro, Edgardo] Univ Autonoma Caribe, Barranquilla, Colombia.
RP Borrero, LA (corresponding author), Univ Costa, Barranquilla, Colombia.
EM lborrero2@cuc.edu.co
NR 21
TC 0
Z9 0
U1 2
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0509
J9 PROCEDIA COMPUT SCI
PY 2020
VL 170
BP 1011
EP 1016
DI 10.1016/j.procs.2020.03.093
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ2ZA
UT WOS:000582714500139
OA gold, Green Published
DA 2022-04-17
ER

PT C
AU Lanus, E
   Freeman, LJ
   Kuhn, DR
   Kacker, RN
AF Lanus, Erin
   Freeman, Laura J.
   Kuhn, D. Richard
   Kacker, Raghu N.
GP IEEE Comp Soc
TI Combinatorial Testing Metrics for Machine Learning
SO 2021 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE TESTING, VERIFICATION AND
   VALIDATION WORKSHOPS (ICSTW 2021)
SE IEEE International Conference on Software Testing Verification and
   Validation Workshops
LA English
DT Proceedings Paper
CT 14th IEEE Conference on Software Testing, Verification and Validation
   (ICST)
CY APR 12-16, 2021
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, Opus Software, CESAR Sch, Facebook
DE combinatorial testing; machine learning; operating envelopes; transfer
   learning; test set selection
AB This paper defines a set difference metric for comparing machine learning (ML) datasets and proposes the difference between datasets be a function of combinatorial coverage. We illustrate its utility for evaluating and predicting performance of ML models. Identifying and measuring differences between datasets is of significant value for ML problems, where the accuracy of the model is heavily dependent on the degree to which training data are sufficiently representative of data encountered in application. The method is illustrated for transfer learning without retraining, the problem of predicting performance of a model trained on one dataset and applied to another.
C1 [Lanus, Erin; Freeman, Laura J.] Virginia Tech, Hume Ctr Natl Secur & Technol, Arlington, VA 22203 USA.
   [Kuhn, D. Richard; Kacker, Raghu N.] NIST, Gaithersburg, MD 20899 USA.
RP Lanus, E (corresponding author), Virginia Tech, Hume Ctr Natl Secur & Technol, Arlington, VA 22203 USA.
EM lanus@vt.edu; laura.freeman@vt.edu; kuhn@nist.gov; raghu.kacker@nist.gov
FU MITRE University Innovation Exchange program
FX Research of EL and LJF funded in part by MITRE University Innovation
   Exchange program.
NR 15
TC 2
Z9 2
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
SN 2159-4848
BN 978-1-6654-4456-9
J9 IEEE ICST WORKSHOP
PY 2021
BP 81
EP 84
DI 10.1109/ICSTW52544.2021.00025
PG 4
WC Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS0BO
UT WOS:000680833800012
DA 2022-04-17
ER

PT J
AU Shakirov, MA
AF Shakirov, M. A.
TI Calibrating optical spectra using machine learning algorithms
SO MAGNETIC RESONANCE IN SOLIDS
LA English
DT Article
DE machine learning; random forest; TDDFT; semi-empirical calculations;
   spectroscopy
ID RANDOM FOREST; REGRESSION; ZINDO/S
AB We suggest an approach using machine learning random forest algorithms to comparing and calibrating the results of calculations of transition energies in organic molecules by ZINDO/S (Zerner's intermediate neglect of differential overlap) and TDDFT (time-dependent density-functional theory) methods. We show how our machine learning model, trained on a relatively small data set can improve the results of semi-empirical methods and obtain absorption spectra comparable to TDDFT calculations.
C1 [Shakirov, M. A.] Kazan Fed Univ, Kremlevskaya 18, Kazan 420008, Russia.
RP Shakirov, MA (corresponding author), Kazan Fed Univ, Kremlevskaya 18, Kazan 420008, Russia.
EM mars.shakirov@gmail.com
FU Ministry of Science and Higher Education of the Russian Federation
   [3.2166.2017]
FX This work was supported by the subsidy of the Ministry of Science and
   Higher Education of the Russian Federation (3.2166.2017) allocated to
   Kazan Federal University for performing the project part of the state
   assignment in the area of scientific activities. Author especially
   thankful to Dr. Semion Saikin and Prof. Dr. Yurii Proshin for valuable
   discussions. Author grateful to Prof. Dr. Stephan Gekle and all members
   of the Bio~uid Simulation and Modeling group at Bayreuth University for
   providing an internship and sharing knowledge.
NR 37
TC 0
Z9 0
U1 1
U2 4
PU KAZAN FEDERAL UNIV
PI KAZAN
PA UL KREMLYOVSKAYA, 18, KAZAN, 420008, RUSSIA
SN 2072-5981
J9 MAGN RESON SOLIDS
JI Magn. Reson. Solids
PY 2020
VL 22
IS 1
AR 20102
DI 10.26907/mrsej-20102
PG 11
WC Physics, Atomic, Molecular & Chemical
WE Emerging Sources Citation Index (ESCI)
SC Physics
GA LL4BN
UT WOS:000531501000002
OA gold
DA 2022-04-17
ER

PT J
AU Zmuk, B
   Josic, H
AF Zmuk, Berislav
   Josic, Hrvoje
TI FORECASTING STOCK MARKET INDICES USING MACHINE LEARNING ALGORITHMS
SO INTERDISCIPLINARY DESCRIPTION OF COMPLEX SYSTEMS
LA English
DT Article
DE machine learning; neural networks; stock market indices prediction
AB In recent years machine learning algorithms have become a very popular tool for analysing financial data and forecasting stock prices. The goal of this article is to forecast five major stock market indexes (DAX, Dow Jones, NASDAQ, Nikkei 225 and S&P 500) using machine learning algorithms (Linear regression, Gaussian Processes, SMOreg and neural network Multilayer Perceptron) on historical data covering the period February 1, 2010, to January 31, 2020. The forecasts were made by using historical data in different base period lengths and forecasting horizons. The precision of machine learning algorithms was evaluated with the help of error metrics. The results of the analysis have shown that machine learning algorithms achieved highly accurate forecasting performance. The overall precision of all algorithms was better for shorter base period lengths and forecast horizons. The results obtained from this analysis could help investors in determining their optimal investment strategy. Stock price prediction remains, however, one of the most complex issues in the field of finance.
C1 [Zmuk, Berislav; Josic, Hrvoje] Univ Zagreb, Fac Econ & Business, Zagreb, Croatia.
RP Zmuk, B (corresponding author), Fac Econ & Business, JF Kennedy Sq 6, HR-10000 Zagreb, Croatia.
EM bzmuk@efzg.hr
NR 25
TC 0
Z9 0
U1 10
U2 15
PU CROATIAN INTERDISCIPLINARY SOC
PI SESVETE
PA SIMUNCEVECKA 38B, SESVETE, HR-10360, CROATIA
SN 1334-4684
EI 1334-4676
J9 INTERDISCIP DESCR CO
JI Interdiscip. Descr. Complex Syst.
PY 2020
VL 18
IS 4
BP 471
EP 489
DI 10.7906/indecs.18.4.7
PG 19
WC Social Sciences, Interdisciplinary
WE Emerging Sources Citation Index (ESCI)
SC Social Sciences - Other Topics
GA OM4VX
UT WOS:000586025600006
OA Green Submitted, Green Published, gold
DA 2022-04-17
ER

PT J
AU Wang, JQ
   Prabhat, B
   Shakil, M
AF Wang Jinqiang
   Prabhat, Basnet
   Shakil, Mahtab
TI Review of machine learning and deep learning application in mine
   microseismic event classification
SO MINING OF MINERAL DEPOSITS
LA English
DT Reprint
DE rock burst; MS event; blasting event; noise event; machine learning;
   deep learning
ID AUTOMATIC CLASSIFICATION; SEISMIC EVENTS; NEURAL-NETWORK; SIGNALS;
   BLASTS; IDENTIFICATION; VOLCANO
AB Purpose. To put forward the concept of machine learning and deep learning approach in Mining Engineering in order to get high accuracy in separating mine microseismic (MS) event from non-useful events such as noise events blasting events and others.
   Methods. Traditionally applied methods are described and their low impact on classifying MS events is discussed. General historical description of machine learning and deep learning methods is shortly elaborated and different approaches conducted using these methods for classifying MS events are analysed.
   Findings. Acquired MS data from rock fracturing process recorded by sensors are inaccurate due to complex mining environment. They always need preprocessing in order to classify actual seismic events. Traditional detecting and classifying methods do not always yield precise results, which is especially disappointing when different events have a similar nature. The breakthrough of machine learning and deep learning methods made it possible to classify various MS events with higher precision compared to the traditional one. This paper introduces a state-of-the-art review of the application of machine learning and deep learning in identifying mine MS events.
   Originality. Previously adopted methods are discussed in short, and a brief historical outline of Machine learning and deep learning development is presented. The recent advancement in discriminating MS events from other events is discussed in the context of these mechanisms, and finally conclusions and suggestions related to the relevant field are drawn.
   Practical implications. By means of machin learning and deep learning technology mine microseismic events can be identified accurately which allows to determine the source location so as to prevent rock burst.
C1 [Wang Jinqiang; Prabhat, Basnet] Univ Sci & Technol Beijing, Sch Civil & Resource Engn, Beijing 10083, Peoples R China.
   [Shakil, Mahtab] Tongji Univ, Dept Geotech Engn, Coll Civil Engn, Shanghai 200092, Peoples R China.
RP Wang, JQ; Prabhat, B (corresponding author), Univ Sci & Technol Beijing, Sch Civil & Resource Engn, Beijing 10083, Peoples R China.; Shakil, M (corresponding author), Tongji Univ, Dept Geotech Engn, Coll Civil Engn, Shanghai 200092, Peoples R China.
EM prabhat@126.com
OI Uddin, Mohammad Mahtab/0000-0003-4799-6813
FU research team of Mining System Engineering [52074022]; National Natural
   Science Foundation of ChinaNational Natural Science Foundation of China
   (NSFC) [52074022]
FX This work has been performed under the acknowledged support of the
   research team of Mining System Engineering and National Natural Science
   Foundation of China, working in big data oriented safety hazard
   identification and accident evolution mechanism of metal underground
   mines, 52074022.
NR 71
TC 1
Z9 1
U1 8
U2 19
PU NATL MINING UNIV
PI DNIPROPETROVSK
PA PR KARLA MARKSA 19, DNIPROPETROVSK, 49005, UKRAINE
SN 2415-3435
EI 2415-3443
J9 MIN MINER DEPOSITS
JI Min. Miner. Deposits
PY 2021
VL 15
IS 1
BP 19
EP 26
DI 10.33271/mining15.01.019
PG 8
WC Mining & Mineral Processing
WE Emerging Sources Citation Index (ESCI)
SC Mining & Mineral Processing
GA QU1HP
UT WOS:000627034500003
OA hybrid
DA 2022-04-17
ER

PT J
AU Chen, LY
   Li, JT
   Chang, MM
AF Chen, Liuyuan
   Li, Juntao
   Chang, Mingming
TI Cancer Diagnosis and Disease Gene Identification via Statistical Machine
   Learning
SO CURRENT BIOINFORMATICS
LA English
DT Review
DE Cancer diagnosis; gene selection; machine learning; support vector
   machine; lasso; group lasso
ID SUPPORT VECTOR MACHINES; FEATURE-SELECTION; MICROARRAY CLASSIFICATION;
   VARIABLE SELECTION; PREDICTION; REGRESSION; REGULARIZATION
AB Diagnosing cancer and identifying the disease gene by using DNA microarray gene expression data are the hot topics in current bioinformatics. This paper is devoted to the latest development in cancer diagnosis and gene selection via statistical machine learning. A support vector machine is firstly introduced for the binary cancer diagnosis. Then, 1-norm support vector machine, doubly regularized support vector machine, adaptive huberized support vector machine and other extensions are presented to improve the performance of gene selection. Lasso, elastic net, partly adaptive elastic net, group lasso, sparse group lasso, adaptive sparse group lasso and other sparse regression methods are also introduced for performing simultaneous binary cancer classification and gene selection. In addition to introducing three strategies for reducing multiclass to binary, methods of directly considering all classes of data in a learning model (multi_class support vector, sparse multinomial regression, adaptive multinomial regression and so on) are presented for performing multiple cancer diagnosis. Limitations and promising directions are also discussed.
C1 [Chen, Liuyuan; Li, Juntao; Chang, Mingming] Henan Normal Univ, Journal Editorial Off, Xinxiang 453007, Henan, Peoples R China.
   [Chen, Liuyuan; Li, Juntao] Henan Normal Univ, Coll Math & Informat Sci, Henan Engn Lab Big Data Stat Anal & Optimal Contr, Xinxiang 453007, Henan, Peoples R China.
RP Chen, LY; Li, JT (corresponding author), Henan Normal Univ, Journal Editorial Off, Xinxiang 453007, Henan, Peoples R China.; Chen, LY; Li, JT (corresponding author), Henan Normal Univ, Coll Math & Informat Sci, Henan Engn Lab Big Data Stat Anal & Optimal Contr, Xinxiang 453007, Henan, Peoples R China.
EM lkxbcly@126.com; juntaolimail@126.com
FU Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [61203293]; Foundation of Henan Educational Committee
   [18A520015]
FX This work was supported by the Natural Science Foundation of China
   (No.61203293), Foundation of Henan Educational Committee (No.18A520015).
NR 63
TC 7
Z9 7
U1 21
U2 31
PU BENTHAM SCIENCE PUBL LTD
PI SHARJAH
PA EXECUTIVE STE Y-2, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB
   EMIRATES
SN 1574-8936
EI 2212-392X
J9 CURR BIOINFORM
JI Curr. Bioinform.
PY 2020
VL 15
IS 9
BP 956
EP 962
DI 10.2174/1574893615666200207094947
PG 7
WC Biochemical Research Methods; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Mathematical & Computational Biology
GA QD0GW
UT WOS:000615207700002
DA 2022-04-17
ER

PT J
AU Zhang, Z
   Flores, P
   Igathinathane, C
   Naik, DL
   Kiran, R
   Ransom, JK
AF Zhang, Zhao
   Flores, Paulo
   Igathinathane, C.
   Naik, Dayakar L.
   Kiran, Ravi
   Ransom, Joel K.
TI Wheat Lodging Detection from UAS Imagery Using Machine Learning
   Algorithms
SO REMOTE SENSING
LA English
DT Article
DE precision agriculture; field crops; machine learning; deep learning;
   image processing; textural features
ID SUPPORT VECTOR MACHINE; YIELD; RICE; CLASSIFICATION; REFLECTANCE;
   INDEXES; SURFACE; HEIGHT
AB The current mainstream approach of using manual measurements and visual inspections for crop lodging detection is inefficient, time-consuming, and subjective. An innovative method for wheat lodging detection that can overcome or alleviate these shortcomings would be welcomed. This study proposed a systematic approach for wheat lodging detection in research plots (372 experimental plots), which consisted of using unmanned aerial systems (UAS) for aerial imagery acquisition, manual field evaluation, and machine learning algorithms to detect the occurrence or not of lodging. UAS imagery was collected on three different dates (23 and 30 July 2019, and 8 August 2019) after lodging occurred. Traditional machine learning and deep learning were evaluated and compared in this study in terms of classification accuracy and standard deviation. For traditional machine learning, five types of features (i.e. gray level co-occurrence matrix, local binary pattern, Gabor, intensity, and Hu-moment) were extracted and fed into three traditional machine learning algorithms (i.e., random forest (RF), neural network, and support vector machine) for detecting lodged plots. For the datasets on each imagery collection date, the accuracies of the three algorithms were not significantly different from each other. For any of the three algorithms, accuracies on the first and last date datasets had the lowest and highest values, respectively. Incorporating standard deviation as a measurement of performance robustness, RF was determined as the most satisfactory. Regarding deep learning, three different convolutional neural networks (simple convolutional neural network, VGG-16, and GoogLeNet) were tested. For any of the single date datasets, GoogLeNet consistently had superior performance over the other two methods. Further comparisons between RF and GoogLeNet demonstrated that the detection accuracies of the two methods were not significantly different from each other (p > 0.05); hence, the choice of any of the two would not affect the final detection accuracies. However, considering the fact that the average accuracy of GoogLeNet (93%) was larger than RF (91%), it was recommended to use GoogLeNet for wheat lodging detection. This research demonstrated that UAS RGB imagery, coupled with the GoogLeNet machine learning algorithm, can be a novel, reliable, objective, simple, low-cost, and effective (accuracy > 90%) tool for wheat lodging detection.
C1 [Zhang, Zhao; Flores, Paulo; Igathinathane, C.] North Dakota State Univ, Dept Agr & Biosyst Engn, Fargo, ND 58102 USA.
   [Naik, Dayakar L.; Kiran, Ravi] North Dakota State Univ, Dept Civil & Environm Engn, Fargo, ND 58105 USA.
   [Ransom, Joel K.] North Dakota State Univ, Dept Plant Sci, Fargo, ND 58108 USA.
RP Zhang, Z (corresponding author), North Dakota State Univ, Dept Agr & Biosyst Engn, Fargo, ND 58102 USA.
EM zhao.zhang.1@ndsu.edu; paulo.flores@ndsu.edu;
   Igathinathane.Cannayen@ndsu.edu; dayakarnaik.lavadiya@ndsu.edu;
   ravi.kiran@ndsu.edu; joel.ransom@ndsu.edu
OI Yellavajjala, Ravi Kiran/0000-0001-8300-0767; zhang,
   zhao/0000-0002-8577-8043
FU United States Department of Agriculture (USDA)United States Department
   of Agriculture (USDA)
FX This research is financially supported by the United States Department
   of Agriculture (USDA).
NR 64
TC 18
Z9 18
U1 9
U2 17
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JUN
PY 2020
VL 12
IS 11
AR 1838
DI 10.3390/rs12111838
PG 19
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA MC6LX
UT WOS:000543397000143
OA gold
DA 2022-04-17
ER

PT J
AU Reza, M
AF Reza, Moonzarin
TI Galaxy morphology classification using automated machine learning
SO ASTRONOMY AND COMPUTING
LA English
DT Article
DE Galaxy; Morphology; Machine learning; Computational complexity
ID DIGITAL SKY SURVEY; DARK ENERGY SURVEY; ENVIRONMENTAL DEPENDENCE; ZOO;
   COSMOS; COLOR; SYSTEMS; FIELD; 1ST
AB In this paper, we apply five different machine learning algorithms to classify samples into four categories - spirals, ellipticals, mergers and stars (don't know) using data from the Sloan Digital Sky Survey to assess the feasibility of using machine learning methods for future surveys. Classifying mergers as a separate class poses a challenge as this category is easily confused with both ellipticals and spirals, and as a result, most previous studies have not included mergers as a distinct morphological class. The dataset is highly imbalanced with the number of ellipticals/spirals being much larger than the number of stars/mergers, and this is another challenge we aim to address. Starting with 62 features, we perform principal component analysis and use the 25 most significant principal components as inputs to the machine learning models. We compare our results with the Galaxy Zoo labels and obtain an overall test accuracy of 98.2% and 97.5% using Artificial Neural Network and ExtraTrees respectively. However, ExtraTrees outperforms Neural Network in classifying mergers and stars. We also perform a parameter sensitivity test to compare the relative importance of different categories of features on the model's performance. Finally, we address the class imbalance problem and examine the effects of different sampling strategies. Our results show that the use of a balanced dataset with a large number of training samples leads to high recall values for the minority classes, and that oversampling methods lead to better performance than undersampling techniques. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Reza, Moonzarin] Texas A&M Univ, Dept Phys & Astron, College Stn, TX 77843 USA.
RP Reza, M (corresponding author), Texas A&M Univ, Dept Phys & Astron, College Stn, TX 77843 USA.
EM moonzarin@tamu.edu
NR 68
TC 0
Z9 0
U1 1
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2213-1337
EI 2213-1345
J9 ASTRON COMPUT
JI Astron. Comput.
PD OCT
PY 2021
VL 37
AR 100492
DI 10.1016/j.ascom.2021.100492
EA SEP 2021
PG 11
WC Astronomy & Astrophysics; Computer Science, Interdisciplinary
   Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Astronomy & Astrophysics; Computer Science
GA WB4JT
UT WOS:000703540700001
DA 2022-04-17
ER

PT C
AU Peneti, S
   Hemalatha, E
AF Peneti, Subhashini
   Hemalatha, E.
GP IEEE
TI DDOS Attack Identification using Machine Learning Techniques
SO 2021 INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND INFORMATICS
   (ICCCI)
SE International Conference on Computer Communication and Informatics
LA English
DT Proceedings Paper
CT 11th International Conference of Computer Communication and Informatics
   (ICCCI)
CY JAN 27-29, 2021
CL Sri Shakthi Inst Engn & Technol, Coimbatore, INDIA
HO Sri Shakthi Inst Engn & Technol
DE CICIDS2017; DoS; DDoS; Machine Learning
AB One of the major problems that the world faces today is cyber attacks. Denial of Service attacks have been one of most frequent attacks. Some of the mitigating techniques are whitelisting / blacklisting IP addresses, rate limiting etc. The major goal of any DoS attack is to bring down the reputation of the victim organisation. So, instead of facing the issues after the attack, it is always advisable to develop a smart detection system to detect and prevent DoS attacks. While there are many ways to detect DoS attacks, applying machine learning techniques to detect and prevent the attacks turns out to be a promising one. Since there is a lot of data available about DoS attacks, machine learning algorithms can detect patterns of these DoS attacks and thus apply these patterns to new requests and classify them as malicious or benign requests.We consider the CICIDS2017 dataset. The dataset has data related to requests of 7 days of a week. Among those, Wednesday's dataset contains records related to types of DoS attacks. Even though techniques like AdaBoost, XGBoost and neural networks can be applied, random forest gives great performance.
C1 [Peneti, Subhashini] MLR Inst Technol, Dept Comp Sci & Engn, Hyderabad, India.
   [Hemalatha, E.] Jawaharlal Nehru Technol Univ, Dept Comp Sci & Engn, Hyderabad, India.
RP Peneti, S (corresponding author), MLR Inst Technol, Dept Comp Sci & Engn, Hyderabad, India.
EM subhashinivalluru@gmail.com; hemamorarjee@jntuh.ac.in
FU TEQIP-III, JNTUH [JNTUH/TEQIP-III/CRS/2019/CSE/18]
FX The research work was supported by TEQIP-III, JNTUH, by grant
   JNTUH/TEQIP-III/CRS/2019/CSE/18.
NR 15
TC 0
Z9 0
U1 2
U2 2
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2329-7190
BN 978-1-7281-5875-4
J9 INT CONF COMP COMMUN
PY 2021
AR CS189
DI 10.1109/ICCCI50826.2021.9402441
PG 5
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Telecommunications
GA BR8DI
UT WOS:000670971000087
DA 2022-04-17
ER

PT C
AU Shahriar, MA
   Aziz, I
   Banik, S
   Sattar, A
AF Shahriar, Md Asif
   Aziz, Iftekhar
   Banik, Shovan
   Sattar, Abdus
GP IEEE
TI Identification of Spoken Language using Machine Learning Approach
SO 2020 23RD INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION
   TECHNOLOGY (ICCIT 2020)
SE International Conference on Computer and Information Technology
LA English
DT Proceedings Paper
CT 23rd International Conference on Computer and Information Technology
   (ICCIT)
CY DEC 19-21, 2020
CL Ahsanullah Univ Sci & Technol, ELECTR NETWORK
SP IEEE Bangladesh Sect, Ahsanullah Univ Sci & Technol, Dept Comp Sci & Engn, Ahsanullah Univ Sci & Technol, Dept Elect & Elect Engn
HO Ahsanullah Univ Sci & Technol
DE identification; machine learning; spoken language; language detection.
AB identification of spoken language is the way to detect the specific language which is spoken by an anonymous speaker. We will also find out several techniques of machine learning for detecting spoken language. Our major task is to identify parameters and features from spoken language that can be used to separate languages. To extract feature from audio file we will use Mel Frequency Cepstral Coefficient (MFCC). So far, many methods have been used for language identification (LID). Of all the techniques, the accuracy of machine learning is the best. That's why we also used machine learning in our project for lid. Our system will train with 30,000 data. This project aims to classify Spanish. German & English languages. Main goal of this project is to find out best algorithm for detecting specific language. We get the best accuracy from random forest algorithm.
C1 [Shahriar, Md Asif; Aziz, Iftekhar; Banik, Shovan; Sattar, Abdus] Daffodil Int Univ, Dept Comp Sci & Engn, Dhaka, Bangladesh.
RP Shahriar, MA (corresponding author), Daffodil Int Univ, Dept Comp Sci & Engn, Dhaka, Bangladesh.
EM asif15-7772@diu.edu.bd; iftekher15-8182@diu.edu.bd;
   shovan15-7790@diu.edu.bd; abdus.cse@diu.edu.bd
NR 19
TC 0
Z9 0
U1 1
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2474-9648
BN 978-1-6654-2244-4
J9 INT CONF COMPUT INFO
PY 2020
PG 6
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BR7PA
UT WOS:000668692800096
DA 2022-04-17
ER

PT J
AU Koker, TE
   Koutmos, D
AF Koker, Thomas E.
   Koutmos, Dimitrios
TI Cryptocurrency Trading Using Machine Learning
SO JOURNAL OF RISK AND FINANCIAL MANAGEMENT
LA English
DT Article
DE Bitcoin; cryptocurrencies; direct reinforcement; machine learning;
   risk-return
AB We present a model for active trading based on reinforcement machine learning and apply this to five major cryptocurrencies in circulation. In relation to a buy-and-hold approach, we demonstrate how this model yields enhanced risk-adjusted returns and serves to reduce downside risk. These findings hold when accounting for actual transaction costs. We conclude that real-world portfolio management application of the model is viable, yet, performance can vary based on how it is calibrated in test samples.
C1 [Koker, Thomas E.] Worcester Polytech Inst, Worcester, MA 01609 USA.
   [Koutmos, Dimitrios] Texas A&M Univ Corpus Christi, Coll Business, Dept Accounting Finance & Business Law, Corpus Christi, TX 78412 USA.
RP Koutmos, D (corresponding author), Texas A&M Univ Corpus Christi, Coll Business, Dept Accounting Finance & Business Law, Corpus Christi, TX 78412 USA.
EM tekoker@wpi.edu; dimitrios.koutmos@tamucc.edu
OI Koker, Teddy/0000-0001-8861-9788
NR 30
TC 4
Z9 4
U1 3
U2 5
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 1911-8066
EI 1911-8074
J9 J RISK FINANC MANAG
JI J. Risk Financ. Manag.
PD AUG
PY 2020
VL 13
IS 8
AR 178
DI 10.3390/jrfm13080178
PG 7
WC Business, Finance
WE Emerging Sources Citation Index (ESCI)
SC Business & Economics
GA OC0FC
UT WOS:000578838000001
OA Green Submitted, gold
DA 2022-04-17
ER

PT J
AU Ntalampiras, S
AF Ntalampiras, Stavros
TI One-shot learning for acoustic diagnosis of industrial machines
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Machine acoustics; Machine health condition monitoring; One-shot
   learning; Fault diagnosis; Deep learning; Online learning
ID FAULT-DIAGNOSIS; CLASSIFICATION
AB Automatic acoustic monitoring of machine health comprises a relevant field as, unfortunately, such equipment often suffers from faults, malfunctions, aging effects, etc. However, it is still an unexplored domain of research where the majority of existing works relies on traditional machine learning based approaches. After providing a critical survey of the available methods, this work highlights the most relevant limitations and designs a solution specifically addressing them. We introduce the one-shot learning paradigm into the specific domain and suitably extent it to (a) classify machine states, (b) detect novel ones, and (c) incorporate them in the class dictionary online. The backbone of the present system is a Siamese Neural Network (SNN) composed of convolutional layers. Conveniently, every processing stage depends on a standardized feature set free of domain knowledge, i.e. spectrograms. Interestingly, we enhance SNN's classification ability by an appropriately designed data selection scheme. The proposed solution is applied on a publicly available dataset of vibration signals representing four states of a drill bit, i.e. healthy state, chisel wear, flank wear, and outer corner wear. After extensive experiments thoroughly examining every aspect of the proposed solution, it is shown to achieve state of the art results while using limited amount of training data. Importantly, at the same time it is able to operate under evolving environments. Last but not least, we show that the obtained predictions are interpretable, a property which is rapidly becoming a requirement in modern machine learning based technologies.
C1 [Ntalampiras, Stavros] Univ Milan, Via Celoria 18, I-20133 Milan, Italy.
RP Ntalampiras, S (corresponding author), Univ Milan, Via Celoria 18, I-20133 Milan, Italy.
EM stavros.ntalampiras@unimi.it
OI Ntalampiras, Stavros/0000-0003-3482-9215
FU NVIDIA Corp.; Piano Sostegno alla Ricerca of University of Milan
FX We gratefully acknowledge the support of NVIDIA Corp. with the donation
   of the Titan V GPU used for this research. This work was carried out
   within the project entitled Advanced methods for sound and music
   computing funded by the Piano Sostegno alla Ricerca of University of
   Milan.
NR 43
TC 3
Z9 3
U1 3
U2 4
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD SEP 15
PY 2021
VL 178
AR 114984
DI 10.1016/j.eswa.2021.114984
EA APR 2021
PG 8
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA UR5PH
UT WOS:000696800700003
DA 2022-04-17
ER

PT J
AU Lu, MY
   Fan, ZJ
   Xu, B
   Chen, LJ
   Zheng, X
   Li, JD
   Znati, T
   Mi, Q
   Jiang, JT
AF Lu, Mingyang
   Fan, Zhenjiang
   Xu, Bin
   Chen, Lujun
   Zheng, Xiao
   Li, Jundong
   Znati, Taieb
   Mi, Qi
   Jiang, Jingting
TI Using machine learning to predict ovarian cancer
SO INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS
LA English
DT Article
DE Ovarian Cancer; Tumor Marker; Machine Learning
ID DIAGNOSTIC-VALUE; HE-4; CA125; CLASSIFICATION; PROTEIN; INDEX; ROMA;
   BIOMARKER; RISK
AB Objective: Ovarian cancer (OC) is one of the most common types of cancer in women. Accurately prediction of benign ovarian tumors (BOT) and OC has important practical value.
   Methods: Our dataset consists of 349 Chinese patients with 49 variables including demographics, blood routine test, general chemistry, and tumor markers. Machine learning Minimum Redundancy - Maximum Relevance (MRMR) feature selection method was applied on the 235 patients' data (89 BOT and 146 OC) to select the most relevant features, with which a simple decision tree model was constructed. The model was tested on the rest of 114 patients (89 BOT and 25 OC). The results were compared with the predictions produced by using the risk of ovarian malignancy algorithm (ROMA) and logistic regression model.
   Results: Eight notable features were selected by MRMR, among which two were identified as the top features by the decision tree model: human epididymis protein 4 (HE4) and carcinoembryonic antigen (CEA). Particularly, CEA is a valuable marker for OC prediction in patients with low HE4. The model also yields better prediction result than ROMA.
   Conclusion: Machine learning approaches were able to accurately classify BOT and OC. Our goal is to derive a simple predictive model which also carries a good performance. Using our approach, we obtained a model that consists of just two biomarkers, HE4 and CEA. The model is simple to interpret and outperforms the existing OC prediction methods. It demonstrates that the machine learning approach has good potential in predictive modeling for the complex diseases.
C1 [Lu, Mingyang; Xu, Bin; Chen, Lujun; Zheng, Xiao; Jiang, Jingting] Soochow Univ, Dept Tumor Biol Treatment, Affiliated Hosp 3, Changzhou, Jiangsu, Peoples R China.
   [Lu, Mingyang; Xu, Bin; Chen, Lujun; Zheng, Xiao; Jiang, Jingting] Jiangsu Engn Res Ctr Tumor Immunotherapy, Changzhou, Jiangsu, Peoples R China.
   [Lu, Mingyang; Xu, Bin; Chen, Lujun; Zheng, Xiao; Jiang, Jingting] Soochow Univ, Inst Cell Therapy, Changzhou, Jiangsu, Peoples R China.
   [Fan, Zhenjiang; Znati, Taieb] Univ Pittsburgh, Dept Comp Sci, Pittsburgh, PA 15260 USA.
   [Li, Jundong] Univ Virginia, Dept Elect & Comp Engn, Charlottesville, VA USA.
   [Mi, Qi] Univ Pittsburgh, Dept Sports Med & Nutr, Pittsburgh, PA 15260 USA.
RP Jiang, JT (corresponding author), Soochow Univ, Dept Tumor Biol Treatment, Affiliated Hosp 3, Changzhou, Jiangsu, Peoples R China.; Jiang, JT (corresponding author), Jiangsu Engn Res Ctr Tumor Immunotherapy, Changzhou, Jiangsu, Peoples R China.; Jiang, JT (corresponding author), Soochow Univ, Inst Cell Therapy, Changzhou, Jiangsu, Peoples R China.; Mi, Q (corresponding author), Univ Pittsburgh, Dept Sports Med & Nutr, Pittsburgh, PA 15260 USA.
EM qi.mi@pitt.edu; jiangjingting@suda.edu.cn
OI Lu, Mingyang/0000-0002-3456-3237
FU National Key RD Plan [2018YFC1313400]; National Natural Science
   Foundation of ChinaNational Natural Science Foundation of China (NSFC)
   [81902386, 31570877, 31729001, 81972869]; National Key Technology RD
   ProgramNational Key Technology R&D Program [2015BAI12B12]; Jiangsu
   Engineering Research Center for Tumor Immunotherapy [BM2014404]; Key R&D
   Project of Science and Technology Department of Jiangsu Province
   [BE2018645]; Young Medical Talents Program of Jiangsu Province
   [QNRC2016286]; Changzhou Science and Technology Project [CJ20190094];
   Changzhou High-Level Medical Talents Training Project [2016CZBJ001]
FX This work was supported in part by grants from the National Key R&D Plan
   (2018YFC1313400) to J. J., the National Natural Science Foundation of
   China (31570877, 31729001, 81972869) to J. J., the National Key
   Technology R&D Program (2015BAI12B12) to J. J., Jiangsu Engineering
   Research Center for Tumor Immunotherapy (BM2014404) to J. J., the Key
   R&D Project of Science and Technology Department of Jiangsu Province
   (BE2018645) to J. J., the National Natural Science Foundation of China
   (81902386) to X. Z., Young Medical Talents Program of Jiangsu Province
   (QNRC2016286) to X. Z., Changzhou Science and Technology Project
   (Applied Based Research, CJ20190094) to X.Z., and Changzhou High-Level
   Medical Talents Training Project (2016CZBJ001) to L.C.
NR 35
TC 12
Z9 13
U1 6
U2 15
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 1386-5056
EI 1872-8243
J9 INT J MED INFORM
JI Int. J. Med. Inform.
PD SEP
PY 2020
VL 141
AR 104195
DI 10.1016/j.ijmedinf.2020.104195
PG 8
WC Computer Science, Information Systems; Health Care Sciences & Services;
   Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Health Care Sciences & Services; Medical Informatics
GA OD3VH
UT WOS:000579780700021
PM 32485554
DA 2022-04-17
ER

PT J
AU Mueller, B
   Kinoshita, T
   Peebles, A
   Graber, MA
   Lee, S
AF Mueller, Brianna
   Kinoshita, Takahiro
   Peebles, Alexander
   Graber, Mark A.
   Lee, Sangil
TI Artificial intelligence and machine learning in emergency medicine: a
   narrative review
SO ACUTE MEDICINE & SURGERY
LA English
DT Review
DE Artificial intelligence; deep learning; emergency medicine; machine
   learning; prediction
ID DISEASE
AB Aim: The emergence and evolution of artificial intelligence (AI) has generated increasing interest in machine learning applications for health care. Specifically, researchers are grasping the potential of machine learning solutions to enhance the quality of care in emergency medicine.
   Methods: We undertook a narrative review of published works on machine learning applications in emergency medicine and provide a synopsis of recent developments.
   Results: This review describes fundamental concepts of machine learning and presents clinical applications for triage, risk stratification specific to disease, medical imaging, and emergency department operations. Additionally, we consider how machine learning models could contribute to the improvement of causal inference in medicine, and to conclude, we discuss barriers to safe implementation of AI.
   Conclusion: We intend that this review serves as an introduction to AI and machine learning in emergency medicine.
C1 [Mueller, Brianna] Univ Iowa, Tippie Coll Business, Dept Business Analyt, Iowa City, IA USA.
   [Kinoshita, Takahiro] Philips Res North Amer, Cambridge, MA USA.
   [Peebles, Alexander; Graber, Mark A.; Lee, Sangil] Univ Iowa, Carver Coll Med, Dept Emergency Med, 200 Hawkins Dr, Iowa City, IA 52242 USA.
RP Lee, S (corresponding author), Univ Iowa, Carver Coll Med, Dept Emergency Med, 200 Hawkins Dr, Iowa City, IA 52242 USA.
EM sangil-lee@uiowa.edu
OI Lee, Sangil/0000-0001-8529-4500
NR 41
TC 0
Z9 0
U1 2
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 2052-8817
J9 ACUTE MED SURG
JI Acute Med. Surg.
PD JAN
PY 2022
VL 9
IS 1
AR e740
DI 10.1002/ams2.740
PG 10
WC Medicine, General & Internal
WE Emerging Sources Citation Index (ESCI)
SC General & Internal Medicine
GA ZJ6RH
UT WOS:000762430500001
PM 35251669
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Wu, YF
   Fang, Y
AF Wu, Yafei
   Fang, Ya
TI Stroke Prediction with Machine Learning Methods among Older Chinese
SO INTERNATIONAL JOURNAL OF ENVIRONMENTAL RESEARCH AND PUBLIC HEALTH
LA English
DT Article
DE stroke; imbalanced data; machine learning; prediction
ID RISK; POPULATION; PREVALENCE
AB Timely stroke diagnosis and intervention are necessary considering its high prevalence. Previous studies have mainly focused on stroke prediction with balanced data. Thus, this study aimed to develop machine learning models for predicting stroke with imbalanced data in an elderly population in China. Data were obtained from a prospective cohort that included 1131 participants (56 stroke patients and 1075 non-stroke participants) in 2012 and 2014, respectively. Data balancing techniques including random over-sampling (ROS), random under-sampling (RUS), and synthetic minority over-sampling technique (SMOTE) were used to process the imbalanced data in this study. Machine learning methods such as regularized logistic regression (RLR), support vector machine (SVM), and random forest (RF) were used to predict stroke with demographic, lifestyle, and clinical variables. Accuracy, sensitivity, specificity, and areas under the receiver operating characteristic curves (AUCs) were used for performance comparison. The top five variables for stroke prediction were selected for each machine learning method based on the SMOTE-balanced data set. The total prevalence of stroke was high in 2014 (4.95%), with men experiencing much higher prevalence than women (6.76% vs. 3.25%). The three machine learning methods performed poorly in the imbalanced data set with extremely low sensitivity (approximately 0.00) and AUC (approximately 0.50). After using data balancing techniques, the sensitivity and AUC considerably improved with moderate accuracy and specificity, and the maximum values for sensitivity and AUC reached 0.78 (95% CI, 0.73-0.83) for RF and 0.72 (95% CI, 0.71-0.73) for RLR. Using AUCs for RLR, SVM, and RF in the imbalanced data set as references, a significant improvement was observed in the AUCs of all three machine learning methods (p < 0.05) in the balanced data sets. Considering RLR in each data set as a reference, only RF in the imbalanced data set and SVM in the ROS-balanced data set were superior to RLR in terms of AUC. Sex, hypertension, and uric acid were common predictors in all three machine learning methods. Blood glucose level was included in both RLR and RF. Drinking, age and high-sensitivity C-reactive protein level, and low-density lipoprotein cholesterol level were also included in RLR, SVM, and RF, respectively. Our study suggests that machine learning methods with data balancing techniques are effective tools for stroke prediction with imbalanced data.
C1 [Wu, Yafei; Fang, Ya] Xiamen Univ, Sch Publ Hlth, State Key Lab Mol Vaccine & Mol Diagnost, Xiamen 361102, Peoples R China.
   [Wu, Yafei; Fang, Ya] Xiamen Univ, Sch Publ Hlth, Key Lab Hlth Technol Assessment Fujian Prov, Xiamen 361102, Peoples R China.
   [Wu, Yafei; Fang, Ya] Xiamen Univ, Natl Inst Data Sci Hlth & Med, Xiamen 361102, Peoples R China.
RP Fang, Y (corresponding author), Xiamen Univ, Sch Publ Hlth, State Key Lab Mol Vaccine & Mol Diagnost, Xiamen 361102, Peoples R China.; Fang, Y (corresponding author), Xiamen Univ, Sch Publ Hlth, Key Lab Hlth Technol Assessment Fujian Prov, Xiamen 361102, Peoples R China.; Fang, Y (corresponding author), Xiamen Univ, Natl Inst Data Sci Hlth & Med, Xiamen 361102, Peoples R China.
EM wyfyyahcx@163.com; fangya@xmu.edu.cn
OI Fang, Ya/0000-0002-9895-3234
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [81973144]
FX This study was supported by the National Natural Science Foundation of
   China (No. 81973144).
NR 35
TC 4
Z9 4
U1 22
U2 29
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1660-4601
J9 INT J ENV RES PUB HE
JI Int. J. Environ. Res. Public Health
PD MAR 2
PY 2020
VL 17
IS 6
AR 1828
DI 10.3390/ijerph17061828
PG 11
WC Environmental Sciences; Public, Environmental & Occupational Health
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Environmental Sciences & Ecology; Public, Environmental & Occupational
   Health
GA LI2VS
UT WOS:000529342300018
PM 32178250
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Harrison, K
   Pullen, H
   Welsh, C
   Oktay, O
   Alvarez-Valle, J
   Jena, R
AF Harrison, K.
   Pullen, H.
   Welsh, C.
   Oktay, O.
   Alvarez-Valle, J.
   Jena, R.
TI p Machine Learning for Auto-Segmentation in Radiotherapy Planning
SO CLINICAL ONCOLOGY
LA English
DT Article
DE &nbsp; Auto-segmentation; Deep learning; Machine learning; Radiotherapy
   planning
ID IMAGE SEGMENTATION; INTEROBSERVER VARIATION; TARGET VOLUMES; ORGANS;
   RISK; DELINEATION; HEAD; PERFORMANCE; MR; VALIDATION
AB Manual segmentation of target structures and organs at risk is a crucial step in the radiotherapy workflow. It has the disadvantages that it can require several hours of clinician time per patient and is prone to inter-and intra-observer variability. Automatic segmentation (auto-segmentation), using computer algo-rithms, seeks to address these issues. Advances in machine learning and computer vision have led to the development of methods for accurate and efficient auto-segmentation. This review surveys auto-segmentation techniques and applications in radiotherapy planning. It provides an overview of traditional ap-proaches to auto-segmentation, including intensity analysis, shape modelling and atlas-based methods. The focus, though, is on uses of machine learning and deep learning, including convolutional neural networks. Finally, the future of machine-learning-driven auto-segmentation in clinical settings is considered, and the barriers that must be overcome for it to be widely accepted into routine practice are highlighted. (c) 2021 The Royal College of Radiologists. Published by Elsevier Ltd. All rights reserved.
C1 [Harrison, K.; Pullen, H.] Univ Cambridge, Cavendish Lab, Cambridge, England.
   [Welsh, C.; Jena, R.] Univ Cambridge, Dept Oncol, Cambridge, England.
   [Oktay, O.; Alvarez-Valle, J.] Microsoft Res, Hlth Intelligence, Cambridge, England.
   [Jena, R.] Cambridge Univ Hosp NHS Fdn Trust, Dept Oncol, Cambridge, England.
RP Harrison, K (corresponding author), Cavendish Lab, JJ Thomson Ave, Cambridge CB3 0HE, England.
EM harrison@hep.phy.cam.ac.uk
FU Cancer Research UK RadNet Cambridge [C17918/A28870]
FX This work was supported by Cancer Research UK RadNet Cambridge
   [C17918/A28870] .
NR 99
TC 1
Z9 1
U1 5
U2 5
PU ELSEVIER SCIENCE LONDON
PI LONDON
PA 84 THEOBALDS RD, LONDON WC1X 8RR, ENGLAND
SN 0936-6555
EI 1433-2981
J9 CLIN ONCOL-UK
JI Clin. Oncol.
PD FEB
PY 2022
VL 34
IS 2
BP 74
EP 88
DI 10.1016/j.clon.2021.12.003
PG 15
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA YL0XJ
UT WOS:000745624000002
PM 34996682
DA 2022-04-17
ER

PT C
AU Akrami, H
   Irimia, A
   Cui, WH
   Joshi, AA
   Leahy, RM
AF Akrami, Haleh
   Irimia, Andrei
   Cui, Wenhui
   Joshi, Anand A.
   Leahy, Richard M.
BE Gimi, BS
   Krol, A
TI Prediction of Posttraumatic Epilepsy using Machine Learning
SO MEDICAL IMAGING 2021: BIOMEDICAL APPLICATIONS IN MOLECULAR, STRUCTURAL,
   AND FUNCTIONAL IMAGING
SE Progress in Biomedical Optics and Imaging
LA English
DT Proceedings Paper
CT Conference on Medical Imaging - Biomedical Applications in Molecular,
   Structural, and Functional Imaging
CY FEB 15-19, 2021
CL ELECTR NETWORK
SP SPIE
DE fMRI; lesion detection; PTE; machine learning
ID TRAUMATIC BRAIN-INJURY; RISK-FACTORS
AB Post-traumatic Epilepsy is one of the common aftereffects of brain injury. This neurological disorder can persist throughout the lifetime of patients and impacts their quality of life significantly. Identification of markers that indicate the likelihood of developing PTE can help develop preventive care for subjects identified as at risk. Despite the relatively high prevalence of PTE, brain imaging-based biomarkers for the diagnosis of PTE are lacking. This is due in part to the heterogeneity of injury in traumatic brain injury patients. Here we investigate the use of structural and functional imaging features for training machine learning models. We compare the performance of four popular machine learning methods in predicting development of PTE after brain injury: (i) support vector machines, (ii) random forests, (iii) fully connected neural networks, and (iv) graph convolutional networks. Our results demonstrate the advantage of using a combination of connectivity features (functional) and lesion volume (structural) in conjunction with a Kernel SVM approach in predicting PTE. We also demonstrate that using a feature reduction method such as principal component analysis (PCA) can be more effective than penalizing classifiers. This might be due to the limitation of penalized models for a framework where features are correlated.
C1 [Akrami, Haleh; Irimia, Andrei; Cui, Wenhui; Joshi, Anand A.; Leahy, Richard M.] Univ Southern Calif, Los Angeles, CA 90007 USA.
RP Akrami, H (corresponding author), Univ Southern Calif, Los Angeles, CA 90007 USA.
FU  [R01 NS074980];  [W81XWH-18-1-0614];  [R01 NS089212];  [R01 EB026299]
FX This work is supported by the following grants: R01 NS074980,
   W81XWH-18-1-0614, R01 NS089212, and R01 EB026299.
NR 36
TC 0
Z9 0
U1 0
U2 1
PU SPIE-INT SOC OPTICAL ENGINEERING
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA
SN 1605-7422
BN 978-1-5106-4030-6
J9 PRO BIOMED OPT IMAG
PY 2021
VL 11600
AR 116001Q
DI 10.1117/12.2580953
PG 7
WC Computer Science, Artificial Intelligence; Optics; Radiology, Nuclear
   Medicine & Medical Imaging
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Optics; Radiology, Nuclear Medicine & Medical Imaging
GA BR8GG
UT WOS:000671880400056
DA 2022-04-17
ER

PT C
AU Divyashree, N
   Prasad, KSN
AF Divyashree, N.
   Prasad, K. S. Nandini
BE Shakya, S
   Du, KL
   Haoxiang, W
TI Algorithms: Supervised Machine Learning Types and Their Application
   Domains
SO PROCEEDINGS OF SECOND INTERNATIONAL CONFERENCE ON SUSTAINABLE EXPERT
   SYSTEMS (ICSES 2021)
SE Lecture Notes in Networks and Systems
LA English
DT Proceedings Paper
CT 2nd International Conference on Sustainable Expert Systems (ICSES)
CY SEP 17-18, 2021
CL NEPAL
SP Tribhuvan Univ
DE Machine Learning; Supervised Learning; Artificial Intelligence;
   Regression; Classification; Decision Trees; Deep Learning; Artificial
   Neural Networks
AB In today's world, millions and trillions of data are available from anywhere and everywhere. However, these data have no use if not processed right away for obtaining unseen and meaningful information from it. Machine learning technique, a subfield under artificial intelligence, aims to train the computer systems to learn and apply knowledge from the given set of training data. Machine learning algorithms are used to extract unseen trends and patterns from the data for deriving meaningful insights and foresights to make future decisions in business, manufacturing, government and many more. This survey provides a complete view on supervised machine learning algorithms, their pros and cons along with their applications in specific areas under each machine learning class.
C1 [Divyashree, N.; Prasad, K. S. Nandini] Dr Ambedkar Inst Technol, Dept Informat Sci & Engn, Bengaluru, India.
RP Divyashree, N (corresponding author), Dr Ambedkar Inst Technol, Dept Informat Sci & Engn, Bengaluru, India.
EM lda19pis02.is@drait.edu.in; nandini.is@drait.edu.in
FU KSTEPS, Department of Science and Technology (DST), GOVT. OF KARNATAKA;
   Dr. Ambedkar Institute of Technology
FX Thisworkwas financially supported by the "KSTEPS, Department of Science
   and Technology (DST), GOVT. OF KARNATAKA". The funders had no role in
   study design, data collection and analysis, decision to publish or
   preparation of the manuscript. I also thank Dr. Ambedkar Institute of
   Technology for their guidance and support with all the facility that was
   required.
NR 21
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2367-3370
EI 2367-3389
BN 978-981-16-7657-4; 978-981-16-7656-7
J9 LECT NOTE NETW SYST
PY 2022
VL 351
BP 787
EP 807
DI 10.1007/978-981-16-7657-4_64
PG 21
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS8KQ
UT WOS:000773047100064
DA 2022-04-17
ER

PT C
AU Grace, RK
   Suganya, B
AF Grace, R. Kingsy
   Suganya, B.
GP IEEE
TI Machine Learning based Rainfall Prediction
SO 2020 6TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND
   COMMUNICATION SYSTEMS (ICACCS)
SE International Conference on Advanced Computing and Communication Systems
LA English
DT Proceedings Paper
CT 6th International Conference on Advanced Computing and Communication
   Systems (ICACCS)
CY MAR 06-07, 2020
CL Coimbatore, INDIA
DE Multiple Linear Regression; rainfall; prediction; machine learning;
   accuracy
AB Rainfall prediction is the one of the important technique to predict the climatic conditions in any country. This paper proposes a rainfall prediction model using Multiple Linear Regression (MLR) for Indian dataset. The input data is having multiple meteorological parameters and to predict the rainfall in more precise. The Mean Square Error (MSE), accuracy, correlation are the parameters used to validate the proposed model. From the results, the proposed machine learning model provides better results than the other algorithms in the literature.
C1 [Grace, R. Kingsy; Suganya, B.] Sri Ramakrishna Engn Coll, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
RP Grace, RK (corresponding author), Sri Ramakrishna Engn Coll, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
EM kingsygrace.r@srec.ac.in; suganya.b@srec.ac.in
NR 10
TC 1
Z9 1
U1 5
U2 7
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2469-5556
BN 978-1-7281-5197-7; 978-1-7281-5196-0
J9 INT CONF ADVAN COMPU
PY 2020
BP 227
EP 229
PG 3
WC Computer Science, Theory & Methods; Engineering, Electrical &
   Electronic; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Telecommunications
GA BP9RJ
UT WOS:000570722600044
DA 2022-04-17
ER

PT C
AU Burton, S
   Kurzidem, I
   Schwaiger, A
   Schleiss, P
   Unterreiner, M
   Graeber, T
   Becker, P
AF Burton, Simon
   Kurzidem, Iwo
   Schwaiger, Adrian
   Schleiss, Philipp
   Unterreiner, Michael
   Graeber, Torben
   Becker, Philipp
BE Habli, I
   Sujan, M
   Bitsch, F
TI Safety Assurance of Machine Learning for Chassis Control Functions
SO COMPUTER SAFETY, RELIABILITY, AND SECURITY (SAFECOMP 2021)
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 40th International Conference on Computer Safety, Reliability and
   Security (SAFECOMP)
CY SEP 08-10, 2021
CL York, ENGLAND
SP Intel
DE Assurance case; Safety engineering; Machine learning; Automotive
   software
AB This paper describes the application of machine learning techniques and an associated assurance case for a safety-relevant chassis control system. The method applied during the assurance process is described including the sources of evidence and deviations from previous ISO 26262 based approaches. The paper highlights how the choice of machine learning approach supports the assurance case, especially regarding the inherent explainability of the algorithm and its robustness to minor input changes. In addition, the challenges that arise if applying more complex machine learning technique, for example in the domain of automated driving, are also discussed. The main contribution of the paper is the demonstration of an assurance approach for machine learning for a comparatively simple function. This allowed the authors to develop a convincing assurance case, whilst identifying pragmatic considerations in the application of machine learning for safety-relevant functions.
C1 [Burton, Simon; Kurzidem, Iwo; Schwaiger, Adrian; Schleiss, Philipp] Fraunhofer IKS, D-80686 Munich, Germany.
   [Unterreiner, Michael; Graeber, Torben; Becker, Philipp] Porsche AG, D-71287 Weissach, Germany.
RP Kurzidem, I (corresponding author), Fraunhofer IKS, D-80686 Munich, Germany.
EM simon.burton@iks.fraunhofer.de; iwo.kurzidem@iks.fraunhofer.de;
   adrian.schwaiger@iks.fraunhofer.de; philipp.schleiss@iks.fraunhofer.de;
   michael.unterreiner@porsche.de; torben.graeber@porsche.de;
   philipp.becker@porsche.de
FU Bavarian Ministry for Economic Affairs, Regional Development and Energy
FX On side of Fraunhofer IKS, the research for developing the theoretical
   safety foundations utilisied in this work was partially funded by the
   Bavarian Ministry for Economic Affairs, Regional Development and Energy
   as part of a project to support the thematic development of the
   Institute for Cognitive Systems.
NR 16
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-83903-1; 978-3-030-83902-4
J9 LECT NOTES COMPUT SC
PY 2021
VL 12852
BP 149
EP 162
DI 10.1007/978-3-030-83903-1_10
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS1WC
UT WOS:000696703000010
DA 2022-04-17
ER

PT C
AU Kalaiyarasi, M
   Dhanasekar, R
   Ram, SS
   Vaishnavi, P
AF Kalaiyarasi, M.
   Dhanasekar, R.
   Ram, S. Sakthiya
   Vaishnavi, P.
GP IOP
TI Classification of Benign or Malignant Tumor Using Machine Learning
SO INTERNATIONAL CONFERENCE ON MECHATRONICS IN ENERGY AND ENVIRONMENT
   PROTECTION (ICMEEP 2020)
SE IOP Conference Series-Materials Science and Engineering
LA English
DT Proceedings Paper
CT International Conference on Mechatronics in Energy and Environment
   Protection (ICMEEP)
CY OCT 16-17, 2020
CL Bannari Amman Inst Technol, Erode, INDIA
SP Bannari Amman Inst Technol, Dept Mechatron
HO Bannari Amman Inst Technol
DE Tumor detection; Machine learning
AB The abnormal growth of the cell in the human body may leads to tumor. There are almost 100 types of cancer will affect the different parts of the human. The affected human may have symptoms like lump, abnormal bleeding, prolonged cough, weight loss etc... And depends on the part where the tumor formed. Breast cancer is one of the types among the 100 types of cancer and it is most commonly found on the female than the male. Breast cancer is a disease that caused due to the over growth of the cell in the breast area and they started to form lump over the breast. The people who are suffering from the breast cancer will have many emotional side effects and they are supped to undergo lot of pain in their day to day life. The most important problem for the health care people is earlier prediction. So, it can be rectified by employing machine learning algorithms in the prediction stage. In this paper the classification algorithms are used to classify whether the tumor is benign or malignant. The supervised learning algorithms of machine learning such as logistic regression, Support vector machine and K Nearest neighbour algorithm are usually used to analyse the tumour detection. Stacking ensemble method used in order to combine the entire three algorithms is proposed and the performance of algorithm is compared with the logistic regression, Support vector machine and K Nearest neighbour algorithm in order to get an efficient model for the classification.
C1 [Kalaiyarasi, M.; Dhanasekar, R.; Ram, S. Sakthiya; Vaishnavi, P.] Bannari Amman Inst Technol, Dept Elect & Instrumentat, Sathyamangalam 638401, Erode, India.
RP Kalaiyarasi, M (corresponding author), Bannari Amman Inst Technol, Dept Elect & Instrumentat, Sathyamangalam 638401, Erode, India.
EM kalaiyarasime@gmail.com; dhanaekar@bitsathy.ac.in;
   sakthiyaram@bitsathy.ac.in; vaishnavi@bitsathy.ac.in
RI Mani, Kalaiyarasi/AAV-7119-2021; RAJU, DHANASEKAR/AAV-7096-2021
NR 26
TC 0
Z9 0
U1 0
U2 1
PU IOP PUBLISHING LTD
PI BRISTOL
PA DIRAC HOUSE, TEMPLE BACK, BRISTOL BS1 6BE, ENGLAND
SN 1757-8981
J9 IOP CONF SER-MAT SCI
PY 2020
VL 995
AR 012028
DI 10.1088/1757-899X/995/1/012028
PG 11
WC Automation & Control Systems; Engineering, Manufacturing; Engineering,
   Mechanical; Robotics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Automation & Control Systems; Engineering; Robotics
GA BR6DE
UT WOS:000659914900028
OA gold
DA 2022-04-17
ER

PT J
AU Wang, QW
   Xu, ZH
   Chen, ZT
   Wang, Y
   Liu, SX
   Qu, HM
AF Wang, Qianwen
   Xu, Zhenhua
   Chen, Zhutian
   Wang, Yong
   Liu, Shixia
   Qu, Huamin
TI Visual Analysis of Discrimination in Machine Learning
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Itemsets; Visualization; Data visualization; Tools; Machine learning;
   Data models; Predictive models; Machine Learning; Discrimination; Data
   Visualization
ID VISUALIZATION; SETS
AB The growing use of automated decision-making in critical applications, such as crime prediction and college admission, has raised questions about fairness in machine learning. How can we decide whether different treatments are reasonable or discriminatory? In this paper, we investigate discrimination in machine learning from a visual analytics perspective and propose an interactive visualization tool, DiscriLens, to support a more comprehensive analysis. To reveal detailed information on algorithmic discrimination, DiscriLens identifies a collection of potentially discriminatory itemsets based on causal modeling and classification rules mining. By combining an extended Euler diagram with a matrix-based visualization, we develop a novel set visualization to facilitate the exploration and interpretation of discriminatory itemsets. A user study shows that users can interpret the visually encoded information in DiscriLens quickly and accurately. Use cases demonstrate that DiscriLens provides informative guidance in understanding and reducing algorithmic discrimination.
C1 [Wang, Qianwen; Xu, Zhenhua; Chen, Zhutian; Wang, Yong; Qu, Huamin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Liu, Shixia] Tsinghua Univ, Beijing, Peoples R China.
RP Wang, QW (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
EM qwangbb@connect.ust.hk; zxubg@connect.ust.hk;
   zhutian.chen@connect.ust.hk; ywangct.chen@connect.ust.hk;
   shixia@tsinghua.edu.cn; huamin@ust.hk
FU Hong Kong Theme-based Research Scheme [T41 -709/17N]; MSRA
FX This research was supported in part by Hong Kong Theme-based Research
   Scheme grant T41 -709/17N and also a grant from MSRA.
NR 69
TC 3
Z9 3
U1 3
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2021
VL 27
IS 2
BP 1470
EP 1480
DI 10.1109/TVCG.2020.3030471
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA WF5FO
UT WOS:000706330100126
PM 33048751
OA Green Accepted, Green Submitted
DA 2022-04-17
ER

PT C
AU Dalmazzo, D
   Ramirez, R
AF Dalmazzo, David
   Ramirez, Rafael
BE Cellier, P
   Driessens, K
TI Bow Gesture Classification to Identify Three Different Expertise Levels:
   A Machine Learning Approach
SO MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES, ECML PKDD 2019,
   PT II
SE Communications in Computer and Information Science
LA English
DT Proceedings Paper
CT European Conference on Machine Learning and Principles and Practice of
   Knowledge Discovery in Databases (ECML PKDD)
CY SEP 16-20, 2019
CL Wurzburg, GERMANY
SP Bosch, Fraunhofer IAIS, Huawei, ASML, IBM Res, NEC, Kreditech, McKinsey & Co, KNIME, European Res Ctr Informat Syst, Odgers Berndtson, Springer, Vogel Stiftung, German Res Fdn
DE Machine learning; Music education; Hidden Markov Model
AB To acquire new skills in a high-level music context, students need many years of conscious dedication and practice. It is understood that precise motor actions have to be incorporated into the musicians' automatic executions, where a repertoire of technical actions must be learned and mastered. In this study, we develop a computer modelled assistant applying machine learning algorithms, for self-practice musicians with the violin as a test case. We recorded synchronized data from the performer's forearms implementing an IMU device with ambient sound recordings. The musicians perform seven standard bow gesture. We tested the model with three different expertise levels to identify relevant dissimilitudes among students and teachers.
C1 [Dalmazzo, David; Ramirez, Rafael] Univ Pompeu Fabra, Barcelona 08018, Spain.
RP Dalmazzo, D; Ramirez, R (corresponding author), Univ Pompeu Fabra, Barcelona 08018, Spain.
EM david.cabrerar@upf.edu; rafael.ramirez@upf.edu
FU Music Technology Group; Spanish Ministry of Economy and Competitiveness
   under the Maria de Maeztu Units of Excellence ProgrammeSpanish
   Government [MDM-2015-0502]
FX Music Technology Group, and Spanish Ministry of Economy and
   Competitiveness under the Maria de Maeztu Units of Excellence Programme
   (MDM-2015-0502).
NR 14
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1865-0929
EI 1865-0937
BN 978-3-030-43887-6; 978-3-030-43886-9
J9 COMM COM INF SC
PY 2020
VL 1168
BP 494
EP 501
DI 10.1007/978-3-030-43887-6_43
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Interdisciplinary Applications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS4EU
UT WOS:000718590300043
DA 2022-04-17
ER

PT J
AU Fazelpour, S
   De-Arteaga, M
AF Fazelpour, Sina
   De-Arteaga, Maria
TI Diversity in sociotechnical machine learning systems
SO BIG DATA & SOCIETY
LA English
DT Article
DE Diversity; fair machine learning; responsible artificial intelligence;
   algorithmic bias; AI ethics; sociotechnical systems
ID HEALTH; BIAS
AB There has been a surge of recent interest in sociocultural diversity in machine learning research. Currently, however, there is a gap between discussions of measures and benefits of diversity in machine learning, on the one hand, and the broader research on the underlying concepts of diversity and the precise mechanisms of its functional benefits, on the other. This gap is problematic because diversity is not a monolithic concept. Rather, different concepts of diversity are based on distinct rationales that should inform how we measure diversity in a given context. Similarly, the lack of specificity about the precise mechanisms underpinning diversity's potential benefits can result in uninformative generalities, invalid experimental designs, and illicit interpretations of findings. In this work, we draw on research in philosophy, psychology, and social and organizational sciences to make three contributions: First, we introduce a taxonomy of different diversity concepts from philosophy of science, and explicate the distinct epistemic and political rationales underlying these concepts. Second, we provide an overview of mechanisms by which diversity can benefit group performance. Third, we situate these taxonomies of concepts and mechanisms in the lifecycle of sociotechnical machine learning systems and make a case for their usefulness in fair and accountable machine learning. We do so by illustrating how they clarify the discourse around diversity in the context of machine learning systems, promote the formulation of more precise research questions about diversity's impact, and provide conceptual tools to further advance research and practice.
C1 [Fazelpour, Sina] Northeastern Univ, Boston, MA 02115 USA.
   [De-Arteaga, Maria] Univ Texas Austin, Austin, TX 78712 USA.
RP Fazelpour, S (corresponding author), Northeastern Univ, Dept Philosophy & Relig, Boston, MA 02115 USA.; Fazelpour, S (corresponding author), Northeastern Univ, Khoury Coll Comp Sci, Boston, MA 02115 USA.
EM s.fazel-pour@northeastern.edu
FU Social Sciences and Humanities Research Council of CanadaSocial Sciences
   and Humanities Research Council of Canada (SSHRC) [756-2019-0289];
   Google AI Award for Inclusion Research; Good Systems, a research grand
   challenge at the University of Texas at Austin
FX The author(s) disclosed receipt of the following financial supportfor
   the research, authorship, and/or publication of this article: For parts
   of the writing of this paper, Sina Fazelpour was a postdoctoral fellow
   at Carnegie Mellon University, supported in part by funding from the
   Social Sciences and Humanities Research Council of Canada (No.
   756-2019-0289). Maria De-Arteaga was supported in part by a Google AI
   Award for Inclusion Research and by Good Systems, a research grand
   challenge at the University of Texas at Austin.
NR 74
TC 0
Z9 0
U1 0
U2 0
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 2053-9517
J9 BIG DATA SOC
JI Big Data Soc.
PD JAN
PY 2022
VL 9
IS 1
AR 20539517221082027
DI 10.1177/20539517221082027
PG 14
WC Social Sciences, Interdisciplinary
WE Social Science Citation Index (SSCI)
SC Social Sciences - Other Topics
GA 0F8FK
UT WOS:000777589400001
OA Green Submitted, gold
DA 2022-04-17
ER

PT J
AU Fudenberg, D
   Liang, AN
AF Fudenberg, Drew
   Liang, Annie
TI Machine Learning for Evaluating and Improving Theories
SO ACM SIGECOM EXCHANGES
LA English
DT Article
DE machine learning; economic theory; modeling; prediction
ID PLAYERS MODELS; PROBABILITY
AB We summarize our recent work that uses machine learning techniques as a complement to theoretical modeling, rather than a substitute for it. The key concepts are those of the completeness and restrictiveness of a model. A theory's completeness is how much it improves predictions over a naive baseline, relative to how much improvement is possible. When a theory is relatively incomplete, machine learning algorithms can help reveal regularities that the theory doesn't capture, and thus lead to the construction of theories that make more accurate predictions. Restrictiveness measures a theory's ability to match arbitrary hypothetical data: A very unrestrictive theory will be complete on almost any data, so the fact that it is complete on the actual data is not very instructive. We algorithmically quantify restrictiveness by measuring how well the theory approximates randomly generated behaviors. Finally, we propose "algorithmic experimental design" as a method to help select which experiments to run.
C1 [Fudenberg, Drew] MIT, Cambridge, MA 02139 USA.
   [Liang, Annie] Univ Penn, Philadelphia, PA 19104 USA.
RP Fudenberg, D (corresponding author), MIT, Cambridge, MA 02139 USA.
EM drewf@mit.edu; anliang@upenn.edu
NR 13
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-9031
J9 ACM SIGECOM EXCH
JI ACM SIGecom Exch.
PD JUL
PY 2020
VL 18
IS 1
BP 4
EP 11
DI 10.1145/3440959.3440962
PG 8
WC Computer Science, Interdisciplinary Applications
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA PL8ER
UT WOS:000603348400003
DA 2022-04-17
ER

PT J
AU Zhao, SL
   Zhang, S
   Liu, JC
   Wang, H
   Zhu, J
   Li, DL
   Zhao, R
AF Zhao, Shili
   Zhang, Song
   Liu, Jincun
   Wang, He
   Zhu, Jia
   Li, Daoliang
   Zhao, Ran
TI Application of machine learning in intelligent fish aquaculture: A
   review
SO AQUACULTURE
LA English
DT Review
DE Machine learning; Fish aquaculture; Fishery development
ID CONVOLUTIONAL NEURAL-NETWORK; DISSOLVED-OXYGEN CONTENT; COMPUTER-VISION;
   ARTIFICIAL-INTELLIGENCE; SPECIES CLASSIFICATION; FISHERIES MANAGEMENT;
   FEATURE-SELECTION; MODEL; PREDICTION; SYSTEMS
AB Among the background of developments in automation and intelligence, machine learning technology has been extensively applied in aquaculture in recent years, providing a new opportunity for the realization of digital fishery farming. In the present paper, the machine learning algorithms and techniques adopted in intelligent fish aquaculture in the past five years are expounded, and the application of machine learning in aquaculture is explored in detail, including the information evaluation of fish biomass, the identification and classification of fish, behavioral analysis and prediction of water quality parameters. Further, the application of machine learning algorithms in aquaculture is outlined, and the results are analyzed. Finally, several current problems in aquaculture are highlighted, and the development trend is considered.
C1 [Zhao, Shili; Zhang, Song; Liu, Jincun; Wang, He; Zhu, Jia; Li, Daoliang; Zhao, Ran] China Agr Univ, Coll Informat & Elect Engn, Beijing 100083, Peoples R China.
   [Zhao, Shili; Zhang, Song; Liu, Jincun; Wang, He; Zhu, Jia; Li, Daoliang; Zhao, Ran] China Agr Univ, Natl Innovat Ctr Digital Fishery, Beijing, Peoples R China.
   [Li, Daoliang] China Agr Univ, Beijing Engn & Technol Res Ctr Internet Things Ag, Beijing 100083, Peoples R China.
   [Li, Daoliang] China Agr Univ, China EU Ctr Informat & Commun Technol Agr, Beijing 100083, Peoples R China.
   [Li, Daoliang] China Agr Univ, Minist Agr, Key Lab Agr Informat Acquisit Technol, Beijing 100083, Peoples R China.
RP Zhao, R (corresponding author), China Agr Univ, POB 121,17 Tsinghua East Rd, Beijing 100083, Peoples R China.
EM ran.zhao@cau.edu.cn
FU Hebei Province Department of Science And Technology [20327217D];
   Ministry of Science and Technology of the People's Republic of
   ChinaMinistry of Science and Technology, China [2019YFE0103700];
   Shandong Province Department of Science and Technology [2019JZZY010703]
FX This paper was supported by Hebei Province Department of Science And
   Technology (Grant No. 20327217D), Ministry of Science and Technology of
   the People's Republic of China (Grant No. 2019YFE0103700) and Shandong
   Province Department of Science and Technology (Grant No.
   2019JZZY010703).
NR 177
TC 9
Z9 9
U1 40
U2 88
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0044-8486
EI 1873-5622
J9 AQUACULTURE
JI Aquaculture
PD JUL 15
PY 2021
VL 540
AR 736724
DI 10.1016/j.aquaculture.2021.736724
EA APR 2021
PG 19
WC Fisheries; Marine & Freshwater Biology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Fisheries; Marine & Freshwater Biology
GA SB0KV
UT WOS:000649692900007
DA 2022-04-17
ER

PT J
AU Culley, C
   Vijayakumar, S
   Zampieri, G
   Angione, C
AF Culley, Christopher
   Vijayakumar, Supreeta
   Zampieri, Guido
   Angione, Claudio
TI A mechanism-aware and multiomic machine-learning pipeline characterizes
   yeast cell growth
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
LA English
DT Article
DE metabolic modeling; machine learning; flux balance analysis; systems
   biology; multimodal learning
ID GENE-EXPRESSION; RANDOM FORESTS; TRANSCRIPTION; BIOLOGY; MODELS
AB Metabolic modeling and machine learning are key components in the emerging next generation of systems and synthetic biology tools, targeting the genotype-phenotype-environment relationship. Rather than being used in isolation, it is becoming clear that their value is maximized when they are combined. However, the potential of integrating these two frameworks for omic data augmentation and integration is largely unexplored. We propose, rigorously assess, and compare machine-learning- based data integration techniques, combining gene expression profiles with computationally generated metabolic flux data to predict yeast cell growth. To this end, we create strain-specific metabolic models for 1,143 Saccharomyces cerevisiae mutants and we test 27 machine-learning methods, incorporating stateof-the-art feature selection and multiview learning approaches. We propose a multiview neural network using fluxomic and transcriptomic data, showing that the former increases the predictive accuracy of the latter and reveals functional patterns that are not directly deducible from gene expression alone. We test the proposed neural network on a further 86 strains generated in a different experiment, therefore verifying its robustness to an additional independent dataset. Finally, we show that introducing mechanistic flux features improves the predictions also for knockout strains whose genes were not modeled in the metabolic reconstruction. Our results thus demonstrate that fusing experimental cues with in silico models, based on known biochemistry, can contribute with disjoint information toward biologically informed and interpretable machine learning. Overall, this study provides tools for understanding and manipulating complex phenotypes, increasing both the prediction accuracy and the extent of discernible mechanistic biological insights.
C1 [Culley, Christopher] Univ Southampton, Fac Engn & Phys Sci, Southampton SO17 1BJ, Hants, England.
   [Culley, Christopher; Vijayakumar, Supreeta; Zampieri, Guido; Angione, Claudio] Teesside Univ, Dept Comp Sci & Informat Syst, Middlesbrough TS1 3BX, Cleveland, England.
   [Angione, Claudio] Teesside Univ, Healthcare Innovat Ctr, Middlesbrough TS1 3BX, Cleveland, England.
RP Angione, C (corresponding author), Teesside Univ, Dept Comp Sci & Informat Syst, Middlesbrough TS1 3BX, Cleveland, England.; Angione, C (corresponding author), Teesside Univ, Healthcare Innovat Ctr, Middlesbrough TS1 3BX, Cleveland, England.
EM c.angione@tees.ac.uk
OI Vijayakumar, Supreeta/0000-0001-6357-0439; Angione,
   Claudio/0000-0002-3140-7909; ZAMPIERI, GUIDO/0000-0002-4518-5913
FU United Kingdom Research and Innovation (UKRI) Centre for Doctoral
   Training (CDT) in Machine Intelligence for Nano-electronic Devices and
   Systems [EP/S024298/1]; Biotechnology and Biological Sciences Research
   Council (BBSRC)UK Research & Innovation (UKRI)Biotechnology and
   Biological Sciences Research Council (BBSRC) [CBMNet-PoC-D0156,
   NPRONET-BIV-015 (BB/L013754/1)]; Teesside University; UKRI Research
   England's Teesside, Hull and York - mobilising bioeconomy knowledge
   exchange (THYME) project; BBSRCUK Research & Innovation
   (UKRI)Biotechnology and Biological Sciences Research Council (BBSRC)
   [BB/L013754/1] Funding Source: UKRI
FX C.C. was supported by the United Kingdom Research and Innovation (UKRI)
   Centre for Doctoral Training (CDT) in Machine Intelligence for
   Nano-electronic Devices and Systems (EP/S024298/1). C.A. received
   funding from Biotechnology and Biological Sciences Research Council
   (BBSRC), Grants CBMNet-PoC-D0156 and NPRONET-BIV-015 (BB/L013754/1).
   G.Z. and C.A. were also supported by Teesside University and by UKRI
   Research England's Teesside, Hull and York - mobilising bioeconomy
   knowledge exchange (THYME) project.
NR 63
TC 9
Z9 9
U1 7
U2 17
PU NATL ACAD SCIENCES
PI WASHINGTON
PA 2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA
SN 0027-8424
J9 P NATL ACAD SCI USA
JI Proc. Natl. Acad. Sci. U. S. A.
PD AUG 4
PY 2020
VL 117
IS 31
BP 18869
EP 18879
DI 10.1073/pnas.2002959117
PG 11
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA NX1RC
UT WOS:000575493200008
PM 32675233
OA Green Published, Green Submitted, Green Accepted
DA 2022-04-17
ER

PT J
AU El Allali, A
   Elhamraoui, Z
   Daoud, R
AF El Allali, A.
   Elhamraoui, Zahra
   Daoud, Rachid
TI Machine learning applications in RNA modification sites prediction
SO COMPUTATIONAL AND STRUCTURAL BIOTECHNOLOGY JOURNAL
LA English
DT Review
DE RNA modification; Machine learning; Deep learning; Feature extraction;
   Prediction
ID 5-METHYLCYTOSINE SITES; FEATURE-SELECTION; CHEMICAL-PROPERTIES; EDITING
   SITES; WEB SERVER; DATABASE; ADENOSINE; FEATURES; MODEL
AB Ribonucleic acid (RNA) modifications are post-transcriptional chemical composition changes that have a fundamental role in regulating the main aspect of RNA function. Recently, large datasets have become available thanks to the recent development in deep sequencing and large-scale profiling. This availability of transcriptomic datasets has led to increased use of machine learning based approaches in epitranscriptomics, particularly in identifying RNA modifications. In this review, we comprehensively explore machine learning based approaches used for the prediction of 11 RNA modification types, namely, m(1)A, m(6)A, m(5)C, 5hmC, psi, 2' -O -Me, alpha c4C, m(7)G, A -to -I, m(2)G, and D. This review covers the life cycle of machine learning methods to predict RNA modification sites including available benchmark datasets, feature extraction, and classification algorithms. We compare available methods in terms of datasets, target species, approach, and accuracy for each RNA modification type. Finally, we discuss the advantages and limitations of the reviewed approaches and suggest future perspectives. (C) 2021 The Author(s). Published by Elsevier B.V. on behalf of Research Network of Computational and Structural Biotechnology.
C1 [El Allali, A.; Elhamraoui, Zahra; Daoud, Rachid] Univ Mohamed VI Polytech, African Genome Ctr, Ben Guerir, Morocco.
RP El Allali, A (corresponding author), Univ Mohamed VI Polytech, African Genome Ctr, Ben Guerir, Morocco.
EM achraf.elallali@um6p.ma
OI El Allali, Achraf/0000-0002-4561-2161
NR 98
TC 0
Z9 0
U1 12
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2001-0370
J9 COMPUT STRUCT BIOTEC
JI Comp. Struct. Biotechnol. J..
PY 2021
VL 19
BP 5510
EP 5524
DI 10.1016/j.csbj.2021.09.0252001-0370
PG 15
WC Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology
GA WP1DV
UT WOS:000712881800010
PM 34712397
DA 2022-04-17
ER

PT J
AU Mewes, B
   Oppel, H
   Marx, V
   Hartmann, A
AF Mewes, B.
   Oppel, H.
   Marx, V.
   Hartmann, A.
TI Information-Based Machine Learning for Tracer Signature Prediction in
   Karstic Environments
SO WATER RESOURCES RESEARCH
LA English
DT Article
DE Machine learning; entropy; information content; karst; hydrograph
   separation
ID SUPPORT VECTOR MACHINE; ARTIFICIAL NEURAL-NETWORK; BASEFLOW SEPARATION;
   STABLE-ISOTOPES; RAINFALL; MODEL; WATER; FLOW; MANAGEMENT; RECHARGE
AB Karstic groundwater systems are often investigated by a combination of environmental or artificial tracers. One of the major downsides of tracer-based methods is the limited availability of tracer measurements, especially in data sparse regions. This study presents an approach to systematically evaluate the information content of the available data, to interpret predictions of tracer concentration from machine learning algorithms, and to compare different machine learning algorithms to obtain an objective assessment of their applicability for predicting environmental tracers. There is a large variety of machine learning approaches, but no clear rules exist on which of them to use for this specific problem. In this study, we formulated a framework to choose the appropriate algorithm for this purpose. We compared four different well-established machine learning algorithms (Support Vector Machines, Extreme Learning Machines, Decision Trees, and Artificial Neural Networks) in seven different karst springs in France for their capability to predict tracer concentrations, in this case SO42- and NO3-, from discharge. Our study reveals that the machine learning algorithms are able to predict some characteristics of the tracer concentration, but not the whole variance, which is caused by the limited information content in the discharge data. Nevertheless, discharge is often the only information available for a catchment, so the ability to predict at least some characteristics of the tracer concentrations from discharge time series to fill, for example, gaps or increase the database for consecutive analyses is a helpful application of machine learning in data sparse regions or for historic databases.
C1 [Mewes, B.; Oppel, H.] Ruhr Univ Bochum, Inst Hydrol Water Resources & Environm Engn, Bochum, Germany.
   [Oppel, H.; Marx, V.; Hartmann, A.] Albert Ludwigs Univ Freiburg, Hydrol Modeling & Water Resources, Freiburg, Germany.
RP Mewes, B (corresponding author), Ruhr Univ Bochum, Inst Hydrol Water Resources & Environm Engn, Bochum, Germany.
EM benjamin.mewes@rub.de
RI Hartmann, Andreas/J-8515-2014
OI Hartmann, Andreas/0000-0003-0407-742X; Oppel,
   Henning/0000-0002-2761-8674
FU Emmy NoetherProgramme of the German Research Foundation (DFG)German
   Research Foundation (DFG) [HA 8113/1-1]
FX Support to Andreas Hartmann was provided by the Emmy NoetherProgramme of
   the German Research Foundation (DFG; Grant HA 8113/1-1; project "Global
   Assessment of Water Stress in Karst Regions in a Changing World").
NR 66
TC 5
Z9 5
U1 0
U2 12
PU AMER GEOPHYSICAL UNION
PI WASHINGTON
PA 2000 FLORIDA AVE NW, WASHINGTON, DC 20009 USA
SN 0043-1397
EI 1944-7973
J9 WATER RESOUR RES
JI Water Resour. Res.
PD FEB
PY 2020
VL 56
IS 2
AR e2018WR024558
DI 10.1029/2018WR024558
PG 20
WC Environmental Sciences; Limnology; Water Resources
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Environmental Sciences & Ecology; Marine & Freshwater Biology; Water
   Resources
GA LR4NE
UT WOS:000535672800025
OA Green Published
DA 2022-04-17
ER

PT J
AU Christensen, AS
   Von Lilienfeld, OA
AF Christensen, Anders S.
   Von Lilienfeld, O. Anatole
TI On the role of gradients for machine learning of molecular energies and
   forces
SO MACHINE LEARNING-SCIENCE AND TECHNOLOGY
LA English
DT Article
DE chemistry; machine learning; quantum mechanics
AB The accuracy of any machine learning potential can only be as good as the data used in the fitting process. The most efficient model therefore selects the training data that will yield the highest accuracy compared to the cost of obtaining the training data. We investigate the convergence of prediction errors of quantum machine learning models for organic molecules trained on energy and force labels, two common data types in molecular simulations. When training models for the potential energy surface of a single molecule, we find that the inclusion of atomic forces in the training data increases the accuracy of the predicted energies and forces 7-fold, compared to models trained on energy only. Surprisingly, for models trained on sets of organic molecules of varying size and composition in non-equilibrium conformations, inclusion of forces in the training does not improve the predicted energies of unseen molecules in new conformations. Predicted forces, however, improve about 7-fold. For the systems studied, we find that force labels and energy labels contribute equally per label to the convergence of the prediction errors. The optimal choice of what type of training data to include depends on several factors: the computational cost of acquiring the force and energy labels for training, the application domain, the property of interest and the complexity of the machine learning model. Based on our observations we describe key considerations for the creation of new datasets for potential energy surfaces of molecules which maximize the efficiency of the resulting machine learning models.
C1 [Christensen, Anders S.; Von Lilienfeld, O. Anatole] Univ Basel, Dept Chem, Inst Phys Chem, Natl Ctr Computat Design & Discovery Novel Mat MA, Klingelbergst 80, CH-4056 Basel, Switzerland.
RP Von Lilienfeld, OA (corresponding author), Univ Basel, Dept Chem, Inst Phys Chem, Natl Ctr Computat Design & Discovery Novel Mat MA, Klingelbergst 80, CH-4056 Basel, Switzerland.
EM anatole.vonlilienfeld@unibas.ch
RI Christensen, Anders Steen/M-2001-2013
OI Christensen, Anders Steen/0000-0002-7253-6897
FU NCCR MARVEL - Swiss National Science FoundationSwiss National Science
   Foundation (SNSF); Swiss National Science foundationSwiss National
   Science Foundation (SNSF)European Commission [407540_167186 NFP 75];
   European Research Council (ERC-CoG grant QML)
FX This work was partly supported by the NCCR MARVEL, funded by the Swiss
   National Science Foundation. O.A.v.L. acknowledges funding from the
   Swiss National Science foundation (407540_167186 NFP 75 Big Data) and
   from the European Research Council (ERC-CoG grant QML). The authors
   thank Puck van Gerwen for helpful comments on the manuscript. We further
   acknowledge the use of the following software: NumPy and the F2PY tool
   [57] and OpenMP [58].
NR 57
TC 11
Z9 11
U1 1
U2 2
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
EI 2632-2153
J9 MACH LEARN-SCI TECHN
JI Mach. Learn.-Sci. Technol.
PD DEC
PY 2020
VL 1
IS 4
AR 045018
DI 10.1088/2632-2153/abba6f
PG 14
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Science & Technology - Other Topics
GA VK7YC
UT WOS:000754876300020
OA Green Submitted, gold
DA 2022-04-17
ER

PT J
AU Villoutreix, P
AF Villoutreix, Paul
TI What machine learning can do for developmental biology
SO DEVELOPMENT
LA English
DT Review
DE Artificial intelligence; Big data; Machine learning; Neural networks
ID NUCLEUS SEGMENTATION; DEEP; NETWORKS
AB Developmental biology has grown into a data intensive science with the development of high-throughput imaging and multi-omics approaches. Machine learning is a versatile set of techniques that can help make sense of these large datasets with minimal human intervention, through tasks such as image segmentation, super-resolution microscopy and cell clustering. In this Spotlight, I introduce the key concepts, advantages and limitations of machine learning, and discuss how these methods are being applied to problems in developmental biology. Specifically, I focus on how machine learning is improving microscopy and single-cell 'omics' techniques and data analysis. Finally, I provide an outlook for the futures of these fields and suggest ways to foster new interdisciplinary developments.
C1 [Villoutreix, Paul] Aix Marseille Univ, LIS UMR 7020, IBDM UMR 7288, Turing Ctr Living Syst, F-13009 Marseille, France.
RP Villoutreix, P (corresponding author), Aix Marseille Univ, LIS UMR 7020, IBDM UMR 7288, Turing Ctr Living Syst, F-13009 Marseille, France.
EM paul.villoutreix@univ-amu.fr
FU Turing Center for Living Systems of Aix-Marseille Universite
FX This work has been funded by the Turing Center for Living Systems of
   Aix-Marseille Universite.
NR 49
TC 4
Z9 4
U1 4
U2 8
PU COMPANY BIOLOGISTS LTD
PI CAMBRIDGE
PA BIDDER BUILDING, STATION RD, HISTON, CAMBRIDGE CB24 9LF, ENGLAND
SN 0950-1991
EI 1477-9129
J9 DEVELOPMENT
JI Development
PD JAN
PY 2021
VL 148
IS 1
AR dev188474
DI 10.1242/dev.188474
PG 6
WC Developmental Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Developmental Biology
GA PZ1UA
UT WOS:000612523700004
PM 33431591
OA Green Published, Bronze
DA 2022-04-17
ER

PT J
AU Jullum, M
   Loland, A
   Huseby, RB
   Anonsen, G
   Lorentzen, J
AF Jullum, Martin
   Loland, Anders
   Huseby, Ragnar Bang
   Anonsen, Geir
   Lorentzen, Johannes
TI Detecting money laundering transactions with machine learning
SO JOURNAL OF MONEY LAUNDERING CONTROL
LA English
DT Article
DE Machine learning; XGBoost; Supervised learning; Suspicious transaction
AB Purpose
   The purpose of this paper is to develop, describe and validate a machine learning model for prioritising which financial transactions should be manually investigated for potential money laundering. The model is applied to a large data set from Norway's largest bank, DNB.
   Design/methodology/approach
   A supervised machine learning model is trained by using three types of historic data: "normal" legal transactions; those flagged as suspicious by the bank's internal alert system; and potential money laundering cases reported to the authorities. The model is trained to predict the probability that a new transaction should be reported, using information such as background information about the sender/receiver, their earlier behaviour and their transaction history.
   Findings
   The paper demonstrates that the common approach of not using non-reported alerts (i.e. transactions that are investigated but not reported) in the training of the model can lead to sub-optimal results. The same applies to the use of normal (un-investigated) transactions. Our developed method outperforms the bank's current approach in terms of a fair measure of performance.
   Originality/value
   This research study is one of very few published anti-money laundering (AML) models for suspicious transactions that have been applied to a realistically sized data set. The paper also presents a new performance measure specifically tailored to compare the proposed method to the bank's existing AML system.
C1 [Jullum, Martin; Loland, Anders; Huseby, Ragnar Bang] Norwegian Comp Ctr, Oslo, Norway.
   [Anonsen, Geir; Lorentzen, Johannes] DNB, Oslo, Norway.
RP Jullum, M (corresponding author), Norwegian Comp Ctr, Oslo, Norway.
EM jullum@nr.no; anders.loland@nr.no; ragnar.huseby@nr.no;
   geir.anonsen@dnb.no; jpl@dnb.no
RI Jullum, Martin/AAW-6123-2021
OI Jullum, Martin/0000-0003-3908-5155
NR 32
TC 11
Z9 12
U1 4
U2 11
PU EMERALD GROUP PUBLISHING LTD
PI BINGLEY
PA HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND
SN 1758-7808
EI 1368-5201
J9 J MONEY LAUND CONTRO
JI J. Money Laund. Control
PD JAN 4
PY 2020
VL 23
IS 1
BP 173
EP 186
DI 10.1108/JMLC-07-2019-0055
PG 14
WC Criminology & Penology
WE Emerging Sources Citation Index (ESCI)
SC Criminology & Penology
GA KH3JC
UT WOS:000510541300002
DA 2022-04-17
ER

PT C
AU Wang, X
   Zhu, WW
AF Wang, Xin
   Zhu, Wenwu
GP ASSOC COMP MACHINERY
TI Automated Machine Learning on Graph
SO KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE
   DISCOVERY & DATA MINING
LA English
DT Proceedings Paper
CT 27th ACM SIGKDD International Conference on Knowledge Discovery and Data
   Mining (KDD)
CY AUG 14-18, 2021
CL ELECTR NETWORK
SP Assoc Comp Machinery, ACM SIGMOD, ACM SIGKDD
DE AutoML; Graph Representation Learning
AB Machine learning on graphs has been extensively studied in both academic and industry. However, as the literature on graph learning booms with a vast number of emerging methods and techniques, it becomes increasingly difficult to manually design the optimal machine learning algorithm for different graph-related tasks. To solve this critical challenge, automated machine learning (AutoML) on graphs which combines the strength of graph machine learning and AutoML together, is gaining attentions from the research community. In this tutorial, we discuss AutoML on graphs, primarily focusing on hyper-parameter optimization (HPO) and neural architecture search (NAS) for graph machine learning. We further overview libraries related to automated graph machine learning and in depth discuss AutoGL, the first dedicated open-source library for AutoML on graphs. In the end, we share our insights on future research directions for automated graph machine learning. To the best of our knowledge, this tutorial is the first to systematically and comprehensively review automated machine learning on graphs, possessing a great potential to draw a large amount of interests in the community.
C1 [Wang, Xin; Zhu, Wenwu] Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China.
RP Wang, X (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China.
EM xin_wang@tsinghua.edu.cn; wwzhu@tsinghua.edu.cn
NR 26
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-8332-5
PY 2021
BP 4082
EP 4083
DI 10.1145/3447548.3470804
PG 2
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS6LU
UT WOS:000749556804037
DA 2022-04-17
ER

PT C
AU Safar, A
   Safar, M
AF Safar, Amna
   Safar, Maytham
BE Bi, Y
   Bhatia, R
   Kapoor, S
TI Intelligent Flower Detection System Using Machine Learning
SO INTELLIGENT SYSTEMS AND APPLICATIONS, VOL 2
SE Advances in Intelligent Systems and Computing
LA English
DT Proceedings Paper
CT Intelligent Systems Conference (IntelliSys)
CY SEP 05-06, 2019
CL London, ENGLAND
DE Machine learning; Flower classification; ResNet model
ID RECOGNITION
AB It is a very hard and a challenging mission to identify different types of flowers as they are very similar. Even expert botanists and gardeners cannot identify some of them accurately. The idea of automating flowers recognition is bewildering as the flowers are not rigid objects and their images can be affected by many External influences. The proposed system use machine learning algorithms to fully automate and increase the accuracy of flower classification. Machine learning model will be used to extract flower's features automatically, process through different layers of the neural network and finally classify the flower class. The proposed work is based on "Resnet" model, which is used for classification task. Resnet won the first place on ILSVRC 2015. Many enhancements have been made on Resnet model to improve the accuracy. Fine tuning, dropout ratio and class weight are some of the proposed model enhancements. The proposed model reaches 92% accuracy, which is the highest percent till the moment.
C1 [Safar, Amna; Safar, Maytham] Kuwait Univ, Kuwait, Kuwait.
RP Safar, A (corresponding author), Kuwait Univ, Kuwait, Kuwait.
EM eng.safar@gmail.com; Maytham.safar@ku.edu.kw
FU Kuwait Foundation for the Advancement of Sciences (KFAS)Kuwait
   Foundation for the Advancement of Sciences (KFAS); College of Graduate
   Studies, Kuwait University
FX This research was supported by Kuwait Foundation for the Advancement of
   Sciences (KFAS) and College of Graduate Studies, Kuwait University.
   Special thanks to Prof. Maytham Safar who provided insight and expertise
   that greatly assisted the research. We would also like to thank the
   experts who were involved in the validation for this research project.
NR 12
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2194-5357
EI 2194-5365
BN 978-3-030-29513-4; 978-3-030-29512-7
J9 ADV INTELL SYST COMP
PY 2020
VL 1038
BP 463
EP 472
DI 10.1007/978-3-030-29513-4_33
PG 10
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR0ER
UT WOS:000628838900033
DA 2022-04-17
ER

PT J
AU Dumakor-Dupey, NK
   Arya, S
AF Dumakor-Dupey, Nelson K.
   Arya, Sampurna
TI Machine Learning-A Review of Applications in Mineral Resource Estimation
SO ENERGIES
LA English
DT Review
DE resource estimation; geostatistics; machine learning; kriging; reserve
   estimation; ore
ID SUPPORT VECTOR MACHINE; IRON-ORE DEPOSIT; SEQUENTIAL GAUSSIAN
   SIMULATION; ARTIFICIAL NEURAL-NETWORKS; RANDOM FOREST CLASSIFIER;
   RESERVE ESTIMATION; CONCEPT DRIFT; ALTERATION ZONES; GRADE ESTIMATION;
   GEOCHEMICAL ANOMALIES
AB Mineral resource estimation involves the determination of the grade and tonnage of a mineral deposit based on its geological characteristics using various estimation methods. Conventional estimation methods, such as geometric and geostatistical techniques, remain the most widely used methods for resource estimation. However, recent advances in computer algorithms have allowed researchers to explore the potential of machine learning techniques in mineral resource estimation. This study presents a comprehensive review of papers that have employed machine learning to estimate mineral resources. The review covers popular machine learning techniques and their implementation and limitations. Papers that performed a comparative analysis of both conventional and machine learning techniques were also considered. The literature shows that the machine learning models can accommodate several geological parameters and effectively approximate complex nonlinear relationships among them, exhibiting superior performance over the conventional techniques.
C1 [Dumakor-Dupey, Nelson K.; Arya, Sampurna] Univ Alaska Fairbanks, Coll Engn & Mines, Dept Min & Mineral Engn, Fairbanks, AK 99775 USA.
RP Dumakor-Dupey, NK (corresponding author), Univ Alaska Fairbanks, Coll Engn & Mines, Dept Min & Mineral Engn, Fairbanks, AK 99775 USA.
EM nkdumakordupey@alaska.edu; snarya@alaska.edu
RI Arya, Sampurna/T-4776-2019
OI Arya, Sampurna/0000-0002-6796-3974; Dumakor-Dupey,
   Nelson/0000-0001-7385-2173
NR 163
TC 1
Z9 1
U1 15
U2 21
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1996-1073
J9 ENERGIES
JI Energies
PD JUL
PY 2021
VL 14
IS 14
AR 4079
DI 10.3390/en14144079
PG 29
WC Energy & Fuels
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Energy & Fuels
GA TO2LO
UT WOS:000676750300001
OA gold
DA 2022-04-17
ER

PT C
AU Fredriksson, T
   Bosch, J
   Olsson, H
AF Fredriksson, Teodor
   Bosch, Jan
   Olsson, Helena
BE Vansinderen, M
   Fill, HG
   Maciaszek, L
TI Machine Learning Models for Automatic Labeling: A Systematic Literature
   Review
SO ICSOFT: PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON SOFTWARE
   TECHNOLOGIES
LA English
DT Proceedings Paper
CT 15th International Conference on Software Technologies (ICSOFT)
CY JUL 07-09, 2020
CL ELECTR NETWORK
DE Semi-supervised Learning; Active Machine Learning; Automatic Labeling
AB Automatic labeling is a type of classification problem. Classification has been studied with the help of statistical methods for a long time. With the explosion of new better computer processing units (CPUs) and graphical processing units (GPUs) the interest in machine learning has grown exponentially and we can use both statistical learning algorithms as well as deep neural networks (DNNs) to solve the classification tasks. Classification is a supervised machine learning problem and there exists a large amount of methodology for performing such task. However, it is very rare in industrial applications that data is fully labeled which is why we need good methodology to obtain error-free labels. The purpose of this paper is to examine the current literature on how to perform labeling using ML, we will compare these models in terms of popularity and on what datatypes they are used on. We performed a systematic literature review of empirical studies for machine learning for labeling. We identified 43 primary studies relevant to our search. From this we were able to determine the most common machine learning models for labeling. Lack of unlabeled instances is a major problem for industry as supervised learning is the most widely used. Obtaining labels is costly in terms of labor and financial costs. Based on our findings in this review we present alternate ways for labeling data for use in supervised learning tasks.
C1 [Fredriksson, Teodor; Bosch, Jan] Chalmers Univ Technol, Dept Comp Sci & Engn, Div Software Engn, Gothenburg, Sweden.
   [Olsson, Helena] Malm Univ, Dept Comp Sci & Media Technol, Malm, Sweden.
RP Fredriksson, T (corresponding author), Chalmers Univ Technol, Dept Comp Sci & Engn, Div Software Engn, Gothenburg, Sweden.
FU Wallenberg AI Autonomous Systems and Software Program (WASP) - Knut and
   Alice Wallenberg Fundation
FX This work was partially supported by the Wallenberg AI Autonomous
   Systems and Software Program (WASP) funded by Knut and Alice Wallenberg
   Fundation.
NR 55
TC 2
Z9 2
U1 1
U2 2
PU SCITEPRESS
PI SETUBAL
PA AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL
BN 978-989-758-443-5
PY 2020
BP 552
EP 561
DI 10.5220/0009972705520561
PG 10
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ7AZ
UT WOS:000614139800057
OA hybrid
DA 2022-04-17
ER

PT J
AU Kim, JM
   Xia, LX
   Kim, I
   Lee, S
   Lee, KH
AF Kim, Jong-Min
   Xia, Leixin
   Kim, Iksuk
   Lee, Seungjoo
   Lee, Keon-Hyung
TI Finding Nemo: Predicting Movie Performances by Machine Learning Methods
SO JOURNAL OF RISK AND FINANCIAL MANAGEMENT
LA English
DT Article
DE quantile regression; neural network; machine learning; forecasting
ID BOX-OFFICE; SUCCESS; REVIEWS
AB Analyzing the success of movies has always been a popular research topic in the film industry. Artificial intelligence and machine learning methods in the movie industry have been applied to modeling the financial success of the movie industry. The new contribution of this research combined Bayesian variable selection and machine learning methods for forecasting the return on investment (ROI). We also attempt to compare machine learning methods including the quantile regression model with movie performance data in terms of in-sample and out of sample forecasting.
C1 [Kim, Jong-Min] Univ Minnesota, Div Sci & Math, Stat Discipline, Morris, MN 56267 USA.
   [Xia, Leixin] Univ Texas Hlth Sci Ctr Houston, Dept Biostat & Data Sci, Houston, TX 77030 USA.
   [Kim, Iksuk] Calif State Univ Los Angeles, Dept Mkt, 5151 State Univ Dr, Los Angeles, CA 90032 USA.
   [Lee, Seungjoo] Cheongju Univ, Dept Big Data & Stat, Chungbuk 28503, South Korea.
   [Lee, Keon-Hyung] Florida State Univ, Askew Sch Publ Adm & Policy, Tallahassee, FL 32306 USA.
RP Lee, KH (corresponding author), Florida State Univ, Askew Sch Publ Adm & Policy, Tallahassee, FL 32306 USA.
EM jongmink@morris.umn.edu; Leixin.Xia@uth.tmc.edu; ikim@calstatela.edu;
   access@cju.ac.kr; klee2@fsu.edu
OI Kim, Jong-Min/0000-0003-3821-2060
NR 27
TC 0
Z9 0
U1 4
U2 7
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 1911-8066
EI 1911-8074
J9 J RISK FINANC MANAG
JI J. Risk Financ. Manag.
PD MAY
PY 2020
VL 13
IS 5
AR 93
DI 10.3390/jrfm13050093
PG 12
WC Business, Finance
WE Emerging Sources Citation Index (ESCI)
SC Business & Economics
GA MA6QQ
UT WOS:000542037300007
OA gold
DA 2022-04-17
ER

PT J
AU Bannigan, P
   Aldeghi, M
   Bao, ZQ
   Hase, F
   Aspuru-Guzik, A
   Allen, C
AF Bannigan, Pauric
   Aldeghi, Matteo
   Bao, Zeqing
   Hase, Florian
   Aspuru-Guzik, Alan
   Allen, Christine
TI Machine learning directed drug formulation development
SO ADVANCED DRUG DELIVERY REVIEWS
LA English
DT Review
DE Machine learning; Deep learning; Drug delivery; Drug development
ID ARTIFICIAL NEURAL-NETWORKS; OSMOTIC PUMP TABLETS; PARTICLE-SIZE;
   EXPERT-SYSTEM; RELEASE; PREDICTION; NANOPARTICLES; DELIVERY; DESIGN;
   OPTIMIZATION
AB Machine learning (ML) has enabled ground-breaking advances in the healthcare and pharmaceutical sectors, from improvements in cancer diagnosis, to the identification of novel drugs and drug targets as well as protein structure prediction. Drug formulation is an essential stage in the discovery and development of new medicines. Through the design of drug formulations, pharmaceutical scientists can engineer important properties of new medicines, such as improved bioavailability and targeted delivery. The traditional approach to drug formulation development relies on iterative trial-and-error, requiring a large number of resource-intensive and time-consuming in vitro and in vivo experiments. This review introduces the basic concepts of ML-directed workflows and discusses how these tools can be used to aid in the development of various types of drug formulations. ML-directed drug formulation development offers unparalleled opportunities to fast-track development efforts, uncover new materials, innovative formulations, and generate new knowledge in drug formulation science. The review also highlights the latest artificial intelligence (AI) technologies, such as generative models, Bayesian deep learning, reinforcement learning, and self-driving laboratories, which have been gaining momentum in drug discovery and chemistry and have potential in drug formulation development. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Bannigan, Pauric; Bao, Zeqing; Allen, Christine] Univ Toronto, Leslie Dan Fac Pharm, Toronto, ON M5S 3M2, Canada.
   [Aldeghi, Matteo; Hase, Florian; Aspuru-Guzik, Alan] Univ Toronto, Dept Chem, Chem Phys Theory Grp, Toronto, ON M5S 3H6, Canada.
   [Aldeghi, Matteo; Hase, Florian; Aspuru-Guzik, Alan] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3H6, Canada.
   [Aldeghi, Matteo; Hase, Florian; Aspuru-Guzik, Alan] Vector Inst Artificial Intelligence, Toronto, ON M5S 1M1, Canada.
   [Aspuru-Guzik, Alan] Canadian Inst Adv Res, Toronto, ON M5S 1M1, Canada.
RP Allen, C (corresponding author), Univ Toronto, Leslie Dan Fac Pharm, Toronto, ON M5S 3M2, Canada.; Aspuru-Guzik, A (corresponding author), Univ Toronto, Dept Chem, Chem Phys Theory Grp, Toronto, ON M5S 3H6, Canada.
EM alan@aspuru.com; cj.allen@utoronto.ca
RI ; Hase, Florian/Y-9650-2018
OI Bao, Zeqing/0000-0002-2328-5331; Aldeghi, Matteo/0000-0003-0019-8806;
   Allen, Christine/0000-0002-4916-3965; Hase, Florian/0000-0003-3711-9761
FU NSERCNatural Sciences and Engineering Research Council of Canada (NSERC)
   [RGPIN-2016-04293]; Defense Advanced Research Projects Agency under the
   Accelerated Molecular Discovery Program [HR00111920027]; Vector
   Institute
FX NSERC Discovery grant (RGPIN-2016-04293) to C. A. F.H., M.A., and A.A.G.
   acknowledge support by the Defense Advanced Research Projects Agency
   under the Accelerated Molecular Discovery Program under Cooperative
   Agreement No. HR00111920027 dated August 1, 2019. A.A.G. would like to
   thank Dr. Anders Froseth for his support. M.A. is supported by a
   Postdoctoral Fellowship of the Vector Institute.
NR 103
TC 7
Z9 7
U1 35
U2 42
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0169-409X
EI 1872-8294
J9 ADV DRUG DELIVER REV
JI Adv. Drug Deliv. Rev.
PD AUG
PY 2021
VL 175
AR 113806
DI 10.1016/j.addr.2021.05.016
EA JUN 2021
PG 14
WC Pharmacology & Pharmacy
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Pharmacology & Pharmacy
GA TS9VC
UT WOS:000679998800015
PM 34019959
DA 2022-04-17
ER

PT J
AU Moss, J
   Wong, AY
   Durriseau, JA
   Bradshaw, GL
AF Moss, Jarrod
   Wong, Aaron Y.
   Durriseau, Jaymes A.
   Bradshaw, Gary L.
TI Tracking strategy changes using machine learning classifiers
SO BEHAVIOR RESEARCH METHODS
LA English
DT Article; Early Access
DE Strategy; Machine learning; Strategy change
ID INDIVIDUAL-DIFFERENCES
AB In complex tasks, high performers often have better strategies than low performers, even with similar amounts of practice. Relatively little research has examined how people form and change strategies in tasks that permit a large set of strategies. One challenge with such research is identifying strategies based on behavior. Three algorithms were developed that track the task features people use in their strategies while performing a complex task. Two of these algorithms were based on task-general, machine-learning classifiers: a support vector machine and a decision tree algorithm. The third was a task-specific algorithm. Data from several strategies in a complex task were simulated, and the algorithms were tested to see how well they identified the underlying features of the simulated strategy. The two machine-learning classifiers performed better than the task-specific algorithm. However, the two classifiers differed on how well they identified different types of strategies. The first two studies show that the ability of these algorithms to recover the underlying strategy depends on the complexity of the strategy relative to the quantity of performance data available. If the underlying strategy changes too frequently, then the performance of the algorithms suffers. However, results from the third study show that it is possible to use these algorithms to track strategy changes that occur in a task. The fourth study examines performance on data from human participants. This approach to tracking strategy exploration may enable further development of theories about how people search for and select effective strategies.
C1 [Moss, Jarrod; Wong, Aaron Y.; Durriseau, Jaymes A.; Bradshaw, Gary L.] Mississippi State Univ, Dept Psychol, POB 6161, Mississippi State, MS 39762 USA.
RP Moss, J (corresponding author), Mississippi State Univ, Dept Psychol, POB 6161, Mississippi State, MS 39762 USA.
EM jarrod.moss@msstate.edu
FU Office of Naval ResearchOffice of Naval Research [N00014-17-1-2324]
FX This research was supported by Office of Naval Research grant
   N00014-17-1-2324. The authors would like to thank Kevin Barnes, Taras
   Krupskyy, and Daniel Roberson for assistance with data collection and
   testing the algorithms.
NR 26
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1554-351X
EI 1554-3528
J9 BEHAV RES METHODS
JI Behav. Res. Methods
DI 10.3758/s13428-021-01720-4
EA OCT 2021
PG 23
WC Psychology, Mathematical; Psychology, Experimental
WE Social Science Citation Index (SSCI)
SC Psychology
GA WM7YD
UT WOS:000711295700001
PM 34704215
DA 2022-04-17
ER

PT J
AU Kochkov, D
   Smith, JA
   Alieva, A
   Wang, Q
   Brenner, MP
   Hoyer, S
AF Kochkov, Dmitrii
   Smith, Jamie A.
   Alieva, Ayya
   Wang, Qing
   Brenner, Michael P.
   Hoyer, Stephan
TI Machine learning-accelerated computational fluid dynamics
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
LA English
DT Article
DE machine learning; turbulence; computational physics; nonlinear partial
   differential equations
ID LARGE-EDDY SIMULATION
AB Numerical simulation of fluids plays an essential role in modeling many physical phenomena, such as weather, climate, aerodynamics, and plasma physics. Fluids are well described by the Navier- Stokes equations, but solving these equations at scale remains daunting, limited by the computational cost of resolving the smallest spatiotemporal features. This leads to unfavorable tradeoffs between accuracy and tractability. Here we use end-to-end deep learning to improve approximations inside computational fluid dynamics for modeling two-dimensional turbulent flows. For both direct numerical simulation of turbulence and large-eddy simulation, our results are as accurate as baseline solvers with 8 to 10x finer resolution in each spatial dimension, resulting in 40- to 80-fold computational speedups. Our method remains stable during long simulations and generalizes to forcing functions and Reynolds numbers outside of the flows where it is trained, in contrast to black-box machine-learning approaches. Our approach exemplifies how scientific computing can leverage machine learning and hardware accelerators to improve simulations without sacrificing accuracy or generalization.
C1 [Kochkov, Dmitrii; Smith, Jamie A.; Alieva, Ayya; Wang, Qing; Brenner, Michael P.; Hoyer, Stephan] Google Res, Mountain View, CA 94043 USA.
   [Brenner, Michael P.] Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA.
RP Kochkov, D; Smith, JA; Brenner, MP; Hoyer, S (corresponding author), Google Res, Mountain View, CA 94043 USA.; Brenner, MP (corresponding author), Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA.
EM dkochkov@google.com; jamieas@google.com; brenner@seas.harvard.edu;
   shoyer@google.com
OI Hoyer, Stephan/0000-0002-5207-0380; Brenner, Michael/0000-0002-5673-7947
NR 54
TC 33
Z9 34
U1 41
U2 62
PU NATL ACAD SCIENCES
PI WASHINGTON
PA 2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA
SN 0027-8424
J9 P NATL ACAD SCI USA
JI Proc. Natl. Acad. Sci. U. S. A.
PD MAY 25
PY 2021
VL 118
IS 21
AR e2101784118
DI 10.1073/pnas.2101784118
PG 8
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA SP1NI
UT WOS:000659438500022
PM 34006645
OA Green Published, hybrid, Green Submitted
HC Y
HP N
DA 2022-04-17
ER

PT J
AU Rashid, M
   Singh, H
   Goyal, V
AF Rashid, Mamoon
   Singh, Harjeet
   Goyal, Vishal
TI The use of machine learning and deep learning algorithms in functional
   magnetic resonance imaging-A systematic review
SO EXPERT SYSTEMS
LA English
DT Review
DE algorithms; artificial intelligence; deep learning; functional MRI;
   machine learning; systematic review
ID RESTING-STATE FMRI; LOW-FREQUENCY FLUCTUATIONS; MILD COGNITIVE
   IMPAIRMENT; SUPPORT VECTOR MACHINE; MULTIVARIATE PATTERN-ANALYSIS;
   REGIONAL HOMOGENEITY CHANGES; ANTERIOR CINGULATE CORTEX; BRAIN ACTIVITY;
   ALZHEIMERS-DISEASE; BIPOLAR DISORDER
AB Functional Magnetic Resonance Imaging (fMRI) is presently one of the most popular techniques for analysing the dynamic states in brain images using various kinds of algorithms. From the last decade, there is an exponential rise in the use of the machine and deep learning algorithms of artificial intelligence for analysing fMRI data. However, it is a big challenge for every researcher to choose a suitable machine or deep learning algorithm for analysing fMRI data due to the availability of a large number of algorithms in the literature. It takes much time for each researcher to know about the various approaches and algorithms which are in use for fMRI data. This paper provides a review in a systematic manner for the present literature of fMRI data that makes use of the machine and deep learning algorithms. The major goals of this review paper are to (a) identify machine learning and deep learning research trends for the implementation of fMRI; (b) identify usage of Machine Learning Algorithms and deep learning in fMRI, and (c) help new researchers based on fMRI to put their new findings appropriately in existing domain of fMRI research. The results of this systematic review identified various fMRI studies and classified them based on fMRI types, mental diseases, use of machine learning and deep learning algorithms. The authors have provided the studies with the best performance of machine learning and deep learning algorithms used in fMRI. The authors believe that this systematic review will help incoming researchers on fMRI in their future works.
C1 [Rashid, Mamoon] Punjabi Univ, Dept Comp Sci & Engn, Patiala, Punjab, India.
   [Singh, Harjeet] Mata Gujri Coll, Dept Comp Sci, Fatehgarh Sahib, India.
   [Goyal, Vishal] Punjabi Univ, Dept Comp Sci, Patiala, Punjab, India.
RP Rashid, M (corresponding author), Punjabi Univ, Dept Comp Sci & Engn, Patiala, Punjab, India.
EM mamoon873@gmail.com
RI Rashid, Mamoon/AAB-7135-2020; Goyal, Vishal/I-5538-2015
OI Rashid, Mamoon/0000-0002-8302-4571; Goyal, Vishal/0000-0003-2269-7606
NR 272
TC 2
Z9 2
U1 14
U2 42
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0266-4720
EI 1468-0394
J9 EXPERT SYST
JI Expert Syst.
PD DEC
PY 2020
VL 37
IS 6
SI SI
AR e12644
DI 10.1111/exsy.12644
EA OCT 2020
PG 29
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PD8FH
UT WOS:000577397300001
DA 2022-04-17
ER

PT J
AU Ashmore, R
   Calinescu, R
   Paterson, C
AF Ashmore, Rob
   Calinescu, Radu
   Paterson, Colin
TI Assuring the Machine Learning Lifecycle: Desiderata, Methods, and
   Challenges
SO ACM COMPUTING SURVEYS
LA English
DT Article
DE Machine learning lifecycle; machine learning workflow; safety-critical
   systems; assurance; assurance evidence
ID ARTIFICIAL-INTELLIGENCE; BLACK-BOX; CLASSIFICATION; VISION; ERROR
AB Machine learning has evolved into an enabling technology for a wide range of highly successful applications. The potential for this success to continue and accelerate has placed machine learning (ML) at the top of research, economic, and political agendas. Such unprecedented interest is fuelled by a vision of ML applicability extending to healthcare, transportation, defence, and other domains of great societal importance. Achieving this vision requires the use of ML in safety-critical applications that demand levels of assurance beyond those needed for current ML applications. Our article provides a comprehensive survey of the state of the art in the assurance of ML, i.e., in the generation of evidence that ML is sufficiently safe for its intended use. The survey covers the methods capable of providing such evidence at different stages of the machine learning lifecycle, i.e., of the complex, iterative process that starts with the collection of the data used to train anML component for a system, and ends with the deployment of that component within the system. The article begins with a systematic presentation of the ML lifecycle and its stages. We then define assurance desiderata for each stage, review existing methods that contribute to achieving these desiderata, and identify open challenges that require further research.
C1 [Ashmore, Rob] Def Sci & Technol Lab, Fareham, England.
   [Calinescu, Radu; Paterson, Colin] Univ York, Dept Comp Sci, Deramore Lane, York YO10 5GH, N Yorkshire, England.
   [Ashmore, Rob; Calinescu, Radu; Paterson, Colin] Assuring Auton Int Programme, York, N Yorkshire, England.
   [Ashmore, Rob] DSTL, East Court C Grenville Bldg,Hill Rd, Fareham PO17 6AD, Hants, England.
RP Ashmore, R (corresponding author), Def Sci & Technol Lab, Fareham, England.; Ashmore, R (corresponding author), DSTL, East Court C Grenville Bldg,Hill Rd, Fareham PO17 6AD, Hants, England.
EM rdashmore@dstl.gov.uk; radu.calinescu@york.ac.uk;
   colin.paterson@york.ac.uk
NR 190
TC 4
Z9 4
U1 8
U2 9
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0360-0300
EI 1557-7341
J9 ACM COMPUT SURV
JI ACM Comput. Surv.
PD JUN
PY 2021
VL 54
IS 5
AR 111
DI 10.1145/3453444
PG 39
WC Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH0MB
UT WOS:000671787900020
OA Bronze
DA 2022-04-17
ER

PT C
AU Sunny, MR
   Kabir, MA
   Naheen, IT
   Ahad, MT
AF Sunny, Mahmood Reaz
   Kabir, Md Ahsan
   Naheen, Intisar Tahmid
   Ahad, Md Tanvir
BE Tiako, PF
   Scolli, R
   Jobe, T
TI Residential Energy Management: A Machine Learning Perspective
SO PROCEEDINGS OF THE 2020 IEEE GREEN TECHNOLOGIES CONFERENCE (GREENTECH)
SE IEEE Green Technologies Conference
LA English
DT Proceedings Paper
CT IEEE Green Technologies Conference (GreenTech) - Collaborative
   Technologies
CY APR 01-03, 2020
CL ELECTR NETWORK
SP IEEE, MERCER, Oklahoma Gas & Elect, Oklahoma Christian Univ, BioInspire, Tiako Univ, IEEE Reg 5, IEEE Oklahoma City Sect, IEEE USA
DE Machine learning; residential energy management; smart grids; load
   forecasting; demand response
ID SMART METER DATA; COMFORT MANAGEMENT; BUILDING ENERGY; CONSUMPTION;
   BEHAVIOR; SYSTEMS; SIDE
AB In smart grids, residential energy management is a vital part of demand-side management. It plays a pivotal role in improving the efficiency and sustainability of the power system. However, challenges such as variability of consumption profiles require machine learning to understand and forecast residential demands. Moreover, machine learning based intelligent load management is required for effective implementation of demand response programs. In this article, applications of machine learning algorithms in residential demand forecasting, load profiling, consumer characterization, and load management are comprehensively discussed. The article also examines the characteristics and availability of relevant databases, and explores research challenges and possibilities.
C1 [Sunny, Mahmood Reaz] Uttara Univ, Dept Elect & Elect Engn, Dhaka, Bangladesh.
   [Kabir, Md Ahsan] Mil Inst Sci & Technol, Dept Elect Elect & Commun Engn, Dhaka, Bangladesh.
   [Naheen, Intisar Tahmid] North South Univ, Dept Elect & Comp Engn, Dhaka, Bangladesh.
   [Ahad, Md Tanvir] Univ Oklahoma, Elect & Comp Engn, Norman, OK 73019 USA.
RP Sunny, MR (corresponding author), Uttara Univ, Dept Elect & Elect Engn, Dhaka, Bangladesh.
RI AHAD, TANVIR/AAW-5882-2020
OI AHAD, TANVIR/0000-0001-7624-8668
NR 50
TC 2
Z9 2
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2166-546X
BN 978-1-7281-5017-8
J9 IEEE GREEN TECHNOL
PY 2020
BP 229
EP 234
PG 6
WC Green & Sustainable Science & Technology; Energy & Fuels; Engineering,
   Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Science & Technology - Other Topics; Energy & Fuels; Engineering
GA BS1DF
UT WOS:000687573400046
DA 2022-04-17
ER

PT J
AU Li, JT
   Zhou, KL
   Mu, BY
AF Li, Juntao
   Zhou, Kanglei
   Mu, Bingyu
TI Machine Learning for Mass Spectrometry Data Analysis in Proteomics
SO CURRENT PROTEOMICS
LA English
DT Review
DE Mass spectrometry; high-throughput technique; machine learning; deep
   learning; computational proteomics; protein identification
ID SUPPORT VECTOR MACHINE; DECISION TREE MODEL; PROTEIN-PROTEIN
   INTERACTION; MIDDLE-DOWN PROTEOMICS; RANDOM FOREST; BOTTOM-UP; TOP-DOWN;
   SEARCH ENGINES; MS/MS SPECTRA; PEPTIDE IDENTIFICATION
AB With the rapid development of high-throughput techniques, mass spectrometry has been widely used for large-scale protein analysis. To search for the existing proteins, discover biomark-ers, and diagnose and prognose diseases, machine learning methods are applied in mass spectrome-try data analysis. This paper reviews the applications of five kinds of machine learning methods to mass spectrometry data analysis from an algorithmic point of view, including support vector ma-chine, decision tree, random forest, naive Bayesian classifier and deep learning.
C1 [Li, Juntao] Henan Normal Univ, Coll Math & Informat Sci, Xinxiang, Henan, Peoples R China.
   [Zhou, Kanglei] Beihang Univ, Sch Comp Sci & Engn, Beijing, Peoples R China.
   [Mu, Bingyu] Zhengzhou Univ Light Ind, Coll Arts & Design, Zhengzhou, Peoples R China.
RP Zhou, KL (corresponding author), Beihang Univ, Sch Comp Sci & Engn, Beijing, Peoples R China.; Mu, BY (corresponding author), Zhengzhou Univ Light Ind, Coll Arts & Design, Zhengzhou, Peoples R China.
EM zhoukanglei@163.com; dianesaidmok@gmail.com
FU Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [61203293, 61702164, 31700858]; Scientific and
   Technological Project of Henan Province [162102310461, 172102310535];
   Foundation of Henan Educational Committee [18A520015]
FX This work was supported by the Natural Science Foundation of China
   (Grant No. 61203293, 61702164, 31700858), Scientific and Technological
   Project of Henan Province (Grant No. 162102310461, 172102310535),
   Foundation of Henan Educational Committee (Grant No. 18A520015), China.
NR 155
TC 0
Z9 0
U1 36
U2 36
PU BENTHAM SCIENCE PUBL LTD
PI SHARJAH
PA EXECUTIVE STE Y-2, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB
   EMIRATES
SN 1570-1646
EI 1875-6247
J9 CURR PROTEOMICS
JI Curr. Proteomics
PY 2021
VL 18
IS 5
BP 620
EP 634
DI 10.2174/1570164617999201023145304
PG 15
WC Biochemical Research Methods; Biochemistry & Molecular Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology
GA WB3VS
UT WOS:000703504200003
DA 2022-04-17
ER

PT J
AU Kaspschak, B
   Meissner, UG
AF Kaspschak, Bastian
   Meissner, Ulf-G
TI How machine learning conquers the unitary limit
SO COMMUNICATIONS IN THEORETICAL PHYSICS
LA English
DT Article
DE unitary limit; machine learning; quantum physics
AB Machine learning has become a premier tool in physics and other fields of science. It has been shown that the quantum mechanical scattering problem cannot only be solved with such techniques, but it was argued that the underlying neural network develops the Born series for shallow potentials. However, classical machine learning algorithms fail in the unitary limit of an infinite scattering length. The unitary limit plays an important role in our understanding of bound strongly interacting fermionic systems and can be realized in cold atom experiments. Here, we develop a formalism that explains the unitary limit in terms of what we define as unitary limit surfaces. This not only allows to investigate the unitary limit geometrically in potential space, but also provides a numerically simple approach towards unnaturally large scattering lengths with standard multilayer perceptrons. Its scope is therefore not limited to applications in nuclear and atomic physics, but includes all systems that exhibit an unnaturally large scale.
C1 [Kaspschak, Bastian; Meissner, Ulf-G] Univ Bonn, Helmholtz Inst Strahlen & Kernphys, D-53115 Bonn, Germany.
   [Kaspschak, Bastian; Meissner, Ulf-G] Univ Bonn, Bethe Ctr Theoret Phys, D-53115 Bonn, Germany.
   [Meissner, Ulf-G] Forschungszentrum Julich, Inst Adv Simulat, Inst Kernphys, D-52425 Julich, Germany.
   [Meissner, Ulf-G] Forschungszentrum Julich, Julich Ctr Hadron Phys, D-52425 Julich, Germany.
   [Meissner, Ulf-G] Tbilisi State Univ, GE-0186 Tbilisi, Georgia.
RP Kaspschak, B (corresponding author), Univ Bonn, Helmholtz Inst Strahlen & Kernphys, D-53115 Bonn, Germany.; Kaspschak, B (corresponding author), Univ Bonn, Bethe Ctr Theoret Phys, D-53115 Bonn, Germany.
EM kaspschak@hiskp.uni-bonn.de
OI Meissner, Ulf-G./0000-0003-1254-442X; Kaspschak,
   Bastian/0000-0003-4224-2932
FU Deutsche ForschungsgemeinschaftGerman Research Foundation (DFG)
   [196253076 - TRR 110]; Chinese Academy of Sciences (CAS) President's
   International Fellowship Initiative (PIFI) [2018DM0034]; EU
   (Strong2020); Volkswagen-StiftungVolkswagen [93562]
FX We thank Hans-Werner Hammer and Bernard Metsch for useful comments. We
   acknowledge partial financial support from the Deutsche
   Forschungsgemeinschaft (Project-ID 196253076 - TRR 110, 'Symmetries and
   the Emergence of Structure in QCD'), Further support was provided by the
   Chinese Academy of Sciences (CAS) President's International Fellowship
   Initiative (PIFI) (Grant No. 2018DM0034), by EU (Strong2020) and by
   Volkswagen-Stiftung (Grant No. 93562).
NR 28
TC 2
Z9 2
U1 1
U2 4
PU IOP PUBLISHING LTD
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 0253-6102
EI 1572-9494
J9 COMMUN THEOR PHYS
JI Commun. Theor. Phys.
PD MAR 1
PY 2021
VL 73
IS 3
AR 035101
DI 10.1088/1572-9494/abd84d
PG 9
WC Physics, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Physics
GA QC3HS
UT WOS:000614725100001
OA Green Submitted
DA 2022-04-17
ER

PT C
AU Yan, JN
   Gu, ZW
   Lin, H
   Rzeszotarski, JM
AF Yan, Jing Nathan
   Gu, Ziwei
   Lin, Hubert
   Rzeszotarski, Jeffrey M.
GP ACM
TI Silva: Interactively Assessing Machine Learning Fairness Using Causality
SO PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING
   SYSTEMS (CHI'20)
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems (CHI)
CY APR 25-30, 2020
CL ELECTR NETWORK
SP Assoc Comp Machinery, ACM SIGCHI
DE Machine learning fairness; bias; interactive systems
ID BIAS
AB Machine learning models risk encoding unfairness on the part of their developers or data sources. However, assessing fairness is challenging as analysts might misidentify sources of bias, fail to notice them, or misapply metrics. In this paper we introduce Silva, a system for exploring potential sources of unfairness in datasets or machine learning models interactively. Silva directs user attention to relationships between attributes through a global causal view, provides interactive recommendations, presents intermediate results, and visualizes metrics. We describe the implementation of Silva, identify salient design and technical challenges, and provide an evaluation of the tool in comparison to an existing fairness optimization tool.
C1 [Yan, Jing Nathan; Gu, Ziwei; Lin, Hubert; Rzeszotarski, Jeffrey M.] Cornell Univ, Ithaca, NY 14850 USA.
RP Yan, JN (corresponding author), Cornell Univ, Ithaca, NY 14850 USA.
EM jy858@cornell.edu; zg48@cornell.edu; hl2247@cornell.edu;
   jmr395@cornell.edu
FU NSFNational Science Foundation (NSF) [IIS-1850195]
FX This work was supported by NSF grant IIS-1850195. We would like to thank
   the associate chairs and anonymous reviewers for their invaluable
   feedback.
NR 68
TC 13
Z9 16
U1 2
U2 59
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-6708-0
PY 2020
DI 10.1145/3313831.3376447
PG 13
WC Computer Science, Cybernetics; Computer Science, Information Systems;
   Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS1SH
UT WOS:000695438100119
DA 2022-04-17
ER

PT J
AU Ren, YL
AF Ren, Yali
TI Optimizing Predictive Maintenance With Machine Learning for Reliability
   Improvement
SO ASCE-ASME JOURNAL OF RISK AND UNCERTAINTY IN ENGINEERING SYSTEMS PART
   B-MECHANICAL ENGINEERING
LA English
DT Review
DE reliability; predictive maintenance; logistic regression; decision tree;
   artificial neural network (ANN); support vector machines (SVMs);
   ensemble learning; instance-based learning; naive bayes; reinforcement
   learning
ID SUPPORT VECTOR MACHINES; NEURAL-NETWORK; FAULT-DIAGNOSIS; DATA FUSION;
   FAILURE; SYSTEM; METHODOLOGY; PROGNOSIS; MODEL
AB Predictive maintenance, as a form of pro-active maintenance, has increasing usage and shows significant superiority over the corrective and preventive maintenance. However, conventional methods of predictive maintenance have noteworthy limitations in maintenance optimization and reliability improvement. In the last two decades, machine learning has flourished and overcome many inherent flaws of conventional maintenance prediction methods. Meanwhile, machine learning displays unprecedented predictive power in maintenance prediction and optimization. This paper compares the features of corrective, preventive, and predictive maintenance, examines the conventional approaches to predictive maintenance, and analyzes their drawbacks. Subsequently, this paper explores the driving forces, and advantages of machine learning over conventional solutions in predictive maintenance. Specifically, this paper reviews popular supervised learning and reinforcement learning algorithms and the associated typical applications in predictive maintenance. Furthermore, this paper summarizes the four critical steps of machine learning applications in maintenance prediction. Finally, the author proposes the future researches concerning how to utilize machine learning to optimize maintenance prediction and planning, improve equipment reliability, and achieve the best possible benefit.
C1 [Ren, Yali] Georgia Inst Technol, Sch Comp Sci, Coll Comp, North Ave, Atlanta, GA 30332 USA.
RP Ren, YL (corresponding author), Georgia Inst Technol, Sch Comp Sci, Coll Comp, North Ave, Atlanta, GA 30332 USA.
EM yren78@gatech.edu
NR 103
TC 2
Z9 2
U1 19
U2 29
PU ASME
PI NEW YORK
PA TWO PARK AVE, NEW YORK, NY 10016-5990 USA
SN 2332-9017
EI 2332-9025
J9 ASCE-ASME J RISK U B
JI ASCE-ASME J. Risk Uncertain. Eng. Syst. Part B-Mech. Eng.
PD SEP 1
PY 2021
VL 7
IS 3
AR 030801
DI 10.1115/1.4049525
PG 13
WC Engineering, Multidisciplinary
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA TQ9OW
UT WOS:000678606100001
DA 2022-04-17
ER

PT J
AU Gangadharan, CK
   Alex, R
   Sabu, MK
AF Gangadharan, Chika K.
   Alex, Roshni
   Sabu, M. K.
TI CHURN PREDICTION - A COMPARATIVE ANALYSIS WITH SUPERVISED MACHINE
   LEARNING ALGORITHMS
SO ADVANCES AND APPLICATIONS IN MATHEMATICAL SCIENCES
LA English
DT Article
DE Machine learning; supervised learning; churn modelling; support vector
   machine; random forest classifier
AB Customer churn predictive model plays an indispensable role in all the industries since "churn is the rate at which the customers stop doing business with an organization". Machine Learning algorithms are used to build faultless models for prediction and classification. In this paper, a comparative analyzation of the performance of five different supervised machine learning algorithms namely Gaussian Naive Bayes, Support Vector Machine, K Nearest Neighbours, Decision Tree and Random Forest Classifiers in predicting churn is studied. Churn_Modelling dataset from Kaggle is used to test these classifiers. Experimental outcomes show that Random Forest Classifier outperforms all other algorithms in predicting the churn of a customer regarding accuracy, precision and recall.
C1 [Gangadharan, Chika K.; Alex, Roshni] MES Coll Marampally, Dept Elect, Kochi, Kerala, India.
   [Sabu, M. K.] Cochin Univ Sci & Technol, Dept Comp Applicat, Cochin, Kerala, India.
RP Gangadharan, CK (corresponding author), MES Coll Marampally, Dept Elect, Kochi, Kerala, India.
EM chika4895@gmail.com; roshnivalex@gmail.com; sabumk@cusat.ac.in
NR 28
TC 0
Z9 0
U1 0
U2 0
PU MILI PUBL
PI ALLAHABAD
PA 422B CHAK RAGHUNATH, NEAR RAILWAY CROSSING, ALLAHABAD, 211 008, INDIA
SN 0974-6803
J9 ADV APPL MATH SCI
JI Adv. Appl. Math. Sci.
PD OCT
PY 2021
VL 20
IS 12
BP 3049
EP 3060
PG 12
WC Mathematics
WE Emerging Sources Citation Index (ESCI)
SC Mathematics
GA YP5AY
UT WOS:000748636200009
DA 2022-04-17
ER

PT J
AU Toplak, M
   Read, ST
   Sandt, C
   Borondics, F
AF Toplak, Marko
   Read, Stuart T.
   Sandt, Christophe
   Borondics, Ferenc
TI Quasar: Easy Machine Learning for Biospectroscopy
SO CELLS
LA English
DT Article
DE open source; machine learning; visual programming; data exploration;
   data analysis
AB Data volumes collected in many scientific fields have long exceeded the capacity of human comprehension. This is especially true in biomedical research where multiple replicates and techniques are required to conduct reliable studies. Ever-increasing data rates from new instruments compound our dependence on statistics to make sense of the numbers. The currently available data analysis tools lack user-friendliness, various capabilities or ease of access. Problem-specific software or scripts freely available in supplementary materials or research lab websites are often highly specialized, no longer functional, or simply too hard to use. Commercial software limits access and reproducibility, and is often unable to follow quickly changing, cutting-edge research demands. Finally, as machine learning techniques penetrate data analysis pipelines of the natural sciences, we see the growing demand for user-friendly and flexible tools to fuse machine learning with spectroscopy datasets. In our opinion, open-source software with strong community engagement is the way forward. To counter these problems, we develop Quasar, an open-source and user-friendly software, as a solution to these challenges. Here, we present case studies to highlight some Quasar features analyzing infrared spectroscopy data using various machine learning techniques.
C1 [Toplak, Marko] Univ Ljubljana, Fac Comp & Informat Sci, Vecna Pot 113, SI-1000 Ljubljana, Slovenia.
   [Read, Stuart T.] Canadian Light Source Inc, 44 Innovat Blvd, Saskatoon, SK S7N 2V3, Canada.
   [Sandt, Christophe; Borondics, Ferenc] SOLEIL Synchrotron, St Aubin BP 48, F-91192 Gif Sur Yvette, France.
RP Toplak, M (corresponding author), Univ Ljubljana, Fac Comp & Informat Sci, Vecna Pot 113, SI-1000 Ljubljana, Slovenia.
EM marko.toplak@fri.uni-lj.si; stuart.read@lightsource.ca;
   christophe.sandt@synchrotron-soleil.fr;
   ferenc.borondics@synchrotron-soleil.fr
RI Soleil, SMIS/I-3166-2014; Sandt, Christophe/M-9806-2014
OI Sandt, Christophe/0000-0002-6432-2004; Read, Stuart/0000-0002-0564-9955
FU ELETTRA Synchrotron (Italy); SOLEIL Synchrotron (France); Campus France
   (France): PHC PROTEUS Project [37490NM]; Slovenian Research
   AgencySlovenian Research Agency - Slovenia [P2-0209]; Canada Foundation
   for Innovation (CFI)Canada Foundation for Innovation; Natural Sciences
   and Engineering Research Council (NSERC)Natural Sciences and Engineering
   Research Council of Canada (NSERC); National Research Council (NRC);
   Canadian Institutes of Health Research (CIHR)Canadian Institutes of
   Health Research (CIHR); Government of Saskatchewan; University of
   Saskatchewan; ARRS (Slovenia)Slovenian Research Agency - Slovenia
FX The Quasar project received funding from in-house grants from the
   ELETTRA Synchrotron (Italy), SOLEIL Synchrotron (France), and a
   bilateral travel grant from ARRS (Slovenia) and Campus France (France):
   PHC PROTEUS Project #37490NM. This work was supported by Slovenian
   Research Agency (P2-0209). The Canadian Light Source (Canada), a
   national research facility of the University of Saskatchewan, is
   supported by the Canada Foundation for Innovation (CFI), the Natural
   Sciences and Engineering Research Council (NSERC), the National Research
   Council (NRC), the Canadian Institutes of Health Research (CIHR), the
   Government of Saskatchewan, and the University of Saskatchewan.
NR 18
TC 1
Z9 1
U1 3
U2 3
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2073-4409
J9 CELLS-BASEL
JI Cells
PD SEP
PY 2021
VL 10
IS 9
AR 2300
DI 10.3390/cells10092300
PG 10
WC Cell Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Cell Biology
GA UU9QL
UT WOS:000699127000001
PM 34571947
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Gemein, LAW
   Schirrmeister, RT
   Chrabaszcz, P
   Wilson, D
   Boedecker, J
   Schulze-Bonhage, A
   Hutter, F
   Ball, T
AF Gemein, Lukas A. W.
   Schirrmeister, Robin T.
   Chrabaszcz, Patryk
   Wilson, Daniel
   Boedecker, Joschka
   Schulze-Bonhage, Andreas
   Hutter, Frank
   Ball, Tonio
TI Machine-learning-based diagnostics of EEG pathology
SO NEUROIMAGE
LA English
DT Article
DE Machine learning; Deep learning; Electroencephalography; EEG;
   Diagnostics; Pathology; Features; Riemannian geometry; Convolutional
   neural networks
ID NEURAL-NETWORKS; BRAIN ACTIVITY; CLASSIFICATION; RECOGNITION;
   QUANTIFICATION; RELIABILITY; COMPLEXITY; EPILEPSY; SEIZURES; KERNEL
AB Machine learning (ML) methods have the potential to automate clinical EEG analysis. They can be categorized into feature-based (with handcrafted features), and end-to-end approaches (with learned features). Previous studies on EEG pathology decoding have typically analyzed a limited number of features, decoders, or both. For a I) more elaborate feature-based EEG analysis, and II) in-depth comparisons of both approaches, here we first develop a comprehensive feature-based framework, and then compare this framework to state-of-the-art end-to-end methods. To this aim, we apply the proposed feature-based framework and deep neural networks including an EEG-optimized temporal convolutional network (TCN) to the task of pathological versus non-pathological EEG classification. For a robust comparison, we chose the Temple University Hospital (TUH) Abnormal EEG Corpus (v2.0.0), which contains approximately 3000 EEG recordings. The results demonstrate that the proposed featurebased decoding framework can achieve accuracies on the same level as state-of-the-art deep neural networks. We find accuracies across both approaches in an astonishingly narrow range from 81 to 86%. Moreover, visualizations and analyses indicated that both approaches used similar aspects of the data, e.g., delta and theta band power at temporal electrode locations. We argue that the accuracies of current binary EEG pathology decoders could saturate near 90% due to the imperfect inter-rater agreement of the clinical labels, and that such decoders are already clinically useful, such as in areas where clinical EEG experts are rare. We make the proposed feature-based framework available open source and thus offer a new tool for EEG machine learning research.
C1 [Gemein, Lukas A. W.; Schirrmeister, Robin T.; Chrabaszcz, Patryk; Wilson, Daniel; Ball, Tonio] Univ Freiburg, Med Ctr, Fac Med, Neuromed AI Lab,Dept Neurosurg, Engelbergerstr 21, D-79106 Freiburg, Germany.
   [Gemein, Lukas A. W.; Schirrmeister, Robin T.; Chrabaszcz, Patryk; Hutter, Frank] Univ Freiburg, Comp Sci Dept, Fac Engn, Machine Learning Lab, Georges Kohler Allee 74, D-79110 Freiburg, Germany.
   [Gemein, Lukas A. W.; Boedecker, Joschka] Univ Freiburg, Comp Sci Dept, Fac Engn, Neurorobot Lab, Georges Kohler Allee 80, D-79110 Freiburg, Germany.
   [Schulze-Bonhage, Andreas; Ball, Tonio] Univ Freiburg, Med Ctr, Fac Med, Dept Neurosurg,Freiburg Epilepsy Ctr, Breisacher Str 64, D-79106 Freiburg, Germany.
RP Gemein, LAW (corresponding author), Univ Freiburg, Med Ctr, Fac Med, Neuromed AI Lab,Dept Neurosurg, Engelbergerstr 21, D-79106 Freiburg, Germany.
EM lukas.gemein@uniklinik-freiburg.de
FU Freiburg Graduate School of Robotics; German Ministry of Education and
   Research (BMBF)Federal Ministry of Education & Research (BMBF)
   [13GW0053D]; DFGGerman Research Foundation (DFG)European Commission [EXC
   1086]
FX This work was supported by the Freiburg Graduate School of Robotics, the
   German Ministry of Education and Research (BMBF) grant 13GW0053D
   (MOTOR-BIC), and the DFG grant EXC 1086 BrainLinks-BrainTools to the
   University of Freiburg, Germany.
NR 95
TC 24
Z9 24
U1 13
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD OCT 15
PY 2020
VL 220
AR 117021
DI 10.1016/j.neuroimage.2020.117021
PG 16
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA OC5GM
UT WOS:000579184700008
PM 32534126
OA Green Submitted, gold
DA 2022-04-17
ER

PT J
AU Singh, N
   Singh, P
   Gupta, M
AF Singh, Narendra
   Singh, Pushpa
   Gupta, Mukul
TI An inclusive survey on machine learning for CRM: a paradigm shift
SO DECISION
LA English
DT Article
DE CRM; Machine learning; Churning; Decision tree; SVM; Deep learning
AB Customer relationship management (CRM) is the tool to enhance customer relationship in any business. Due to the exponential growth of data volume, in any field, it is significant to develop new techniques to discover the customer knowledge, automation of the system and moreover customer satisfaction to win customer lifetime value. CRM with machine learning could bring a catalytic change in business. Several supervised and unsupervised machine learning techniques are utilized to improve the customer experience and profitability of business. This paper reviews the available literature on the CRM with machine learning techniques for customer identification, customer attraction, and customer retention and customer development. This study reveals that supervised learning techniques are 48.48% utilized, unsupervised learning techniques are utilized 15.15%, and 9.09% utilized other techniques in CRM. Paradigm is also shifted toward the deep learning from machine learning as 28.28% text has been reported to deep learning. Decision tree-based algorithm and support vector machine algorithms are most utilized algorithm of supervised learning. E-commerce and telecommunication sectors are the most important areas identified with the exponential growth of the users and hence need a suitable machine learning techniques for customer satisfaction and business profitability.
C1 [Singh, Narendra; Gupta, Mukul] GL Bajaj Inst Management & Res, Dept Management Studies, Greater Noida, India.
   [Singh, Pushpa] Dept Comp Sci & Engn, Delhi Tech Campus, Greater Noida, India.
RP Singh, N (corresponding author), GL Bajaj Inst Management & Res, Dept Management Studies, Greater Noida, India.
EM narendra.naman09@gmail.com; pushpa.gla@gmail.com; mukul.gupta@glbimr.org
OI Singh, Narendra/0000-0002-6760-8550
NR 60
TC 1
Z9 1
U1 7
U2 20
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0304-0941
EI 2197-1722
J9 DECISION-INDIA
JI Decision
PD DEC
PY 2020
VL 47
IS 4
BP 447
EP 457
DI 10.1007/s40622-020-00261-7
EA JAN 2021
PG 11
WC Management
WE Emerging Sources Citation Index (ESCI)
SC Business & Economics
GA QJ6SJ
UT WOS:000609117400001
DA 2022-04-17
ER

PT J
AU Wang, PP
   Zheng, XQ
   Ku, JH
   Wang, CN
AF Wang, Peipei
   Zheng, Xinqi
   Ku, Junhua
   Wang, Chunning
TI Multiple-Instance Learning Approach via Bayesian Extreme Learning
   Machine
SO IEEE ACCESS
LA English
DT Article
DE Multiple-instance learning; Bayesian extreme learning machine; instance
   selection; classification
ID NETWORK; CLASSIFICATION; PREDICTION
AB Multiple-instance learning (MIL) can solve supervised learning tasks, where only a bag of multiple instances is labeled, instead of a single instance. It is considerably important to develop effective and efficient MIL algorithms, because real-world datasets usually contain large instances. Known for its good generalization performance, MIL based on extreme learning machines (ELMx2013;MIL) has proven to be more efficient than several typical MIL classification methods. ELMx2013;MIL selects the most qualified instances from each bag through a single hidden layer feedforward network (SLFN) and trains modified ELM models to update the output weights. This learning approach often performs susceptible to the number of hidden nodes and can easily suffer from over-fitting problem. Using Bayesian inferences, this study introduces a Bayesian ELM (BELM)-based MIL algorithm (BELMx2013;MIL) to address MIL classification problems. First, weight self-learning method based on a Bayesian network is applied to determine the weights of instance features. The most qualified instances are then selected from each bag to represent the bag. Second, BELM can improve the classification model via regularization of automatic estimations to reduce possible over-fitting during the calibration process. Experiments and comparisons are conducted with several competing algorithms on Musk datasets, images datasets, and inductive logic programming datasets. Superior classification accuracy and performance are demonstrated by BELMx2013;MIL.
C1 [Wang, Peipei; Zheng, Xinqi] China Univ Geosci, Sch Informat Engn, Beijing 100083, Peoples R China.
   [Zheng, Xinqi] MNR China, Technol Innovat Ctr Terr Spatial Big Data, Beijing 100036, Peoples R China.
   [Ku, Junhua] Yibin Univ, Sch Math, Yibin 644000, Peoples R China.
   [Wang, Chunning] Natl Geol Lib China, Beijing 100083, Peoples R China.
RP Zheng, XQ (corresponding author), China Univ Geosci, Sch Informat Engn, Beijing 100083, Peoples R China.; Zheng, XQ (corresponding author), MNR China, Technol Innovat Ctr Terr Spatial Big Data, Beijing 100036, Peoples R China.
EM zhengxq@cugb.edu.cn
RI Zheng, Xinqi/E-4894-2013
OI wang, peipei/0000-0003-0154-7457
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [71673256]; Funds for Basic Scientific
   Research of Central Universities [2652020001]; Key Research and
   Development Project of Hainan Province [ZDYF2018234]; China Geological
   SurveyChina Geological Survey [DD20190413]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 71673256, in part by the Funds for Basic
   Scientific Research of Central Universities under Grant 2652020001, in
   part by Key Research and Development Project of Hainan Province under
   Grant ZDYF2018234, and in part by the China Geological Survey under
   Grant DD20190413.
NR 61
TC 1
Z9 1
U1 3
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 62458
EP 62470
DI 10.1109/ACCESS.2020.2984271
PG 13
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA LH3NV
UT WOS:000528695000014
OA gold
DA 2022-04-17
ER

PT J
AU Pfluger, PM
   Glorius, F
AF Pflueger, Philipp M.
   Glorius, Frank
TI Molecular Machine Learning: The Future of Synthetic Chemistry?
SO ANGEWANDTE CHEMIE-INTERNATIONAL EDITION
LA English
DT Editorial Material
DE computer chemistry; machine learning; synthesis design
ID NEURAL-NETWORKS; TRANSFORMER; DESIGN
AB During the last decade, modern machine learning has found its way into synthetic chemistry. Some long-standing challenges, such as computer-aided synthesis planning (CASP), have been successfully addressed, while other issues have barely been touched. This Viewpoint poses the question of whether current trends can persist in the long term and identifies factors that may lead to an (un)productive development. Thereby, specific risks of molecular machine learning (MML) are discussed. Furthermore, possible sustainable developments are suggested, such as explainable artificial intelligence (exAI) for synthetic chemistry. This Viewpoint will illuminate chances for possible newcomers and aims to guide the community into a discussion about current as well as future trends.
C1 [Pflueger, Philipp M.; Glorius, Frank] Univ Munster, Organisch Chem Inst, Corrensstr 40, D-48149 Munster, Germany.
RP Glorius, F (corresponding author), Univ Munster, Organisch Chem Inst, Corrensstr 40, D-48149 Munster, Germany.
EM glorius@uni-muenster.de
RI Glorius, Frank/K-6385-2015
OI Glorius, Frank/0000-0002-0648-956X
NR 45
TC 17
Z9 17
U1 25
U2 75
PU WILEY-V C H VERLAG GMBH
PI WEINHEIM
PA POSTFACH 101161, 69451 WEINHEIM, GERMANY
SN 1433-7851
EI 1521-3773
J9 ANGEW CHEM INT EDIT
JI Angew. Chem.-Int. Edit.
PD OCT 19
PY 2020
VL 59
IS 43
BP 18860
EP 18865
DI 10.1002/anie.202008366
EA SEP 2020
PG 6
WC Chemistry, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry
GA OC4DY
UT WOS:000569154000001
PM 32931084
DA 2022-04-17
ER

PT C
AU Kim, L
   Han, M
   Guo, RK
AF Kim, Lori
   Han, Meng
   Guo, Rongkai
GP ASSOC COMP MACHINERY
TI Machine Learning in the Analysis of Mental Disease
SO ACMSE 2020: PROCEEDINGS OF THE 2020 ACM SOUTHEAST CONFERENCE
LA English
DT Proceedings Paper
CT ACM Southeast Conference (ACMSE)
CY APR 02-04, 2020
CL Tampa, FL
SP Assoc Comp Machinery, Univ S Florida
DE Mental Disease; Machine Learning; Review
AB Mental Health issues affect millions of people every year and deter the ability of an individual to live a fulfilling life. 1 in 5 U.S. adults experience some type of mental illness every year. Even though in the U.S. there are progressive policies and initiatives to help those with mental illnesses, there are still many people suffering and not receiving the help they need. There are different factors and reasons behind why some individuals are hesitant to receive care. Location, stigma, and the fear of treatment are some of the reasons, but with the help of technology like machine learning there can be a access to help everywhere. This work provides general overview on the mental disease particularly to review the machine learning application in the mental disease analysis to provide the best overview of this emerging direction.
C1 [Kim, Lori; Han, Meng; Guo, Rongkai] Kennesaw State Univ, Marietta, GA 30144 USA.
RP Kim, L (corresponding author), Kennesaw State Univ, Marietta, GA 30144 USA.
EM lkim12@students.kennesaw.edu; mhan9@kennesaw.edu; rguo@kennesaw.edu
NR 3
TC 0
Z9 0
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
BN 978-1-4503-7105-6
PY 2020
BP 316
EP 317
DI 10.1145/3374135.3385299
PG 2
WC Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS1PY
UT WOS:000694698300055
DA 2022-04-17
ER

PT C
AU Smith, GE
   Gurburt, SZ
   Bruggenwirth, S
   John-Baptiste, P
AF Smith, Graeme E.
   Gurburt, Sevgi Z.
   Bruggenwirth, Stefan
   John-Baptiste, Peter
GP IEEE
TI Neural Networks & Machine Learning in Cognitive Radar
SO 2020 IEEE RADAR CONFERENCE (RADARCONF20)
SE IEEE Radar Conference
LA English
DT Proceedings Paper
CT IEEE Radar Conference (RadarConf)
CY SEP 21-25, 2020
CL Florence, ITALY
SP IEEE
DE cognitive radar; neural networks; machine learning
AB This paper reports on how neural networks and machine learning can support the development of cognitive radar systems. We discuss the aspects of cognition that can be supported by neural networks, review the recent literature on the use of neural networks for radar and review the significant challenges to implementation. The paper concludes with an example where a neural network, trained using reinforcement learning, generates radar waveforms containing a 26 dB notch in the power spectral density. The notch location is specified using a spectral mask that is the input to the neural network.
C1 [John-Baptiste, Peter] Johns Hopkins Appl Phys Lab, Laurel, MD USA.
   [Smith, Graeme E.] Univ Alabama, Tuscaloosa, AL 35487 USA.
   [Gurburt, Sevgi Z.] Fraunhofer FHR, Wachtberg, Germany.
   [Bruggenwirth, Stefan] Ohio State Univ, Columbus, OH 43210 USA.
RP Smith, GE (corresponding author), Univ Alabama, Tuscaloosa, AL 35487 USA.
EM graeme.e.smith@ieee.org; szgurbuz@ua.edu;
   stefan.brueggenwirth@fhr.fraunhofer.de;
   john-baptiste.2@buckeyemail.osu.edu
NR 22
TC 0
Z9 0
U1 1
U2 2
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1097-5764
BN 978-1-7281-8942-0
J9 IEEE RAD CONF
PY 2020
PG 6
WC Engineering, Electrical & Electronic; Physics, Applied;
   Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering; Physics; Telecommunications
GA BQ6JJ
UT WOS:000612224900344
DA 2022-04-17
ER

PT J
AU Mswahili, ME
   Lee, MJ
   Martin, GL
   Kim, J
   Kim, P
   Choi, GJ
   Jeong, YS
AF Mswahili, Medard Edmund
   Lee, Min-Jeong
   Martin, Gati Lother
   Kim, Junghyun
   Kim, Paul
   Choi, Guang J.
   Jeong, Young-Seob
TI Cocrystal Prediction Using Machine Learning Models and Descriptors
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE descriptor; machine learning; feature selection; cocrystal prediction
AB Cocrystals are of much interest in industrial application as well as academic research, and screening of suitable coformers for active pharmaceutical ingredients is the most crucial and challenging step in cocrystal development. Recently, machine learning techniques are attracting researchers in many fields including pharmaceutical research such as quantitative structure-activity/property relationship. In this paper, we develop machine learning models to predict cocrystal formation. We extract descriptor values from simplified molecular-input line-entry system (SMILES) of compounds and compare the machine learning models by experiments with our collected data of 1476 instances. As a result, we found that artificial neural network shows great potential as it has the best accuracy, sensitivity, and F1 score. We also found that the model achieved comparable performance with about half of the descriptors chosen by feature selection algorithms. We believe that this will contribute to faster and more accurate cocrystal development.
C1 [Mswahili, Medard Edmund; Martin, Gati Lother; Jeong, Young-Seob] Soonchunhyang Univ, Dept ICT Convergence, Asan 31538, South Korea.
   [Lee, Min-Jeong; Choi, Guang J.] Soonchunhyang Univ, Dept Pharmaceut Engn, Asan 31538, South Korea.
   [Kim, Junghyun] Soonchunhyang Univ, Dept Future Convergence Technol, Asan 31538, South Korea.
   [Kim, Paul] Soonchunhyang Univ, Dept Med Sci, Asan 31538, South Korea.
RP Jeong, YS (corresponding author), Soonchunhyang Univ, Dept ICT Convergence, Asan 31538, South Korea.
EM medardedmund25@sch.ac.kr; 20200210@sch.ac.kr; gatimartin@sch.ac.kr;
   kimjh@sch.ac.kr; kp94@sch.ac.kr; guangchoi@sch.ac.kr; bytecell@sch.ac.kr
OI Mswahili, Medard Edmund/0000-0002-6893-6281
FU Institute of Information & Communications Technology Planning &
   Evaluation(IITP) - Korea government(MSIT) [2020-0-01108]; Soonchunhyang
   University Research Fund
FX This work was supported by Institute of Information & Communications
   Technology Planning & Evaluation(IITP) grant funded by the Korea
   government(MSIT) (No. 2020-0-01108, Big data-based development of novel
   solid forms for P-CAB drugs and establishment of dedicated AI platforms)
   This work was supported by the Soonchunhyang University Research Fund.
NR 67
TC 2
Z9 2
U1 18
U2 35
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD FEB
PY 2021
VL 11
IS 3
AR 1323
DI 10.3390/app11031323
PG 12
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Materials Science; Physics
GA QC6NG
UT WOS:000614951800001
OA gold
DA 2022-04-17
ER

PT J
AU Salam, MA
   Ibrahim, L
   Abdelminaam, DS
AF Salam, Mustafa Abdul
   Ibrahim, Lobna
   Abdelminaam, Diaa Salama
TI Earthquake Prediction using Hybrid Machine Learning Techniques
SO INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS
LA English
DT Article
DE Extreme learning machine; least square support vector machine; flower
   pollination algorithm; earthquake prediction
ID MAGNITUDE PREDICTION; NEURAL-NETWORKS; ALGORITHM; MODELS
AB This research proposes two earthquake prediction models using seismic indicators and hybrid machine learning techniques in the region of southern California. Seven seismic indicators were mathematically and statistically calculated depending on pervious recorded seismic events in the earthquake catalogue of that region. These indicators are namely, time taken during the occurrence of n seismic events (T), average magnitude of n events (M_mean), magnitude deficit that is the difference between the observed magnitude and expected one (Delta M), the curve slope for n events using inverse power law of Gutenberg Richter (b), mean square deviation for n events using inverse power law of Gutenberg Richter (eta), the square root of the released energy during T time (DE1/2) and average time between events (mu). Two hybrid machine learning models are proposed to predict the earthquake magnitude during fifteen days. The first model is FPA-ELM, which is a hybrid of the flower pollination algorithm (FPA) and the extreme learning machine (ELM). The second is FPA-LS-SVM, which is a hybrid of FPA and the least square support vector machine (LS-SVM). These two models' performance is compared and assessed using four assessment criteria: Root Mean Square Error (RMSE), Mean Absolute Error (MAE), Symmetric Mean Absolute Percentage Error (SMAPE), and Percent Mean Relative Error (PMRE). The simulation results showed that the FPA-LS-SVM model outperformed the FPA-ELM, LS-SVM, and ELM models in terms of prediction accuracy.
C1 [Salam, Mustafa Abdul] Fac Comp & Artificial Intelligence, Artificial Intelligence Dept, Banha, Egypt.
   [Ibrahim, Lobna] Fac Comp & Artificial Intelligence, Sci Comp Dept, Banha, Egypt.
   [Abdelminaam, Diaa Salama] Fac Comp & Artificial Intelligence, Informat Syst Dept, Banha, Egypt.
   [Abdelminaam, Diaa Salama] Misr Int Univ, Fac Comp Sci, Cairo, Egypt.
RP Salam, MA (corresponding author), Fac Comp & Artificial Intelligence, Artificial Intelligence Dept, Banha, Egypt.
RI Salama, Diaa/AAB-3018-2022
NR 42
TC 0
Z9 0
U1 3
U2 4
PU SCIENCE & INFORMATION SAI ORGANIZATION LTD
PI WEST YORKSHIRE
PA 19 BOLLING RD, BRADFORD, WEST YORKSHIRE, 00000, ENGLAND
SN 2158-107X
EI 2156-5570
J9 INT J ADV COMPUT SC
JI Int. J. Adv. Comput. Sci. Appl.
PD MAY
PY 2021
VL 12
IS 5
BP 654
EP 665
PG 12
WC Computer Science, Theory & Methods
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA TC2GZ
UT WOS:000668461200079
DA 2022-04-17
ER

PT J
AU Park, JS
   Park, JH
AF Park, Ji Su
   Park, Jong Hyuk
TI Advanced Technologies in Blockchain, Machine Learning, and Big Data
SO JOURNAL OF INFORMATION PROCESSING SYSTEMS
LA English
DT Article
DE Big Data; Blockchain; Machine Learning
AB Blockchain, machine learning, and big data are among the key components of the future IT track. These technologies are used in various fields; hence their increasing application. This paper discusses the technologies developed in various research fields, such as data representation, Blockchain application, 3D shape recognition and classification, query method, classification method, and search algorithm, to provide insights into the future paradigm. In this paper, we present a summary of 18 high-quality accepted articles following a rigorous review process in the fields of Blockchain, machine learning, and big data.
C1 [Park, Ji Su] Jeonju Univ, Dept Comp Sci & Engn, Jeonju, South Korea.
   [Park, Jong Hyuk] Seoul Natl Univ Sci & Technol, SeoulTech, Dept Comp Sci & Engn, Seoul, South Korea.
RP Park, JH (corresponding author), Seoul Natl Univ Sci & Technol, SeoulTech, Dept Comp Sci & Engn, Seoul, South Korea.
EM jhpark1@seoultech.ac.kr; jisupark@jj.ac.kr
NR 18
TC 4
Z9 4
U1 7
U2 18
PU KOREA INFORMATION PROCESSING SOC
PI SEOUL
PA 1002HO YONGSUNGBIZTEL 314-1 2GA HANKANGRO YONGSAN-GU, SEOUL, 140-750,
   SOUTH KOREA
SN 1976-913X
EI 2092-805X
J9 J INF PROCESS SYST
JI J. Inf. Process. Syst.
PD APR
PY 2020
VL 16
IS 2
BP 239
EP 245
DI 10.3745/JIPS.01.0052
PG 7
WC Computer Science, Information Systems
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA MA1CN
UT WOS:000541652700001
DA 2022-04-17
ER

PT J
AU Wang, Y
   Ji, CP
   Wang, Y
   Ji, MH
   Yang, JJ
   Zhou, CM
AF Wang, Yong
   Ji, Chaopeng
   Wang, Ying
   Ji, Muhuo
   Yang, Jian-Jun
   Zhou, Cheng-Mao
TI Predicting postoperative liver cancer death outcomes with machine
   learning
SO CURRENT MEDICAL RESEARCH AND OPINION
LA English
DT Article
DE Machine learning; hepatocellular carcinoma; mortality; postoperative;
   AUC
AB Objective
   To investigate the effect of 5 machine learning algorithms in predicting total hepatocellular carcinoma (HCC) postoperative death outcomes.
   Methods
   This study was a secondary analysis. A prognosis model was established using machine learning with python.
   Results
   The results from the machine learning gbm algorithm showed that the most important factors, ranked from first to fifth, were: preoperative aspartate aminotransferase (GOT), preoperative AFP, preoperative cereal third transaminase (GPT), preoperative total bilirubin, and LC3. Postoperative death model results for liver cancer patients in the test group: of the 5 algorithm models, the highest accuracy rate was that of forest (0.739), followed by the gbm algorithm (0.714); of the 5 algorithms, the AUC values, from high to low, were forest (0.803), GradientBoosting (0.746), gbm (0.724), Logistic (0.660) and DecisionTree (0.578).
   Conclusion
   Machine learning can predict total hepatocellular carcinoma postoperative death outcomes.
C1 [Wang, Yong; Wang, Ying; Ji, Muhuo; Yang, Jian-Jun; Zhou, Cheng-Mao] Zhengzhou Univ, Affiliated Hosp 1, Dept Anesthesiol Pain & Perioperat Med, Zhengzhou, Peoples R China.
   [Ji, Chaopeng] Zhengzhou Univ, Affiliated Hosp 1, Dept Rehabil Med, Zhengzhou, Peoples R China.
   [Ji, Chaopeng] Zhengzhou Univ, Med Coll, Zhengzhou, Peoples R China.
RP Yang, JJ; Zhou, CM (corresponding author), Zhengzhou Univ, Affiliated Hosp 1, Dept Anesthesiol Pain & Perioperat Med, Zhengzhou, Peoples R China.
EM yjyangjj@126.com; zhouchengmao187@foxmail.com
RI Zhou, Cheng-Mao/ABF-4435-2020; Yang, Jianjun/AAN-4960-2021
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [81600950, 81771156, 81772126]
FX This study was supported by grants from the National Natural Science
   Foundation of China [Nos., 81600950, 81771156, 81772126].
NR 26
TC 4
Z9 4
U1 6
U2 11
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0300-7995
EI 1473-4877
J9 CURR MED RES OPIN
JI Curr. Med. Res. Opin.
PD APR 3
PY 2021
VL 37
IS 4
BP 629
EP 634
DI 10.1080/03007995.2021.1885361
EA FEB 2021
PG 6
WC Medicine, General & Internal; Medicine, Research & Experimental
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine; Research & Experimental Medicine
GA RA8OI
UT WOS:000619334000001
PM 33539249
DA 2022-04-17
ER

PT J
AU Dastile, X
   Celik, T
   Potsane, M
AF Dastile, Xolani
   Celik, Turgay
   Potsane, Moshe
TI Statistical and machine learning models in credit scoring: A systematic
   literature survey
SO APPLIED SOFT COMPUTING
LA English
DT Article
DE Credit scoring; Statistical learning; Machine learning; Deep learning;
   Systematic literature survey
ID CONVOLUTIONAL NEURAL-NETWORKS; RESTRICTED BOLTZMANN MACHINE;
   FEATURE-SELECTION; BANKRUPTCY PREDICTION; GENETIC ALGORITHM; ROUGH SET;
   CLASSIFIER ENSEMBLES; MAXIMUM-LIKELIHOOD; TIME-SERIES; RISK
AB In practice, as a well-known statistical method, the logistic regression model is used to evaluate the credit-worthiness of borrowers due to its simplicity and transparency in predictions. However, in literature, sophisticated machine learning models can be found that can replace the logistic regression model. Despite the advances and applications of machine learning models in credit scoring, there are still two major issues: the incapability of some of the machine learning models to explain predictions; and the issue of imbalanced datasets. As such, there is a need for a thorough survey of recent literature in credit scoring. This article employs a systematic literature survey approach to systematically review statistical and machine learning models in credit scoring, to identify limitations in literature, to propose a guiding machine learning framework, and to point to emerging directions. This literature survey is based on 74 primary studies, such as journal and conference articles, that were published between 2010 and 2018. According to the meta-analysis of this literature survey, we found that in general, an ensemble of classifiers performs better than single classifiers. Although deep learning models have not been applied extensively in credit scoring literature, they show promising results. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Dastile, Xolani; Celik, Turgay; Potsane, Moshe] Univ Witwatersrand, Sch Comp Sci & Appl Math, Johannesburg, South Africa.
   [Celik, Turgay] Univ Witwatersrand, Wits Inst Data Sci, Johannesburg, South Africa.
RP Dastile, X (corresponding author), Univ Witwatersrand, Sch Comp Sci & Appl Math, Johannesburg, South Africa.
EM xdastile12@gmail.com; celikturgay@gmail.com; Moshe.Potsane@wesbank.co.za
RI Celik, Turgay/Q-9713-2018
OI Celik, Turgay/0000-0001-6925-6010
NR 146
TC 39
Z9 40
U1 19
U2 67
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1568-4946
EI 1872-9681
J9 APPL SOFT COMPUT
JI Appl. Soft. Comput.
PD JUN
PY 2020
VL 91
AR 106263
DI 10.1016/j.asoc.2020.106263
PG 21
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA MH2GL
UT WOS:000546550100020
DA 2022-04-17
ER

PT J
AU Zhu, S
   Wang, H
   Lv, H
   Zhang, HS
AF Zhu, Shuai
   Wang, Hui
   Lv, Hui
   Zhang, Huisheng
TI Augmented Online Sequential Quaternion Extreme Learning Machine
SO NEURAL PROCESSING LETTERS
LA English
DT Article
DE Extreme learning machine; Online sequential learning; Quaternion signal
   processing; Augmented quaternion statistics
AB Online sequential extreme learning machine (OS-ELM) is one of the most popular real-time learning strategy for feedforward neural networks with single hidden layer due to its fast learning speed and excellent generalization ability. When dealing with quaternion signals, traditional real-valued learning models usually provide only suboptimal solutions compared with their quaternion-valued counterparts. However, online sequential quaternion extreme learning machine (OS-QELM) model is still lacking in literature. To fill this gap, this paper aims to establish a framework for the derivation and the design of OS-QELM. Specifically, we first derive a standard OS-QELM, and then propose two augmented OS-QELM models which can capture the complete second-order statistics of noncircular quaternion signals. The corresponding regularized models and two approaches to reducing the computational complexity are also derived and discussed respectively. Benefiting from the quaternion algebra and the augmented structure, the proposed models exhibit superiority over OS-ELM in simulation results on several benchmark quaternion regression problems and colour face recognition problems.
C1 [Zhu, Shuai; Wang, Hui; Zhang, Huisheng] Dalian Maritime Univ, Sch Sci, Dalian 116026, Peoples R China.
   [Lv, Hui] Shandong Intelligent Equipment Inst, Ctr HRG, Jinan 250200, Peoples R China.
RP Zhang, HS (corresponding author), Dalian Maritime Univ, Sch Sci, Dalian 116026, Peoples R China.
EM hszhang@dlmu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61671099, 61301202]; Fundamental Research
   Funds for the Central Universities of ChinaFundamental Research Funds
   for the Central Universities
FX This work is supported by the National Natural Science Foundation of
   China (Nos. 61671099, 61301202) and the Fundamental Research Funds for
   the Central Universities of China.
NR 60
TC 1
Z9 1
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1370-4621
EI 1573-773X
J9 NEURAL PROCESS LETT
JI Neural Process. Lett.
PD APR
PY 2021
VL 53
IS 2
BP 1161
EP 1186
DI 10.1007/s11063-021-10435-8
EA FEB 2021
PG 26
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RM9CQ
UT WOS:000615208200001
DA 2022-04-17
ER

PT J
AU Li, C
   Yang, YY
   Liang, H
   Wu, BY
AF Li, Chun
   Yang, Yunyun
   Liang, Hui
   Wu, Boying
TI Learning Quantum Drift-Diffusion Phenomenon by Physics-Constraint
   Machine Learning
SO IEEE-ACM TRANSACTIONS ON NETWORKING
LA English
DT Article; Early Access
DE Mathematical models; Quantum computing; Machine learning; Quantum
   mechanics; Machine learning algorithms; Numerical models; Semiconductor
   device modeling; Quantum machine learning; quantum drift-diffusion;
   physical-information learning; quantum transport; quantum fluid model
ID NEURAL-NETWORKS; INVERSE PROBLEMS; APPROXIMATION; TRANSPORT; MODEL
AB Recently, deep learning (DL) is widely used to detect physical phenomena and has obtained encouraging results. Several works have shown that it can learn quantum phenomenon. Subsequently, quantum machine learning (QML) has been paid more attention by academia and industry. Quantum drift-diffusion (QDD) is a commonplace physical phenomenon, which is a macroscopic description of electrons and holes in a semiconductor. They are commonly used to attain an understanding of the property of semiconductor devices in physics and engineering. We are motivated by the relaxation-time limit from the quantum-Navier-Stokes-Poisson system (QNSP) to the QDD equation and the existence of finite energy weak solutions to the QDD equation has been proved. Therefore, in this work, the quantum drift-diffusion learning neural network (QDDLNN) is proposed to investigate the quantum drift phenomena from limited observations. Furthermore, a piece of numerical evidence is found that the NNs can describe quantum transport phenomena by simulating the quantum confinement transport equation-quantum Navier-Stokes equation.
C1 [Li, Chun; Yang, Yunyun; Liang, Hui] Harbin Inst Technol, Sch Sci, Shenzhen 518055, Peoples R China.
   [Wu, Boying] Harbin Inst Technol, Sch Math, Harbin 150001, Peoples R China.
RP Yang, YY (corresponding author), Harbin Inst Technol, Sch Sci, Shenzhen 518055, Peoples R China.
EM lichun2020@hit.edu.cn; yangyunyun@hit.edu.cn; lianghtti@hit.edu.cn;
   mathwby@hit.edu.cn
FU Shenzhen Higher Education Institutions Stable Support Plan
   [GXWD20201230155427003-20200729105427008]; China Postdoctoral Science
   FoundationChina Postdoctoral Science Foundation [2021M690837]; Guangdong
   Basic and Applied Basic Research Foundation [2021A1515220073]
FX This work was supported in part by the Shenzhen Higher Education
   Institutions Stable Support Plan under Grant
   GXWD20201230155427003-20200729105427008, in part by the China
   Postdoctoral Science Foundation under Grant 2021M690837, and in part by
   the Guangdong Basic and Applied Basic Research Foundation under Grant
   2021A1515220073.
NR 74
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1063-6692
EI 1558-2566
J9 IEEE ACM T NETWORK
JI IEEE-ACM Trans. Netw.
DI 10.1109/TNET.2022.3158987
EA APR 2022
PG 12
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA 0J4LZ
UT WOS:000780077400001
DA 2022-04-17
ER

PT J
AU Sun, ML
   Liu, Y
   Liu, GM
   Cui, D
   Heidari, AA
   Jia, WY
   Ji, X
   Chen, HL
   Luo, YG
AF Sun, Mao-Lei
   Liu, Yun
   Liu, Guomin
   Cui, Dan
   Heidari, Ali Asghar
   Jia, Wen-Yuan
   Ji, Xuan
   Chen, Huiling
   Luo, Yungang
TI Application of Machine Learning to Stomatology: A Comprehensive Review
SO IEEE ACCESS
LA English
DT Review
DE Cancer; Support vector machines; Machine learning; Prognostics and
   health management; Predictive models; Dentistry; Machine learning;
   artificial intelligence; stomatology; prediction; medical diagnosis
ID POTENTIALLY MALIGNANT DISORDERS; ARTIFICIAL NEURAL-NETWORK; CARIES
   DETECTION; DENTAL IMPLANTS; SOLAR-RADIATION; RISK-ASSESSMENT; AURORA-A;
   PREDICTION; DIAGNOSIS; CLASSIFICATION
AB In recent years, machine learning methods has been widely used in various fields, such as finance, spatial sciences, smart grid, intelligent transportation, renewable energy, agriculture, especially medicine. In the era of big medical data, the advantage of machine learning is that it can predict and diagnose through the analysis of a large number of clinical data, and its performance is very close and competitive to or even better than the performance of clinicians. This article focuses on the application of machine learning techniques in the field of stomatology and detailedly describes application cases involving oral cancer, dental caries, periodontitis, dental pulp diseases, periapical lesions, oral implants, and orthodontics. Finally, the research obstacles and future work are discussed.
C1 [Sun, Mao-Lei; Liu, Yun; Ji, Xuan; Luo, Yungang] Second Hosp Jilin Univ, Dept Stomatol, Changchun 130041, Peoples R China.
   [Sun, Mao-Lei; Liu, Yun; Liu, Guomin; Jia, Wen-Yuan; Ji, Xuan; Luo, Yungang] Jilin Prov Changbai Mt Antitumor Med Engn Ctr, Changchun 130041, Peoples R China.
   [Liu, Guomin; Jia, Wen-Yuan] Second Hosp Jilin Univ, Dept Orthoped, Changchun 130041, Peoples R China.
   [Cui, Dan] Second Hosp Jilin Univ, Dept Cardiovasc Surg, Changchun 130041, Peoples R China.
   [Heidari, Ali Asghar] Univ Tehran, Coll Engn, Sch Surveying & Geospatial Engn, Tehran 1417466191, Iran.
   [Heidari, Ali Asghar] Natl Univ Singapore, Sch Comp, Dept Comp Sci, Singapore 119077, Singapore.
   [Chen, Huiling] Wenzhou Univ, Coll Comp Sci & Artificial Intelligence, Wenzhou 325035, Peoples R China.
RP Luo, YG (corresponding author), Second Hosp Jilin Univ, Dept Stomatol, Changchun 130041, Peoples R China.; Luo, YG (corresponding author), Jilin Prov Changbai Mt Antitumor Med Engn Ctr, Changchun 130041, Peoples R China.; Chen, HL (corresponding author), Wenzhou Univ, Coll Comp Sci & Artificial Intelligence, Wenzhou 325035, Peoples R China.
EM chenhuiling.jlu@gmail.com; luoygjlu@sina.com
RI Heidari, Ali Asghar/M-6255-2018; Chen, Huiling/N-8510-2019
OI Heidari, Ali Asghar/0000-0001-6938-9948; Chen,
   Huiling/0000-0002-7714-9693
NR 183
TC 2
Z9 2
U1 19
U2 34
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 184360
EP 184374
DI 10.1109/ACCESS.2020.3028600
PG 15
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA OF3AS
UT WOS:000581085700001
OA gold
DA 2022-04-17
ER

PT C
AU Oliinyk, VA
   Vysotska, V
   Burov, Y
   Mykich, K
   Basto-Fernandes, V
AF Oliinyk, Vitaliia-Anna
   Vysotska, Victoria
   Burov, Yevhen
   Mykich, Khrystyna
   Basto-Fernandes, Vitor
BE Emmerich, M
   Lytvyn, V
   Vysotska, V
   BastoFernandes, V
   Lytvynenko, V
TI Propaganda Detection in Text Data Based on NLP and Machine Learning
SO MOMLET+DS 2020: MODERN MACHINE LEARNING TECHNOLOGIES AND DATA SCIENCE
   WORKSHOP
SE CEUR Workshop Proceedings-Series
LA English
DT Proceedings Paper
CT 2nd International Workshop on Modern Machine Learning Technologies and
   Data Science (MoMLeT+DS)
CY JUN 02-03, 2020
CL ELECTR NETWORK
SP Leiden Univ, Leiden Inst Adv Comp Sci, Lviv Polytechn Natl Univ, Montfort Univ, Comp Sci, Univ Inst Lisbon, Kherson Natl Tech Univ, Lesya Ukrainka Eastern European Natl Univ, SoftServe, Lviv IT Cluster, Perfectial, Skelia, Fortifier, Envion Software, PI MINDS, SSA Group, SYTOSS
DE Content; Text Data; Propaganda Detection; Data Classification; Machine
   Learning
AB The goal of this research is to build a machine-learning model, as well as preliminary data process and feature extraction algorithms that would allow to successfully identify signs of propaganda in text data and to solve a binary classification task. The task is presented in two forms: article level propaganda detection and sentence level propaganda detection. The propaganda detection dataset for this level of task consists of 35 993 articles (including headlines) written in English. Each article is marked as either "propaganda" or "non-propaganda". The dataset also contains unique identifier for each article.
C1 [Oliinyk, Vitaliia-Anna; Vysotska, Victoria; Burov, Yevhen; Mykich, Khrystyna] Lviv Polytech Natl Univ, Lvov, Ukraine.
   [Basto-Fernandes, Vitor] Univ Inst Lisbon, Lisbon, Portugal.
RP Oliinyk, VA (corresponding author), Lviv Polytech Natl Univ, Lvov, Ukraine.
EM vitaliia-anna.oliinyk.sa.2017@lpnu.ua; Victoria.A.Vysotska@lpnu.ua
RI Vysotska, Victoria/P-7714-2016; Basto-Fernandes, Vitor/N-1891-2016
OI Vysotska, Victoria/0000-0001-6417-3689; Basto-Fernandes,
   Vitor/0000-0003-4269-5114
NR 39
TC 1
Z9 1
U1 0
U2 0
PU RWTH AACHEN
PI Aachen
PA Ahornstr. 55, Aachen, *, GERMANY
SN 1613-0073
J9 CEUR WORKSHOP PROCEE
PY 2020
VL 2631
PG 13
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Operations Research & Management Science
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Operations Research & Management Science
GA BR6TX
UT WOS:000664104800010
DA 2022-04-17
ER

PT C
AU Dasari, V
   Im, MS
   Beshaj, L
AF Dasari, Venkat
   Im, Mee Seong
   Beshaj, Lubjana
BE Blowers, M
   Hall, RD
   Dasari, VR
TI Solving machine learning optimization problems using quantum computers
SO DISRUPTIVE TECHNOLOGIES IN INFORMATION SCIENCES IV
SE Proceedings of SPIE
LA English
DT Proceedings Paper
CT Conference on Disruptive Technologies in Information Sciences IV
CY APR 27-MAY 01, 2020
CL ELECTR NETWORK
SP SPIE
DE quantum machine learning; higher-dimensional data sets; quantum
   computation; quantum parallelism
ID TARGET TRACKING; RETRIEVAL; COLOR
AB Classical optimization algorithms in machine learning often take a long time to compute when applied to a multi-dimensional problem and require a huge amount of CPU and GPU resource. Quantum parallelism has a potential to speed up machine learning algorithms. We describe a generic mathematical model to leverage quantum parallelism to speed-up machine learning algorithms. We also apply quantum machine learning and quantum parallelism to a 3-dimensional image that vary with time as well as tracking speed in object identification.
C1 [Dasari, Venkat] US Army Res Lab, Aberdeen Proving Ground, MD 21005 USA.
   [Im, Mee Seong] US Mil Acad, West Point, NY 10996 USA.
   [Beshaj, Lubjana] Army Cyber Inst, West Point, NY 10996 USA.
RP Dasari, V (corresponding author), US Army Res Lab, Aberdeen Proving Ground, MD 21005 USA.
EM venkateswara.r.dasari.civ@mail.mil; meeseong.im@westpoint.edu;
   lubjana.beshaj@westpoint.edu
OI Im, Mee Seong/0000-0003-1587-9145
NR 31
TC 0
Z9 0
U1 6
U2 10
PU SPIE-INT SOC OPTICAL ENGINEERING
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA
SN 0277-786X
EI 1996-756X
BN 978-1-5106-3616-3
J9 PROC SPIE
PY 2020
VL 11419
AR 114190F
DI 10.1117/12.2565038
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ4IY
UT WOS:000589922100008
OA Green Submitted
DA 2022-04-17
ER

PT C
AU Pouchard, L
   Lin, YW
   Van Dam, H
AF Pouchard, Line
   Lin, Yuewei
   Van Dam, Hubertus
BE Foster, I
   Joubert, GR
   Kucera, L
   Nagel, WE
   Peters, F
TI Replicating Machine Learning Experiments in Materials Science
SO PARALLEL COMPUTING: TECHNOLOGY TRENDS
SE Advances in Parallel Computing
LA English
DT Proceedings Paper
CT Conference on Parallel Computing - Technology Trends (ParCo)
CY SEP 10-13, 2019
CL Charles Univ, Prague, CZECH REPUBLIC
SP European Processor Initiat, hoComputer & Intel, Julich Supercomputing Ctr, Julich Forschungszentrum, Univ Chicago, Tech Univ Clausthal
HO Charles Univ
DE reproducibility; machine learning; materials science; materials
   informatics
ID DATABASE
AB Transparency and reproducibility are important aspects of validation for Machine Learning (ML) models that are not fully understood and applies independently of the application domain. We offer a case study of reproducibility that highlights the challenges encountered when attempting to reproduce analyzes obtained with Machine Learning methods in materials informatics. Our study explores prediction results obtained with ML models and issues in training data serving as input. We discuss challenges related to theory-driven and numerical errors in training data, lack of reproducibility across platforms and versions, and effects of randomness when varying hyperparameters. In addition to model accuracy, a main metric of interest in the ML community, our results show that model sensitivity may be equally important for applying ML in domain applications such a materials science.
C1 [Pouchard, Line; Lin, Yuewei; Van Dam, Hubertus] Brookhaven Natl Lab, Upton, NY 11973 USA.
RP Pouchard, L (corresponding author), Brookhaven Natl Lab, Upton, NY 11973 USA.
EM pouchard@bnl.gov
RI van Dam, Hubertus Johannes Jacobus/J-4996-2017
OI van Dam, Hubertus Johannes Jacobus/0000-0002-0876-3294
FU U.S. Department of EnergyUnited States Department of Energy (DOE)
   [DE-SC0012704]; Brookhaven National Laboratory under the Laboratory
   Directed Research and Development [18-05 FY 18-20]
FX This work was performed using resources of Brookhaven National
   Laboratory operated for the U.S. Department of Energy by Brookhaven
   Science Associates under contract number DE-SC0012704. The authors
   gratefully acknowledge some funding support from the Brookhaven National
   Laboratory under the Laboratory Directed Research and Development 18-05
   FY 18-20.
NR 29
TC 0
Z9 0
U1 2
U2 3
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 0927-5452
BN 978-1-64368-071-2; 978-1-64368-070-5
J9 ADV PARALLEL COMPUT
PY 2020
VL 36
BP 743
EP 755
DI 10.3233/APC200105
PG 13
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ9FE
UT WOS:000624288400068
OA gold, Green Submitted
DA 2022-04-17
ER

PT J
AU Xie, JX
   Su, YJ
   Xue, DZ
   Jiang, X
   Fu, HD
   Huang, HY
AF Xie Jianxin
   Su Yanjing
   Xue Dezhen
   Jiang Xue
   Fu Huadong
   Huang Haiyou
TI Machine Learning for Materials Research and Development
SO ACTA METALLURGICA SINICA
LA Chinese
DT Article
DE materials data; data mining; machine learning; material design; material
   genome engineering
ID HIGH ENTROPY ALLOYS; ARTIFICIAL NEURAL-NETWORK; MULTIOBJECTIVE
   OPTIMIZATION; PROCESSING PARAMETERS; MATERIALS INFORMATICS; PHASE
   PREDICTION; CORROSION RATE; FATIGUE LIFE; DESIGN; DISCOVERY
AB The rapid advancement of big data and artificial intelligence has resulted in new data-driven materials research and development (R&D), which has achieved substantial progress. This fourth paradigm is believed to improve materials design efficiency and industrialized application and stimulate the discovery of new materials. The focus of this work is on the emerging field of machine learning-assisted material R&D, with an emphasis on machine learning predictions and optimization design. Following a brief description of feature construction and selection, recent developments in material predictions on phases/structures, processing-structure-property relationships, microstructure, and material performance are reviewed. This paper also summarizes the research progress on optimization algorithms with machine learning models, which is expected to overcome the bottlenecks such as the small size and high noise level of material data samples and huge space for exploration. The challenges and future opportunities for machine learning applications in materials R&D are discussed and prospected.
C1 [Xie Jianxin; Su Yanjing; Jiang Xue; Fu Huadong; Huang Haiyou] Univ Sci & Technol Beijing, Inst Adv Mat & Technol, Beijing Adv Innovat Ctr Mat Genome Engn, Beijing 100083, Peoples R China.
   [Xue Dezhen] Xi An Jiao Tong Univ, State Key Lab Mech Behav Mat, Xian 710049, Peoples R China.
RP Xie, JX; Su, YJ (corresponding author), Univ Sci & Technol Beijing, Inst Adv Mat & Technol, Beijing Adv Innovat Ctr Mat Genome Engn, Beijing 100083, Peoples R China.
EM jxxie@mater.ustb.cdu.cn; yjsu@ustb.edu.cn
NR 148
TC 1
Z9 1
U1 110
U2 110
PU SCIENCE PRESS
PI BEIJING
PA 16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100717, PEOPLES R CHINA
SN 0412-1961
J9 ACTA METALL SIN
JI Acta Metall. Sin.
PD NOV
PY 2021
VL 57
IS 11
BP 1343
EP 1361
DI 10.11900/0412.1961.2021.00357
PG 19
WC Metallurgy & Metallurgical Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Metallurgy & Metallurgical Engineering
GA WQ8IL
UT WOS:000714054200001
DA 2022-04-17
ER

PT J
AU Selvaratnam, B
   Koodali, RT
AF Selvaratnam, Balaranjan
   Koodali, Ranjit T.
TI Machine learning in experimental materials chemistry
SO CATALYSIS TODAY
LA English
DT Article
DE Machine learning; Catalysis; Materials Chemsitry
ID NEURAL-NETWORK; MATERIALS DISCOVERY; CATALYSIS; DESIGN; IDENTIFICATION;
   OPTIMIZATION; INFORMATICS; KNOWLEDGE
AB The development of advanced materials is an important aspect of modern life. However, the discovery of novel materials involves searching the vast chemical space to find materials with desired properties. Recent developments in the applications of Machine Learning (ML) in materials chemistry show promise to accelerate the material discovery process. In this perspective article, we highlight the importance of ML in materials chemistry. We discuss few examples of ML applications in synthesis, characterization, and predicting activities of materials. Finally, we discuss the challenges in this field and how the progress in ML in chemistry is leveraged together with advanced robotics to perform automated optimization of material discovery.
C1 [Selvaratnam, Balaranjan; Koodali, Ranjit T.] Univ South Dakota, Dept Chem, Vermillion, SD 57069 USA.
RP Koodali, RT (corresponding author), Univ South Dakota, Dept Chem, Vermillion, SD 57069 USA.
EM Ktranjit@gmail.com
FU National Science FoundationNational Science Foundation (NSF)
   [DGE-1633213]
FX We are thankful to the University of South Dakota-Neuroscience,
   Nanotechnology, and Networks (USD-N3) program, funded by the National
   Science Foundation, DGE-1633213 grant.
NR 60
TC 6
Z9 6
U1 22
U2 59
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0920-5861
EI 1873-4308
J9 CATAL TODAY
JI Catal. Today
PD JUL 1
PY 2021
VL 371
SI SI
BP 77
EP 84
DI 10.1016/j.cattod.2020.07.074
EA MAY 2021
PG 8
WC Chemistry, Applied; Chemistry, Physical; Engineering, Chemical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering
GA SD1IW
UT WOS:000651121900010
DA 2022-04-17
ER

PT J
AU Tian, Y
   Snoek, C
   Wang, J
   Liu, Z
   Lienhart, R
   Boll, S
AF Tian, Y.
   Snoek, C.
   Wang, J.
   Liu, Z.
   Lienhart, R.
   Boll, S.
TI Guest Editorial Multimedia Computing With Interpretable Machine Learning
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Editorial Material
DE Special issues and sections; Machine learning; Feature extraction;
   Visualization; Multimedia communication; Deep learning; Big Data
AB The papers in this special section is to broadly engage the machine learning and multimedia communities on the emerging yet challenging interpretable machine learning. Multimedia is increasingly becoming the "biggest big data," among the most important and valuable source for insight and information. Many powerful machine learning algorithms, especially deep learning models such as convolutional neural networks (CNNs), have recently achieved outstanding predictive performance in a wide range of multimedia applications, including visual object classification, scene understanding, speech recognition, and activity prediction. Nevertheless, most deep learning algorithms are generally conceived as blackbox methods, and it is difficult to intuitively and quantitatively understand the results of their prediction and inference. Since this lack of interpretability is a major bottleneck in designing more successful predictive models and exploring wider-range useful applications, there has been an explosion of interest in interpreting the representations learned by these models, with profound implications for research into interpretable machine learning in the multimedia community.
C1 [Tian, Y.] Peking Univ, Sch EE&CS, Dept Comp Sci & Technol, Beijing 100871, Peoples R China.
   [Tian, Y.] PengCheng Lab, Artificial Intelligence Res Ctr, Shenzhen 518066, Peoples R China.
   [Snoek, C.] Univ Amsterdam, Informat Inst, NL-94323 Amsterdam, Netherlands.
   [Wang, J.] Microsoft Res Asia, Beijing 100080, Peoples R China.
   [Liu, Z.] AT&T Labs Res, Middletown, NJ 07748 USA.
   [Lienhart, R.] Univ Augsburg, Comp Sci Dept, D-86159 Augsburg, Germany.
   [Boll, S.] Carl von Ossietzky Univ Oldenburg, Dept Comp Sci, D-26121 Oldenburg, Germany.
RP Tian, Y (corresponding author), Peking Univ, Sch EE&CS, Dept Comp Sci & Technol, Beijing 100871, Peoples R China.; Tian, Y (corresponding author), PengCheng Lab, Artificial Intelligence Res Ctr, Shenzhen 518066, Peoples R China.
NR 0
TC 0
Z9 0
U1 2
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD JUL
PY 2020
VL 22
IS 7
BP 1661
EP 1666
DI 10.1109/TMM.2020.2991292
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA MG4GJ
UT WOS:000545990500001
OA Bronze, Green Submitted
DA 2022-04-17
ER

PT J
AU Sirsat, MS
   Ferme, E
   Camara, J
AF Sirsat, Manisha Sanjay
   Ferme, Eduardo
   Camara, Joana
TI Machine Learning for Brain Stroke: A Review
SO JOURNAL OF STROKE & CEREBROVASCULAR DISEASES
LA English
DT Review
DE support vector machine; Machine learning; Deep learning; Stroke
   diagnosis; Stroke prevention; Stroke prognostication
ID CLASSIFICATION; PREDICTION; ULTRASOUND; IMAGES; SENSOR; MRI
AB Machine Learning (ML) delivers an accurate and quick prediction outcome and it has become a powerful tool in health settings, offering personalized clinical care for stroke patients. An application of ML and Deep Learning in health care is growing however, some research areas do not catch enough attention for scientific investigation though there is real need of research. Therefore, the aim of this work is to classify state-of-arts on ML techniques for brain stroke into 4 categories based on their functionalities or similarity, and then review studies of each category systematically. A total of 39 studies were identified from the results of ScienceDirect web scientific database on ML for brain stroke from the year 2007 to 2019. Support Vector Machine (SVM) is obtained as optimal models in 10 studies for stroke problems. Besides, maximum studies are found in stroke diagnosis although number for stroke treatment is least thus, it identifies a research gap for further investigation. Similarly, CT images are a frequently used dataset in stroke. Finally SVM and Random Forests are efficient techniques used under each category. The present study showcases the contribution of various ML approaches applied to brain stroke. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Sirsat, Manisha Sanjay; Ferme, Eduardo; Camara, Joana] NOVA LINCS, Campus Univ, P-2829516 Quinta Da Torre, Caparica, Portugal.
   [Ferme, Eduardo; Camara, Joana] Univ Madeira, Rua Dos Ferreiros 105, P-9000082 Funchal, Portugal.
   [Camara, Joana] Univ Coimbra, Rua Colegio Novo, P-3000115 Coimbra, Portugal.
RP Sirsat, MS (corresponding author), NOVA LINCS, Campus Univ, P-2829516 Quinta Da Torre, Caparica, Portugal.
EM manisha.sirsat2015@gmail.com
RI Fermé, Eduardo/J-3015-2012; SIRSAT, MANISHA/W-6992-2018
OI Fermé, Eduardo/0000-0002-9618-2421; Freitas Camara,
   Joana/0000-0002-4330-7702; SIRSAT, MANISHA/0000-0002-5696-3602
FU BRaNT team; BRaNT - Belief Revision applied to Neurorehabilitation
   Therapy - FCT - Fundaca o para a Ciencia e a Tecnologia
   [PTDC/CCI-COM/30990/2017]; MACBIOIDI: Promoting the cohesion of
   Macaronesian regions through a common ICT platform for biomedical R - D
   - i (INTERREG program) [MAC/1.1.b/098];  [UID/CEC/04516/2019]
FX We want to thank the BRaNT team for their support and stimulating
   discussions. This research is supported by BRaNT - Belief Revision
   applied to Neurorehabilitation Therapy [project number
   PTDC/CCI-COM/30990/2017], financed by FCT - Fundaca o para a Ciencia e a
   Tecnologia. EF is partially supported by UID/CEC/04516/2019. SBB is
   partially supported by MACBIOIDI: Promoting the cohesion of Macaronesian
   regions through a common ICT platform for biomedical R - D - i (INTERREG
   program MAC/1.1.b/098)
NR 71
TC 17
Z9 18
U1 12
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1052-3057
EI 1532-8511
J9 J STROKE CEREBROVASC
JI J. Stroke Cerebrovasc. Dis.
PD OCT
PY 2020
VL 29
IS 10
AR 105162
DI 10.1016/j.jstrokecerebrovasdis.2020.105162
PG 17
WC Neurosciences; Peripheral Vascular Disease
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Neurosciences & Neurology; Cardiovascular System & Cardiology
GA NO4EP
UT WOS:000569438600041
PM 32912543
OA Green Published
DA 2022-04-17
ER

PT J
AU Al-Anqoudi, Y
   Al-Hamdani, A
   Al-Badawi, M
   Hedjam, R
AF Al-Anqoudi, Younis
   Al-Hamdani, Abdullah
   Al-Badawi, Mohamed
   Hedjam, Rachid
TI Using Machine Learning in Business Process Re-Engineering
SO BIG DATA AND COGNITIVE COMPUTING
LA English
DT Article
DE business process re-engineering; data mining; machine learning
ID LEAN 6 SIGMA; OPTIMIZATION; MODELS
AB A business process re-engineering value in improving the business process is undoubted. Nevertheless, it is incredibly complex, time-consuming and costly. This study aims to review available literature in the use of machine learning for business process re-engineering. The review investigates available literature in business process re-engineering frameworks, methodologies, tools, techniques, and machine-learning applications in automating business process re-engineering. The study covers 200+ research papers published between 2015 and 2020 in reputable scientific publication platforms: Scopus, Emerald, Science Direct, IEEE, and British Library. The results indicate that business process re-engineering is a well-established field with scientifically solid frameworks, methodologies, tools, and techniques, which support decision making by generating and analysing relevant data. The study indicates a wealth of data generated, analysed and utilised throughout business process re-engineering projects, thus making it a potential greenfield for innovative machine-learning applications aiming to reduce implementation costs and manage complexity by exploiting the data's hiding patterns. This suggests that there were attempts towards applying machine learning in business process management and improvement in general. They address process discovery, process behaviour prediction, process improvement, and process optimisation. The review suggests that expanding the applications to business process re-engineering is promising. The study proposed a machine-learning model for automating business process re-engineering, inspired by the Lean Six Sigma principles of eliminating waste and variance in the business process.
C1 [Al-Anqoudi, Younis; Al-Hamdani, Abdullah; Al-Badawi, Mohamed; Hedjam, Rachid] Sultan Qaboos Univ, Dept Comp Sci, POB 36, Muscat 123, Oman.
RP Al-Anqoudi, Y (corresponding author), Sultan Qaboos Univ, Dept Comp Sci, POB 36, Muscat 123, Oman.
EM s22781@student.squ.edu.om; abd@squ.edu.om; mbadawi@squ.edu.om;
   rachid.hedjam@squ.edu.om
NR 59
TC 0
Z9 0
U1 4
U2 4
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2504-2289
J9 BIG DATA COGN COMPUT
JI Big Data Cogn. Comput.
PD DEC
PY 2021
VL 5
IS 4
AR 61
DI 10.3390/bdcc5040061
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA XX0AA
UT WOS:000735969000001
OA gold
DA 2022-04-17
ER

PT C
AU Zaidi, MA
AF Zaidi, Moayid Ali
BE Gervasi, O
   Murgante, B
   Misra, S
   Garau, C
   Blecic, I
   Taniar, D
   Apduhan, BO
   Rocha, AMAC
   Tarantino, E
   Torre, CM
TI Conceptual Modeling Interacts with Machine Learning - A Systematic
   Literature Review
SO COMPUTATIONAL SCIENCE AND ITS APPLICATIONS, ICCSA 2021, PT IX
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Science and Its
   Applications (ICCSA)
CY SEP 13-16, 2021
CL Cagliari, ITALY
DE Machine Learning; Conceptual Modeling; Systematic Literature Review
ID ONTOLOGY; SUPPORT
AB Due to the advancement in the digital world, society's expectation towards Machine Learning is very high, especially in Conceptual Modeling. However, the relationship between Machine Learning and Conceptual models are very interesting. Literature in this field has identified the relationship and interaction between Machine Learning and Conceptual Models. However, to the best of our knowledge, there is not a Systematic Literature Review devoted to studying in deep the interaction of these two fields. In this paper, the authors conduct a Systematic Literature Review to get to know how Machine Learning is used in Conceptual Modeling. Results show the deep connection of Machine Learning with Conceptual Models in a solid way, as well as providing challenges and opportunities for future research.
C1 [Zaidi, Moayid Ali] Ostfold Univ Coll, Halden, Norway.
RP Zaidi, MA (corresponding author), Ostfold Univ Coll, Halden, Norway.
NR 31
TC 0
Z9 0
U1 9
U2 9
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-87013-3; 978-3-030-87012-6
J9 LECT NOTES COMPUT SC
PY 2021
VL 12957
BP 522
EP 532
DI 10.1007/978-3-030-87013-3_39
PG 11
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods; Mathematics, Applied
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Mathematics
GA BS4SP
UT WOS:000722395800039
DA 2022-04-17
ER

PT J
AU Jaza, R
   Mollon, G
   Descartes, S
   Paquet, A
   Berthier, Y
AF Jaza, Rabii
   Mollon, Guilhem
   Descartes, Sylvie
   Paquet, Amandine
   Berthier, Yves
TI Lessons learned using machine learning to link third body particles
   morphology to interface rheology
SO TRIBOLOGY INTERNATIONAL
LA English
DT Article
DE Third body; Morphology; Rheology; Machine learning
ID COMPUTER IMAGE-ANALYSIS; WEAR PARTICLES; CLASSIFICATION; SHAPE; DEBRIS;
   SEGMENTATION; LUBRICATION; THICKNESS; FRICTION; TEXTURE
AB This paper reports a preliminary investigation on the ability of Machine Learning algorithms to relate the morphology of third body particles to the rheology of the contact interface that created them. A testing campaign is performed on a pin-on-disc tribometer, followed by a comprehensive observation of the worn surfaces. Several Machine Learning algorithms are then used to establish and quantify the logical relations between the rheological and the morphological databases built from this campaign. Success rates and thorough analysis of their predictions are used to validate the general approach and to propose possible improvements. It appears that Machine Learning presents an interesting potential in quantitative tribological analysis if the morphological and rheological databases are properly enriched.
C1 [Jaza, Rabii; Mollon, Guilhem; Descartes, Sylvie; Paquet, Amandine; Berthier, Yves] Univ Lyon, CNRS UMR5259, INSA Lyon, LaMCoS, F-69621 Lyon, France.
RP Mollon, G (corresponding author), Univ Lyon, CNRS UMR5259, INSA Lyon, LaMCoS, F-69621 Lyon, France.
EM guilhem.mollon@insa-lyon.fr
RI Descartes, Sylvie/H-9844-2016
OI Descartes, Sylvie/0000-0003-0611-1820
FU LABEX MANUTECH-SISE of Universite de Lyon, within the program
   "Investissements d'Avenir"French National Research Agency (ANR)
   [ANR-10-LABX-0075, ANR-11-IDEX-0007]
FX This work is supported by the LABEX MANUTECH-SISE (ANR-10-LABX-0075) of
   Universite de Lyon, within the program "Investissements d'Avenir"
   (ANR-11-IDEX-0007) operated by the French National Research Agency
   (ANR).
NR 69
TC 3
Z9 3
U1 6
U2 13
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0301-679X
EI 1879-2464
J9 TRIBOL INT
JI Tribol. Int.
PD JAN
PY 2021
VL 153
AR 106630
DI 10.1016/j.triboint.2020.106630
PG 15
WC Engineering, Mechanical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA OH7DZ
UT WOS:000582755900066
OA Bronze
DA 2022-04-17
ER

PT J
AU Alkhathlan, L
   Saudagar, AKJ
AF Alkhathlan, Lina
   Saudagar, Abdul Khader Jilani
TI Predicting and Classifying Breast Cancer Using Machine Learning
SO JOURNAL OF COMPUTATIONAL BIOLOGY
LA English
DT Article; Early Access
DE breast cancer; classification; deep learning; machine learning;
   prediction
ID CLASSIFICATION
AB The proposed research work aims to develop a method to predict and classify breast cancer (BC) at an early stage. In this research, three models are developed, and their performance is compared against each other. The first model was built using one of the machine learning algorithms called support vector machine (SVM), the second model was built using a deep learning algorithm called convolutional neural networks (CNNs), and the third model combines CNNs with a transfer learning technique for delivering better results. The data set is provided by the BC Histopathological Image Classification (BreakHis). All models are trained on the training set with two main categories: benign tumor and malignant tumor. The malignant tumor category is divided into subsets of invasive carcinoma tumors and in situ carcinoma tumors. Furthermore, invasive carcinoma tumors are classified into grade 1, grade 2, or grade 3, where grade 3 is the highest and is more aggressive. The results show that the accuracies of biopsy image classification using SVM are 92%, the accuracy of CNN is 94%, and the accuracy of CNN using the transfer learning technique is 97%. The results of this research will be beneficial in the early diagnosis of BC and help doctors in making better decisions and medical interventions.
C1 [Alkhathlan, Lina; Saudagar, Abdul Khader Jilani] Imam Mohammad Ibn Saud Islamic Univ IMSIU, Informat Syst Dept, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
RP Saudagar, AKJ (corresponding author), Imam Mohammad Ibn Saud Islamic Univ, Informat Syst Dept, Coll Comp & Informat Sci, Bldg 312,Off 2075, Riyadh 11432, Saudi Arabia.
EM aksaudagar@imamu.edu.sa
OI Saudagar, Abdul Khader Jilani/0000-0003-4205-3621
FU Imam Mohammad Ibn Saud Islamic University through the Graduate Students
   Research Support Program
FX The authors extend their appreciation to the Deanship of Scientific
   Research at Imam Mohammad Ibn Saud Islamic University for funding and
   supporting this work through the Graduate Students Research Support
   Program.
NR 46
TC 0
Z9 0
U1 12
U2 12
PU MARY ANN LIEBERT, INC
PI NEW ROCHELLE
PA 140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA
SN 1066-5277
EI 1557-8666
J9 J COMPUT BIOL
JI J. Comput. Biol.
DI 10.1089/cmb.2021.0236
EA DEC 2021
PG 18
WC Biochemical Research Methods; Biotechnology & Applied Microbiology;
   Computer Science, Interdisciplinary Applications; Mathematical &
   Computational Biology; Statistics & Probability
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology;
   Computer Science; Mathematical & Computational Biology; Mathematics
GA XM8SO
UT WOS:000729089700001
PM 34883032
DA 2022-04-17
ER

PT J
AU Pang, LG
AF Pang, Long-Gang
TI Machine learning for high energy heavy ion collisions
SO NUCLEAR PHYSICS A
LA English
DT Article; Proceedings Paper
CT 28th International Conference on Ultra-Relativistic Nucleus-Nucleus
   Collisions (Quark Matter)
CY NOV 04-09, 2019
CL Wuhan, PEOPLES R CHINA
SP Key Lab Quark & Lepton Phys, Cent China Norm Univ, Inst Particle Phys, S China Normal Univ, Inst Quantum Matter
DE Heavy ion collisions; deep learning; machine learning for physics
AB The high energy heavy ion collision is a multi-stage process that is described by complex hybrid models. The initial state fluctuations in event-by-event simulations of heavy ion collisions convert to final state correlations by collective flow and hadronic cascade. It is not easy to design final state correlations (observables) from particles in momentum space, that can help to extract useful information, such as the initial state nuclear structure, the properties of quark gluon plasma and the nuclear equation of state. Machine learning is helpful in automatic feature extraction in heavy ion collisions. This article reviews the applications, challenges and possible future developments of machine learning in heavy ion physics.
C1 [Pang, Long-Gang] Cent China Normal Univ, Key Lab Quark & Lepton Phys MOE, Wuhan 430079, Peoples R China.
   [Pang, Long-Gang] Cent China Normal Univ, Inst Particle Phys, Wuhan 430079, Peoples R China.
RP Pang, LG (corresponding author), Cent China Normal Univ, Key Lab Quark & Lepton Phys MOE, Wuhan 430079, Peoples R China.; Pang, LG (corresponding author), Cent China Normal Univ, Inst Particle Phys, Wuhan 430079, Peoples R China.
NR 30
TC 3
Z9 3
U1 2
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0375-9474
EI 1873-1554
J9 NUCL PHYS A
JI Nucl. Phys. A
PD JAN
PY 2021
VL 1005
SI SI
AR 121972
DI 10.1016/nuclphysa.2020.121972
PG 7
WC Physics, Nuclear
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Physics
GA PN6IF
UT WOS:000604580000018
DA 2022-04-17
ER

PT C
AU Moriya, T
AF Moriya, Tsuyoshi
GP IEEE
TI Machine Learning Approaches Optimizing Semiconductor Manufacturing
   Processes
SO 2021 5TH IEEE ELECTRON DEVICES TECHNOLOGY & MANUFACTURING CONFERENCE
   (EDTM)
LA English
DT Proceedings Paper
CT 5th IEEE Electron Devices Technology and Manufacturing Conference (EDTM)
CY APR 08-11, 2021
CL Chengdu, PEOPLES R CHINA
SP IEEE
DE Machine learning; plasma processing; materials informatics
AB This study was geared toward the optimization of semiconductor manufacturing processes through machine learning (ML) based on a regression algorithm. The nonuniformity of plasma-enhanced atomic layer deposition (PEALD) film thickness and PEALD film stress and the film thickness and carbon etching profiles were demonstrated herein to successfully achieve their targets.
C1 [Moriya, Tsuyoshi] Tokyo Electron Ltd, Tokyo, Japan.
RP Moriya, T (corresponding author), Tokyo Electron Ltd, Tokyo, Japan.
EM tsuyoshi.moriya@tel.com
NR 7
TC 0
Z9 0
U1 6
U2 6
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-8176-9
PY 2021
DI 10.1109/EDTM50988.2021.9420955
PG 3
WC Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering
GA BR9HB
UT WOS:000675595800141
DA 2022-04-17
ER

PT J
AU Adegun, IP
   Vadapalli, HB
AF Adegun, Iyanu Pelumi
   Vadapalli, Hima Bindu
TI Facial micro-expression recognition: A machine learning approach
SO SCIENTIFIC AFRICAN
LA English
DT Article
DE Micro-expressions; Feature extraction; Support vector machine; Emotions;
   Extreme learning machine
ID LOCAL BINARY PATTERNS
AB Micro-expression recognition is a growing research area owing to its application in revealing subtle intention of humans, especially while under high stake conditions. With the rapid increase in security issues all over the world, the use of micro-expressions to understand one's state of mind has received major interest. Micro-expressions are characterized by short duration and low intensity, hence, efforts to train humans in recognizing them have resulted in very low performances. Automatic recognition of micro-expressions using machine learning techniques thus promises a more effective result and saves time and resources. In this study, we explore the use of Extreme Learning Machine (ELM) for micro-expression recognition because of its fast learning ability and higher performance when compared with other models. Support Vector Machine (SVM) is used as a baseline model and its recognition performance and its training time compared with ELM training time. Feature extraction is performed on apex micro-expression frames using Local Binary Pattern (LBP) and on micro-expression videos divided into image sequences using a spatiotemporal feature extraction technique called Local Binary Pattern on Three Orthogonal Planes (LBP-TOP). Evaluation of the two models is performed on spontaneous facial micro-expression samples acquired from Chinese Academy of Sciences (CASME II). Results obtained from the experiments show that ELM produces a higher recognition performance than SVM in terms of accuracy, precision, recall and F-score when temporal features are used. Comparison between SVM and ELM training time also shows that ELM learns faster than SVM. An average training time of 0.3405 seconds is achieved for SVM while an average training time of 0.0409 seconds is achieved for ELM for the five selected microexpression classes. This study shows that automatic recognition of micro-expressions is produces a better result when temporal features and a machine learning algorithm with fast learning speed are used. (C) 2020 The Authors. Published by Elsevier B.V. on behalf of African Institute of Mathematical Sciences / Next Einstein Initiative.
C1 [Adegun, Iyanu Pelumi] Fed Univ Technol Akure, Dept Comp Sci, Akure, Nigeria.
   [Adegun, Iyanu Pelumi] Rufus Giwa Polytech, Dept Comp Sci, Owo, Nigeria.
   [Adegun, Iyanu Pelumi; Vadapalli, Hima Bindu] Univ Witwatersrand, Sch Comp Sci, ZA-2000 Johannesburg, South Africa.
RP Adegun, IP (corresponding author), Fed Univ Technol Akure, Dept Comp Sci, Akure, Nigeria.; Adegun, IP (corresponding author), Rufus Giwa Polytech, Dept Comp Sci, Owo, Nigeria.; Adegun, IP (corresponding author), Univ Witwatersrand, Sch Comp Sci, ZA-2000 Johannesburg, South Africa.
EM iyanupelumi22@gmail.com; hima.vadapalli@wits.ac.za
RI Vadapalli, Hima/AAD-2624-2022
FU DST-NRF Centre of Excellence in Mathematical and Statistical Sciences
   (CoE-MaSS)
FX The support of the DST-NRF Centre of Excellence in Mathematical and
   Statistical Sciences (CoE-MaSS) towards the research is hereby
   acknowledged. Opinions expressed and conclusions arrived at, are those
   of the author and are not necessarily to be attributed to the CoE. The
   Institute of Psychology, Chinese Academy of Sciences is appreciated for
   releasing CASME II micro-expression database for this research.
NR 30
TC 5
Z9 5
U1 5
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2468-2276
J9 SCI AFR
JI Sci. Afr.
PD JUL
PY 2020
VL 8
AR e00465
DI 10.1016/j.sciaf.2020.e00465
PG 14
WC Multidisciplinary Sciences
WE Emerging Sources Citation Index (ESCI)
SC Science & Technology - Other Topics
GA SN7NJ
UT WOS:000658474000153
OA gold
DA 2022-04-17
ER

PT J
AU Hu, RY
   Zhang, SY
   Meng, HL
   Yu, H
   Zhang, JZ
   Luo, XZ
   Si, T
   Liu, CL
   Qiao, Y
AF Hu, Ruyun
   Zhang, Songya
   Meng, Hailin
   Yu, Han
   Zhang, Jianzhi
   Luo, Xiaozhou
   Si, Tong
   Liu, Chenli
   Qiao, Yu
TI Machine learning for synthetic biology: Methods and applications
SO CHINESE SCIENCE BULLETIN-CHINESE
LA Chinese
DT Article
DE machine learning; synthetic biology; synthetic biology parts design;
   bio-networks design
ID ANTIMICROBIAL PEPTIDE DATABASE; CLUSTER-ANALYSIS; METABOLIC PATHWAYS;
   BAYESIAN NETWORKS; PROTEIN; PREDICTION; MODEL; DNA; CLASSIFICATION;
   IDENTIFICATION
AB Traditional synthetic biology takes a trial-and-error approach, suffering from inefficiency and local optima. Recent advances in high-throughput experimental techniques generate a huge amount of biological data, which enables the use of machine learning to close the "design-build-test-learn" loop. Machine learning, especially deep learning, is a data-driven modeling method, which extracts useful patterns from big data and then leverages learned knowledge to tackle specific tasks. In this review, we aim to provide a brief primer of machine learning to synthetic biologists. Starting with common taxonomy, we introduce representative methods, pipelines, and underlying principles of machine learning that can be applied in synthetic biology. We include typical methods such as support vector machine, deep neural networks, generative adversarial nets, transfer learning and reinforcement learning. In particular, discriminative models, including convolutional neural networks and support vector machine, are appropriate for predicting sequence-function relationship. Generative models, including generative adversarial nets (GANs) and deep generative models for graph generation, are suitable for sequence or network design.
   Next, we review the recent applications of machine learning in studying synthetic biology parts and modules, including promoters, bioactive peptides, enzymes, metabolic pathways, and genetic circuits. For example, DeePromoter combined a convolutional neural network and a long-short term memory to achieve an accuracy as high as 90% when predicting promoter sequences. For enzyme design, a Gauss Process model was proposed with Bayesian optimization by upper confidence bound method, which resulted in the engineering of thermostable P450 enzymes. For antimicrobial peptides, a generative GAN model enhanced with a feedback mechanism was trained to design peptide sequences with new functions.
   Finally, we conclude with future challenges and directions. Particularly, interpretable machine learning models are desirable to guide mechanistic investigation. Moreover, it is necessary to develop new machine learning methods that are more compatible with biological data, which are heterogeneous, multi-modal (such as sequence, network, image, and structure), and lack of proper labels. With the increasing availability of big biological data and development of machine learning methods tailored for synthetic biology, we envision a paradigm shift towards a closed cycle of "design-build-testlearn" in creating artificial life with predictable functions.
C1 [Hu, Ruyun; Qiao, Yu] Chinese Acad Sci, Inst Adv Comp & Digital Engn, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
   [Zhang, Songya; Meng, Hailin; Yu, Han; Zhang, Jianzhi; Luo, Xiaozhou; Si, Tong; Liu, Chenli] Chinese Acad Sci, Inst Synthet Biol, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
   [Zhang, Songya; Yu, Han; Zhang, Jianzhi; Luo, Xiaozhou; Si, Tong; Liu, Chenli] Shenzhen Inst Synthet Biol, Shenzhen 518055, Peoples R China.
   [Zhang, Songya; Yu, Han; Zhang, Jianzhi; Luo, Xiaozhou; Si, Tong; Liu, Chenli] CAS Key Lab Quantitat Engn Biol, Shenzhen 518055, Peoples R China.
   [Meng, Hailin] Chinese Acad Sci, Ctr Biol Engn, Guangzhou Inst Adv Technol, Guangzhou 511458, Peoples R China.
RP Qiao, Y (corresponding author), Chinese Acad Sci, Inst Adv Comp & Digital Engn, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.; Si, T; Liu, CL (corresponding author), Chinese Acad Sci, Inst Synthet Biol, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.; Si, T; Liu, CL (corresponding author), Shenzhen Inst Synthet Biol, Shenzhen 518055, Peoples R China.; Si, T; Liu, CL (corresponding author), CAS Key Lab Quantitat Engn Biol, Shenzhen 518055, Peoples R China.
EM tong.si@siat.ac.cn; cl.liu@siat.ac.cn; yqiao@siat.ac.cn
NR 127
TC 2
Z9 3
U1 27
U2 46
PU SCIENCE PRESS
PI EPHRATA
PA 300 WEST CHESNUT ST, EPHRATA, PA 17522 USA
SN 0023-074X
EI 2095-9419
J9 CHIN SCI B-CHIN
JI Chin. Sci. Bull.-Chin.
PY 2021
VL 66
IS 3
BP 284
EP 299
DI 10.1360/TB-2020-0456
PG 16
WC Multidisciplinary Sciences
WE Emerging Sources Citation Index (ESCI)
SC Science & Technology - Other Topics
GA QW5BC
UT WOS:000628664100004
OA Bronze
DA 2022-04-17
ER

PT J
AU Suomalainen, J
   Juhola, A
   Shahabuddin, S
   Mammela, A
   Ahmad, I
AF Suomalainen, Jani
   Juhola, Arto
   Shahabuddin, Shahriar
   Mammela, Aarne
   Ahmad, Ijaz
TI Machine Learning Threatens 5G Security
SO IEEE ACCESS
LA English
DT Article
DE 5G; cybersecurity; machine learning; mobile networks; survey; threats;
   vulnerabilities; wireless networks
ID SOFTWARE-DEFINED NETWORKING; PHYSICAL LAYER SECURITY; NEXT-GENERATION;
   BLACK-BOX; CHALLENGES; WIRELESS; INTELLIGENCE; PERFORMANCE; MANAGEMENT;
   TAXONOMY
AB Machine learning (ML) is expected to solve many challenges in the fifth generation (5G) of mobile networks. However, ML will also open the network to several serious cybersecurity vulnerabilities. Most of the learning in ML happens through data gathered from the environment. Un-scrutinized data will have serious consequences on machines absorbing the data to produce actionable intelligence for the network. Scrutinizing the data, on the other hand, opens privacy challenges. Unfortunately, most of the ML systems are borrowed from other disciplines that provide excellent results in small closed environments. The resulting deployment of such ML systems in 5G can inadvertently open the network to serious security challenges such as unfair use of resources, denial of service, as well as leakage of private and confidential information. Therefore, in this article we dig into the weaknesses of the most prominent ML systems that are currently vigorously researched for deployment in 5G. We further classify and survey solutions for avoiding such pitfalls of ML in 5G systems.
C1 [Suomalainen, Jani; Juhola, Arto; Ahmad, Ijaz] VTT Tech Res Ctr Finland, Espoo 02044, Finland.
   [Shahabuddin, Shahriar] Nokia, Oulu 90540, Finland.
   [Mammela, Aarne] VTT Tech Res Ctr Finland, Oulu 90571, Finland.
RP Suomalainen, J (corresponding author), VTT Tech Res Ctr Finland, Espoo 02044, Finland.
EM jani.suomalainen@vtt.fi
RI Ahmad, Ijaz/ABE-7822-2020
OI Ahmad, Ijaz/0000-0003-1101-8698; Suomalainen, Jani/0000-0001-7921-8667
FU Business Finland through the PRIORITY project
FX This work was supported in part by the Business Finland through the
   PRIORITY project.
NR 184
TC 11
Z9 11
U1 2
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 190822
EP 190842
DI 10.1109/ACCESS.2020.3031966
PG 21
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA OK8GH
UT WOS:000584882100001
OA gold, Green Published
DA 2022-04-17
ER

PT J
AU Jiang, T
AF Jiang, Tiffany
TI Using Machine Learning to Analyze Merger Activity
SO FRONTIERS IN APPLIED MATHEMATICS AND STATISTICS
LA English
DT Article
DE supervised training; machine learning; finance; mergers and
   acquisations; text
ID TEXT
AB An unprecedented amount of access to data, "big data (or high dimensional data)," cloud computing, and innovative technology have increased applications of artificial intelligence in finance and numerous other industries. Machine learning is used in process automation, security, underwriting and credit scoring, algorithmic trading and robo-advisory. In fact, machine learning AI applications are purported to save banks an estimated $447 billion by 2023. Given the advantages that AI brings to finance, we focused on applying supervised machine learning to an investment problem. 10-K SEC filings are routinely used by investors to determine the worth and status of a company-Warren Buffett is frequently cited to read a 10-K a day. We sought to answer-"Can machine learning analyze more than thousands of companies and spot patterns? Can machine learning automate the process of human analysis in predicting whether a company is fit to merge? Can machine learning spot something that humans cannot?" In the advent of rising antitrust discussion of growing market concentrations and the concern for decrease in competition, we analyzed merger activity using text as a data set. Merger activity has been traditionally hard to predict in the past. We took advantage of the large amount of publicly available filings through the Securities Exchange Commission that give a comprehensive summary of a company, and used text, and an innovative way to analyze a company. In order to verify existing theory and measure harder to observe variables, we look to use a text document and examined a firm's 10-K SEC filing. To minimize over-fitting, the L2 LASSO regularization technique is used. We came up with a model that has 85% accuracy compared to a 35% accuracy using the "bag-of-words" method to predict a company's likelihood of merging from words alone on the same period's test data set. These steps are the beginnings of tackling more complicated questions, such as "Which section or topic of words is the most predictive?" and "What is the difference between being acquired and acquiring?" Using product descriptions to characterize mergers further into horizontal and vertical mergers could eventually assist with the causal estimates that are of interest to economists. More importantly, using language and words to categorize companies could be useful in predicting counterfactual scenarios and answering policy questions, and could have different applications ranging from detecting fraud to better trading.
C1 [Jiang, Tiffany] Stanford Univ, Dept Econ, Stanford, CA 94305 USA.
   [Jiang, Tiffany] Univ Calif Davis, Dept Econ, Davis, CA 95616 USA.
RP Jiang, T (corresponding author), Stanford Univ, Dept Econ, Stanford, CA 94305 USA.; Jiang, T (corresponding author), Univ Calif Davis, Dept Econ, Davis, CA 95616 USA.
EM tiffj56@gmail.com
NR 19
TC 0
Z9 0
U1 1
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2297-4687
J9 FRONT APPL MATH STAT
JI Front. Appl. Math. Stat.
PD AUG 2
PY 2021
VL 7
AR 649501
DI 10.3389/fams.2021.649501
PG 9
WC Mathematics, Interdisciplinary Applications
WE Emerging Sources Citation Index (ESCI)
SC Mathematics
GA UA6AK
UT WOS:000685242400001
OA gold
DA 2022-04-17
ER

PT J
AU Chen, YH
   Xie, XL
   Zhang, TL
   Bai, JX
   Hou, MZ
AF Chen, Yinghao
   Xie, Xiaoliang
   Zhang, Tianle
   Bai, Jiaxian
   Hou, Muzhou
TI A deep residual compensation extreme learning machine and applications
SO JOURNAL OF FORECASTING
LA English
DT Article
DE airfoil self-noise; deep residual compensation extreme learning machine;
   extreme learning machine; gold price forecasting; regression problem
ID AIC MODEL SELECTION; OPTIMIZATION; REDUCTION; ALGORITHM
AB The extreme learning machine (ELM) is a type of machine learning algorithm for training a single hidden layer feedforward neural network. Randomly initializing the weight between the input layer and the hidden layer and the threshold of each hidden layer neuron, the weight matrix of the hidden layer can be calculated by the least squares method. The efficient learning ability in ELM makes it widely applicable in classification, regression, and more. However, owing to some unutilized information in the residual, there are relatively huge prediction errors involving ELM. In this paper, a deep residual compensation extreme learning machine model (DRC-ELM) of multilayer structures applied to regression is presented. The first layer is the basic ELM layer, which helps in obtaining an approximation of the objective function by learning the characteristics of the sample. The other layers are the residual compensation layers in which the learned residual is corrected layer by layer to the predicted value obtained in the previous layer by constructing a feature mapping between the input layer and the output of the upper layer. This model is applied to two practical problems: gold price forecasting and airfoil self-noise prediction. We used the DRC-ELM with 50, 100, and 200 residual compensation layers respectively for experiments, which show that DRC-ELM does better in generalization and robustness than classical ELM, improved ELM models such as GA-RELM and OS-ELM, and other traditional machine learning algorithms such as support vector machine (SVM) and back-propagation neural network (BPNN).
C1 [Chen, Yinghao; Zhang, Tianle; Hou, Muzhou] Cent South Univ, Coll Math & Stat, Changsha 410083, Peoples R China.
   [Xie, Xiaoliang] Hunan Univ Technol & Business, Sch Math & Stat, Changsha, Peoples R China.
   [Bai, Jiaxian] Hunan Univ, Coll Finance & Stat, Changsha, Peoples R China.
RP Hou, MZ (corresponding author), Cent South Univ, Coll Math & Stat, Changsha 410083, Peoples R China.
EM houmuzhou@sina.com
RI Zhang, Tianle/V-8753-2019
OI Zhang, Tianle/0000-0003-4881-2406; Chen, Yinghao/0000-0002-9176-8394;
   Hou, Muzhou/0000-0001-6658-2187
FU National Social Science Foundation of China [19BTJ011]
FX The Projects of the National Social Science Foundation of China,
   Grant/Award Number: 19BTJ011
NR 49
TC 13
Z9 13
U1 5
U2 21
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0277-6693
EI 1099-131X
J9 J FORECASTING
JI J. Forecast.
PD SEP
PY 2020
VL 39
IS 6
BP 986
EP 999
DI 10.1002/for.2663
EA FEB 2020
PG 14
WC Economics; Management
WE Social Science Citation Index (SSCI)
SC Business & Economics
GA MS7CO
UT WOS:000513815200001
DA 2022-04-17
ER

PT J
AU Zimmermann, J
   Kiktova, E
AF Zimmermann, JUlius
   Kiktova, Eva
TI Machine learning for detection of anticipation nucleus
SO SKASE JOURNAL OF THEORETICAL LINGUISTICS
LA English
DT Article; Proceedings Paper
CT Conference on Anticipation in Consecutive and Simultaneous Cognitive
   Tasks
CY JUN 20-22, 2019
CL Kosice, SLOVAKIA
DE interpreting; anticipation; prosody; machine learning; detection; k-NN
AB Anticipation is highly beneficial for an interpreter: it enables prediction of what the speaker has in his mind and how his speech will continue. The detection of anticipation nuclei is a challenging task for interpreters. Their ability to detect them is strongly dependent on their personal skills and experience. This prediction - anticipation - is based on semantics, syntax, and intonation. In our study, a machine learning approach based on statistical learning methods is applied for the detection of anticipation nuclei via prosody. Perceptually identified anticipation nuclei from French speeches were used to train the statistical models. The models created were then evaluated in the testing process. For the efficient use of the database, cross-validation was performed. The results obtained suggest that machine learning algorithms can be effectively used to detect a very fine suprasegmental phenomenon - the anticipation.
C1 [Zimmermann, JUlius; Kiktova, Eva] Pavol Jozef Safarik Univ Kosice, LICOLAB Language Informat & Commun Lab, Dept Slovak Studies Slavon Philol & Commun, Kosice, Slovakia.
RP Zimmermann, J (corresponding author), Pavol Jozef Safarik Univ Kosice, LICOLAB Language Informat & Commun Lab, Dept Slovak Studies Slavon Philol & Commun, Kosice, Slovakia.
EM julius.zimmermann@upjs.sk; eva.kiktova@upjs.sk
RI Kiktova, Eva/AAN-3730-2020
OI Kiktova, Eva/0000-0001-9325-7339
FU Slovak Research and Development AgencySlovak Research and Development
   Agency [APVV-15-0307, APVV-15-0492]
FX This work was supported by the Slovak Research and Development Agency
   under contracts No. APVV-15-0307 and APVV-15-0492.
NR 12
TC 0
Z9 0
U1 0
U2 0
PU SLOVAK ASSOC STUDY ENGLISH-SKASE
PI KOSICE
PA SLOVAK ASSOC STUDY ENGLISH-SKASE, KOSICE, 00000, SLOVAKIA
EI 1336-782X
J9 SKASE J THEOR LING
JI SKASE J. Theor. Linguist.
PY 2020
VL 17
IS 4
BP 2
EP 8
PG 7
WC Linguistics; Language & Linguistics
WE Emerging Sources Citation Index (ESCI)
SC Linguistics
GA OM8PD
UT WOS:000586278400001
DA 2022-04-17
ER

PT J
AU Fersht, AR
AF Fersht, Alan R.
TI AlphaFold - A Personal Perspective on the Impact of Machine Learning
SO JOURNAL OF MOLECULAR BIOLOGY
LA English
DT Review
DE protein folding; machine learning; chess; Go
ID PROTEIN; GO; GAME
AB I outline how over my career as a protein scientist Machine Learning has impacted my area of science and one of my pastimes, chess, where there are some interesting parallels. In 1968, modelling of three-dimensional structures was initiated based on a known structure as a template, the problem of the pathway of protein folding was posed and bets were taken in the emerging field of Machine Learning on whether computers could outplay humans at chess. Half a century later, Machine Learning has progressed from using computational power combined with human knowledge in solving problems to playing chess without human knowledge being used, where it has produced novel strategies. Protein structures are being solved by Machine Learning based on human-derived knowledge but without templates. There is much promise that programs like AlphaFold based on Machine Learning will be powerful tools for designing entirely novel protein folds and new activities. But, will they produce novel ideas on protein folding pathways and provide new insights into the principles that govern folds? (C) 2021 Elsevier Ltd. All rights reserved.
C1 [Fersht, Alan R.] MRC Lab Mol Biol, Hills Rd, Cambridge CB2 0QH, England.
RP Fersht, AR (corresponding author), MRC Lab Mol Biol, Hills Rd, Cambridge CB2 0QH, England.
FU MRC Laboratory of Molecular BiologyUK Research & Innovation
   (UKRI)Medical Research Council UK (MRC)
FX I thank the MRC Laboratory of Molecular Biology for funding.
NR 13
TC 2
Z9 2
U1 18
U2 18
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0022-2836
EI 1089-8638
J9 J MOL BIOL
JI J. Mol. Biol.
PD OCT 1
PY 2021
VL 433
IS 20
SI SI
AR 167088
DI 10.1016/j.jmb.2021.167088
EA OCT 2021
PG 4
WC Biochemistry & Molecular Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology
GA WP7KK
UT WOS:000713305500004
PM 34087198
OA Bronze
DA 2022-04-17
ER

PT J
AU Mohamed, A
   Abuoda, G
   Ghanem, A
   Kaoudi, Z
   Aboulnaga, A
AF Mohamed, Aisha
   Abuoda, Ghadeer
   Ghanem, Abdurrahman
   Kaoudi, Zoi
   Aboulnaga, Ashraf
TI RDFFrames: knowledge graph access for machine learning tools
SO VLDB JOURNAL
LA English
DT Article
DE Knowledge graphs; RDF; SPARQL; PyData; Data preparation; Machine
   learning
ID CONSTRUCTION
AB Knowledge graphs represented as RDF datasets are integral to many machine learning applications. RDF is supported by a rich ecosystem of data management systems and tools, most notably RDF database systems that provide a SPARQL query interface. Surprisingly, machine learning tools for knowledge graphs do not use SPARQL, despite the obvious advantages of using a database system. This is due to the mismatch between SPARQL and machine learning tools in terms of data model and programming style. Machine learning tools work on data in tabular format and process it using an imperative programming style, while SPARQL is declarative and has as its basic operation matching graph patterns to RDF triples. We posit that a good interface to knowledge graphs from a machine learning software stack should use an imperative, navigational programming paradigm based on graph traversal rather than the SPARQL query paradigm based on graph patterns. In this paper, we present RDFFrames, a framework that provides such an interface. RDFFrames provides an imperative Python API that gets internally translated to SPARQL, and it is integrated with the PyData machine learning software stack. RDFFrames enables the user to make a sequence of Python calls to define the data to be extracted from a knowledge graph stored in an RDF database system, and it translates these calls into a compact SPQARL query, executes it on the database system, and returns the results in a standard tabular format. Thus, RDFFrames is a useful tool for data preparation that combines the usability of PyData with the flexibility and performance of RDF database systems.
C1 [Mohamed, Aisha; Aboulnaga, Ashraf] HBKU, Qatar Comp Res Inst, Education City, Qatar.
   [Abuoda, Ghadeer] HBKU, Coll Sci & Engn, Education City, Qatar.
   [Ghanem, Abdurrahman] Bluescape, San Carlos, CA USA.
   [Kaoudi, Zoi] Tech Univ Berlin, Berlin, Germany.
RP Abuoda, G (corresponding author), HBKU, Coll Sci & Engn, Education City, Qatar.
EM ahmohamed@hbku.edu.qa; gabuoda@hbku.edu.qa; ghanemabdo@gmail.com;
   zoi.kaoudi@tu-berlin.de; aaboulnaga@hbku.edu.qa
OI Kaoudi, Zoi/0000-0003-4520-5360
FU Qatar National Library
FX Open access funding provided by the Qatar National Library.
NR 48
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1066-8888
EI 0949-877X
J9 VLDB J
JI VLDB J.
PD MAR
PY 2022
VL 31
IS 2
SI SI
BP 321
EP 346
DI 10.1007/s00778-021-00690-5
EA AUG 2021
PG 26
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZU6ZC
UT WOS:000689650700001
OA hybrid, Green Submitted
DA 2022-04-17
ER

PT C
AU Dalvi, RR
   Chavan, SB
   Halbe, A
AF Dalvi, Rahul Ramesh
   Chavan, Sudhanshu Baliram
   Halbe, Apama
GP IEEE
TI Detecting A Twitter Cyberbullying Using Machine Learning
SO PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND
   CONTROL SYSTEMS (ICICCS 2020)
LA English
DT Proceedings Paper
CT International Conference on Intelligent Computing and Control Systems
   (ICICCS)
CY MAY 13-15, 2020
CL Anna Univ, Vaigai Coll Engn, Madurai, INDIA
SP IEEE
HO Anna Univ, Vaigai Coll Engn
DE cyberbullying; machine learning; classifiers; Naive Bayes; support
   vector machine (SVM); Twitter API
AB Social media is a platform where many young people are getting bullied. As social networking sites are increasing, cyberbullying is increasing day by day. To identify word similarities in the tweets made by bullies and make use of machine learning and can develop an ML model automatically detect social media bullying actions. However, many social media bullying detection techniques have been implemented, but many of them were textual based. The goal of this paper is to show the implementation of software that will detect bullied tweets, posts, etc. A machine learning model is proposed to detect and prevent bullying on Twitter. Two classifiers i.e. SVM and Naive Bayes are used for training and testing the social media bullying content. Both Naive Bayes and SVM (Support Vector Machine) were able to detect the true positives with 71.25% and 52.70% accuracy respectively. But SVM outperforms Naive Bayes of similar work on the same dataset. Also, Twitter API is used to fetch tweets and tweets are passed to the model to detect whether the tweets are bullying or not.
C1 [Dalvi, Rahul Ramesh; Chavan, Sudhanshu Baliram; Halbe, Apama] Sardar Patel Inst Technol, Dept Informat Technol, Mumbai, Maharashtra, India.
RP Dalvi, RR (corresponding author), Sardar Patel Inst Technol, Dept Informat Technol, Mumbai, Maharashtra, India.
EM rahuldalvi1999@gmail.com; sudhanshuchavhan5136@gmail.com;
   aparna_halbe@spit.ac.in
NR 8
TC 1
Z9 1
U1 0
U2 2
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-4876-2
PY 2020
BP 297
EP 301
PG 5
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Automation & Control Systems; Computer Science
GA BQ5ZQ
UT WOS:000609825100051
DA 2022-04-17
ER

PT C
AU Liu, Y
   Ling, ZJ
   Huo, BY
   Wang, BQ
   Chen, TAN
   Mouine, E
AF Liu, Yan
   Ling, Zhijing
   Huo, Boyu
   Wang, Boqian
   Chen, Tianen
   Mouine, Esma
TI Building A Platform for Machine Learning Operations from Open Source
   Frameworks
SO IFAC PAPERSONLINE
LA English
DT Proceedings Paper
CT 3rd IFAC Workshop pn Cyber-Physical and Human Systems (CPHS)
CY DEC 03-05, 2020
CL Beijing, PEOPLES R CHINA
SP Int Federat Automat Control, Tech Comm 9 1 Econ, Busines, & Financial Syst, Int Federat Automat Control, Tech Comm 9 2 Social Impact Automat, Int Federat Automat Control, Tech Comm 1 3 Discrete Event & Hybrid Syst, Int Federat Automat Control, Tech Comm 1 4 Stochastic Syst, Int Federat Automat Control, Tech Comm 1 5 Networked Syst, Int Federat Automat Control, Tech Comm 3 1 Comp Control, Int Federat Automat Control, Tech Comm 4 3 Robot, Int Federat Automat Control, Tech Comm 4 5 Human Machine Syst, Int Federat Automat Control, Tech Comm 7 3 Aerosp, Int Federat Automat Control, Tech Comm 9 5 Technol, Culture & Int Stabil
DE Machine Learning; DevOps; Software Architecture; Open Source
AB Machine Learning Operations (MLOps) aim to establish a set of practices that put tools, pipelines, and processes to build fast time-to-value machine learning development projects. The lifecycle of machine learning project development encompasses a set of roles, stacks of software frameworks and multiple types of computing resources. Such complexity makes MLOps support usually bundled with commercial cloud platforms that is referred as vendor lock. In this paper, we provide an alternative solution that devises a MLOps platform with open source frameworks on any virtual resources. Our MLOps approach is driven by the development roles of machine learning models. The tool chain of our MLOps connects to the typical CI/CD workflow of machine learning applications. We demonstrate a working example of training and deploying a model for the application of detecting software repository code vulnerability. Copyright (C) 2020 The Authors.
C1 [Liu, Yan; Ling, Zhijing; Huo, Boyu; Wang, Boqian; Chen, Tianen; Mouine, Esma] Concordia Univ, Gina Cody Sch Engn & Comp Sci, Montreal, PQ H3G 1M8, Canada.
RP Liu, Y (corresponding author), Concordia Univ, Gina Cody Sch Engn & Comp Sci, Montreal, PQ H3G 1M8, Canada.
EM yan.liu@concordia.ca
NR 13
TC 0
Z9 0
U1 10
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2405-8963
J9 IFAC PAPERSONLINE
JI IFAC PAPERSONLINE
PY 2020
VL 53
IS 5
SI SI
BP 704
EP 709
DI 10.1016/j.ifacol.2021.04.161
PG 6
WC Automation & Control Systems
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Automation & Control Systems
GA SL0EN
UT WOS:000656589700125
OA gold
DA 2022-04-17
ER

PT J
AU Avanzo, M
   Wei, LS
   Stancanello, J
   Vallieres, M
   Rao, A
   Morin, O
   Mattonen, SA
   El Naqa, I
AF Avanzo, Michele
   Wei, Lise
   Stancanello, Joseph
   Vallieres, Martin
   Rao, Arvind
   Morin, Olivier
   Mattonen, Sarah A.
   El Naqa, Issam
TI Machine and deep learning methods for radiomics
SO MEDICAL PHYSICS
LA English
DT Article
DE deep learning; machine learning; quantitative image analysis; radiomics
ID CELL LUNG-CANCER; FDG-PET RADIOMICS; TEXTURAL FEATURES;
   RADIATION-THERAPY; BREAST-CANCER; SURVIVAL ANALYSIS; NEURAL-NETWORKS;
   CT; IMAGES; PREDICTION
AB Radiomics is an emerging area in quantitative image analysis that aims to relate large-scale extracted imaging information to clinical and biological endpoints. The development of quantitative imaging methods along with machine learning has enabled the opportunity to move data science research towards translation for more personalized cancer treatments. Accumulating evidence has indeed demonstrated that noninvasive advanced imaging analytics, that is, radiomics, can reveal key components of tumor phenotype for multiple three-dimensional lesions at multiple time points over and beyond the course of treatment. These developments in the use of CT, PET, US, and MR imaging could augment patient stratification and prognostication buttressing emerging targeted therapeutic approaches. In recent years, deep learning architectures have demonstrated their tremendous potential for image segmentation, reconstruction, recognition, and classification. Many powerful open-source and commercial platforms are currently available to embark in new research areas of radiomics. Quantitative imaging research, however, is complex and key statistical principles should be followed to realize its full potential. The field of radiomics, in particular, requires a renewed focus on optimal study design/reporting practices and standardization of image acquisition, feature calculation, and rigorous statistical analysis for the field to move forward. In this article, the role of machine and deep learning as a major computational vehicle for advanced model building of radiomics-based signatures or classifiers, and diverse clinical applications, working principles, research opportunities, and available computational platforms for radiomics will be reviewed with examples drawn primarily from oncology. We also address issues related to common applications in medical physics, such as standardization, feature extraction, model building, and validation.
C1 [Avanzo, Michele] IRCCS, Dept Med Phys, Ctr Rifrrimento Oncol Aviano CRO, I-33081 Aviano, PN, Italy.
   [Wei, Lise; Rao, Arvind; El Naqa, Issam] Univ Michigan, Dept Radiat Oncol, Ann Arbor, MI 48103 USA.
   [Stancanello, Joseph] Guerbet SA, Villepinte, France.
   [Vallieres, Martin] McGill Univ, Med Phys Unit, Montreal, PQ, Canada.
   [Vallieres, Martin; Morin, Olivier] Univ Calif San Francisco, Dept Radiat Oncol, San Francisco, CA 94143 USA.
   [Rao, Arvind] Univ Michigan, Dept Computat Med & Bioinformat, Ann Arbor, MI 48103 USA.
   [Mattonen, Sarah A.] Stanford Univ, Dept Radiol, Stanford, CA 94305 USA.
RP Avanzo, M (corresponding author), IRCCS, Dept Med Phys, Ctr Rifrrimento Oncol Aviano CRO, I-33081 Aviano, PN, Italy.
EM mavanzo@cro.it
RI Avanzo, Michele/C-8529-2009
OI Avanzo, Michele/0000-0003-1711-4242
NR 147
TC 55
Z9 57
U1 25
U2 49
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0094-2405
EI 2473-4209
J9 MED PHYS
JI Med. Phys.
PD JUN
PY 2020
VL 47
IS 5
BP E185
EP E202
DI 10.1002/mp.13678
PG 18
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA PB0JZ
UT WOS:000596015500007
PM 32418336
OA Green Accepted, Green Published
DA 2022-04-17
ER

PT C
AU Ghazimirsaeed, SM
   Anthony, Q
   Shafi, A
   Subramoni, H
   Panda, DKD
AF Ghazimirsaeed, S. Mahdieh
   Anthony, Quentin
   Shafi, Aamir
   Subramoni, Hari
   Panda, Dhabaleswar K. Dk
GP IEEE Comp Soc
TI Accelerating GPU-based Machine Learning in Python using MPI Library: A
   Case Study with MVAPICH2-GDR
SO 2020 IEEE/ACM WORKSHOP ON MACHINE LEARNING IN HIGH PERFORMANCE COMPUTING
   ENVIRONMENTS (MLHPC 2020) AND WORKSHOP ON ARTIFICIAL INTELLIGENCE AND
   MACHINE LEARNING FOR SCIENTIFIC APPLICATIONS (AI4S 2020)
LA English
DT Proceedings Paper
CT IEEE/ACM Workshop on Machine Learning in High Performance Computing
   Environments (MLHPC) / Workshop on Artificial Intelligence and Machine
   Learning for Scientific Applications (AI4S)
CY NOV 09-19, 2020
CL ELECTR NETWORK
SP IEEE, ACM, TCHPC, SIGHPC, IEEE Comp Soc
DE Machine Learning; cuML; MPI; GPUs
ID ALGORITHMS
AB The growth of big data applications during the last decade has led to a surge in the deployment and popularity of machine learning (ML) libraries. On the other hand, the high performance offered by GPUs makes them well suited for ML problems. To take advantage of GPU performance for ML, NVIDIA has recently developed the cuML library. cuML is the GPU counterpart of Scikit-learn, and provides similar Pythonic interfaces to Scikit-learn while hiding the complexities of writing GPU compute kernels directly using CUDA. To support execution of ML workloads on Multi-Node Multi-GPU (MNMG) systems, the cuML library exploits the NVIDIA Collective Communications Library (NCCL) as a backend for collective communications between processes. On the other hand, MPI is a de facto standard for communication in HPC systems. Among various MPI libraries, MVAPICH2-GDR is the pioneer in optimizing GPU communication.
   This paper explores various aspects and challenges of providing MPI-based communication support for GPU-accelerated cuML applications. More specifically, it proposes a Python API to take advantage of MPI-based communications for cuML applications. It also gives an in-depth analysis, characterization, and benchmarking of the cuML algorithms such as K-Means, Nearest Neighbors, Random Forest, and tSVD. Moreover, it provides a comprehensive performance evaluation and profiling study for MPI-based versus NCCL-based communication for these algorithms. The evaluation results show that the proposed MPI-based communication approach achieves up to 1.6x, 1.25x, 1.25x, and 1.36x speedup for K-Means, Nearest Neighbors, Linear Regression, and tSVD, respectively on up to 32 GPUs.
C1 [Ghazimirsaeed, S. Mahdieh; Anthony, Quentin; Shafi, Aamir; Subramoni, Hari; Panda, Dhabaleswar K. Dk] Ohio State Univ, Columbus, OH 43210 USA.
RP Ghazimirsaeed, SM (corresponding author), Ohio State Univ, Columbus, OH 43210 USA.
EM ghazimirsaeed.3@osu.edu; anthony.301@osu.edu; shafi.16@osu.edu;
   subramoni.1@osu.edu; panda.2@osu.edu
FU NSFNational Science Foundation (NSF) [1450440, 1565414, 1664137,
   1818253, 1854828, 1931537, 2007991]; XRAC [NCR-130002]
FX We would like to thank Arpan Jain for assisting us in the initial setup
   of cuML. This research is supported in part by NSF grants #1450440,
   #1565414, #1664137, #1818253, #1854828, #1931537, #2007991, and XRAC
   grant #NCR-130002.
NR 30
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
BN 978-1-6654-2291-8
PY 2020
BP 17
EP 28
DI 10.1109/MLHPCAI4S51975.2020.00010
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR8DS
UT WOS:000671059400003
DA 2022-04-17
ER

PT C
AU Dhrangadhariya, A
   Hilfiker, R
   Schaer, R
   Muller, H
AF Dhrangadhariya, Anjani
   Hilfiker, Roger
   Schaer, Roger
   Mueller, Henning
BE PapeHaugaard, LB
   Lovis, C
   Madsen, IC
   Weber, P
   Nielsen, PH
   Scott, P
TI Machine Learning Assisted Citation Screening for Systematic Reviews
SO DIGITAL PERSONALIZED HEALTH AND MEDICINE
SE Studies in Health Technology and Informatics
LA English
DT Proceedings Paper
CT 30th Medical Informatics Europe (MIE) Conference
CY APR, 2020
CL European Federat Med Informat, Geneva, SWITZERLAND
HO European Federat Med Informat
DE Systematic reviews; Automation; Natural language processing; Machine
   learning
AB Evidence-based practice is highly dependent upon up-to-date systematic reviews (SR) for decision making. However, conducting and updating systematic reviews, especially the citation screening for identification of relevant studies, requires much human work and is therefore expensive. Automating citation screening using machine learning (ML) based approaches can reduce cost and labor. Machine learning has been applied to automate citation screening but not for the SRs with very narrow research questions. This paper reports the results and observations for an ongoing research that aims to automate citation screening for SRs with narrow research questions using machine learning. The research also sheds light on the problem of class imbalance and class overlap on the performance of ML classifiers when applied to SRs with narrow research questions.
C1 [Dhrangadhariya, Anjani; Schaer, Roger; Mueller, Henning] Univ Appl Sci Western Switzerland HES SO, Technopole 3, CH-3960 Sierre, Switzerland.
   [Hilfiker, Roger] HES SO Valais Wallis, Sch Hlth Sci, Leukerbad, Switzerland.
   [Mueller, Henning] Univ Geneva UNIGE, Geneva, Switzerland.
RP Dhrangadhariya, A (corresponding author), Univ Appl Sci Western Switzerland HES SO, Technopole 3, CH-3960 Sierre, Switzerland.
EM anjani.dhrangadhariya@hevs.ch
NR 12
TC 1
Z9 1
U1 0
U2 0
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 0926-9630
EI 1879-8365
BN 978-1-64368-083-5; 978-1-64368-082-8
J9 STUD HEALTH TECHNOL
PY 2020
VL 270
BP 302
EP 306
DI 10.3233/SHTI200171
PG 5
WC Health Care Sciences & Services; Medical Informatics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Health Care Sciences & Services; Medical Informatics
GA BQ9KC
UT WOS:000625278800061
PM 32570395
DA 2022-04-17
ER

PT C
AU Negi, R
   Mathew, R
AF Negi, Richaa
   Mathew, Rejo
BE Pandian, AP
   Senjyu, T
   Islam, SMS
   Wang, H
TI Machine Learning Algorithms for Diagnosis of Breast Cancer
SO PROCEEDING OF THE INTERNATIONAL CONFERENCE ON COMPUTER NETWORKS, BIG
   DATA AND IOT (ICCBI-2018)
SE Lecture Notes on Data Engineering and Communications Technologies
LA English
DT Proceedings Paper
CT International Conference on Computer Networks, Big Data and IoT (ICCBI)
CY DEC 19-20, 2018
CL Madurai, INDIA
DE Machine learning; Classification; Breast cancer diagnosis; Support
   Vector Machine; K-nearest neighbors; Random Forest; Bayesian Networks
AB Machine learning is applied on systems for sequence and trend recognition, incomprehensible by humans or traditional programming, as they efficiently utilize the patterns for training the networks to overcome particular challenges. The prevalence of machine learning in medical sciences is devised to decrease the mortality rate of cancer patients owing to its detection at early stages. The objective of this review paper is to compare machine learning algorithms, to be precise, Support Vector Machine (SVM), Random Forest (RF), Bayesian Networks (BN) and k-Nearest Neighbor (kNN) so as to achieve precise detection and classification of breast cancer.
C1 [Negi, Richaa; Mathew, Rejo] NMIMS Deemed Univ, Dept IT, Mukesh Patel Sch Technol Management & Engn, Mumbai, Maharashtra, India.
RP Negi, R (corresponding author), NMIMS Deemed Univ, Dept IT, Mukesh Patel Sch Technol Management & Engn, Mumbai, Maharashtra, India.
EM richaanegi24@gmail.com; rejo.mathew@nmims.edu
OI Mathew, Rejo/0000-0002-0549-2695
NR 11
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2367-4512
BN 978-3-030-24643-3; 978-3-030-24642-6
J9 LECT NOTE DATA ENG
PY 2020
VL 31
BP 928
EP 932
DI 10.1007/978-3-030-24643-3_109
PG 5
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ3OA
UT WOS:000587291400109
DA 2022-04-17
ER

PT J
AU Kotsiopoulos, T
   Sarigiannidis, P
   Ioannidis, D
   Tzovaras, D
AF Kotsiopoulos, Thanasis
   Sarigiannidis, Panagiotis
   Ioannidis, Dimosthenis
   Tzovaras, Dimitrios
TI Machine Learning and Deep Learning in smart manufacturing: The Smart
   Grid paradigm
SO COMPUTER SCIENCE REVIEW
LA English
DT Review
DE Industry 4.0; Machine Learning; Deep Learning; Industrial AI; Smart Grid
ID ARTIFICIAL NEURAL-NETWORKS; RESTRICTED BOLTZMANN MACHINE; GENERALIZED
   ADDITIVE-MODELS; ELECTRICITY THEFT DETECTION; DECISION TREE CLASSIFIER;
   SUPPORT VECTOR MACHINES; RANDOM FOREST; MULTILAYER PERCEPTRON;
   LOGISTIC-REGRESSION; INDUSTRIAL INTERNET
AB Industry 4.0 is the new industrial revolution. By connecting every machine and activity through network sensors to the Internet, a huge amount of data is generated. Machine Learning (ML) and Deep Learning (DL) are two subsets of Artificial Intelligence (AI), which are used to evaluate the generated data and produce valuable information about the manufacturing enterprise, while introducing in parallel the Industrial AI (IAI). In this paper, the principles of the Industry 4.0 are highlighted, by giving emphasis to the features, requirements, and challenges behind Industry 4.0. In addition, a new architecture for AIA is presented. Furthermore, the most important ML and DL algorithms used in Industry 4.0 are presented and compiled in detail. Each algorithm is discussed and evaluated in terms of its features, its applications, and its efficiency. Then, we focus on one of the most important Industry 4.0 fields, namely the smart grid, where ML and DL models are presented and analyzed in terms of efficiency and effectiveness in smart grid applications. Lastly, trends and challenges in the field of data analysis in the context of the new Industrial era are highlighted and discussed such as scalability, cybersecurity, and big data. (C) 2020 Published by Elsevier Inc.
C1 [Kotsiopoulos, Thanasis; Sarigiannidis, Panagiotis] Univ Western Macedonia, Dept Elect & Comp Engn, Karamanli & Ligeris St, Kozani 50100, Greece.
   [Kotsiopoulos, Thanasis; Ioannidis, Dimosthenis; Tzovaras, Dimitrios] Ctr Res & Technol Hellas, Informat Technol Inst, Thermi 57001, Greece.
RP Sarigiannidis, P (corresponding author), Univ Western Macedonia, Dept Elect & Comp Engn, Karamanli & Ligeris St, Kozani 50100, Greece.
EM psarigiannidis@uowm.gr
RI Tzovaras, Dimitrios/ABB-9576-2021; Sarigiannidis, Panagiotis/O-5246-2017
OI Tzovaras, Dimitrios/0000-0001-6915-6722; Sarigiannidis,
   Panagiotis/0000-0001-6042-0355
FU European Union's Horizon 2020 research and innovation programme [787011]
FX This project has received funding from the European Union's Horizon 2020
   research and innovation programme under grant agreement No. 787011
   (SPEAR).
NR 237
TC 19
Z9 19
U1 19
U2 32
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1574-0137
EI 1876-7745
J9 COMPUT SCI REV
JI Comput. Sci. Rev.
PD MAY
PY 2021
VL 40
AR 100341
DI 10.1016/j.cosrev.2020.100341
EA FEB 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA SL2ZV
UT WOS:000656789000011
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Chugh, G
   Kumar, S
   Singh, N
AF Chugh, Gunjan
   Kumar, Shailender
   Singh, Nanhay
TI Survey on Machine Learning and Deep Learning Applications in Breast
   Cancer Diagnosis
SO COGNITIVE COMPUTATION
LA English
DT Article
DE Breast cancer; Machine learning; Deep learning; Convolution neural
   network (CNN); Computer-aided diagnosis (CAD)
ID CONVOLUTIONAL NEURAL-NETWORK; COMPUTER-AIDED DIAGNOSIS; MASS DETECTION;
   CLASSIFICATION; SEGMENTATION; MAMMOGRAMS; ULTRASOUND; HISTOLOGY;
   SHALLOW; SYSTEM
AB Cancer is a fatal disease caused due to the undesirable spread of cells. Breast carcinoma is the most invasive tumors and is the main reason for cancer deaths in females. Therefore, early diagnosis and prognosis have become necessary to increase survivability and reduce death rates in the long run. New artificial intelligence technologies are assisting radiologists in medical image scrutiny, thereby improving cancer patients' status. This survey enrolls peer-reviewed, newly developed computer-aided diagnosis (CAD) systems implementing machine learning (ML) and deep learning (DL) techniques for diagnosing breast carcinoma, compares them with previously established methods, and provides technical details with the pros and cons for each model. We also discuss some open issues, research gaps, and future research directions for the advanced CAD models in medical image analysis. Over the past decade, machine learning and deep learning have emerged as a subfield of artificial intelligence (AI), whose healthcare industry applications have provided excellent results with reduced cost and improved efficiency. This survey analyzes different classifiers of machine learning and deep learning approaches for breast cancer diagnosis. Results from previous studies proved that deep learning outperforms conventional machine learning for diagnosing breast carcinoma when the dataset is broad. Research gaps from the recent studies depict that practical and scientific research is an urgent necessity for improving healthcare in the long run.
C1 [Chugh, Gunjan; Kumar, Shailender] Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
   [Singh, Nanhay] Ambedkar Inst Adv Commun Technol & Res, Dept Comp Sci, Delhi, India.
RP Kumar, S (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
EM shailenderkumar@dce.ac.in
RI ; Kumar, Shailender/O-5116-2016
OI Singh, Prof.Nanhay/0000-0002-3303-1386; Kumar,
   Shailender/0000-0003-4244-2299
NR 93
TC 4
Z9 4
U1 16
U2 36
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1866-9956
EI 1866-9964
J9 COGN COMPUT
JI Cogn. Comput.
PD NOV
PY 2021
VL 13
IS 6
BP 1451
EP 1470
DI 10.1007/s12559-020-09813-6
EA JAN 2021
PG 20
WC Computer Science, Artificial Intelligence; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Neurosciences & Neurology
GA XN0XT
UT WOS:000613042000001
DA 2022-04-17
ER

PT J
AU Tegen, A
   Davidsson, P
   Persson, JA
AF Tegen, Agnes
   Davidsson, Paul
   Persson, Jan A.
TI Activity recognition through interactive machine learning in a dynamic
   sensor setting
SO PERSONAL AND UBIQUITOUS COMPUTING
LA English
DT Article; Early Access
DE Interactive machine learning; Activity recognition; Internet of things;
   Active learning; Machine learning
AB The advances in Internet of things lead to an increased number of devices generating and streaming data. These devices can be useful data sources for activity recognition by using machine learning. However, the set of available sensors may vary over time, e.g. due to mobility of the sensors and technical failures. Since the machine learning model uses the data streams from the sensors as input, it must be able to handle a varying number of input variables, i.e. that the feature space might change over time. Moreover, the labelled data necessary for the training is often costly to acquire. In active learning, the model is given a budget for requesting labels from an oracle, and aims to maximize accuracy by careful selection of what data instances to label. It is generally assumed that the role of the oracle only is to respond to queries and that it will always do so. In many real-world scenarios however, the oracle is a human user and the assumptions are simplifications that might not give a proper depiction of the setting. In this work we investigate different interactive machine learning strategies, out of which active learning is one, which explore the effects of an oracle that can be more proactive and factors that might influence a user to provide or withhold labels. We implement five interactive machine learning strategies as well as hybrid versions of them and evaluate them on two datasets. The results show that a more proactive user can improve the performance, especially when the user is influenced by the accuracy of earlier predictions. The experiments also highlight challenges related to evaluating performance when the set of classes is changing over time.
C1 [Tegen, Agnes; Davidsson, Paul; Persson, Jan A.] Malmo Univ, Internet Things & People Res Ctr, Malmo, Sweden.
RP Tegen, A (corresponding author), Malmo Univ, Internet Things & People Res Ctr, Malmo, Sweden.
EM agnes.tegen@mau.se; paul.davidsson@mau.se; jan.a.persson@mau.se
RI Davidsson, Paul/B-2969-2012
OI Davidsson, Paul/0000-0003-0998-6585
FU Knowledge Foundation through the Internet of Things and People grant
   [20140035]
FX This research was partially funded by the Knowledge Foundation through
   the Internet of Things and People grant number 20140035.
NR 36
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1617-4909
EI 1617-4917
J9 PERS UBIQUIT COMPUT
JI Pers. Ubiquitous Comput.
DI 10.1007/s00779-020-01414-2
EA JUN 2020
PG 14
WC Computer Science, Information Systems; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA LW2RD
UT WOS:000538990600002
OA hybrid
DA 2022-04-17
ER

PT J
AU Gundersen, OE
   Shamsaliei, S
   Isdahl, RJ
AF Gundersen, Odd Erik
   Shamsaliei, Saeid
   Isdahl, Richard Juul
TI Do machine learning platforms provide out-of-the-box reproducibility?
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
LA English
DT Article
DE Reproducibility; Reproducible AI; Machine learning; Survey;
   Reproducibility experiment
ID SOFTWARE
AB Science is experiencing an ongoing reproducibility crisis. In light of this crisis, our objective is to investigate whether machine learning platforms provide out-of-the-box reproducibility. Our method is twofold: First, we survey machine learning platforms for whether they provide features that simplify making experiments reproducible out-of-the-box. Second, we conduct the exact same experiment on four different machine learning platforms, and by this varying the processing unit and ancillary software only. The survey shows that no machine learning platform supports the feature set described by the proposed framework while the experiment reveals statstically significant difference in results when the exact same experiment is conducted on different machine learning platforms. The surveyed machine learning platforms do not on their own enable users to achieve the full reproducibility potential of their research. Also, the machine learning platforms with most users provide less functionality for achieving it. Furthermore, results differ when executing the same experiment on the different platforms. Wrong conclusions can be inferred at the at 95% confidence level. Hence, we conclude that machine learning platforms do not provide reproducibility out-of-the-box and that results generated from one machine learning platform alone cannot be fully trusted. (C) 2021 The Author(s). Published by Elsevier B.V.
C1 [Gundersen, Odd Erik; Shamsaliei, Saeid; Isdahl, Richard Juul] Norwegian Univ Sci & Technol, Dept Comp Sci, Trondheim, Norway.
RP Gundersen, OE (corresponding author), Norwegian Univ Sci & Technol, Dept Comp Sci, Trondheim, Norway.
EM odderik@ntnu.no
OI Gundersen, Odd Erik/0000-0002-9754-5941
NR 37
TC 0
Z9 0
U1 4
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-739X
EI 1872-7115
J9 FUTURE GENER COMP SY
JI Futur. Gener. Comp. Syst.
PD JAN
PY 2022
VL 126
BP 34
EP 47
DI 10.1016/j.future.2021.06.014
EA AUG 2021
PG 14
WC Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UY9IE
UT WOS:000701828000003
OA hybrid, Green Published
DA 2022-04-17
ER

PT J
AU Jiang, H
   Liu, YR
   Song, XF
   Wang, H
   Zheng, ZH
   Xu, QL
AF Jiang Han
   Liu Yiran
   Song Xiangfu
   Wang Hao
   Zheng Zhihua
   Xu Qiuliang
TI Cryptographic Approaches for Privacy-Preserving Machine Learning
SO JOURNAL OF ELECTRONICS & INFORMATION TECHNOLOGY
LA Chinese
DT Article
DE Privacy-Preserving Machine (PPM) learning; Secure MultiParty Computation
   (SMPC); Homomorphic Encryption (HE); Private Set Intersection (PSI)
AB The characteristics of the new generation of artificial intelligence technology are shown as follows: with the help of GPU computing, cloud computing and other high-performance distributed computing capabilities, machine learning algorithms represented by deep learning algorithms are used for learning and training on big data to simulate, extend and expand human intelligence. Different data sources and computing physical locations make the current machine learning face serious privacy leakage problem, so the Privacy Protection of Machine (PPM) Learning has become a widely concerned research area. Using cryptography technology to solve the problem of privacy in machine learning is an important technology to protect the privacy of machine learning. Cryptographic tools used in privacy-preserving machine learning are introduced, such as general Secure Multi-Party Computing (SMPC), privacy protection set operation and Homomorphic Encryption (HE), describes the status and developments applying the tools to solving the problems of privacy protection in various stages of machine learning, such as data processing, model training, model testing, and data prediction.
C1 [Jiang Han; Liu Yiran; Song Xiangfu; Xu Qiuliang] Shandong Univ, Sch Software, Jinan 250101, Peoples R China.
   [Wang Hao; Zheng Zhihua] Shandong Normal Univ, Sch Informat Sci & Technol, Jinan 250358, Peoples R China.
RP Xu, QL (corresponding author), Shandong Univ, Sch Software, Jinan 250101, Peoples R China.
EM xql@sdu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61632020, 61572294]; Natural Science
   Foundation of Shandong ProvinceNatural Science Foundation of Shandong
   Province [ZR2017MF021]; Major Innovation Project of Science and
   Technology of Shandong Province [2018CXGC0702]; Funds Project of
   National Independent Innovation Demonstration Zone in Shandong Peninsula
   [S190101010001]
FX The National Natural Science Foundation of China (61632020, 61572294);
   The Natural Science Foundation of Shandong Province (ZR2017MF021); The
   Major Innovation Project of Science and Technology of Shandong Province
   (2018CXGC0702); The Funds Project of National Independent Innovation
   Demonstration Zone in Shandong Peninsula (S190101010001)
NR 43
TC 1
Z9 3
U1 7
U2 18
PU CHINESE ACAD SCIENCES, INST ELECTRONICS
PI BEIJING
PA PO BOX 2702, BEIJING, 100190, PEOPLES R CHINA
SN 1009-5896
J9 J ELECTRON INF TECHN
JI J. Electron. Inf. Technol.
PD MAY
PY 2020
VL 42
IS 5
BP 1068
EP 1078
DI 10.11999/JEIT190887
PG 11
WC Engineering, Electrical & Electronic
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA LW6MY
UT WOS:000539259500003
DA 2022-04-17
ER

PT J
AU Dietrich, B
   Walther, J
   Chen, Y
   Weigold, M
AF Dietrich, B.
   Walther, J.
   Chen, Y.
   Weigold, M.
TI A DEEP LEARNING APPROACH TO ELECTRIC LOAD FORECASTING OF MACHINE TOOLS
SO MM SCIENCE JOURNAL
LA English
DT Article
DE Machine learning; Machine tool; Load forecasting
ID LEVEL
AB The ongoing climate change and increasingly strict climate goals of the European Union demand decisive action in all sectors. Especially in manufacturing industry, demand response measures have a high potential to balance the industrial electricity consumption with the increasingly volatile electricity supply from renewable sources. This work aims to develop a method to forecast the electrical energy demand of metal cutting machine tools as a necessary input for implementing demand response measures in factories. Building on the results of a previous study, long short-term memory networks (LSTM) and convolutional neural networks (CNN) are examined in their performance for forecasting the electric load of a machine tool for a 100 second time horizon. The results show that especially the combination of CNN and LSTM in a deep learning approach generates accurate and robust time series forecasts with reduced feature preparation effort. To further improve the forecasting accuracy, different network architectures including an attention mechanism for the LSTMs and different hyperparameter combinations are evaluated. The results are validated on real production data obtained in the ETA Research Factory.
C1 [Dietrich, B.; Walther, J.; Chen, Y.; Weigold, M.] Tech Univ Darmstadt, Inst Prod Management Technol & Machine Tools PTW, Otto Berndt Str 2, D-64287 Darmstadt, Germany.
RP Dietrich, B (corresponding author), Tech Univ Darmstadt, Inst Prod Management Technol & Machine Tools PTW, Otto Berndt Str 2, D-64287 Darmstadt, Germany.
EM b.dietrich@ptw.tu-darmstadt.de
NR 39
TC 0
Z9 0
U1 1
U2 1
PU MM SCIENCE
PI PRAGUE 10
PA PRIPOCNI 1519-10A, PRAGUE 10, 10100, CZECH REPUBLIC
SN 1803-1269
EI 1805-0476
J9 MM SCI J
JI MM Sci. J.
PD NOV
PY 2021
VL 2021
BP 5283
EP 5290
DI 10.17973/MMSJ.2021_11_2021146
PG 8
WC Engineering, Mechanical
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA WP4TO
UT WOS:000713126400047
OA gold
DA 2022-04-17
ER

PT C
AU Hossain, MS
   Iqbal, SM
   Zhou, Y
AF Hossain, Md Shakhawat
   Iqbal, Samir M.
   Zhou, Yong
GP IEEE
TI Microwave Glucose Concentration Classification by Machine Learning
SO PROCEEDINGS OF THE 2020 IEEE TEXAS SYMPOSIUM ON WIRELESS AND MICROWAVE
   CIRCUITS AND SYSTEMS (WMCS)
SE IEEE Texas Symposium on Wireless and Microwave Circuits and Systems WMCS
LA English
DT Proceedings Paper
CT IEEE Texas Symposium on Wireless and Microwave Circuits and Systems
   (WMCS)
CY MAY 26-28, 2020
CL ELECTR NETWORK
SP IEEE, Baylor Univ, Wireless & Microwave Circuits & Syst Lab, IEEE Microwave Theory & Tech Soc, IEEE Antennas & Propagat Soc, Baylor Univ, IEEE Baylor Student Chapter
DE Machine Learning; Support Vector Machine (SVM); S-parameters; Microwave
   Dielectric Measurement; Non-invasive Glucose Concentration Detection
AB This work aims to utilize machine learning algorithms to classify glucose concentration from the measured broadband microwave scattering signals (S-11). The sweeping frequency signals are first measured from glucose aqueous solution with various concentrations from pure water to 1000 mg/dL. Dielectric parameters are then extracted based on the modified Debye dielectric dispersion model and utilized as the features to create a larger dataset by adding Gaussian noises at various levels. Two separate datasets are created; one containing S-11 parameters and another containing Debye dielectric parameters. Several machine learning algorithms are used to classify glucose concentrations. Results indicate that the best algorithm can achieve perfect glucose concentration classification accuracy for the Debye dielectric parameter-based feature sets. The study suggests an alternative way to develop the non-invasive glucose detection method using machine learning.
C1 [Hossain, Md Shakhawat; Iqbal, Samir M.; Zhou, Yong] Univ Texas Rio Grande Valley, Dept Elect & Comp Engn, Edinburg, TX 78539 USA.
RP Hossain, MS (corresponding author), Univ Texas Rio Grande Valley, Dept Elect & Comp Engn, Edinburg, TX 78539 USA.
EM Mdshakhawat.hossain01@utrgv.edu; sm.iqbal@utrgv.edu; Yong.Zhou@utrgv.edu
NR 12
TC 0
Z9 0
U1 1
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2638-3845
BN 978-1-7281-6192-1
J9 IEEE TEXAS SYMP WIRE
PY 2020
PG 4
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Telecommunications
GA BQ8TT
UT WOS:000621642200024
DA 2022-04-17
ER

PT J
AU Vandermeeren, S
   Bruneel, H
   Steendam, H
AF Vandermeeren, Stef
   Bruneel, Herwig
   Steendam, Heidi
TI Feature Selection for Machine Learning Based Step Length Estimation
   Algorithms
SO SENSORS
LA English
DT Article
DE machine learning; feature selection; IMU
AB An accurate step length estimation can provide valuable information to different applications such as indoor positioning systems or it can be helpful when analyzing the gait of a user, which can then be used to detect various gait impairments that lead to a reduced step length (caused by e.g., Parkinson's disease or multiple sclerosis). In this paper, we focus on the estimation of the step length using machine learning techniques that could be used in an indoor positioning system. Previous step length algorithms tried to model the length of a step based on measurements from the accelerometer and some tuneable (user-specific) parameters. Machine-learning-based step length estimation algorithms eliminate these parameters to be tuned. Instead, to adapt these algorithms to different users, it suffices to provide examples of the length of multiple steps for different persons to the machine learning algorithm, so that in the training phase the algorithm can learn to predict the step length for different users. Until now, these machine learning algorithms were trained with features that were chosen intuitively. In this paper, we consider a systematic feature selection algorithm to be able to determine the features from a large collection of features, resulting in the best performance. This resulted in a step length estimator with a mean absolute error of 3.48 cm for a known test person and 4.19 cm for an unknown test person, while current state-of-the-art machine-learning-based step length estimators resulted in a mean absolute error of 4.94 cm and 6.27 cm for respectively a known and unknown test person.
C1 [Vandermeeren, Stef; Bruneel, Herwig; Steendam, Heidi] Univ Ghent, Dept Telecommun & Informat Proc IMEC, B-9000 Ghent, Belgium.
RP Vandermeeren, S (corresponding author), Univ Ghent, Dept Telecommun & Informat Proc IMEC, B-9000 Ghent, Belgium.
EM stef.vandermeeren@ugent.be; herwig.bruneel@ugent.be;
   Heidi.Steendam@UGent.be
FU Belgian Research Council FWO [30452698]; Belgian Research Council
   FNRSFonds de la Recherche Scientifique - FNRS [30452698]
FX This research was funded by the EOS grant 30452698 from the Belgian
   Research Councils FWO and FNRS.
NR 16
TC 4
Z9 5
U1 6
U2 12
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD FEB
PY 2020
VL 20
IS 3
AR 778
DI 10.3390/s20030778
PG 17
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Instruments & Instrumentation
GA KR7HH
UT WOS:000517786200202
PM 32023938
OA Green Published, Green Submitted, gold
DA 2022-04-17
ER

PT J
AU Wang, HB
   Yao, YJ
   Liu, X
   Tu, XY
AF Wang, Hongbo
   Yao, Yuejuan
   Liu, Xi
   Tu, Xuyan
TI Scalable Real-Time Attributes Responsive Extreme Learning Machine
SO INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS
LA English
DT Article
DE Extreme learning machine; Attributes scalable; Cropping strategy
ID RECOGNITION
AB Extreme learning machine (ELM) has recently attracted many researchers interest due to its very fast learning speed, and ease of implementation. Its many applications, such as regression, binary and multiclass classification, acquired better results. However, When some attributes of the dataset have been lost, this fixed network structure will be less than satisfactory. This article suggests a Scalable Real-Time Attributes Responsive Extreme Learning Machine (Star-ELM), is such can grow its appropriate structure with nodes autonomous coevolution based on the different dataset. Its hidden nodes can be merged to more effectively adjust structure and. Weight In the experiments of classical data sets we compare with other relevant variants of ELM, Star-ELM makes better performance on classification learning with loss of dataset attributes in some situations. (C) 2020 The Authors. Published by Atlatatis Press B.V.
C1 [Wang, Hongbo; Yao, Yuejuan; Liu, Xi; Tu, Xuyan] Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Beijing Key Lab Knowledge Engn Mat Sci, Xueyuan Rd 30, Beijing 100083, Peoples R China.
RP Wang, HB (corresponding author), Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Beijing Key Lab Knowledge Engn Mat Sci, Xueyuan Rd 30, Beijing 100083, Peoples R China.
EM foreverwhb@126.com
FU National Natural Science Foundation of China (NSFC)National Natural
   Science Foundation of China (NSFC) [61572074]
FX This work is supported by National Natural Science Foundation of China
   (NSFC) under Grant NO.61572074.
NR 21
TC 0
Z9 0
U1 1
U2 2
PU ATLANTIS PRESS
PI PARIS
PA 29 AVENUE LAUMIERE, PARIS, 75019, FRANCE
SN 1875-6891
EI 1875-6883
J9 INT J COMPUT INT SYS
JI Int. J. Comput. Intell. Syst.
PY 2020
VL 13
IS 1
BP 1101
EP 1107
DI 10.2991/ijcis.d.200731.001
PG 7
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NI7MJ
UT WOS:000565532900055
OA gold
DA 2022-04-17
ER

PT C
AU Dobrea, M
   Badicu, A
   Barbu, M
   Subea, O
   Balanescu, M
   Suciu, G
   Birdici, A
   Orza, O
   Dobre, C
AF Dobrea, Marius
   Badicu, Andreea
   Barbu, Marina
   Subea, Oana
   Balanescu, Mihaela
   Suciu, Geroge
   Birdici, Andrei
   Orza, Oana
   Dobre, Ciprian
GP IEEE
TI Machine Learning algorithms for air pollutants forecasting
SO 2020 IEEE 26TH INTERNATIONAL SYMPOSIUM FOR DESIGN AND TECHNOLOGY IN
   ELECTRONIC PACKAGING (SIITME 2020)
SE International Symposium for Design and Technology in Electronic
   Packaging
LA English
DT Proceedings Paper
CT IEEE 26th International Symposium for Design and Technology in
   Electronic Packaging (SIITME)
CY OCT 21-24, 2020
CL Pitesti, ROMANIA
SP IEEE, APTE, IEEE Elect Packaging Soc, TUV Profi Cert, Univ Pitesti, Politehnica Univ Bucharest
DE Machine Learning; Air Pollution; Forecasting; Time Series
AB Air pollution represents an issue that raises many concerns nowadays, as it has various negative effects on the environment and the economy worldwide. Because of the rapid urbanization, cities are suffering from polluted air, so it is important to predict future air quality. For this purpose, new applications of artificial intelligence should be employed. In this paper, we will present several Machine Learning algorithms, the possible software that can be used for them and the applications used in the field of air quality. Based on the research in the field, we propose SVR, ARIMA and LSTM, 3 Machine Learning models, which can be used to predict air pollution. These algorithms have been tested using time-series for PM10 and PM2.5 particles. The results showed that SVR and ARIMA algorithms are the most suitable in forecasting air pollutant concentrations.
C1 [Dobrea, Marius; Badicu, Andreea; Barbu, Marina; Subea, Oana; Balanescu, Mihaela; Suciu, Geroge; Birdici, Andrei; Orza, Oana] BEIA Consult Int, Res & Dev Dept, Bucharest, Romania.
   [Dobre, Ciprian] Univ POLITEHNICA, Dept Comp, Bucharest, Romania.
RP Dobrea, M (corresponding author), BEIA Consult Int, Res & Dev Dept, Bucharest, Romania.
RI Balanescu, Mihaela/ABB-7213-2021
OI Balanescu, Mihaela/0000-0003-4479-8459
FU Tel-MONAER project [1223/22.01.2018, P 40270, 105976]; FarmSustainaBL
   project (ERANET-ERAGAS-ICT-AGRI3 program) [119/2019]; WINS@HI project
   [PN-III-P3-3.5-EUK-2017-02-0038]
FX We would like to express our gratitude to Tel-MONAER project (subsidiary
   contract no. 1223/22.01.2018, from NETIO Project ID: P 40270, MySMIS
   CODE: 105976), FarmSustainaBL project (contract no. 119/2019, from
   ERANET-ERAGAS-ICT-AGRI3 program) and WINS@HI project
   (PN-III-P3-3.5-EUK-2017-02-0038) for the work presented in this paper.
NR 14
TC 1
Z9 1
U1 12
U2 20
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2641-287X
BN 978-1-7281-7506-5
J9 INT SYM DES TECH ELE
PY 2020
BP 109
EP 113
PG 5
WC Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering
GA BR4DG
UT WOS:000651085100021
DA 2022-04-17
ER

PT J
AU Sankhye, S
   Hu, GP
AF Sankhye, Sidharth
   Hu, Guiping
TI Machine Learning Methods for Quality Prediction in Production
SO LOGISTICS-BASEL
LA English
DT Article
DE machine learning; quality; classification
ID NEURAL-NETWORK; CLASSIFICATION; PERFORMANCE
AB The rising popularity of smart factories and Industry 4.0 has made it possible to collect large amounts of data from production stages. Thus, supervised machine learning methods such as classification can viably predict product compliance quality using manufacturing data collected during production. Elimination of uncertainty via accurate prediction provides significant benefits at any stage in a supply chain. Thus, early knowledge of product batch quality can save costs associated with recalls, packaging, and transportation. While there has been thorough research on predicting the quality of specific manufacturing processes, the adoption of classification methods to predict the overall compliance of production batches has not been extensively investigated. This paper aims to design machine learning based classification methods for quality compliance and validate the models via case study of a multi-model appliance production line. The proposed classification model could achieve an accuracy of 0.99 and Cohen's Kappa of 0.91 for the compliance quality of unit batches. Thus, the proposed method would enable implementation of a predictive model for compliance quality. The case study also highlights the importance of feature construction and dataset knowledge in training classification models.
C1 [Sankhye, Sidharth; Hu, Guiping] Iowa State Univ, Dept Ind & Mfg Syst Engn, Ames, IA 50011 USA.
RP Hu, GP (corresponding author), Iowa State Univ, Dept Ind & Mfg Syst Engn, Ames, IA 50011 USA.
EM ssankhye@iastate.edu; gphu@iastate.edu
OI Hu, Guiping/0000-0001-8392-8442
NR 41
TC 3
Z9 3
U1 8
U2 13
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2305-6290
J9 LOGISTICS-BASEL
JI Logistics
PD DEC
PY 2020
VL 4
IS 4
AR 35
DI 10.3390/logistics4040035
PG 19
WC Management; Operations Research & Management Science
WE Emerging Sources Citation Index (ESCI)
SC Business & Economics; Operations Research & Management Science
GA TI2QC
UT WOS:000672637100013
OA gold, Green Published
DA 2022-04-17
ER

PT J
AU Khosravikia, F
   Clayton, P
AF Khosravikia, Farid
   Clayton, Patricia
TI Machine learning in ground motion prediction
SO COMPUTERS & GEOSCIENCES
LA English
DT Article
DE Ground motion prediction; Machine learning; Artificial neural network;
   Random forest; Support vector machine
ID NEURAL-NETWORK APPROACH; INDUCED EARTHQUAKES; MODELS; PGA; ATTENUATION;
   ACCELERATION; NGA-WEST2; VARIABILITY; ALGORITHM; EQUATIONS
AB This paper studies the advantages and disadvantages of different machine learning techniques in predicting ground-motion intensity measures given source characteristics, source-to-site distance, and local site conditions. Typically, linear regression-based models with predefined equations and coefficients are used in ground motion prediction. However, restrictions of the linear regression models may limit their capabilities in extracting complex nonlinear behaviors in the data. Therefore, the present paper comparatively investigates potential benefits from employing other machine learning techniques as statistical method in ground motion prediction such as Artificial Neural Network, Random Forest, and Support Vector Machine. This study quantifies event-toevent and site-to-site variability of the ground motions by implementing them as random effect terms to reduce the aleatory uncertainty. All the algorithms are trained using a selected database of 4528 ground-motions, including 376 seismic events with magnitude 3 to 5.8, recorded over the hypocentral distance range of 4-500 km in Oklahoma, Kansas, and Texas since 2005. The results indicate the algorithms satisfy some physically sound characteristics such as magnitude scaling distance dependency without requiring predefined equations or coefficients. Moreover, it is found that, when sufficient data is available, all the alternative algorithms tend to provide more accurate estimates compared to the conventional linear regression-based method, and particularly, Random Forest outperforms the other algorithms. However, the conventional method is a better tool when limited data is available.
C1 [Khosravikia, Farid; Clayton, Patricia] Univ Texas Austin, Dept Civil Architectural & Environm Engn, Austin, TX 78712 USA.
RP Khosravikia, F (corresponding author), Univ Texas Austin, Dept Civil Architectural & Environm Engn, Austin, TX 78712 USA.
EM farid.khosravikia@utexas.edu; clayton@utexas.edu
FU Texas Department of Transportation (TxDOT) [0-6916-1, 5-6916-1]; State
   of Texas through the TexNet Seismic Monitoring Project; Industrial
   Associates of the Center for Integrated Seismic Research (CISR) at the
   Bureau of Economic Geology of The University of Texas
FX The research presented in this article was financially supported by the
   Texas Department of Transportation (TxDOT) with Grant Numbers of
   0-6916-1 and 5-6916-1, the State of Texas through the TexNet Seismic
   Monitoring Project, and the Industrial Associates of the Center for
   Integrated Seismic Research (CISR) at the Bureau of Economic Geology of
   The University of Texas. The presented findings, opinions, and
   recommendations are those of the authors and do not necessarily reflect
   the views of the sponsors.
NR 67
TC 4
Z9 4
U1 4
U2 7
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0098-3004
EI 1873-7803
J9 COMPUT GEOSCI-UK
JI Comput. Geosci.
PD MAR
PY 2021
VL 148
AR 104700
DI 10.1016/j.cageo.2021.104700
EA JAN 2021
PG 11
WC Computer Science, Interdisciplinary Applications; Geosciences,
   Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Geology
GA QP5WW
UT WOS:000623908100002
DA 2022-04-17
ER

PT C
AU Varghese, NV
   Azim, A
   Mahmoud, QH
AF Varghese, Nelson Vithayathil
   Azim, Akramul
   Mahmoud, Qusay H.
GP IEEE
TI A Feature-Based Machine Learning Approach for Mixed-Criticality Systems
SO 2021 22ND IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT)
SE IEEE International Conference on Industrial Technology
LA English
DT Proceedings Paper
CT 22nd IEEE International Conference on Industrial Technology (ICIT)
CY MAR 10-12, 2021
CL ELECTR NETWORK
SP Inst Elect & Elect Engineers, IEEE Ind Elect Soc
DE Machine Learning; Deep Learning; Cyber-Physical Systems; Safety-Critical
   Systems; Partitioning
AB Driven by the recent technological advancements in the field of artificial intelligence, machine learning has emerged as a promising representation learning and decision-making method in many technological domains. Inspired by impressive these results, now machine learning techniques are also being applied to address the decision-making and control problems in the area of cyber-physical systems. For instance, some of these systems fall under the category of safety-critical systems such as chemical plants, autonomous vehicles, surgical robots, and modern medical equipment. One of the major performance issues related to the applicability of machine learning with safety-critical systems is related to the probability-based prediction nature of machine learning components used within such systems. This particular characteristic of machine learning makes it extremely difficult to guarantee safety as directed by standards such as ISO 26262. More importantly, the non-transparent and complex nature of machine learning algorithms make both the reasoning as well as formally establishing the safety aspects of the underlying system extremely difficult. The objective of this research work is to investigate on this key issue, and further on propose an efficient machine learning methodology based on the mixed-criticality approach feasible to safety-critical systems.
C1 [Varghese, Nelson Vithayathil; Azim, Akramul; Mahmoud, Qusay H.] Ontario Tech Univ, Dept Elect Comp & Software Engn, Oshawa, ON, Canada.
RP Varghese, NV (corresponding author), Ontario Tech Univ, Dept Elect Comp & Software Engn, Oshawa, ON, Canada.
EM nelson.vithayathilvarghese@ontariotechu.ca;
   akramul.azim@ontariotecthu.ca; qusay.mahmoud@ontariotechu.ca
FU Natural Sciences and Engineering Research Council of Canada (NSERC)
   GrantNatural Sciences and Engineering Research Council of Canada (NSERC)
FX This work was supported in part by a Natural Sciences and Engineering
   Research Council of Canada (NSERC) Grant.
NR 10
TC 0
Z9 0
U1 3
U2 3
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2643-2978
BN 978-1-7281-5730-6
J9 IEEE INT CONF INDUST
PY 2021
BP 699
EP 704
DI 10.1109/ICIT46573.2021.9453482
PG 6
WC Engineering, Industrial; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering
GA BS1DQ
UT WOS:000687856000108
DA 2022-04-17
ER

PT C
AU Tun, TP
   Pillai, G
AF Tun, Thet Paing
   Pillai, Gobind
GP IEEE
TI Power Quality Event Classification in Distribution Grids Using Machine
   Learning
SO 2021 56TH INTERNATIONAL UNIVERSITIES POWER ENGINEERING CONFERENCE (UPEC
   2021): POWERING NET ZERO EMISSIONS
LA English
DT Proceedings Paper
CT 56th International Universities Power Engineering Conference (UPEC) -
   Powering Net Zero Emissions
CY AUG 31-SEP 03, 2021
CL Teesside Univ, ELECTR NETWORK
SP IEEE, IEEE United Kingdom & Ireland Sect, IEEE Power & Energy Soc, Inst Engn & Technol, Lucas Nulle, MDPI, Elect Journal, MDPI, Energies Journal
HO Teesside Univ
DE power quality; machine learning; wavelet transform; classification
AB With the penetration of non-linear loads, renewables and distributed generation with power electronic converters, solutions for maintaining good power quality have become a major concern for the stakeholders of electrical power systems. In this paper, a machine learning based model for power quality event classification is developed and tested. 16 categories of the most commonly occurring power quality events are classified by means of wavelet transform and select machine learning based methods to evaluate the best performing machine learning model. The outcome of classifications and effectiveness of machine learning methods is evaluated using the 'Classification Learners' application in MATLAB. The selected machine learning model is implemented in Simulink for test distribution grid circuits. The results obtained from simulation showed acceptable accuracy and performance and demonstrated the efficiency of the model in different operating conditions.
C1 [Tun, Thet Paing; Pillai, Gobind] Teesside Univ, Sch Comp Engn & Digital Technol, Middlesbrough, Cleveland, England.
RP Tun, TP (corresponding author), Teesside Univ, Sch Comp Engn & Digital Technol, Middlesbrough, Cleveland, England.
EM W9057615@tees.ac.uk; g.g.pillai@tees.ac.uk
NR 15
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-6654-4389-0
PY 2021
DI 10.1109/UPEC50034.2021.9548222
PG 6
WC Energy & Fuels; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Energy & Fuels; Engineering
GA BS4WL
UT WOS:000723608400072
OA Green Published
DA 2022-04-17
ER

PT J
AU Matus, KJM
   Veale, M
AF Matus, Kira J. M.
   Veale, Michael
TI Certification systems for machine learning: Lessons from sustainability
SO REGULATION & GOVERNANCE
LA English
DT Article
DE artificial intelligence; certification system; governance; machine
   learning; sustainability certification
ID DECENTRALIZED INSTITUTIONS; ENVIRONMENTAL GOVERNANCE; STANDARDS;
   PROGRAMS; DESIGN; MARKET; ROLES; BIG
AB Concerns around machine learning's societal impacts have led to proposals to certify some systems. While prominent governance efforts to date center around networking standards bodies such as the Institute of Electrical and Electronics Engineers (IEEE), we argue that machine learning certification should build on structures from the sustainability domain. Policy challenges of machine learning and sustainability share significant structural similarities, including difficult to observe credence properties, such as data collection characteristics or carbon emissions from model training, and value chain concerns, including core-periphery inequalities, networks of labor, and fragmented and modular value creation. While networking-style standards typically draw their adoption and enforcement from functional needs to conform to enable network participation, machine learning, despite its digital nature, does not benefit from this dynamic. We therefore apply research on certification systems in sustainability, particularly of commodities, to generate lessons across both areas, informing emerging proposals such as the EU's AI Act.
C1 [Matus, Kira J. M.] Hong Kong Univ Sci & Technol, Div Publ Policy, Hong Kong, Peoples R China.
   [Veale, Michael] UCL, Fac Laws, London, England.
RP Veale, M (corresponding author), UCL, London, England.
EM m.veale@ucl.ac.uk
RI Matus, Kira/AAL-6456-2021
OI Matus, Kira/0000-0001-8477-0691; Veale, Michael/0000-0002-2342-8785
NR 108
TC 1
Z9 1
U1 12
U2 16
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1748-5983
EI 1748-5991
J9 REGUL GOV
JI Regul. Gov.
PD JAN
PY 2022
VL 16
IS 1
BP 177
EP 196
DI 10.1111/rego.12417
EA JUN 2021
PG 20
WC Law; Political Science; Public Administration
WE Social Science Citation Index (SSCI)
SC Government & Law; Public Administration
GA YJ6OY
UT WOS:000659260600001
OA hybrid, Green Published
DA 2022-04-17
ER

PT J
AU Amezquita-Sanchez, JP
   Valtierra-Rodriguez, M
   Adeli, H
AF Amezquita-Sanchez, J. P.
   Valtierra-Rodriguez, M.
   Adeli, H.
TI Machine learning in structural engineering
SO SCIENTIA IRANICA
LA English
DT Review
DE Civil structures; Machine learning; Deep learning; Structural
   engineering; System identification; Structural health monitoring;
   Vibration control; Structural design; Prediction
ID NEURAL DYNAMIC CLASSIFICATION; VIBRATION CONTROL; DAMAGE DETECTION;
   NETWORK MODEL; PREDICTION; IDENTIFICATION; METHODOLOGY; CONTROLLER
AB This article presents a review of selected articles about structural engineering applications of Machine Learning (ML) in the past few years. It is divided into the following areas: structural system identification, structural health monitoring, structural vibration control, structural design, and prediction applications. Deep neural network algorithms have been the subject of a large number of articles in civil and structural engineering. There are, however, other ML algorithms with great potential in civil and structural engineering that are worth exploring. Four novel supervised ML algorithms developed recently by the senior author and his associates with potential applications in civil/structural engineering are reviewed in this paper. They are the Enhanced Probabilistic Neural Network (EPNN), the Neural Dynamic Classification (NDC) algorithm, the Finite Element Machine (FEMa), and the Dynamic Ensemble Learning (DEL) algorithm. (C) 2020 Sharif University of Technology. All rights reserved.
C1 [Amezquita-Sanchez, J. P.; Valtierra-Rodriguez, M.] Autonomous Univ Queretaro, Fac Engn, CA Sistemas Dinam, ENAP RG,Dept Electromech, Campus San Juan Del Rio,Moctezuma 249, San Juan Del Rio 76807, Queretaro, Mexico.
   [Amezquita-Sanchez, J. P.; Valtierra-Rodriguez, M.] Autonomous Univ Queretaro, Fac Engn, CA Sistemas Dinam, ENAP RG,Dept Biomed Engn, Campus San Juan Del Rio,Moctezuma 249, San Juan Del Rio 76807, Queretaro, Mexico.
   [Adeli, H.] Ohio State Univ, Dept Civil Environm & Geodet Engn, 470 Hitchcock Hall,2070 Neil Avenude, Columbus, OH 43220 USA.
RP Amezquita-Sanchez, JP (corresponding author), Autonomous Univ Queretaro, Fac Engn, CA Sistemas Dinam, ENAP RG,Dept Electromech, Campus San Juan Del Rio,Moctezuma 249, San Juan Del Rio 76807, Queretaro, Mexico.; Amezquita-Sanchez, JP (corresponding author), Autonomous Univ Queretaro, Fac Engn, CA Sistemas Dinam, ENAP RG,Dept Biomed Engn, Campus San Juan Del Rio,Moctezuma 249, San Juan Del Rio 76807, Queretaro, Mexico.
EM jamezquita@uaq.mx
RI adeli, hojjat/D-1430-2010
OI adeli, hojjat/0000-0001-5718-1453
NR 103
TC 1
Z9 1
U1 29
U2 65
PU SHARIF UNIV TECHNOLOGY
PI TEHRAN
PA PO BOX 11155-8639, TEHRAN, 00000, IRAN
SN 1026-3098
J9 SCI IRAN
JI Sci. Iran.
PD NOV-DEC
PY 2020
VL 27
IS 6
BP 2645
EP 2656
DI 10.24200/sci.2020.22091
PG 12
WC Engineering, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA PT1FB
UT WOS:000608364000006
DA 2022-04-17
ER

PT J
AU Lee, CS
   Tsai, YL
   Wang, MH
   Huang, SH
   Reformat, M
   Kubota, N
AF Lee, Chang-Shing
   Tsai, Yi-Lin
   Wang, Mei-Hui
   Huang, Sheng-Hui
   Reformat, Marek
   Kubota, Naoyuki
TI Adaptive Fuzzy Neural Agent for Human and Machine Co-learning
SO INTERNATIONAL JOURNAL OF FUZZY SYSTEMS
LA English
DT Article; Early Access
DE Fuzzy Markup Language; Agent; Fuzzy Machine Learning; Robot; Patch
   learning
ID EXPLAINABLE ARTIFICIAL-INTELLIGENCE; SYSTEM; GAME; ANFIS; GO
AB This paper proposes an Adaptive Fuzzy Neural Agent (AFNA) with a Patch Learning Mechanism and IEEE 1855 Fuzzy Markup Language (FML) for human and machine co-learning. There are three phases of patch learning mechanism embedded in AFNA, including (1) training an initial global model, (2) training a patch model for each identified patch, and (3) updating the global model using the training data that do not fall into any patch. The AFNA can be applied to construct the student and robot co-learning regression model, as well as the regression model for the dataset retrieved from the game of Go. First, students generate human learning data through interactions with handheld devices or robots based on the AFNA in Taiwan and Japan. Then, the AFNA utilizes the student learning data collected in the classroom and the Go game data provided by both Google DeepMind and Facebook AI Research open-source OpenGo to train the Fuzzy Machine-Learning Model. In addition, the trained Fuzzy Machine-Learning Model of AFNA is deployed to the robots to make students and machines co-learn together based on IEEE 1855 FML. The experiments show that the AFNA with Patch Learning Mechanism and Fuzzy Machine-Learning Model can improve the performance of regression model based on the datasets of student learning and Go game. In the future, we hope to apply the AFNA with robots to the other domain areas, embed it with the Artificial Intelligence of Things devices, and introduce it to more teaching fields in various countries.
C1 [Lee, Chang-Shing; Tsai, Yi-Lin; Wang, Mei-Hui; Huang, Sheng-Hui] Natl Univ Tainan, Dept Comp Sci & Informat Engn, Tainan, Taiwan.
   [Reformat, Marek] Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB, Canada.
   [Kubota, Naoyuki] Tokyo Metropolitan Univ, Dept Mech Syst Engn, Tokyo, Japan.
RP Lee, CS (corresponding author), Natl Univ Tainan, Dept Comp Sci & Informat Engn, Tainan, Taiwan.
EM leecs@mail.nutn.edu.tw
FU Ministry of Science and Technology (MOST) of TaiwanMinistry of Science
   and Technology, Taiwan [MOST 109-2622-E-024-001-CC1, MOST
   108-2218-E-024-001]
FX The authors would like to thank the financial support sponsored by the
   Ministry of Science and Technology (MOST) of Taiwan under the grant MOST
   109-2622-E-024-001-CC1 and MOST 108-2218-E-024-001. The authors would
   like to thank the staff of the KWS Center and OASE Lab. of NUTN as well
   as the involved faculty and students of Gueinan elementary school and
   Rende elementary school in Taiwan. Finally, the authors would like to
   thank Rinpin Chang for editing the videos adopted in this paper.
NR 35
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1562-2479
EI 2199-3211
J9 INT J FUZZY SYST
JI Int. J. Fuzzy Syst.
DI 10.1007/s40815-021-01188-6
EA NOV 2021
PG 21
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Computer Science, Information Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA XA7IV
UT WOS:000720816400009
DA 2022-04-17
ER

PT C
AU Shao, RT
   Delp, EJ
AF Shao, Ruiting
   Delp, Edward J.
GP IEEE
TI Forensic Scanner Identification Using Machine Learning
SO 2020 IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION
   (SSIAI 2020)
SE IEEE Southwest Symposium on Image Analysis and Interpretation
LA English
DT Proceedings Paper
CT IEEE Southwest Symposium on Image Analysis and Interpretation (SSIAI)
CY MAR 29-31, 2020
CL ELECTR NETWORK
SP Inst Elect & Elect Engineers, IEEE Comp Soc
DE scanner classification; machine learning; media forensics; convolutional
   neural network
ID CAMERA IDENTIFICATION
AB Due to the increasing availability and functionality of image editing tools, many forensic techniques such as digital image authentication, source identification and tamper detection are important for forensic image analysis. In this paper, we describe a machine learning based system to address the forensic analysis of scanner devices. The proposed system uses deep-learning to automatically learn the intrinsic features from various scanned images. Our experimental results show that high accuracy can he achieved for source scanner identification. The proposed system can also generate a reliability map that indicates the manipulated regions in an scanned image.
C1 [Shao, Ruiting; Delp, Edward J.] Purdue Univ, Sch Elect & Comp Engn, Video & Image Proc Lab VIPER, W Lafayette, IN 47907 USA.
RP Shao, RT (corresponding author), Purdue Univ, Sch Elect & Comp Engn, Video & Image Proc Lab VIPER, W Lafayette, IN 47907 USA.
OI Delp, Edward/0000-0002-2909-7323
FU Defense Advanced Research Projects Agency (DARPA)United States
   Department of DefenseDefense Advanced Research Projects Agency (DARPA);
   Air Force Research Laboratory (AFRL)United States Department of
   DefenseUS Air Force Research Laboratory [FA8750-16-2-0173]
FX This material is based on research sponsored by the Defense Advanced
   Research Projects Agency (DARPA) and the Air Force Research Laboratory
   (AFRL) under agreement number FA8750-16-2-0173. The U.S. Government is
   authorized to reproduce and distribute reprints for Governmental
   purposes notwithstanding any copyright notation thereon. The views and
   conclusions contained herein are those of the authors and should not be
   interpreted as necessarily representing the official policies or
   endorsements, either expressed or implied, of DARPA, AURI, or the U.S.
   Government. Address all comments to Edward J. Delp, ace@)ecn.purdue.edu.
NR 20
TC 7
Z9 7
U1 0
U2 3
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1550-5782
BN 978-1-7281-5745-0
J9 IEEE SW SYMP IMAG
PY 2020
BP 1
EP 4
PG 4
WC Computer Science, Artificial Intelligence; Imaging Science &
   Photographic Technology
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Imaging Science & Photographic Technology
GA BQ3RL
UT WOS:000587759600001
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Nishizaki, Y
   Horisaki, R
   Kitaguchi, K
   Saito, M
   Tanida, J
AF Nishizaki, Yohei
   Horisaki, Ryoichi
   Kitaguchi, Katsuhisa
   Saito, Mamoru
   Tanida, Jun
TI Analysis of non-iterative phase retrieval based on machine learning
SO OPTICAL REVIEW
LA English
DT Article
DE Phase retrieval; Machine learning; Deep learning; Convolutional neural
   network; Inverse problem
ID DIGITAL HOLOGRAPHY; RECONSTRUCTION; MICROSCOPY; ALGORITHMS
AB In this paper, we analyze a machine-learning-based non-iterative phase retrieval method. Phase retrieval and its applications have been attractive research topics in optics and photonics, for example, in biomedical imaging, astronomical imaging, and so on. Most conventional phase retrieval methods have used iterative processes to recover phase information; however, the calculation speed and convergence with these methods are serious issues in real-time monitoring applications. Machine-learning-based methods are promising for addressing these issues. Here, we numerically compare conventional methods and a machine-learning-based method in which a convolutional neural network is employed. Simulations with several conditions show that the machine-learning-based method realizes fast and robust phase recovery compared with the conventional methods. We also numerically demonstrate machine-learning-based phase retrieval from noisy measurements with a noisy training data set for improving the noise robustness. The machine-learning-based approach used in this study may increase the impact of phase retrieval, which is useful in various fields, where phase retrieval has been used as a fundamental tool.
C1 [Nishizaki, Yohei; Horisaki, Ryoichi; Tanida, Jun] Osaka Univ, Grad Sch Informat Sci & Technol, Dept Informat & Phys Sci, 1-5 Yamadaoka, Suita, Osaka 5650871, Japan.
   [Nishizaki, Yohei; Kitaguchi, Katsuhisa; Saito, Mamoru] Osaka Res Inst Ind Sci & Technol, Environm Technol Res Div, Syst & Control Lab, Joto Ku, 1-6-50 Morinomiya, Osaka 5368553, Japan.
   [Horisaki, Ryoichi] JST, PRESTO, 4-1-8 Honcho, Kawaguchi, Saitama 3320012, Japan.
RP Horisaki, R (corresponding author), Osaka Univ, Grad Sch Informat Sci & Technol, Dept Informat & Phys Sci, 1-5 Yamadaoka, Suita, Osaka 5650871, Japan.; Horisaki, R (corresponding author), JST, PRESTO, 4-1-8 Honcho, Kawaguchi, Saitama 3320012, Japan.
EM r.horisaki@ist.osaka-u.ac.jp
OI Horisaki, Ryoichi/0000-0002-2280-5921
FU JSPS KAKENHIMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) [JP17H02799,
   JP17K00233]; JST PRESTOJapan Science & Technology Agency (JST)
   [JPMJPR17PB]
FX This work was supported by JSPS KAKENHI Grant Numbers JP17H02799 and
   JP17K00233, JST PRESTO Grant Number JPMJPR17PB.
NR 45
TC 14
Z9 14
U1 9
U2 22
PU OPTICAL SOC JAPAN
PI TOKYO
PA KUDAN-KITA BLDG 5F, 1-12-3, KUDAN-KITA CHIYODA-KU, TOKYO, 102, JAPAN
SN 1340-6000
EI 1349-9432
J9 OPT REV
JI Opt. Rev.
PD FEB
PY 2020
VL 27
IS 1
BP 136
EP 141
DI 10.1007/s10043-019-00574-8
PG 6
WC Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Optics
GA KT7PV
UT WOS:000519206300017
OA hybrid
DA 2022-04-17
ER

PT J
AU Asha, S
   Vinod, P
AF Asha, S.
   Vinod, P.
TI Evaluation of adversarial machine learning tools for securing AI systems
SO CLUSTER COMPUTING-THE JOURNAL OF NETWORKS SOFTWARE TOOLS AND
   APPLICATIONS
LA English
DT Article
DE Adversarial machine learning; Evasion attack; Poisoning attack;
   Adversarial robustness tools; Machine learning models
AB Artificial intelligence aims to build intelligent systems capable of performing tasks that need human intelligence. Research works in recent years have revealed many potential vulnerabilities in machine learning algorithms. Precisely to exploit these vulnerabilities, an attacker may attempt to design an adversarial input to be incorrectly processed by machine learning algorithms. This paper focuses on methods of generating adversarial samples and discusses possible countermeasures. Our proposed method effectively checks the robustness of different machine learning models using six available hostile robustness tools and summarizes their current development state. The work compares the features of these tools, highlights similarities, and differences among the tools, their strength and weaknesses and trace connections among theoretical methods and their implementations. This paper will provide more insight for researchers and scientists to develop robust solutions and accelerate their experimentation.
C1 [Asha, S.] APJ Abdul Kalam Technol Univ, SCMS Sch Engn & Technol, Dept Comp Sci & Engn, Trivandrum, Kerala, India.
   [Vinod, P.] Cochin Univ Sci & Technol, Dept Comp Applicat, Cochin, Kerala, India.
RP Vinod, P (corresponding author), Cochin Univ Sci & Technol, Dept Comp Applicat, Cochin, Kerala, India.
EM ashas@semsgroup.org; vinod.p@cusat.ac.in
NR 68
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1386-7857
EI 1573-7543
J9 CLUSTER COMPUT
JI Cluster Comput.
PD FEB
PY 2022
VL 25
IS 1
BP 503
EP 522
DI 10.1007/s10586-021-03421-1
EA SEP 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YJ5MG
UT WOS:000701354900001
DA 2022-04-17
ER

PT C
AU Alameri, SA
   Mohd, M
AF Alameri, Saeed Amer
   Mohd, Masnizah
GP IEEE
TI Comparison of Fake News Detection using Machine Learning and Deep
   Learning Techniques
SO 2021 3RD INTERNATIONAL CYBER RESILIENCE CONFERENCE (CRC)
LA English
DT Proceedings Paper
CT 3rd International Cyber Resilience Conference (CRC)
CY JAN 29-31, 2021
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, Cyber Secur Acad Malaysia, Univ Teknologi Malaysia, Informat Assurance & Secur Res Grp, Univ Kebangsaan Malaysia, IEEE Comp Soc, Malaysia Sect
DE Fake news detection; Machine learning; Deep learning techniques; LSTM
AB Fake news has spread widely on the Web in recent years due to the massive amount of information exchanged on digital media. This has motivates our study to determine the best-performing model among two Machine Learning models: Naive Bayes (NB), Support Vector Machine (SVM), and three Deep Learning models: Long Short-Term Memory (LSTM), Neural Network with Keras (NN-Keras), and Neural Network with Tensor-Flow (NN-TF). We examined five models using two different English language news datasets. The performance of the models was evaluated using four metrics; accuracy, precision, recall and F1-score. The obtained results showed that deep learning models had achieved better accuracy than traditional ML models. The LSTM model has outperformed all other models examined. It achieved an average accuracy of 94.21%. The NN-Keras has also produced a good performance with an average accuracy of 92.99%. The words' order carries critical information and plays a significant role in the fake news classification, where our LSTM makes a prediction based on this.
C1 [Alameri, Saeed Amer] Seiyun Univ, Dept Informat Technol, Hadhramout, Yemen.
   [Mohd, Masnizah] Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Bangi, Selangor, Malaysia.
RP Alameri, SA (corresponding author), Seiyun Univ, Dept Informat Technol, Hadhramout, Yemen.
EM salameri@seiyunu.edu.ye; masnizah.mohd@ukm.edu.my
FU Universiti Kebangsaan Malaysia [DCP-2017-007/4]
FX This study was supported by the Universiti Kebangsaan Malaysia grant
   DCP-2017-007/4.
NR 16
TC 0
Z9 0
U1 5
U2 8
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-6654-1844-7
PY 2021
BP 101
EP 106
DI 10.1109/CRC50527.2021.9392458
PG 6
WC Computer Science, Information Systems
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS0YA
UT WOS:000685218700018
DA 2022-04-17
ER

PT J
AU Shen, L
   Thompson, PM
AF Shen, Li
   Thompson, Paul M.
TI Brain Imaging Genomics: Integrated Analysis and Machine Learning
SO PROCEEDINGS OF THE IEEE
LA English
DT Article
DE Genomics; Bioinformatics; Brain; Machine learning; Biomedical imaging;
   Big data; brain imaging; genomics; machine learning; statistics
ID CANONICAL CORRELATION-ANALYSIS; POLYGENIC RISK SCORES; WIDE ASSOCIATION
   ANALYSIS; QUANTITATIVE TRAIT LOCI; SET ENRICHMENT ANALYSIS; RANK
   REGRESSION-MODELS; ALZHEIMERS-DISEASE; GENETIC INFLUENCES; ANALYSIS
   REVEALS; NEUROIMAGING PHENOTYPES
AB Brain imaging genomics is an emerging data science field, where integrated analysis of brain imaging and genomics data, often combined with other biomarker, clinical, and environmental data, is performed to gain new insights into the phenotypic, genetic, and molecular characteristics of the brain as well as their impact on normal and disordered brain function and behavior. It has enormous potential to contribute significantly to biomedical discoveries in brain science. Given the increasingly important role of statistical and machine learning in biomedicine and rapidly growing literature in brain imaging genomics, we provide an up-to-date and comprehensive review of statistical and machine learning methods for brain imaging genomics, as well as a practical discussion on method selection for various biomedical applications.
C1 [Shen, Li] Univ Penn, Perelman Sch Med, Dept Biostat Epidemiol & Informat, Philadelphia, PA 19104 USA.
   [Thompson, Paul M.] Univ Southern Calif, Keck Sch Med, Mark & Mary Stevens Inst Neuroimaging & Informat, Imaging Genet Ctr, Los Angeles, CA 90232 USA.
RP Shen, L (corresponding author), Univ Penn, Perelman Sch Med, Dept Biostat Epidemiol & Informat, Philadelphia, PA 19104 USA.
EM li.shen@pennmedicine.upenn.edu; pthomp@usc.edu
RI Thompson, Paul M/C-4194-2018; Shen, Li/AAB-6870-2021
OI Thompson, Paul M/0000-0002-4720-8867; Shen, Li/0000-0002-5443-0503
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA; NSFNational Science Foundation (NSF)
   [R01 EB022574, R01 LM011360, RF1 AG063481, IIS 1837964]; NIH Big Data to
   Knowledge (BD2K) Program [U54 EB020403]; ENIGMA World Aging Center [NIA
   R56 AG058854]; ENIGMA Sex Differences Initiative [R01 MH116147];  [P41
   EB015922];  [RF1 AG041915];  [U01 AG024904];  [RF1 AG051710];  [R21
   AG056782];  [P01 AG026572];  [R01 MH111671]
FX This work was supported under Grant P41 EB015922, Grant RF1 AG041915,
   Grant U01 AG024904, Grant RF1 AG051710, Grant R21 AG056782, and Grant
   P01 AG026572. The work of L. Shen was supported in part by NIH and NSF
   under Grant R01 EB022574, Grant R01 LM011360, Grant RF1 AG063481, and
   Grant IIS 1837964. The work of P. M. Thompson was supported in part by
   the NIH Big Data to Knowledge (BD2K) Program under Consortium Grant U54
   EB020403, in part by the ENIGMA World Aging Center under Grant NIA R56
   AG058854, in part by the ENIGMA Sex Differences Initiative under Grant
   R01 MH116147, and a grant to the ENIGMA-PGC PTSD Working Group under
   Grant R01 MH111671.
NR 234
TC 21
Z9 21
U1 9
U2 28
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9219
EI 1558-2256
J9 P IEEE
JI Proc. IEEE
PD JAN
PY 2020
VL 108
IS 1
BP 125
EP 162
DI 10.1109/JPROC.2019.2947272
PG 38
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA KA4TS
UT WOS:000505790500008
PM 31902950
OA Green Accepted, hybrid
DA 2022-04-17
ER

PT J
AU Zhan, BQ
   Zhang, S
   Du, HS
   Yang, XG
AF Zhan, Baoqiang
   Zhang, Shu
   Du, Helen S.
   Yang, Xiaoguang
TI Exploring Statistical Arbitrage Opportunities Using Machine Learning
   Strategy
SO COMPUTATIONAL ECONOMICS
LA English
DT Article; Early Access
DE Statistical arbitrage; Cointegration; Machine learning; Opportunities
   exploration
ID PAIRS TRADING STRATEGY; STOCK; MARKET; INDEX; PRICES; COINTEGRATION;
   MODELS; TREND; RISK; DEEP
AB Arbitrage opportunity exploration is important to ensure the profitability of statistical arbitrage. Prior studies that concentrate on cointegration model and other predictive models suffer from various problems in both prediction and transaction. To prevent these problems, we propose a novel strategy based on machine learning to explore arbitrage opportunities and further predict whether they will make a profit or not. The experiment is conducted in the context of Chinese financial markets with high-frequency data of CSI 300 exchange traded fund (ETF) and CSI 300 index futures (IF) from 2012 to 2020. We find that machine learning strategy can explore more arbitrage opportunities with lower risks, which outperforms cointegration strategy in different aspects. Besides, we compare different algorithms and find that LSTM achieve better performance in predicting the positive arbitrage samples and obtaining higher ROI and Sharpe ratio. The profitability of machine learning strategy validate the mean reversion and price discovery function of asset price between spot market and futures market, which further substantiate the market efficiency. Our empirical results provide practical significance to the development of quantitative finance.
C1 [Zhan, Baoqiang] Harbin Inst Technol, Sch Management, Harbin, Peoples R China.
   [Zhang, Shu; Du, Helen S.] Guangdong Univ Technol, Sch Management, Guangzhou, Peoples R China.
   [Yang, Xiaoguang] Chinese Acad Sci, Acad Math & Syst Sci, Beijing, Peoples R China.
RP Zhan, BQ (corresponding author), Harbin Inst Technol, Sch Management, Harbin, Peoples R China.
EM 2111708031@mail2.gdut.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [71532013, 71431008, 71572050]
FX This work was supported by National Natural Science Foundation of China
   (Nos. 71532013, 71431008 and 71572050).
NR 38
TC 0
Z9 0
U1 12
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0927-7099
EI 1572-9974
J9 COMPUT ECON
JI Comput. Econ.
DI 10.1007/s10614-021-10169-8
EA NOV 2021
PG 22
WC Economics; Management; Mathematics, Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Business & Economics; Mathematics
GA XA4LJ
UT WOS:000720620200001
DA 2022-04-17
ER

PT J
AU Kasinathan, T
   Uyyala, SR
AF Kasinathan, Thenmozhi
   Uyyala, Srinivasulu Reddy
TI Machine learning ensemble with image processing for pest identification
   and classification in field crops
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Crops; Ensemble classification; Image processing; Insect classification;
   Machine learning algorithm; Majority voting
ID NEURAL-NETWORK; FEATURES; TEXTURE; COLOR; REPRESENTATION; INSECTS;
   SYSTEM; APHIDS; SCENE; SHAPE
AB In agriculture field, yield loss is a major problem due to attack of various insects in field crops. Traditional insect identification and classification methods are time-consuming and require entomologist experts. Early information about the attack of insects helps farmers to control the crop damage to improve the productivity and reduce the use of pesticides. This research work focuses on the classification of crop insects by applying machine vision and knowledge-based techniques with image processing by using different feature descriptors including texture, color, shape, histogram of oriented gradients (HOG) and global image descriptor (GIST). A combination of all these features was used in the classification of insects. In this research, several machine learning algorithms including both base classifiers and ensemble classifiers were applied for three different insect datasets and the performances of classification results were evaluated by majority voting. Naive bayes (NB), support vector machine (SVM), K-nearest-neighbor (KNN) and multi-layer perceptron (MLP) were used as base classifiers. Ensemble classifiers include random forest (RF), bagging and XGBoost were utilized; 10-fold cross-validation test was conducted to achieve a better classification and identification of insects. The experimental results showed that the classification accuracy is improved by majority voting with ensemble classifiers in the combination of texture, color, shape, HOG and GIST features.
C1 [Kasinathan, Thenmozhi; Uyyala, Srinivasulu Reddy] Natl Inst Technol Tiruchirappalli, Dept Comp Applicat, Ctr Excellence Artificial Intelligence, Machine Learning & Data Analyt Lab, Tiruchirappalli 620015, Tamil Nadu, India.
RP Kasinathan, T; Uyyala, SR (corresponding author), Natl Inst Technol Tiruchirappalli, Dept Comp Applicat, Ctr Excellence Artificial Intelligence, Machine Learning & Data Analyt Lab, Tiruchirappalli 620015, Tamil Nadu, India.
EM thenmozhi@nitt.edu; usreddy@nitt.edu
RI Uyyala, Srinivasulu Reddy/AAD-4228-2020; Thenmozhi, K./AAV-1373-2020
OI Uyyala, Srinivasulu Reddy/0000-0002-6478-3839; Thenmozhi,
   K/0000-0001-9956-9261
FU Department of Science and Technology, India, under women scientist B
   (WOS-B)Department of Science & Technology (India)Department of Science &
   Technology (DOST), Philippines [DST/Disha/SoRF-PM/059/2013]
FX This work was supported by the Department of Science and Technology,
   India, under women scientist B (WOS-B), Grant No.
   DST/Disha/SoRF-PM/059/2013. Authors thankful to the Machine Learning and
   Data Analytics Lab, Department of Computer Applications, National
   Institute of Technology, Tiruchirappalli, for their infrastructural
   support.
NR 51
TC 3
Z9 3
U1 9
U2 30
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD JUL
PY 2021
VL 33
IS 13
SI SI
BP 7491
EP 7504
DI 10.1007/s00521-020-05497-z
EA JAN 2021
PG 14
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SY2KO
UT WOS:000604218100016
DA 2022-04-17
ER

PT J
AU Wlodarczyk, T
   Plotka, S
   Szczepanski, T
   Rokita, P
   Sochacki-Wojcicka, N
   Wojcicki, J
   Lipa, M
   Trzcinski, T
AF Wlodarczyk, Tomasz
   Plotka, Szymon
   Szczepanski, Tomasz
   Rokita, Przemyslaw
   Sochacki-Wojcicka, Nicole
   Wojcicki, Jakub
   Lipa, Michal
   Trzcinski, Tomasz
TI Machine Learning Methods for Preterm Birth Prediction: A Review
SO ELECTRONICS
LA English
DT Review
DE artificial intelligence; deep learning; machine learning; preterm birth
ID TIME TRENDS; SYSTEMATIC ANALYSIS; IMMUNE ALGORITHM; NEURAL-NETWORK;
   MORTALITY; TERM; CLASSIFICATION; DELIVERY; MORBIDITY; REDUCE
AB Preterm births affect around 15 million children a year worldwide. Current medical efforts focus on mitigating the effects of prematurity, not on preventing it. Diagnostic methods are based on parent traits and transvaginal ultrasound, during which the length of the cervix is examined. Approximately 30% of preterm births are not correctly predicted due to the complexity of this process and its subjective assessment. Based on recent research, there is hope that machine learning can be a helpful tool to support the diagnosis of preterm births. The objective of this study is to present various machine learning algorithms applied to preterm birth prediction. The wide spectrum of analysed data sets is the advantage of this survey. They range from electrohysterogram signals through electronic health records to transvaginal ultrasounds. Reviews of works on preterm birth already exist; however, this is the first review that includes works that are based on a transvaginal ultrasound examination. In this work, we present a critical appraisal of popular methods that have employed machine learning methods for preterm birth prediction. Moreover, we summarise the most common challenges incurred and discuss their possible application in the future.
C1 [Wlodarczyk, Tomasz; Plotka, Szymon; Szczepanski, Tomasz; Rokita, Przemyslaw; Trzcinski, Tomasz] Warsaw Univ Technol, Inst Comp Sci, PL-00661 Warsaw, Poland.
   [Sochacki-Wojcicka, Nicole; Wojcicki, Jakub; Lipa, Michal] Med Univ Warsaw, Dept Obstet & Gynecol 1, PL-02091 Warsaw, Poland.
   [Trzcinski, Tomasz] Tooploox, PL-53601 Wroclaw, Poland.
RP Wlodarczyk, T; Trzcinski, T (corresponding author), Warsaw Univ Technol, Inst Comp Sci, PL-00661 Warsaw, Poland.; Trzcinski, T (corresponding author), Tooploox, PL-53601 Wroclaw, Poland.
EM wlodarczyk.tomasz@gmail.com; plotkaszymon@gmail.com;
   tmk.szczepanski@gmail.com; pro@ii.pw.edu.pl;
   nicole.wojcicki@googlemail.com; jakub.wojcicki@googlemail.com;
   michallipa1@gmail.com; tomasz.trzcinski@pw.edu.pl
RI Płotka, Szymon/AAE-1811-2021
OI Rokita, Przemyslaw/0000-0002-4433-2133; Wlodarczyk,
   Tomasz/0000-0002-0437-470X
FU Warsaw University of Technology [II/2019/GD/2]; Grant of Scientific
   Discipline of Computer Science and Telecommunications atWarsaw
   University of Technology
FX This work was funded by Warsaw University of Technology Dean's grant
   number II/2019/GD/2 and Grant of Scientific Discipline of Computer
   Science and Telecommunications atWarsaw University of Technology.
NR 117
TC 1
Z9 1
U1 5
U2 6
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2079-9292
J9 ELECTRONICS-SWITZ
JI Electronics
PD MAR
PY 2021
VL 10
IS 5
AR 586
DI 10.3390/electronics10050586
PG 24
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Physics
GA QV5KI
UT WOS:000628009900001
DA 2022-04-17
ER

PT J
AU Pugalenthi, R
   Chakkaravarthy, AP
   Ramya, J
   Babu, S
   Krishnan, RR
AF Pugalenthi, R.
   Prabhu Chakkaravarthy, A.
   Ramya, J.
   Babu, Samyuktha
   Rasika Krishnan, R.
TI Artificial learning companionusing machine learning and natural language
   processing
SO INTERNATIONAL JOURNAL OF SPEECH TECHNOLOGY
LA English
DT Article
DE Artificial learning; Natural language processing; Hidden Markov model;
   Machine learning; Chatbots
AB Artificial Intelligence, also referred to as AI, is one of the most rapidly evolving branches of Computer Science. The two branches of AI which empowers it to understand and interact with humans are Machine Learning (ML) and Natural Language Processing (NLP). Together, these three forms the bases of Artificial Learning Companion-which can be described as a system which can be used to aid the Learning process of the humans. While ML allows the computer program to learn on its own with minimal human intervention, NLP empowers the system to understand the user's natural communication language through pre-coded programs. When these two aspects of Human Computer Interaction are combined, it enables the AI to take intelligent decisions with sufficient, relevant information. These decisions made by the system can be conveyed to the user using a static GUI, a voice assistant or a chatbot. In this paper, we have chosen to go with a chatbot because it is easy to use and is more relevant to the real-world implementation. The probability for each word is calculated and it provides P (A very close game | Sports) has obtained the highest probability
C1 [Pugalenthi, R.; Prabhu Chakkaravarthy, A.; Ramya, J.; Babu, Samyuktha; Rasika Krishnan, R.] St Josephs Coll Engn, Dept CSE, Chennai 600119, Tamil Nadu, India.
RP Pugalenthi, R (corresponding author), St Josephs Coll Engn, Dept CSE, Chennai 600119, Tamil Nadu, India.
EM rpugalsir@gmail.com; sjce.prabhuca@gmail.com; ramsharsha@gmail.com;
   samyuktha200399@gmail.com
RI Chakkaravarthy, Prabhu/T-4373-2019; R, Pugalenthi/T-4509-2019; J,
   Ramya/AAR-5157-2020
OI R, Pugalenthi/0000-0001-6256-941X; 
NR 11
TC 1
Z9 1
U1 2
U2 18
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1381-2416
EI 1572-8110
J9 INT J SPEECH TECHNOL
JI Int. J. Speech Technol.
PD SEP
PY 2021
VL 24
IS 3
SI SI
BP 553
EP 560
DI 10.1007/s10772-020-09773-0
EA NOV 2020
PG 8
WC Engineering, Electrical & Electronic
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA UC6XW
UT WOS:000587975200001
DA 2022-04-17
ER

PT C
AU Amich, A
   Eshete, B
AF Amich, Abderrahmen
   Eshete, Birhanu
BE GarciaAlfaro, J
   Li, S
   Poovendran, R
   Debar, H
   Yung, M
TI Explanation-Guided Diagnosis of Machine Learning Evasion Attacks
SO SECURITY AND PRIVACY IN COMMUNICATION NETWORKS, SECURECOMM 2021, PT I
SE Lecture Notes of the Institute for Computer Sciences Social Informatics
   and Telecommunications Engineering
LA English
DT Proceedings Paper
CT 17th EAI International Conference on Security and Privacy in
   Communication Networks (SecureComm)
CY SEP 06-09, 2021
CL ELECTR NETWORK
SP European Alliance Innovat
DE Machine learning evasion; Explainable machine learning
AB Machine Learning (ML) models are susceptible to evasion attacks. Evasion accuracy is typically assessed using aggregate evasion rate, and it is an open question whether aggregate evasion rate enables feature-level diagnosis on the effect of adversarial perturbations on evasive predictions. In this paper, we introduce a novel framework that harnesses explainable ML methods to guide high-fidelity assessment of ML evasion attacks. Our framework enables explanation-guided correlation analysis between pre-evasion perturbations and post-evasion explanations. Towards systematic assessment of ML evasion attacks, we propose and evaluate a novel suite of model-agnostic metrics for sample-level and dataset-level correlation analysis. Using malware and image classifiers, we conduct comprehensive evaluations across diverse model architectures and complementary feature representations. Our explanation-guided correlation analysis reveals correlation gaps between adversarial samples and the corresponding perturbations performed on them. Using a case study on explanation-guided evasion, we show the broader usage of our methodology for assessing robustness of ML models.
C1 [Amich, Abderrahmen; Eshete, Birhanu] Univ Michigan, Dearborn, MI 48128 USA.
RP Amich, A (corresponding author), Univ Michigan, Dearborn, MI 48128 USA.
EM aamich@umich.edu; birhanu@umich.edu
NR 50
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1867-8211
EI 1867-822X
BN 978-3-030-90019-9; 978-3-030-90018-2
J9 L N INST COMP SCI SO
PY 2021
VL 398
BP 207
EP 228
DI 10.1007/978-3-030-90019-9_11
PG 22
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Telecommunications
GA BS7ZY
UT WOS:000769458100011
OA Green Submitted
DA 2022-04-17
ER

PT C
AU Bezzubov, SS
   Frolov, AA
AF Bezzubov, Sam S.
   Frolov, Aleksey A.
GP IEEE
TI Practical Use of Machine Learning in the Minecraft Computer Game
SO PROCEEDINGS OF THE 2021 IEEE CONFERENCE OF RUSSIAN YOUNG RESEARCHERS IN
   ELECTRICAL AND ELECTRONIC ENGINEERING (ELCONRUS)
SE IEEE NW Russia Young Researchers in Electrical and Electronic
   Engineering Conference
LA English
DT Proceedings Paper
CT IEEE Conference of Russian Young Researchers in Electrical and
   Electronic Engineering (ElConRus)
CY JAN 26-28, 2021
CL Saint Petersburg Electrotechn Univ, RUSSIA
SP IEEE
HO Saint Petersburg Electrotechn Univ
DE Minecraft; machine learning; Java
AB this article investigates the use of the Minecraft computer game for the implementation and training of machine learning algorithms. In the introduction, an analysis of works on this topic is described. Similar experiments using Minecraft are also discussed. The experimental part describes the process of implementing a game modification, which adds a new AI-controlled character to the game. As the result, examples of work that reflect the possibilities of using machine learning are shown. In conclusion, the pros and cons of this work are given basing on the results of the experiment.
C1 [Bezzubov, Sam S.; Frolov, Aleksey A.] Natl Res Nucl Univ MEPhI, Dept Comp Syst & Technol, Moscow, Russia.
RP Bezzubov, SS (corresponding author), Natl Res Nucl Univ MEPhI, Dept Comp Syst & Technol, Moscow, Russia.
EM sambezzubov@yandex.ru; aleksey2093@outlook.com
NR 5
TC 0
Z9 0
U1 2
U2 2
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2376-6557
BN 978-1-6654-0476-1
J9 IEEE NW RUSS YOUNG
PY 2021
BP 238
EP 240
DI 10.1109/ElConRus51938.2021.9396731
PG 3
WC Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering
GA BR7SJ
UT WOS:000669709800054
DA 2022-04-17
ER

PT J
AU Kandpal, N
   Singh, A
   Agarwal, A
AF Kandpal, Naveen
   Singh, Anil
   Agarwal, Alpana
TI A Machine Learning Driven PVT-Robust VCO with Enhanced Linearity Range
SO CIRCUITS SYSTEMS AND SIGNAL PROCESSING
LA English
DT Article; Early Access
DE PVT; Machine learning; VCO; Prediction; Linearity
ID RING OSCILLATOR; DESIGN; ADC; BANDWIDTH; NOISE; PLL
AB This work presents a PVT robust machine learning-based Voltage-controlled Oscillator (VCO) with an enhanced linearity range. The machine learning algorithm with PVT robustness is implemented digitally. Different from conventional methods, the proposed scheme does not require the VCO to be in working mode every time one needs the prediction of frequency. The proposed scheme uses the frequency to digital converter (FDC) output data as an input learning vector and uses a prediction block to predict the future frequencies. An 11-stage voltage-controlled oscillator with a machine learning algorithm is implemented in SCL 180 nm CMOS technology. The measurement results show that the proposed architecture is robust against PVT variations with an enhanced linearity range. Without a machine learning algorithm, the VCO's control voltage linearity range is 0.28 V to 0.40 V that increases to the range from 0.1 to 1.8 V after applying the proposed machine learning algorithm. The maximum gain variation of 3.71% is observed at FF with respect to the TT corner after applying the proposed machine learning algorithm.
C1 [Kandpal, Naveen; Singh, Anil; Agarwal, Alpana] Thapar Inst Engn & Technol, ECED, Patiala, Punjab, India.
RP Singh, A (corresponding author), Thapar Inst Engn & Technol, ECED, Patiala, Punjab, India.
EM nkandpal_phd19@thapar.edu; anils.rawat@thapar.edu; alpana@thapar.edu
FU Ministry of Electronics and Information Technology (MeitY), GoI, through
   the SMDP-VLSI C2SD project
FX The Ministry of Electronics and Information Technology (MeitY), GoI,
   through the SMDP-VLSI C2SD project, is gratefully acknowledged for
   providing research facilities and support.
NR 46
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER BIRKHAUSER
PI NEW YORK
PA 233 SPRING STREET, 6TH FLOOR, NEW YORK, NY 10013 USA
SN 0278-081X
EI 1531-5878
J9 CIRC SYST SIGNAL PR
JI Circuits Syst. Signal Process.
DI 10.1007/s00034-022-02001-x
EA MAR 2022
PG 18
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA ZY0EQ
UT WOS:000772264500001
DA 2022-04-17
ER

PT C
AU Toledo, RN
   Akamine, C
   Jerji, F
   Silva, LA
AF Toledo, Roberto Neves
   Akamine, Cristiano
   Jerji, Fadi
   Silva, Leandro A.
GP IEEE
TI M-QAM Demodulation based on Machine Learning
SO 2020 IEEE INTERNATIONAL SYMPOSIUM ON BROADBAND MULTIMEDIA SYSTEMS AND
   BROADCASTING (BMSB)
SE IEEE International Symposium on Broadband Multimedia Systems and
   Broadcasting
LA English
DT Proceedings Paper
CT 15th IEEE International Symposium on Broadband Multimedia Systems and
   Broadcasting (BMSB)
CY OCT 27-29, 2020
CL ELECTR NETWORK
SP IEEE Broadcasting Technol Soc, IEEE Reg 8, IEEE France Sect, ISEP, French Engn Sch, IEEE
DE Demodulation; LLR; Machine Learning; M-QAN
AB This paper presents a new Quadrature Amplitude Modulation (M-QAM) demodulation method using Machine Learning techniques. The new method significantly reduces the demodulation complexity for high -order constellations while maintains the demodulation accuracy. The experimental results demonstrate a performance gain of up to 1485% for 4096-QAM in comparison with the classical Log -Likelihood Ratio demodulator.
C1 [Toledo, Roberto Neves; Akamine, Cristiano; Jerji, Fadi; Silva, Leandro A.] Univ Prebiteriana Mackenzie, PPGEEC, Sao Paulo, Brazil.
RP Toledo, RN (corresponding author), Univ Prebiteriana Mackenzie, PPGEEC, Sao Paulo, Brazil.
RI JERJI, FADI/AGF-7341-2022; Akamine, Cristiano/AFU-3342-2022; Akamine,
   Cristiano/F-6096-2015
OI JERJI, FADI/0000-0002-2076-5831; Akamine, Cristiano/0000-0002-3161-4668;
   Akamine, Cristiano/0000-0002-3161-4668
FU Post-graduation Program in Electrical and Computer Engineering of
   Mackenzie Presbyterian University and its Digital TV and Big Data &
   Analytic Methods Laboratories
FX This work had the support of the Post-graduation Program in Electrical
   and Computer Engineering of Mackenzie Presbyterian University and its
   Digital TV and Big Data & Analytic Methods Laboratories.
NR 11
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2155-5044
BN 978-1-7281-5784-9
J9 IEEE INT SYM BROADB
PY 2020
DI 10.1109/BMSB49480.2020.9379442
PG 6
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BR6QO
UT WOS:000662913100012
DA 2022-04-17
ER

PT J
AU Liaqat, S
   Dashtipour, K
   Zahid, A
   Assaleh, K
   Arshad, K
   Ramzan, N
AF Liaqat, Sidrah
   Dashtipour, Kia
   Zahid, Adnan
   Assaleh, Khaled
   Arshad, Kamran
   Ramzan, Naeem
TI Detection of Atrial Fibrillation Using a Machine Learning Approach
SO INFORMATION
LA English
DT Article
DE atrial fibrillation; machine learning; cardiovascular; deep learning;
   healthcare
ID AUTOMATIC DETECTION
AB The atrial fibrillation (AF) is one of the most well-known cardiac arrhythmias in clinical practice, with a prevalence of 1-2% in the community, which can increase the risk of stroke and myocardial infarction. The detection of AF electrocardiogram (ECG) can improve the early detection of diagnosis. In this paper, we have further developed a framework for processing the ECG signal in order to determine the AF episodes. We have implemented machine learning and deep learning algorithms to detect AF. Moreover, the experimental results show that better performance can be achieved with long short-term memory (LSTM) as compared to other algorithms. The initial experimental results illustrate that the deep learning algorithms, such as LSTM and convolutional neural network (CNN), achieved better performance (10%) as compared to machine learning classifiers, such as support vectors, logistic regression, etc. This preliminary work can help clinicians in AF detection with high accuracy and less probability of errors, which can ultimately result in reduction in fatality rate.
C1 [Liaqat, Sidrah; Ramzan, Naeem] Univ West Scotland, Sch Engn & Comp, Glasgow G72 0LH, Lanark, Scotland.
   [Dashtipour, Kia; Zahid, Adnan] Univ Glasgow, James Watt Sch Engn, Glasgow G12 8QQ, Lanark, Scotland.
   [Zahid, Adnan] Heriot Watt Univ, Sch Engn & Phys Sci, Edinburgh EH14 4AS, Midlothian, Scotland.
   [Assaleh, Khaled; Arshad, Kamran] Ajman Univ, Fac Engn & IT, Ajman 346, U Arab Emirates.
RP Ramzan, N (corresponding author), Univ West Scotland, Sch Engn & Comp, Glasgow G72 0LH, Lanark, Scotland.
EM sidra193@gmail.com; kia.dashtipour@glasgow.ac.uk;
   a.zahid.1@research.gla.ac.uk; k.assaleh@ajman.ac.ae;
   k.arshad@ajman.ac.ae; Naeem.Ramzan@uws.ac.uk
RI Dashtipour, Kia/AAX-9489-2020
OI Dashtipour, Kia/0000-0002-9651-6487; Ramzan, Naeem/0000-0002-5088-1462;
   Assaleh, Khaled/0000-0002-0942-0453
FU EPSRC DTGUK Research & Innovation (UKRI)Engineering & Physical Sciences
   Research Council (EPSRC) [EP/N509668/1 Eng]; Ajman University
FX This research work was funded by EPSRC DTG EP/N509668/1 Eng. This work
   is supported in part by the Ajman University Internal Research Grant.
NR 56
TC 10
Z9 10
U1 3
U2 7
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2078-2489
J9 INFORMATION
JI Information
PD DEC
PY 2020
VL 11
IS 12
AR 549
DI 10.3390/info11120549
PG 15
WC Computer Science, Information Systems
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA PK0GW
UT WOS:000602135000001
OA Green Accepted, gold
DA 2022-04-17
ER

PT J
AU Situ, HZ
   He, ZM
AF Situ, Haozhen
   He, Zhimin
TI Machine learning distributions of quantum ansatz with hierarchical
   structure
SO INTERNATIONAL JOURNAL OF MODERN PHYSICS B
LA English
DT Article
DE Quantum machine learning; quantum ansatz; variational autoencoder
AB Machine learning techniques can help to represent and solve quantum systems. Learning measurement outcome distribution of quantum ansatz is useful for characterization of near-term quantum computing devices. In this work, we use the popular unsupervised machine learning model, variational autoencoder (VAE), to reconstruct the measurement outcome distribution of quantum ansatz. The number of parameters in the VAE are compared with the number of measurement outcomes. The numerical results show that VAE can efficiently learn the measurement outcome distribution with few parameters. The influence of entanglement on the task is also revealed.
C1 [Situ, Haozhen] South China Agr Univ, Coll Math & Informat, Guangzhou 510642, Peoples R China.
   [He, Zhimin] Foshan Univ, Sch Elect & Informat Engn, Foshan 528000, Peoples R China.
RP He, ZM (corresponding author), Foshan Univ, Sch Elect & Informat Engn, Foshan 528000, Peoples R China.
EM situhaozhen@gmail.com; zhmihe@gmail.com
OI Situ, Haozhen/0000-0001-7853-6647
FU Guangdong Basic and Applied Basic Research Foundation [2020A1515011204];
   Natural Science Foundation of Guangdong Province of ChinaNational
   Natural Science Foundation of Guangdong Province [2019A1515011166];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61802061, 61902132, 61772565]
FX This work is supported by Guangdong Basic and Applied Basic Research
   Foundation (No. 2020A1515011204), the Natural Science Foundation of
   Guangdong Province of China (No. 2019A1515011166), and the National
   Natural Science Foundation of China (Grant Nos. 61802061, 61902132,
   61772565).
NR 12
TC 0
Z9 0
U1 0
U2 1
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0217-9792
EI 1793-6578
J9 INT J MOD PHYS B
JI Int. J. Mod. Phys. B
PD AUG 10
PY 2020
VL 34
IS 20
AR 2050196
DI 10.1142/S0217979220501969
PG 9
WC Physics, Applied; Physics, Condensed Matter; Physics, Mathematical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Physics
GA NM0RR
UT WOS:000567812900011
DA 2022-04-17
ER

PT J
AU Soumya, S
   Pramod, KV
AF Soumya, S.
   Pramod, K., V
TI Sentiment analysis of malayalam tweets using machine learning techniques
SO ICT EXPRESS
LA English
DT Article
DE Machine learning; Malayalam; Sentiment analysis; Sentiwordnet
AB Sentiment Analysis of Malayalam Tweets using Machine Learning techniques is done in this paper. The tweets are classified into positive and negative using different machine learning techniques such as Naive Bayes (NB), Support Vector Machine (SVM) and Random Forest (RF). The different features like Bag of Words (BOW), Term Frequency vs. Inverse Document Frequency (TF - IDF), Unigram with Sentiwordnet, and Unigram with Sentiwordnet including negation words are considered for feature vector formation of input dataset. The Random Forest classifier shows higher accuracy while considering Unigram with Sentiwordnet including negation words as a feature. (C) 2020 The Korean Institute of Communications and Information Sciences (KICS). Publishing services by Elsevier B.V.
C1 [Soumya, S.; Pramod, K., V] Cochin Univ Sci & Technol, Dept Comp Applicat, Cochin, Kerala, India.
RP Soumya, S (corresponding author), Cochin Univ Sci & Technol, Dept Comp Applicat, Cochin, Kerala, India.
EM soumya@cemunnar.ac.in
NR 21
TC 8
Z9 8
U1 4
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2405-9595
J9 ICT EXPRESS
JI ICT Express
PD DEC
PY 2020
VL 6
IS 4
BP 300
EP 305
DI 10.1016/j.icte.2020.04.003
PG 6
WC Computer Science, Information Systems; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA OX3GB
UT WOS:000593456300007
OA gold
DA 2022-04-17
ER

PT C
AU Dong, Y
   Chen, XJ
   Shen, LY
   Wang, DK
AF Dong, Ye
   Chen, Xiaojun
   Shen, Liyan
   Wang, Dakui
BE Zhou, J
   Luo, X
   Shen, Q
   Xu, Z
TI Privacy-Preserving Distributed Machine Learning Based on Secret Sharing
SO INFORMATION AND COMMUNICATIONS SECURITY (ICICS 2019)
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 21st International Conference on Information and Communications Security
   (ICICS)
CY DEC 15-17, 2019
CL Beijing, PEOPLES R CHINA
SP Peking Univ, Sch Software & Microelectron, Chinese Acad Sci, Inst Informat Engn, Chinese Acad Sci, Inst Software, Ali, TCG, Microsoft, Intel, AWS, 360, Neusoft, Nationz Technol, Octa Innovat, SANGFOR, China Int Talent Exchange Fdn, Springer
DE Secret sharing; Distributed machine learning; Privacy-preserving
AB Machine Learning has been widely applied in practice, such as disease diagnosis, target detection. Commonly, a good model relies on massive training data collected from different sources. However, the collected data might expose sensitive information. To solve the problem, researchers have proposed many excellent methods that combine machine learning with privacy protection technologies, such as secure multiparty computation (MPC), homomorphic encryption (HE), and differential privacy. In the meanwhile, some other researchers proposed distributed machine learning which allows the clients to store their data locally but train a model collaboratively. The first kind of methods focuses on security, but the performance and accuracy remain to be improved, while the second provides higher accuracy and better performance but weaker security, for instance, the adversary can launch membership attacks from the gradients' updates in plaintext.
   In this paper, we join secret sharing to distributed machine learning to achieve reliable performance, accuracy, and high-level security. Next, we design, implement, and evaluate a practical system to jointly learn an accurate model under semi-honest and servers-only malicious adversary security, respectively. And the experiments show our protocols achieve the best overall performance as well.
C1 [Dong, Ye; Chen, Xiaojun; Shen, Liyan; Wang, Dakui] Chinese Acad Sci, Inst Informat Engn, Beijing, Peoples R China.
   [Dong, Ye; Shen, Liyan] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing, Peoples R China.
RP Chen, XJ (corresponding author), Chinese Acad Sci, Inst Informat Engn, Beijing, Peoples R China.
EM dongye@iie.ac.cn; chenxiaojun@iie.ac.cn; shenliyan@iie.ac.cn;
   wangdakui@iie.ac.cn
OI Dong, Ye/0000-0002-2105-8047
FU Singapore University of Technology; Strategic Priority Research Program
   of Chinese Academy of SciencesChinese Academy of Sciences [XDC02040400]
FX We are grateful to the anonymous reviewers for their comprehensive
   comments. And we thank Xiangfu Song, Yiran Liu from Shandong University
   for helpful discussions on MPC, and Junming Ke from Singapore University
   of Technology and Design for his help. This work was supported by the
   Strategic Priority Research Program of Chinese Academy of Sciences,
   Grant No. XDC02040400.
NR 31
TC 0
Z9 1
U1 2
U2 2
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-41579-2; 978-3-030-41578-5
J9 LECT NOTES COMPUT SC
PY 2020
VL 11999
BP 684
EP 702
DI 10.1007/978-3-030-41579-2_40
PG 19
WC Computer Science, Information Systems; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Telecommunications
GA BR7MJ
UT WOS:000668350000040
DA 2022-04-17
ER

PT J
AU Elyan, E
   Hussain, A
   Sheikh, A
   Elmanama, AA
   Vuttipittayamongkol, P
   Hijazi, K
AF Elyan, Eyad
   Hussain, Amir
   Sheikh, Aziz
   Elmanama, Abdelraouf A.
   Vuttipittayamongkol, Pattaramon
   Hijazi, Karolin
TI Antimicrobial Resistance and Machine Learning: Challenges and
   Opportunities
SO IEEE ACCESS
LA English
DT Article
DE Antibiotics; Immune system; Testing; Predictive models; Pandemics;
   Microorganisms; Machine learning algorithms; AMR; antimicrobial
   resistance; machine learning; LMICs
ID ANTIBIOTIC-RESISTANCE; RANDOM FORESTS; CROSS-VALIDATION;
   DECISION-SUPPORT; SUSCEPTIBILITY; PREDICTION; MANAGEMENT; HOSPITALS;
   INFECTION; SYSTEMS
AB Antimicrobial Resistance (AMR) has been identified by the World Health Organisation (WHO) as one of the top ten global health threats. Inappropriate use of antibiotics around the world and in particular in Low-to-Middle-Income Countries (LMICs), where antibiotics use and prescription are poorly managed, is considered one of the main reasons for this problem. It is projected that the COVID-19 pandemic will accelerate the threat of AMR due to the increasing use of antibiotics across the world, and especially in countries with limited resources. In recent years, machine learning-based methods showed promising results and proved capable of providing the necessary tools to inform antimicrobial prescription and combat AMR. This timely paper provides a critical and technical review of existing machine learning-based methods for addressing AMR. First, an overview of the AMR problem as a global threat to public health, and its impact on countries with limited resources (LMICs) are presented. Then, a technical review and evaluation of existing literature that utilises machine learning to tackle AMR are provided with emphasis on methods that use readily available demographic and clinical data as well as microbial culture and sensitivity laboratory data of clinical isolates associated with multi-drug resistant infections. This is followed by a discussion of challenges and limitations that are considered barriers to scaling up the use of machine learning to address AMR. Finally, a framework for accelerating the use of AMR data-driven framework, and building a feasible solution that can be realistically implemented in LMICs is presented with a discussion of future directions and recommendations.
C1 [Elyan, Eyad] Robert Gordon Univ, Sch Comp, Aberdeen AB10 7AQ, Scotland.
   [Hussain, Amir] Edinburgh Napier Univ, Sch Comp, Edinburgh EH14 1DJ, Midlothian, Scotland.
   [Sheikh, Aziz] Univ Edinburgh, Usher Inst, Edinburgh EH8 9AG, Midlothian, Scotland.
   [Elmanama, Abdelraouf A.] Islamic Univ Gaza, Fac Hlth Sci, Med Technol Dept, Gaza, Palestine.
   [Vuttipittayamongkol, Pattaramon] Mae Fah Luang Univ, Sch Informat Technol, Chiang Rai 57100, Thailand.
   [Hijazi, Karolin] Univ Aberdeen, Sch Med Med Sci & Nutr, Aberdeen AB24 3FX, Scotland.
RP Elyan, E (corresponding author), Robert Gordon Univ, Sch Comp, Aberdeen AB10 7AQ, Scotland.
EM e.elyan@rgu.ac.uk
NR 117
TC 0
Z9 0
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2022
VL 10
BP 31561
EP 31577
DI 10.1109/ACCESS.2022.3160213
PG 17
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA ZZ4VE
UT WOS:000773267700001
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Hruschka, H
AF Hruschka, Harald
TI Comparing unsupervised probabilistic machine learning methods for market
   basket analysis
SO REVIEW OF MANAGERIAL SCIENCE
LA English
DT Article
DE Machine learning; Market basket analysis; Factor analysis; Topic models;
   Restricted Boltzmann machine; Deep learning
ID SHOPPING BASKET; MODEL; PACKAGE
AB We compare several unsupervised probabilistic machine learning methods for market basket analysis, namely binary factor analysis, two topic models (latent Dirichlet allocation and the correlated topic model), the restricted Boltzmann machine and the deep belief net. After an overview of previous applications of unsupervised probabilistic machine learning methods to market basket analysis we shortly present the methods which we investigate and outline their estimation. Performance is measured by tenfold cross-validated log likelihood values. Binary factor analysis vastly outperforms topic models. The restricted Boltzmann machine attains a similar performance advantage over binary factor analysis. Overall, a deep belief net with 45 variables in the first and 15 variables in the second hidden layers turns out to be the best model. We also compare the investigated machine learning methods with respect to ease of interpretation and runtimes. In addition, we show how to interpret the relationships between hidden variables and observed category purchases. To demonstrate managerial implications we estimate the effect of promoting each category both on purchase probability increases of other product categories and the relative increase of basket size. Finally, we indicate several possibilities to extend restricted Boltzmann machines and deep belief nets for market basket analysis.
C1 [Hruschka, Harald] Univ Regensburg, Univ Str 31, D-93040 Regensburg, Germany.
RP Hruschka, H (corresponding author), Univ Regensburg, Univ Str 31, D-93040 Regensburg, Germany.
EM harald.hruschka@ur.de
NR 58
TC 3
Z9 3
U1 6
U2 9
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1863-6683
EI 1863-6691
J9 REV MANAG SCI
JI Rev. Manag. Sci.
PD FEB
PY 2021
VL 15
IS 2
BP 497
EP 527
DI 10.1007/s11846-019-00349-0
PG 31
WC Management
WE Social Science Citation Index (SSCI)
SC Business & Economics
GA QL3TM
UT WOS:000621002400012
DA 2022-04-17
ER

PT C
AU Schule, M
   Lang, H
   Springer, M
   Kemper, A
   Neumann, T
   Gunnemann, S
AF Schuele, Maximilian
   Lang, Harald
   Springer, Maximilian
   Kemper, Alfons
   Neumann, Thomas
   Guennemann, Stephan
BE Zhu, Q
   Zhu, X
   Tu, Y
   Xu, Z
   Kumar, A
TI In-Database Machine Learning with SQL on GPUs
SO 33RD INTERNATIONAL CONFERENCE ON SCIENTIFIC AND STATISTICAL DATABASE
   MANAGEMENT (SSDBM 2021)
LA English
DT Proceedings Paper
CT 33rd International Conference on Scientific and Statistical Database
   Management (SSDBM)
CY JUL 06-07, 2021
CL ELECTR NETWORK
DE In-Database Machine Learning; Automatic Differentiation; GPU
AB In machine learning, continuously retraining a model guarantees accurate predictions based on the latest data as training input. But to retrieve the latest data from a database, time-consuming extraction is necessary as database systems have rarely been used for operations such as matrix algebra and gradient descent.
   In this work, we demonstrate that SQL with recursive tables makes it possible to express a complete machine learning pipeline out of data preprocessing, model training and its validation. To facilitate the specification of loss functions, we extend the code-generating database system Umbra by an operator for automatic differentiation for use within recursive tables: With the loss function expressed in SQL as a lambda function, Umbra generates machine code for each partial derivative. We further use automatic differentiation for a dedicated gradient descent operator, which generates LLVM code to train a user-specified model on GPUs. We fine-tune GPU kernels at hardware level to allow a higher throughput and propose non-blocking synchronisation of multiple units.
   In our evaluation, automatic differentiation accelerated the run-time by the number of cached subexpressions compared to compiling each derivative separately. Our GPU kernels with independent models allowed maximal throughput even for small batch sizes, making machine learning pipelines within SQL more competitive.
C1 [Schuele, Maximilian; Lang, Harald; Springer, Maximilian; Kemper, Alfons; Neumann, Thomas; Guennemann, Stephan] Tech Univ Munich, Munich, Germany.
RP Schule, M (corresponding author), Tech Univ Munich, Munich, Germany.
EM m.schuele@tum.de; harald.lang@tum.de; max.springer@tum.de;
   kemper@in.tum.de; neumann@in.tum.de; guennemann@in.tum.de
NR 68
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-8413-1
PY 2020
BP 25
EP 36
DI 10.1145/3468791.3468840
PG 12
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS5ZG
UT WOS:000744484800003
DA 2022-04-17
ER

PT C
AU Burch, R
   Merrick, L
   Zhu, Q
   Honda, T
   David, J
AF Burch, Richard
   Merrick, Luke
   Zhu, Qing
   Honda, Tomonori
   David, Jeff
GP IEEE
TI Applications for Machine Learning in Semiconductor Manufacturing
SO 2021 5TH IEEE ELECTRON DEVICES TECHNOLOGY & MANUFACTURING CONFERENCE
   (EDTM)
LA English
DT Proceedings Paper
CT 5th IEEE Electron Devices Technology and Manufacturing Conference (EDTM)
CY APR 08-11, 2021
CL Chengdu, PEOPLES R CHINA
SP IEEE
DE Manufacturing; FDC; Modeling; Machine Learning; Artificial Intelligence
AB This paper presents a machine learning system for comprehensive root cause analysis of low yielding wafers, enabling rapid reaction to correct problems and identify practical actions to reduce the probability and severity of repeated occurrences of the same root cause.
RI Honda, Tomonori/M-8478-2015
OI Honda, Tomonori/0000-0003-2365-1378
NR 0
TC 0
Z9 0
U1 3
U2 3
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-8176-9
PY 2021
DI 10.1109/EDTM50988.2021.9421052
PG 3
WC Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering
GA BR9HB
UT WOS:000675595800231
DA 2022-04-17
ER

PT J
AU Phan, HC
   Dhar, AS
AF Phan, Hieu Chi
   Dhar, Ashutosh Sutra
TI Predicting pipeline burst pressures with machine learning models
SO INTERNATIONAL JOURNAL OF PRESSURE VESSELS AND PIPING
LA English
DT Article
DE Pipeline integrity; Burst pressure; Machine learning; Random forest;
   Support vector machine; Artificial neural network
AB Establishing an accurate model to predict burst pressure is desired, which has been developed for decades. Although various models have been developed, errors unavoidably appear in the prediction of burst pressures because of the uncertainty in both input variables and nonlinear relationship of such variables to the burst pressure. Consequently, machine learning models, which is a data-driven approach, are potential alternatives. In this paper, various machine learning models such as Random Forest, Support Vector Machine, and Artificial Neural Network are examined to predict the burst pressure, gathering databases available in the literature. The applications of these models are investigated to identify the advantages and limitations of the models. The machine learning models showed a significant improvement in the prediction of the burst pressures compared to the available reference models. However, some drawbacks of the models should be carefully considered, including an increase of error with the unfamiliar data and the fluctuations within the overall trend in the parametric study.
C1 [Phan, Hieu Chi] Le Quy Don Tech Univ, 236 Hoang Quoc Viet, Hanoi 100000, Vietnam.
   [Dhar, Ashutosh Sutra] Mem Univ Newfoundland, Fac Engn & Appl Sci, St John, NF A1B 3X5, Canada.
RP Phan, HC (corresponding author), Le Quy Don Tech Univ, 236 Hoang Quoc Viet, Hanoi 100000, Vietnam.
EM phanchihieu@lqdtu.edu.vn
OI Dhar, Ashutosh/0000-0001-5137-3921; Phan, Hieu Chi/0000-0001-9603-486X
NR 36
TC 3
Z9 4
U1 1
U2 6
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0308-0161
EI 1879-3541
J9 INT J PRES VES PIP
JI Int. J. Pressure Vessels Pip.
PD JUN
PY 2021
VL 191
AR 104384
DI 10.1016/j.ijpvp.2021.104384
EA MAR 2021
PG 11
WC Engineering, Multidisciplinary; Engineering, Mechanical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA RJ9SU
UT WOS:000637947000055
DA 2022-04-17
ER

PT J
AU Lindsay, GW
AF Lindsay, Grace W.
TI Attention in Psychology, Neuroscience, and Machine Learning
SO FRONTIERS IN COMPUTATIONAL NEUROSCIENCE
LA English
DT Review
DE attention; artificial neural networks; machine learning; vision; memory;
   awareness
ID OBJECT-BASED ATTENTION; SELECTIVE ATTENTION; VISUAL-ATTENTION;
   BAYESIAN-INFERENCE; TOP-DOWN; BIASED COMPETITION; MEMORY; MODEL;
   MECHANISMS; CORTEX
AB Attention is the important ability to flexibly control limited computational resources. It has been studied in conjunction with many other topics in neuroscience and psychology including awareness, vigilance, saliency, executive control, and learning. It has also recently been applied in several domains in machine learning. The relationship between the study of biological attention and its use as a tool to enhance artificial neural networks is not always clear. This review starts by providing an overview of how attention is conceptualized in the neuroscience and psychology literature. It then covers several use cases of attention in machine learning, indicating their biological counterparts where they exist. Finally, the ways in which artificial attention can be further inspired by biology for the production of complex and integrative systems is explored.
C1 [Lindsay, Grace W.] UCL, Gatsby Computat Neurosci Unit, Sainsbury Wellcome Ctr, London, England.
RP Lindsay, GW (corresponding author), UCL, Gatsby Computat Neurosci Unit, Sainsbury Wellcome Ctr, London, England.
EM gracewlindsay@gmail.com
FU Marie Sklodowska-Curie Individual Fellowship [844003]; Sainsbury
   Wellcome Centre/Gatsby Computational Unit Fellowship
FX This work was supported by a Marie Sklodowska-Curie Individual
   Fellowship (No. 844003) and a Sainsbury Wellcome Centre/Gatsby
   Computational Unit Fellowship.
NR 170
TC 21
Z9 21
U1 15
U2 26
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-5188
J9 FRONT COMPUT NEUROSC
JI Front. Comput. Neurosci.
PD APR 16
PY 2020
VL 14
AR 29
DI 10.3389/fncom.2020.00029
PG 21
WC Mathematical & Computational Biology; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Mathematical & Computational Biology; Neurosciences & Neurology
GA LL0KK
UT WOS:000531246100001
PM 32372937
OA gold, Green Published
DA 2022-04-17
ER

PT C
AU Byun, T
   Rayadurgam, S
AF Byun, Taejoon
   Rayadurgam, Sanjai
GP IEEE
TI Manifold for Machine Learning Assurance
SO 2020 IEEE/ACM 42ND INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: NEW
   IDEAS AND EMERGING RESULTS (ICSE-NIER 2020)
LA English
DT Proceedings Paper
CT 42nd IEEE/ACM International Conference on Software Engineering: New
   Ideas and Emerging Results (ICSE-NIER)
CY JUN 27-JUL 19, 2020
CL Seoul, SOUTH KOREA
SP IEEE, ACM, ACM SIGSOFT, IEEE Comp Soc, IEEE Tech Council Software Engn
DE machine learning testing; neural networks; variational autoencoder
AB The increasing use of machine-learning (ML) enabled systems in critical tasks fuels the quest for novel verification and validation techniques yet grounded in accepted system assurance principles. In traditional system development, model-based techniques have been widely adopted, where the central premise is that abstract models of the required system provide a sound basis for judging its implementation. We posit an analogous approach for ML systems using an ML technique that extracts from the high-dimensional training data implicitly describing the required system, a low-dimensional underlying structure-a manifold. It is then harnessed for a range of quality assurance tasks such as test adequacy measurement, test input generation, and runtime monitoring of the target ML system. The approach is built on variational autoencoder, an unsupervised method for learning a pair of mutually near-inverse functions between a given high-dimensional dataset and a low-dimensional representation. Preliminary experiments establish that the proposed manifold-based approach, for test adequacy drives diversity in test data, for test generation yields fault-revealing yet realistic test cases, and for run-time monitoring provides an independent means to assess trustability of the target system's output.
C1 [Byun, Taejoon; Rayadurgam, Sanjai] Univ Minnesota, Minneapolis, MN 55455 USA.
RP Byun, T (corresponding author), Univ Minnesota, Minneapolis, MN 55455 USA.
EM taejoon@umn.edu; rsanjai@umn.edu
FU AFRLUnited States Department of DefenseUS Air Force Research Laboratory;
   DARPAUnited States Department of DefenseDefense Advanced Research
   Projects Agency (DARPA) [FA8750-18-C-0099]
FX This work was supported by AFRL and DARPA under contract
   FA8750-18-C-0099.
NR 16
TC 4
Z9 4
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
BN 978-1-4503-7126-1
PY 2020
BP 97
EP 100
DI 10.1145/3377816.3381734
PG 4
WC Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR8AT
UT WOS:000670587700025
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Rajendra, P
   Naidu, TG
   Brahmajirao, V
AF Rajendra, P.
   Naidu, T. Gunavardhana
   Brahmajirao, V.
TI MODELING OF DYNAMICAL SYSTEMS THROUGH MACHINE LEARNING
SO ADVANCES AND APPLICATIONS IN MATHEMATICAL SCIENCES
LA English
DT Article
DE dynamical systems; machine learning; dimensionality reduction; dynamic
   mode decomposition
ID DECOMPOSITION
AB This review presents the key challenges of discovering dynamics from data and finding data-driven representations that make nonlinear systems amenable to linear analysis. Data-driven models drive to discover the governing equations and give laws of physics. The identification of dynamical systems through machine learning techniques succeeds in inferring physical systems. The two chief challenges are nonlinear dynamics and unknown or partially known dynamics. Machine learning is providing new and powerful techniques for both challenges. Dimensionality reduction methods are used for projecting dynamical methods in reduced form and these methods perform computational efficiency on real-world data.
C1 [Rajendra, P.] CMR Inst Technol, Dept Math, Bengaluru, Karnataka, India.
   [Naidu, T. Gunavardhana] Aditya Inst Technol & Management, Dept Phys, Srikakulam, Andhra Pradesh, India.
   [Brahmajirao, V.] DSR Fdn, Sch Biotechnol MGNIRSA, Hyderabad, Telangana, India.
RP Rajendra, P (corresponding author), CMR Inst Technol, Dept Math, Bengaluru, Karnataka, India.
EM rajendra.padidhapu@gmail.com
NR 33
TC 0
Z9 0
U1 1
U2 1
PU MILI PUBL
PI ALLAHABAD
PA 422B CHAK RAGHUNATH, NEAR RAILWAY CROSSING, ALLAHABAD, 211 008, INDIA
SN 0974-6803
J9 ADV APPL MATH SCI
JI Adv. Appl. Math. Sci.
PD SEP
PY 2021
VL 20
IS 11
BP 2635
EP 2644
PG 10
WC Mathematics
WE Emerging Sources Citation Index (ESCI)
SC Mathematics
GA YJ5KG
UT WOS:000744570500019
DA 2022-04-17
ER

PT J
AU Mathur, P
   Srivastava, S
   Xu, XW
   Mehta, JL
AF Mathur, Pankaj
   Srivastava, Shweta
   Xu, Xiaowei
   Mehta, Jawahar L.
TI Artificial Intelligence, Machine Learning, and Cardiovascular Disease
SO CLINICAL MEDICINE INSIGHTS-CARDIOLOGY
LA English
DT Review
DE AI; machine learning; big data; precision medicine; cardiovascular
   disease
ID HEART-FAILURE; PHARMACOGENOMICS; DIAGNOSIS; CLASSIFICATION; CARDIOLOGY;
   ARTERY; GAME
AB Artificial intelligence (AI)-based applications have found widespread applications in many fields of science, technology, and medicine. The use of enhanced computing power of machines in clinical medicine and diagnostics has been under exploration since the 1960s. More recently, with the advent of advances in computing, algorithms enabling machine learning, especially deep learning networks that mimic the human brain in function, there has been renewed interest to use them in clinical medicine. In cardiovascular medicine, AI-based systems have found new applications in cardiovascular imaging, cardiovascular risk prediction, and newer drug targets. This article aims to describe different AI applications including machine learning and deep learning and their applications in cardiovascular medicine. AI-based applications have enhanced our understanding of different phenotypes of heart failure and congenital heart disease. These applications have led to newer treatment strategies for different types of cardiovascular diseases, newer approach to cardiovascular drug therapy and postmarketing survey of prescription drugs. However, there are several challenges in the clinical use of AI-based applications and interpretation of the results including data privacy, poorly selected/outdated data, selection bias, and unintentional continuance of historical biases/stereotypes in the data which can lead to erroneous conclusions. Still, AI is a transformative technology and has immense potential in health care.
C1 [Mathur, Pankaj] Univ Arkansas Med Sci, Dept Internal Med, Little Rock, AR 72205 USA.
   [Srivastava, Shweta] Univ Arkansas Med Sci, Dept Radiol, Little Rock, AR 72205 USA.
   [Xu, Xiaowei] Univ Arkansas, Dept Informat Sci, Little Rock, AR 72204 USA.
   [Mehta, Jawahar L.] Univ Arkansas Med Sci, Div Cardiol, Dept Internal Med, Little Rock, AR 72205 USA.
RP Mehta, JL (corresponding author), Univ Arkansas Med Sci, Div Cardiol, Dept Internal Med, Little Rock, AR 72205 USA.
EM mehtajl@uams.edu
NR 56
TC 14
Z9 15
U1 8
U2 16
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1179-5468
J9 CLIN MED INSIGHTS-CA
JI Clin. Med. Insights-Cardiol.
PD SEP
PY 2020
VL 14
AR 1179546820927404
DI 10.1177/1179546820927404
PG 9
WC Cardiac & Cardiovascular Systems
WE Emerging Sources Citation Index (ESCI)
SC Cardiovascular System & Cardiology
GA NM8PY
UT WOS:000568356000001
PM 32952403
OA gold, Green Published
DA 2022-04-17
ER

PT J
AU Bickler, SH
AF Bickler, Simon H.
TI Machine Learning Arrives in Archaeology
SO ADVANCES IN ARCHAEOLOGICAL PRACTICE
LA English
DT Review
DE machine learning; transfer learning; heritage management;
   classification; neural networks
ID NEURAL-NETWORKS; CLASSIFICATION; RECOGNITION; PROSPECTION; POTTERY
AB Machine learning (ML) is rapidly being adopted by archaeologists interested in analyzing a range of geospatial, material cultural, textual, natural, and artistic data. The algorithms are particularly suited toward rapid identification and classification of archaeological features and objects. The results of these new studies include identification of many new sites around the world and improved classification of large archaeological datasets. ML fits well with more traditional methods used in archaeological analysis, and it remains subject to both the benefits and difficulties of those approaches. Small datasets associated with archaeological work make ML vulnerable to hidden complexity, systemic bias, and high validation costs if not managed appropriately. ML's scalability, flexibility, and rapid development, however, make it an essential part of twenty-first-century archaeological practice. This review briefly describes what ML is, how it is being used in archaeology today, and where it might be used in the future for archaeological purposes.
C1 [Bickler, Simon H.] Bickler Consultants Ltd, 1-623 Manukau Rd, Auckland 1023, New Zealand.
RP Bickler, SH (corresponding author), Bickler Consultants Ltd, 1-623 Manukau Rd, Auckland 1023, New Zealand.
EM arch@bickler.co.nz
NR 57
TC 4
Z9 4
U1 2
U2 5
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 2326-3768
J9 ADV ARCHAEOL PRACT
JI Adv. Archaeol. Pract.
PD MAY
PY 2021
VL 9
IS 2
BP 186
EP 191
DI 10.1017/aap.2021.6
PG 6
WC Archaeology
WE Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Archaeology
GA SE6PR
UT WOS:000652193800009
OA Bronze
DA 2022-04-17
ER

PT J
AU Cong, WX
   Xi, Y
   De Man, B
   Wang, G
AF Cong, Wenxiang
   Xi, Yan
   De Man, Bruno
   Wang, Ge
TI Monochromatic image reconstruction via machine learning
SO MACHINE LEARNING-SCIENCE AND TECHNOLOGY
LA English
DT Article
DE computed tomography (CT); radon transform; monochromatic image
   reconstruction; machine learning
ID DUAL-ENERGY CT; TOMOGRAPHY PHYSICAL PRINCIPLES; USAGE
AB X-ray computed tomography (CT) is a nondestructive imaging technique to reconstruct cross-sectional images of an object using x-ray measurements taken from different view angles for medical diagnosis, therapeutic planning, security screening, and other applications. In clinical practice, the x-ray tube emits polychromatic x-rays, and the x-ray detector array operates in the energy-integrating mode to acquire energy intensity. This physical process of x-ray imaging is accurately described by an energy-dependent non-linear integral equation on the basis of the Beer-Lambert law. However, the non-linear model is not invertible using a computationally efficient solution and is often approximated as a linear integral model in the form of the Radon transform, which basically loses energy-dependent information. This approximate model produces an inaccurate quantification of attenuation images, suffering from beam-hardening effects. In this paper, a machine learning-based approach is proposed to correct the model mismatch to achieve quantitative CT imaging. Specifically, a one-dimensional network model is proposed to learn a non-linear transform from a training dataset to map a polychromatic CT image to its monochromatic sinogram at a pre-specified energy level, realizing virtual monochromatic (VM) imaging effectively and efficiently. Our results show that the proposed method recovers high-quality monochromatic projections with an average relative error of less than 2%. The resultant x-ray VM imaging can be applied for beam-hardening correction, material differentiation and tissue characterization, and proton therapy treatment planning.
C1 [Cong, Wenxiang; Wang, Ge] Rensselaer Polytech Inst, Dept Biomed Engn, Biomed Imaging Ctr, Troy, NY 12180 USA.
   [Xi, Yan] Shanghai First Imaging Tech, Shanghai, Peoples R China.
   [De Man, Bruno] GE Res, One Res Circle, Niskayuna, NY 12309 USA.
RP Cong, WX (corresponding author), Rensselaer Polytech Inst, Dept Biomed Engn, Biomed Imaging Ctr, Troy, NY 12180 USA.
EM congw@rpi.edu
OI Wang, Ge/0000-0002-2656-7705
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01CA237267,
   R01EB026646, R01CA233888, R01HL151561]; Shanghai Ruijin Hospital, China
FX This work was supported by National Institutes of Health Grants
   R01CA237267, R01EB026646, R01CA233888, and R01HL151561. The authors
   would like to thank Shanghai Ruijin Hospital, China, for providing the
   dual-energy dataset.
NR 32
TC 1
Z9 1
U1 4
U2 6
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
EI 2632-2153
J9 MACH LEARN-SCI TECHN
JI Mach. Learn.-Sci. Technol.
PD JUN
PY 2021
VL 2
IS 2
AR 025032
DI 10.1088/2632-2153/abdbff
PG 12
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Science & Technology - Other Topics
GA SR2IM
UT WOS:000660867100001
OA gold
DA 2022-04-17
ER

PT J
AU Mihaljevic, B
   Bielza, C
   Larranaga, P
AF Mihaljevic, Bojan
   Bielza, Concha
   Larranaga, Pedro
TI Bayesian networks for interpretable machine learning and optimization
SO NEUROCOMPUTING
LA English
DT Article
DE Interpretability; Explainable machine learning; Probabilistic graphical
   models
ID MARKOV BLANKET INDUCTION; GABAERGIC INTERNEURONS; HUMAN BRAIN;
   PROBABILISTIC INFERENCE; FEATURE-SELECTION; CAUSAL DISCOVERY;
   DECISION-MAKING; BELIEF NETWORKS; LOCAL CAUSAL; CLASSIFICATION
AB As artificial intelligence is being increasingly used for high-stakes applications, it is becoming more and more important that the models used be interpretable. Bayesian networks offer a paradigm for inter-pretable artificial intelligence that is based on probability theory. They provide a semantics that enables a compact, declarative representation of a joint probability distribution over the variables of a domain by leveraging the conditional independencies among them. The representation consists of a directed acyclic graph that encodes the conditional independencies among the variables and a set of parameters that encodes conditional distributions. This representation has provided a basis for the development of algo-rithms for probabilistic reasoning (inference) and for learning probability distributions from data. Bayesian networks are used for a wide range of tasks in machine learning, including clustering, super -vised classification, multi-dimensional supervised classification, anomaly detection, and temporal mod-eling. They also provide a basis for estimation of distribution algorithms, a class of evolutionary algorithms for heuristic optimization. We illustrate the use of Bayesian networks for interpretable machine learning and optimization by presenting applications in neuroscience, the industry, and bioin-formatics, covering a wide range of machine learning and optimization tasks. (c) 2021 Published by Elsevier B.V.
C1 [Mihaljevic, Bojan] Univ Autonoma Madrid, Dept Matemat, Madrid, Spain.
   [Bielza, Concha; Larranaga, Pedro] Univ Politecn Madrid, Madrid, Spain.
RP Mihaljevic, B (corresponding author), Univ Autonoma Madrid, Dept Matemat, Madrid, Spain.
EM bojan.mihaljevic@uam.es
RI Larranaga, Pedro/F-9293-2013; Mihaljevic, Bojan/X-6153-2018
OI Larranaga, Pedro/0000-0003-0652-9872; Mihaljevic,
   Bojan/0000-0002-1656-6135
FU Spanish Ministry of Economy and CompetitivenessSpanish Government
   [TIN2016-79684-P]; Spanish Ministry of Science, Innovation and
   UniversitiesSpanish Government [PID2019-109247GB-I00]; BBVA
   FoundationBBVA Foundation; European UnionEuropean Commission [945539]
FX This work has been partially supported by the Spanish Ministry of
   Economy and Competitiveness through the TIN2016-79684-P project and the
   Spanish Ministry of Science, Innovation and Universities through the
   PID2019-109247GB-I00 project, by the BBVA Foundation (2019 Call) through
   the "Scorebased nonstationary temporal Bayesian networks. Applications
   in climate and neuroscience" project, the BBVA Foundation's grants (2020
   Call) for Scientific Investigation Teams SARSCoV2 and COVID-19 through
   the "Outcome prediction and treatment efficiency in patients
   hospitalized with Covid19 in Madrid: A Bayesian network
   approach"project, and European Union's Horizon 2020 Framework Programme
   for Research and Innovation under the Specific Grant Agreement N. 945539
   (Human Brain Project SGA3) .
NR 165
TC 1
Z9 1
U1 8
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD OCT 7
PY 2021
VL 456
BP 648
EP 665
DI 10.1016/j.neucom.2021.01.138
EA AUG 2021
PG 18
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA UD8SV
UT WOS:000687473600006
DA 2022-04-17
ER

PT C
AU Mangold, B
   Stubinger, J
AF Mangold, Benedikt
   Stuebinger, Johannes
BE Domenech, J
   Vicente, MR
TI Investigating inefficiencies of bookmaker odds in football using machine
   learning
SO 3RD INTERNATIONAL CONFERENCE ON ADVANCED RESEARCH METHODS AND ANALYTICS
   (CARMA 2020)
LA English
DT Proceedings Paper
CT 3rd International Conference on Advanced Research Methods and Analytics
   (CARMA)
CY JUL 08-09, 2020
CL Univ Politecnica Valencia, ELECTR NETWORK
SP Univ Politecnica Valencia, Fac Adm & Direccion Empresas, Dept Economia & Ciencias Sociales, DevStat
HO Univ Politecnica Valencia
DE Machine Learning; Football
AB The efficient-market hypothesis states that it is impossible to beat the market, as the price reflects all available information. Applied to bookmaker odds for football games, there should not be a systematic way of winning money on the long run. However, we show that by using simple machine learning models we can systematically outperform the markets belief manifested through the bookmakers odds. The effect of this inefficiency is diminishing over time, which indicates that the knowledge that has been derived from and the pure amount of the data is also reflected in the odds in recent times.
   We give some insights how this effect differs across major football leagues in Europe, which algorithms are performing best and statistics on the ROI using machine learning in football betting. Additionally, we share how the simulation study has been designed in more detail.
C1 [Mangold, Benedikt] GfK, Nurnberg, Germany.
   [Stuebinger, Johannes] Univ Erlangen Nurnberg, Dept Stat & Econometr, Erlangen, Germany.
RP Mangold, B (corresponding author), GfK, Nurnberg, Germany.
NR 5
TC 0
Z9 0
U1 0
U2 0
PU UNIV POLITECNICA VALENCIA
PI VALENCIA
PA CAMINO VERA S-N, VALENCIA, 46022, SPAIN
BN 978-84-9048-832-4
PY 2020
BP 173
EP 179
DI 10.4995/CARMA2020.2020.11619
PG 7
WC Business; Computer Science, Interdisciplinary Applications; Information
   Science & Library Science
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Business & Economics; Computer Science; Information Science & Library
   Science
GA BS7DW
UT WOS:000759227700019
OA Bronze, Green Published
DA 2022-04-17
ER

PT J
AU Wu, JQ
   Sun, YT
   Wang, WH
   Li, MZ
AF Wu Jiaqi
   Sun Yitao
   Wang WeiHua
   Li MaoZhi
TI Application of machine learning approach in disordered materials
SO SCIENTIA SINICA-PHYSICA MECHANICA & ASTRONOMICA
LA Chinese
DT Review
DE machine learning; disordered materials; glass-forming ability;
   structure-property relationships
ID POTENTIAL-ENERGY SURFACES; NEURAL-NETWORKS; DISCOVERY; MODEL
AB As a new amorphous material, metallic glass has been widely studied because of its excellent mechanical, physical and chemical properties. Glass-forming ability has always been an important problem restricting the development of amorphous materials. In order to design amorphous materials with good glass-forming ability, a lot of research has been done on the glass-forming ability of amorphous materials. It has been shown that a single factor cannot describe glassforming ability of amorphous materials. Because of the complex and disordered structure of amorphous materials, it is difficult to understand the structure and nature of amorphous materials comprehensively and clearly by traditional methods. Machine learning method, as a new research paradigm, provides new opportunities for exploring these bottleneck scientific issues in disordered materials. In this paper, some machine learning algorithms, such as support vector machine, artificial neural network and K-means clustering, are briefly introduced. Moreover, we briefly review the application of machine learning approach in amorphous materials, including the classification of amorphous structure, the correlation between amorphous structure and properties, and the prediction of macroscopic properties of amorphous materials. We also discuss the future application of machine learning approach to disordered materials, including the development of comprehensive database, high throughput calculation method and the development of machine learning potential function.
C1 [Wu Jiaqi; Li MaoZhi] Renmin Univ China, Beijing Key Lab Optoelect Funct Mat & Micronano D, Dept Phys, Beijing 100872, Peoples R China.
   [Sun Yitao; Wang WeiHua] Chinese Acad Sci, Inst Phys, Beijing 100190, Peoples R China.
RP Li, MZ (corresponding author), Renmin Univ China, Beijing Key Lab Optoelect Funct Mat & Micronano D, Dept Phys, Beijing 100872, Peoples R China.
EM maozhili@ruc.edu.cn
RI Li, Maozhi/AAL-9540-2021
NR 67
TC 1
Z9 1
U1 4
U2 17
PU SCIENCE PRESS
PI BEIJING
PA 16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100717, PEOPLES R CHINA
SN 1674-7275
EI 2095-9478
J9 SCI SIN-PHYS MECH AS
JI Sci. Sin.-Phys. Mech. Astron.
PY 2020
VL 50
IS 6
AR 067002
DI 10.1360/SSPMA-2019-0345
PG 14
WC Astronomy & Astrophysics; Physics, Multidisciplinary
WE Emerging Sources Citation Index (ESCI)
SC Astronomy & Astrophysics; Physics
GA MA6ZW
UT WOS:000542063800007
OA Bronze
DA 2022-04-17
ER

PT C
AU Sravya, V
   Malathi, S
AF Sravya, V
   Malathi, S.
GP IEEE
TI Survey on Brain Tumor Detection using Machine Learning and Deep Learning
SO 2021 INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND INFORMATICS
   (ICCCI)
SE International Conference on Computer Communication and Informatics
LA English
DT Proceedings Paper
CT 11th International Conference of Computer Communication and Informatics
   (ICCCI)
CY JAN 27-29, 2021
CL Sri Shakthi Inst Engn & Technol, Coimbatore, INDIA
HO Sri Shakthi Inst Engn & Technol
DE Brain tumour; Machine Learning; Deep Learning
ID SEGMENTATION; IMAGES
AB Abnormal growth of cell in brain is known as Brain tumor. Some are benign and some are malignant. Brain tumor can start in brain or it can spread from any part of the body and this is one of deadly cancers across all ages. Major challenge in identifying brain tumor is isolation of abnormal cell. Early detection of brain tumor and its grade is very essential to provide appropriate service. Non invasive methodology of MR has made researches more inclined towards MR images. Medical Image processing was extensively used for more than a decade on MR images to detect tumor by applying segmentation and classification. Though there are many advantages with automated classification, still major challenges hover due to various grades, various shapes, various size and area. Over a decade researches had made giant leaps using combinations of various techniques in extraction, segmentation and classification. With advances technology of Machine Learning and Deep Learning the classification accuracy has gone higher. Here we present study of various techniques used for identifying and classifying brain tumors.
C1 [Sravya, V; Malathi, S.] Panimalar Engn Coll, ME CSE, Chennai, Tamil Nadu, India.
RP Sravya, V (corresponding author), Panimalar Engn Coll, ME CSE, Chennai, Tamil Nadu, India.
EM sravya.krupakar@gmail.com; malathi.raghuram@gmail.com
NR 20
TC 0
Z9 0
U1 4
U2 5
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2329-7190
BN 978-1-7281-5875-4
J9 INT CONF COMP COMMUN
PY 2021
DI 10.1109/ICCCI50826.2021.9457019
PG 3
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Telecommunications
GA BR8DI
UT WOS:000670971000252
DA 2022-04-17
ER

PT J
AU Maric, I
   Tsur, A
   Aghaeepour, N
   Montanari, A
   Stevenson, DK
   Shaw, GM
   Winn, VD
AF Maric, Ivana
   Tsur, Abraham
   Aghaeepour, Nima
   Montanari, Andrea
   Stevenson, David K.
   Shaw, Gary M.
   Winn, Virginia D.
TI Early prediction of preeclampsia via machine learning
SO AMERICAN JOURNAL OF OBSTETRICS & GYNECOLOGY MFM
LA English
DT Article
DE early prediction of preeclampsia; elastic net; gradient boosting
   algorithm; machine learning; preeclampsia; statistical learning
ID UTERINE ARTERY DOPPLER; 1ST-TRIMESTER PREDICTION; HYPERTENSIVE
   DISORDERS; MATERNAL FACTORS; RISK-FACTORS; PAPP-A; PREGNANCY;
   REGRESSION; MODEL; SELECTION
AB BACKGROUND: Early prediction of preeclampsia is challenging because of poorly understood causes, various risk factors, and likely multiple pathogenic phenotypes of preeclampsia. Statistical learning methods are well-equipped to deal with a large number of variables, such as patients' clinical and laboratory data, and to select the most informative features automatically.
   OBJECTIVE: Our objective was to use statistical learning methods to analyze all available clinical and laboratory data that were obtained during routine prenatal visits in early pregnancy and to use them to develop a prediction model for preeclampsia.
   STUDY DESIGN: This was a retrospective cohort study that used data from 16,370 births at Lucile Packard Children Hospital at Stanford, CA, from April 2014 to January 2018. Two statistical learning algorithms were used to build a predictive model: (1) elastic net and (2) gradient boosting algorithm. Models for all preeclampsia and early-onset preeclampsia (<34 weeks gestation) were fitted with the use of patient data that were available at <16 weeks gestational age. The 67 variables that were considered in the models included maternal characteristics, medical history, routine prenatal laboratory results, and medication intake. The area under the receiver operator curve, true-positive rate, and false-positive rate were assessed via cross-validation.
   RESULTS: Using the elastic net algorithm, we developed a prediction model that contained a subset of the most informative features from all variables. The obtained prediction model for preeclampsia yielded an area under the curve of 0.79 (95% confidence interval, 0.75-0.83), sensitivity of 45.2%, and false-positive rate of 8.1%. The prediction model for early-onset preeclampsia achieved an area under the curve of 0.89 (95% confidence interval, 0.84-0.95), true-positive rate of 72.3%, and false-positive rate of 8.8%.
   CONCLUSION: Statistical learning methods in a retrospective cohort study automatically identified a set of significant features for prediction and yielded high prediction performance for preeclampsia risk from routine early pregnancy information.
C1 [Maric, Ivana; Stevenson, David K.; Shaw, Gary M.] Stanford Univ, Dept Pediat, Sch Med, Stanford, CA 94305 USA.
   [Aghaeepour, Nima] Stanford Univ, Dept Anesthesiol Perioperat & Pain Med, Sch Med, Stanford, CA 94305 USA.
   [Tsur, Abraham; Winn, Virginia D.] Stanford Univ, Dept Obstet & Gynecol, Sch Med, Stanford, CA 94305 USA.
   [Montanari, Andrea] Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA.
   [Montanari, Andrea] Stanford Univ, Dept Stat, Stanford, CA 94305 USA.
   [Tsur, Abraham] Sheba Med Ctr, Dept Obstet & Gynecol, Tel Hashomer, Israel.
RP Maric, I (corresponding author), Stanford Univ, Dept Pediat, Sch Med, Stanford, CA 94305 USA.
EM ivanam@stanford.edu
OI Winn, Virginia/0000-0003-1136-2907; Shaw, Gary/0000-0001-7438-4914
FU March of Dimes Prematurity Research Center at Stanford University School
   of Medicine; Burroughs Wellcome Fund's Preterm Birth Initiative; MCHRI
   Award New Ideas for Mid/Senior Investigators "Early Prediction of
   Preeclampsia via Machine Learning" grant; National Institutes of
   HealthUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [1R01HL139844]
FX Supported by the March of Dimes Prematurity Research Center at Stanford
   University School of Medicine, the Burroughs Wellcome Fund's Preterm
   Birth Initiative, MCHRI Award New Ideas for Mid/Senior Investigators
   "Early Prediction of Preeclampsia via Machine Learning" grant, and the
   National Institutes of Health, grant 1R01HL139844.
NR 56
TC 3
Z9 3
U1 4
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2589-9333
J9 AM J OBST GYNEC MFM
JI Amer. J. Obstet. Gynecol. MFM
PD MAY
PY 2020
VL 2
IS 2
AR 100100
DI 10.1016/j.ajogmf.2020.100100
PG 17
WC Obstetrics & Gynecology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Obstetrics & Gynecology
GA SN3VR
UT WOS:000658221800016
PM 33345966
DA 2022-04-17
ER

PT C
AU Batool, T
   Abuelnoor, M
   El Boutari, O
   Aloul, F
   Sagahyroon, A
AF Batool, Tasneem
   Abuelnoor, Mostafa
   El Boutari, Omar
   Aloul, Fadi
   Sagahyroon, Assim
GP IEEE
TI Predicting Hospital No-Shows Using Machine Learning
SO 2020 IEEE INTERNATIONAL CONFERENCE ON INTERNET OF THINGS AND
   INTELLIGENCE SYSTEM (IOTAIS)
LA English
DT Proceedings Paper
CT IEEE International Conference on Internet of Things and Intelligence
   System (IoTaIS)
CY JAN 27-28, 2021
CL ELECTR NETWORK
SP IEEE, Telkom Univ, IEEE Commun Soc, Indonesia Chapter
DE no-shows; machine learning; appointments
AB All over the globe, significant amounts of patients miss their appointments without cancelling in time or even cancelling at all, resulting in billions of dollars wasted yearly due to increased idle time, overtime and waiting time that the other patients and hospitals face. Hospitals are actively trying to implement methods to try to reduce the idle time caused by patient no-shows by using overbooking and reminder systems. However, these two methods can be very costly. Overbooking can lead to patient dissatisfaction and constant personalized reminders, such as phone calls, to every patient can be annoying and costly in terms of manpower. This paper focuses on offering a solution which mitigates the global phenomenon of medical no-shows by creating a machine learning model using existing patient datasets to discover patterns and relationships between multiple patient variables and their tendency to miss appointments. Therefore, the likelihood of a patient showing up, given their information, may be predicted. The machine learning model used to form the solution predictive model is based on the decision tree classification algorithm. Furthermore, a scheduling system was implemented such that the overall model detects whether a patient has a risk of missing an appointment with a 95% accuracy, upon which it automatically enables the risky patient's schedule slot for overbooking and notifies medical staff or administration to contact them accordingly.
C1 [Batool, Tasneem; Abuelnoor, Mostafa; El Boutari, Omar; Aloul, Fadi; Sagahyroon, Assim] Amer Univ Sharjah, Dept Comp Sci & Engn, Sharjah, U Arab Emirates.
RP Batool, T (corresponding author), Amer Univ Sharjah, Dept Comp Sci & Engn, Sharjah, U Arab Emirates.
EM g00071143@aus.edu; b00069562@aus.edu; b00063858@aus.edu; faloul@aus.edu;
   asagahyroon@aus.edu
NR 16
TC 2
Z9 2
U1 8
U2 14
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-9448-6
PY 2021
BP 142
EP 148
DI 10.1109/IoTaIS50849.2021.9359692
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Telecommunications
GA BR8BB
UT WOS:000670599800024
DA 2022-04-17
ER

PT C
AU Verbruggen, G
   Van Wolputte, E
   Dumancic, S
   De Raedt, L
AF Verbruggen, Gust
   Van Wolputte, Elia
   Dumancic, Sebastijan
   De Raedt, Luc
BE Abreu, PH
   Rodrigues, PP
   Fernandez, A
   Gama, J
TI AVATAR-Automated Feature Wrangling for Machine Learning
SO ADVANCES IN INTELLIGENT DATA ANALYSIS XIX, IDA 2021
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 19th International Symposium on Intelligent Data Analysis (IDA)
CY APR 26-28, 2021
CL ELECTR NETWORK
DE Data wrangling; Program synthesis; Machine learning
AB A large part of the time invested in data science is spent on manual preparation of data. Transforming wrongly formatted columns into useful features takes up a significant part of this time. We present the avatar algorithm for automatically learning programs that perform this type of feature wrangling. Instead of relying on users to guide the wrangling process, avatar directly uses the predictive performance of machine learning models to measure its progress during wrangling. We use datasets from Kaggle to show that avatar improves raw data for prediction, and square it off against human data scientists.
C1 [Verbruggen, Gust; Van Wolputte, Elia; Dumancic, Sebastijan; De Raedt, Luc] Katholieke Univ Leuven, Dept Comp Sci, Leuven, Belgium.
   [Verbruggen, Gust; Van Wolputte, Elia; Dumancic, Sebastijan; De Raedt, Luc] Leuven AI KU Leuven Inst AI, Leuven, Belgium.
RP Verbruggen, G (corresponding author), Katholieke Univ Leuven, Dept Comp Sci, Leuven, Belgium.; Verbruggen, G (corresponding author), Leuven AI KU Leuven Inst AI, Leuven, Belgium.
EM gust.verbruggen@kuleuven.be; eliavan.wolputte@kuleuven.be;
   sebastijan.dumancic@kuleuven.be; lucde.raedt@kuleuven.be
OI De Raedt, Luc/0000-0002-6860-6303; Van Wolputte,
   Elia/0000-0002-6502-0809
FU European Research Council (ERC) under the European UnionEuropean
   Research Council (ERC) [694980]; Flemish Government (AI Research
   Program); Research Foundation-Flanders (FWO)FWO
FX This work has received funding from the European Research Council (ERC)
   under the European Union's Horizon 2020 research and innovation
   programme (grant agreement No [694980] SYNTH: Synthesising Inductive
   Data Models). This research received funding from the Flemish Government
   (AI Research Program). Sebastijan Dumancic is funded by the Research
   Foundation-Flanders (FWO).
NR 18
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-74251-5; 978-3-030-74250-8
J9 LECT NOTES COMPUT SC
PY 2021
VL 12695
BP 235
EP 247
DI 10.1007/978-3-030-74251-5_19
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS4UP
UT WOS:000722625800019
OA Green Accepted
DA 2022-04-17
ER

PT C
AU Sawan, A
   Jayousi, R
AF Sawan, Aktham
   Jayousi, Rashid
GP IEEE
TI Machine Learning Approaches to Predict New Mobile Internet Customers
SO 2020 IEEE 14TH INTERNATIONAL CONFERENCE ON APPLICATION OF INFORMATION
   AND COMMUNICATION TECHNOLOGIES (AICT2020)
SE International Conference on Application of Information and Communication
   Technologies
LA English
DT Proceedings Paper
CT 14th IEEE International Conference on Application of Information and
   Communication Technologies (AICT)
CY OCT 07-09, 2020
CL ELECTR NETWORK
SP IEEE, ADA University, Tashkent Univ Informat Technologies
DE Python; Machine learning; XGBoost; Data Mining; Deep learning; Mobile
   Internet; Telecommunication
AB Globalization and liberalization of the economy dramatically shifted the nature of business competition. The emergence of new technology in business operations has intensified rivalry and generated new opportunities for service providers. In order to deal with increasing situations, businesses are turning their focus to maintaining current clients rather than acquiring new ones. This is more cost-effective and therefore needs fewer energy. In this article, future mobile internet customers are investigated on the basis of machine learning and deep learning strategies applied to consumer activity and usage knowledge, which can assist new mobile internet customers. This paper utilized consumer usage and similar knowledge from a telephone service provider to examine mobile internet customers in the telecommunications industry. XGBoost and Random Forest the decision tree ensembles are used as basic statistical machine learning models for the development of a binary mobile internet classifier. The implementation component was developed using Python, a state-of-the-art structured data processing platform for machine learning and data mining. Many ML and deep learning approaches such as (K-Nearest Neighbors KNN, logistic regression, Support Vector Machine SVM, and Deep Neural Network DNN) have been tested to achieve greater and more successful outcomes and results.
C1 [Sawan, Aktham; Jayousi, Rashid] Al Quds Univ, Dept Comp Sci, Jerusalem, Palestine.
RP Jayousi, R (corresponding author), Al Quds Univ, Dept Comp Sci, Jerusalem, Palestine.
EM Rjayousi@staff.alquds.edu
OI sawan, aktham/0000-0002-2840-6024
NR 10
TC 0
Z9 0
U1 1
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2378-8232
EI 2472-8586
BN 978-1-7281-7386-3
J9 I C APPL INF COMM TE
PY 2020
DI 10.1109/AICT50176.2020.9368770
PG 6
WC Computer Science, Theory & Methods; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Telecommunications
GA BS2JF
UT WOS:000702043900063
DA 2022-04-17
ER

PT J
AU Cil, B
   Ayyildiz, H
   Tuncer, T
AF Cil, Betul
   Ayyildiz, Hakan
   Tuncer, Taner
TI Discrimination of beta-thalassemia and iron deficiency anemia through
   extreme learning machine and regularized extreme learning machine based
   decision support system
SO MEDICAL HYPOTHESES
LA English
DT Article
DE Extreme Learning Machines (ELM); beta-Thalassemia; Iron deficiency
   anemia; Machine learning
ID DIFFERENTIATION; INDEXES; MODELS; TRAIT
AB The symptoms of Iron Deficiency Anemia (IDA) and beta-thalassemia (beta-TT) disease are similar and the distinction between them is time consuming and costly. There are several indices used to differentiate IDA from beta-thalassemia disease. Complete Blood Count (CBC) is a rapid, inexpensive and accessible test for the diagnosis of anemia and is used as a primary test. However, since CBC cannot fully distinguish between IDA and beta-thalassemia, more advanced testing is required. These tests are not available in small centers and are performed on higher-cost devices. Moreover, it is important to differentiate between anemia and beta-thalassemia medically for two reasons (IDA). First, if a patient with beta-Thalassemia is diagnosed with IDA, the patient is given unnecessary iron supplementation as a result of the treatment, which is recommended by the doctor. Secondly, when the patient with beta-thalassemia is diagnosed with IDA, children will have beta-thalassemia patients in marriages. A decision support system to distinguish between beta-Thalassemia and IDA has been developed. Logistic Regression, K-Nearest Neighbours, Support Vector Machine, Extreme Learning Machine and Regularized Extreme Learning Machine classification algorithms were used in the proposed system. Classification performance was evaluated with Accuracy, sensitivity, f-measure, Specificty parameters using Hemoglobin, RBC, HCT, MCV, MCH, MCHC and RDW parameters obtained from 342 patients. 96.30% accuracy for female, 94.37% for male, and 95.59% in co-evaluation of male and female patients were obtained.
C1 [Cil, Betul; Tuncer, Taner] Firat Univ, Dept Comp Engn, TR-23119 Elazig, Turkey.
   [Ayyildiz, Hakan] Fethi Sekin Hosp, Dept Biochem, Elazig, Turkey.
RP Tuncer, T (corresponding author), Firat Univ, Dept Comp Engn, TR-23119 Elazig, Turkey.
EM hakan.ayyildiz1@saglik.gov.tr; ttuncer@firat.edu.tr
RI AYYILDIZ, hakan/AAG-7493-2019
OI AYYILDIZ, hakan/0000-0002-3133-9862
NR 32
TC 5
Z9 5
U1 3
U2 10
PU CHURCHILL LIVINGSTONE
PI EDINBURGH
PA JOURNAL PRODUCTION DEPT, ROBERT STEVENSON HOUSE, 1-3 BAXTERS PLACE,
   LEITH WALK, EDINBURGH EH1 3AF, MIDLOTHIAN, SCOTLAND
SN 0306-9877
EI 1532-2777
J9 MED HYPOTHESES
JI Med. Hypotheses
PD MAY
PY 2020
VL 138
AR 109611
DI 10.1016/j.mehy.2020.109611
PG 6
WC Medicine, Research & Experimental
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Research & Experimental Medicine
GA LA0JA
UT WOS:000523642300012
PM 32036196
DA 2022-04-17
ER

PT J
AU Lai, JP
   Chang, YM
   Chen, CH
   Pai, PF
AF Lai, Jung-Pin
   Chang, Yu-Ming
   Chen, Chieh-Huang
   Pai, Ping-Feng
TI A Survey of Machine Learning Models in Renewable Energy Predictions
SO APPLIED SCIENCES-BASEL
LA English
DT Review
DE renewable energy; machine learning; prediction
ID CONVOLUTIONAL NEURAL-NETWORK; DIFFUSE SOLAR-RADIATION; TIME-SERIES
   PREDICTION; SUPPORT VECTOR MACHINE; TERM WIND-SPEED; FORECASTING MODELS;
   FEATURE-SELECTION; GAUSSIAN PROCESS; BIOMASS GASIFICATION;
   HYDROGEN-PRODUCTION
AB The use of renewable energy to reduce the effects of climate change and global warming has become an increasing trend. In order to improve the prediction ability of renewable energy, various prediction techniques have been developed. The aims of this review are illustrated as follows. First, this survey attempts to provide a review and analysis of machine-learning models in renewable-energy predictions. Secondly, this study depicts procedures, including data pre-processing techniques, parameter selection algorithms, and prediction performance measurements, used in machine-learning models for renewable-energy predictions. Thirdly, the analysis of sources of renewable energy, values of the mean absolute percentage error, and values of the coefficient of determination were conducted. Finally, some possible potential opportunities for future work were provided at end of this survey.
C1 [Lai, Jung-Pin; Chang, Yu-Ming; Chen, Chieh-Huang; Pai, Ping-Feng] Natl Chi Nan Univ, PhD Program Strategy & Dev Emerging Ind, Nantou 54561, Taiwan.
   [Chang, Yu-Ming] HungKuang Univ, Dept Culinary Arts & Hotel Management, Taichung 43302, Taiwan.
   [Pai, Ping-Feng] Natl Chi Nan Univ, Dept Informat Management, Nantou 54561, Taiwan.
RP Pai, PF (corresponding author), Natl Chi Nan Univ, PhD Program Strategy & Dev Emerging Ind, Nantou 54561, Taiwan.; Pai, PF (corresponding author), Natl Chi Nan Univ, Dept Informat Management, Nantou 54561, Taiwan.
EM s105245902@ncnu.edu.tw; s105245909@ncnu.edu.tw; s106245911@ncnu.edu.tw;
   paipf@ncnu.edu.tw
OI Pai, Ping-Feng/0000-0002-4020-3326
FU Ministry of Science and Technology, TaiwanMinistry of Science and
   Technology, Taiwan [MOST 109-2410-H-260-023]
FX This research was funded by the Ministry of Science and Technology,
   Taiwan under the Contract Number MOST 109-2410-H-260-023.
NR 150
TC 15
Z9 16
U1 22
U2 43
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD SEP
PY 2020
VL 10
IS 17
AR 5975
DI 10.3390/app10175975
PG 20
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Materials Science; Physics
GA NP1JL
UT WOS:000569937500001
OA gold
DA 2022-04-17
ER

PT J
AU Kawamura, A
   Kinoshita, Y
   Nakachi, T
   Shiota, S
   Kiya, H
AF Kawamura, Ayana
   Kinoshita, Yuma
   Nakachi, Takayuki
   Shiota, Sayaka
   Kiya, Hitoshi
TI A Privacy-Preserving Machine Learning Scheme Using EtC Images
SO IEICE TRANSACTIONS ON FUNDAMENTALS OF ELECTRONICS COMMUNICATIONS AND
   COMPUTER SCIENCES
LA English
DT Article
DE support vector machine; random forests; machine learning;
   encryption-then-compression; privacy-preserving
AB We propose a privacy-preserving machine learning scheme with encryption-then-compression (EtC) images, where EtC images are images encrypted by using a block-based encryption method proposed for EtC systems with JPEG compression. In this paper, a novel property of EtC images is first discussed, although EtC ones was already shown to be compressible as a property. The novel property allows us to directly apply EtC images to machine learning algorithms non-specialized for computing encrypted data. In addition, the proposed scheme is demonstrated to provide no degradation in the performance of some typical machine learning algorithms including the support vector machine algorithm with kernel trick and random forests under the use of z-score normalization. A number of facial recognition experiments with are carried out to confirm the effectiveness of the proposed scheme.
C1 [Kawamura, Ayana; Kinoshita, Yuma; Shiota, Sayaka; Kiya, Hitoshi] Tokyo Metropolitan Univ, Hino, Tokyo 1910065, Japan.
   [Nakachi, Takayuki] NTT Corp, NTT Network Innovat Labs, Yokosuka, Kanagawa 2390847, Japan.
RP Kawamura, A (corresponding author), Tokyo Metropolitan Univ, Hino, Tokyo 1910065, Japan.
EM kawamura-ayana@ed.tmu.ac.jp; kinoshita-yuma@ed.tmu.ac.jp;
   nakachi.takayuki@lab.ntt.co.jp; sayaka@tmu.ac.jp; kiya@tmu.ac.jp
FU Japan Society for the Promotion ScienceMinistry of Education, Culture,
   Sports, Science and Technology, Japan (MEXT)Japan Society for the
   Promotion of Science [17H03267]
FX This work was partially supported by Grant-in-Aid for Scientific
   Research(B), No.17H03267, from the Japan Society for the Promotion
   Science.
NR 27
TC 4
Z9 4
U1 0
U2 2
PU IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG
PI TOKYO
PA KIKAI-SHINKO-KAIKAN BLDG, 3-5-8, SHIBA-KOEN, MINATO-KU, TOKYO, 105-0011,
   JAPAN
SN 0916-8508
EI 1745-1337
J9 IEICE T FUND ELECTR
JI IEICE Trans. Fundam. Electron. Commun. Comput. Sci.
PD DEC
PY 2020
VL E103A
IS 12
BP 1571
EP 1578
DI 10.1587/transfun.2020SMP0022
PG 8
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ7XG
UT WOS:000595133600029
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Seshimo, K
   Ota, A
   Nishio, D
   Yamane, S
AF Seshimo, Kazuki
   Ota, Akira
   Nishio, Daichi
   Yamane, Satoshi
TI Practical Evaluation of Online Heterogeneous Machine Learning
SO IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS
LA English
DT Article
DE machine-learning; big data; mixture model; EM algorithm
ID ALGORITHM
AB In recent years, the use of big data has attracted more attention, and many techniques for data analysis have been proposed. Big data analysis is difficult, however, because such data varies greatly in its regularity. Heterogeneous mixture machine learning is one algorithm for analyzing such data efficiently. In this study, we propose online heterogeneous learning based on an online EM algorithm. Experiments show that this algorithm has higher learning accuracy than that of a conventional method and is practical. The online learning approach will make this algorithm useful in the field of data analysis.
C1 [Seshimo, Kazuki; Ota, Akira; Nishio, Daichi; Yamane, Satoshi] Kanazawa Univ, Kanazawa, Ishikawa 9201192, Japan.
RP Yamane, S (corresponding author), Kanazawa Univ, Kanazawa, Ishikawa 9201192, Japan.
EM syamane@is.t.kanazawa-u.ac.jp
NR 18
TC 0
Z9 0
U1 1
U2 2
PU IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG
PI TOKYO
PA KIKAI-SHINKO-KAIKAN BLDG, 3-5-8, SHIBA-KOEN, MINATO-KU, TOKYO, 105-0011,
   JAPAN
SN 1745-1361
J9 IEICE T INF SYST
JI IEICE Trans. Inf. Syst.
PD DEC
PY 2020
VL E103D
IS 12
BP 2620
EP 2631
DI 10.1587/transinf.2020EDP7020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OZ7YI
UT WOS:000595136600025
OA gold
DA 2022-04-17
ER

PT J
AU Wang, ZQ
   Ritou, M
   Da Cunha, C
   Furet, B
AF Wang, Zhiqiang
   Ritou, Mathieu
   Da Cunha, Catherine
   Furet, Benoit
TI Contextual classification for smart machining based on unsupervised
   machine learning by Gaussian mixture model
SO INTERNATIONAL JOURNAL OF COMPUTER INTEGRATED MANUFACTURING
LA English
DT Article
DE Industry 4; 0; machining; unsupervised machine learning; GMM; BIC
ID PREDICTION; SIMULATION
AB Intelligent machine-tools generate a large amount of digital data. Data mining can support decision-making for operational management. The first step in a data mining approach is the selection of relevant data. Raw data must, therefore, be classified into different groups of contexts. This paper proposes an original contextual classification of data for smart machining based on unsupervised machine learning by Gaussian mixture model. The optimal number of classes is determined by the silhouette method based on the Bayesian information criterion. This method is validated on real data from four different machine-tools in the aerospace industry. Manual data mining andk-fold cross-validation confirm that the proposed method provides good contextual classification results. Then, several key performance indicators are calculated using this contextual classification. They show the relevancy of the approach.
C1 [Wang, Zhiqiang; Ritou, Mathieu; Furet, Benoit] Univ Nantes, Lab Digital Sci Nantes LS2N, UMR CNRS 6004, Nantes, France.
   [Da Cunha, Catherine] Cent Nantes, Lab Digital Sci Nantes LS2N, UMR CNRS 6004, Nantes, France.
RP Ritou, M (corresponding author), Univ Nantes, LS2N, 2 Av Pr J Rouxel, F-11475 Carquefou, France.
EM mathieu.ritou@univ-nantes.fr
RI da Cunha, Catherine/AEP-8940-2022; Ritou, Mathieu/AAD-7512-2019
OI da Cunha, Catherine/0000-0002-1330-8384; Ritou,
   Mathieu/0000-0002-0568-9383
FU Agence Nationale de la RechercheFrench National Research Agency
   (ANR)European Commission [ANR-16-CE10-0005]
FX This work was supported by the Agence Nationale de la Recherche
   [ANR-16-CE10-0005].
NR 24
TC 4
Z9 4
U1 0
U2 5
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0951-192X
EI 1362-3052
J9 INT J COMPUT INTEG M
JI Int. J. Comput. Integr. Manuf.
PD NOV 1
PY 2020
VL 33
IS 10-11
SI SI
BP 1042
EP 1054
DI 10.1080/0951192X.2020.1775302
EA JUL 2020
PG 13
WC Computer Science, Interdisciplinary Applications; Engineering,
   Manufacturing; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA OZ4QW
UT WOS:000547054000001
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Bertomeu, J
AF Bertomeu, Jeremy
TI Machine learning improves accounting: discussion, implementation and
   research opportunities
SO REVIEW OF ACCOUNTING STUDIES
LA English
DT Article
DE Machine learning; Accounting; Estimates; Modelling
AB Machine learning has been growing in importance in empirical accounting research. In this opinion piece, I review the unique challenges of going beyond prediction and leveraging these tools into generalizable conceptual insights. Taking as springboard "Machine learning improves accounting estimates" presented at the 2019 Conference of the Review of Accounting Studies, I propose a conceptual framework with various testable implications. I also develop implementation considerations panels with accounting data, such as colinearities between accounting numbers or suitable choices of validation and test samples to mitigate between-sample correlations. Lastly, I offer a personal viewpoint toward embracing the many low-hanging opportunities to bring the methodology into major unanswered accounting questions.
C1 [Bertomeu, Jeremy] Washington Univ, Olin Sch Business, St Louis, MO 63110 USA.
RP Bertomeu, J (corresponding author), Washington Univ, Olin Sch Business, St Louis, MO 63110 USA.
EM bjeremy@wustl.edu
RI Bertomeu, Jeremy/ABF-4952-2020
OI Bertomeu, Jeremy/0000-0001-6746-5767
NR 23
TC 0
Z9 0
U1 17
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-6653
EI 1573-7136
J9 REV ACCOUNT STUD
JI Rev. Account. Stud.
PD SEP
PY 2020
VL 25
IS 3
BP 1135
EP 1155
DI 10.1007/s11142-020-09554-9
EA AUG 2020
PG 21
WC Business, Finance
WE Social Science Citation Index (SSCI)
SC Business & Economics
GA OB1TV
UT WOS:000559409600001
DA 2022-04-17
ER

PT J
AU Pereira, A
   Thomas, C
AF Pereira, Ana
   Thomas, Carsten
TI Challenges of Machine Learning Applied to Safety-Critical Cyber-Physical
   Systems
SO MACHINE LEARNING AND KNOWLEDGE EXTRACTION
LA English
DT Article
DE machine learning; safety; cyber-physical systems; hazard analysis
ID INDUSTRY 4.0; UNCERTAINTY
AB Machine Learning (ML) is increasingly applied for the control of safety-critical Cyber-Physical Systems (CPS) in application areas that cannot easily be mastered with traditional control approaches, such as autonomous driving. As a consequence, the safety of machine learning became a focus area for research in recent years. Despite very considerable advances in selected areas related to machine learning safety, shortcomings were identified on holistic approaches that take an end-to-end view on the risks associated to the engineering of ML-based control systems and their certification. Applying a classic technique of safety engineering, our paper provides a comprehensive and methodological analysis of the safety hazards that could be introduced along the ML lifecycle, and could compromise the safe operation of ML-based CPS. Identified hazards are illustrated and explained using a real-world application scenario-an autonomous shop-floor transportation vehicle. The comprehensive analysis presented in this paper is intended as a basis for future holistic approaches for safety engineering of ML-based CPS in safety-critical applications, and aims to support the focus on research onto safety hazards that are not yet adequately addressed.
C1 [Pereira, Ana; Thomas, Carsten] Hsch Tech & Wirtschaft Berlin, Sch Engn, Wilhelminenhofstr 75A, D-12459 Berlin, Germany.
RP Pereira, A (corresponding author), Hsch Tech & Wirtschaft Berlin, Sch Engn, Wilhelminenhofstr 75A, D-12459 Berlin, Germany.
EM Ana.Pereira@htw-berlin.de; Carsten.Thomas@htw-berlin.de
FU German Federal Ministry of Education and ResearchFederal Ministry of
   Education & Research (BMBF) [01IS18061D]; ITEA project [17032]
FX This paper has been created within the framework of the ITEA project
   17032 CyberFactory#1. The German partners are funded by the German
   Federal Ministry of Education and Research (Grant Number 01IS18061D).
NR 78
TC 3
Z9 3
U1 0
U2 2
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2504-4990
J9 MACH LEARN KNOW EXTR
JI Mach. Learn. Knowl. Extr.
PD DEC
PY 2020
VL 2
IS 4
BP 579
EP 602
DI 10.3390/make2040031
PG 24
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
WE Emerging Sources Citation Index (ESCI)
SC Computer Science; Engineering
GA TX0LV
UT WOS:000682782200011
OA gold
DA 2022-04-17
ER

PT J
AU Chen, JZ
   Yang, CW
   Ren, J
AF Chen Jiang-Zhi
   Yang Chen-Wen
   Ren Jie
TI Machine learning based on wave and diffusion physical systems
SO ACTA PHYSICA SINICA
LA Chinese
DT Article
DE wave systems; diffusion systems; machine learning; artificial neural
   network
ID NEURAL-NETWORK; CALYPSO; OPTICS
AB Recently, the application of physics to machine learning and the interdisciplinary convergence of the two have attracted wide attention. This paper focuses on exploring the internal relationship between physical systems and machine learning, and also on promoting machine learning algorithm and physical implementation. We summarize the researches of machine learning in wave systems and diffusion systems, and introduce some of the latest research results. We first discuss the realization of supervised learning for wave systems, including the wave optics realization of neural networks, the wave realization of quantum search, the recurrent neural networks based on wave systems, and the nonlinear wave computation of neural morphology. Then, we discuss the machine learning algorithms inspired by diffusion systems, such as the classification algorithm based on diffusion dynamics, data mining and information filtering based on thermal diffusion, searching for optimization based on population diffusion, etc. The physical mechanism of diffusion system can inspire the construction of efficient machine learning algorithms for the classification and optimization of complex systems and physics research, which may create a new vision for the development of physics inspired algorithms and hardware implementation, and even the integration of software and hardware.
C1 [Chen Jiang-Zhi; Yang Chen-Wen; Ren Jie] Tongji Univ, Sch Phys Sci & Engn, Ctr Phonon & Thermal Energy Sci, Shanghai Key Lab Special Artificial Microstruct M, Shanghai 200092, Peoples R China.
   [Ren Jie] Tongji Univ, Shanghai Res Inst Intelligent Autonomous Syst, Shanghai 200092, Peoples R China.
RP Ren, J (corresponding author), Tongji Univ, Sch Phys Sci & Engn, Ctr Phonon & Thermal Energy Sci, Shanghai Key Lab Special Artificial Microstruct M, Shanghai 200092, Peoples R China.; Ren, J (corresponding author), Tongji Univ, Shanghai Res Inst Intelligent Autonomous Syst, Shanghai 200092, Peoples R China.
EM xonics@tongji.edu.cn
RI Ren, Jie/G-5314-2010
OI Ren, Jie/0000-0003-2806-7226
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [11935010, 11775159]; Natural Science
   Foundation of Shanghai Science and Technology Committee, ChinaNatural
   Science Foundation of Shanghai [18JC1410900]; Opening Project of
   Shanghai Key Laboratory of Special Artificial Microstructure Materials
   and Technology, China; Fundamental Research Funds for the Central
   Universities, ChinaFundamental Research Funds for the Central
   Universities
FX Project supported by the National Natural Science Foundation of China
   (Grant Nos. 11935010, 11775159), the Natural Science Foundation of
   Shanghai Science and Technology Committee, China (Grant No.
   18JC1410900), the Opening Project of Shanghai Key Laboratory of Special
   Artificial Microstructure Materials and Technology, China, and the
   Fundamental Research Funds for the Central Universities, China.
NR 74
TC 0
Z9 0
U1 21
U2 32
PU CHINESE PHYSICAL SOC
PI BEIJING
PA P O BOX 603, BEIJING 100080, PEOPLES R CHINA
SN 1000-3290
J9 ACTA PHYS SIN-CH ED
JI Acta Phys. Sin.
PD JUL 20
PY 2021
VL 70
IS 14
AR 144204
DI 10.7498/aps.70.20210879
PG 15
WC Physics, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Physics
GA TP4DB
UT WOS:000677544100017
OA gold
DA 2022-04-17
ER

PT J
AU Merenda, M
   Porcaro, C
   Iero, D
AF Merenda, Massimo
   Porcaro, Carlo
   Iero, Demetrio
TI Edge Machine Learning for AI-Enabled IoT Devices: A Review
SO SENSORS
LA English
DT Review
DE artificial intelligence; machine learning; Internet of Things; edge
   devices; deep learning
ID COMMUNICATION TECHNOLOGIES; BIG DATA; INTERNET; THINGS; FRAMEWORK;
   NETWORKS; STEP; 5G
AB In a few years, the world will be populated by billions of connected devices that will be placed in our homes, cities, vehicles, and industries. Devices with limited resources will interact with the surrounding environment and users. Many of these devices will be based on machine learning models to decode meaning and behavior behind sensors' data, to implement accurate predictions and make decisions. The bottleneck will be the high level of connected things that could congest the network. Hence, the need to incorporate intelligence on end devices using machine learning algorithms. Deploying machine learning on such edge devices improves the network congestion by allowing computations to be performed close to the data sources. The aim of this work is to provide a review of the main techniques that guarantee the execution of machine learning models on hardware with low performances in the Internet of Things paradigm, paving the way to the Internet of Conscious Things. In this work, a detailed review on models, architecture, and requirements on solutions that implement edge machine learning on Internet of Things devices is presented, with the main goal to define the state of the art and envisioning development requirements. Furthermore, an example of edge machine learning implementation on a microcontroller will be provided, commonly regarded as the machine learning "Hello World".
C1 [Merenda, Massimo; Porcaro, Carlo; Iero, Demetrio] Univ Mediterranea Reggio Calabria, Dept Informat Engn Infrastruct & Sustainable Ener, I-89124 Reggio Di Calabria, Italy.
   [Merenda, Massimo; Porcaro, Carlo; Iero, Demetrio] Univ Mediterranea Reggio Calabria, HWA Srl Spin, Via Reggio Campi 2 Tr 135, I-89126 Reggio Di Calabria, Italy.
RP Merenda, M (corresponding author), Univ Mediterranea Reggio Calabria, Dept Informat Engn Infrastruct & Sustainable Ener, I-89124 Reggio Di Calabria, Italy.; Merenda, M (corresponding author), Univ Mediterranea Reggio Calabria, HWA Srl Spin, Via Reggio Campi 2 Tr 135, I-89126 Reggio Di Calabria, Italy.
EM massimo.merenda@unirc.it; porcarocarlo@libero.it; demetrio.iero@unirc.it
RI Merenda, Massimo/K-7061-2013
OI Merenda, Massimo/0000-0003-3668-8014
NR 177
TC 34
Z9 34
U1 11
U2 29
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD MAY
PY 2020
VL 20
IS 9
AR 2533
DI 10.3390/s20092533
PG 34
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Instruments & Instrumentation
GA LT5JF
UT WOS:000537106200097
PM 32365645
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Park, H
   Son, JH
AF Park, Hochong
   Son, Joo-Hiuk
TI Machine Learning Techniques for THz Imaging and Time-Domain Spectroscopy
SO SENSORS
LA English
DT Review
DE terahertz imaging; terahertz time-domain spectroscopy; machine learning;
   classification; regression; supervised learning; feature extraction
ID CONVOLUTIONAL NEURAL-NETWORK; TRAUMATIC BRAIN-INJURY; TERAHERTZ
   SPECTROSCOPY; WATER-CONTENT; LIVER-INJURY; CLASSIFICATION; RECOGNITION;
   CANCER; INFORMATION; REGRESSION
AB Terahertz imaging and time-domain spectroscopy have been widely used to characterize the properties of test samples in various biomedical and engineering fields. Many of these tasks require the analysis of acquired terahertz signals to extract embedded information, which can be achieved using machine learning. Recently, machine learning techniques have developed rapidly, and many new learning models and learning algorithms have been investigated. Therefore, combined with state-of-the-art machine learning techniques, terahertz applications can be performed with high performance that cannot be achieved using modeling techniques that precede the machine learning era. In this review, we introduce the concept of machine learning and basic machine learning techniques and examine the methods for performance evaluation. We then summarize representative examples of terahertz imaging and time-domain spectroscopy that are conducted using machine learning.
C1 [Park, Hochong] Kwangwoon Univ, Dept Elect Engn, Seoul 01897, South Korea.
   [Son, Joo-Hiuk] Univ Seoul, Dept Phys, Seoul 02504, South Korea.
RP Son, JH (corresponding author), Univ Seoul, Dept Phys, Seoul 02504, South Korea.
EM hcpark@kw.ac.kr; joohiuk@uos.ac.kr
FU Kwangwoon University; National Research Foundation of Korea (NRF) -
   Korean government (MSIT)National Research Foundation of Korea
   [NRF-2016R1D1A1B03930923]; Institute for Information & Communications
   Technology Promotion (IITP) - Korean government (MSIT) [2017-0-00422]
FX This research was partly funded by the Research Grant of Kwangwoon
   University in 2020, the National Research Foundation of Korea (NRF)
   grant funded by the Korean government (MSIT) (NRF-2016R1D1A1B03930923),
   and an Institute for Information & Communications Technology Promotion
   (IITP) grant funded by the Korean government (MSIT) (No. 2017-0-00422,
   Cancer DNA demethylation using ultra-high-power terahertz radiation).
NR 132
TC 10
Z9 10
U1 49
U2 77
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD FEB
PY 2021
VL 21
IS 4
AR 1186
DI 10.3390/s21041186
PG 25
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Instruments & Instrumentation
GA QQ6PR
UT WOS:000624645700001
PM 33567605
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Mousavi, M
   Rezazadeh, J
   Sianaki, OA
AF Mousavi, Mitra
   Rezazadeh, Javad
   Sianaki, Omid Ameri
TI Machine learning applications for fog computing in IoT: a survey
SO INTERNATIONAL JOURNAL OF WEB AND GRID SERVICES
LA English
DT Article
DE internet of things; IoT; fog computing; machine learning; fog-based
   machine learning
ID DATA ANALYTICS; ATTACK DETECTION; MOBILE EDGE; THINGS; ARCHITECTURE;
   MANAGEMENT; INTERNET; SYSTEMS; TRENDS; CLOUD
AB Today, internet of things (IoT) has become an important paradigm. Everyday increasing number of IoT applications and services emerge. Smart devices connected by the IoT generate significant amounts of data. Analysis IoT sensor data using machine learning algorithms is a key to achieve useful information for prediction, classification, data association and data conceptualisation. Offloading input data to cloud servers leads to increased communication costs. Undertaking data analytics at the network edge using fog computing enables the rapid processing of incoming data for real-time response. In this paper, we examine the results of using different machine learning algorithms on fog nodes based on existing research. These results are low latency, high accuracy and low bandwidth. Also, this work presents the current fog computing architecture which consists of different layers that distribute computing, storage, control and networking and finally we investigate the challenges and open issues related to the deployment of machine learning on fog nodes.
C1 [Mousavi, Mitra] Islamic Azad Univ, North Tehran Branch, Tehran, Iran.
   [Rezazadeh, Javad] Univ Technol Sydney UTS, Sydney, NSW, Australia.
   [Sianaki, Omid Ameri] Victoria Univ Business Sch, City Flinders Campus, Victoria, BC, Canada.
RP Rezazadeh, J (corresponding author), Univ Technol Sydney UTS, Sydney, NSW, Australia.
EM mitrasadatmousavi@yahoo.com; rezazadeh@ieee.org;
   omid.amerisianaki@vu.edu.au
NR 146
TC 0
Z9 0
U1 2
U2 2
PU INDERSCIENCE ENTERPRISES LTD
PI GENEVA
PA WORLD TRADE CENTER BLDG, 29 ROUTE DE PRE-BOIS, CASE POSTALE 856, CH-1215
   GENEVA, SWITZERLAND
SN 1741-1106
EI 1741-1114
J9 INT J WEB GRID SERV
JI Int. J. Web Grid Serv.
PY 2021
VL 17
IS 4
BP 293
EP 320
DI 10.1504/IJWGS.2021.118395
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WM3XE
UT WOS:000711020700001
DA 2022-04-17
ER

PT C
AU Suvorova, A
AF Suvorova, Alena
BE Alexandrov, DA
   Boukhanovsky, AV
   Chugunov, AV
   Kabanov, Y
   Koltsova, O
   Musabirov, I
   Pashakhin, S
TI Interpretable Machine Learning in Social Sciences: Use Cases and
   Limitations
SO DIGITAL TRANSFORMATION AND GLOBAL SOCIETY, DTGS 2021
SE Communications in Computer and Information Science
LA English
DT Proceedings Paper
CT 6th International Conference on Digital Transformation and Global
   Society (DTGS)
CY JUN 23-25, 2021
CL ITMO Univ, St Petersburg, RUSSIA
HO ITMO Univ
DE Explainable AI; Machine learning; Research design; Social sciences
ID TRUST
AB The increasing use of intelligent technologies, the development and implementation of machine learning systems in various spheres of life require explaining machine learning-based decisions in such systems. This need for interpretation leads to the increasing development of new methods for interpreting machine learning models and their more intense use in real systems. The paper reviews existing studies with applications of the interpretable machine learning (IML) methods in social sciences and summarizes results using bibliometric analysis. In total, seven research topics were described based on 210 papers. Moreover, the paper discusses the opportunities, limitations, and challenges of the interpretable machine learning approach in social science research.
C1 [Suvorova, Alena] HSE Univ, St Petersburg, Russia.
RP Suvorova, A (corresponding author), HSE Univ, St Petersburg, Russia.
EM asuvorova@hse.ru
FU Russian Science FoundationRussian Science Foundation (RSF) [19-71-00064]
FX The work is supported by the Russian Science Foundation grant (project
   No. 19-71-00064).
NR 60
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1865-0929
EI 1865-0937
BN 978-3-030-93715-7; 978-3-030-93714-0
J9 COMM COM INF SC
PY 2022
VL 1503
BP 319
EP 331
DI 10.1007/978-3-030-93715-7_23
PG 13
WC Communication; Computer Science, Interdisciplinary Applications;
   Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Communication; Computer Science
GA BS8FF
UT WOS:000771923700023
DA 2022-04-17
ER

PT J
AU Li, H
   Fang, C
   Lin, ZC
AF Li, Huan
   Fang, Cong
   Lin, Zhouchen
TI Accelerated First-Order Optimization Algorithms for Machine Learning
SO PROCEEDINGS OF THE IEEE
LA English
DT Article
DE Numerical analysis; Machine learning algorithms; Optimization methods;
   Machine learning; Convergence; Complexity theory; Approximation
   algorithms; Convex functions; Acceleration; convex optimization;
   deterministic algorithms; machine learning; nonconvex optimization;
   stochastic algorithms
ID ALTERNATING DIRECTION METHOD; COORDINATE DESCENT METHODS; GRADIENT
   METHODS; DISTRIBUTED OPTIMIZATION; ITERATION-COMPLEXITY; MINIMIZATION;
   CONVERGENCE; PERFORMANCE; EFFICIENCY; SHRINKAGE
AB Numerical optimization serves as one of the pillars of machine learning. To meet the demands of big data applications, lots of efforts have been put on designing theoretically and practically fast algorithms. This article provides a comprehensive survey on accelerated first-order algorithms with a focus on stochastic algorithms. Specifically, this article starts with reviewing the basic accelerated algorithms on deterministic convex optimization, then concentrates on their extensions to stochastic convex optimization, and at last introduces some recent developments on acceleration for nonconvex optimization.
C1 [Li, Huan] Nankai Univ, Inst Robot & Automat Informat Syst, Coll Artificial Intelligence, Tianjin 300071, Peoples R China.
   [Li, Huan] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 210016, Peoples R China.
   [Fang, Cong] Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
   [Lin, Zhouchen] Peking Univ, Sch Elect Engn & Comp Sci EECS, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China.
RP Lin, ZC (corresponding author), Peking Univ, Sch Elect Engn & Comp Sci EECS, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China.
EM lihuan_ss@126.com; fangcong@pku.edu.cn; zlin@pku.edu.cn
FU Zhejiang Laboratory [2019KBOAB02]; NSF ChinaNational Natural Science
   Foundation of China (NSFC) [61625301, 61731018]; Major Research Project
   of Zhejiang Laboratory [2019KBOAB02, 2019KBOAC01]; Beijing Academy of
   Artificial Intelligence
FX The work of Huan Li was supported in part by the Zhejiang Laboratory
   under Grant 2019KBOAB02. The work of Zhouchen Lin was supported in part
   by NSF China under Grant 61625301 and Grant 61731018, in part by the
   Major Research Project of Zhejiang Laboratory under Grant 2019KBOAC01
   and Grant 2019KBOAB02, and in part by the Beijing Academy of Artificial
   Intelligence.
NR 142
TC 5
Z9 5
U1 7
U2 20
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9219
EI 1558-2256
J9 P IEEE
JI Proc. IEEE
PD NOV
PY 2020
VL 108
IS 11
BP 2067
EP 2082
DI 10.1109/JPROC.2020.3007634
PG 16
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA OJ1FR
UT WOS:000583713600012
DA 2022-04-17
ER

PT J
AU Le, DC
   Zincir-Heywood, N
AF Duc C Le
   Zincir-Heywood, Nur
TI A Frontier: Dependable, Reliable and Secure Machine Learning for
   Network/System Management
SO JOURNAL OF NETWORK AND SYSTEMS MANAGEMENT
LA English
DT Article
DE Network and system management; Reliable and dependable machine learning;
   Secure machine learning
ID INTRUSION DETECTION; TRAFFIC CLASSIFICATION; BOTNET DETECTION; STREAMING
   DATA; ARCHITECTURE; ALGORITHM; ENSEMBLE; ATTACKS; CLOUD
AB Modern networks and systems pose many challenges to traditional management approaches. Not only the number of devices and the volume of network traffic are increasing exponentially, but also new network protocols and technologies require new techniques and strategies for monitoring controlling and managing up and coming networks and systems. Moreover, machine learning has recently found its successful applications in many fields due to its capability to learn from data to automatically infer patterns for network analytics. Thus, the deployment of machine learning in network and system management has become imminent. This work provides a review of the applications of machine learning in network and system management. Based on this review, we aim to present the current opportunities and challenges in and highlight the need for dependable, reliable and secure machine learning for network and system management.
C1 [Duc C Le; Zincir-Heywood, Nur] Dalhousie Univ, Halifax, NS, Canada.
RP Zincir-Heywood, N (corresponding author), Dalhousie Univ, Halifax, NS, Canada.
EM lcd@dal.ca; zincir@cs.dal.ca
OI Zincir-Heywood, Nur/0000-0003-2796-7265
FU Natural Science and Engineering Research Council of Canada
   (NSERC)Natural Sciences and Engineering Research Council of Canada
   (NSERC); Killam Trusts; province of Nova Scotia
FX This research is supported by Natural Science and Engineering Research
   Council of Canada (NSERC). Duc C. Le gratefully acknowledges the
   supports of the Killam Trusts and the province of Nova Scotia. The
   research is conducted as part of the Dalhousie NIMS Lab at:
   https://projects.cs.dal.ca/projectx/.The authors would like to thank the
   anonymous reviewers.
NR 129
TC 8
Z9 8
U1 2
U2 5
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1064-7570
EI 1573-7705
J9 J NETW SYST MANAG
JI J. Netw. Syst. Manag.
PD OCT
PY 2020
VL 28
IS 4
SI SI
BP 827
EP 849
DI 10.1007/s10922-020-09512-5
EA JAN 2020
PG 23
WC Computer Science, Information Systems; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA NP4SI
UT WOS:000510275100001
DA 2022-04-17
ER

PT J
AU Dong, XW
   Thanou, D
   Toni, L
   Bronstein, M
   Frossard, P
AF Dong, Xiaowen
   Thanou, Dorina
   Toni, Laura
   Bronstein, Michael
   Frossard, Pascal
TI Graph Signal Processing for Machine Learning: A Review and New
   Perspectives
SO IEEE SIGNAL PROCESSING MAGAZINE
LA English
DT Article
DE Machine learning; Convolution; Graphical models; Laplace equations; Data
   models; Machine learning algorithms
ID KERNELS
AB The effective representation, processing, analysis, and visualization of large-scale structured data, especially those related to complex domains, such as networks and graphs, are one of the key questions in modern machine learning. Graph signal processing (GSP), a vibrant branch of signal processing models and algorithms that aims at handling data supported on graphs, opens new paths of research to address this challenge. In this article, we review a few important contributions made by GSP concepts and tools, such as graph filters and transforms, to the development of novel machine learning algorithms. In particular, our discussion focuses on the following three aspects: exploiting data structure and relational priors, improving data and computational efficiency, and enhancing model interpretability. Furthermore, we provide new perspectives on the future development of GSP techniques that may serve as a bridge between applied mathematics and signal processing on one side and machine learning and network science on the other. Cross-fertilization across these different disciplines may help unlock the numerous challenges of complex data analysis in the modern age.
C1 [Dong, Xiaowen] Univ Oxford, Dept Engn Sci, Oxford, England.
   [Dong, Xiaowen] MIT, Media Lab, Cambridge, MA 02139 USA.
   [Thanou, Dorina] Ecole Polytech Fed Lausanne, Swiss Data Sci Ctr, Lausanne, Switzerland.
   [Thanou, Dorina] Swiss Fed Inst Technol, Zurich, Switzerland.
   [Thanou, Dorina] Ecole Polytech Fed Lausanne, Signal Proc Lab LTS4, Lausanne, Switzerland.
   [Toni, Laura] Univ Calif San Diego, San Diego, CA 92103 USA.
   [Toni, Laura; Frossard, Pascal] Swiss Fed Inst Technol EPFL, Lausanne, Switzerland.
   [Toni, Laura] UCL, Dept Elect & Elect Engn, London, England.
   [Bronstein, Michael] Imperial Coll London, London, England.
   [Bronstein, Michael] Twitter, Graph Learning Res, San Francisco, CA USA.
   [Bronstein, Michael] Stanford Univ, Stanford, CA 94305 USA.
   [Bronstein, Michael] MIT, Cambridge, MA 02139 USA.
   [Bronstein, Michael] Harvard Univ, Cambridge, MA 02138 USA.
   [Bronstein, Michael] Harvard, Inst Adv Study, Cambridge, MA USA.
   [Bronstein, Michael] Tech Univ Munich, Munich, Germany.
   [Bronstein, Michael] Acad Europaea, London, England.
   [Frossard, Pascal] Ecole Polytech Fed Lausanne, Signal Proc Lab 4, Lausanne, Switzerland.
   [Frossard, Pascal] IBM TJ Watson Res Ctr, Yorktown Hts, NY USA.
RP Dong, XW (corresponding author), Univ Oxford, Dept Engn Sci, Oxford, England.
EM xdong@robots.ox.ac.uk; dorina.thanou@epfl.ch; l.toni@ucl.ac.uk;
   m.bronstein@imperial.ac.uk; pascal.frossard@epfl.ch
RI Dong, Xiaowen/AAJ-5058-2021
OI Dong, Xiaowen/0000-0002-1143-9786; Frossard, Pascal/0000-0002-4010-714X
NR 40
TC 13
Z9 13
U1 6
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1053-5888
EI 1558-0792
J9 IEEE SIGNAL PROC MAG
JI IEEE Signal Process. Mag.
PD NOV
PY 2020
VL 37
IS 6
BP 117
EP 127
DI 10.1109/MSP.2020.3014591
PG 11
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA OO9HP
UT WOS:000587684700011
OA Green Submitted
DA 2022-04-17
ER

PT C
AU Nosho, T
   Fujimoto, M
AF Nosho, Takahiro
   Fujimoto, Mitoshi
GP IEEE
TI Investigation of Hyperparameters for DOA Using Machine Learning
SO 2020 INTERNATIONAL SYMPOSIUM ON ANTENNAS AND PROPAGATION (ISAP)
LA English
DT Proceedings Paper
CT International Symposium on Antennas and Propagation (ISAP)
CY JAN 25-28, 2021
CL ELECTR NETWORK
SP Inst Elect Informat & Commun Engineers, Commun Soc, Antenna Measurement Tech Assoc, Inst Elect & Elect Engineers Antennas & Propagat Soc, Chinese Inst Elect, Antennas Soc, Elect Engn Elect Comp Commun Informat Technol Assoc Thailand, European Assoc Antennas & Propagat, Inst Antenna Engineers Taiwan, Int Union Radio Sci, Korean Inst Electromagnet Engn & Sci, Taiwan Microwave Assoc
DE DOA estimation; machine learning; hyperparameter; deep neural network
AB In estimating the direction of arrival (DOA) of a radio wave using array antennas, the correlation matrix calculated from the received signals at each antenna element is generally used. In recent years, applied researches such as DOA estimation and radio propagation estimation using machine learning have been conducted. In this paper, a method for estimating the DOA using machine learning is proposed, and clarify the influence of each hyperparameter on the estimation accuracy.
C1 [Nosho, Takahiro; Fujimoto, Mitoshi] Univ Fukui, Grad Sch Engn, 3-9-1 Bunkyo, Fukui 9108507, Japan.
RP Nosho, T (corresponding author), Univ Fukui, Grad Sch Engn, 3-9-1 Bunkyo, Fukui 9108507, Japan.
EM nosho@wireless.fuis.u-fukui.ac.jp
NR 5
TC 0
Z9 0
U1 1
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-4-88552-326-7
PY 2021
BP 505
EP 506
PG 2
WC Engineering, Electrical & Electronic; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering; Telecommunications
GA BR7PS
UT WOS:000668734200226
DA 2022-04-17
ER

PT C
AU Banerji, S
   Hamrick, A
   Majumder, A
   Menon, R
   Sensale-Rodriguez, B
AF Banerji, Sourangsu
   Hamrick, Alex
   Majumder, Apratim
   Menon, Rajesh
   Sensale-Rodriguez, Berardi
GP IEEE
TI Ultra-compact Design of Power Splitters via Machine Learning
SO 2020 IEEE PHOTONICS CONFERENCE (IPC)
SE IEEE Photonics Conference
LA English
DT Proceedings Paper
CT IEEE Photonics Conference (IPC)
CY SEP 28-OCT 01, 2020
CL ELECTR NETWORK
SP IEEE
DE Nanophotonics; Silicon photonics; Machine learning
AB We demonstrate efficient ultra-compact power splitters designed via machine learning algorithm viz. binary-additive reinforcement learning algorithm. Two different splitter geometries (Y- and T-junctions) are shown; each with an area footprint of 1.2 x 1.2 mu m(2). The simulated insertion loss is < 1dB for both.
C1 [Banerji, Sourangsu; Majumder, Apratim; Menon, Rajesh; Sensale-Rodriguez, Berardi] Univ Utah, Dept Elect & Comp Engn, Salt Lake City, UT 84112 USA.
   [Hamrick, Alex] Univ Utah, Sch Comp, Salt Lake City, UT USA.
RP Banerji, S (corresponding author), Univ Utah, Dept Elect & Comp Engn, Salt Lake City, UT 84112 USA.
EM sourangsu.baneiji@utah.edu; rmenon@eng.utah.edu;
   berardi.sensale@utah.edu
RI Banerji, Sourangsu/M-5142-2019
OI Banerji, Sourangsu/0000-0001-5545-3988; Majumder,
   Apratim/0000-0002-4192-0722
NR 6
TC 0
Z9 0
U1 1
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2374-0140
BN 978-1-7281-5891-4
J9 IEEE PHOTON CONF
PY 2020
PG 2
WC Engineering, Electrical & Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering; Optics
GA BQ6JM
UT WOS:000612237500024
DA 2022-04-17
ER

PT J
AU Choi, JA
   Lim, K
AF Choi, Jin-A
   Lim, Kiho
TI Identifying machine learning techniques for classification of target
   advertising
SO ICT EXPRESS
LA English
DT Article
DE Machine learning; Artificial intelligence; Target advertising;
   Classification
ID VIDEO; POWER
AB There have been numerous applications of artificial intelligence (AI) technologies to online advertising, especially to optimize the reach of target audiences. Previous studies show that improved computational power significantly advances granular audience targeting capabilities. This study investigates and classifies various machine learning techniques that are used to enhance targeted online advertising. Twenty-three machine learning-based online targeted advertising strategies are identified and classified largely into two categories, user-centric and contentcentric approaches. The paper also identifies an underexamined area, algorithm-based detection of click frauds, to illustrate how machine learning approaches can be integrated to preserve the viability of online advertising. (C) 2020 The Korean Institute of Communications and Information Sciences (KICS). Publishing services by Elsevier B.V.
C1 [Choi, Jin-A] William Paterson Univ New Jersey, Dept Commun, Wayne, NJ 07470 USA.
   [Lim, Kiho] William Paterson Univ New Jersey, Dept Comp Sci, Wayne, NJ 07470 USA.
RP Lim, K (corresponding author), William Paterson Univ New Jersey, Dept Comp Sci, Wayne, NJ 07470 USA.
EM choij21@wpunj.edu; limk2@wpunj.edu
FU A.R.T. Program; College of the Arts and Communication Center for
   Creative Activity & Research Summer Grant, William Paterson University
   of New Jersey
FX This work was supported in part by the A.R.T. Program and the College of
   the Arts and Communication Center for Creative Activity & Research
   Summer Grant, William Paterson University of New Jersey.
NR 30
TC 4
Z9 4
U1 5
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2405-9595
J9 ICT EXPRESS
JI ICT Express
PD SEP
PY 2020
VL 6
IS 3
BP 175
EP 180
DI 10.1016/j.icte.2020.04.012
PG 6
WC Computer Science, Information Systems; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA NF8SG
UT WOS:000563562300006
OA gold
DA 2022-04-17
ER

PT J
AU Macfarlane, A
   Missaoui, S
   Frankowska-Takhari, S
AF Macfarlane, Andrew
   Missaoui, Sondess
   Frankowska-Takhari, Sylwia
TI On Machine Learning and Knowledge Organization in Multimedia Information
   Retrieval
SO KNOWLEDGE ORGANIZATION
LA English
DT Article
DE features; machine learning; knowledge organization; multimedia
ID CONCEPT ONTOLOGY; CLASSIFICATION; EVOLUTION
AB Recent technological developments have increased the use of machine learning to solve many problems, including many in information retrieval. Multimedia information retrieval as a problem represents a significant challenge to machine learning as a technological solution, but some problems can still be addressed by using appropriate AI techniques. We review the technological developments and provide a perspective on the use of machine learning in conjunction with knowledge organization to address multimedia IR needs. The semantic gap in multimedia IR remains a significant problem in the field, and solutions to them are many years off. However, new technological developments allow the use of knowledge organization and machine learning in multimedia search systems and services. Specifically, we argue that, the improvement of detection of some classes of low-level features in images music and video can be used in conjunction with knowledge organization to tag or label multimedia content for better retrieval performance. We provide an overview of the use of knowledge organization schemes in machine learning and make recommendations to information professionals on the use of this technology with knowledge organization techniques to solve multimedia IR problems. We introduce a five-step process model that extracts features from multimedia objects (Step 1) from both knowledge organization (Step la) and machine learning (Step lb), merging them together (Step 2) to create an index of those multimedia objects (Step 3). We also overview further steps in creating an application to utilize the multimedia objects (Step 4) and maintaining and updating the database of features on those objects (Step 5).
C1 [Macfarlane, Andrew; Missaoui, Sondess; Frankowska-Takhari, Sylwia] City Univ London, Ctr HCI Design, Dept Comp Sci, London, England.
RP Macfarlane, A (corresponding author), City Univ London, Ctr HCI Design, Dept Comp Sci, London, England.
EM andym@city.ac.uk; Sondess.Missaoui@city.ac.uk;
   Sylwia.Frankowska.1@city.ac.uk
FU EPSRCUK Research & Innovation (UKRI)Engineering & Physical Sciences
   Research Council (EPSRC) [EP/M023265/1] Funding Source: UKRI
NR 43
TC 1
Z9 1
U1 3
U2 15
PU NOMOS VERLAGSGESELLSCHAFT MBH & CO KG
PI BADEN-BADEN
PA WALDSEESTR 3 5, BADEN-BADEN, 76530, GERMANY
SN 0943-7444
J9 KNOWL ORGAN
JI Knowl. Organ.
PY 2020
VL 47
IS 1
BP 45
EP 55
DI 10.5771/0943-7444-2020-1-45
PG 11
WC Information Science & Library Science
WE Social Science Citation Index (SSCI)
SC Information Science & Library Science
GA LH6PX
UT WOS:000528907600004
DA 2022-04-17
ER

PT J
AU Moroni, D
   Pascali, MA
AF Moroni, Davide
   Pascali, Maria Antonietta
TI Learning Topology: Bridging Computational Topology and Machine Learning
SO PATTERN RECOGNITION AND IMAGE ANALYSIS
LA English
DT Article
DE computational topology; persistent homology; machine learning; deep
   learning; image and shape analysis; data analysis
ID PERSISTENT HOMOLOGY; TIME-SERIES; ALGORITHMS; FEATURES
AB Topology is a classical branch of mathematics, born essentially from Euler's studies in the XVII century, which deals with the abstract notion of shape and geometry. Last decades were characterized by a renewed interest in topology and topology-based tools, due to the birth of computational topology and topological data analysis (TDA). A large and novel family of methods and algorithms computing topological features and descriptors (e.g., persistent homology) have proved to be effective tools for the analysis of graphs, 3D objects, 2D images, and even heterogeneous datasets. This survey is intended to be a concise but complete compendium that, offering the essential basic references, allows you to orient yourself among the recent advances in TDA and its applications, with an eye to those related to machine learning and deep learning.
C1 [Moroni, Davide; Pascali, Maria Antonietta] Natl Res Council Italy, Inst Informat Sci & Technol, I-56124 Pisa, PI, Italy.
RP Moroni, D (corresponding author), Natl Res Council Italy, Inst Informat Sci & Technol, I-56124 Pisa, PI, Italy.
EM davide.moroni@isti.cnr.it; maria.antonietta.pascali@isti.cnr.it
RI Moroni, Davide/T-8258-2018
OI Moroni, Davide/0000-0002-5175-5126
NR 71
TC 1
Z9 1
U1 3
U2 5
PU SPRINGERNATURE
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND
SN 1054-6618
EI 1555-6212
J9 PATTERN RECOGN IMAGE
JI Pattern Recogn. Image Anal.
PD JUL
PY 2021
VL 31
IS 3
BP 443
EP 453
DI 10.1134/S1054661821030184
PG 11
WC Computer Science, Interdisciplinary Applications
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA US8JJ
UT WOS:000697671200009
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Aniceto, MC
   Barboza, F
   Kimura, H
AF Aniceto, Maisa Cardoso
   Barboza, Flavio
   Kimura, Herbert
TI Machine learning predictivity applied to consumer creditworthiness
SO FUTURE BUSINESS JOURNAL
LA English
DT Article
DE Machine learning; Credit risk; Consumer lending; Default prediction;
   Performance analysis
ID FEATURE-SELECTION; CREDIT; DEFAULT; MODELS
AB Credit risk evaluation has a relevant role to financial institutions, since lending may result in real and immediate losses. In particular, default prediction is one of the most challenging activities for managing credit risk. This study analyzes the adequacy of borrower's classification models using a Brazilian bank's loan database, and exploring machine learning techniques. We develop Support Vector Machine, Decision Trees, Bagging, AdaBoost and Random Forest models, and compare their predictive accuracy with a benchmark based on a Logistic Regression model. Comparisons are analyzed based on usual classification performance metrics. Our results show that Random Forest and Adaboost perform better when compared to other models. Moreover, Support Vector Machine models show poor performance using both linear and nonlinear kernels. Our findings suggest that there are value creating opportunities for banks to improve default prediction models by exploring machine learning techniques.
C1 [Aniceto, Maisa Cardoso; Kimura, Herbert] Univ Brasilia, Dept Management, Campus Darcy Ribeiro North Wing, BR-70910900 Brasilia, DF, Brazil.
   [Barboza, Flavio] Univ Fed Uberlandia, Sch Business & Management, Av Joao Naves de Avila 2121, BR-38400902 Uberlandia, MG, Brazil.
RP Aniceto, MC (corresponding author), Univ Brasilia, Dept Management, Campus Darcy Ribeiro North Wing, BR-70910900 Brasilia, DF, Brazil.
EM maisa.c.aniceto@gmail.com
RI Kimura, Herbert/B-6186-2013; Barboza, Flavio/M-9090-2017
OI Kimura, Herbert/0000-0001-6772-1863; Barboza, Flavio/0000-0002-3449-5297
FU CNPqConselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPQ)
   [435173/2018-9, 409725/2013-7, 310666/2016-3, 438314/2018-2,
   312866/2019-4]
FX CNPq provided funds to this research, grants 435173/2018-9 (FB),
   409725/2013-7 (HK), 310666/2016-3 (HK), 438314/2018-2 (HK), and
   312866/2019-4 (HK).
NR 35
TC 2
Z9 2
U1 5
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2314-7202
EI 2314-7210
J9 FUTUR BUS J
JI Futur. Bus. J.
PD NOV 15
PY 2020
VL 6
IS 1
AR 37
DI 10.1186/s43093-020-00041-w
PG 14
WC Business
WE Emerging Sources Citation Index (ESCI)
SC Business & Economics
GA OX3QA
UT WOS:000593482200001
OA gold, Green Published
DA 2022-04-17
ER

PT C
AU Geist, V
   Moser, M
   Pichler, J
   Beyer, S
   Pinzger, M
AF Geist, Verena
   Moser, Michael
   Pichler, Josef
   Beyer, Stefanie
   Pinzger, Martin
BE Kontogiannis, K
   Khomh, F
   Chatzigeorgiou, A
   Fokaefs, ME
   Zhou, M
TI Leveraging Machine Learning for Software Redocumentation
SO PROCEEDINGS OF THE 2020 IEEE 27TH INTERNATIONAL CONFERENCE ON SOFTWARE
   ANALYSIS, EVOLUTION, AND REENGINEERING (SANER '20)
LA English
DT Proceedings Paper
CT 27th IEEE International Conference on Software Analysis, Evolution, and
   Reengineering (SANER)
CY FEB 18-21, 2020
CL London, CANADA
SP IEEE, IEEE Comp Soc, Western Univ, IEEE Tech Council Software Engn
DE software redocumentation; legacy system; comment classification
   pipeline; heuristic rules; machine learning; NLP; CNNs
AB Source code comments contain key information about the underlying software system. Many redocumentation approaches, however, cannot exploit this valuable source of information. This is mainly due to the fact that not all comments have the same goals and target audience and can therefore only be used selectively for redocumentation. Performing a required classification manually, e.g. in the form of heuristic rules, is usually time-consuming and error-prone and strongly dependent on programming languages and guidelines of concrete software systems. By leveraging machine learning, it should be possible to classify comments and thus transfer valuable information from the source code into documentation with less effort but the same quality. We applied different machine learning techniques to a COBOL legacy system and compared the results with industry-strength heuristic classification. As a result, we found that machine learning outperforms the heuristics in number of errors and less effort.
C1 [Geist, Verena; Moser, Michael] Software Competence Ctr Hagenberg GmbH, Software Analyt & Evolut, Hagenberg, Austria.
   [Pichler, Josef] Univ Appl Sci Upper Austria, Dept Software Engn, Hagenberg, Austria.
   [Beyer, Stefanie; Pinzger, Martin] Alpen Adria Univ Klagenfurt, Software Engn Res Grp, Klagenfurt, Austria.
RP Geist, V (corresponding author), Software Competence Ctr Hagenberg GmbH, Software Analyt & Evolut, Hagenberg, Austria.
EM verena.geist@scch.at; michael.moser@scch.at;
   josef.pichler@fh-hagenberg.at; stefanie.beyer@aau.at;
   martin.pinzger@aau.at
RI Fritola, Renato/AAU-4721-2021
FU Austrian Ministry for Transport, Innovation and Technology; Federal
   Ministry for Digital and Economic Affairs; Province of Upper Austria
FX The research reported in this paper has been partly supported by the
   Austrian Ministry for Transport, Innovation and Technology, the Federal
   Ministry for Digital and Economic Affairs, and the Province of Upper
   Austria in the frame of the COMET center SCCH.
NR 14
TC 5
Z9 5
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-5143-4
PY 2020
BP 622
EP 626
PG 5
WC Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BP8WU
UT WOS:000568240800066
DA 2022-04-17
ER

PT J
AU Basu, S
   Faghmous, JH
   Doupe, P
AF Basu, Sanjay
   Faghmous, James H.
   Doupe, Patrick
TI MACHINE LEARNING METHODS FOR PRECISION MEDICINE RESEARCH DESIGNED TO
   REDUCE HEALTH DISPARITIES: A STRUCTURED TUTORIAL
SO ETHNICITY & DISEASE
LA English
DT Article
DE Machine Learning; Precision Medicine; Health Disparities; Gradient
   Boosting Machines; Random Forest; Deep Learning
ID REGRESSION; MODELS
AB Precision medicine research designed to reduce health disparities often involves studying multi-level datasets to understand how diseases manifest disproportionately in one group over another, and how scarce health care resources can be directed precisely to those most at risk for disease. In this article, we provide a structured tutorial for medical and public health researchers on the application of machine learning methods to conduct precision medicine research designed to reduce health disparities. We review key terms and concepts for understanding machine learning papers, including supervised and unsupervised learning, regularization, cross-validation, bagging, and boosting. Metrics are reviewed for evaluating machine learners and major families of learning approaches, including tree-based learning, deep learning, and ensemble learning. We highlight the advantages and disadvantages of different learning approaches, describe strategies for interpreting "black box" models, and demonstrate the application of common methods in an example dataset with open-source statistical code in R.
C1 [Basu, Sanjay] Collect Hlth, Res & Analyt, San Francisco, CA USA.
   [Basu, Sanjay] Harvard Med Sch, Ctr Primary Care, Boston, MA 02115 USA.
   [Basu, Sanjay] Imperial Coll London, Sch Publ Hlth, London, England.
   [Doupe, Patrick] Zalando ES, Berlin, Germany.
RP Basu, S (corresponding author), 635 Huntington Ave,Second Floor, Boston, MA 02115 USA.
EM sanjay_basu@hms.harvard.edu
FU National Institute on Minority Health And Health Disparities of the
   National Institutes of Health [U54MD010724, DP2MD010478]
FX Research reported in this publication was supported by the National
   Institute on Minority Health And Health Disparities of the National
   Institutes of Health under Award Numbers U54MD010724 and DP2MD010478.
   The content is solely the responsibility of the authors and does not
   necessarily represent the official views of the National Institutes of
   Health. SB is employed by Collective Health, which uses machine learning
   methods to support care navigation programs. SB has previously received
   grants, stipends or consulting fees, unrelated to the current work, from
   the US National Institutes of Health, US Centers for Disease and
   Prevention, US Department of Agriculture's Economic Research Service,
   Center for Poverty Research, KPMG, Research Triangle International, the
   Robert Wood Johnson Foundation, Harvard University, Stanford University,
   and PLOS Medicine.
NR 27
TC 1
Z9 1
U1 2
U2 3
PU INT SOC HYPERTENSION BLACKS-ISHIB
PI ATLANTA
PA 100 AUBURN AVE NE STE 401, ATLANTA, GA 30303-2527 USA
SN 1049-510X
EI 1945-0826
J9 ETHNIC DIS
JI Ethn. Dis.
PD APR
PY 2020
VL 30
SU 1
SI SI
BP 217
EP 228
DI 10.18865/ed.30.S1.217
PG 12
WC Public, Environmental & Occupational Health
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Public, Environmental & Occupational Health
GA KZ5RE
UT WOS:000523318600012
PM 32269464
OA Green Published, Bronze
DA 2022-04-17
ER

PT J
AU West, R
   Burbano, A
AF West, Ruth
   Burbano, Andres
TI AI Arts & Design: Questioning Learning Machines
SO ARTNODES
LA English
DT Article
DE artificial intelligence; machine learning: Al; ML; arts; design
AB Explorations of the relationship between Artificial Intelligence (AI), the arts, and design have existed throughout the historical development of AI. We are currently witnessing exponential growth in the application of Machine Learning (ML) and AI in all domains of art (visual, sonic, performing, spatial, transmedia, audiovisual, and narrative) in parallel with activity in the field that is so rapid that publication can not keep pace. In dialogue with our contemplation about this development in the arts, authors in this issue answer with questions of their own. Through questioning authorship and ethics, autonomy and automation, exploring the contribution of art to AI, algorithmic bias, control structures, machine intelligence in public art, formalization of aesthetics, the production of culture, socio-technical dimensions, relationships to games and aesthetics, and democratization of machine-based creative tools the contributors provide a multifaceted view into crucial dimensions of the present and future of creative AI. In this Artnodes special issue, we pose the question: Does generative and machine creativity in the arts and design represent an evolution of "artistic intelligence," or is it a metamorphosis of creative practice yielding fundamentally distinct forms and modes of authorship?
C1 [West, Ruth] Univ North Texas, xREZ Art Sci Lab, Denton, TX 76203 USA.
   [West, Ruth] Leonardo Int Soc Art Sci & Technol, Oakland, CA 94612 USA.
   [Burbano, Andres] Univ Los Andes, Sch Architecture & Design, Bogota, Colombia.
   [Burbano, Andres] Leonardo Int Soc Art Sci & Technol, LEAF Int Liaison, Oakland, CA USA.
RP West, R (corresponding author), Univ North Texas, xREZ Art Sci Lab, Denton, TX 76203 USA.; West, R (corresponding author), Leonardo Int Soc Art Sci & Technol, Oakland, CA 94612 USA.
NR 16
TC 1
Z9 1
U1 9
U2 15
PU UNIV OBERTA CATALUNYA
PI BARCELONA
PA AV TIBIDABO 39-43, BARCELONA, 08035, SPAIN
SN 1695-5951
J9 ARTNODES
JI Artnodes
PY 2020
IS 26
DI 10.7238/a.v0i26.3390
PG 9
WC Humanities, Multidisciplinary
WE Emerging Sources Citation Index (ESCI)
SC Arts & Humanities - Other Topics
GA MQ1BT
UT WOS:000552632500015
OA gold
DA 2022-04-17
ER

PT C
AU Thulasidas, M
AF Thulasidas, Manoj
BE Mitsuhara, H
   Goda, Y
   Ohashi, Y
   Rodrigo, MT
   Shen, J
   Venkatarayalu, N
   Wong, G
   Yamada, M
   Lei, CU
TI Nearest Centroid: A Bridge between Statistics and Machine Learning
SO PROCEEDINGS OF 2020 IEEE INTERNATIONAL CONFERENCE ON TEACHING,
   ASSESSMENT, AND LEARNING FOR ENGINEERING (IEEE TALE 2020)
SE Proceedings of IEEE International Conference on Teaching Assessment and
   Learning for Engineering
LA English
DT Proceedings Paper
CT IEEE International Conference on Teaching, Assessment, and Learning for
   Engineering (IEEE TALE)
CY DEC 08-11, 2020
CL IEEE Shikoku Sect, ELECTR NETWORK
SP IEEE, IEEE Educ Soc, Japanese Soc Informat & Syst Educ, Japan Soc Educ Technol, Telecommunicat Advancement Fdn
HO IEEE Shikoku Sect
DE statistical thinking; applied statistics; machine learning; nearest
   centroid; k-means clustering; k nearest neighbor
AB In order to guide our students of machine learning in their statistical thinking, we need conceptually simple and mathematically defensible algorithms. In this paper, we present the Nearest Centroid algorithm (NC) algorithm as a pedagogical tool, combining the key concepts behind two foundational algorithms: K-Means clustering and K Nearest Neighbors (kNN). In NC, we use the centroid (as defined in the K-Means algorithm) of the observations belonging to each class in our training data set and its distance from a new observation (similar to k-NN) for class prediction. Using this obvious extension, we will illustrate how the concepts of probability and statistics are applied in machine learning algorithms. Furthermore, we will describe how the practical aspects of validation and performance measurements are carried out. The algorithm and the work presented here can be easily converted to labs and reading assignments to cement the students' understanding of applied statistics and its connection to machine learning algorithms, as described toward the end of this paper.
C1 [Thulasidas, Manoj] Singapore Management Univ, Sch Informat Syst, Singapore, Singapore.
RP Thulasidas, M (corresponding author), Singapore Management Univ, Sch Informat Syst, Singapore, Singapore.
EM manojt@smu.edu.sg
NR 30
TC 0
Z9 0
U1 3
U2 5
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2374-0191
BN 978-1-7281-6942-2
J9 PR IEEE INT CONF TEA
PY 2020
BP 9
EP 16
DI 10.1109/TALE48869.2020.9368396
PG 8
WC Education, Scientific Disciplines; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Education & Educational Research; Engineering
GA BR6NG
UT WOS:000662184600007
OA Green Accepted
DA 2022-04-17
ER

PT J
AU Belle, V
   Papantonis, I
AF Belle, Vaishak
   Papantonis, Ioannis
TI Principles and Practice of Explainable Machine Learning
SO FRONTIERS IN BIG DATA
LA English
DT Review
DE survey; explainable AI; black-box models; transparent models; machine
   learning
ID NEURAL-NETWORKS; RULE EXTRACTION; EXPLANATION; DECISIONS
AB Artificial intelligence (AI) provides many opportunities to improve private and public life. Discovering patterns and structures in large troves of data in an automated manner is a core component of data science, and currently drives applications in diverse areas such as computational biology, law and finance. However, such a highly positive impact is coupled with a significant challenge: how do we understand the decisions suggested by these systems in order that we can trust them? In this report, we focus specifically on data-driven methods-machine learning (ML) and pattern recognition models in particular-so as to survey and distill the results and observations from the literature. The purpose of this report can be especially appreciated by noting that ML models are increasingly deployed in a wide range of businesses. However, with the increasing prevalence and complexity of methods, business stakeholders in the very least have a growing number of concerns about the drawbacks of models, data-specific biases, and so on. Analogously, data science practitioners are often not aware about approaches emerging from the academic literature or may struggle to appreciate the differences between different methods, so end up using industry standards such as SHAP. Here, we have undertaken a survey to help industry practitioners (but also data scientists more broadly) understand the field of explainable machine learning better and apply the right tools. Our latter sections build a narrative around a putative data scientist, and discuss how she might go about explaining her models by asking the right questions. From an organization viewpoint, after motivating the area broadly, we discuss the main developments, including the principles that allow us to study transparent models vs. opaque models, as well as model-specific or model-agnostic post-hoc explainability approaches. We also briefly reflect on deep learning models, and conclude with a discussion about future research directions.
C1 [Belle, Vaishak; Papantonis, Ioannis] Univ Edinburgh, Sch Informat, Edinburgh, Midlothian, Scotland.
   [Belle, Vaishak] Alan Turing Inst, London, England.
RP Papantonis, I (corresponding author), Univ Edinburgh, Sch Informat, Edinburgh, Midlothian, Scotland.
EM i.papantonis@sms.ed.ac.uk
FU Royal Society University Research FellowshipRoyal Society of London;
   EPSRCUK Research & Innovation (UKRI)Engineering & Physical Sciences
   Research Council (EPSRC); NatWest Group
FX VB was partly supported by a Royal Society University Research
   Fellowship. IP was partly supported by the EPSRC grant Towards
   Explainable and Robust Statistical AI: A Symbolic Approach. The authors
   acknowledge the financial support received by NatWest Group. This work
   was carried out in collaboration with University of Edinburgh's Bayes
   Centre and NatWest Group. We are especially grateful to Peter Gostev
   from the Data Strategy and Innovation team as well as a wide range of
   teams throughout Data and Analytics function at NatWest Group who
   provided insights on industry use cases, key issues faced by financial
   institutions as well as on the applicability of machine learning
   techniques in practice.
NR 111
TC 6
Z9 6
U1 23
U2 28
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2624-909X
J9 FRONT BIG DATA
JI Front. Big Data
PD JUL 1
PY 2021
VL 4
AR 688969
DI 10.3389/fdata.2021.688969
PG 25
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Multidisciplinary Sciences
WE Emerging Sources Citation Index (ESCI)
SC Computer Science; Science & Technology - Other Topics
GA TL4VZ
UT WOS:000674857200001
PM 34278297
OA gold, Green Submitted, Green Published
DA 2022-04-17
ER

PT J
AU Bognar, L
   Fauszt, T
   Nagy, GZ
AF Bognar, Laszlo
   Fauszt, Tibor
   Nagy, Gabor Zsolt
TI Analysis of Conditions for Reliable Predictions by Moodle Machine
   Learning Models
SO INTERNATIONAL JOURNAL OF EMERGING TECHNOLOGIES IN LEARNING
LA English
DT Article
DE Machine learning; online learning; student success; Moodle
AB In this paper the issue of bias-variance trade-off in building and operating Moodle Machine Learning (ML) models are discussed to avoid traps of getting unreliable predictions. Moodle is one of the world's most popular open-source Learning Management System (LMS) with millions of users. Although since Moodle 3.4 release it is possible to create ML models within the LMS system very few studies have been published so far about the conditions of its proper application. Using these models as black boxes hold serious risks to get unreliable predictions and false alarms. From a comprehensive study of differently built machine learning models elaborated at the University of Dunaujvaros in Hungary, one specific issue is addressed here, namely the influence of the size and the row-column ratio of the predictor matrix on the goodness of the predictions. In the so-called Time Splitting Method in Moodle Learning Analytics the effect of varying numbers of time splits and of predictors has also been studied to see their influence on the bias and the variance of the models. An Applied Statistics course is used to demonstrate the consequences of the different model set up.
C1 [Bognar, Laszlo] Univ Dunaujvaros, Appl Stat, Tancsics M U 1, H-2400 Dunaujvaros, Hungary.
   [Fauszt, Tibor] Budapest Business Sch Univ Appl Sci, Informat Technol, Buzogany U 10-12, H-1149 Budapest, Hungary.
   [Nagy, Gabor Zsolt] Eduroll Consulting, Zsokavar U 18, H-1157 Budapest, Hungary.
RP Fauszt, T (corresponding author), Budapest Business Sch Univ Appl Sci, Informat Technol, Buzogany U 10-12, H-1149 Budapest, Hungary.
EM fauszt.tibor@uni-bge.hu
RI Bognár, László/ABA-2063-2021
NR 22
TC 2
Z9 2
U1 2
U2 5
PU KASSEL UNIV PRESS GMBH
PI KASSEL
PA DIAGONALE 10, D-34127 KASSEL, GERMANY
SN 1863-0383
J9 INT J EMERG TECHNOL
JI Int. J. Emerg. Technol. Learn.
PY 2021
VL 16
IS 6
BP 106
EP 121
DI 10.3991/ijet.v16i06.18347
PG 16
WC Education & Educational Research
WE Emerging Sources Citation Index (ESCI)
SC Education & Educational Research
GA RG6BC
UT WOS:000635620300007
OA gold
DA 2022-04-17
ER

PT J
AU Kansal, P
   Kumar, A
   Gangadharappa, M
AF Kansal, P.
   Kumar, A.
   Gangadharappa, M.
TI Optimized Extreme Learning Machine for Intelligent Spectrum Sensing in
   5G systems
SO JOURNAL OF COMMUNICATIONS TECHNOLOGY AND ELECTRONICS
LA English
DT Article
DE extreme learning machine; BAT algorithm; support vector machine;
   spectrum sensing; optimization
ID COGNITIVE RADIO
AB A two-level learned distributed networking (LDN) structure that uses existing machine learning (ML) algorithms and the novel Optimized Extreme Learning Machine (OELM) algorithm to perform intelligent spectrum sensing for 5G systems has been proposed and implemented. This novel technique uses input vectors like received signal strength indicator, the distance between Cognitive Radio users and gateways, and energy vectors to train the model. Extreme Learning Machine optimized by BAT algorithm outperforms the existing Machine Learning techniques in terms of detection accuracy, false alarm, detection probability and cross validation curves at different SNR scenarios.
C1 [Kansal, P.; Kumar, A.] Indira Gandhi Delhi Tech Univ, New Church Rd,Opp St, Delhi 110006, India.
   [Gangadharappa, M.] Ambedkar Inst Adv Commun Technol & Res, Krishna Nagar Rd,Geeta Colony, Delhi 110031, India.
RP Kansal, P (corresponding author), Indira Gandhi Delhi Tech Univ, New Church Rd,Opp St, Delhi 110006, India.
EM parnikakansal@gmail.com
NR 26
TC 0
Z9 0
U1 5
U2 8
PU PLEIADES PUBLISHING INC
PI NEW YORK
PA PLEIADES HOUSE, 7 W 54 ST, NEW YORK,  NY, UNITED STATES
SN 1064-2269
EI 1555-6557
J9 J COMMUN TECHNOL EL+
JI J. Commun. Technol. Electron.
PD MAR
PY 2021
VL 66
IS 3
BP 322
EP 332
DI 10.1134/S1064226921040045
PG 11
WC Engineering, Electrical & Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Telecommunications
GA RM7TW
UT WOS:000639862400012
DA 2022-04-17
ER

PT C
AU Matera, F
AF Matera, Francesco
BE Pietralunga, SM
   Selleri, S
TI MACHINE LEARNING IN SOA OPTICAL COMMUNICATION SYSTEMS
SO PROCEEDINGS OF 2020 ITALIAN CONFERENCE ON OPTICS AND PHOTONICS (ICOP)
LA English
DT Proceedings Paper
CT Italian Conference on Optics and Photonics (ICOP)
CY SEP 08-11, 2020
CL ELECTR NETWORK
SP Univ Parma, IEEE, IEEE Photon Soc Italy Chapter, Consorzio Nazl Interuniversitario Telecomunicazioni, Soc Italiana Ottica Fotonica, Soc Italiana Elettronica, IEEE Photon Soc, Photonics21, Soc Italiana Elettromagnetismo
DE SOA; IM-DD; Kerr; Machine Learning; Neural networks
ID NETWORKS
AB The performance of cascaded optical communication systems with in-line semiconductor optical amplifiers is evaluated by means of machine learning approaches based both on a regression model and an artificial neural network.
C1 [Matera, Francesco] Fdn Ugo Bordoni, Via Policlin 147, I-00161 Rome, Italy.
RP Matera, F (corresponding author), Fdn Ugo Bordoni, Via Policlin 147, I-00161 Rome, Italy.
EM fmatera@fub.it
NR 14
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-6239-3
PY 2020
PG 4
WC Engineering, Electrical & Electronic; Nanoscience & Nanotechnology;
   Optics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering; Science & Technology - Other Topics; Optics
GA BR5DC
UT WOS:000654210800004
DA 2022-04-17
ER

PT J
AU Pushpanathan, K
   Hanafi, M
   Mashohor, S
   Ilahi, WFF
AF Pushpanathan, Kalananthni
   Hanafi, Marsyita
   Mashohor, Syamsiah
   Ilahi, Wan Fazilah Fazlil
TI Machine learning in medicinal plants recognition: a review
SO ARTIFICIAL INTELLIGENCE REVIEW
LA English
DT Review
DE Medicinal plants; Machine learning; Leaf identification; Classification
ID K-NEAREST-NEIGHBOR; AUTOMATIC CLASSIFICATION; SHAPE-FEATURES; LEAF;
   IDENTIFICATION; RETRIEVAL; IMAGES; LEAVES
AB Medicinal plants are gaining attention in the pharmaceutical industry due to having less harmful effects reactions and cheaper than modern medicine. Based on these facts, many researchers have shown considerable interest in the research of automatic medicinal plants recognition. There are various opportunities for advancement in producing a robust classifier that has the ability to classify medicinal plants accurately in real-time. In this paper, various effective and reliable machine learning algorithms for plant classifications using leaf images that have been used in recent years are reviewed. The review includes the image processing methods used to detect leaf and extract important leaf features for some machine learning classifiers. These machine learning classifiers are categorised according to their performance when classifying leaf images based on typical plant features, namely shape, vein, texture and a combination of multiple features. The leaf databases that are publicly available for automatic plants recognition are reviewed as well and we conclude with a discussion of prominent ongoing research and opportunities for enhancement in this area.
C1 [Pushpanathan, Kalananthni; Hanafi, Marsyita; Mashohor, Syamsiah] Univ Putra Malaysia, Fac Engn, Upm Serdang 43400, Selangor Darul, Malaysia.
   [Ilahi, Wan Fazilah Fazlil] Univ Putra Malaysia, Fac Agr, Upm Serdang 43400, Selangor Darul, Malaysia.
RP Hanafi, M (corresponding author), Univ Putra Malaysia, Fac Engn, Upm Serdang 43400, Selangor Darul, Malaysia.
EM kalananthni19@gmail.com; marsyita@upm.edu.my; syamsiah@upm.edu.my;
   wanfazilah@upm.edu.my
OI Pushpanathan, Kalananthni/0000-0003-1290-1087
FU Ministry of Education, Malaysia under a Fundamental Research Grant
   Scheme (FRGS) [5540078]; Universiti Putra Malaysia under IPS Grants
   [GP-IPS/2017/9529000, GP-IPS/2017/9634300]
FX The authors wish to acknowledge the financial supports received from the
   Ministry of Education, Malaysia under a Fundamental Research Grant
   Scheme (FRGS) (Vot Number: 5540078) and Universiti Putra Malaysia under
   IPS Grants (Vot Numbers: GP-IPS/2017/9529000 and GP-IPS/2017/9634300).
NR 97
TC 2
Z9 2
U1 6
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0269-2821
EI 1573-7462
J9 ARTIF INTELL REV
JI Artif. Intell. Rev.
PD JAN
PY 2021
VL 54
IS 1
BP 305
EP 327
DI 10.1007/s10462-020-09847-0
EA MAY 2020
PG 23
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PU3JQ
UT WOS:000532132700001
OA Green Accepted
DA 2022-04-17
ER

PT J
AU Chen, X
   Wang, LF
   Gao, XY
   Zhao, YF
   Lin, DY
   Chu, WD
   Song, HF
AF Chen, Xin
   Wang, Li-Fang
   Gao, Xing-Yu
   Zhao, Ya-Fan
   Lin, De-Ye
   Chu, Wei-Dong
   Song, Hai-Feng
TI Machine learning enhanced empirical potentials for metals and alloys
SO COMPUTER PHYSICS COMMUNICATIONS
LA English
DT Article
DE Machine learning; Alloy; Materials modeling; Computational physics;
   Empirical potentials
ID EMBEDDED-ATOM POTENTIALS; GLOBAL OPTIMIZATION; APPROXIMATION; STABILITY;
   CHEMISTRY; SURFACES; CLUSTERS; MODELS; SYSTEM; PHASE
AB Interatomic potential (i.e. force-field) plays a vital role in atomistic simulation of materials. Empirical potentials like the embedded atom method (EAM) and its variant angular-dependent potential (ADP) have proven successful in many metals. In the past few years, machine learning has become a compelling approach for modeling interatomic interactions. Powered by big data and efficient optimizers, machine learning interatomic potentials can generally approximate to the accuracy of the first-principles calculations based on the quantum mechanics theory. In this works, we successfully developed a route to express EAM and ADP within machine learning framework in highly-vectorizable form and further incorporated several physical constraints into the training. As it is proved in this work, the performances of empirical potentials can be significantly boosted with few training data. For energy and force predictions, machine tuned EAM and ADP, can be almost as accurate as the computationally expensive spectral neighbor analysis potential (SNAP) on the fcc Ni, bcc Mo and Mo-Ni alloy systems. Machine learned EAM and ADP can also reproduce some key materials properties, such as elastic constants, melting temperatures and surface energies, close to the first-principles accuracy. Our results suggest a new and systematic route for developing machine learning interatomic potentials. All the new algorithms have been implemented in our program TensorAlloy.
   Program summary
   Program Title: TensorAlloy
   CPC Library link to program files: https://doi.org/10.17632/w8htd7vmwh.2
   Code Ocean capsule: https://codeocean.com/capsule/1671487
   Licensing provisions: LGPL
   Programming language: Python 3.7
   Journal reference of previous version: Comput. Phys. Commun. 250 (2020) 107057, https://doi.org/10.1016/j.cpc.2019.107057
   Does the new version supersede the previous version?: Yes
   Reasons for the new version: This new version is a significant extension to the previous version. Now machine learning approaches and physical constraints can be used together to tune empirical potentials (for example the embedded atom method). Machine learning optimized empirical potentials can be almost as accurate as machine learning interaction potentials but run much faster.
   Nature of problem: Optimizing empirical potentials with machine learning approaches and physical constraints.
   Solution method: The TensorAlloy program is built upon TensorFlow and the virtual-atom approach. We successfully developed a route to express the embedded atom method and the angular-dependent potential within machine learning framework in highly-vectorizable form and further enhanced the potentials with physical constraints. Machine learning can significantly boost their performances with few training data.
   Additional comments including restrictions and unusual features: This program needs TensorFlow 1.14.*. Neither newer or older TensorFlow is supported. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Chen, Xin; Wang, Li-Fang; Gao, Xing-Yu; Chu, Wei-Dong; Song, Hai-Feng] Inst Appl Phys & Computat Math, Beijing 100088, Peoples R China.
   [Zhao, Ya-Fan; Lin, De-Ye] CAEP Software Ctr High Performance Numer Simulat, Beijing 100088, Peoples R China.
RP Song, HF (corresponding author), Inst Appl Phys & Computat Math, Beijing 100088, Peoples R China.; Lin, DY (corresponding author), CAEP Software Ctr High Performance Numer Simulat, Beijing 100088, Peoples R China.
EM lindeye0716@163.com; song_haifeng@iapcm.ac.cn
OI Lin, De-Ye/0000-0002-1944-7342
FU National Key Research and De-velopment Program of China
   [2016YFB0201204]; Science Challenge Project [TZ2018002]; National
   Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [U1630250, 12002064, 12004046]
FX This work was supported by the National Key Research and De-velopment
   Program of China under Grant No. 2016YFB0201204, the Science Challenge
   Project under Grant No. TZ2018002, the National Natural Science
   Foundation of China under Grant No. U1630250, No. 12002064 and No.
   12004046.
NR 60
TC 0
Z9 0
U1 20
U2 27
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0010-4655
EI 1879-2944
J9 COMPUT PHYS COMMUN
JI Comput. Phys. Commun.
PD DEC
PY 2021
VL 269
AR 108132
DI 10.1016/j.cpc.2021.108132
EA AUG 2021
PG 11
WC Computer Science, Interdisciplinary Applications; Physics, Mathematical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Physics
GA UP2WY
UT WOS:000695246200008
DA 2022-04-17
ER

PT J
AU Casadio, R
   Martelli, PL
   Savojardo, C
AF Casadio, Rita
   Martelli, Pier Luigi
   Savojardo, Castrense
TI Machine learning solutions for predicting protein-protein interactions
SO WILEY INTERDISCIPLINARY REVIEWS-COMPUTATIONAL MOLECULAR SCIENCE
LA English
DT Review; Early Access
DE deep learning; machine learning; protein-protein interactions
ID INTERACTION SITES PREDICTION; STATISTICAL-ANALYSIS; PHASE-SEPARATION;
   CONSERVATION; FINGERPRINTS; COVARIANCE; NETWORKS; RESIDUES; ACCURATE
AB Proteins are "social molecules." Recent experimental evidence supports the notion that large protein aggregates, known as biomolecular condensates, affect structurally and functionally many biological processes. Condensate formation may be permanent and/or time dependent, suggesting that biological processes can occur locally, depending on the cell needs. The question then arises as to which extent we can monitor protein-aggregate formation, both experimentally and theoretically and then predict/simulate functional aggregate formation. Available data are relative to mesoscopic interacting networks at a proteome level, to protein-binding affinity data, and to interacting protein complexes, solved with atomic resolution. Powerful algorithms based on machine learning (ML) can extract information from data sets and infer properties of never-seen-before examples. ML tools address the problem of protein-protein interactions (PPIs) adopting different data sets, input features, and architectures. According to recent publications, deep learning is the most successful method. However, in ML-computational biology, convincing evidence of a success story comes out by performing general benchmarks on blind data sets. Results indicate that the state-of-the-art ML approaches, based on traditional and/or deep learning, can still be ameliorated, irrespectively of the power of the method and richness in input features. This being the case, it is quite evident that powerful methods still are not trained on the whole possible spectrum of PPIs and that more investigations are necessary to complete our knowledge of PPI-functional interactions. This article is categorized under: Software > Molecular Modeling Structure and Mechanism > Computational Biochemistry and Biophysics Data Science > Artificial Intelligence/Machine Learning Molecular and Statistical Mechanics > Molecular Interactions
C1 [Casadio, Rita; Martelli, Pier Luigi; Savojardo, Castrense] Univ Bologna, Biocomp Grp, Bologna, Italy.
RP Martelli, PL (corresponding author), Univ Bologna, Biocomp Grp, Bologna, Italy.
EM pierluigi.martelli@unibo.it
FU Italian Ministry of University and ResearchMinistry of Education,
   Universities and Research (MIUR) [2017483NH8_002]
FX The work was supported by PRIN2017 grant (project 2017483NH8_002),
   delivered to CS by the Italian Ministry of University and Research.
NR 118
TC 0
Z9 0
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1759-0876
EI 1759-0884
J9 WIRES COMPUT MOL SCI
JI Wiley Interdiscip. Rev.-Comput. Mol. Sci.
AR e1618
DI 10.1002/wcms.1618
EA MAR 2022
PG 21
WC Chemistry, Multidisciplinary; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Mathematical & Computational Biology
GA 0B4SO
UT WOS:000774626800001
DA 2022-04-17
ER

PT C
AU Zhou, P
   Lin, Q
   Loghin, D
   Ooi, BC
   Wu, YC
   Yu, HF
AF Zhou, Pan
   Lin, Qian
   Loghin, Dumitrel
   Ooi, Beng Chin
   Wu, Yuncheng
   Yu, Hongfang
GP IEEE
TI Communication-efficient Decentralized Machine Learning over
   Heterogeneous Networks
SO 2021 IEEE 37TH INTERNATIONAL CONFERENCE ON DATA ENGINEERING (ICDE 2021)
SE IEEE International Conference on Data Engineering
LA English
DT Proceedings Paper
CT 37th IEEE International Conference on Data Engineering (IEEE ICDE)
CY APR 19-22, 2021
CL ELECTR NETWORK
SP IEEE
DE distributed machine learning; decentralized machine learning;
   heterogeneous network; communication efficiency
AB In the last few years, distributed machine learning has been usually executed over heterogeneous networks such as a local area network within a multi-tenant cluster or a wide area network connecting data centers and edge clusters. In these heterogeneous networks, the link speeds among worker nodes vary significantly, making it challenging for state-of-the-art machine learning approaches to perform efficient training. Both centralized and decentralized training approaches suffer from low-speed links. In this paper, we propose a decentralized approach, namely NetMax, that enables worker nodes to communicate via high-speed links and, thus, significantly speed up the training process. NetMax possesses the following novel features. First, it consists of a novel consensus algorithm that allows worker nodes to train model copies on their local dataset asynchronously and exchange information via peer-to-peer communication to synchronize their local copies, instead of a central master node (i.e., parameter server). Second, each worker node selects one peer randomly with a fine-tuned probability to exchange information per iteration. In particular, peers with high-speed links are selected with high probability. Third, the probabilities of selecting peers are designed to minimize the total convergence time. Moreover, we mathematically prove the convergence of NetMax. We evaluate NetMax on heterogeneous cluster networks and show that it achieves speedups of 3.7x, 3.4x, and 1.9x in comparison with the state-of-the-art decentralized training approaches Prague, Allreduce-SGD, and AD-PSGD, respectively.
C1 [Zhou, Pan; Yu, Hongfang] Univ Elect Sci & Technol China, Chengdu, Peoples R China.
   [Zhou, Pan; Lin, Qian; Loghin, Dumitrel; Ooi, Beng Chin; Wu, Yuncheng] Natl Univ Singapore, Singapore, Singapore.
RP Zhou, P (corresponding author), Univ Elect Sci & Technol China, Chengdu, Peoples R China.
EM willzhoupan@gmail.com; linqian@comp.nus.edu.sg;
   dumitrel@comp.nus.edu.sg; ooibc@comp.nus.edu.sg; wuyc@comp.nus.edu.sg;
   yuhf@uestc.edu.cn
FU Singapore Ministry of Education Academic Research Fund Tier 3 under MOEs
   official grantMinistry of Education, Singapore [MOE2017-T3-1-007]; China
   Scholarship CouncilChina Scholarship Council
FX The work of Qian Lin, Dumitrel Loghin, Beng Chin Ooi, and Yuncheng Wu
   was supported by Singapore Ministry of Education Academic Research Fund
   Tier 3 under MOEs official grant number MOE2017-T3-1-007. The work of
   Pan Zhou was supported by the China Scholarship Council.
NR 29
TC 1
Z9 1
U1 4
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
SN 1084-4627
BN 978-1-7281-9184-3
J9 PROC INT CONF DATA
PY 2021
BP 384
EP 395
DI 10.1109/ICDE51399.2021.00040
PG 12
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS1DL
UT WOS:000687830800033
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Kaur, H
   Malhi, AK
   Pannu, HS
AF Kaur, Harkawalpreet
   Malhi, Avleen Kaur
   Pannu, Husanbir Singh
TI Machine learning ensemble for neurological disorders
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Machine learning; Soft-computing; Ensemble; Neurological disorders;
   Parkinson disease
ID PARKINSONS-DISEASE; REGRESSION; CLASSIFICATION; PROGRESSION; FREQUENCY;
   SPEECH; CART
AB Parkinson disease is a neurodegenerative disorder of the central nerve system which affects body movements. The proposed technique selects best five machine learning models competitively, out of 25 state-of-the-art regression models to generate a robust ensemble. Data from 42 patients having early stage of Parkinson disease were collected which contains a total of 5875 voice recordings. Numerous state-of-the-art machine learning models have been explored to predict the motor Unified Parkinson's Disease Rating Score (UPDRS) for the collected voice measures. Evaluation parameters such as correlation, R-Square, RMSE, and accuracy have been calculated for comparative analysis. Results from the ensemble model consisting of best five models have been recalculated to analyze the prediction. K-fold validation has been incorporated to measure the robustness of ensembled model. The proposed ensemble yields UPDRS with higher accuracy of 99.6% making it well suitable to assist the diagnose for Parkinson disease.
C1 [Kaur, Harkawalpreet; Malhi, Avleen Kaur; Pannu, Husanbir Singh] Thapar Univ, Comp Sci & Engn Dept, Patiala 147004, Punjab, India.
RP Pannu, HS (corresponding author), Thapar Univ, Comp Sci & Engn Dept, Patiala 147004, Punjab, India.
EM harkawalpannu20@gmail.com; avleen@thapar.edu; hspannu@thapar.edu
NR 49
TC 4
Z9 4
U1 5
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD AUG
PY 2020
VL 32
IS 16
BP 12697
EP 12714
DI 10.1007/s00521-020-04720-1
EA JAN 2020
PG 18
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MP3XS
UT WOS:000507959300001
DA 2022-04-17
ER

PT J
AU Bustillo, A
   Reis, R
   Machado, AR
   Pimenov, DY
AF Bustillo, Andres
   Reis, Roberto
   Machado, Alisson R.
   Pimenov, Danil Yu.
TI Improving the accuracy of machine-learning models with data from machine
   test repetitions
SO JOURNAL OF INTELLIGENT MANUFACTURING
LA English
DT Article
DE Machine learning; Artificial intelligence; Ensembles; Brandsma facing
   tests; Tool geometry; Turning
ID ARTIFICIAL NEURAL-NETWORKS; TOOL RAKE ANGLE; SURFACE-ROUGHNESS; CUTTING
   CONDITIONS; PREDICTION; WEAR; INTELLIGENCE; GEOMETRY; TRENDS; FORCE
AB The modelling of machining processes by means of machine-learning algorithms is still based on principles that are especially adapted to mechanical approaches, in which very few inputs are varied with little repetition of experimental conditions. These principles might not be ideal to achieve accurate machine-learning models and they are certainly not aligned with the practicalities of industrial machining in factories. In this research the effect of a new strategy to improve machine-learning model accuracy is studied: experimental repetition. Tool-life prediction in the face-turning operations of AISI 1045 steel discs, depending on different cooling systems and tool geometries, is selected as a case study. Both the side rake and the relief angles of HSS tools are optimized using the Brandsma facing test under dry, MQL, and flooding conditions. Different machine-learning algorithms, such as regression trees, kNNs, artificial neural networks, and ensembles (bagging and Random Forest) are tested. On the one hand, the results of the study showed that artificial neural networks of Radial Basis Functions presented the highest model accuracy (11.4 mm RMSE), but required a very sensitive and complex tuning process. On the other hand, they demonstrated that ensembles, especially Random Forest, provided models with accuracy in the same range, but with no tuning procedure (12.8 mm RMSE). Secondly, the effect of an increased dataset size, by means of experimental repetition, is evaluated and compared with traditional experimental modelling that used average values. The results showed that some machine-learning techniques, including both ensemble types, significantly improved their accuracy with this strategy, by up to 23%. The results therefore suggested that the use of raw experimental data, rather than their averaged values, can achieve machine-learning models of higher accuracy for tool-wear processes.
C1 [Bustillo, Andres] Univ Burgos, Dept Civil Engn, Avda Cantabria S-N, Burgos 09006, Spain.
   [Reis, Roberto; Machado, Alisson R.] Univ Fed Uberlandia, Sch Mech Engn, Av Joao Naves Avila 2121,Bloco 1M, BR-38400902 Uberlandia, MG, Brazil.
   [Machado, Alisson R.] Pontificia Univ Catolica Parana PUC PR, Grad Program Mech Engn, R Imaculada Conceicao 1155, BR-80215901 Curitiba, PR, Brazil.
   [Pimenov, Danil Yu.] South Ural State Univ, Dept Automated Mech Engn, Lenin Prosp 76, Chelyabinsk 454080, Russia.
RP Pimenov, DY (corresponding author), South Ural State Univ, Dept Automated Mech Engn, Lenin Prosp 76, Chelyabinsk 454080, Russia.
EM abustillo@ubu.es; rr3d_@hotmail.com; alissonr.rocha@pucpr.br;
   danil_u@rambler.ru
RI Pimenov, Danil Yu./D-9048-2013; Machado, Alisson Rocha/X-5521-2019;
   Bustillo, Andres/I-1403-2015
OI Pimenov, Danil Yu./0000-0002-5568-8928; Machado, Alisson
   Rocha/0000-0002-5388-2954; Bustillo, Andres/0000-0003-2855-7532
FU Ministerio de Economia y Competitividad of the Spanish Government
   through European Union FEDER funds [TIN2015-67534-P]; Junta de Castilla
   y Leon through European Union FEDER funds [BU085P17]; Act 211 of the
   Government of the Russian Federation [02.A03.21.0011]
FX This investigation was partially supported by Project TIN2015-67534-P of
   the Ministerio de Economia y Competitividad of the Spanish Government
   and by Project BU085P17 of the Junta de Castilla y Leon, both
   co-financed through European Union FEDER funds. The work was supported
   through Act 211 of the Government of the Russian Federation, under
   contract No. 02.A03.21.0011.
NR 61
TC 15
Z9 15
U1 5
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0956-5515
EI 1572-8145
J9 J INTELL MANUF
JI J. Intell. Manuf.
PD JAN
PY 2022
VL 33
IS 1
BP 203
EP 221
DI 10.1007/s10845-020-01661-3
EA SEP 2020
PG 19
WC Computer Science, Artificial Intelligence; Engineering, Manufacturing
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YC1KT
UT WOS:000570479500001
DA 2022-04-17
ER

PT J
AU Li, JX
   Zhang, ZX
   Guo, CY
AF Li, Jiaxin
   Zhang, Zhaoxin
   Guo, Changyong
TI Machine Learning-Based Malicious X.509 Certificates' Detection
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE HTTPS; malicious X; 509 certificates; machine learning
AB X.509 certificates play an important role in encrypting the transmission of data on both sides under HTTPS. With the popularization of X.509 certificates, more and more criminals leverage certificates to prevent their communications from being exposed by malicious traffic analysis tools. Phishing sites and malware are good examples. Those X.509 certificates found in phishing sites or malware are called malicious X.509 certificates. This paper applies different machine learning models, including classical machine learning models, ensemble learning models, and deep learning models, to distinguish between malicious certificates and benign certificates with Verification for Extraction (VFE). The VFE is a system we design and implement for obtaining plentiful characteristics of certificates. The result shows that ensemble learning models are the most stable and efficient models with an average accuracy of 95.9%, which outperforms many previous works. In addition, we obtain an SVM-based detection model with an accuracy of 98.2%, which is the highest accuracy. The outcome indicates the VFE is capable of capturing essential and crucial characteristics of malicious X.509 certificates.
C1 [Li, Jiaxin; Zhang, Zhaoxin; Guo, Changyong] Harbin Inst Technol, Sch Comp Sci & Technol, Network Informat Secur Res Ctr, Weihai 264200, Shandong, Peoples R China.
RP Zhang, ZX; Guo, CY (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Network Informat Secur Res Ctr, Weihai 264200, Shandong, Peoples R China.
EM 19s030153@stu.hit.edu.cn; heart@hit.edu.cn; guocy@hit.edu.cn
OI Li, Jiaxin/0000-0002-5366-843X
FU  [2018YFB0804703]
FX This researchwas fundedby theNationalKeyR&DProgramofChina (GrantNo.
   2018YFB0804703).
NR 30
TC 0
Z9 0
U1 3
U2 9
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD MAR
PY 2021
VL 11
IS 5
AR 2164
DI 10.3390/app11052164
PG 24
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Materials Science; Physics
GA QV4JF
UT WOS:000627939300001
OA gold
DA 2022-04-17
ER

PT C
AU Dhall, D
   Kaur, R
   Juneja, M
AF Dhall, Devanshi
   Kaur, Ravinder
   Juneja, Mamta
BE Singh, PK
   Kar, AK
   Singh, Y
   Kolekar, MH
   Tanwar, S
TI Machine Learning: A Review of the Algorithms and Its Applications
SO PROCEEDINGS OF RECENT INNOVATIONS IN COMPUTING, ICRIC 2019
SE Lecture Notes in Electrical Engineering
LA English
DT Proceedings Paper
CT 2nd International Conference on Recent Innovations in Computing (ICRIC)
CY MAR 08-09, 2019
CL Cent Univ Jammu, INDIA
HO Cent Univ Jammu
DE Algorithm; Machine learning; Data; Artificial intelligence
AB In today's world, machine learning has gained much popularity, and its algorithms are employed in every field such as pattern recognition, object detection, text interpretation and different research areas. Machine learning, a part of AI (artificial intelligence), is used in the designing of algorithms based on the recent trends of data. This paper aims at introducing the algorithms of machine learning, its principles and highlighting the advantages and disadvantages in this field. It also focuses on the advancements that have been carried out so that the current researchers can be benefitted out of it. Based on artificial intelligence, many techniques have been developed such as perceptron-based techniques and logic-based techniques and also in statistics, instance-based techniques and Bayesian networks. So, overall this paper produces the work done by the authors in the area of machine learning and its applications and to draw attention towards the scholars who are working in this field.
C1 [Dhall, Devanshi; Kaur, Ravinder; Juneja, Mamta] Punjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
RP Kaur, R; Juneja, M (corresponding author), Punjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
EM devanshidhall12@gmail.com; ravinder.kaur7@yahoo.com;
   mamtajuneja@pu.ac.in
OI Juneja, Mamta/0000-0002-2611-9005
NR 17
TC 20
Z9 20
U1 7
U2 7
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1876-1100
EI 1876-1119
BN 978-3-030-29407-6; 978-3-030-29406-9
J9 LECT NOTES ELECTR EN
PY 2020
VL 597
BP 47
EP 63
DI 10.1007/978-3-030-29407-6_5
PG 17
WC Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ6RC
UT WOS:000613001900005
DA 2022-04-17
ER

PT J
AU Nami, Y
   Imeni, N
   Panahi, B
AF Nami, Yousef
   Imeni, Nazila
   Panahi, Bahman
TI Application of machine learning in bacteriophage research
SO BMC MICROBIOLOGY
LA English
DT Review
DE Machine learning; Bacteriophage; Classification; Host; Life cycle
ID VIRION PROTEINS; PHAGE; INFECTION
AB Phages are one of the key components in the structure, dynamics, and interactions of microbial communities in different bins. It has a clear impact on human health and the food industry. Bacteriophage characterization using in vitro approaches are time/cost consuming and laborious tasks. On the other hand, with the advent of new high-throughput sequencing technology, the development of a powerful computational framework to characterize the newly identified bacteriophages is inevitable for future research. Machine learning includes powerful techniques that enable the analysis of complex datasets for knowledge discovery and pattern recognition. In this study, we have conducted a comprehensive review of machine learning methods application using different types of features were applied in various aspects of bacteriophage research including, automated curation, identification, classification, host species recognition, virion protein identification, and life cycle prediction. Moreover, potential limitations and advantages of the developed frameworks were discussed.
C1 [Nami, Yousef] Agr Res Educ & Extens Org AREEO, Agr Biotechnol Res Inst Iran, Branch Northwest & West Reg, Dept Food Biotechnol, Tabriz, Iran.
   [Imeni, Nazila] Islamic Azad Univ, Marand Branch, Young Researchers & Elite Clube, Marand, Iran.
   [Panahi, Bahman] Agr Res Educ & Extens Org AREEO, Agr Biotechnol Res Inst Iran, Branch Northwest & West Reg, Dept Genom, Tabriz, Iran.
RP Panahi, B (corresponding author), Agr Res Educ & Extens Org AREEO, Agr Biotechnol Res Inst Iran, Branch Northwest & West Reg, Dept Genom, Tabriz, Iran.
EM b.panahi@abrii.ac.ir
OI Panahi, Bahman/0000-0001-8523-994X
FU Agricultural Biotechnology Research Institute of Iran (ABRII)
   [12-05-05-008-99014-990780]
FX This work was supported by the Agricultural Biotechnology Research
   Institute of Iran (ABRII) [Grant number 12-05-05-008-99014-990780]. The
   funders had no role in study design, data collection and analysis,
   decision to publish, or preparation of the manuscript.
NR 53
TC 5
Z9 5
U1 12
U2 16
PU BMC
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 1471-2180
J9 BMC MICROBIOL
JI BMC Microbiol.
PD JUN 26
PY 2021
VL 21
IS 1
AR 193
DI 10.1186/s12866-021-02256-5
PG 8
WC Microbiology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Microbiology
GA TC4SA
UT WOS:000668629100002
PM 34174831
OA Green Published, gold
DA 2022-04-17
ER

PT S
AU Bishwas, AK
   Mani, A
   Palade, V
AF Bishwas, Arit Kumar
   Mani, Ashish
   Palade, Vasile
BE Bhattacharyya, S
   Pan, I
   Mani, A
   De, S
   Behrman, E
   Chakraborti, S
TI From classical to quantum machine learning
SO QUANTUM MACHINE LEARNING
SE De Gruyter Frontiers in Computational Intelligence
LA English
DT Article; Book Chapter
DE quantum algorithm; quantum random access memory (QRAM); quantum deep
   learning; quantum computation
AB In recent years, Machine Learning (ML) has started to be ubiquitously applied to practically most of the human activity domains. Although traditional, or classical machine learning (CML) approaches are useful in solving many complex tasks, there are still many challenges that such approaches are facing. One issue is the limitation in the processing speed of current silicon technology based computers, which made researchers look to the underlying quantum theory principles and try to run complex quantum computing experiments. In future, in order to develop more complex artificial intelligence systems, we will have to process huge amounts of data at high speed, and the existing classical computing will probably not serve well this purpose, due to silicon technology limitations. A different technology that can handle huge volumes of data and at high speed is needed. In recent years, the progress in quantum computing research seems to provide hopeful answers to overcome the speed processing barrier. This is very important for the training of many computational intensive machine learning models. The latest advancements in quantum technology appear to be promising, which can boost the field of machine learning overall. In this chapter, we discuss the transition from classical machine learning to quantum machine learning (QML) and explore the recent progress in this domain. QML is not only associated with the development of high-performance machine learning algorithms that can run on a quantum computer with significant performance improvements but also has a very diverse meaning in other aspects. The chapter tried to touch those aspects in brief too, but the main focus is on the advancements in the field of developing machine learning algorithms that will run on a quantum computer.
C1 [Bishwas, Arit Kumar] Amity Univ, AIIT, Noida, Uttar Pradesh, India.
   [Mani, Ashish] Amity Univ, ASET, EEE, Noida, Uttar Pradesh, India.
   [Palade, Vasile] Coventry Univ, Fac Engn & Comp, Coventry, W Midlands, England.
RP Bishwas, AK (corresponding author), Amity Univ, AIIT, Noida, Uttar Pradesh, India.
EM aritkumar.official@gmail.com; amani@amity.edu;
   vasile.palade@coventry.ac.uk
OI Bishwas, Arit Kumar/0000-0001-8064-2035
NR 50
TC 0
Z9 0
U1 0
U2 0
PU WALTER DE GRUYTER GMBH
PI BERLIN
PA GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY
SN 2512-8868
BN 978-3-11-067070-7; 978-3-11-067064-6
J9 DE GR FRONT COMPU IN
PY 2020
VL 6
BP 67
EP 87
DI 10.1515/9783110670707-004
D2 10.1515/9783110670707
PG 21
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic;
   Quantum Science & Technology
WE Book Citation Index – Science (BKCI-S)
SC Computer Science; Engineering; Physics
GA BQ5AP
UT WOS:000596459300005
DA 2022-04-17
ER

PT J
AU Coe, J
   Atay, M
AF Coe, James
   Atay, Mustafa
TI Evaluating Impact of Race in Facial Recognition across Machine Learning
   and Deep Learning Algorithms
SO COMPUTERS
LA English
DT Article
DE facial recognition; machine learning; deep learning; dataset; bias;
   race; ethnicity; fairness; diversity
ID FACE-RECOGNITION
AB The research aims to evaluate the impact of race in facial recognition across two types of algorithms. We give a general insight into facial recognition and discuss four problems related to facial recognition. We review our system design, development, and architectures and give an in-depth evaluation plan for each type of algorithm, dataset, and a look into the software and its architecture. We thoroughly explain the results and findings of our experimentation and provide analysis for the machine learning algorithms and deep learning algorithms. Concluding the investigation, we compare the results of two kinds of algorithms and compare their accuracy, metrics, miss rates, and performances to observe which algorithms mitigate racial bias the most. We evaluate racial bias across five machine learning algorithms and three deep learning algorithms using racially imbalanced and balanced datasets. We evaluate and compare the accuracy and miss rates between all tested algorithms and report that SVC is the superior machine learning algorithm and VGG16 is the best deep learning algorithm based on our experimental study. Our findings conclude the algorithm that mitigates the bias the most is VGG16, and all our deep learning algorithms outperformed their machine learning counterparts.
C1 [Coe, James; Atay, Mustafa] Winston Salem State Univ, Dept Comp Sci, Winston Salem, NC 27110 USA.
RP Coe, J; Atay, M (corresponding author), Winston Salem State Univ, Dept Comp Sci, Winston Salem, NC 27110 USA.
EM jcoe118@rams.wssu.edu; ataymu@wssu.edu
FU NSFNational Science Foundation (NSF) [1900087]
FX This research is funded by NSF Award #1900087. Any opinions, findings,
   conclusions, or recommendations expressed in this material are those of
   the author(s) and do not necessarily reflect the views of NSF.
NR 29
TC 1
Z9 1
U1 2
U2 2
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 2073-431X
J9 COMPUTERS
JI Computers
PD SEP
PY 2021
VL 10
IS 9
AR 113
DI 10.3390/computers10090113
PG 24
WC Computer Science, Interdisciplinary Applications
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA UV5AF
UT WOS:000699490400001
OA gold
DA 2022-04-17
ER

PT C
AU Duan, Y
   Zhang, Y
   Wu, JC
AF Duan, Yang
   Zhang, Yong
   Wu, Jiacheng
BE Xing, C
   Fu, X
   Zhang, Y
   Zhang, G
   Borjigin, C
TI Database Native Approximate Query Processing Based on Machine-Learning
SO WEB INFORMATION SYSTEMS AND APPLICATIONS (WISA 2021)
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 18th Web Information Systems and Applications Conference (WISA)
CY SEP 24-26, 2021
CL Kaifeng, PEOPLES R CHINA
SP China Comp Federat Tech Comm Informat Syst, Henan Univ, China Comp Federat
DE AQP; Machine learning; UDF; RDBMS; Database
AB With the worldwide digital transformation, many databases with large volumes appear and provide interesting insights analyzed by data scientists through all kinds of tools. The large volumes of them inevitably increase the workload of calculation, lengthen the response time of applications and negatively impact the user experience. Approximate Query Processing (AQP) is proposed to alleviate this issue. Although many researchers continuously improve the performance of AQP with the help of Machine Learning, there are few studies on embedding Machine Learning based AQP inside the relational database through User Defined Functions (UDF). In this paper, we focus on one specific kind of aggregate queries and present two different implementations to embed one Machine Learning based AQP inside Relational Database Management System (RDBMS) by taking advantage of UDF. Both implementations are able to calculate estimates with acceptable errors, and the implementation with external training and internal query processing has even better performance in term of response times.
C1 [Duan, Yang] Univ Illinois, Champaign, IL 61820 USA.
   [Duan, Yang] Tsinghua Univ, BNRist, Beijing, Peoples R China.
   [Zhang, Yong; Wu, Jiacheng] Tsinghua Univ, Inst Internet Ind, Dept Comp Sci & Technol, BNRist,RIIT, Beijing, Peoples R China.
RP Zhang, Y (corresponding author), Tsinghua Univ, Inst Internet Ind, Dept Comp Sci & Technol, BNRist,RIIT, Beijing, Peoples R China.
EM yangd4@illinois.edu; zhangyong05@tsinghua.edu.cn
FU National Key R&D Program of China [2020AAA0109603]; State Key Laboratory
   of Computer Architecture (ICT, CAS)Russian Academy of Sciences
   [CARCHA202008]
FX This work was supported by National Key R&D Program of
   China(2020AAA0109603), State Key Laboratory of Computer Architecture
   (ICT, CAS) under Grant No. CARCHA202008.
NR 18
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-87571-8; 978-3-030-87570-1
J9 LECT NOTES COMPUT SC
PY 2021
VL 12999
BP 74
EP 86
DI 10.1007/978-3-030-87571-8_7
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS7UO
UT WOS:000767941100007
DA 2022-04-17
ER

PT J
AU Jergensen, GE
   McGovern, A
   Lagerquist, R
   Smith, T
AF Jergensen, G. Eli
   McGovern, Amy
   Lagerquist, Ryan
   Smith, Travis
TI Classifying Convective Storms Using Machine Learning
SO WEATHER AND FORECASTING
LA English
DT Article
DE Convective storms; Classification; Decision trees; Machine learning;
   Support vector machines
ID SEVERE WEATHER; SEVERE THUNDERSTORMS; HOURLY ASSIMILATION; FORECAST
   CYCLE; SQUALL LINES; PART I; PREDICTION; MODEL; CLASSIFICATION;
   REGULARIZATION
AB We demonstrate that machine learning (ML) can skillfully classify thunderstorms into three categories: supercell, part of a quasi-linear convective system, or disorganized. These classifications are based on radar data and environmental information obtained through a proximity sounding. We compare the performance of five ML algorithms: logistic regression with the elastic-net penalty, random forests, gradient-boosted forests, and support-vector machines with both a linear and nonlinear kernel. The gradient-boosted forest performs best, with an accuracy of 0.77 +/- 0.02 and a Peirce score of 0.58 +/- 0.04. The linear support-vector machine performs second best, with values of 0.70 +/- 0.02 and 0.55 +/- 0.05, respectively. We use two interpretation methods, permutation importance and sequential forward selection, to determine the most important predictors for the ML models. We also use partial-dependence plots to determine how these predictors influence the outcome. A main conclusion is that shape predictors, based on the outline of the storm, appear to be highly important across ML models. The training data, a storm-centered radar scan and modeled proximity sounding, are similar to real-time data. Thus, the models could be used operationally to aid human decision-making by reducing the cognitive load involved in manual storm-mode identification. Also, they could be run on historical data to perform climatological analyses, which could be valuable to both the research and operational communities.
C1 [Jergensen, G. Eli; McGovern, Amy; Lagerquist, Ryan; Smith, Travis] Univ Oklahoma, Norman, OK 73019 USA.
   [Lagerquist, Ryan; Smith, Travis] Cooperat Inst Mesoscale Meteorol Studies, Norman, OK USA.
   [Smith, Travis] Natl Severe Storms Lab, Norman, OK 73069 USA.
RP McGovern, A (corresponding author), Univ Oklahoma, Norman, OK 73019 USA.
EM amcgovern@ou.edu
RI McGovern, Amy/AAC-8132-2022
OI McGovern, Amy/0000-0001-6675-7119
FU National Science FoundationNational Science Foundation (NSF) [EAGER AGS
   1802627]; NOAA/Office of Oceanic and Atmospheric Research under
   NOAA-University of OklahomaNational Oceanic Atmospheric Admin (NOAA) -
   USA [NA16OAR4320115]
FX The authors thank Rich Thompson and Bryan Smith for sharing their data
   with us and for the many hours of work put into creating the labels for
   each storm. We further thank the MYRORSS team and Holly Obermeier for
   the radar data and additional labels, respectively. This material is
   based upon work supported by the National Science Foundation under Grant
   EAGER AGS 1802627. Funding was also provided by the NOAA/Office of
   Oceanic and Atmospheric Research under NOAA-University of Oklahoma
   Cooperative Agreement NA16OAR4320115, U.S. Department of Commerce. Most
   of the computing for this project was performed at the University of
   Oklahoma Supercomputing Center for Education and Research (OSCER).
NR 82
TC 9
Z9 10
U1 6
U2 17
PU AMER METEOROLOGICAL SOC
PI BOSTON
PA 45 BEACON ST, BOSTON, MA 02108-3693 USA
SN 0882-8156
EI 1520-0434
J9 WEATHER FORECAST
JI Weather Forecast.
PD APR
PY 2020
VL 35
IS 2
BP 537
EP 559
DI 10.1175/WAF-D-19-0170.1
PG 23
WC Meteorology & Atmospheric Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Meteorology & Atmospheric Sciences
GA LE4UB
UT WOS:000526714000001
DA 2022-04-17
ER

PT C
AU Huang, ZX
AF Huang Zixi
GP IEEE
TI Poverty Prediction Through Machine Learning
SO 2021 2ND INTERNATIONAL CONFERENCE ON E-COMMERCE AND INTERNET TECHNOLOGY
   (ECIT 2021)
LA English
DT Proceedings Paper
CT 2nd International Conference on E-Commerce and Internet Technology
   (ECIT)
CY MAR 05-07, 2021
CL ELECTR NETWORK
DE Poverty; Prediction; Multidimensional; Machine Learning; Models
AB Poverty elimination stands as an inevitable process in human development, with predicting poverty being the first and one of the essential steps. The paper considers poverty as an outcome of multidimensional factors, and offers various practical models for such prediction using machine learning, none of which accounts for the whole, while some factors may outweigh others. Thereby, an integrated approach of prediction is needed by combining the data from Poverty Probability Index and Oxford Poverty & Human Development Initiative. Through applying linear regression model, decision tree, random forest model, gradian boosting model, and neural network to analysis existing data, the paper assesses respectively the extent to which the factors matter and the efficacy of each model. Final advancing employs cross validation and grid research. Through analysis and comparison, the paper concludes that generally, gradient boosting is the model with the highest accuracy for predicting poverty and education as the most influencing factor. The finale finishes upon the possible reason behind the factors.
C1 [Huang Zixi] UWC Changshu China, Changshu, Peoples R China.
RP Huang, ZX (corresponding author), UWC Changshu China, Changshu, Peoples R China.
EM zxhuang19@uwcchina.org
NR 6
TC 0
Z9 0
U1 5
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
BN 978-1-6654-3873-5
PY 2021
BP 314
EP 324
DI 10.1109/ECIT52743.2021.00073
PG 11
WC Business; Computer Science, Interdisciplinary Applications; Management
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Business & Economics; Computer Science
GA BR8SG
UT WOS:000672805700066
DA 2022-04-17
ER

PT J
AU Alhajjar, E
   Maxwell, P
   Bastian, N
AF Alhajjar, Elie
   Maxwell, Paul
   Bastian, Nathaniel
TI Adversarial machine learning in Network Intrusion Detection Systems
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Network Intrusion Detection Systems; Adversarial machine learning;
   Evolutionary computation; Deep learning; Monte Carlo simulation
ID BUSINESS; SECURITY
AB Adversarial examples are inputs to a machine learning system intentionally crafted by an attacker to fool the model into producing an incorrect output. These examples have achieved a great deal of success in several domains such as image recognition, speech recognition and spam detection. In this paper, we study the nature of the adversarial problem in Network Intrusion Detection Systems (NIDS). We focus on the attack perspective, which includes techniques to generate adversarial examples capable of evading a variety of machine learning models. More specifically, we explore the use of evolutionary computation (particle swarm optimization and genetic algorithm) and deep learning (generative adversarial networks) as tools for adversarial example generation. To assess the performance of these algorithms in evading a NIDS, we apply them to two publicly available data sets, namely the NSL-KDD and UNSW-NB15, and we contrast them to a baseline perturbation method: Monte Carlo simulation. The results show that our adversarial example generation techniques cause high misclassification rates in eleven different machine learning models, along with a voting classifier. Our work highlights the vulnerability of machine learning based NIDS in the face of adversarial perturbation.
C1 [Alhajjar, Elie; Maxwell, Paul; Bastian, Nathaniel] US Mil Acad, Army Cyber Inst, West Point, NY 10996 USA.
RP Alhajjar, E (corresponding author), US Mil Acad, Army Cyber Inst, West Point, NY 10996 USA.
EM elie.alhajjar@westpoint.edu; paul.maxwell@westpoint.edu;
   nathaniel.bastian@westpoint.edu
OI Alhajjar, Elie/0000-0002-7500-1214; Maxwell, Paul/0000-0001-9055-9534;
   Bastian, Nathaniel/0000-0001-9957-2778
FU U.S. Army Combat Capabilities Development Command (DEVCOM) Army Research
   Laboratory (ARL) Faculty and Cadet Collaborative Research Program
   through the Mathematical Sciences Center, Department of Mathematical
   Sciences, U.S. Military Academy, West Point, NY; National Security
   Agency Laboratory for Advanced Cybersecurity Research [USMA21035]; U.S.
   Army DEVCOM C5ISR Center [USMA21056]; U.S. Army DEVCOM ARL [USMA21050]
FX This work was partially funded by the U.S. Army Combat Capabilities
   Development Command (DEVCOM) Army Research Laboratory (ARL) Faculty and
   Cadet Collaborative Research Program through the Mathematical Sciences
   Center, Department of Mathematical Sciences, U.S. Military Academy, West
   Point, NY. This work was also supported in part by the National Security
   Agency Laboratory for Advanced Cybersecurity Research under Interagency
   Agreement No. USMA21035, the U.S. Army DEVCOM C5ISR Center under
   Interagency Agreement No. USMA21056, and the U.S. Army DEVCOM ARL under
   Interagency Agreement No. USMA21050. The authors would like to thank the
   U.S. Army Engineer Research and Development Center for use of their
   compute resources in the course of this work.
NR 55
TC 2
Z9 3
U1 27
U2 30
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD DEC 30
PY 2021
VL 186
AR 115782
DI 10.1016/j.eswa.2021.115782
EA SEP 2021
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA UZ0AD
UT WOS:000701874800010
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Mubarakova, SR
   Amanzholova, ST
   Uskenbayeva, RK
AF Mubarakova, S. R.
   Amanzholova, S. T.
   Uskenbayeva, R. K.
TI USING MACHINE LEARNING METHODS IN CYBERSECURITY
SO EURASIAN JOURNAL OF MATHEMATICAL AND COMPUTER APPLICATIONS
LA English
DT Article
DE Network security; machine learning; data science; cybersecurity;
   cyberattack; intrusion detection systems (IDS)
AB Cybersecurity is an ever-changing field, with advances in technology that open up new opportunities for cyberattacks. In addition, even though serious security breaches are often reported, small organizations still have to worry about security breaches as they can often be the target of viruses and phishing. This is why it is so important to ensure the privacy of your user profile in cyberspace. The past few years have seen a rise in machine learning algorithms that address major cybersecurity issues such as intrusion detection systems (IDS), detection of new modifications of known malware, malware, and Spam detection, and malware analysis. In this article, algorithms have been analyzed using data mining collected from various libraries, and analytics with additional emerging data-driven models to provide more effective security solutions. In addition, an analysis was carried out of companies that are engaged in cyber attacks using machine learning. According to the research results, it was revealed that the concept of cybersecurity data science allows you to make the computing process more efficient and intelligent compared to traditional processes in the field of cybersecurity. As a result, according to the results of the study, it was revealed that machine learning, namely unsupervised learning, is an effective method of dealing with risks in cybersecurity and cyberattacks.
C1 [Mubarakova, S. R.; Amanzholova, S. T.; Uskenbayeva, R. K.] Int Informat Technol Univ, Manas Str 8, Alma Ata, Kazakhstan.
RP Mubarakova, SR (corresponding author), Int Informat Technol Univ, Manas Str 8, Alma Ata, Kazakhstan.
EM mubarakova.saltanat@gmail.com; s.amanzholova@edu.iitu.kz;
   r.usskenbayeva@edu.iitu.kz
NR 19
TC 0
Z9 0
U1 0
U2 0
PU L N GUMILYOV EURASIAN NATL UNIV
PI ASTANA
PA PUSHKIN ST, 11, RM 210, ASTANA, 010008, KAZAKHSTAN
SN 2306-6172
EI 2308-9822
J9 EURASIAN J MATH COMP
JI Eurasian J. Math. Comput. Appl.
PY 2022
VL 10
IS 1
BP 69
EP 78
DI 10.32523/2306-6172-2022-10-1-69-78
PG 10
WC Mathematics, Interdisciplinary Applications
WE Emerging Sources Citation Index (ESCI)
SC Mathematics
GA 0A8TD
UT WOS:000774219600005
DA 2022-04-17
ER

PT C
AU Zacarias, AGV
   Ghabri, R
   Reiman, P
AF Zacarias, Alejandro Gabriel Villanueva
   Ghabri, Rachaa
   Reiman, Peter
GP IEEE Comp Soc
TI AD4ML: Axiomatic Design to Specify Machine Learning Solutions for
   Manufacturing
SO 2020 IEEE 21ST INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND
   INTEGRATION FOR DATA SCIENCE (IRI 2020)
LA English
DT Proceedings Paper
CT 21st IEEE International Conference on Information Reuse and Integration
   for Data Science (IEEE IRI)
CY AUG 11-13, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, Soc Informat Reuse & Integrat
DE manufacturing; machine-learning; design
AB Machine learning is increasingly adopted in manufacturing use cases, e. g., for fault detection in a production line. Each new use case requires developing its own machine learning (ML) solution. A ML solution integrates different software components to read, process, and analyze all use case data, as well as to finally generate the output that domain experts need for their decision-making. The process to design a system specification for a ML solution is not straight-forward. It entails two types of complexity: (1) The technical complexity of selecting combinations of ML algorithms and software components that suit a use case; (2) the organizational complexity of integrating different requirements from a multidisciplinary team of, e. g., domain experts, data scientists, and IT specialists. In this paper, we propose several adaptations to Axiomatic Design in order to design ML solution specifications that handle these complexities. We call this Axiomatic Design for Machine Learning (AD4ML). We apply AD4ML to specify a ML solution for a fault detection use case and discuss to what extent our approach conquers the above-mentioned complexities. We also discuss how AD4ML facilitates the agile design of ML solutions.
C1 [Zacarias, Alejandro Gabriel Villanueva; Reiman, Peter] Univ Stuttgart, GSaME, Stuttgart, Germany.
   [Ghabri, Rachaa] Univ Stuttgart, IPVS, Stuttgart, Germany.
RP Zacarias, AGV (corresponding author), Univ Stuttgart, GSaME, Stuttgart, Germany.
EM avillanueva@gsame.uni-stuttgart.de; rachaa.ghabri@ipvs.uni-stuttgart.de;
   peter.reimann@gsame.uni-suttgart.de
NR 16
TC 1
Z9 1
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
BN 978-1-7281-1054-7
PY 2020
BP 148
EP 155
DI 10.1109/IRI49571.2020.00029
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Interdisciplinary Applications; Computer
   Science, Software Engineering; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BR1TM
UT WOS:000635425100021
DA 2022-04-17
ER

PT J
AU Ahmad, I
   Alqarni, MA
   Almazroi, AA
   Tariq, A
AF Ahmad, Iftikhar
   Alqarni, Mohammed A.
   Almazroi, Abdulwahab Ali
   Tariq, Abdullah
TI Experimental Evaluation of Clickbait Detection Using Machine Learning
   Models
SO INTELLIGENT AUTOMATION AND SOFT COMPUTING
LA English
DT Article
DE Clickbait; machine learning; BERT; social media
AB The exponential growth of social media has been instrumental in directing the news outlets to rely on the stated platform for the dissemination of news stories. While social media has helped in the fast propagation of breaking news, it also has allowed many bad actors to exploit this medium for political and monetary purposes. With such an intention, tempting headlines, which are not aligned with the content, are being used to lure users to visit the websites that often post dodgy and unreliable information. This phenomenon is commonly known as clickbait. A number of machine learning techniques have been developed in the literature for automatic detection of clickbait. In this work, we consider six state of the art and classical machine learning algorithms, namely Support Vector Machine (SVM), Logistic Regression (LR), Naive Bayes Classifier (NBC), Long Short Term Memory (LSTM), Parallel Convolutional Network (PNN), and Bidirectional Encoder Representations from Transformers (BERT) for automated clickbait detection. We also use four performance evaluation metrics, namely accuracy, precision, recall and F1-score to evaluate the performance of the selected set of machine learning algorithms on a real world data set. The results show that BERT is the best performing learning algorithm on three out of four evaluation metrics, and it achieves an average performance superiority of 3%- 4% over all the other algorithms. Furthermore, it is observed that PNN has the worst performance among the selected algorithms.
C1 [Ahmad, Iftikhar; Tariq, Abdullah] Univ Engn & Technol, Dept Comp Sci & Informat Technol, Peshawar, Pakistan.
   [Alqarni, Mohammed A.] Univ Jeddah, Coll Comp Sci & Engn, Dept Software Engn, Jeddah, Saudi Arabia.
   [Almazroi, Abdulwahab Ali] Univ Jeddah, Coll Comp & Informat Technol Khulais, Dept Informat Technol, Jeddah, Saudi Arabia.
RP Ahmad, I (corresponding author), Univ Engn & Technol, Dept Comp Sci & Informat Technol, Peshawar, Pakistan.
EM ia@uetpeshawar.edu.pk
RI Ahmad, Iftikhar/ABE-5182-2021
OI Alqarni, Mohammed A./0000-0002-3284-537X
NR 18
TC 2
Z9 2
U1 1
U2 2
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1079-8587
EI 2326-005X
J9 INTELL AUTOM SOFT CO
JI Intell. Autom. Soft Comput.
PY 2020
VL 26
IS 6
BP 1335
EP 1344
DI 10.32604/iasc.2020.013861
PG 10
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA QH9NT
UT WOS:000618601400010
OA hybrid
DA 2022-04-17
ER

PT C
AU Damiani, E
   Ardagna, CA
AF Damiani, Ernesto
   Ardagna, Claudio A.
BE Chatzigeorgiou, A
   Dondi, R
   Herodotou, H
   Kapoutsis, C
   Manolopoulos, Y
   Papadopoulos, GA
   Sikora, F
TI Certified Machine-Learning Models
SO SOFSEM 2020: THEORY AND PRACTICE OF COMPUTER SCIENCE
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 46th International Conference on Current Trends in Theory and Practice
   of Informatics (SOFSEM)
CY JAN 20-24, 2020
CL Limassol, CYPRUS
DE Intelligent systems; Machine Learning; Certification
AB The massive adoption of Machine Learning (ML) has deeply changed the internal structure, the design and the operation of software systems. ML has shifted the focus from code to data, especially in application areas where it is easier to collect samples that embody correct solutions to individual instances of a problem, than to design and code a deterministic algorithm solving it for all instances. There is an increasing awareness of the need to verify key non-functional properties of ML-based software applications like fairness and privacy. However, the traditional approach trying to verify these properties by code inspection is pointless, since ML models' behavior mostly depends on the data and parameters used to train them. Classic software certification techniques cannot solve the issue as well. The Artificial Intelligence (AI) community has been working on the idea of preventing undesired behavior by controlling a priori the ML models' training sets and parameters. In this paper, we take a different, online approach to ML verification, where novel behavioral monitoring techniques based on statistical testing are used to support a dynamic certification framework enforcing the desired properties on black-box ML models in operation. Our aim is to deliver a novel framework suitable for practical certification of distributed ML-powered applications in heavily regulated domains like transport, energy, healthcare, even when the certifying authority is not privy to the model training. To achieve this goal, we rely on three key ideas: (i) use test suites to define desired non-functional properties of ML models, (ii) Use statistical monitoring of ML models' behavior at inference time to check that the desired behavioral properties are achieved, and (iii) compose monitors' outcome within dynamic, virtual certificates for composite software applications.
C1 [Damiani, Ernesto] Khalifa Univ, Ctr Cyber Phys Syst, Abu Dhabi, U Arab Emirates.
   [Damiani, Ernesto; Ardagna, Claudio A.] Univ Milan, Comp Sci Dept, Milan, Italy.
RP Damiani, E (corresponding author), Khalifa Univ, Ctr Cyber Phys Syst, Abu Dhabi, U Arab Emirates.; Damiani, E (corresponding author), Univ Milan, Comp Sci Dept, Milan, Italy.
EM ernesto.damiani@unimi.it; claudio.ardagna@unimi.it
RI damiani, ernesto/AAI-5709-2020
OI damiani, ernesto/0000-0002-9557-6496
FU ECEuropean CommissionEuropean Commission Joint Research Centre [830927];
   Universita degli Studi di Milano
FX Research supported, in parts, by EC H2020 Project CONCORDIA GA 830927
   and Universita degli Studi di Milano under the program "Piano sostegno
   alla ricerca 2018".
NR 42
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-38919-2; 978-3-030-38918-5
J9 LECT NOTES COMPUT SC
PY 2020
VL 12011
BP 3
EP 15
DI 10.1007/978-3-030-38919-2_1
PG 13
WC Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR5IY
UT WOS:000655605200001
OA Green Published
DA 2022-04-17
ER

PT J
AU Lane, TR
   Foil, DH
   Minerali, E
   Urbina, F
   Zorn, KM
   Ekins, S
AF Lane, Thomas R.
   Foil, Daniel H.
   Minerali, Eni
   Urbina, Fabio
   Zorn, Kimberley M.
   Ekins, Sean
TI Bioactivity Comparison across Multiple Machine Learning Algorithms Using
   over 5000 Datasets for Drug Discovery
SO MOLECULAR PHARMACEUTICS
LA English
DT Article
DE deep learning; drug discovery; machine learning; pharmaceutics; support
   vector machines
ID SUPPORT VECTOR MACHINE; ADMET EVALUATION; PREDICTION MODELS;
   NEURAL-NETWORKS; BIGGER DATA; IDENTIFICATION; BENCHMARKING; VALIDATION;
   AGREEMENT
AB Machine learning methods are attracting considerable attention from the pharmaceutical industry for use in drug discovery and applications beyond. In recent studies, we and others have applied multiple machine learning algorithms and modeling metrics and, in some cases, compared molecular descriptors to build models for individual targets or properties on a relatively small scale. Several research groups have used large numbers of datasets from public databases such as ChEMBL in order to evaluate machine learning methods of interest to them. The largest of these types of studies used on the order of 1400 datasets. We have now extracted well over 5000 datasets from CHEMBL for use with the ECFP6 fingerprint and in comparison of our proprietary software Assay Central with random forest, k-nearest neighbors, support vector classification, naive Bayesian, AdaBoosted decision trees, and deep neural networks (three layers). Model performance was assessed using an array of fivefold cross-validation metrics including area-under-the-curve, F1 score, Cohen's kappa, and Matthews correlation coefficient. Based on ranked normalized scores for the metrics or datasets, all methods appeared comparable, while the distance from the top indicated that Assay Central and support vector classification were comparable. Unlike prior studies which have placed considerable emphasis on deep neural networks (deep learning), no advantage was seen in this case. If anything, Assay Central may have been at a slight advantage as the activity cutoff for each of the over 5000 datasets representing over 570,000 unique compounds was based on Assay Central performance, although support vector classification seems to be a strong competitor. We also applied Assay Central to perform prospective predictions for the toxicity targets PXR and hERG to further validate these models. This work appears to be the largest scale comparison of these machine learning algorithms to date. Future studies will likely evaluate additional databases, descriptors, and machine learning algorithms and further refine the methods for evaluating and comparing such models.
C1 [Lane, Thomas R.; Foil, Daniel H.; Minerali, Eni; Zorn, Kimberley M.; Ekins, Sean] Collaborat Pharmaceut Inc, Raleigh, NC 27606 USA.
   [Urbina, Fabio] Univ North Carolina Chapel Hill, Dept Cell Biol & Physiol, Chapel Hill, NC 27599 USA.
RP Ekins, S (corresponding author), Collaborat Pharmaceut Inc, Raleigh, NC 27606 USA.
EM sean@collaborationspharma.com
RI Foil, Daniel/AAJ-1809-2021
OI Foil, Daniel/0000-0003-0512-8997; Minerali, Eni/0000-0002-7018-7021
FU NIH from NIGMS [R44GM122196-02A1]; NIH from NCCAM [3R43AT010585-01S1];
   NIH from NIEHS [1R43ES031038-01]; National Institute of Environmental
   Health Sciences of the National Institutes of HealthUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute of Environmental Health Sciences (NIEHS)
   [R43ES031038]
FX We kindly acknowledge NIH funding: R44GM122196-02A1 from NIGMS,
   3R43AT010585-01S1 from NCCAM and 1R43ES031038-01 from NIEHS (PI.Sean
   Ekins). "Research reported in this publication was supported by the
   National Institute of Environmental Health Sciences of the National
   Institutes of Health under award number R43ES031038. The content is
   solely the responsibility of the authors and does not necessarily
   represent the official views of the National Institutes of Health."
NR 77
TC 5
Z9 5
U1 8
U2 18
PU AMER CHEMICAL SOC
PI WASHINGTON
PA 1155 16TH ST, NW, WASHINGTON, DC 20036 USA
SN 1543-8384
EI 1543-8392
J9 MOL PHARMACEUT
JI Mol. Pharm.
PD JAN 4
PY 2021
VL 18
IS 1
BP 403
EP 415
DI 10.1021/acs.molpharmaceut.0c01013
PG 13
WC Medicine, Research & Experimental; Pharmacology & Pharmacy
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Research & Experimental Medicine; Pharmacology & Pharmacy
GA PQ8OX
UT WOS:000606803900032
PM 33325717
OA Green Accepted
DA 2022-04-17
ER

PT J
AU Spasic, I
   Nenadic, G
AF Spasic, Irena
   Nenadic, Goran
TI Clinical Text Data in Machine Learning: Systematic Review
SO JMIR MEDICAL INFORMATICS
LA English
DT Review
DE natural language processing; machine learning; medical informatics;
   medical informatics applications
ID ELECTRONIC MEDICAL-RECORDS; NAMED-ENTITY RECOGNITION; INFORMATION
   EXTRACTION; RADIOLOGY REPORTS; NEURAL-NETWORKS; CLASSIFICATION;
   IDENTIFICATION; PREDICTION; QUALITY; ANNOTATION
AB Background: Clinical narratives represent the main form of communication within health care, providing a personalized account of patient history and assessments, and offering rich information for clinical decision making. Natural language processing (NLP) has repeatedly demonstrated its feasibility to unlock evidence buried in clinical narratives. Machine learning can facilitate rapid development of NLP tools by leveraging large amounts of text data.
   Objective: The main aim of this study was to provide systematic evidence on the properties of text data used to train machine learning approaches to clinical NLP. We also investigated the types of NLP tasks that have been supported by machine learning and how they can be applied in clinical practice.
   Methods: Our methodology was based on the guidelines for performing systematic reviews. In August 2018, we used PubMed, a multifaceted interface, to perform a literature search against MEDLINE. We identified 110 relevant studies and extracted information about text data used to support machine learning, NLP tasks supported, and their clinical applications. The data properties considered included their size, provenance, collection methods, annotation, and any relevant statistics.
   Results: The majority of datasets used to train machine learning models included only hundreds or thousands of documents. Only 10 studies used tens of thousands of documents, with a handful of studies utilizing more. Relatively small datasets were utilized for training even when much larger datasets were available. The main reason for such poor data utilization is the annotation bottleneck faced by supervised machine learning algorithms. Active learning was explored to iteratively sample a subset of data for manual annotation as a strategy for minimizing the annotation effort while maximizing the predictive performance of the model. Supervised learning was successfully used where clinical codes integrated with free-text notes into electronic health records were utilized as class labels. Similarly, distant supervision was used to utilize an existing knowledge base to automatically annotate raw text. Where manual annotation was unavoidable, crowdsourcing was explored, but it remains unsuitable because of the sensitive nature of data considered. Besides the small volume, training data were typically sourced from a small number of institutions, thus offering no hard evidence about the transferability of machine learning models. The majority of studies focused on text classification. Most commonly, the classification results were used to support phenotyping, prognosis, care improvement, resource management, and surveillance.
   Conclusions: We identified the data annotation bottleneck as one of the key obstacles to machine learning approaches in clinical NLP. Active learning and distant supervision were explored as a way of saving the annotation efforts. Future research in this field would benefit from alternatives such as data augmentation and transfer learning, or unsupervised learning, which do not require data annotation.
C1 [Spasic, Irena] Cardiff Univ, Sch Comp Sci & Informat, 5 Parade, Cardiff CF24 3AA, Wales.
   [Nenadic, Goran] Univ Manchester, Dept Comp Sci, Manchester, Lancs, England.
RP Spasic, I (corresponding author), Cardiff Univ, Sch Comp Sci & Informat, 5 Parade, Cardiff CF24 3AA, Wales.
EM spasici@cardiff.ac.uk
OI Nenadic, Goran/0000-0003-0795-5363; Spasic, Irena/0000-0002-8132-3885
FU Engineering and Physical Sciences Research Council for HealTex-UK
   Healthcare Text Analytics Research NetworkUK Research & Innovation
   (UKRI)Engineering & Physical Sciences Research Council (EPSRC)
   [EP/N027280/1]; EPSRCUK Research & Innovation (UKRI)Engineering &
   Physical Sciences Research Council (EPSRC) [EP/N027280/1] Funding
   Source: UKRI; MRCUK Research & Innovation (UKRI)Medical Research Council
   UK (MRC) [MR/K006665/1] Funding Source: UKRI
FX The authors gratefully acknowledge the support from the Engineering and
   Physical Sciences Research Council for HealTex-UK Healthcare Text
   Analytics Research Network (Grant number EP/N027280/1).
NR 146
TC 32
Z9 33
U1 15
U2 32
PU JMIR PUBLICATIONS, INC
PI TORONTO
PA 130 QUEENS QUAY E, STE 1102, TORONTO, ON M5A 0P6, CANADA
EI 2291-9694
J9 JMIR MED INF
JI JMIR Med. Inf.
PD MAR
PY 2020
VL 8
IS 3
AR e17984
DI 10.2196/17984
PG 19
WC Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Medical Informatics
GA KZ5CX
UT WOS:000523281400011
PM 32229465
OA Green Published, Green Accepted, gold
DA 2022-04-17
ER

PT C
AU Nafreen, M
   Bhattacharya, S
   Fiondella, L
AF Nafreen, Maskura
   Bhattacharya, Saikath
   Fiondella, Lance
GP IEEE
TI Architecture-based Software Reliability Incorporating Fault Tolerant
   Machine Learning
SO 2020 ANNUAL RELIABILITY AND MAINTAINABILITY SYMPOSIUM (RAMS 2020)
SE Reliability and Maintainability Symposium
LA English
DT Proceedings Paper
CT Annual Reliability and Maintainability Symposium (RAMS)
CY JAN 27-30, 2020
CL Palm Springs, CA
DE Architecture-based software; software reliability; machine learning;
   fault-tolerance; correlation
AB With the increased interest to incorporate machine learning into software and systems, methods to characterize the impact of the reliability of machine learning are needed to ensure the reliability of the software and systems in which these algorithms reside. Towards this end, we build upon the architecture-based approach to software reliability modeling, which represents application reliability in terms of the component reliabilities and the probabilistic transitions between the components. Traditional architecture-based software reliability models consider all components to be deterministic software. We therefore extend this modeling approach to the case, where some components represent learning enabled components. Here, the reliability of a machine learning component is interpreted as the accuracy of its decisions, which is a common measure of classification algorithms. Moreover, we allow these machine learning components to be fault-tolerant in the sense that multiple diverse classifier algorithms are trained to guide decisions and the majority decision taken. We demonstrate the utility of the approach to assess the impact of machine learning on software reliability as well as illustrate the concept of reliability growth in machine learning. Finally, we validate past analytical results for a fault tolerant system composed of correlated components with real machine learning algorithms and data, demonstrating the analytical expression's ability to accurately estimate the reliability of the fault tolerant machine learning component and subsequently the architecture-based software within which it resides.
C1 [Nafreen, Maskura; Bhattacharya, Saikath; Fiondella, Lance] Univ Massachusetts Dartmouth, Dept Elect & Comp Engn, 285 Old Westport Rd, N Dartmouth, MA 02747 USA.
RP Nafreen, M (corresponding author), Univ Massachusetts Dartmouth, Dept Elect & Comp Engn, 285 Old Westport Rd, N Dartmouth, MA 02747 USA.
EM mnafreen@umassd.edu; sbhattacharya@umassd.edu; lfiondella@umassd.edu
FU National Science FoundationNational Science Foundation (NSF) [1749635]
FX This material is based upon work supported by the National Science
   Foundation under Grant Number (#1749635). Any opinions, findings, and
   conclusions or recommendations expressed in this material are those of
   the authors and do not necessarily reflect the views of the National
   Science Foundation.
NR 20
TC 1
Z9 1
U1 1
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 0149-144X
BN 978-1-7281-3689-9
J9 P REL MAINT S
PY 2020
PG 6
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BQ7NZ
UT WOS:000618045900136
DA 2022-04-17
ER

PT J
AU Roter, B
   Dordevic, SV
AF Roter, B.
   Dordevic, S., V
TI Predicting new superconductors and their critical temperatures using
   machine learning
SO PHYSICA C-SUPERCONDUCTIVITY AND ITS APPLICATIONS
LA English
DT Article
DE Machine learning; High temperature superconductors
AB We used the superconductors in the SuperCon database to construct element vectors and then perform machine learning of their critical temperatures (T-c). Only the chemical composition of superconductors was used in this procedure. No physical predictors (neither experimental nor computational) of any kind were used. We achieved the coefficient of determination R-2 similar or equal to 0.93, which is comparable and in some cases higher than similar estimates using other artificial intelligence techniques. Based on this machine learning model, we predicted several new superconductors with high critical temperatures. We also discuss several factors that limit the learning process and suggest possible ways to overcome them.
C1 [Roter, B.; Dordevic, S., V] Univ Akron, Dept Phys, Akron, OH 44325 USA.
RP Dordevic, SV (corresponding author), Univ Akron, Dept Phys, Akron, OH 44325 USA.
EM dsasa@uakron.edu
NR 25
TC 8
Z9 8
U1 3
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0921-4534
EI 1873-2143
J9 PHYSICA C
JI Physica C
PD AUG 15
PY 2020
VL 575
AR 1353689
DI 10.1016/j.physc.2020.1353689
PG 4
WC Physics, Applied; Physics, Condensed Matter
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Physics
GA MJ0XY
UT WOS:000547820300005
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Malavika, G
   Rajathi, N
   Vanitha, V
   Parameswari, P
AF Malavika, G.
   Rajathi, N.
   Vanitha, V.
   Parameswari, P.
TI Alzheimer Disease Forecasting using Machine Learning Algorithm
SO BIOSCIENCE BIOTECHNOLOGY RESEARCH COMMUNICATIONS
LA English
DT Article
DE ACCURACY; ALZHEIMER'S DETECTION; MACHINE LEARNING; PRIMITIVE DETECTION
AB Alzheimer disease is a neurodegenerative disease that makes a gradual disorder of human brain cells and it leads to degenerate the cells away and die. In India more than one million cases per year are affected by this disease. The most common in people over the age group of above 65. There is no treatment for this disease to cure, but now a day's medications are available to temporarily decline the process of disease. The primitive detection of this disease may help the doctors, physician, and other family members to treat them in a better way. The objective of the proposed system is to offer a fast, early and cost-efficient method to detect disease in premature period. Machine learning is the blooming field in the healthcare industry, so by using the machine learning techniques the disease will get forecast in the earlier stage. The techniques are K-Nearest Neighbor, Adaboost Classifier, Support Vector Machine, Logistic Regression, Decision Tree Classifier and Random Forest classifier. Among these algorithms, the best prediction accuracy is produced by the Random Forest algorithm.
C1 [Malavika, G.; Rajathi, N.; Vanitha, V.] Kumaraguru Coll Technol, Dept Informat Technol, Coimbatore, Tamil Nadu, India.
   [Parameswari, P.] Kumaraguru Coll Technol, Dept MCA, Coimbatore, Tamil Nadu, India.
RP Rajathi, N (corresponding author), Kumaraguru Coll Technol, Dept Informat Technol, Coimbatore, Tamil Nadu, India.
EM rajathi.in.it@kct.ac.in
NR 16
TC 0
Z9 0
U1 2
U2 3
PU SOC SCIENCE & NATURE
PI BHOPAL
PA C-52 HOUSING BOARD COLONY, KOHE FIZA, BHOPAL, MADHYA PRADESH 462 001,
   INDIA
SN 0974-6455
J9 BIOSCI BIOTECH RES C
JI Biosci. Biotechnol. Res. Commun.
PY 2020
VL 13
IS 11
SI SI
BP 15
EP 19
DI 10.21786/bbrc/13.11/4
PG 5
WC Biotechnology & Applied Microbiology
WE Emerging Sources Citation Index (ESCI)
SC Biotechnology & Applied Microbiology
GA RN0XA
UT WOS:000640077900004
OA Bronze
DA 2022-04-17
ER

PT J
AU Zhang, P
   Wu, HN
   Chen, RP
   Dai, T
   Meng, FY
   Wang, HB
AF Zhang, Pin
   Wu, Huai-Na
   Chen, Ren-Peng
   Dai, Tian
   Meng, Fan-Yan
   Wang, Hong-Bo
TI A critical evaluation of machine learning and deep learning in
   shield-ground interaction prediction
SO TUNNELLING AND UNDERGROUND SPACE TECHNOLOGY
LA English
DT Article
DE Machine learning; Deep learning; Tunnel; Settlement
ID ARTIFICIAL NEURAL-NETWORKS; SURFACE SETTLEMENTS; TUNNEL; DEFORMATION;
   MODEL; ANN; CONVERGENCE; PARAMETERS; MOVEMENTS; BEHAVIOR
AB The interaction between a shield machine and the ground is a complicated problem involving numerous extrinsic and intrinsic factors. Machine learning (ML) algorithms have been recently employed to predict tunnel-soil interactions. This study introduces a more powerful algorithm termed the deep learning (DL) long short-term memory (LSTM) neural network, to identify the interaction between a shield machine and the ground; this network can predict tunnelling-induced maximum settlement, the longitudinal settlement curve, and shield operational parameters. In addition, the generalisation ability of LSTM is comprehensively compared with that of a conventional ML algorithm-random forest (RF)-based on field records collected from two practical tunnel projects. A standard process of developing an ML or DL algorithm-based model, including the pre-processing of raw data, feature selection, determination of optimum hyper-parameters, and evaluation of prediction performance and generalization ability, was introduced. The results indicated that the RF-based model performs capably in terms of predicting tunnelling-induced maximum settlement, and that the LSTM-based model is suitable for predicting longitudinal settlement curves and shield operational parameters. Furthermore, the generalization ability of the LSTM-based model is better than that of the RF-based model. The strong robustness of the LSTM-based model enables its application in different types of tunnel projects.
C1 [Zhang, Pin; Wu, Huai-Na; Chen, Ren-Peng; Dai, Tian; Meng, Fan-Yan; Wang, Hong-Bo] Hunan Univ, Coll Civil Engn, Changsha 410082, Hunan, Peoples R China.
   [Wu, Huai-Na; Chen, Ren-Peng; Meng, Fan-Yan] Hunan Univ, Key Lab Bldg Safety & Energy Efficiency, Minist Educ, Changsha 410082, Hunan, Peoples R China.
   [Wu, Huai-Na; Chen, Ren-Peng; Meng, Fan-Yan] Hunan Univ, Natl Joint Res Ctr Bldg Safety & Environm, Changsha 410082, Hunan, Peoples R China.
RP Wu, HN (corresponding author), Hunan Univ, Coll Civil Engn, Changsha 410082, Hunan, Peoples R China.
EM wuhn@hnu.edu.cn
RI Zhang, Pin/AAH-7482-2019
OI Zhang, Pin/0000-0002-9004-647X; Fanyan, Meng/0000-0003-2681-9797
FU National Key Research and Development Program of China [2019YFB1705201];
   Innovative Hunan Province Special Funds/Programms [2019GK1011]
FX The research work described herein was funded by the National Key
   Research and Development Program of China (Grant No. 2019YFB1705201) and
   Innovative Hunan Province Special Funds/Programms (Grant No.
   2019GK1011). These financial supports are gratefully acknowledged.
NR 69
TC 13
Z9 13
U1 23
U2 72
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0886-7798
J9 TUNN UNDERGR SP TECH
JI Tunn. Undergr. Space Technol.
PD DEC
PY 2020
VL 106
AR 103593
DI 10.1016/j.tust.2020.103593
PG 14
WC Construction & Building Technology; Engineering, Civil
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Construction & Building Technology; Engineering
GA OU6UK
UT WOS:000591661300002
DA 2022-04-17
ER

PT J
AU Allegra, A
   Tonacci, A
   Sciaccotta, R
   Genovese, S
   Musolino, C
   Pioggia, G
   Gangemi, S
AF Allegra, Alessandro
   Tonacci, Alessandro
   Sciaccotta, Raffaele
   Genovese, Sara
   Musolino, Caterina
   Pioggia, Giovanni
   Gangemi, Sebastiano
TI Machine Learning and Deep Learning Applications in Multiple Myeloma
   Diagnosis, Prognosis, and Treatment Selection
SO CANCERS
LA English
DT Review
DE artificial intelligence; machine learning; deep learning; multiple
   myeloma; prognosis; diagnosis; chemotherapy; bone disease
ID INDUCED BREAKDOWN SPECTROSCOPY; INTERNATIONAL STAGING SYSTEM; MINIMAL
   RESIDUAL DISEASE; PLASMA-CELL DISORDERS; ARTIFICIAL-INTELLIGENCE;
   GENE-EXPRESSION; FAMILY PROTEINS; FLOW-CYTOMETRY; PIVOTAL ROLE;
   BORTEZOMIB
AB Simple Summary Multiple myeloma is a malignant neoplasm of plasma cells with complex pathogenesis. With major progresses in multiple myeloma research, it is essential that we reconsider our methods for diagnosing and monitoring multiple myeloma disease. This fact needs the integration of serology, histology, radiology, and genetic data; therefore, multiple myeloma study has generated massive quantities of granular high-dimensional data exceeding human understanding. With improved computational techniques, artificial intelligence tools for data processing and analysis are becoming more and more relevant. Artificial intelligence represents a wide set of algorithms for which machine learning and deep learning are presently among the most impactful. This review focuses on artificial intelligence applications in multiple myeloma research, first illustrating machine learning and deep learning procedures and workflow, followed by how these algorithms are used for multiple myeloma diagnosis, prognosis, bone lesions identification, and evaluation of response to the treatment. Artificial intelligence has recently modified the panorama of oncology investigation thanks to the use of machine learning algorithms and deep learning strategies. Machine learning is a branch of artificial intelligence that involves algorithms that analyse information, learn from that information, and then employ their discoveries to make abreast choice, while deep learning is a field of machine learning basically represented by algorithms inspired by the organization and function of the brain, named artificial neural networks. In this review, we examine the possibility of the artificial intelligence applications in multiple myeloma evaluation, and we report the most significant experimentations with respect to the machine and deep learning procedures in the relevant field. Multiple myeloma is one of the most common haematological malignancies in the world, and among them, it is one of the most difficult ones to cure due to the high occurrence of relapse and chemoresistance. Machine learning- and deep learning-based studies are expected to be among the future strategies to challenge this negative-prognosis tumour via the detection of new markers for their prompt discovery and therapy selection and by a better evaluation of its relapse and survival.
C1 [Allegra, Alessandro; Sciaccotta, Raffaele; Musolino, Caterina] Univ Messina, Dept Human Pathol Adulthood & Childhood Gaetano B, Div Hematol, I-98125 Messina, Italy.
   [Tonacci, Alessandro] Natl Res Council Italy IFC CNR, Clin Physiol Inst, I-56124 Pisa, Italy.
   [Genovese, Sara; Pioggia, Giovanni] Natl Res Council Italy CNR, Inst Biomed Res & Innovat IRIB, I-98164 Messina, Italy.
   [Gangemi, Sebastiano] Univ Messina, Unit & Sch Allergy & Clin Immunol, Dept Clin & Expt Med, I-98125 Messina, Italy.
RP Allegra, A (corresponding author), Univ Messina, Dept Human Pathol Adulthood & Childhood Gaetano B, Div Hematol, I-98125 Messina, Italy.
EM aallegra@unime.it; atonacci@ifc.cnr.it; sciaccottaraffaele@gmail.com;
   sara.genovese@cnr.it; cmusolino@unime.it; giovanni.pioggia@cnr.it;
   gangemis@unime.it
RI Pioggia, Giovanni/C-8119-2016; Tonacci, Alessandro/J-7996-2016
OI Pioggia, Giovanni/0000-0002-8089-7449; Tonacci,
   Alessandro/0000-0001-8335-5541; GENOVESE, SARA/0000-0002-2639-4680;
   Allegra, Alessandro/0000-0001-6156-8239
NR 98
TC 0
Z9 0
U1 3
U2 3
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-6694
J9 CANCERS
JI Cancers
PD FEB
PY 2022
VL 14
IS 3
AR 606
DI 10.3390/cancers14030606
PG 16
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA ZA4DU
UT WOS:000756117000001
PM 35158874
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Uddin, MN
   Bin Hafiz, MF
   Hossain, S
   Islam, SMM
AF Uddin, Mohammed Nazim
   Bin Hafiz, Md Ferdous
   Hossain, Sohrab
   Islam, Shah Mohammad Mominul
TI Drug Sentiment Analysis using Machine Learning Classifiers
SO INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS
LA English
DT Article
DE Machine Learning Algorithms; natural language processing; drugs
   sentiment analysis; text mining
ID NEURAL-NETWORKS
AB In recent times, one of the most emerging sub -dimensions of natural language processing is sentiment analysis which refers to analyzing opinion on a particular subject from plain text. Drug sentiment analysis has become very significant in present times as classifying medicines based on their effectiveness through analyzing reviews from users can assist potential future consumers in gaining knowledge and making better decisions about a particular drug. The objective of this proposed research is to measure the effectiveness level of a particular drug. Currently most of the text mining researches are based on unsupervised machine learning methods to cluster data. When supervised learning methods are used for text mining, the usual primary concern is to classify the data into two classes. Lack of technical terms in similar datasets make the categorization even more challenging. The proposed research focuses on finding out the keywords through tokenization and lemmatization so that better accuracy can be achieved for categorizing the drugs based on their effectiveness using different algorithms. Such categorization can be instrumental for treating illness as well as improve one's health and well-being. Four machine learning algorithms have been applied for binary classification and one for multiclass classification on the drug review dataset acquired from the UCI machine learning repository. The machine learning algorithms used for binary classification are naive Bayes classifier, random forest, support vector classifier (SVC), and multilayer perceptron; among these machine learning algorithms, linear SVC was used for multiclass classification. Results obtained from these four classifier algorithms have been analyzed to evaluate their performances. The random forest has been proven to have the best performance among these four algorithms. However, multiclass classification was found to have low performance when applied to natural language processing. On the contrary, the applied linear SVC algorithm performed better for class 2 with AUC 0.82 in this research.
C1 [Uddin, Mohammed Nazim; Bin Hafiz, Md Ferdous; Hossain, Sohrab] East Delta Univ, Dept Comp Sci & Engn, Sch Sci Engn & Technol, Chattogram, Bangladesh.
   [Islam, Shah Mohammad Mominul] East Delta Univ, Dept Elect & Elect Engn, Sch Sci Engn & Technol, Chattogram, Bangladesh.
RP Uddin, MN (corresponding author), East Delta Univ, Dept Comp Sci & Engn, Sch Sci Engn & Technol, Chattogram, Bangladesh.
RI Hossain, Sohrab/AAL-1545-2021
OI Hossain, Sohrab/0000-0003-3090-2972
NR 28
TC 0
Z9 0
U1 2
U2 2
PU SCIENCE & INFORMATION SAI ORGANIZATION LTD
PI WEST YORKSHIRE
PA 19 BOLLING RD, BRADFORD, WEST YORKSHIRE, 00000, ENGLAND
SN 2158-107X
EI 2156-5570
J9 INT J ADV COMPUT SC
JI Int. J. Adv. Comput. Sci. Appl.
PD JAN
PY 2022
VL 13
IS 1
BP 92
EP 100
PG 9
WC Computer Science, Theory & Methods
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YY3OW
UT WOS:000754701200001
DA 2022-04-17
ER

PT J
AU Wang, X
   Ryoo, JH
   Bendle, N
   Kopalle, PK
AF Wang, Xin (Shane)
   Ryoo, Jun Hyun (Joseph)
   Bendle, Neil
   Kopalle, Praveen K.
TI The role of machine learning analytics and metrics in retailing research
SO JOURNAL OF RETAILING
LA English
DT Article
DE Machine learning; Prediction; Metrics; Analytics; Retailing; Trends
ID USER-GENERATED CONTENT; BIG DATA; ARTIFICIAL-INTELLIGENCE;
   CONSUMER-RESEARCH; CLASSIFICATION; DYNAMICS; CHATTER; HETEROGENEITY;
   PREDICTION; CUSTOMERS
AB This research presents the use of machine learning analytics and metrics in the retailing context. We first discuss what is machine learning and explain the field's origins. We then demonstrate the strengths of machine learning methods using an online retailing dataset, noting key areas of divergence from the traditional explanatory approach to data analysis. We then provide a review of the current state of machine learning in top-level retailing and marketing research, integrating ideas for future research and showcasing potential applications for practitioners. We propose that the explanatory and machine learning approaches need not be mutually exclusive. Particularly, we discuss four key areas in the general scientific research process that can benefit from machine learning: data exploration/theory building, variable creation, estimation, and predicting an outcome metric. Due to the customer-facing nature of retailing, we anticipate several challenges researchers and practitioners might face in the adoption and implementation of machine learning, such as ethical prediction and customer privacy issues. Overall, our belief is that machine learning can enhance customer experience and, accordingly, we advance opportunities for future research. (c) 2020 New York University. Published by Elsevier Inc. All rights reserved.
C1 [Wang, Xin (Shane)] Western Univ, Ivey Business Sch, 1255 Western Rd, London, ON N6G 0N1, Canada.
   [Ryoo, Jun Hyun (Joseph)] City Univ Hong Kong, Coll Business, Kowloon Tong, 83 Tat Chee Ave, Hong Kong, Peoples R China.
   [Bendle, Neil] Univ Georgia, Terry Coll Business, 630 S Lumpkin St, Athens, GA USA.
   [Kopalle, Praveen K.] Dartmouth Coll, Tuck Sch Business Dartmouth, Hanover, NH 03755 USA.
RP Wang, X (corresponding author), Western Univ, Ivey Business Sch, 1255 Western Rd, London, ON N6G 0N1, Canada.
EM xwang@ivey.uwo.ca; jryoo.phd@ivey.ca; neil.bendle@uga.edu;
   kopalle@dartmouth.edu
OI Bendle, Neil/0000-0002-8557-5983; Ryoo, Jun Hyun
   (Joseph)/0000-0002-9434-1724
NR 96
TC 1
Z9 1
U1 10
U2 10
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0022-4359
EI 1873-3271
J9 J RETAILING
JI J. Retail.
PD DEC
PY 2021
VL 97
IS 4
BP 658
EP 675
DI 10.1016/j.jretai.2020.12.001
EA DEC 2021
PG 18
WC Business
WE Social Science Citation Index (SSCI)
SC Business & Economics
GA XS5KA
UT WOS:000732946500010
DA 2022-04-17
ER

PT C
AU George, J
   Santhosh, R
AF George, Jean
   Santhosh, R.
GP IEEE
TI IMPLEMENTATION OF MACHINE LEARNING CLASSIFIER FOR DTN ROUTING
SO PROCEEDINGS OF THE 2021 FIFTH INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN
   SOCIAL, MOBILE, ANALYTICS AND CLOUD) (I-SMAC 2021)
LA English
DT Proceedings Paper
CT 5th International Conference on IoT in Social, Mobile, Analytics and
   Cloud (I-SMAC)
CY NOV 11-13, 2021
CL ELECTR NETWORK
SP IEEE, SCAD Inst Technol
DE DTN; CORE; Machine Learning; Bundle protocol
AB This paper presents, better routing method in Delay Tolerant Network using Machine learning. Delay Tolerant Network is a wireless network, in which nodes are changing its positions dynamically in an unexpected way due to that Round trip time and error rates are very high. Examples are Disaster area, under the sea, Space communication, etc. In the proposed method neighbouring nodes are predicted by machine learning classifiers. These nodes use message history delivery information to deliver the message on destination. With the help of Bundle protocol implementation IBR-DTN [3], collects network traffic status and real-world location trace. These information uses to emulate DTN environment by Common Open Research Emulator (CORE) [2]. The new application is used to predict the results, preparation for the network history data, analysis and classification-based routing.
C1 [George, Jean; Santhosh, R.] Karpagam Acad Higher Educ, Dept Comp Sci & Engn, Fac Engn, Coimbatore, Tamil Nadu, India.
RP George, J (corresponding author), Karpagam Acad Higher Educ, Dept Comp Sci & Engn, Fac Engn, Coimbatore, Tamil Nadu, India.
EM jeenvj@gmail.com; santhoshrd@gmail.com
NR 36
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-6654-2642-8
PY 2021
BP 508
EP 516
DI 10.1109/I-SMAC52330.2021.9640863
PG 9
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS7GZ
UT WOS:000760875500086
DA 2022-04-17
ER

PT C
AU Diako, DJ
   Achiepo, OYM
   Mensah, EP
AF Diako, Doffou Jerome
   Achiepo, Odilon Yapo M.
   Mensah, Edoete Patrice
BE Zitouni, R
   Agueh, M
   Houngue, P
   Soude, H
TI Analysis of Software Vulnerabilities Using Machine Learning Techniques
SO E-INFRASTRUCTURE AND E-SERVICES FOR DEVELOPING COUNTRIES (AFRICOMM 2019)
SE Lecture Notes of the Institute for Computer Sciences Social Informatics
   and Telecommunications Engineering
LA English
DT Proceedings Paper
CT 11th European-Alliance-for-Innovation (EAI) International Conference on
   e-Infrastructure and e-Services for Developing Countries (AFRICOMM)
CY DEC 03-04, 2019
CL Porto Novo, BENIN
SP European Alliance Innovat
DE Machine learning; Vulnerabilities; Naive Bayes; Support vectors
   machines; CVSS
AB With the increasing development of software technologies, we see that software vulnerabilities are a very critical issue of IT security. Because of their serious impacts, many different approaches have been proposed in recent decades to mitigate the damage caused by software vulnerabilities. Machine learning is also part of an approach to solve this problem. The main objective of this document is to provide three supervised machine to predict software vulnerabilities from a dataset of 6670 observations from national vulnerabilities database (NVD). The effectiveness of the proposed models has been evaluated with several performance indicators including Accuracy.
C1 [Diako, Doffou Jerome] INPHB Yamoussoukro, EDP, Yamoussoukro, Cote Ivoire.
   [Achiepo, Odilon Yapo M.] Peleforo Gon Coulibaly Univ, Korhogo, Cote Ivoire.
   [Mensah, Edoete Patrice] INPHB Yamoussoukro, Yamoussoukro, Cote Ivoire.
RP Diako, DJ (corresponding author), INPHB Yamoussoukro, EDP, Yamoussoukro, Cote Ivoire.
EM kingdjako@gmail.com
NR 11
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1867-8211
EI 1867-822X
BN 978-3-030-41593-8; 978-3-030-41592-1
J9 L N INST COMP SCI SO
PY 2020
VL 311
BP 30
EP 37
DI 10.1007/978-3-030-41593-8_3
PG 8
WC Development Studies; Computer Science, Information Systems; Computer
   Science, Interdisciplinary Applications; Computer Science, Theory &
   Methods; Regional & Urban Planning; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Development Studies; Computer Science; Public Administration;
   Telecommunications
GA BS4SB
UT WOS:000722300500003
DA 2022-04-17
ER

PT J
AU Kaluarachchi, T
   Reis, A
   Nanayakkara, S
AF Kaluarachchi, Tharindu
   Reis, Andrew
   Nanayakkara, Suranga
TI A Review of Recent Deep Learning Approaches in Human-Centered Machine
   Learning
SO SENSORS
LA English
DT Review
DE human-centered machine learning; HCML; HCAI; human-centered artificial
   intelligence; Deep Learning
ID BLACK-BOX; CHALLENGES; MODELS
AB After Deep Learning (DL) regained popularity recently, the Artificial Intelligence (AI) or Machine Learning (ML) field is undergoing rapid growth concerning research and real-world application development. Deep Learning has generated complexities in algorithms, and researchers and users have raised concerns regarding the usability and adoptability of Deep Learning systems. These concerns, coupled with the increasing human-AI interactions, have created the emerging field that is Human-Centered Machine Learning (HCML). We present this review paper as an overview and analysis of existing work in HCML related to DL. Firstly, we collaborated with field domain experts to develop a working definition for HCML. Secondly, through a systematic literature review, we analyze and classify 162 publications that fall within HCML. Our classification is based on aspects including contribution type, application area, and focused human categories. Finally, we analyze the topology of the HCML landscape by identifying research gaps, highlighting conflicting interpretations, addressing current challenges, and presenting future HCML research opportunities.
C1 [Kaluarachchi, Tharindu; Reis, Andrew; Nanayakkara, Suranga] Univ Auckland, Auckland Bioengn Inst, Augmented Human Lab, 70 Symonds St, Auckland 1010, New Zealand.
RP Kaluarachchi, T (corresponding author), Univ Auckland, Auckland Bioengn Inst, Augmented Human Lab, 70 Symonds St, Auckland 1010, New Zealand.
EM tharindu@ahlab.org; andrew@ahlab.org; suranga@ahlab.org
OI Kaluarachchi, Tharindu/0000-0002-1777-231X; NANAYAKKARA,
   SURANGA/0000-0001-7441-5493
FU Tertiary Education Commission Assistive Augmentation research grant
   under the Entrepreneurial Universities (EU) initiative of New Zealand
   [3716751]
FX This research was funded by Tertiary Education Commission Assistive
   Augmentation research grant under the Entrepreneurial Universities (EU)
   initiative of New Zealand; grant number 3716751.
NR 230
TC 5
Z9 6
U1 20
U2 26
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD APR
PY 2021
VL 21
IS 7
AR 2514
DI 10.3390/s21072514
PG 29
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Instruments & Instrumentation
GA RL3LM
UT WOS:000638878700001
PM 33916850
OA Green Published, gold
DA 2022-04-17
ER

PT C
AU Koranga, M
   Pandey, R
   Joshi, M
   Kumar, M
AF Koranga, Manisha
   Pandey, Richa
   Joshi, Mayurika
   Kumar, Manish
TI Analysis of white wine using machine learning algorithms
SO MATERIALS TODAY-PROCEEDINGS
LA English
DT Proceedings Paper
CT International Conference on Technological Advancements in Materials
   Science and Manufacturing (ICTAMSM)
CY FEB 19-20, 2021
CL INDIA
DE Machine learning; ROC curve; Wine quality; WEKA; Regression;
   Classification
AB Wine is one of the popular drinks as its consumption is quite popular among generations and the quality is dependent of time generally older the wine better the taste. One of the growing research areas in the field of engineering is machine learning. The current research emphasizes on the study of wine quality and class attributes using machine learning algorithms on Wine quality dataset. The quality of Wine contains different characteristics along with alcohol content found in it. The fluctuating nature of characteristics also defines variation, improvements received in quality of wine with reference to time horizon. Machine learning techniques are used to assess the quality under the dimension of different classification and regression methods to seek out higher accuracy. (C) 2021 Elsevier Ltd. All rights reserved.
C1 [Koranga, Manisha; Pandey, Richa; Joshi, Mayurika] Graph Era Hill Univ, Dept Comp Sci & Engn, Haldwani 263139, India.
   [Kumar, Manish] Graph Era Hill Univ, Dept Management, Haldwani 263139, India.
RP Koranga, M (corresponding author), Graph Era Hill Univ, Dept Comp Sci & Engn, Haldwani 263139, India.
EM koranga.manisha@gmail.com
NR 17
TC 1
Z9 1
U1 3
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2214-7853
J9 MATER TODAY-PROC
JI Mater. Today-Proc.
PY 2021
VL 46
SI SI
BP 11087
EP 11093
DI 10.1016/j.matpr.2021.02.229
EA SEP 2021
PN 20
PG 7
WC Materials Science, Multidisciplinary
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Materials Science
GA UZ1UK
UT WOS:000701996500034
DA 2022-04-17
ER

PT J
AU Wei, WT
   Gu, HX
   Li, BC
AF Wei, Wenting
   Gu, Huaxi
   Li, Baochun
TI Congestion Control: A Renaissance with Machine Learning
SO IEEE NETWORK
LA English
DT Article
DE Bandwidth; Protocols; Delays; Machine learning; Throughput; Packet loss;
   Switches
AB In the past several decades, it has been well known that the Transmission Control Protocol (TCP), even with its modern variants such as CUBIC, may not perform optimally when available bottleneck bandwidth needs to be fully utilized, yet without unnecessarily increasing the end-to-end latency. These observations have led to a recent resurgence of interest in the topic of redesigning congestion control protocols and replacing modern TCP variants using machine learning. In this article, we examine and compare some of the most prominent recent research results on the use of machine learning to redesign congestion control protocols, with an editorial commentary on potential research directions in the near-term future.
C1 [Wei, Wenting; Gu, Huaxi] Xidian Univ, Telecommun & Informat Syst, Xian, Peoples R China.
   [Li, Baochun] Univ Toronto, Dept Elect & Comp Engn, Toronto, ON, Canada.
RP Wei, WT (corresponding author), Xidian Univ, Telecommun & Informat Syst, Xian, Peoples R China.
FU National Key R&D Program of China [2018YFE0202800]; National Natural
   Science Foundation of ChinaNational Natural Science Foundation of China
   (NSFC) [61634004, 61934002]; Natural Science Foundation of Shaanxi
   Province for Distinguished Young Scholars [2020JC-26]; Fundamental
   Research Funds for the Central UniversitiesFundamental Research Funds
   for the Central Universities [XJS200119, JB190105]; State Key Laboratory
   of Mathematical Engineering and Advanced Computing [2019A01]; China
   Postdoctoral Science FoundationChina Postdoctoral Science Foundation
   [2018M633465]; Youth Innovation Team of Shaanxi Universities
FX This work was supported in part by the National Key R&D Program of China
   under Grant 2018YFE0202800; the National Natural Science Foundation of
   China under Grant 61634004 and 61934002; the Natural Science Foundation
   of Shaanxi Province for Distinguished Young Scholars under Grant
   2020JC-26; the Fundamental Research Funds for the Central Universities
   under Grant XJS200119 and JB190105; the Open Proj-ect Program of the
   State Key Laboratory of Mathematical Engineering and Advanced Computing
   under Grant 2019A01; and the China Postdoctoral Science Foundation
   2018M633465. This work was supported by The Youth Innovation Team of
   Shaanxi Universities.
NR 15
TC 4
Z9 4
U1 4
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0890-8044
EI 1558-156X
J9 IEEE NETWORK
JI IEEE Netw.
PD JUL-AUG
PY 2021
VL 35
IS 4
BP 262
EP 269
DI 10.1109/MNET.011.2000603
PG 8
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Engineering, Electrical & Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA UF4BY
UT WOS:000688521300048
DA 2022-04-17
ER

PT C
AU Tollefsen, M
   Osen, OL
AF Tollefsen, Mikael
   Osen, Ottar L.
BE Klinger, T
   Kollmitzer, C
   Pester, A
TI A runtime execution environment for machine-learning laboratory work
SO PROCEEDINGS OF THE 2021 IEEE GLOBAL ENGINEERING EDUCATION CONFERENCE
   (EDUCON)
SE IEEE Global Engineering Education Conference
LA English
DT Proceedings Paper
CT IEEE Global Engineering Education Conference (IEEE EDUCON)
CY APR 21-23, 2021
CL Vienna, AUSTRIA
SP IEEE
DE Remote Lab; machine learning; computer science education
ID PERFORMANCE; TECHNOLOGY; STRATEGIES; SCIENCE
AB Machine-learning requires resources that are usually not available on students private computers/laptops. Instead, students will often need to upload their code to on- or off-campus facilities. This process may be quite challenging for novice students. To mitigate this, we have developed a system for remote execution of machine-learning algorithms on public or private cloud-like environments.
C1 [Tollefsen, Mikael; Osen, Ottar L.] NTNU Norwegian Univ Sci & Technol, Cyber Phys Syst Lab, Dept ICT & Nat Sci, Postboks 1517, NO-6025 Alesund, Norway.
RP Tollefsen, M (corresponding author), NTNU Norwegian Univ Sci & Technol, Cyber Phys Syst Lab, Dept ICT & Nat Sci, Postboks 1517, NO-6025 Alesund, Norway.
EM mikael.tollefsen@ntnu.no; ottar.osen@ntnu.no
FU NTNU Excited, a university centre for excellent IT education
FX This work was partially funded by NTNU Excited, a university centre for
   excellent IT education.
NR 34
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2165-9567
BN 978-1-7281-8478-4
J9 IEEE GLOB ENG EDUC C
PY 2021
BP 664
EP 669
DI 10.1109/EDUCON46332.2021.9454052
PG 6
WC Education, Scientific Disciplines; Engineering, Multidisciplinary
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Education & Educational Research; Engineering
GA BS1GK
UT WOS:000689064100097
DA 2022-04-17
ER

PT C
AU Guarino, A
   Malandrino, D
   Zaccagnino, R
   Cozza, F
   Rapuano, A
AF Guarino, Alfonso
   Malandrino, Delfina
   Zaccagnino, Rocco
   Cozza, Federico
   Rapuano, Antonio
BE Furnell, S
   Mori, P
   Weippl, E
   Camp, O
TI On Analyzing Third-party Tracking via Machine Learning
SO ICISSP: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INFORMATION
   SYSTEMS SECURITY AND PRIVACY
LA English
DT Proceedings Paper
CT 6th International Conference on Information Systems Security and Privacy
   (ICISSP)
CY FEB 25-27, 2020
CL Valletta, MALTA
DE Privacy; Third Party Tracking; Machine Learning
ID ACCURACY; PRIVACY
AB Nowadays, websites rely on services provided by third party sites to track users and offer personalized experiences. However, this practice threatens the privacy of individuals through the use of valuable information to create a digital personal profile. The existing client-side countermeasures to protect privacy, exhibit performance issues, mainly due to the use of blacklisting mechanisms (list of resources to be filtered out). In this paper, we study the use of machine learning methods to classify the thirdy-party privacy intrusive resources (trackers). To this end, we first downloaded (browsing Alexa's Top 10 websites for each category like sports, shopping etc.) a dataset of 1000 web resources split into functional and tracking, and then we identified suitable metrics to distinguish between the two classes. In order to evaluate the effectiveness of the proposed metrics we have compared the performances of several machine learning models based on supervised learning among the most used in literature. As a result, we obtained that the Random Forest can classify functional and tracking resources with an accuracy of 91%.
C1 [Guarino, Alfonso; Malandrino, Delfina; Zaccagnino, Rocco; Cozza, Federico; Rapuano, Antonio] Univ Salerno, Dept Comp Sci, Via Giovanni Paolo II, I-84084 Fisciano, SA, Italy.
RP Guarino, A (corresponding author), Univ Salerno, Dept Comp Sci, Via Giovanni Paolo II, I-84084 Fisciano, SA, Italy.
OI Malandrino, Delfina/0000-0003-2693-0196; Zaccagnino,
   Rocco/0000-0002-9089-5957
NR 62
TC 0
Z9 0
U1 0
U2 0
PU SCITEPRESS
PI SETUBAL
PA AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL
BN 978-989-758-399-5
PY 2020
BP 532
EP 539
DI 10.5220/0008972005320539
PG 8
WC Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BP9RT
UT WOS:000570766300056
OA hybrid
DA 2022-04-17
ER

PT J
AU Li, YB
   Lei, G
   Bramerdorfer, G
   Peng, S
   Sun, XD
   Zhu, JG
AF Li, Yanbin
   Lei, Gang
   Bramerdorfer, Gerd
   Peng, Sheng
   Sun, Xiaodong
   Zhu, Jianguo
TI Machine Learning for Design Optimization of Electromagnetic Devices:
   Recent Developments and Future Directions
SO APPLIED SCIENCES-BASEL
LA English
DT Review
DE electromagnetic devices; electrical machines; optimization methods;
   machine learning; deep learning; reliability; topology optimization;
   robust design
ID MAGNET SYNCHRONOUS MOTOR; ROBUST GLOBAL OPTIMIZATION; PM-SMC MOTORS;
   MULTIOBJECTIVE OPTIMIZATION; SEQUENTIAL OPTIMIZATION; ELECTRICAL
   MACHINES; DRIVE SYSTEM; MANUFACTURING TOLERANCES; COGGING TORQUE; HYBRID
AB This paper reviews the recent developments of design optimization methods for electromagnetic devices, with a focus on machine learning methods. First, the recent advances in multi-objective, multidisciplinary, multilevel, topology, fuzzy, and robust design optimization of electromagnetic devices are overviewed. Second, a review is presented to the performance prediction and design optimization of electromagnetic devices based on the machine learning algorithms, including artificial neural network, support vector machine, extreme learning machine, random forest, and deep learning. Last, to meet modern requirements of high manufacturing/production quality and lifetime reliability, several promising topics, including the application of cloud services and digital twin, are discussed as future directions for design optimization of electromagnetic devices.
C1 [Li, Yanbin; Peng, Sheng] Zhongyuan Univ Technol, Sch Elect & Informat, Zhengzhou 450007, Peoples R China.
   [Lei, Gang] Univ Technol Sydney, Sch Elect & Data Engn, Ultimo, NSW 2007, Australia.
   [Bramerdorfer, Gerd] Johannes Kepler Univ Linz, Dept Elect Drives & Power Elect, A-4040 Linz, Austria.
   [Sun, Xiaodong] Jiangsu Univ, Automot Engn Res Inst, Zhenjiang 212013, Jiangsu, Peoples R China.
   [Zhu, Jianguo] Univ Sydney, Sch Elect & Informat Engn, Sydney, NSW 2006, Australia.
RP Lei, G (corresponding author), Univ Technol Sydney, Sch Elect & Data Engn, Ultimo, NSW 2007, Australia.
EM liyanbin@zut.edu.cn; gang.lei@uts.edu.au; gerd.bramerdorfer@jku.at;
   9907@zut.edu.cn; xdsun@ujs.edu.cn; jianguo.zhu@sydney.edu.au
OI Sun, Xiaodong/0000-0002-9451-3311; Zhu, Jianguo/0000-0002-9763-4047
FU National Natural Science Foundation of China (NSFC)National Natural
   Science Foundation of China (NSFC) [61873292]; Education Department of
   Henan Province [19A470005]
FX This work was supported in part by the National Natural Science
   Foundation of China (NSFC) under grant 61873292, and in part by the
   Education Department of Henan Province under project 19A470005.
NR 156
TC 6
Z9 6
U1 16
U2 27
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD FEB
PY 2021
VL 11
IS 4
AR 1627
DI 10.3390/app11041627
PG 24
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Materials Science; Physics
GA RB4NM
UT WOS:000632089400001
OA gold
DA 2022-04-17
ER

PT J
AU Hosseini, MP
   Hosseini, A
   Ahi, K
AF Hosseini, Mohammad-Parsa
   Hosseini, Amin
   Ahi, Kiarash
TI A Review on Machine Learning for EEG Signal Processing in Bioengineering
SO IEEE REVIEWS IN BIOMEDICAL ENGINEERING
LA English
DT Review
DE Electroencephalography; Machine learning; Support vector machines;
   Supervised learning; Brain modeling; Unsupervised learning; Mathematical
   model; Machine learning; eeg; survey; medical applications; signal
   processing; signal analysis
ID EPILEPTIC SEIZURE DETECTION; TEMPORAL-LOBE EPILEPSY; FUNCTIONAL
   CONNECTIVITY; PERFORMANCE EVALUATION; APPROXIMATE ENTROPY;
   CLASSIFICATION; PREDICTION; DISCRIMINATION; TRANSFORM; ARTIFACTS
AB Electroencephalography (EEG) has been a staple method for identifying certain health conditions in patients since its discovery. Due to the many different types of classifiers available to use, the analysis methods are also equally numerous. In this review, we will be examining specifically machine learning methods that have been developed for EEG analysis with bioengineering applications. We reviewed literature from 1988 to 2018 to capture previous and current classification methods for EEG in multiple applications. From this information, we are able to determine the overall effectiveness of each machine learning method as well as the key characteristics. We have found that all the primary methods used in machine learning have been applied in some form in EEG classification. This ranges from Naive-Bayes to Decision Tree/Random Forest, to Support Vector Machine (SVM). Supervised learning methods are on average of higher accuracy than their unsupervised counterparts. This includes SVM and KNN. While each of the methods individually is limited in their accuracy in their respective applications, there is hope that the combination of methods when implemented properly has a higher overall classification accuracy. This paper provides a comprehensive overview of Machine Learning applications used in EEG analysis. It also gives an overview of each of the methods and general applications that each is best suited to.
C1 [Hosseini, Mohammad-Parsa] Santa Clara Univ, Bioengn Dept, Santa Clara, CA 95053 USA.
   [Hosseini, Mohammad-Parsa] Al Res, Silicon Valley, CA USA.
   [Hosseini, Amin] Azad Univ, Cent Tehran Branch, Elect & Comp Engn Dept, Tehran, Iran.
   [Ahi, Kiarash] Univ Connecticut, Storrs, CT 06269 USA.
RP Hosseini, MP (corresponding author), Santa Clara Univ, Bioengn Dept, Santa Clara, CA 95053 USA.
EM mhosseini@scu.edu; ami.hosseini.eng@iauctb.ac.ir; kiarash.ahi@uconn.edu
OI Hosseini, Mohammad-Parsa/0000-0002-0611-7520
NR 113
TC 17
Z9 17
U1 23
U2 39
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1937-3333
EI 1941-1189
J9 IEEE REV BIOMED ENG
JI IEEE Rev. Biomed. Eng.
PY 2021
VL 14
BP 204
EP 218
DI 10.1109/RBME.2020.2969915
PG 15
WC Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA WI6CE
UT WOS:000708445300016
PM 32011262
DA 2022-04-17
ER

PT S
AU Angelis, I
   Exarchos, T
AF Angelis, Ioannis
   Exarchos, Themis
BE Vlamos, P
TI Hepatocellular Carcinoma Detection Using Machine Learning Techniques
SO GENEDIS 2020: COMPUTATIONAL BIOLOGY AND BIOINFORMATICS
SE Advances in Experimental Medicine and Biology
LA English
DT Article; Proceedings Paper
CT 4th World Congress on Genetics, Geriatrics and Neurodegenerative
   Diseases Research (GeNeDis)
CY OCT 09-11, 2020
CL ELECTR NETWORK
DE Hepatocellular carcinoma; Machine learning; Classification
AB Hepatocellular carcinoma (HCC) is a form of primary cancer appearing in the liver. In this work used the hepatocellular carcinoma data-set from the UCI machine learning repository and tested different techniques for feature selection and classification. The following algorithms were used: decision trees, random forests, SVMs, k-NN classifiers, AdaBoost, and gradient boost. The best results were obtained using gradient boost with 84% accuracy and 93% precision. Finally, we deployed the model to a web application as a decision support system for clinicians.
C1 [Angelis, Ioannis; Exarchos, Themis] Ionian Univ, Dept Informat, Corfu, Greece.
RP Exarchos, T (corresponding author), Ionian Univ, Dept Informat, Corfu, Greece.
EM c19ange@ionio.gr; exarchos@ionio.com
NR 12
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0065-2598
EI 2214-8019
BN 978-3-030-78775-2; 978-3-030-78774-5
J9 ADV EXP MED BIOL
JI Adv.Exp.Med.Biol.
PY 2021
VL 1338
BP 21
EP 29
DI 10.1007/978-3-030-78775-2_4
PG 9
WC Biology; Engineering, Biomedical; Medicine, Research & Experimental
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Engineering; Research &
   Experimental Medicine
GA BS6XU
UT WOS:000754557400004
PM 34973006
DA 2022-04-17
ER

PT J
AU Jiang, MD
   Li, YT
   Jiang, CD
   Zhao, LD
   Zhang, X
   Lipsky, PE
AF Jiang, Mengdi
   Li, Yueting
   Jiang, Chendan
   Zhao, Lidan
   Zhang, Xuan
   Lipsky, Peter E.
TI Machine Learning in Rheumatic Diseases
SO CLINICAL REVIEWS IN ALLERGY & IMMUNOLOGY
LA English
DT Review
DE Machine learning; Rheumatic diseases; Medicine; Clinical application
ID JUVENILE IDIOPATHIC ARTHRITIS; SYSTEMIC-LUPUS-ERYTHEMATOSUS; KNEE
   OSTEOARTHRITIS; BIG DATA; PREDICTION; ULTRASOUND; MORTALITY; OUTCOMES;
   IMAGES; CLASSIFICATION
AB With advances in information technology, the demand for using data science to enhance healthcare and disease management is rapidly increasing. Among these technologies, machine learning (ML) has become ubiquitous and indispensable for solving complex problems in many scientific fields, including medical science. ML allows the development of guidelines and framing of the evaluation system for complex diseases based on massive data. In the analysis of rheumatic diseases, which are chronic and remarkably heterogeneous, ML can be anticipated to be extremely helpful in deciphering and revealing the inherent interrelationships in disease development and progression, which can further enhance the overall understanding of the disease, optimize patients' stratification, calibrate therapeutic strategies, and predict prognosis and outcomes. In this review, the basics of ML, its potential clinical applications in rheumatology, together with its strengths and limitations are summarized.
C1 [Jiang, Mengdi; Li, Yueting; Zhao, Lidan] Chinese Acad Med Sci & Peking Union Med Coll, Peking Union Med Coll Hosp, Dept Rheumatol & Clin Immunol, Beijing 100730, Peoples R China.
   [Jiang, Mengdi; Li, Yueting; Zhao, Lidan; Zhang, Xuan] Minist Educ, Key Lab, Beijing 100730, Peoples R China.
   [Jiang, Mengdi; Li, Yueting; Zhang, Xuan] Chinese Acad Med Sci & Peking Union Med Coll, Peking Union Med Coll Hosp, Clin Immunol Ctr, Med Epigenet Res Ctr, Beijing 100730, Peoples R China.
   [Jiang, Chendan] Chinese Acad Med Sci & Peking Union Med Coll, Peking Union Med Coll Hosp, Dept Neurosurg, Beijing 100730, Peoples R China.
   [Lipsky, Peter E.] RILITE Res Inst, Charlottesville, VA USA.
   [Lipsky, Peter E.] AMPEL BioSolut, Charlottesville, VA USA.
RP Zhao, LD (corresponding author), Chinese Acad Med Sci & Peking Union Med Coll, Peking Union Med Coll Hosp, Dept Rheumatol & Clin Immunol, Beijing 100730, Peoples R China.; Zhao, LD; Zhang, X (corresponding author), Minist Educ, Key Lab, Beijing 100730, Peoples R China.; Zhang, X (corresponding author), Chinese Acad Med Sci & Peking Union Med Coll, Peking Union Med Coll Hosp, Clin Immunol Ctr, Med Epigenet Res Ctr, Beijing 100730, Peoples R China.
EM zhaolidan@hotmail.com; zxpumch2003@sina.com
RI zhang, xuan/AAN-9914-2020
OI zhang, xuan/0000-0001-8775-1699; Zhao, Lidan/0000-0001-6599-3339; Jiang,
   Mengdi/0000-0003-2978-8834
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [81788101, 81630044]; Chinese Academy of
   Medical Science Innovation Fund for Medical Sciences
   [CIFMS2016-12M-1-003, 2017-12M-1-008, 2017-I2M-3-011, 2016-12M-1-008];
   Beijing Capital Health Development Fund [2020-2-4019]; Medical
   Epigenetics Research Center, Chinese Academy of Medical Sciences
   [2017PT31035]
FX This study was supported by grants from the National Natural Science
   Foundation of China (81788101, 81630044), Chinese Academy of Medical
   Science Innovation Fund for Medical Sciences (CIFMS2016-12M-1-003,
   2017-12M-1-008, 2017-I2M-3-011, 2016-12M-1-008), Beijing Capital Health
   Development Fund (2020-2-4019), and Grant from Medical Epigenetics
   Research Center, Chinese Academy of Medical Sciences (2017PT31035).
NR 112
TC 5
Z9 5
U1 7
U2 21
PU HUMANA PRESS INC
PI TOTOWA
PA 999 RIVERVIEW DRIVE SUITE 208, TOTOWA, NJ 07512 USA
SN 1080-0549
EI 1559-0267
J9 CLIN REV ALLERG IMMU
JI Clin. Rev. Allergy Immunol.
PD FEB
PY 2021
VL 60
IS 1
SI SI
BP 96
EP 110
DI 10.1007/s12016-020-08805-6
EA JUL 2020
PG 15
WC Allergy; Immunology
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Allergy; Immunology
GA PU7KM
UT WOS:000549671900001
PM 32681407
DA 2022-04-17
ER

PT J
AU Huang, D
   Liu, SS
   Zhang, L
AF Huang, Duan
   Liu, Susu
   Zhang, Ling
TI Secure Continuous-Variable Quantum Key Distribution with Machine
   Learning
SO PHOTONICS
LA English
DT Review
DE CVQKD; machine learning; attack and defense
ID PARAMETER OPTIMIZATION
AB Quantum key distribution (QKD) offers information-theoretical security, while real systems are thought not to promise practical security effectively. In the practical continuous-variable (CV) QKD system, the deviations between realistic devices and idealized models might introduce vulnerabilities for eavesdroppers and stressors for two parties. However, the common quantum hacking strategies and countermeasures inevitably increase the complexity of practical CV systems. Machine-learning techniques are utilized to explore how to perceive practical imperfections. Here, we review recent works on secure CVQKD systems with machine learning, where the methods for detections and attacks were studied.
C1 [Huang, Duan; Liu, Susu] Cent South Univ, Sch Comp Sci & Engn, Changsha 410083, Peoples R China.
   [Zhang, Ling] Cent South Univ, Sch Automat, Changsha 410083, Peoples R China.
RP Huang, D (corresponding author), Cent South Univ, Sch Comp Sci & Engn, Changsha 410083, Peoples R China.
EM duanhuang@csu.edu.cn; lingzhang2019@csu.edu.cn
OI Liu, Susu/0000-0002-6334-9563
FU National Natural Science Foundation of China (NSFC)National Natural
   Science Foundation of China (NSFC) [61972418, 61977062, 61872390,
   61801522]; National Natural Science Foundation of Hunan Province,
   ChinaNatural Science Foundation of Hunan Province [2019JJ40352];
   Fundamental Research Funds for the Central Universities of Central South
   University [2019zzts278]
FX This research was funded by the National Natural Science Foundation of
   China (NSFC) (61972418, 61977062, 61872390, and 61801522), the National
   Natural Science Foundation of Hunan Province, China (2019JJ40352), and
   the Fundamental Research Funds for the Central Universities of Central
   South University (2019zzts278).
NR 55
TC 1
Z9 1
U1 11
U2 11
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2304-6732
J9 PHOTONICS-BASEL
JI Photonics
PD NOV
PY 2021
VL 8
IS 11
AR 511
DI 10.3390/photonics8110511
PG 12
WC Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Optics
GA XJ5QI
UT WOS:000726841800001
OA gold
DA 2022-04-17
ER

PT J
AU Zhang, YC
   Wijeratne, LOH
   Talebi, S
   Lary, DJ
AF Zhang, Yichao
   Wijeratne, Lakitha O. H.
   Talebi, Shawhin
   Lary, David J.
TI Machine Learning for Light Sensor Calibration
SO SENSORS
LA English
DT Article
DE spectrophotometer; light sensor; machine learning; neural networks
ID NEURAL-NETWORKS; DIFFUSE-RADIATION; TWILIGHT; MODEL
AB Sunlight incident on the Earth's atmosphere is essential for life, and it is the driving force of a host of photo-chemical and environmental processes, such as the radiative heating of the atmosphere. We report the description and application of a physical methodology relative to how an ensemble of very low-cost sensors (with a total cost of <$20, less than 0.5% of the cost of the reference sensor) can be used to provide wavelength resolved irradiance spectra with a resolution of 1 nm between 360-780 nm by calibrating against a reference sensor using machine learning. These low-cost sensor ensembles are calibrated using machine learning and can effectively reproduce the observations made by an NIST calibrated reference instrument (Konica Minolta CL-500A with a cost of around USD 6000). The correlation coefficient between the reference sensor and the calibrated low-cost sensor ensemble has been optimized to have R-2 > 0.99. Both the circuits used and the code have been made publicly available. By accurately calibrating the low-cost sensors, we are able to distribute a large number of low-cost sensors in a neighborhood scale area. It provides unprecedented spatial and temporal insights into the micro-scale variability of the wavelength resolved irradiance, which is relevant for air quality, environmental and agronomy applications.
C1 [Zhang, Yichao; Wijeratne, Lakitha O. H.; Talebi, Shawhin; Lary, David J.] Univ Texas Dallas, Hanson Ctr Space Sci, Richardson, TX 75080 USA.
RP Zhang, YC; Lary, DJ (corresponding author), Univ Texas Dallas, Hanson Ctr Space Sci, Richardson, TX 75080 USA.
EM yichao.zhang1@utdallas.edu; lhw150030@utdallas.edu;
   Shawhin.Talebi@utdallas.edu; Davidiary@utdallas.edu
OI Talebi, Shawhin/0000-0002-9841-6703; Wijeratne,
   Lakitha/0000-0003-2688-648X; Lary, David/0000-0003-4265-9543; Zhang,
   Yichao/0000-0003-0494-2276
FU USAMRMC Award [W81XWH-18-1-0400]; NSFNational Science Foundation (NSF)
   [2019135]
FX This research was funded by USAMRMC Award Number W81XWH-18-1-0400. The
   authors acknowledge the Texas Research and Education Cyberinfrastructure
   Services (TRECIS) Center, NSF Award #2019135, and the University of
   Texas at Dallas for providing HPC, visualization, database or grid
   resources and support that have contributed to the research results
   reported within this paper. URL:
   https://trecis.cyberinfrastructure.org/, accessed 22 July 2021.
NR 44
TC 0
Z9 0
U1 4
U2 4
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD SEP
PY 2021
VL 21
IS 18
AR 6259
DI 10.3390/s21186259
PG 17
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Instruments & Instrumentation
GA UY8BB
UT WOS:000701741500001
PM 34577466
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Peng, ZH
   Yang, ZY
   Wang, YJ
AF Peng, Zheng-Han
   Yang, Zeng-Yu
   Wang, Yun-Jiang
TI Machine learning atomic-scale stiffness in metallic glass
SO EXTREME MECHANICS LETTERS
LA English
DT Article
DE Metallic glass; Machine learning; Atomic stiffness; Molecular dynamics
ID MECHANICAL-BEHAVIOR; DYNAMICS; DEFORMATION; RELAXATION; SIMULATION;
   DEFECTS; ENTROPY; FLOW
AB Due to lack of either translational or rotational symmetries at atomic-scale, predicting properties of amorphous materials from static structure is a challenging task. To circumvent the dilemma, a supervised machine-learning strategy via neural network is proposed to predict the atomic stiffness of metallic glass from discretized radial distribution function. The predicted stiffness and its spatial nature are calibrated with molecular dynamics simulations. After which, the origin of atomic constraint is interpreted via the learning structural input. Inadequacy of the model is discussed in terms of incompleteness in both machine-learning configurational space and structural descriptor. (C) 2021 Elsevier Ltd. All rights reserved.
C1 [Peng, Zheng-Han; Yang, Zeng-Yu; Wang, Yun-Jiang] Chinese Acad Sci, Inst Mech, State Key Lab Nonlinear Mech, Beijing 100190, Peoples R China.
   [Peng, Zheng-Han] Sichuan Univ, Coll Mat Sci & Engn, Chengdu 610065, Peoples R China.
   [Yang, Zeng-Yu; Wang, Yun-Jiang] Univ Chinese Acad Sci, Sch Engn Sci, Beijing 100049, Peoples R China.
RP Wang, YJ (corresponding author), Chinese Acad Sci, Inst Mech, State Key Lab Nonlinear Mech, Beijing 100190, Peoples R China.
EM yjwang@imech.ac.cn
RI Yang, Zengyu/AAC-8577-2019; Wang, Yun-Jiang/H-6062-2011
OI Yang, Zengyu/0000-0003-0510-8785; Wang, Yun-Jiang/0000-0002-2969-3889
FU National Key Research and Development Program of China [2017YFB0701502,
   2017YFB0702003]; National Natural Science Foundation of ChinaNational
   Natural Science Foundation of China (NSFC) [12072344, 11790292]; Youth
   Innovation Promotion Association of Chinese Academy of Sciences, China
   [2017025]
FX This work is financially supported by the National Key Research and
   Development Program of China (Nos. 2017YFB0701502 and 2017YFB0702003),
   the National Natural Science Foundation of China (Nos. 12072344 and
   11790292), and the Youth Innovation Promotion Association of Chinese
   Academy of Sciences, China (No. 2017025).
NR 53
TC 1
Z9 1
U1 10
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2352-4316
J9 EXTREME MECH LETT
JI EXTREME MECH. LETT.
PD OCT
PY 2021
VL 48
AR 101446
DI 10.1016/j.eml.2021.101446
EA JUL 2021
PG 5
WC Engineering, Mechanical; Materials Science, Multidisciplinary; Mechanics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Materials Science; Mechanics
GA UD0IT
UT WOS:000686901700002
DA 2022-04-17
ER

PT J
AU Crampon, K
   Giorkallos, A
   Deldossi, M
   Baud, S
   Steffenel, LA
AF Crampon, Kevin
   Giorkallos, Alexis
   Deldossi, Myrtille
   Baud, Stephanie
   Steffenel, Luiz Angelo
TI Machine-learning methods for ligand-protein molecular docking
SO DRUG DISCOVERY TODAY
LA English
DT Review
DE Molecular docking; Sampling; Scoring; Machine learning; Deep learning;
   Data representation
ID SCORING FUNCTION; BINDING-AFFINITY; INTERACTION FINGERPRINTS; INVERSE
   DOCKING; NEURAL-NETWORK; PREDICTION; ENERGY; COMPLEXES; DYNAMICS;
   TARGETS
AB Artificial intelligence (AI) is often presented as a new Industrial Revolution. Many domains use AI, including molecular simulation for drug discovery. In this review, we provide an overview of ligand-protein molecular docking and how machine learning (ML), especially deep learning (DL), a subset of ML, is transforming the field by tackling the associated challenges.
C1 [Crampon, Kevin; Baud, Stephanie] Univ Reims, CNRS, MEDyC UMR 7369, F-51097 Reims, France.
   [Crampon, Kevin; Steffenel, Luiz Angelo] Univ Reims, LICIIS LRC CEA Digit, F-51100 Reims, France.
   [Crampon, Kevin; Giorkallos, Alexis; Deldossi, Myrtille] Atos SE, Ctr Excellence Adv Comp, F-38130 Echirolles, France.
RP Steffenel, LA (corresponding author), Univ Reims, LICIIS LRC CEA Digit, F-51100 Reims, France.
EM angelo.steffenel@univ-reims.fr
RI Baud, Stephanie/AAR-8256-2020
OI Baud, Stephanie/0000-0002-4436-0652; Crampon, Kevin/0000-0001-6124-0719;
   Steffenel, Luiz Angelo/0000-0003-3670-4088
FU Association Nationale de la Recherche et de la Technologie (ANRT)
   through a CIFRE grantFrench National Research Agency (ANR)
FX The authors thank Manuel Dauchez for his helpful and fruit-ful
   discussions. This work was supported by the Association Nationale de la
   Recherche et de la Technologie (ANRT) through a CIFRE grant.
NR 119
TC 1
Z9 1
U1 35
U2 35
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1359-6446
EI 1878-5832
J9 DRUG DISCOV TODAY
JI Drug Discov. Today
PD JAN
PY 2022
VL 27
IS 1
BP 151
EP 164
DI 10.1016/j.drudis.2021.09.007
PG 14
WC Pharmacology & Pharmacy
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Pharmacology & Pharmacy
GA XY4XN
UT WOS:000736977400012
PM 34560276
DA 2022-04-17
ER

PT J
AU Straub, J
AF Straub, Jeremy
TI Machine learning performance validation and training using a 'perfect'
   expert system
SO METHODSX
LA English
DT Article
DE Machine learning; Learning model; Knowledge engineering; System
   performance evaluation
ID ARTIFICIAL-INTELLIGENCE
AB A method is proposed for generating application domain agnostic data for training and evaluating machine learning systems. The proposed method randomly generates an expert system network based upon user specified parameters. This expert system serves as a generic model of an unspecified phenomena. The expert system is run to determine the ideal output from a set of random inputs. These inputs and ideal output are used for training and testing a machine learning system. This allows a machine learning technology to be developed and tested without requiring compatible test data to be collected or before data collection as a proof-of-concept validation of system operations. It also allows systems to be tested without data error noise or with known levels of noise and with other perturbations, to facilitate analysis. It may also facilitate testing system security, adversarial attacks and conducting other types of research into machine learning systems.
   Provides an application domain agnostic way to test machine learning technologies and facilitates the generalization of results.
   Allows technologies to be tested with data with different characteristics without having to locate datasets that have these characteristics.
   Utilizes randomly generated network to represent non-specific phenomena which can be used for training and testing machine learning techniques. (C) 2021 The Author. Published by Elsevier B.V.
C1 [Straub, Jeremy] North Dakota State Univ, Dept Comp Sci, Fargo, ND 58105 USA.
RP Straub, J (corresponding author), North Dakota State Univ, Dept Comp Sci, Fargo, ND 58105 USA.
EM jeremy.straub@ndsu.edu
NR 14
TC 2
Z9 2
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
EI 2215-0161
J9 METHODSX
JI MethodsX
PY 2021
VL 8
AR 101477
DI 10.1016/j.mex.2021.101477
EA AUG 2021
PG 6
WC Multidisciplinary Sciences
WE Emerging Sources Citation Index (ESCI)
SC Science & Technology - Other Topics
GA WK5MP
UT WOS:000709769700006
PM 34434876
OA gold, Green Published
DA 2022-04-17
ER

PT C
AU Heruwidagdo, IR
   Suharjito
   Hanafiah, N
   Setiawan, Y
AF Heruwidagdo, Ignatius Rahardjo
   Suharjito
   Hanafiah, Novita
   Setiawan, Yanto
BE Budiharto, W
   Kurniawan, A
   Suhartono, D
   Chowanda, A
   Gunawan, AAS
   Udjaja, Y
TI Performance of Information Technology Infrastructure Prediction using
   Machine Learning
SO 5TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND COMPUTATIONAL
   INTELLIGENCE 2020
SE Procedia Computer Science
LA English
DT Proceedings Paper
CT 5th International Conference on Computer Science and Computational
   Intelligence (ICCSCI)
CY NOV 19-20, 2020
CL ELECTR NETWORK
DE log performance; machine learning; kNN; IT infrastructure; performance
   prediction
AB Resource management is always an important issue related to good governance decision making. One of the common problem faced in managing IT Infrastructure is about allocating server resources to improve the performance. In this study we use a machine learning approach to make predictions about the performance of information technology infrastructure. The experiment took data from several servers in a company to be tested. The performance measure of resources used in this study are CPU Performance, Disk performance, Memory capacity, and Network performance. Several algorithms and machine learning methods are tested, such as Linear Regression, kNN, SVR, Decision Tree and Random Forest, to find the best model fit for the servers. The comparison result shows that Linear regression and kNN perform well in predicting the network performance in those three servers. (C) 2021 The Authors. Published by Elsevier B.V.
C1 [Heruwidagdo, Ignatius Rahardjo; Suharjito] Bina Nusantara Univ, Comp Sci Dept, Binus Grad Program, Comp Sci, West Jakarta, Indonesia.
   [Suharjito; Hanafiah, Novita; Setiawan, Yanto] Bina Nusantara Univ, Comp Sci Dept, BINUS Online Learning, Jakarta 11480, Indonesia.
RP Hanafiah, N (corresponding author), Bina Nusantara Univ, Comp Sci Dept, BINUS Online Learning, Jakarta 11480, Indonesia.
EM novita.hanafiah@binus.ac.id
NR 15
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0509
J9 PROCEDIA COMPUT SCI
PY 2021
VL 179
BP 515
EP 523
DI 10.1016/j.procs.2021.01.035
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR5DK
UT WOS:000654256300065
OA gold
DA 2022-04-17
ER

PT J
AU Wang, JW
   Jing, XY
   Yan, Z
   Fu, YL
   Pedrycz, W
   Yang, LT
AF Wang, Jingwen
   Jing, Xuyang
   Yan, Zheng
   Fu, Yulong
   Pedrycz, Witold
   Yang, Laurence T.
TI A Survey on Trust Evaluation Based on Machine Learning
SO ACM COMPUTING SURVEYS
LA English
DT Article
DE Trust evaluation; machine learning; performance metrics; evaluation
   requirements
ID PRACTICAL REPUTATION SYSTEM; EVALUATION MODEL; NETWORKS; PREDICTION;
   PROPAGATION; BEHAVIORS
AB Trust evaluation is the process of quantifying trust with attributes that influence trust. It faces a number of severe issues such as lack of essential evaluation data, demand of big data process, request of simple trust relationship expression, and expectation of automation. In order to overcome these problems and intelligently and automatically evaluate trust, machine learning has been applied into trust evaluation. Researchers have proposed many methods to use machine learning for trust evaluation. However, the literature still lacks a comprehensive literature review on this topic. In this article, we perform a thorough survey on trust evaluation based on machine learning. First, we cover essential prerequisites of trust evaluation and machine learning. Then, we justify a number of requirements that a sound trust evaluation method should satisfy, and propose them as evaluation criteria to assess the performance of trust evaluation methods. Furthermore, we systematically organize existing methods according to application scenarios and provide a comprehensive literature review on trust evaluation from the perspective of machine learning's function in trust evaluation and evaluation granularity. Finally, according to the completed review and evaluation, we explore some open research problems and suggest the directions that are worth our research effort in the future.
C1 [Wang, Jingwen; Jing, Xuyang; Fu, Yulong] Xidian Univ, State Kay Lab ISN, Sch Cyber Engn, 266 Xinglong Sect Xifeng Rd, Xian 710126, Shaanxi, Peoples R China.
   [Yan, Zheng] Xidian Univ, State Kay Lab ISN, Sch Cyber Engn, 2 South Taibai Rd, Xian 710071, Shaanxi, Peoples R China.
   [Yan, Zheng] Aalto Univ, Dept Commun & Networking, Konemiehentie 2,POB 15400, Espoo 02150, Finland.
   [Pedrycz, Witold] Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6R 2V4, Canada.
   [Yang, Laurence T.] St Francis Xavier Univ, Dept Comp Sci, Antigonish, NS B2G 2W5, Canada.
RP Wang, JW (corresponding author), Xidian Univ, State Kay Lab ISN, Sch Cyber Engn, 266 Xinglong Sect Xifeng Rd, Xian 710126, Shaanxi, Peoples R China.
EM wjwen0914@163.com; xuyangjing91@163.com; zyan@xidian.edu.cn;
   ylfu@xidian.edu.cn; wpedrycz@ualberta.ca; ltyang@gmail.com
RI Jing, Xuyang/AAP-5757-2021
OI Jing, Xuyang/0000-0003-2274-0969; Yan, Zheng/0000-0002-9697-2108
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61672410, 61802293]; National Postdoctoral
   Program for Innovative Talents [BX20180238]; China Postdoctoral Science
   FoundationChina Postdoctoral Science Foundation [2018M633461]; Academy
   of FinlandAcademy of Finland [308087, 314203, 335262]; Shaanxi
   Innovation Team project [2018TD-007]; 111 projectMinistry of Education,
   China - 111 Project [B16037]; open grant of the Tactical Data Link Lab
   of the 20th Research Institute of China Electronics Technology Group
   Corporation, P.R. China [CLDL-20182119]
FX The work is supported in part by the National Natural Science Foundation
   of China under Grants 61672410 and 61802293, the National Postdoctoral
   Program for Innovative Talents under grant BX20180238, the Project
   funded by China Postdoctoral Science Foundation under grant 2018M633461,
   the Academy of Finland under Grants 308087, 314203 and 335262, the open
   grant of the Tactical Data Link Lab of the 20th Research Institute of
   China Electronics Technology Group Corporation, P.R. China under grant
   CLDL-20182119, the Shaanxi Innovation Team project under grant
   2018TD-007, and the 111 project under grant B16037.
NR 99
TC 13
Z9 14
U1 23
U2 45
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 0360-0300
EI 1557-7341
J9 ACM COMPUT SURV
JI ACM Comput. Surv.
PD OCT
PY 2020
VL 53
IS 5
AR 107
DI 10.1145/3408292
PG 37
WC Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OH1YB
UT WOS:000582365900016
OA Green Published, Bronze
DA 2022-04-17
ER

PT J
AU Cummings, ML
   Li, SP
AF Cummings, Mary L.
   Li, Songpo
TI Subjectivity in the Creation of Machine Learning Models
SO ACM JOURNAL OF DATA AND INFORMATION QUALITY
LA English
DT Article
DE Bias; interpretable machine learning; transportation; logistic
   regression; subjectivity
AB Transportation analysts are inundated with requests to apply popular machine learning modeling techniques to datasets to uncover never-before-seen relationships that could potentially revolutionize safety, congestion, and mobility. However, the results from such models can be influenced not just by biases in underlying data, but also through practitioner-induced biases. To demonstrate the significant number of subjective judgments made in the development and interpretation of machine learning models, we developed Logistic Regression and Neural Network models for transportation-focused datasets including those looking at driving injury/fatalities and pedestrian fatalities. We then developed five different representations of feature importance for each dataset, including different feature interpretations commonly used in the machine learning community. Twelve distinct judgments were highlighted in the development and interpretation of these models, which produced inconsistent results. Such inconsistencies can lead to very different interpretations of the results, which can lead to errors of commission and omission, with significant cost and safety implications if policies are erroneously adapted from such outcomes.
C1 [Cummings, Mary L.; Li, Songpo] Duke Univ, Elect & Comp Engn, Durham, NC 27708 USA.
RP Cummings, ML (corresponding author), Duke Univ, Elect & Comp Engn, Durham, NC 27708 USA.
EM m.cummings@duke.edu; songpo.li@duke.edu
FU US Department of Transportation University Transportation Center;
   University of North Carolina Collaborative Science Center for Road
   Safety
FX This work was sponsored by the US Department of Transportation
   University Transportation Center in partnership with the University of
   North Carolina Collaborative Science Center for Road Safety.
NR 35
TC 0
Z9 0
U1 2
U2 3
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1936-1955
J9 ACM J DATA INF QUAL
JI ACM J. Data Inf. Qual.
PD JUN
PY 2021
VL 13
IS 2
AR 7
DI 10.1145/3418034
PG 19
WC Computer Science, Information Systems
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA TE2SE
UT WOS:000669865000002
DA 2022-04-17
ER

PT C
AU Clement, C
AF Clement, Claudiu
BE Dinu, V
TI MACHINE LEARNING FOR FINANCIAL APPLICATIONS-A MINI-REVIEW
SO 2020 BASIQ INTERNATIONAL CONFERENCE: NEW TRENDS IN SUSTAINABLE BUSINESS
   AND CONSUMPTION
SE Proceedings of BASIQ
LA English
DT Proceedings Paper
CT 6th BASIQ International Conference on New Trends in Sustainable Business
   and Consumption
CY JUN 04-06, 2020
CL Messina, ITALY
SP Assoc Innovat & Qual Sustainable Bsiness, Acad Studii Economice Bucuresti, Studiorum Univ, FAA, AE
DE machine learning; financial applications; finance; scoping review
AB There is an increasing interest in utilizing machine learning in financial applications, with an increasing number of researchers contributing to the literature. Considerable amount of research has been published from academics and industry and there has been a constant focus on which is the best tool to be used for specific applications. The momentum of research on this topic does not mean that it is not faced with challenges. This paper, through a mini scoping review of a number of 342 texts published in the year of 2019 on Scopus, aims at providing academics and practitioners with a broad overview picture of the current literature on machine learning applied in finance. The review shows that even though the focus is on the techniques applied in the field of finance, most papers are published in computer science or engineering thematic journals, with economics, econometrics or finance researchers on the fifth place with a mere 4.2% of papers published. Finally, it is concluded that the interest in machine learning for financial applications is undoubtedly continously increasing with still room for research on the area, being it research or review papers.
C1 [Clement, Claudiu] Alexandru Ioan Cuza Univ, Iasi, Romania.
RP Clement, C (corresponding author), Alexandru Ioan Cuza Univ, Iasi, Romania.
EM office.claudiuclement@gmail.com
NR 15
TC 0
Z9 0
U1 6
U2 7
PU EDITURA ASE
PI BUCURESTI
PA PIATA ROMANA NR 6, SECTOR 1, BUCURESTI, 701631, ROMANIA
SN 2457-483X
J9 PROC BASIQ
PY 2020
BP 306
EP 312
PG 7
WC Business; Green & Sustainable Science & Technology
WE Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Business & Economics; Science & Technology - Other Topics
GA BR0QE
UT WOS:000630165800037
DA 2022-04-17
ER

PT J
AU Chen, YJ
   Mao, YM
   Liang, HY
   Yu, S
   Wei, YK
   Leng, SP
AF Chen, Yijin
   Mao, Yuming
   Liang, Haoyang
   Yu, Shui
   Wei, Yunkai
   Leng, Supeng
TI Data Poison Detection Schemes for Distributed Machine Learning
SO IEEE ACCESS
LA English
DT Article
DE Distributed machine learning; data poison detection; resource allocation
ID SECURITY
AB Distributed machine learning (DML) can realize massive dataset training when no single node can work out the accurate results within an acceptable time. However, this will inevitably expose more potential targets to attackers compared with the non-distributed environment. In this paper, we classify DML into basic-DML and semi-DML. In basic-DML, the center server dispatches learning tasks to distributed machines and aggregates their learning results. While in semi-DML, the center server further devotes resources into dataset learning in addition to its duty in basic-DML. We firstly put forward a novel data poison detection scheme for basic-DML, which utilizes a cross-learning mechanism to find out the poisoned data. We prove that the proposed cross-learning mechanism would generate training loops, based on which a mathematical model is established to find the optimal number of training loops. Then, for semi-DML, we present an improved data poison detection scheme to provide better learning protection with the aid of the central resource. To efficiently utilize the system resources, an optimal resource allocation approach is developed. Simulation results show that the proposed scheme can significantly improve the accuracy of the final model by up to 20 & x0025; for support vector machine and 60 & x0025; for logistic regression in the basic-DML scenario. Moreover, in the semi-DML scenario, the improved data poison detection scheme with optimal resource allocation can decrease the wasted resources for 20-100 & x0025;.
C1 [Chen, Yijin; Mao, Yuming; Liang, Haoyang; Wei, Yunkai; Leng, Supeng] Univ Elect Sci & Technol China, Sch Informat & Commun Engn, Chengdu 611731, Peoples R China.
   [Yu, Shui] Univ Technol Sydney, Sch Software, Sydney, NSW 2007, Australia.
RP Wei, YK (corresponding author), Univ Elect Sci & Technol China, Sch Informat & Commun Engn, Chengdu 611731, Peoples R China.
EM ykwei@uestc.edu.cn
RI Kattupalli, Sudhakar/AAV-4318-2021
OI Kattupalli, Sudhakar/0000-0002-6360-7921; Liang,
   Haoyang/0000-0003-1017-6125; Yu, Shui/0000-0003-4485-6743; Chen,
   Yijin/0000-0002-4307-0346; Wei, Yunkai/0000-0002-4895-2073
FU National Key Research and Development Program of China [2018YFE0117500];
   EU H2020 Project COSAFE [MSCA-RISE-2018-824019]; Science and Technology
   Department of Sichuan Province [18ZDYF0329]; Ministry of Education of
   ChinaMinistry of Education, China [MCM 20160304]; China Mobile [MCM
   20160304]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2018YFE0117500, in part by the
   EU H2020 Project COSAFE under Grant MSCA-RISE-2018-824019, in part by
   the Science and Technology Department of Sichuan Province under Grant
   18ZDYF0329, and in part by the Joint Fund of the Ministry of Education
   of China and China Mobile under Grant MCM 20160304.
NR 31
TC 5
Z9 5
U1 1
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 7442
EP 7454
DI 10.1109/ACCESS.2019.2962525
PG 13
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA LC6ED
UT WOS:000525422700058
OA gold
DA 2022-04-17
ER

PT J
AU Kirchner, E
   Bienefeld, C
   Schirra, T
   Moltschanov, A
AF Kirchner, Eckhard
   Bienefeld, Christoph
   Schirra, Tobias
   Moltschanov, Alexander
TI Predicting the Electrical Impedance of Rolling Bearings Using Machine
   Learning Methods
SO MACHINES
LA English
DT Article
DE rolling bearings; impedance; force sensor; machine learning
AB The present paper describes a measurement setup and a related prediction of the electrical impedance of rolling bearings using machine learning algorithms. The impedance of the rolling bearing is expected to be key in determining the state of health of the bearing, which is an essential component in almost all machines. In previous publications, the determination of the impedance of rolling bearings has already been advanced using analytical methods. Despite the improvements in accuracy achieved within the calculations, there are still discrepancies between the calculated and the measured impedance, leading to an approximately constant off-set value. This discrepancy motivates the machine learning approach introduced in this paper. It is shown that with the help of the data-driven methods the difference between analytical prediction and measurement is reduced to the order of up to 2% across the operational range analyzed so far. To introduce the context of the research shown, first the underlying physics of bearing impedance is presented. Subsequently different machine learning approaches are highlighted and compared with each other in terms of their prediction quality in the results part of this paper. As a further aspect, in addition to the prediction of the bearing impedance, it is investigated whether the rotational speed present at the bearing can be predicted from the frequency spectrum of the impedance using order analysis methods which is independent from the force prediction accuracy. The background to this is that, if the prediction quality is sufficiently high, the additional use of speed sensors could be omitted in future investigations.
C1 [Kirchner, Eckhard; Bienefeld, Christoph; Schirra, Tobias; Moltschanov, Alexander] Tech Univ Darmstadt, Inst Product Dev & Machine Elements, Otto Berndt Str 2, D-64287 Darmstadt, Germany.
   [Bienefeld, Christoph] Robert Bosch GmbH, Corp Res, Robert Bosch Campus 1, D-71272 Renningen, Germany.
RP Kirchner, E (corresponding author), Tech Univ Darmstadt, Inst Product Dev & Machine Elements, Otto Berndt Str 2, D-64287 Darmstadt, Germany.
EM kirchner@pmd.tu-darmstadt.de; christoph.bienefeld@gast.tu-darmstadt.de;
   schirra@pmd.tu-darmstadt.de; a.moltschanov@outlook.com
OI Kirchner, Eckhard/0000-0002-7663-8073; Bienefeld,
   Christoph/0000-0002-7989-1293
FU Deutsche ForschungsgemeinschaftGerman Research Foundation (DFG)
   [401671541]; Deutsche Forschungsgemeinschaft (DFG-German Research
   Foundation)German Research Foundation (DFG); Open Access Publishing Fund
   of Technical University of Darmstadt
FX The adaptation and setup of the test bench was supported by Deutsche
   Forschungsgemeinschaft under project number 401671541. We acknowledge
   support by the Deutsche Forschungsgemeinschaft (DFG-German Research
   Foundation) and the Open Access Publishing Fund of Technical University
   of Darmstadt.
NR 22
TC 0
Z9 0
U1 2
U2 2
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2075-1702
J9 MACHINES
JI Machines
PD FEB
PY 2022
VL 10
IS 2
AR 156
DI 10.3390/machines10020156
PG 15
WC Engineering, Electrical & Electronic; Engineering, Mechanical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA ZN5MO
UT WOS:000765078500001
DA 2022-04-17
ER

PT J
AU Khdair, H
   Dasari, NM
AF Khdair, Hisham
   Dasari, Naga M.
TI Exploring Machine Learning Techniques for Coronary Heart Disease
   Prediction
SO INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS
LA English
DT Article
DE Coronary heart disease; machine learning; prediction; classification
ID CLASSIFICATION; DIAGNOSIS
AB Coronary Heart Disease (CHD) is one of the leading causes of death nowadays. Prediction of the disease at an early stage is crucial for many health care providers to protect their patients and save lives and costly hospitalization resources. The use of machine learning in the prediction of serious disease events using routine medical records has been successful in recent years. In this paper, a comparative analysis of different machine learning techniques that can accurately predict the occurrence of CHD events from clinical data was performed. Four machine learning classifiers, namely Logistic Regression, Support Vector Machine (SVM), K- Nearest Neighbor (KNN), and Multi-Layer Perceptron (MLP) Neural Networks were identified and applied to a dataset of 462 medical instances and 9 features as well as the class feature from the South African Heart Disease data retrieved from the KEEL repository. The dataset consists of 302 records of healthy patients and 160 records of patients who suffer from CHD. In order to handle the imbalanced classification problem, the K-means algorithm along with Synthetic Minority Oversampling TEchnique (SMOTE) was used in this study. The empirical results of applying the four machine learning classifiers on the oversampled dataset have been very promising. The results reported using different evaluation metrics showed that SVM has achieved the highest overall prediction performance.
C1 [Khdair, Hisham; Dasari, Naga M.] Federat Univ Associate, Int Inst Business & Informat Technol, Adelaide, SA, Australia.
RP Khdair, H (corresponding author), Federat Univ Associate, Int Inst Business & Informat Technol, Adelaide, SA, Australia.
RI Khdair, Hisham/C-8465-2016
OI Khdair, Hisham/0000-0001-9065-0573
NR 47
TC 0
Z9 0
U1 8
U2 10
PU SCIENCE & INFORMATION SAI ORGANIZATION LTD
PI WEST YORKSHIRE
PA 19 BOLLING RD, BRADFORD, WEST YORKSHIRE, 00000, ENGLAND
SN 2158-107X
EI 2156-5570
J9 INT J ADV COMPUT SC
JI Int. J. Adv. Comput. Sci. Appl.
PD MAY
PY 2021
VL 12
IS 5
BP 28
EP 36
PG 9
WC Computer Science, Theory & Methods
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA TC2GZ
UT WOS:000668461200006
DA 2022-04-17
ER

PT J
AU Oala, L
   Murchison, AG
   Balachandran, P
   Choudhary, S
   Fehr, J
   Leite, AW
   Goldschmidt, PG
   Johner, C
   Schorverth, EDM
   Nakasi, R
   Meyer, M
   Cabitza, F
   Baird, P
   Prabhu, C
   Weicken, E
   Liu, XX
   Wenzel, M
   Vogler, S
   Akogo, D
   Alsalamah, S
   Kazim, E
   Koshiyama, A
   Piechottka, S
   Macpherson, S
   Shadforth, I
   Geierhofer, R
   Matek, C
   Krois, J
   Sanguinetti, B
   Arentz, M
   Bielik, P
   Calderon-Ramirez, S
   Abbood, A
   Langer, N
   Haufe, S
   Kherif, F
   Pujari, S
   Samek, W
   Wiegand, T
AF Oala, Luis
   Murchison, Andrew G.
   Balachandran, Pradeep
   Choudhary, Shruti
   Fehr, Jana
   Leite, Alixandro Werneck
   Goldschmidt, Peter G.
   Johner, Christian
   Schorverth, Elora D. M.
   Nakasi, Rose
   Meyer, Martin
   Cabitza, Federico
   Baird, Pat
   Prabhu, Carolin
   Weicken, Eva
   Liu, Xiaoxuan
   Wenzel, Markus
   Vogler, Steffen
   Akogo, Darlington
   Alsalamah, Shada
   Kazim, Emre
   Koshiyama, Adriano
   Piechottka, Sven
   Macpherson, Sheena
   Shadforth, Ian
   Geierhofer, Regina
   Matek, Christian
   Krois, Joachim
   Sanguinetti, Bruno
   Arentz, Matthew
   Bielik, Pavol
   Calderon-Ramirez, Saul
   Abbood, Auss
   Langer, Nicolas
   Haufe, Stefan
   Kherif, Ferath
   Pujari, Sameer
   Samek, Wojciech
   Wiegand, Thomas
TI Machine Learning for Health: Algorithm Auditing & Quality Control
SO JOURNAL OF MEDICAL SYSTEMS
LA English
DT Article
DE Machine learning; Artificial intelligence; Algorithm; Health; Auditing;
   Quality control
ID ARTIFICIAL-INTELLIGENCE; DEEP
AB Developers proposing new machine learning for health (ML4H) tools often pledge to match or even surpass the performance of existing tools, yet the reality is usually more complicated. Reliable deployment of ML4H to the real world is challenging as examples from diabetic retinopathy or Covid-19 screening show. We envision an integrated framework of algorithm auditing and quality control that provides a path towards the effective and reliable application of ML systems in healthcare. In this editorial, we give a summary of ongoing work towards that vision and announce a call for participation to the special issue Machine Learning for Health: Algorithm Auditing & Quality Control in this journal to advance the practice of ML4H auditing.
C1 [Oala, Luis; Schorverth, Elora D. M.; Weicken, Eva; Wenzel, Markus; Samek, Wojciech; Wiegand, Thomas] Fraunhofer HHI, Berlin, Germany.
   [Murchison, Andrew G.] Oxford Univ Hosp NHS Fdn Trust, Oxford, England.
   [Balachandran, Pradeep] Tech Consultant Digital Hlth, Thiruvananthapuram, Kerala, India.
   [Choudhary, Shruti] Univ Oxford, Oxford, England.
   [Fehr, Jana] Hasso Plattner Inst Digital Engn, Potsdam, Germany.
   [Leite, Alixandro Werneck] Univ Brasilia, Machine Learning Lab Finance & Org, Brasilia, Brazil.
   [Goldschmidt, Peter G.] World Dev Grp Inc, Bethesda, MD USA.
   [Johner, Christian] Johner Inst, Constance, Germany.
   [Nakasi, Rose] Makerere Univ, Kampala, Uganda.
   [Meyer, Martin] Siemens Healthineers, Erlangen, Germany.
   [Cabitza, Federico] Univ Milano Bicocca, Milan, Italy.
   [Baird, Pat] Philips, New Kensington, PA USA.
   [Prabhu, Carolin] Off Auditor Gen Norway, Oslo, Norway.
   [Liu, Xiaoxuan] Univ Birmingham, Coll Med & Dent Sci, Inst Inflammat & Ageing, Univ Hosp Birmingham NHS Fdn Trust & Acad Unit Op, Birmingham, W Midlands, England.
   [Vogler, Steffen] Bayer AG, Berlin, Germany.
   [Akogo, Darlington] minoHlth AI Labs, Accra, Ghana.
   [Alsalamah, Shada] King Saud Univ, Coll Comp & Informat Sci, Informat Syst Dept, Riyadh, Saudi Arabia.
   [Alsalamah, Shada; Pujari, Sameer] World Hlth Org, Digital Hlth & Innovat Dept, Div Sci, Winterthur, Switzerland.
   [Kazim, Emre; Koshiyama, Adriano] UCL, London, England.
   [Piechottka, Sven] Open Regulatory, Bonn, Germany.
   [Macpherson, Sheena; Shadforth, Ian] MIOTIFY LTD, London, England.
   [Geierhofer, Regina] IEC TC62 & Siemens Healthineers, Erlangen, Germany.
   [Matek, Christian] Helmholtz Zentrum Munchen, Neuherberg, Germany.
   [Krois, Joachim] Charite, Oral Diagnost Digital Hlth Hlth Serv Res, Berlin, Germany.
   [Sanguinetti, Bruno] Dotphoton AG, Zug, Switzerland.
   [Arentz, Matthew] Univ Washington, Dept Global Hlth, Washington, DC USA.
   [Bielik, Pavol] LatticeFlow & ETH Zurich, Zurich, Switzerland.
   [Calderon-Ramirez, Saul] De Montfort Univ, Cartago, Costa Rica.
   [Calderon-Ramirez, Saul] Inst Tecnol Costa Rica, Cartago, Costa Rica.
   [Abbood, Auss] Robert Koch Inst, Berlin, Germany.
   [Langer, Nicolas] Univ Zurich, Dept Psychol, Zurich, Switzerland.
   [Haufe, Stefan] Tech Univ Berlin, Berlin, Germany.
   [Kherif, Ferath] Lausanne Univ Hosp, Lab Res Neuroimaging, Dept Clin Neurosci, Lausanne, Switzerland.
   [Kherif, Ferath] Univ Lausanne, Lausanne, Switzerland.
RP Oala, L (corresponding author), Fraunhofer HHI, Berlin, Germany.
EM luis.oala@hhi.fraunhofer.de; agmurchison@gmail.com; pbn.tvm@gmail.com;
   shruti.choudhary@kellogg.ox.ac.uk; jana.fehr@hpi.de;
   alixandrowerneck@outlook.com; pgg@worlddg.com;
   christian.johner@johner-institut.de;
   elora-dana.schoerverth@hhi.fraunhofer.de; g.nakasirose@gmail.com;
   martin.mm.meyer@siemens-healthineers.com; federico.cabitza@unimib.it;
   pat.baird@philips.com; cap@riksrevisjonen.no;
   eva.weicken@hhi.fraunhofer.de; x.liu.8@bham.ac.uk;
   markus.wenzel@hhi.fraunhofer.de; steffen.vogler@bayer.com;
   darlington@gudra-studio.com; alsalamahs@who.int; e.kazim@ucl.ac.uk;
   adriano.koshiyama.15@ucl.ac.uk; sven@openregulatory.com;
   sheena.macpherson@miotify.co.uk; ian.shadforth@miotify.co.uk;
   geierhofer@cocir.org; christian.matek@helmholtz-muenchen.de;
   joachim.krois@charite.de; bruno.sanguinetti@dotphoton.com;
   marentz@uw.edu; pavol.bielik@inf.ethz.ch; sacalderon@itcr.ac.cr;
   abbooda@rki.de; n.langer@psychologie.uzh; haufe@tu-berlin.de;
   ferath.kherif@chuv.ch; pujaris@who.int;
   wojciech.samek@hhi.fraunhofer.de; thomas.wiegand@hhi.fraunhofer.de
RI Fehr, Jana/E-2995-2019
OI Fehr, Jana/0000-0001-6183-2044; Oala, Luis/0000-0002-1379-8627
FU World Health OrganizationWorld Health Organization [001] Funding Source:
   Medline
NR 75
TC 1
Z9 1
U1 10
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0148-5598
EI 1573-689X
J9 J MED SYST
JI J. Med. Syst.
PD DEC
PY 2021
VL 45
IS 12
AR 105
DI 10.1007/s10916-021-01783-y
PG 8
WC Health Care Sciences & Services; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Health Care Sciences & Services; Medical Informatics
GA WQ7WW
UT WOS:000714023800001
PM 34729675
OA Green Published, hybrid, Green Accepted
DA 2022-04-17
ER

PT J
AU Chau, VH
AF Chau, Vinh Huy
TI Powerlifting score prediction using a machine learning method
SO MATHEMATICAL BIOSCIENCES AND ENGINEERING
LA English
DT Article
DE artificial intelligence; machine learning; powerlifting; score
   prediction
ID PERFORMANCE
AB This research discusses an interesting topic, using artificial intelligence methods to predict the score of powerlifters. We collected the characteristics of powerlifters, and then used the reservoir computing extreme learning machine to build a predictive model. In order to further improve the prediction results, we propose a method to optimize the reservoir computing extreme learning machine using the whale optimization algorithm. Experimental results show that our proposed method can effectively predict the score of powerlifters with the coefficient of determination value is 0.7958 and root-mean-square error of prediction value is 16.73. This provides a reliable basis for experts to judge the results before the competition.
C1 [Chau, Vinh Huy] Ho Chi Minh City Univ Phys Educ & Sport, Ho Chi Minh City 700000, Vietnam.
RP Chau, VH (corresponding author), Ho Chi Minh City Univ Phys Educ & Sport, Ho Chi Minh City 700000, Vietnam.
EM huyvcc@upes.edu.vn
FU Ministry of Education Fund Project of Vietnam [B-2021-STS-01]
FX This work is supported by Ministry of Education Fund Project of Vietnam
   (No. B-2021-STS-01).
NR 34
TC 0
Z9 0
U1 2
U2 6
PU AMER INST MATHEMATICAL SCIENCES-AIMS
PI SPRINGFIELD
PA PO BOX 2604, SPRINGFIELD, MO 65801-2604 USA
SN 1547-1063
EI 1551-0018
J9 MATH BIOSCI ENG
JI Math. Biosci. Eng.
PY 2021
VL 18
IS 2
BP 1040
EP 1050
DI 10.3934/mbe.2021056
PG 11
WC Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Mathematical & Computational Biology
GA PR8TV
UT WOS:000607506100006
PM 33757174
OA gold
DA 2022-04-17
ER

PT J
AU Kopper, A
   Karkare, R
   Paffenroth, RC
   Apelian, D
AF Kopper, Adam
   Karkare, Rasika
   Paffenroth, Randy C.
   Apelian, Diran
TI Model Selection and Evaluation for Machine Learning: Deep Learning in
   Materials Processing
SO INTEGRATING MATERIALS AND MANUFACTURING INNOVATION
LA English
DT Article
DE Machine learning; Deep learning; Random forest; Support vector machine;
   Neural network; High pressure die casting; Principal component analysis;
   Bias-variance trade-off
ID SI
AB Materials processing is a critical subset of manufacturing which is benefitting by implementing machine learning to create knowledge from the data mined/collected and gain a deeper understanding of manufacturing processes. In this study, we focus on aluminum high-pressure die-casting (HPDC) process, which constitutes over 60% of all cast Al components. Routinely collected process data over a year's time of serial production are used to make predictions on mechanical properties of castings, specifically, the ultimate tensile strength (UTS). Random Forest, Support Vector Machine (SVM), and XGBoost regression algorithms were selected from the machine learning spectrum along with a Neural Network, a deep learning method. These methods were evaluated and assessed and were compared to predictions based on historical data. Machine learning, including Neural Network, regression models do improve the predictability of UTS above that of predicting the mean from prior tests. Choosing the correct models to use for the data requires an understanding of the bias-variance trade-off such that a balance is struck between the complexity of the algorithms chosen and the size of the dataset in question. These concepts are reviewed and discussed in context of HPDC.
C1 [Kopper, Adam] Mercury Marine, Fond Du Lac, WI 54935 USA.
   [Karkare, Rasika] WPI, Data Sci, Worcester, MA 01609 USA.
   [Paffenroth, Randy C.] WPI, Data Sci, Comp Sci, Math Sci, Worcester, MA 01609 USA.
   [Apelian, Diran] UCI, Mat Sci & Engn, Irvine, CA 92967 USA.
RP Kopper, A (corresponding author), Mercury Marine, Fond Du Lac, WI 54935 USA.
EM adam.kopper@mercmarine.com
OI Paffenroth, Randy/0000-0002-4823-1348; Kopper, Adam/0000-0001-5236-3960
NR 55
TC 4
Z9 4
U1 6
U2 26
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 2193-9764
EI 2193-9772
J9 INTEGR MATER MANUF I
JI Integr. Mater. Manuf. Innov.
PD SEP
PY 2020
VL 9
IS 3
BP 287
EP 300
DI 10.1007/s40192-020-00185-1
EA SEP 2020
PG 14
WC Engineering, Manufacturing; Materials Science, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Materials Science
GA NQ3IV
UT WOS:000570117500002
DA 2022-04-17
ER

PT J
AU Abu-Alhaija, M
   Turab, NM
AF Abu-Alhaija, Mwaffaq
   Turab, Nidal M.
TI Automated Learning of ECG Streaming Data Through Machine Learning
   Internet of Things
SO INTELLIGENT AUTOMATION AND SOFT COMPUTING
LA English
DT Article
DE Machine learning; heartbeat anomalies; K-means clustering algorithm;
   T-Digest algorithm
ID BIG DATA
AB Applying machine learning techniques on Internet of Things (IoT) data streams will help achieve better understanding, predict future perceptions, and make crucial decisions based on those analytics. The collaboration between IoT, Big Data and machine learning can be found in different domains such as Health care, Smart cities, and Telecommunications. The aim of this paper is to develop a method for automated learning of electrocardiogram (ECG) streaming data to detect any heart beat anomalies. A promising solution is to use medical sensors that transfer vital signs to medical care computer systems, combined with machine learning, such that clinicians can get alerted about patient's critical condition and act accordingly. Since the probability of false alarms pose serious impact to the accuracy of cardiac arrhythmia detection, it is the most important factor to keep false alarms to the lowest level. The proposed method in this paper demonstrates an example of how machine learning can contribute to health technologies with in detecting heart disease through minimizing negative false alarms. Stages of heartbeat learning model are proposed and explained besides the stages heartbeat anomalies detection stages.
C1 [Abu-Alhaija, Mwaffaq; Turab, Nidal M.] Al Ahliyya Amman Univ, Fac Informat Technol, Dept Networks & Informat Secur, Amman 19328, Jordan.
RP Turab, NM (corresponding author), Al Ahliyya Amman Univ, Fac Informat Technol, Dept Networks & Informat Secur, Amman 19328, Jordan.
EM N.turab@ammanu.edu.jo
NR 26
TC 0
Z9 0
U1 6
U2 6
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1079-8587
EI 2326-005X
J9 INTELL AUTOM SOFT CO
JI Intell. Autom. Soft Comput.
PY 2022
VL 32
IS 1
BP 45
EP 53
DI 10.32604/iasc.2022.021426
PG 9
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA WN7WG
UT WOS:000711977500004
OA hybrid
DA 2022-04-17
ER

PT C
AU Lazcano-Herrera, AG
   Fuentes-Aguilar, RQ
   Alfaro-Ponce, M
AF Guadalupe Lazcano-Herrera, Alicia
   Fuentes-Aguilar, Rita Q.
   Alfaro-Ponce, Mariel
GP IEEE
TI EEG motor/imagery signal classification comparative using machine
   learning algorithms
SO 2021 18TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING, COMPUTING
   SCIENCE AND AUTOMATIC CONTROL (CCE 2021)
LA English
DT Proceedings Paper
CT 18th International Conference on Electrical Engineering, Computing
   Science and Automatic Control (CCE)
CY NOV 10-12, 2021
CL ELECTR NETWORK
SP IEEE Electron Devices Soc, Cinvestav
DE Classification; EEG; Machine Learning
AB Electroencephalography (EEG) study allows the recording of brain activity associated with different mental tasks through electrodes placed on the scalp that amplifies the electricity changes at neurons activity. Because of the nature of EEG signals, their interpretation and classification require an expert. Recently, machine learning algorithms for EEG analysis have gained popularity and are applied in various activities such as brain-computer interfaces (BCI), diagnostic of brain disorders, etc. In this work, an EEG classification was performed with different machine learning algorithms. For this, Support Vector machines (SVM), K-nearest neighbor (KNN), Quadratic Discriminant Analysis (QDA), Linear Discriminant Analysis (LDA), Naive Bayes (NB) and Ensemble were implemented and the performance of different algorithms when distinguishing between two classes: one of movement and one of inactivity. The movement class was composed of Motor Imagery(MI) data and actual movement and inactivity class of a baseline. From the proposed techniques for EEG classification, the QDA and NB achieve the highest accuracy.
C1 [Guadalupe Lazcano-Herrera, Alicia; Fuentes-Aguilar, Rita Q.; Alfaro-Ponce, Mariel] Tecnol Monterrey, Sch Engn & Sci, Mexico City, DF, Mexico.
RP Lazcano-Herrera, AG (corresponding author), Tecnol Monterrey, Sch Engn & Sci, Mexico City, DF, Mexico.
EM alicia_gpe_hg@hotmail.com; rita.fuentes@tec.mx; marielalfa@gmail.com
NR 22
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-6654-0029-9
PY 2021
DI 10.1109/CCE53527.2021.9633055
PG 6
WC Computer Science, Cybernetics; Computer Science, Theory & Methods;
   Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BS7NY
UT WOS:000765325700031
DA 2022-04-17
ER

PT J
AU Shahriar, S
   Al-Ali, AR
   Osman, AH
   Dhou, S
   Nijim, M
AF Shahriar, Sakib
   Al-Ali, A. R.
   Osman, Ahmed H.
   Dhou, Salam
   Nijim, Mais
TI Prediction of EV Charging Behavior Using Machine Learning
SO IEEE ACCESS
LA English
DT Article
DE Energy consumption; Support vector machines; Machine learning; Radio
   frequency; Prediction algorithms; Machine learning algorithms;
   Predictive models; Electric vehicles (EVs); charging behavior; machine
   learning; smart city; smart transportation
ID SYSTEM
AB As a key pillar of smart transportation in smart city applications, electric vehicles (EVs) are becoming increasingly popular for their contribution in reducing greenhouse gas emissions. One of the key challenges, however, is the strain on power grid infrastructure that comes with large-scale EV deployment. The solution to this lies in utilization of smart scheduling algorithms to manage the growing public charging demand. Using data-driven tools and machine learning algorithms to learn the EV charging behavior can improve scheduling algorithms. Researchers have focused on using historical charging data for predictions of behavior such as departure time and energy needs. However, variables such as weather, traffic, and nearby events, which have been neglected to a large extent, can perhaps add meaningful representations, and provide better predictions. Therefore, in this paper we propose the usage of historical charging data in conjunction with weather, traffic, and events data to predict EV session duration and energy consumption using popular machine learning algorithms including random forest, SVM, XGBoost and deep neural networks. The best predictive performance is achieved by an ensemble learning model, with SMAPE scores of 9.9% and 11.6% for session duration and energy consumptions, respectively, which improves upon the existing works in the literature. In both predictions, we demonstrate a significant improvement compared to previous work on the same dataset and we highlight the importance of traffic and weather information for charging behavior predictions.
C1 [Shahriar, Sakib; Al-Ali, A. R.; Dhou, Salam] Amer Univ Sharjah, Comp Sci & Engn Dept, Sharjah, U Arab Emirates.
   [Osman, Ahmed H.] Amer Univ Sharjah, Elect Engn Dept, Sharjah, U Arab Emirates.
   [Nijim, Mais] Texas A&M Univ Kingsville, Elect Engn & Comp Sci Dept, Kingsville, TX 78363 USA.
RP Al-Ali, AR (corresponding author), Amer Univ Sharjah, Comp Sci & Engn Dept, Sharjah, U Arab Emirates.
EM aali@aus.edu
RI Dhou, Salam/AAG-6516-2019; Shahriar, Sakib/AAD-4542-2021
OI Dhou, Salam/0000-0002-8143-6417; Shahriar, Sakib/0000-0002-5778-4876;
   Osman, Ahmed/0000-0001-9302-8608
FU Computer Science and Engineering Department; American University of
   Sharjah, United Arab Emirates
FX This work was supported by the Computer Science and Engineering
   Department and the Open Access Program from the American University of
   Sharjah, United Arab Emirates.
NR 58
TC 0
Z9 0
U1 9
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 111576
EP 111586
DI 10.1109/ACCESS.2021.3103119
PG 11
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA TZ7TC
UT WOS:000684673900001
OA gold
DA 2022-04-17
ER

PT C
AU Jiang, JW
   Gan, SD
   Liu, Y
   Wang, FL
   Alonso, G
   Klimovic, A
   Singla, A
   Wu, WT
   Zhang, C
AF Jiang, Jiawei
   Gan, Shaoduo
   Liu, Yue
   Wang, Fanlin
   Alonso, Gustavo
   Klimovic, Ana
   Singla, Ankit
   Wu, Wentao
   Zhang, Ce
GP ASSOC COMP MACHINERY
TI Towards Demystifying Serverless Machine Learning Training
SO SIGMOD '21: PROCEEDINGS OF THE 2021 INTERNATIONAL CONFERENCE ON
   MANAGEMENT OF DATA
SE International Conference on Management of Data
LA English
DT Proceedings Paper
CT ACM SIGMOD International Conference on Management of Data (SIGMOD)
CY JUN 20-25, 2021
CL ELECTR NETWORK
SP ACM SIGMOD, Assoc Comp Machinery
DE Serverless Computing; Machine Learning
ID DATABASE
AB The appeal of serverless (FaaS) has triggered a growing interest on how to use it in data-intensive applications such as ETL, query processing, or machine learning (ML). Several systems exist for training large-scale ML models on top of serverless infrastructures (e.g., AWS Lambda) but with inconclusive results in terms of their performance and relative advantage over "serverful" infrastructures (IaaS). In this paper we present a systematic, comparative study of distributed ML training over FaaS and IaaS. We present a design space covering design choices such as optimization algorithms and synchronization protocols, and implement a platform, LambdaML, that enables a fair comparison between FaaS and IaaS. We present experimental results using LambdaML, and further develop an analytic model to capture cost/performance tradeoffs that must be considered when opting for a serverless infrastructure. Our results indicate that ML training pays off in serverless only for models with efficient (i.e., reduced) communication and that quickly converge. In general, FaaS can be much faster but it is never significantly cheaper than IaaS.
C1 [Jiang, Jiawei; Gan, Shaoduo; Liu, Yue; Wang, Fanlin; Alonso, Gustavo; Klimovic, Ana; Singla, Ankit; Zhang, Ce] Swiss Fed Inst Technol, Syst Grp, Zurich, Switzerland.
   [Wu, Wentao] Microsoft Res, Redmond, WA USA.
RP Jiang, JW (corresponding author), Swiss Fed Inst Technol, Syst Grp, Zurich, Switzerland.
EM jiawei.jiang@inf.ethz.ch; sgan@inf.ethz.ch; liuyue@student.ethz.ch;
   fanwang@student.ethz.ch; alonso@inf.ethz.ch; ana.klimovic@inf.ethz.ch;
   ankit.singla@inf.ethz.ch; wentao.wu@microsoft.com; ce.zhang@inf.ethz.ch
FU Swiss National Science FoundationSwiss National Science Foundation
   (SNSF)European Commission [200021_184628]; Innosuisse/SNF BRIDGE
   Discovery [40B2-0_187132]; European UnionEuropean Commission [957407];
   Botnar Research Centre for Child Health; Swiss Data Science Center;
   Alibaba; Cisco; eBay; Google Focused Research AwardsGoogle Incorporated;
   Oracle Labs; Swisscom; Zurich Insurance; Chinese Scholarship
   CouncilChina Scholarship Council; Department of Computer Science at ETH
   Zurich
FX CZ and the DS3Lab gratefully acknowledge the support from the Swiss
   National Science Foundation (Project Number 200021_184628),
   Innosuisse/SNF BRIDGE Discovery (Project Number 40B2-0_187132), European
   Union Horizon 2020 Research and Innovation Programme (DAPHNE, 957407),
   Botnar Research Centre for Child Health, Swiss Data Science Center,
   Alibaba, Cisco, eBay, Google Focused Research Awards, Oracle Labs,
   Swisscom, Zurich Insurance, Chinese Scholarship Council, and the
   Department of Computer Science at ETH Zurich.
NR 92
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
SN 0730-8078
BN 978-1-4503-8343-1
J9 INT CONF MANAGE DATA
PY 2021
BP 857
EP 871
DI 10.1145/3448016.3459240
PG 15
WC Computer Science, Information Systems
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS6FP
UT WOS:000747673800071
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Chen, CB
   Ren, CL
   Lin, HQ
   Lu, H
AF Chen, Changbo
   Ren, Changliang
   Lin, Hongqing
   Lu, He
TI Entanglement structure detection via machine learning
SO QUANTUM SCIENCE AND TECHNOLOGY
LA English
DT Article
DE entanglement structure; machine learning; multipartite entanglement;
   correct predictions
AB Detecting the entanglement structure, such as intactness and depth, of an n-qubit state is important for understanding the imperfectness of the state preparation in experiments. However, identifying such structure usually requires an exponential number of local measurements. In this letter, we propose an efficient machine learning based approach for predicting the entanglement intactness and depth simultaneously. The generalization ability of this classifier has been convincingly proved, as it can precisely distinguish the whole range of pure generalized Greenberger-Horne-Zeilinger (GHZ) states which never exist in the training process. In particular, the learned classifier can discover the entanglement intactness and depth bounds for the noised GHZ state, for which the exact bounds are only partially known.
C1 [Chen, Changbo] Chinese Acad Sci, Chongqing Inst Green & Intelligent Technol, Chongqing Key Lab Automated Reasoning & Cognit, Chongqing 400714, Peoples R China.
   [Ren, Changliang] Hunan Normal Univ, Key Lab Low Dimens Quantum Struct & Quantum Contr, Key Lab Matter Microstruct & Funct Hunan Prov, Dept Phys,Minist Educ, Changsha 410081, Peoples R China.
   [Ren, Changliang] Hunan Normal Univ, Synerget Innovat Ctr Quantum Effects & Applicat, Changsha 410081, Peoples R China.
   [Ren, Changliang; Lin, Hongqing] Chinese Acad Sci, Ctr Nanofabricat & Syst Integrat, Chongqing Inst Green & Intelligent Technol, Beijing, Peoples R China.
   [Lu, He] Shandong Univ, Sch Phys, Jinan 250100, Peoples R China.
RP Ren, CL (corresponding author), Hunan Normal Univ, Key Lab Low Dimens Quantum Struct & Quantum Contr, Key Lab Matter Microstruct & Funct Hunan Prov, Dept Phys,Minist Educ, Changsha 410081, Peoples R China.; Ren, CL (corresponding author), Hunan Normal Univ, Synerget Innovat Ctr Quantum Effects & Applicat, Changsha 410081, Peoples R China.; Ren, CL (corresponding author), Chinese Acad Sci, Ctr Nanofabricat & Syst Integrat, Chongqing Inst Green & Intelligent Technol, Beijing, Peoples R China.
EM renchangliang@hunnu.edu.cn
OI changliang, ren/0000-0003-0584-7430; Lu, He/0000-0001-6501-5447; Chen,
   Changbo/0000-0002-7412-7667
FU NSFCNational Natural Science Foundation of China (NSFC) [11771421,
   12075245]; National Key Research and Development Program
   [2017YFA0305200, 2020YFA0712300]; CAS "Light of West China" Program; CAS
   Chongqing Programs [cstc2018jcyj-yszxX0002, cstc2019yszx-jcyjX0003,
   cstc2020yszx-jcyjX0005]
FX This work was supported by NSFC (Nos. 11771421 and 12075245), National
   Key Research and Development Program (Nos. 2017YFA0305200 and
   2020YFA0712300). CC also acknowledges CAS "Light of West China" Program,
   and Chongqing Programs (Nos. cstc2018jcyj-yszxX0002,
   cstc2019yszx-jcyjX0003, and cstc2020yszx-jcyjX0005). CR also
   acknowledges the Natural Science Fund of Hunan Province and Xiaoxiang
   Scholars Program of Hunan Normal University.
NR 30
TC 0
Z9 0
U1 6
U2 7
PU IOP PUBLISHING LTD
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 2058-9565
J9 QUANTUM SCI TECHNOL
JI Quantum Sci. Technol.
PD JUL
PY 2021
VL 6
IS 3
AR 035017
DI 10.1088/2058-9565/ac0a3e
PG 8
WC Quantum Science & Technology; Physics, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Physics
GA TZ8FE
UT WOS:000684705300001
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Yang, Y
   Huang, M
   Wang, ZY
   Zhu, QB
AF Yang, Yu
   Huang, Min
   Wang, Zhen Yu
   Zhu, Qi Bing
TI Robust scheduling based on extreme learning machine for bi-objective
   flexible job-shop problems with machine breakdowns
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Flexible job-shop problem; Machine breakdowns; Surrogate measure;
   Extreme learning machine
ID OPTIMIZATION APPROACH; GENETIC ALGORITHM; SINGLE-MACHINE; FACE
AB In modern manufacturing systems, a flexible job-shop schedule problem (FJSP) with random machine breakdown has been widely studied. Two objectives, namely makespan and robustness, were simultaneously considered in this study. Maximizing the workload and float time of each operation and the machine breakdowns, one surrogate measure named RMc was developed via an extreme learning machine (ELM) to evaluate robustness. Specifically, this measure determines the impact of float time on the robustness by the probability of machine breakdown and the location of float time. Simultaneously, the impact was automatically adjusted by the ELM. Then, a method combining an improved version of nondominated sorting genetic algorithm II and RMc was proposed to address the bi-objective FJSP. Computational results on the benchmarks show that RMc accurately evaluates the robustness of the schedules with a small amount of computation cost. (C) 2020 Elsevier Ltd. All rights reserved.
C1 [Yang, Yu; Huang, Min; Zhu, Qi Bing] Jiangnan Univ, Minist Educ, Key Lab Adv Proc Control Light Ind, Wuxi 214122, Jiangsu, Peoples R China.
   [Wang, Zhen Yu] Zhejiang Univ, Coll Elect Engn, Hangzhou 310058, Peoples R China.
RP Zhu, QB (corresponding author), Jiangnan Univ, Minist Educ, Key Lab Adv Proc Control Light Ind, Wuxi 214122, Jiangsu, Peoples R China.
EM yangxiangyu1168@163.com; huangmzqb@163.com; iotwzy@163.com;
   zhuqib@163.com
RI Huang, Min/AAH-8509-2021
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61772240, 61775086]; 111 ProjectMinistry of
   Education, China - 111 Project [B12018]
FX Dr. Qibing Zhu, and Dr. Min Huang gratefully acknowledge the financial
   support from the National Natural Science Foundation of China (Grant no.
   61772240, 61775086), the 111 Project (B12018).
NR 46
TC 9
Z9 10
U1 14
U2 68
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD NOV 15
PY 2020
VL 158
AR 113545
DI 10.1016/j.eswa.2020.113545
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA NP0HZ
UT WOS:000569866100002
DA 2022-04-17
ER

PT J
AU Brengman, CMJ
   Barnhart, WD
AF Brengman, Clayton M. J.
   Barnhart, William D.
TI Identification of Surface Deformation in InSAR Using Machine Learning
SO GEOCHEMISTRY GEOPHYSICS GEOSYSTEMS
LA English
DT Article
DE convolutional neural networks; InSAR; machine learning; operational
   analysis; surface deformation; transfer learning
ID CONVOLUTIONAL NEURAL-NETWORK; REMOTE-SENSING DATA; CLASSIFICATION
AB The availability and frequency of synthetic aperture radar (SAR) imagery are rapidly increasing. This surge of data presents new opportunities to constrain surface deformation that spans various spatial and temporal scales. This expansion also introduces common challenges associated with large volumes of data, including best practices for analyzing these data. In recent years, machine learning techniques have been at the forefront of big data challenges, as an efficient methodology for automatically classifying large volumes of data. Convolutional Neural Networks (CNNs), in particular, have achieved strong levels of performance on image classification problems. Here we present SarNet, a CNN developed to detect, locate, and classify the presence of co-seismic-like surface deformation within an interferogram. We trained SarNet using 4 x 10(6) synthetic interferograms, including both wrapped and unwrapped forward modeled co-seismic-like surface deformation with synthetic noise representative of the atmospheric and topographic noise found in interferograms. The results show that SarNet obtains an overall accuracy of 99.74% on a validation data set. We use class activation maps (CAMs) to show that SarNet returns the location of surface deformation within the interferogram. We employ a transfer learning method to translate the accuracy of SarNet trained on synthetic data to real interferograms with manually classified co-seismic surface displacement. We train SarNet on 32 interferograms containing labeled co-seismic surface deformation as well as noise. The results show that, through transfer learning, SarNet obtains an overall accuracy of 85.22% on a real InSAR data set, and that SarNet returns the location of the surface deformation within the interferogram.
C1 [Brengman, Clayton M. J.; Barnhart, William D.] Univ Iowa, Dept Earth & Environm Sci, Iowa City, IA 52242 USA.
   [Barnhart, William D.] US Geol Survey, Earthquake Hazards Program Off, Golden, CO USA.
RP Brengman, CMJ (corresponding author), Univ Iowa, Dept Earth & Environm Sci, Iowa City, IA 52242 USA.
EM clayton-brengman@uiowa.edu
OI Brengman, Clayton/0000-0001-8189-0284
FU National Aeronautics and Space Administration (NASA) Earth and Space
   Science Fellowship [18-EARTH18F-0046]
FX This work was supported by National Aeronautics and Space Administration
   (NASA) Earth and Space Science Fellowship 18-EARTH18F-0046. Machine
   Learning work was done in the PyTorch environment (Paszke et al., 2019).
NR 46
TC 4
Z9 4
U1 10
U2 15
PU AMER GEOPHYSICAL UNION
PI WASHINGTON
PA 2000 FLORIDA AVE NW, WASHINGTON, DC 20009 USA
EI 1525-2027
J9 GEOCHEM GEOPHY GEOSY
JI Geochem. Geophys. Geosyst.
PD MAR
PY 2021
VL 22
IS 3
AR e2020GC009204
DI 10.1029/2020GC009204
PG 15
WC Geochemistry & Geophysics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Geochemistry & Geophysics
GA RH6XZ
UT WOS:000636360200018
OA Bronze
DA 2022-04-17
ER

PT C
AU Toivonen, T
   Jormanainen, I
   Kahila, J
   Tedre, M
   Valtonen, T
   Vartiainen, H
AF Toivonen, Tapani
   Jormanainen, Ilkka
   Kahila, Juho
   Tedre, Matti
   Valtonen, Teemu
   Vartiainen, Henriikka
BE Chang, M
   Sampson, DG
   Huang, R
   Hooshyar, D
   Chen, NS
   Kinshuk
   Pedaste, M
TI Co-Designing Machine Learning Apps in K-12 With Primary School Children
SO 2020 IEEE 20TH INTERNATIONAL CONFERENCE ON ADVANCED LEARNING
   TECHNOLOGIES (ICALT 2020)
SE IEEE International Conference on Advanced Learning Technologies
LA English
DT Proceedings Paper
CT 20th IEEE International Conference on Advanced Learning Technologies
   (ICALT)
CY JUL 06-09, 2020
CL ELECTR NETWORK
SP IEEE, Univ Tartu, Inst Educ, IEEE Comp Soc, IEEE Tech Comm Learning Technol
DE Machine Learning; K-12; Co-Design; Artificial Intelligence; Primary
   School; Neural Network; Computational Thinking
ID ARTIFICIAL-INTELLIGENCE; COMPUTER
AB Artificial intelligence and machine learning are making their ways rapidly to K-12 education. Google Teachable Machine, powered by convolutional neural networks, provides an easy-to-use yet powerful tool for classification tasks. We conducted a series of co-design workshops with primary school children, where they explored and designed their own machine learning powered applications with Google Teachable Machine. Our results show that Google Teachable Machine is a feasible tool for K-12 education. The trained machine learning models are lightweight and computationally efficient, and the applications are usable even with low-end mobile devices. The students and teachers appreciated the multidisciplinary and inclusive workshop, which supports development of transversal competencies in accordance to the national primary school curriculum.
C1 [Toivonen, Tapani; Jormanainen, Ilkka; Tedre, Matti] Univ Eastern Finland, Sch Comp, Joensuu, Finland.
   [Kahila, Juho; Valtonen, Teemu; Vartiainen, Henriikka] Univ Eastern Finland, Sch Appl Educ Sci & Teacher Educ, Joensuu, Finland.
RP Toivonen, T (corresponding author), Univ Eastern Finland, Sch Comp, Joensuu, Finland.
EM tapani.toivonen@uef.fi; ilkka.jormanainen@uef.fi; juho.kahila@uef.fi;
   matti.tedre@uef.fi; teemu.valtonen@uef.fi; henriikka.vartiainen@uef.fi
OI Kahila, Juho/0000-0002-9913-0627
NR 18
TC 9
Z9 9
U1 9
U2 13
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2161-3761
BN 978-1-7281-6090-0
J9 IEEE INT CONF ADV LE
PY 2020
BP 308
EP 310
DI 10.1109/ICALT49669.2020.00099
PG 3
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Education & Educational Research
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Education & Educational Research
GA BQ8JQ
UT WOS:000620344900092
DA 2022-04-17
ER

PT C
AU Zytek, A
   Liu, DY
   Vaithianathan, R
   Veeramachaneni, K
AF Zytek, Alexandra
   Liu, Dongyu
   Vaithianathan, Rhema
   Veeramachaneni, Kalyan
GP ACM
TI Sibyl: Explaining Machine Learning Models for High-Stakes Decision
   Making
SO EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN
   COMPUTING SYSTEMS (CHI'21)
LA English
DT Proceedings Paper
CT CHI Conference on Human Factors in Computing Systems
CY MAY 08-13, 2021
CL ELECTR NETWORK
SP ACM SIGCHI, Assoc Comp Machinery, Bloomberg, Facebook, Google, Kyocera, Microsoft, Monash Univ, Verizon Media
DE machine learning; interpretability; explainability; child welfare;
   social good; tool
AB As machine learning is applied to an increasingly large number of domains, the need for an effective way to explain its predictions grows apace. In the domain of child welfare screening, machine learning offers a promising method of consolidating the large amount of data that screeners must look at, potentially improving the outcomes for children reported to child welfare departments. Interviews and case-studies suggest that adding an explanation alongside the model prediction may result in better outcomes, but it is not obvious what kind of explanation would be most useful in this context. Through a series of interviews and user studies, we developed Sibyl, a machine learning explanation dashboard specifically designed to aid child welfare screeners' decision making. When testing Sibyl, we evaluated four different explanation types, and based on this evaluation, decided a local feature contribution approach was most useful to screeners.
C1 [Zytek, Alexandra; Liu, Dongyu; Veeramachaneni, Kalyan] MIT, Cambridge, MA 02139 USA.
   [Vaithianathan, Rhema] Auckland Univ Technol, Auckland, New Zealand.
RP Zytek, A (corresponding author), MIT, Cambridge, MA 02139 USA.
EM zyteka@mit.edu; dongyu@mit.edu; rhema.vaithianathan@aut.ac.nz;
   kalyan@csail.mit.edu
FU National Science FoundationNational Science Foundation (NSF) [1761812]
FX We would like to thank Diana Benavides Prado, Megh Mayur, Athena Ning,
   and Larissa Lorimer for their guidance throughout the process of
   applying machine learning explainability to child welfare, for
   connecting us to the child welfare domain experts, and for providing us
   with their trained model and dataset. We thank the child welfare experts
   at Larimer County Department of Human Services for their invaluable
   insights and feedback on the tool. We thank Iulia Ionescu, Sergiu Ojoc,
   Ionut Radu, and Ionut Margarint for their work on developing the Sibyl
   application. We thank Arash Akhgari for his work on our diagrams and
   visualizations. We thank Michaela Henry for support in project
   management and insights. We thank the participants of the user studies
   for their time and feedback. We would like to thank our anonymous
   reviewers for their comments and suggestions. This work was supported in
   part by National Science Foundation grant #1761812 -Spokes: MEDIUM:
   NORTHEAST: Collaborative Research: Data Science Foundry: A Collaborative
   Platform for Computational Social Science.
NR 14
TC 0
Z9 0
U1 1
U2 1
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES
BN 978-1-4503-8095-9
PY 2021
DI 10.1145/3411763.3451743
PG 6
WC Computer Science, Cybernetics; Computer Science, Interdisciplinary
   Applications; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS7DM
UT WOS:000759178502053
OA Bronze
DA 2022-04-17
ER

PT J
AU Luo, Y
   Chen, SF
   Valdes, G
AF Luo, Yi
   Chen, Shifeng
   Valdes, Gilmer
TI Machine learning for radiation outcome modeling and prediction
SO MEDICAL PHYSICS
LA English
DT Article
DE accuracy; interpretability; machine learning; radiation outcome
   modeling; structured and unstructured datasets
ID TISSUE COMPLICATION PROBABILITY; CELL LUNG-CANCER; NEURAL-NETWORK;
   DOSE-VOLUME; THERAPY; PNEUMONITIS; DIAGNOSIS; SUPPORT; HEAD; LIFE
AB Aims This review paper intends to summarize the application of machine learning to radiotherapy outcome modeling based on structured and un-structured radiation oncology datasets.
   Materials and methods The most appropriate machine learning approaches for structured datasets in terms of accuracy and interpretability are identified. For un-structured datasets, deep learning algorithms are explored and a critical view of the use of these approaches in radiation oncology is also provided.
   Conclusions We discuss the challenges in radiotherapy outcome prediction, and suggest to improve radiation outcome modeling by developing appropriate machine learning approaches where both accuracy and interpretability are taken into account.
C1 [Luo, Yi] Univ Michigan, Dept Radiat Oncol, Ann Arbor, MI 48103 USA.
   [Chen, Shifeng] Univ Maryland, Dept Radiat Oncol, Sch Med, Baltimore, MD 21201 USA.
   [Valdes, Gilmer] Univ Calif San Francisco, Dept Radiat Oncol, San Francisco, CA 94158 USA.
RP Luo, Y (corresponding author), Univ Michigan, Dept Radiat Oncol, Ann Arbor, MI 48103 USA.
EM yiyiLuo@med.umich.edu
NR 97
TC 8
Z9 8
U1 7
U2 15
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0094-2405
EI 2473-4209
J9 MED PHYS
JI Med. Phys.
PD JUN
PY 2020
VL 47
IS 5
BP E178
EP E184
DI 10.1002/mp.13570
PG 7
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA PB0JZ
UT WOS:000596015500006
PM 32418338
OA Green Published
DA 2022-04-17
ER

PT J
AU Suzuki, T
   Katouda, M
AF Suzuki, Teppei
   Katouda, Michio
TI Predicting toxicity by quantum machine learning
SO JOURNAL OF PHYSICS COMMUNICATIONS
LA English
DT Article
DE quantum computer; quantum machine learning; parameterized quantum
   circuits; QSAR; drug discovery
ID NEURAL-NETWORKS; VALIDATION; DESIGN
AB In recent years, parameterized quantum circuits have been regarded as machine learning models within the framework of the hybrid quantum-classical approach. Quantum machine learning (QML) has been applied to binary classification problems and unsupervised learning. However, practical quantum application to nonlinear regression tasks has received considerably less attention. Here, we develop QML models designed for predicting the toxicity of 221 phenols on the basis of quantitative structure activity relationship. The results suggest that our data encoding enhanced by quantum entanglement provided more expressive power than the previous ones, implying that quantum correlation could be beneficial for the feature map representation of classical data. Our QML models performed significantly better than the multiple linear regression method. Furthermore, our simulations indicate that the QML models were comparable to those obtained using radial basis function networks, while improving the generalization performance. The present study implies that QML could be an alternative approach for nonlinear regression tasks such as cheminformatics.
C1 [Suzuki, Teppei] TerraSky Co Ltd, Chuo Ku, Taiyo Life Nihombashi Bldg 15-17F, Tokyo 1030027, Japan.
   [Suzuki, Teppei] Quemix Inc, Chuo Ku, Taiyo Life Nihombashi Bldg 16F,2-11-2 Nihombashi, Tokyo 1030027, Japan.
   [Katouda, Michio] Res Org Informat Sci & Technol, Minato Ku, Sumitomo Hamamatsucho Bldg 7F, Tokyo 1050013, Japan.
RP Suzuki, T (corresponding author), TerraSky Co Ltd, Chuo Ku, Taiyo Life Nihombashi Bldg 15-17F, Tokyo 1030027, Japan.; Suzuki, T (corresponding author), Quemix Inc, Chuo Ku, Taiyo Life Nihombashi Bldg 16F,2-11-2 Nihombashi, Tokyo 1030027, Japan.
EM tsuzuki@quemix.com
RI Katouda, Michio/E-2334-2011
OI Katouda, Michio/0000-0001-7980-5386; Suzuki, Teppei/0000-0001-7054-5493
NR 62
TC 1
Z9 1
U1 1
U2 3
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 2399-6528
J9 J PHYS COMMUN
JI J. Phys. Commun.
PD DEC
PY 2020
VL 4
IS 12
AR 125012
DI 10.1088/2399-6528/abd3d8
PG 15
WC Physics, Multidisciplinary
WE Emerging Sources Citation Index (ESCI)
SC Physics
GA PO3OY
UT WOS:000605079500001
OA gold, Green Submitted
DA 2022-04-17
ER

PT C
AU Mirza, NM
AF Mirza, Nada Masood
GP IEEE
TI Machine Learning and Soft Robotics
SO 2020 21ST INTERNATIONAL ARAB CONFERENCE ON INFORMATION TECHNOLOGY (ACIT)
SE International Arab Conference on Information Technology ACIT
LA English
DT Proceedings Paper
CT 21st International Arab Conference on Information Technology (ACIT)
CY NOV 28-30, 2020
CL EGYPT
SP MISR Univ Sci & Technol, ACIT Int, IEEE
DE machine learning; soft robotics; bio robotics; soft grippers
ID DESIGN
AB In recent times, robotics and especially soft robotics has attracted a wide range of researchers and scientists. As oft robotics has an extensive number of advantages in the real environment, due to their less complex system and cost. Soft grippers are more adaptive as compared to the rigid robotic grippers. The grasping performance of soft robots can be improved without bringing major changes in the control inputs. Machine learning has played a vital role in improving the controls and increasing the number of applications of these kinds of robots in the real world. In this paper relevant research in modeling, design, intelligent control, sensing, and practical applications of soft robots has been discussed.
C1 [Mirza, Nada Masood] Al Ain Univ, Coll Engn, Al Ain, U Arab Emirates.
RP Mirza, NM (corresponding author), Al Ain Univ, Coll Engn, Al Ain, U Arab Emirates.
EM nada.mirza@aau.ac.ae
NR 34
TC 0
Z9 0
U1 4
U2 4
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1812-0857
EI 2075-2245
BN 978-1-7281-8855-3
J9 INT ARAB CONF INF TE
PY 2020
PG 5
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BS0HU
UT WOS:000682789800058
DA 2022-04-17
ER

PT C
AU Raza, MO
   Memon, M
   Bhatti, S
   Bux, R
AF Raza, Muhammad Owais
   Memon, Mohsin
   Bhatti, Sania
   Bux, Rahim
BE Arai, K
   Kapoor, S
   Bhatia, R
TI Detecting Cyberbullying in Social Commentary Using Supervised Machine
   Learning
SO ADVANCES IN INFORMATION AND COMMUNICATION, VOL 2
SE Advances in Intelligent Systems and Computing
LA English
DT Proceedings Paper
CT Future of Information and Communication Conference (FICC)
CY MAR 05-06, 2020
CL San Francisco, CA
DE Cyberbullying; Python; NLP; Supervised machine learning
AB This paper addresses the problem of cyberbullying on various online discussion forums in the form of social commentary. Here, supervised machine learning algorithms are employed to detect whether a particular comment is an insult, threat or a hate message. First of all, a machine learning model is developed with Logistic Regression, Random forest and naive bayes algorithms for classification and then, both Voting and AdaBoost classifiers are applied on the developed model to observe which works best in this case. In Japan, the members of PTA (Parent Teacher Association) perform net-petrol with a manual website monitoring in order to catch and stop cyberbullying activities; however, doing all this manually is very time consuming and hectic process. The main contribution of this paper includes a mechanism to detect cyberbullying and by using supervised machine learning with logistic regression algorithm, model has achieved an accuracy of 82.7%. With voting classifier, an accuracy of 84.4% was observed. The evaluation results show that voting classifier outperforms all other algorithms in detecting cyberbullying.
C1 [Raza, Muhammad Owais; Memon, Mohsin; Bhatti, Sania; Bux, Rahim] Mehran Univ Engn Technol, Dept Software Engn, Jamshoro, Pakistan.
RP Raza, MO (corresponding author), Mehran Univ Engn Technol, Dept Software Engn, Jamshoro, Pakistan.
EM owais.leghari@hotmail.com; mohsin.memon@faculty.muet.edu.pk;
   sania.bhatti@faculty.muet.edu.pk; raheembux991@gmail.com
OI Bhatti, Sania/0000-0002-0887-8083
NR 14
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2194-5357
EI 2194-5365
BN 978-3-030-39442-4; 978-3-030-39441-7
J9 ADV INTELL SYST COMP
PY 2020
VL 1130
BP 621
EP 630
DI 10.1007/978-3-030-39442-4_45
PG 10
WC Computer Science, Artificial Intelligence; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Telecommunications
GA BR9FM
UT WOS:000675390800045
DA 2022-04-17
ER

PT C
AU Tkachenko, E
   Rogova, E
   Bodrunov, S
   Romanov, I
AF Tkachenko, Elena
   Rogova, Elena
   Bodrunov, Sergey
   Romanov, Igor
BE GarciaPerez, A
   Simkin, L
TI Development of a Corporate Knowledge Management System Using Machine
   Learning Techniques
SO PROCEEDINGS OF THE 22ND EUROPEAN CONFERENCE ON KNOWLEDGE MANAGEMENT
   (ECKM 2021)
SE Proceedings of the European Conference on Knowledge Management
LA English
DT Proceedings Paper
CT 22nd European Conference on Knowledge Management (ECKM)
CY SEP 02-03, 2021
CL Coventry Univ, ELECTR NETWORK
HO Coventry Univ
DE Knowledge management; machine learning; forecasting
AB Modern knowledge management systems are often essentially data libraries that differ only in the degree of structuring and processing methodology. From the point of view of management theory, the management process consists of such stages as analysis, goal setting, planning, implementation and control. In knowledge management, as a rule, only the analytical stage is presented. The process of management itself is limited by the difficulty of forecasting the processes of development of the system of corporate and public knowledge. In our study, we attempted to solve this problem by applying machine learning techniques. The term Machine Learning was used for the first time by Arthur Lee Samuel (1959). Machine learning is a class of artificial intelligence methods, the characteristic feature of which is not a direct solution to the problem, but training in the process of applying solutions to many similar problems. The science of machine learning itself studies methods for constructing algorithms capable of learning from various inputs. As part of this study, we will be interested only in learning with a teacher, which, in turn, is divided into the following subtasks: - Classification tasks; Regression tasks; Ranking tasks; Prediction tasks. The specific feature of learning with a teacher is that there is both a lot of data in which the model searches for patterns, and answers to the forecast of the model as part of its training. We have simulated the forecasting process in relation to the knowledge system of a company operating in the securities market. Machine learning methods have shown high efficiency in solving the entire range of tasks related to knowledge management.
C1 [Tkachenko, Elena; Romanov, Igor] St Petersburg State Univ Econ, St Petersburg, Russia.
   [Rogova, Elena] Natl Res Univ Higher Sch Econ, Moscow, Russia.
   [Bodrunov, Sergey] Inst New Ind Dev, St Petersburg, Russia.
RP Tkachenko, E (corresponding author), St Petersburg State Univ Econ, St Petersburg, Russia.
EM eletkachenko@ya.ru; elena.rogova@mail.ru; inir@inir.ru;
   igorromanov96@yandex.ru
NR 15
TC 0
Z9 0
U1 1
U2 1
PU ACAD  CONFERENCES LTD
PI NR READING
PA CURTIS FARM, KIDMORE END, NR READING, RG4 9AY, ENGLAND
SN 2048-8963
BN 978-1-914587-07-8
J9 PROC EUR CONF KNOWL
PY 2021
BP 757
EP 767
DI 10.34190/EKM.21.128
PG 11
WC Business; Management
WE Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Business & Economics
GA BS7BB
UT WOS:000758201900088
DA 2022-04-17
ER

PT J
AU Pinter, G
   Felde, I
   Mosavi, A
   Ghamisi, P
   Gloaguen, R
AF Pinter, Gergo
   Felde, Imre
   Mosavi, Amir
   Ghamisi, Pedram
   Gloaguen, Richard
TI COVID-19 Pandemic Prediction for Hungary; A Hybrid Machine Learning
   Approach
SO MATHEMATICS
LA English
DT Article
DE machine learning; prediction model; COVID-19
ID IMPERIALIST COMPETITIVE ALGORITHM; FUZZY INFERENCE SYSTEM; DENGUE
   OUTBREAK; ANFIS; PARAMETERS; MODEL; SEIR
AB Several epidemiological models are being used around the world to project the number of infected individuals and the mortality rates of the COVID-19 outbreak. Advancing accurate prediction models is of utmost importance to take proper actions. Due to the lack of essential data and uncertainty, the epidemiological models have been challenged regarding the delivery of higher accuracy for long-term prediction. As an alternative to the susceptible-infected-resistant (SIR)-based models, this study proposes a hybrid machine learning approach to predict the COVID-19, and we exemplify its potential using data from Hungary. The hybrid machine learning methods of adaptive network-based fuzzy inference system (ANFIS) and multi-layered perceptron-imperialist competitive algorithm (MLP-ICA) are proposed to predict time series of infected individuals and mortality rate. The models predict that by late May, the outbreak and the total morality will drop substantially. The validation is performed for 9 days with promising results, which confirms the model accuracy. It is expected that the model maintains its accuracy as long as no significant interruption occurs. This paper provides an initial benchmarking to demonstrate the potential of machine learning for future research.
C1 [Pinter, Gergo; Felde, Imre] Obuda Univ, John von Neumann Fac Informat, H-1034 Budapest, Hungary.
   [Mosavi, Amir] Tech Univ Dresden, Fac Civil Engn, D-01069 Dresden, Germany.
   [Mosavi, Amir] Obuda Univ, Kalman Kando Fac Elect Engn, H-1034 Budapest, Hungary.
   [Mosavi, Amir] Thuringian Inst Sustainabil & Climate Protect, D-07743 Jena, Germany.
   [Mosavi, Amir] J Selye Univ, Dept Math, Komarno 94501, Slovakia.
   [Ghamisi, Pedram] Helmholtz Zentrum Dresden Rossendorf, Helmholtz Inst Freiberg Resource Technol, Machine Learning Grp, Chemnitzer Str 40, D-09599 Freiberg, Germany.
   [Gloaguen, Richard] Helmholtz Zentrum Dresden Rossendorf, Helmholtz Inst Freiberg Resource Technol, Chemnitzer Str 40, D-09599 Freiberg, Germany.
RP Mosavi, A (corresponding author), Tech Univ Dresden, Fac Civil Engn, D-01069 Dresden, Germany.; Mosavi, A (corresponding author), Obuda Univ, Kalman Kando Fac Elect Engn, H-1034 Budapest, Hungary.; Mosavi, A (corresponding author), Thuringian Inst Sustainabil & Climate Protect, D-07743 Jena, Germany.; Mosavi, A (corresponding author), J Selye Univ, Dept Math, Komarno 94501, Slovakia.
EM pinter.gergo@nik.uni-obuda.hu; felde@uni-obuda.hu;
   amir.mosavi@mailbox.tu-dresden.de; p.ghamisi@hzdr.de; r.gloaguen@hzdr.de
RI Gloaguen, Richard/A-1238-2011; Batista, Ewerthon/AAY-5409-2020; Ghamisi,
   Pedram/ABD-5419-2021; Felde, Imre/ABB-8474-2020; Mosavi,
   Amir/I-7440-2018
OI Gloaguen, Richard/0000-0002-4383-473X; Felde, Imre/0000-0003-4126-2480;
   Mosavi, Amir/0000-0003-4842-0613; Ghamisi, Pedram/0000-0003-1203-741X
FU European UnionEuropean Commission [EFOP-3.6.1-16-2016-00010,
   2017-1.3.1-VKE-2017-00025]
FX We acknowledge the financial support of this work by the Hungarian State
   and the European Union under the EFOP-3.6.1-16-2016-00010 project and
   the 2017-1.3.1-VKE-2017-00025 project.
NR 96
TC 78
Z9 78
U1 14
U2 30
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2227-7390
J9 MATHEMATICS-BASEL
JI Mathematics
PD JUN
PY 2020
VL 8
IS 6
AR 890
DI 10.3390/math8060890
PG 20
WC Mathematics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Mathematics
GA MN4KG
UT WOS:000550811800001
OA Green Submitted, gold
HC Y
HP N
DA 2022-04-17
ER

PT J
AU Akpabio, II
   Savari, SA
AF Akpabio, Inimfon I.
   Savari, Serap A.
TI Uncertainty quantification of machine learning models: on conformal
   prediction
SO JOURNAL OF MICRO-NANOPATTERNING MATERIALS AND METROLOGY-JM3
LA English
DT Article
DE deep learning; machine learning; prediction intervals; line edge
   roughness
ID REGRESSION; INTERVALS; SURFACES
AB Background: Machine learning is predicted to have an increasingly important role in semiconductor metrology. Prediction intervals that describe the reliability of the predictive performance of machine learning models are important to guide decision making and to improve trust in deep learning and other forms of machine learning and artificial intelligence. Image processing is an important application of artificial intelligence. Low-dose images from the scanning electron microscope (SEM) are often used for roughness measurements such as line edge roughness (LER) because of relatively small acquisition times and resist shrinkage, but such images are corrupted by noise, blur, edge effects, and other instrument errors. LER affects semiconductor device performance and the yield of the manufacturing process. Aim: We consider prediction intervals for the deep convolutional neural network EDGENet, which was trained on a large dataset of simulated SEM images and directly estimates the edge positions from a SEM rough line image containing an unknown level of Poisson noise. Approach: Conformal prediction is a relatively recent, increasingly popular, rigorously proven, and simple methodology to address this need for both classification and regression problems, and it does not use distributional assumptions such as Gaussianity or the Bayesian framework; one new variant combines it with another technique to generate prediction intervals known as quantile regression. Results: We illustrate the strengths and limitations of different conformal prediction procedures for the EDGENet approach to LER estimation. Combining these approaches into ensemble schemes and incorporating domain knowledge produces more informative prediction intervals. Conclusions: Deep learning models can help in the estimation of LER, but their acceptance has been hindered by a lack of trust in these techniques. Prediction intervals that provide coverage guarantees are an approach to alleviate this problem and may catalyze the transition within semiconductor manufacturing to a wider acceptance and implementation of machine learning. (c) 2021 Society of Photo-Optical Instrumentation Engineers (SPIE) [DOI: 10.1117/1.JMM.20.4.041206]
C1 [Akpabio, Inimfon I.; Savari, Serap A.] Texas A&M Univ, College Stn, TX 77843 USA.
RP Savari, SA (corresponding author), Texas A&M Univ, College Stn, TX 77843 USA.
EM savari@tamu.edu
NR 39
TC 0
Z9 0
U1 1
U2 1
PU SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA
SN 1932-5150
EI 2708-8340
J9 J MICRO-NANOPATTERN
JI J. Micro-Nanopatterning Mater. Metrol.-JM3
PD OCT
PY 2021
VL 20
IS 4
AR 041206
DI 10.1117/1.JMM.20.4.041206
PG 14
WC Engineering, Electrical & Electronic; Nanoscience & Nanotechnology;
   Materials Science, Multidisciplinary; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Science & Technology - Other Topics; Materials Science;
   Optics
GA YD9HW
UT WOS:000740745400004
DA 2022-04-17
ER

PT C
AU Alnoman, A
AF Alnoman, Ali
GP IEEE
TI Machine Learning-Based Task Clustering for Enhanced Virtual Machine
   Utilization in Edge Computing
SO 2020 IEEE CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING
   (CCECE)
SE Canadian Conference on Electrical and Computer Engineering
LA English
DT Proceedings Paper
CT IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)
CY AUG 30-SEP 01, 2020
CL London, CANADA
SP IEEE
DE Machine learning; K-means; edge computing; virtual machine
AB Edge computing provides cloud-like services at the network edge near mobile users. Due to the prosperity of smart applications that involve computing-intensive tasks, edge devices are intended to provide sufficient amounts of resources in order to accommodate the increasing computing demands. However, computing resources could also suffer being underutilized which leads to both resource and energy wastage. In this paper, heterogeneous virtual machine (VM) allocation in edge computing is considered to cope with the different computing demands at each edge device. To this end, an unsupervised machine learning technique, namely, the K-means is used to cluster incoming tasks into three different categories according to their processing requirements. Afterwards, tasks belonging to each cluster will be allocated the appropriate type of VMs to better utilize the computing resources. Results show the effectiveness of the proposed scheme in clustering computing tasks and improving resource utilization in edge devices.
C1 [Alnoman, Ali] Sheridan Coll, Fac Appl Sci & Technol, Oakville, ON, Canada.
RP Alnoman, A (corresponding author), Sheridan Coll, Fac Appl Sci & Technol, Oakville, ON, Canada.
NR 15
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 0840-7789
BN 978-1-7281-5442-8
J9 CAN CON EL COMP EN
PY 2020
PG 4
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BR2DA
UT WOS:000637286700139
DA 2022-04-17
ER

PT J
AU Li, ZF
   Liu, HX
   Luo, CB
   Fu, GT
AF Li, Zhufeng
   Liu, Haixing
   Luo, Chunbo
   Fu, Guangtao
TI Assessing Surface Water Flood Risks in Urban Areas Using Machine
   Learning
SO WATER
LA English
DT Article
DE CNNs; deep learning; flood management; machine learning; surface water
   flooding
ID SUSCEPTIBILITY ASSESSMENT; CLASSIFICATION; MODELS
AB Urban flooding is a devastating natural hazard for cities around the world. Flood risk mapping is a key tool in flood management. However, it is computationally expensive to produce flood risk maps using hydrodynamic models. To this end, this paper investigates the use of machine learning for the assessment of surface water flood risks in urban areas. The factors that are considered in machine learning models include coordinates, elevation, slope gradient, imperviousness, land use, land cover, soil type, substrate, distance to river, distance to road, and normalized difference vegetation index. The machine learning models are tested using the case study of Exeter, UK. The performance of machine learning algorithms, including naive Bayes, perceptron, artificial neural networks (ANNs), and convolutional neural networks (CNNs), is compared based on a spectrum of indicators, e.g., accuracy, F-beta score, and receiver operating characteristic curve. The results obtained from the case study show that the flood risk maps can be accurately generated by the machine learning models. The performance of models on the 30-year flood event is better than 100-year and 1000-year flood events. The CNNs and ANNs outperform the other machine learning algorithms tested. This study shows that machine learning can help provide rapid flood mapping, and contribute to urban flood risk assessment and management.
C1 [Li, Zhufeng; Luo, Chunbo; Fu, Guangtao] Univ Exeter, Coll Engn Math & Phys Sci, Exeter EX4 4QF, Devon, England.
   [Liu, Haixing] Dalian Univ Technol, Sch Hydraul Engn, Dalian 116023, Peoples R China.
RP Liu, HX (corresponding author), Dalian Univ Technol, Sch Hydraul Engn, Dalian 116023, Peoples R China.
EM hliu@dlut.edu.cn
OI Li, Zhufeng/0000-0001-9346-6245
FU British CouncilThe British Council in India [2019-RLWK11-10585]; Royal
   SocietyRoyal Society of LondonEuropean Commission [IF160108]; Alan
   Turing Institute under the EPSRCUK Research & Innovation
   (UKRI)Engineering & Physical Sciences Research Council (EPSRC)
   [EP/N510129/1]; National Natural Science Foundation of ChinaNational
   Natural Science Foundation of China (NSFC) [52079016, 52122901]
FX This research was funded by the British Council grant number
   2019-RLWK11-10585, the Royal Society under the Industry Fellowship
   Scheme grant number IF160108, the Alan Turing Institute under the EPSRC
   Grant grant number EP/N510129/1, and the National Natural Science
   Foundation of China grant number 52079016, 52122901. And the APC was
   funded by the British Council.
NR 41
TC 0
Z9 0
U1 16
U2 16
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2073-4441
J9 WATER-SUI
JI Water
PD DEC
PY 2021
VL 13
IS 24
AR 3520
DI 10.3390/w13243520
PG 14
WC Environmental Sciences; Water Resources
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Environmental Sciences & Ecology; Water Resources
GA XZ0RA
UT WOS:000737368700001
OA gold
DA 2022-04-17
ER

PT J
AU Pedoia, V
   Caliva, F
   Kazakia, G
   Burghardt, AJ
   Majumdar, S
AF Pedoia, Valentina
   Caliva, Francesco
   Kazakia, Galateia
   Burghardt, Andrew J.
   Majumdar, Sharmila
TI Augmenting Osteoporosis Imaging with Machine Learning
SO CURRENT OSTEOPOROSIS REPORTS
LA English
DT Review
DE Machine learning; Osteoporosis; Imaging; Diagnosis; Fracture detection;
   Risk prediction
ID ARTIFICIAL-INTELLIGENCE; BONE; PREDICTION
AB Purpose of Review In this paper, we discuss how recent advancements in image processing and machine learning (ML) are shaping a new and exciting era for the osteoporosis imaging field. With this paper, we want to give the reader a basic exposure to the ML concepts that are necessary to build effective solutions for image processing and interpretation, while presenting an overview of the state of the art in the application of machine learning techniques for the assessment of bone structure, osteoporosis diagnosis, fracture detection, and risk prediction. Recent Findings ML effort in the osteoporosis imaging field is largely characterized by "low-cost" bone quality estimation and osteoporosis diagnosis, fracture detection, and risk prediction, but also automatized and standardized large-scale data analysis and data-driven imaging biomarker discovery. Our effort is not intended to be a systematic review, but an opportunity to review key studies in the recent osteoporosis imaging research landscape with the ultimate goal of discussing specific design choices, giving the reader pointers to possible solutions of regression, segmentation, and classification tasks as well as discussing common mistakes.
C1 [Pedoia, Valentina; Caliva, Francesco; Kazakia, Galateia; Burghardt, Andrew J.; Majumdar, Sharmila] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 1700 Fourth St,Suite 201,QB3 Bldg, San Francisco, CA 94158 USA.
RP Pedoia, V (corresponding author), Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 1700 Fourth St,Suite 201,QB3 Bldg, San Francisco, CA 94158 USA.
EM valentian.pedoia@ucsf.edu
NR 46
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1544-1873
EI 1544-2241
J9 CURR OSTEOPOROS REP
JI Curr. Osteoporos. Rep.
PD DEC
PY 2021
VL 19
IS 6
BP 699
EP 709
DI 10.1007/s11914-021-00701-y
EA NOV 2021
PG 11
WC Endocrinology & Metabolism
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Endocrinology & Metabolism
GA XY1DH
UT WOS:000715006000003
PM 34741729
DA 2022-04-17
ER

PT J
AU Dubey, A
AF Dubey, Anubha
TI Machine Learning Model for Vaccine Development: A Perspective
SO BIOSCIENCE BIOTECHNOLOGY RESEARCH COMMUNICATIONS
LA English
DT Article
DE CLINICAL; DISEASE IMMUNE SYSTEM; MACHINE LEARNING; VACCINE
AB A vaccine is a hope to prevent disease while training the immune system to produce antibodies against pathogens. As it is safe, easy in use, and having no side effects, it is used for the cure of many diseases. Vaccines may be of different types, like subunit vaccines, attenuated vaccines, DNA vaccines, etc. The process of vaccine development is taking a long way, needs highly sophisticated labs, clinical trials, and much more. This whole process will take a long time to develop a vaccine. And then manufacturing in the specific environment will again time is taken to reach to the market. While clinical trials of vaccines sometimes failed to produce the desired results. So to improve these trial methods and making vaccine production successful. Here in this paper, it is tried to propose machine learning methods i.e. classification, clustering, association (mainly used algorithms) in different stages of vaccine development clinical trials. Because machine learning techniques are soft, time-consuming, and help to achieve a particular target with great sensitivity and accuracy. It is hoped that if machine learning methods are followed in a proper way time will be saved and vaccine designing will be done in less time with great accuracy, sensitivity, and specificity.
C1 [Dubey, Anubha] Bioinformatics, Katni, MP, India.
RP Dubey, A (corresponding author), Bioinformatics, Katni, MP, India.
EM anubhadubey@rediffmail.com
RI Dubey, Anubha/V-5554-2019
NR 16
TC 0
Z9 0
U1 2
U2 2
PU SOC SCIENCE & NATURE
PI BHOPAL
PA C-52 HOUSING BOARD COLONY, KOHE FIZA, BHOPAL, MADHYA PRADESH 462 001,
   INDIA
SN 0974-6455
J9 BIOSCI BIOTECH RES C
JI Biosci. Biotechnol. Res. Commun.
PD APR-JUN
PY 2020
VL 13
IS 2
BP 762
EP 769
DI 10.21786/bbrc/13.2/58
PG 8
WC Biotechnology & Applied Microbiology
WE Emerging Sources Citation Index (ESCI)
SC Biotechnology & Applied Microbiology
GA MU1XF
UT WOS:000555465500058
DA 2022-04-17
ER

PT J
AU Lee, YW
   Choi, JW
   Shin, EH
AF Lee, You Won
   Choi, Jae Woo
   Shin, Eun-Hee
TI Machine learning model for predicting malaria using clinical information
SO COMPUTERS IN BIOLOGY AND MEDICINE
LA English
DT Article
DE Machine learning; Malaria; Diagnosis; Case reports; Patient information
AB Background: Rapid diagnosing is crucial for controlling malaria. Various studies have aimed at developing machine learning models to diagnose malaria using blood smear images; however, this approach has many limitations. This study developed a machine learning model for malaria diagnosis using patient information.
   Methods: To construct datasets, we extracted patient information from the PubMed abstracts from 1956 to 2019. We used two datasets: a solely parasitic disease dataset and total dataset by adding information about other diseases. We compared six machine learning models: support vector machine, random forest (RF), multilayered perceptron, AdaBoost, gradient boosting (GB), and CatBoost. In addition, a synthetic minority oversampling technique (SMOTE) was employed to address the data imbalance problem.
   Results: Concerning the solely parasitic disease dataset, RF was found to be the best model regardless of using SMOTE. Concerning the total dataset, GB was found to be the best. However, after applying SMOTE, RF performed the best. Considering the imbalanced data, nationality was found to be the most important feature in malaria prediction. In case of the balanced data with SMOTE, the most important feature was symptom.
   Conclusions: The results demonstrated that machine learning techniques can be successfully applied to predict malaria using patient information.
C1 [Lee, You Won; Shin, Eun-Hee] Seoul Natl Univ, Dept Trop Med & Parasitol, Coll Med, 103 Daehak Ro, Seoul 03080, South Korea.
   [Lee, You Won; Shin, Eun-Hee] Seoul Natl Univ, Inst Endem Dis, Seoul 03080, South Korea.
   [Choi, Jae Woo] Yonsei Univ, Dept Pharmacol, Coll Med, Seoul 03722, South Korea.
   [Choi, Jae Woo] Yonsei Univ, Severance Biomed Sci Inst, Coll Med, Seoul 03722, South Korea.
   [Shin, Eun-Hee] Seoul Natl Univ, Bundang Hosp, Seongnam 13620, South Korea.
RP Shin, EH (corresponding author), Seoul Natl Univ, Dept Trop Med & Parasitol, Coll Med, 103 Daehak Ro, Seoul 03080, South Korea.; Shin, EH (corresponding author), Seoul Natl Univ, Inst Endem Dis, Seoul 03080, South Korea.
EM ehshin@snu.ac.kr
OI Choi, Jae Woo/0000-0001-5741-8748
FU Korea Association of Health Promotion Fund [2014-01]
FX This work was supported by the Korea Association of Health Promotion
   Fund (Grant no. 2014-01).
NR 55
TC 3
Z9 3
U1 7
U2 18
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0010-4825
EI 1879-0534
J9 COMPUT BIOL MED
JI Comput. Biol. Med.
PD FEB
PY 2021
VL 129
AR 104151
DI 10.1016/j.compbiomed.2020.104151
PG 7
WC Biology; Computer Science, Interdisciplinary Applications; Engineering,
   Biomedical; Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Life Sciences & Biomedicine - Other Topics; Computer Science;
   Engineering; Mathematical & Computational Biology
GA QB1ST
UT WOS:000613923800002
PM 33290932
DA 2022-04-17
ER

PT J
AU Parlett-Pelleriti, CM
   Stevens, E
   Dixon, D
   Linstead, EJ
AF Parlett-Pelleriti, Chelsea M.
   Stevens, Elizabeth
   Dixon, Dennis
   Linstead, Erik J.
TI Applications of Unsupervised Machine Learning in Autism Spectrum
   Disorder Research: a Review
SO REVIEW JOURNAL OF AUTISM AND DEVELOPMENTAL DISORDERS
LA English
DT Review; Early Access
DE Autism spectrum disorder; ASD; Autism; Unsupervised machine learning;
   Clustering; Phenotypes; Subgroups
ID CLUSTER-ANALYSIS; SUBTYPES; CHILDREN; PHENOTYPES; SUBGROUPS
AB Large amounts of autism spectrum disorder (ASD) data is created through hospitals, therapy centers, and mobile applications; however, much of this rich data does not have pre-existing classes or labels. Large amounts of data-both genetic and behavioral-that are collected as part of scientific studies or a part of treatment can provide a deeper, more nuanced insight into both diagnosis and treatment of ASD. This paper reviews 43 papers using unsupervised machine learning in ASD, including k-means clustering, hierarchical clustering, model-based clustering, and self-organizing maps. The aim of this review is to provide a survey of the current uses of unsupervised machine learning in ASD research and provide insight into the types of questions being answered with these methods.
C1 [Parlett-Pelleriti, Chelsea M.; Stevens, Elizabeth; Linstead, Erik J.] Chapman Univ, Fowler Sch Engn, Machine Learning & Affiliated Technol Lab, One Univ Dr, Orange, CA 92866 USA.
   [Dixon, Dennis] Ctr Autism & Related Disorders, Woodland Hills, CA USA.
RP Linstead, EJ (corresponding author), Chapman Univ, Fowler Sch Engn, Machine Learning & Affiliated Technol Lab, One Univ Dr, Orange, CA 92866 USA.
EM linstead@chapman.edu
FU NSF GRFPNational Science Foundation (NSF)NSF - Office of the Director
   (OD) [1849569]
FX CPP was funded by NSF GRFP, Fellowship ID #1849569.
NR 51
TC 0
Z9 0
U1 9
U2 9
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 2195-7177
EI 2195-7185
J9 REV J AUTISM DEV DIS
JI Rev. J. Autism Dev. Disord.
DI 10.1007/s40489-021-00299-y
EA JAN 2022
PG 16
WC Psychology, Developmental
WE Social Science Citation Index (SSCI)
SC Psychology
GA YS7OB
UT WOS:000750860800001
OA Green Published, hybrid
DA 2022-04-17
ER

PT J
AU O'Quinn, W
   Mao, SW
AF O'Quinn, Wesley
   Mao, Shiwen
TI Quantum Machine Learning: Recent Advances and Outlook
SO IEEE WIRELESS COMMUNICATIONS
LA English
DT Article
DE Quantum computing; Machine learning; Computers; Hardware; Program
   processors; Transistors; Annealing
AB Quantum computing is currently at the nexus of physics and engineering. Although current generation quantum processors are small and noisy, advancements are happening at an astounding rate. In addition, machine learning has played a crucial role in many recent advances. The combination of these two fields, Quantum Machine Learning, is a small but extremely promising new field with the possibility of unlimited abilities. This work seeks to provide an introduction to this emerging field, along with a discussion of recent advances as well as problems that are yet to be solved.
C1 [O'Quinn, Wesley] Auburn Univ, Auburn, AL 36849 USA.
   [Mao, Shiwen] Auburn Univ, Wireless Engn Res Arid Educ Ctr, Auburn, AL 36849 USA.
RP O'Quinn, W (corresponding author), Auburn Univ, Auburn, AL 36849 USA.
RI Mao, Shiwen/AAY-4471-2020
FU NSFNational Science Foundation (NSF) [ECCS-1923717, ACI-1659845];
   Wireless Engineering Research and Education Center (WEREC) at Auburn
   University
FX This work is supported in part by the NSF under Grant ECCS-1923717 and
   ACI-1659845, and by the Wireless Engineering Research and Education
   Center (WEREC) at Auburn University. We would like to thank Dr. Peter
   Mueller with the IBM Zurich Research Laboratory for his suggestions with
   regard to the IBM Q systems, and the authors of [4] for constructive
   feedback. We would also like to thank Dr. Mark Novotny with Mississippi
   State University for his explanation of his recent work with quantum
   annealers. We are indebted to Mr. Michal Stechly with Zapata Computing
   for his exceptional work in explaining concepts related to NISQ
   processors and related suggestions. Finally, Dr. Joel Gottlieb at D-Wave
   Systems has been an invaluable resource in both this work and future
   works.
NR 15
TC 2
Z9 2
U1 5
U2 16
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1536-1284
EI 1558-0687
J9 IEEE WIREL COMMUN
JI IEEE Wirel. Commun.
PD JUN
PY 2020
VL 27
IS 3
BP 126
EP 131
DI 10.1109/MWC.001.1900341
PG 6
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Engineering, Electrical & Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA MC0CC
UT WOS:000542963900020
DA 2022-04-17
ER

PT J
AU Jeong, Y
   Hong, YJ
   Han, JH
AF Jeong, Yeonwoo
   Hong, Yu-Jin
   Han, Jae-Ho
TI Review of Machine Learning Applications Using Retinal Fundus Images
SO DIAGNOSTICS
LA English
DT Article
DE deep learning; fundus image; machine learning; retinal image
ID BLOOD-VESSEL SEGMENTATION; OPEN-ANGLE GLAUCOMA; NERVE-FIBER LAYER;
   DIABETIC-RETINOPATHY; MACULAR DEGENERATION; ARTIFICIAL-INTELLIGENCE;
   DEEP; CLASSIFICATION; PERFORMANCE; AGREEMENT
AB Automating screening and diagnosis in the medical field saves time and reduces the chances of misdiagnosis while saving on labor and cost for physicians. With the feasibility and development of deep learning methods, machines are now able to interpret complex features in medical data, which leads to rapid advancements in automation. Such efforts have been made in ophthalmology to analyze retinal images and build frameworks based on analysis for the identification of retinopathy and the assessment of its severity. This paper reviews recent state-of-the-art works utilizing the color fundus image taken from one of the imaging modalities used in ophthalmology. Specifically, the deep learning methods of automated screening and diagnosis for diabetic retinopathy (DR), age-related macular degeneration (AMD), and glaucoma are investigated. In addition, the machine learning techniques applied to the retinal vasculature extraction from the fundus image are covered. The challenges in developing these systems are also discussed.
C1 [Jeong, Yeonwoo; Han, Jae-Ho] Korea Univ, Dept Brain & Cognit Engn, 145 Anam Rd, Seoul 02841, South Korea.
   [Hong, Yu-Jin] Hoseo Univ, Div Elect & Display Engn, 20 Hoseo Ro79beon Gil, Asan 31066, South Korea.
   [Han, Jae-Ho] Korea Univ, Dept Artificial Intelligence, 145 Anam Rd, Seoul 02841, South Korea.
RP Han, JH (corresponding author), Korea Univ, Dept Brain & Cognit Engn, 145 Anam Rd, Seoul 02841, South Korea.; Han, JH (corresponding author), Korea Univ, Dept Artificial Intelligence, 145 Anam Rd, Seoul 02841, South Korea.
EM boyjeong@korea.ac.kr; yjhong@hoseo.edu; hanjaeho@korea.ac.kr
FU National Research Foundation of Korea (NRF) - Korean government (MSIT)
   [NRF-2020R1A4A1018309]; MSIT (Ministry of Science and ICT), Korea
   [IITP-2021-2020-0-01819]
FX This work was supported in part by the National Research Foundation of
   Korea (NRF) grant funded by the Korean government (MSIT)
   (NRF-2020R1A4A1018309). This research was supported in part by the MSIT
   (Ministry of Science and ICT), Korea, under the ICT Creative Consilience
   program(IITP-2021-2020-0-01819) supervised by the IITP(Institute for
   Information & communications Technology Planning & Evaluation).
NR 139
TC 0
Z9 0
U1 8
U2 8
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2075-4418
J9 DIAGNOSTICS
JI Diagnostics
PD JAN
PY 2022
VL 12
IS 1
AR 134
DI 10.3390/diagnostics12010134
PG 27
WC Medicine, General & Internal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC General & Internal Medicine
GA YO2UQ
UT WOS:000747800700001
PM 35054301
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Wickramasinghe, CS
   Amarasinghe, K
   Marino, DL
   Rieger, C
   Manic, M
AF Wickramasinghe, Chathurika S.
   Amarasinghe, Kasun
   Marino, Daniel L.
   Rieger, Craig
   Manic, Milos
TI Explainable Unsupervised Machine Learning for Cyber-Physical Systems
SO IEEE ACCESS
LA English
DT Article
DE Machine learning; Data models; Machine learning algorithms; Prediction
   algorithms; Self-organizing feature maps; Decision making; Artificial
   intelligence; Explainable artificial intelligence; self-organizing maps;
   interpretable machine learning; unsupervised machine learning
ID SELF-ORGANIZING MAP; DEEP; AUTOENCODER; SECURITY; MODELS
AB Cyber-Physical Systems (CPSs) play a critical role in our modern infrastructure due to their capability to connect computing resources with physical systems. As such, topics such as reliability, performance, and security of CPSs continue to receive increased attention from the research community. CPSs produce massive amounts of data, creating opportunities to use predictive Machine Learning (ML) models for performance monitoring and optimization, preventive maintenance, and threat detection. However, the "black-box" nature of complex ML models is a drawback when used in safety-critical systems such as CPSs. While explainable ML has been an active research area in recent years, much of the work has been focused on supervised learning. As CPSs rapidly produce massive amounts of unlabeled data, relying on supervised learning alone is not sufficient for data-driven decision making in CPSs. Therefore, if we are to maximize the use of ML in CPSs, it is necessary to have explainable unsupervised ML models. In this paper, we outline how unsupervised explainable ML could be used within CPSs. We review the existing work in unsupervised ML, present initial desiderata of explainable unsupervised ML for CPS, and present a Self-Organizing Maps based explainable clustering methodology which generates global and local explanations. We evaluate the fidelity of the generated explanations using feature perturbation techniques. The results show that the proposed method identifies the most important features responsible for the decision-making process of Self-organizing Maps. Further, we demonstrated that explainable Self-Organizing Maps are a strong candidate for explainable unsupervised machine learning by comparing its model capabilities and limitations with current explainable unsupervised methods.
C1 [Wickramasinghe, Chathurika S.; Marino, Daniel L.; Manic, Milos] Virginia Commonwealth Univ, Dept Comp Sci, Richmond, VA 23220 USA.
   [Amarasinghe, Kasun] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
   [Rieger, Craig] Idaho Natl Lab INL, Idaho Falls, ID 83415 USA.
RP Wickramasinghe, CS (corresponding author), Virginia Commonwealth Univ, Dept Comp Sci, Richmond, VA 23220 USA.
EM brahmanacsw@vcu.edu
RI Wickramasinghe, Chathurika S/AAC-7024-2020
OI Wickramasinghe, Chathurika/0000-0002-3333-5101; Marino,
   Daniel/0000-0002-8686-4752; Manic, Milos/0000-0003-1484-7678
FU Commonwealth Cyber Initiative, an investment in the advancement of cyber
   R&D, innovation and workforce development
FX This work was supported in part by the Commonwealth Cyber Initiative, an
   investment in the advancement of cyber R&D, innovation and workforce
   development. For more info about CCI, visit cyberinitiative.org.
NR 72
TC 1
Z9 1
U1 7
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 131824
EP 131843
DI 10.1109/ACCESS.2021.3112397
PG 20
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA UZ9VJ
UT WOS:000702545900001
OA gold
DA 2022-04-17
ER

PT S
AU MacLennan, BJ
AF MacLennan, Bruce J.
BE Bhattacharyya, S
   Pan, I
   Mani, A
   De, S
   Behrman, E
   Chakraborti, S
TI Topographic representation for quantum machine learning
SO QUANTUM MACHINE LEARNING
SE De Gruyter Frontiers in Computational Intelligence
LA English
DT Article; Book Chapter
DE computational map; neural network; quantum computation; quantum machine
   learning; quantum neural network; topographic map; topographic
   representation
AB One of the most common information representations in the brain is the topographic or computational map, in which neurons are arranged systematically according to the values they represent. By representing quantitative relationships spatially, computational maps enable the brain to compute complex, nonlinear functions to the accuracy required. This chapter proposes two approaches to quantum computation for machine learning by means of topographic representation. It shows how to construct unitary operators, implementable on quantum computers, that implement arbitrary (including nonlinear) functions via computational maps.
C1 [MacLennan, Bruce J.] Univ Tennessee, Knoxville, TN 37996 USA.
RP MacLennan, BJ (corresponding author), Univ Tennessee, Knoxville, TN 37996 USA.
EM maclennan@utk.edu
NR 19
TC 0
Z9 0
U1 0
U2 0
PU WALTER DE GRUYTER GMBH
PI BERLIN
PA GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY
SN 2512-8868
BN 978-3-11-067070-7; 978-3-11-067064-6
J9 DE GR FRONT COMPU IN
PY 2020
VL 6
BP 11
EP 37
DI 10.1515/9783110670707-002
D2 10.1515/9783110670707
PG 27
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic;
   Quantum Science & Technology
WE Book Citation Index – Science (BKCI-S)
SC Computer Science; Engineering; Physics
GA BQ5AP
UT WOS:000596459300003
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Cui, YX
   Wang, S
   Zhao, R
AF Cui, Yuxin
   Wang, Sheng
   Zhao, Ran
TI Machine Learning-Based Student Emotion Recognition for Business English
   Class
SO INTERNATIONAL JOURNAL OF EMERGING TECHNOLOGIES IN LEARNING
LA English
DT Article
DE Teaching model; machine learning; emotion recognition; emotion
   understanding; emotion expression
ID ADULT-EDUCATION TEACHERS; MODEL; BURNOUT; LABOR; AGE
AB Traditional English teaching model neglects student emotions, making many tired of learning. Machine learning supports end-to-end recognition of learning emotions, such that the recognition system can adaptively adjust the learning difficulty in English classroom. With the help of machine learning, this paper presents a method to extract the facial expression features of students in business English class, and establishes a student emotion recognition model, which consists of such modules as emotion mechanism, signal acquisition, analysis and recognition, emotion understanding, emotion expression, and wearable equipment. The results show that the proposed emotion recognition model monitors the real-time emotional states of each student during English learning; upon detecting frustration or boredom, machine learning will timely switch to the contents that interest the student or easier to learn, keeping the student active in learning. The research provides an end-to-end student emotion recognition system to assist with classroom teaching, and enhance the positive emotions of students in English learning.
C1 [Cui, Yuxin; Wang, Sheng] Beijing Forestry Univ, Beijing, Peoples R China.
   [Zhao, Ran] Beijing Inst Econ & Management, Beijing, Peoples R China.
RP Zhao, R (corresponding author), Beijing Inst Econ & Management, Beijing, Peoples R China.
EM jo_eyCui0123@163.com; ws13121192200@bjfu.edu.cn; zhaoran@biem.edu.cn
NR 31
TC 2
Z9 2
U1 7
U2 14
PU KASSEL UNIV PRESS GMBH
PI KASSEL
PA DIAGONALE 10, D-34127 KASSEL, GERMANY
SN 1863-0383
J9 INT J EMERG TECHNOL
JI Int. J. Emerg. Technol. Learn.
PY 2021
VL 16
IS 12
BP 94
EP 107
DI 10.3991/ijet.v16i12.23313
PG 14
WC Education & Educational Research
WE Emerging Sources Citation Index (ESCI)
SC Education & Educational Research
GA SU8DP
UT WOS:000663361200006
OA gold
DA 2022-04-17
ER

PT J
AU Gu, RJ
   Niu, CY
   Wu, F
   Chen, GH
   Hu, C
   Lyu, CF
   Wu, ZH
AF Gu, Renjie
   Niu, Chaoyue
   Wu, Fan
   Chen, Guihai
   Hu, Chun
   Lyu, Chengfei
   Wu, Zhihua
TI From Server-Based to Client-Based Machine Learning: A Comprehensive
   Survey
SO ACM COMPUTING SURVEYS
LA English
DT Article
DE Mobile intelligence; machine learning; distributed system; decentralized
   training; federated learning
ID ALGORITHMS
AB In recent years, mobile devices have gained increasing development with stronger computation capability and larger storage space. Some of the computation-intensive machine learning tasks can now be run on mobile devices. To exploit the resources available on mobile devices and preserve personal privacy, the concept of client-based machine learning has been proposed. It leverages the users' local hardware and local data to solve machine learning sub-problems on mobile devices and only uploads computation results rather than the original data for the optimization of the global model. Such an architecture can not only relieve computation and storage burdens on servers but also protect the users' sensitive information. Another benefit is the bandwidth reduction because various kinds of local data can be involved in the training process without being uploaded. In this article, we provide a literature review on the progressive development of machine learning from server based to client based. We revisit a number of widely used server-based and client-based machine learning methods and applications. We also extensively discuss the challenges and future directions in this area. We believe that this survey will give a clear overview of client-based machine learning and provide guidelines on applying client-based machine learning to practice.
C1 [Gu, Renjie; Niu, Chaoyue; Wu, Fan; Chen, Guihai] Shanghai Jiao Tong Univ, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
   [Hu, Chun; Lyu, Chengfei; Wu, Zhihua] Alibaba Grp, 969 Wenyi Rd W, Hangzhou 311121, Peoples R China.
RP Wu, F (corresponding author), Shanghai Jiao Tong Univ, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
EM grj165@sjtu.edu.cn; rvince@sjtu.edu.cn; fwu@cs.sjtu.edu.cn;
   gchen@cs.sjtu.edu.cn; shiji.hc@alibaba-inc.com;
   chengfei.lef@alibaba-inc.com; zhihua.wzh@alibaba-inc.com
FU National Key R&D Program of China [2019YFB2102200]; China NSFNational
   Natural Science Foundation of China (NSFC) [61972252, 61972254,
   61672348, 61672353]; Joint Scientific Research Foundation of the State
   Education Ministry [6141A02033702]; Alibaba Group through the Alibaba
   Innovation Research Program
FX This work was supported in part by National Key R&D Program of China No.
   2019YFB2102200; in part by China NSF grant No. 61972252, 61972254,
   61672348, and 61672353; in part by Joint Scientific Research Foundation
   of the State Education Ministry No. 6141A02033702; and in part by
   Alibaba Group through the Alibaba Innovation Research Program. The
   opinions, findings, conclusions, and recommendations expressed in this
   article are those of the authors and do not necessarily reflect the
   views of the funding agencies or the government. The authors also want
   to sincerely thank Dr. Shuo Yang for offering valuable suggestions on
   polishing the initial version of this work.
NR 122
TC 1
Z9 1
U1 8
U2 12
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 0360-0300
EI 1557-7341
J9 ACM COMPUT SURV
JI ACM Comput. Surv.
PD APR
PY 2021
VL 54
IS 1
AR 6
DI 10.1145/3424660
PG 36
WC Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RT4PM
UT WOS:000644443200006
OA Green Submitted
DA 2022-04-17
ER

PT C
AU Ferreira, L
   Pilastri, A
   Martins, C
   Santos, P
   Cortez, P
AF Ferreira, Luis
   Pilastri, Andre
   Martins, Carlos
   Santos, Pedro
   Cortez, Paulo
BE Rocha, AP
   Steels, L
   VanDenHerik, J
TI An Automated and Distributed Machine Learning Framework for
   Telecommunications Risk Management
SO ICAART: PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON AGENTS AND
   ARTIFICIAL INTELLIGENCE, VOL 2
LA English
DT Proceedings Paper
CT 12th International Conference on Agents and Artificial Intelligence
   (ICAART)
CY FEB 22-24, 2020
CL Valletta, MALTA
DE Automated Machine Learning; Distributed Machine Learning; Supervised
   Learning; Risk Management
AB Automation and scalability are currently two of the main challenges of Machine Learning. This paper proposes an automated and distributed ML framework that automatically trains a supervised learning model and produces predictions independently of the dataset and with minimum human input. The framework was designed for the domain of telecommunications risk management, which often requires supervised learning models that need to be quickly updated by non-ML-experts and trained on vast amounts of data. Thus, the architecture assumes a distributed environment, in order to deal with big data, and Automated Machine Learning (Au-toML), to select and tune the ML models. The framework includes several modules: task detection (to detect if classification or regression), data preprocessing, feature selection, model training, and deployment. In this paper, we detail the model training module. In order to select the computational technologies to be used in this module, we first analyzed the capabilities of an initial set of five modern AutoML tools: Auto-Keras, Auto-Sklearn, Auto-Weka, H2O AutoML, and TransmogrifAI. Then, we performed a benchmarking of the only two tools that address distributed ML (H2O AutoML and TransmogrifAI). Several comparison experiments were held using three real-world datasets from the telecommunications domain (churn, event forecasting, and fraud detection), allowing us to measure the computational effort and predictive capability of the AutoML tools.
C1 [Ferreira, Luis; Pilastri, Andre] CCG ZGDV Inst, EPMQ IT Engn Matur & Qual Lab, Guimaraes, Portugal.
   [Ferreira, Luis; Cortez, Paulo] Univ Minho, ALGORITMI Ctr, Dep Informat Syst, Guimaraes, Portugal.
   [Martins, Carlos; Santos, Pedro] WeDo Technol, Braga, Portugal.
RP Ferreira, L (corresponding author), CCG ZGDV Inst, EPMQ IT Engn Matur & Qual Lab, Guimaraes, Portugal.; Ferreira, L (corresponding author), Univ Minho, ALGORITMI Ctr, Dep Informat Syst, Guimaraes, Portugal.
RI Pilastri, Andre/AAH-9679-2020; Cortez, Paulo/A-2674-2008; Ferreira,
   Luís/AAX-9736-2021
OI Pilastri, Andre/0000-0002-4380-3220; Cortez, Paulo/0000-0002-7991-2090;
   Ferreira, Luís/0000-0002-4790-5128
FU Incentive System for Research and Technological Development, from the
   Thematic Operational Program Competitiveness of the national framework
   program - Portugal2020 [NUP: POCI-01-0247-FEDER038526]
FX This work was executed under the project IRMDA - Intelligent Risk
   Management for the Digital Age, Individual Project, NUP:
   POCI-01-0247-FEDER038526, co-funded by the Incentive System for Research
   and Technological Development, from the Thematic Operational Program
   Competitiveness of the national framework program - Portugal2020.
NR 19
TC 2
Z9 2
U1 1
U2 4
PU SCITEPRESS
PI SETUBAL
PA AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL
BN 978-989-758-395-7
PY 2020
BP 99
EP 107
DI 10.5220/0008952800990107
PG 9
WC Computer Science, Artificial Intelligence; Engineering, Manufacturing;
   Materials Science, Multidisciplinary; Physics, Applied
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Materials Science; Physics
GA BP9RW
UT WOS:000570769000009
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Androcec, D
AF Androcec, Darko
TI Machine learning methods for toxic comment classification: a systematic
   review
SO ACTA UNIVERSITATIS SAPIENTIAE INFORMATICA
LA English
DT Review
DE machine learning; toxic comment; deep learning; systematic review
AB Nowadays users leave numerous comments on different social networks, news portals, and forums. Some of the comments are toxic or abusive. Due to numbers of comments, it is unfeasible to manually moderate them, so most of the systems use some kind of automatic discovery of toxicity using machine learning models. In this work, we performed a systematic review of the state-of-the-art in toxic comment classification using machine learning methods. We extracted data from 31 selected primary relevant studies. First, we have investigated when and where the papers were published and their maturity level. In our analysis of every primary study we investigated: data set used, evaluation metric, used machine learning methods, classes of toxicity, and comment language. We finish our work with comprehensive list of gaps in current research and suggestions for future research themes related to online toxic comment classification problem.
C1 [Androcec, Darko] Univ Zagreb, Fac Org & Informat, Pavlinska 2, Varazhdin 42000, Croatia.
RP Androcec, D (corresponding author), Univ Zagreb, Fac Org & Informat, Pavlinska 2, Varazhdin 42000, Croatia.
EM dandrocec@foi.unizg.hr
NR 32
TC 0
Z9 0
U1 8
U2 10
PU SCIENDO
PI WARSAW
PA BOGUMILA ZUGA 32A, WARSAW, MAZOVIA, POLAND
SN 1844-6086
EI 2066-7760
J9 ACTA U SAPIEN INFORM
JI Acta Univ. Sapientiae Inform.
PD DEC
PY 2020
VL 12
IS 2
BP 205
EP 216
DI 10.2478/ausi-2020-0012
PG 12
WC Computer Science, Theory & Methods
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA PR5HL
UT WOS:000607267500003
OA gold
DA 2022-04-17
ER

PT C
AU Ferreira, L
   Pilastri, A
   Martins, CM
   Pires, PM
   Cortez, P
AF Ferreira, Luis
   Pilastri, Andre
   Martins, Carlos Manuel
   Pires, Pedro Miguel
   Cortez, Paulo
GP IEEE
TI A Comparison of AutoML Tools for Machine Learning, Deep Learning and
   XGBoost
SO 2021 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
LA English
DT Proceedings Paper
CT International Joint Conference on Neural Networks (IJCNN)
CY JUL 18-22, 2021
CL ELECTR NETWORK
SP Int Neural Network Soc, IEEE Computat Intelligence Soc
DE Automated Deep Learning (AutoDL); Automated Machine Learning (AutoML);
   Benchmarking; Classification; Neural Architecture Search (NAS);
   Regression; Software; Supervised Learning
AB This paper presents a benchmark of supervised Automated Machine Learning (AutoML) tools. Firstly, we analyze the characteristics of eight recent open-source AutoML tools (Auto-Keras, Auto-PyTorch, Auto-Sklearn, AutoGluon, H2O AutoML, rminer, TPOT and TransmogrifAI) and describe twelve popular OpenML datasets that were used in the benchmark (divided into regression, binary and multi-class classification tasks). Then, we perform a comparison study with hundreds of computational experiments based on three scenarios: General Machine Learning (GML), Deep Learning (DL) and XGBoost (XGB). To select the best tool, we used a lexicographic approach, considering first the average prediction score for each task and then the computational effort. The best predictive results were achieved for GML, which were further compared with the best OpenML public results. Overall, the best GML AutoML tools obtained competitive results, outperforming the best OpenML models in five datasets. These results confirm the potential of the general-purpose AutoML tools to fully automate the Machine Learning (ML) algorithm selection and tuning.
C1 [Ferreira, Luis] Univ Minho, ALGORITMI Ctr, CCG ZGDV Inst, EPMQ IT, Guimaraes, Portugal.
   [Pilastri, Andre] CCG ZGDV Inst, EPMQ IT, Guimaraes, Portugal.
   [Martins, Carlos Manuel; Pires, Pedro Miguel] WeDo Technol, Braga, Portugal.
   [Cortez, Paulo] Univ Minho, Dept Informat Syst, ALGORITMI Ctr, Guimaraes, Portugal.
RP Ferreira, L (corresponding author), Univ Minho, ALGORITMI Ctr, CCG ZGDV Inst, EPMQ IT, Guimaraes, Portugal.
EM luis.ferreira@ccg.pt; andre.pilastri@ccg.pt;
   carlosmmartins@mobileum.com; pedro.mpires@mobileum.com;
   pcortez@dsi.uminho.pt
RI Ferreira, Luís/AAX-9736-2021; Pilastri, Andre/AAH-9679-2020
OI Ferreira, Luís/0000-0002-4790-5128; Pilastri, Andre/0000-0002-4380-3220
FU Incentive System for Research and Technological Development, from the
   Thematic Operational Program Competitiveness of the national framework
   program - Portugal2020 [NUP: POCI-01-0247-FEDER-045220]
FX This work was executed under the project Opti-Edge: 5G Digital Services
   Optimization at the Edge, Individual Project, NUP:
   POCI-01-0247-FEDER-045220, co-funded by the Incentive System for
   Research and Technological Development, from the Thematic Operational
   Program Competitiveness of the national framework program -
   Portugal2020.
NR 34
TC 1
Z9 1
U1 10
U2 10
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2161-4393
BN 978-0-7381-3366-9
J9 IEEE IJCNN
PY 2021
DI 10.1109/IJCNN52387.2021.9534091
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BS4TO
UT WOS:000722581706043
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Park, MS
   Son, H
   Hyun, C
   Hwang, HJ
AF Park, Min Sue
   Son, Hwijae
   Hyun, Chongseok
   Hwang, Hyung Ju
TI Explainability of Machine Learning Models for Bankruptcy Prediction
SO IEEE ACCESS
LA English
DT Article
DE Predictive models; Bankruptcy; Data models; Machine learning; Companies;
   Feature extraction; Analytical models; Bankruptcy prediction; machine
   learning; explainable AI; feature importance
ID FEATURE-SELECTION; FINANCIAL RATIOS; NEURAL-NETWORKS; FIRMS
AB As the amount of data increases, it is more likely that the assumptions in the existing economic analysis model are unsatisfied or make it difficult to establish a new analysis model. Therefore, there has been increased demand for applying the machine learning methodology to bankruptcy prediction due to its high performance. By contrast, machine learning models usually operate as black-boxes but credit rating regulatory systems require the provisioning of appropriate information regarding credit rating standards. If machine learning models have sufficient interpretablility, they would have the potential to be used as effective analytical models in bankruptcy prediction. From this aspect, we study the explainability of machine learning models for bankruptcy prediction by applying the Local Interpretable Model-Agnostic Explanations (LIME) algorithm, which measures the feature importance for each data point. To compare how the feature importance measured through LIME differs from that of models themselves, we first applied this algorithm to typical tree-based models that have ability to measure the feature importance of the models themselves. We showed that the feature importance measured through LIME could be a consistent generalization of the feature importance measured by tree-based models themselves. Moreover, we study the consistency of the feature importance through the model's predicted bankruptcy probability, which suggests the possibility that observations of important features can be used as a basis for the fair treatment of loan eligibility requirements.
C1 [Park, Min Sue; Hwang, Hyung Ju] Pohang Univ Sci & Technol, Dept Math, Pohang 790784, South Korea.
   [Son, Hwijae] Korea Adv Inst Sci & Technol, Stochast Anal & Applicat Res Ctr, Daejeon 34141, South Korea.
   [Hyun, Chongseok] BNK Financial Grp Inc, Busan 48400, South Korea.
   [Hwang, Hyung Ju] Pohang Univ Sci & Technol, Grad Sch Artificial Intelligence, Pohang 790784, South Korea.
RP Hwang, HJ (corresponding author), Pohang Univ Sci & Technol, Dept Math, Pohang 790784, South Korea.; Hwang, HJ (corresponding author), Pohang Univ Sci & Technol, Grad Sch Artificial Intelligence, Pohang 790784, South Korea.
EM hjhwang@postech.ac.kr
OI Park, Min Sue/0000-0002-8766-6934
FU National Research Foundation of Korea (NRF) Grants through Korean
   Government [Ministry of Science and ICT (MSIT)]
   [NRF-2017R1E1A1A03070105, NRF-2019R1A5A1028324]; Institute for the
   Information and Communications Technology Promotion (IITP) Grant through
   Korean Government [Ministry of Science, ICT and Future Planning (MSIP)]
   [2019-0-01906]; Information Technology Research Center (ITRC)
   [IITP-2020-2018-0-01441]
FX This work was supported in part by the National Research Foundation of
   Korea (NRF) Grants through Korean Government [Ministry of Science and
   ICT (MSIT)] under Grant NRF-2017R1E1A1A03070105 and Grant
   NRF-2019R1A5A1028324, in part by the Institute for the Information and
   Communications Technology Promotion (IITP) Grant through Korean
   Government [Ministry of Science, ICT and Future Planning (MSIP)]
   [Artificial Intelligence Graduate School Program (Pohang University of
   Science and Technology (POSTECH))] under Grant 2019-0-01906, and in part
   by the Information Technology Research Center (ITRC) Support Program
   under Grant IITP-2020-2018-0-01441.
NR 41
TC 2
Z9 2
U1 21
U2 25
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 124887
EP 124899
DI 10.1109/ACCESS.2021.3110270
PG 13
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Telecommunications
GA UQ4YC
UT WOS:000696069600001
OA gold
DA 2022-04-17
ER

PT J
AU Guo, X
   Zhang, YD
   Lu, SY
   Lu, ZH
AF Guo, Xing
   Zhang, Yu-Dong
   Lu, Siyuan
   Lu, Zhihai
TI A Survey on Machine Learning in COVID-19 Diagnosis
SO CMES-COMPUTER MODELING IN ENGINEERING & SCIENCES
LA English
DT Review
DE COVID-19 diagnosis; machine learning; deep learning; deep neural network
ID FEATURE-SELECTION; EXPLAINABLE AI; CLASSIFICATION; PNEUMONIA; FRAMEWORK;
   NETWORK; SEGMENTATION; LOCALIZATION; EXTRACTION; ALGORITHM
AB Since Corona Virus Disease 2019 outbreak, many expert groups worldwide have studied the problem and proposed many diagnostic methods. This paper focuses on the research of Corona Virus Disease 2019 diagnosis. First, the procedure of the diagnosis based on machine learning is introduced in detail, which includes medical data collection, image preprocessing, feature extraction, and image classification. Then, we review seven methods in detail: transfer learning, ensemble learning, unsupervised learning and semi-supervised learning, convolutional neural networks, graph neural networks, explainable deep neural networks, and so on. What's more, the advantages and limitations of different diagnosis methods are compared. Although the great achievements in medical images classification in recent years, Corona Virus Disease 2019 images classification based on machine learning still encountered many problems. For example, the highly unbalanced dataset, the difficulty of collecting labeled data, and the poor quality of the data. Aiming at these problems, we propose some solutions and provide a comprehensive presentation for future research.
C1 [Guo, Xing; Lu, Zhihai] Nanjing Normal Univ, Sch Educ Sci, Nanjing 210023, Peoples R China.
   [Zhang, Yu-Dong; Lu, Siyuan] Univ Leicester, Sch Informat, Leicester LE1 7RH, Leics, England.
RP Lu, ZH (corresponding author), Nanjing Normal Univ, Sch Educ Sci, Nanjing 210023, Peoples R China.
EM luzhihai@njnu.edu.cn
RI Lu, Siyuan/ABE-7949-2020
NR 170
TC 2
Z9 2
U1 25
U2 25
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1526-1492
EI 1526-1506
J9 CMES-COMP MODEL ENG
JI CMES-Comp. Model. Eng. Sci.
PY 2022
VL 130
IS 1
BP 23
EP 71
DI 10.32604/cmes.2021.017679
EA SEP 2021
PG 49
WC Engineering, Multidisciplinary; Mathematics, Interdisciplinary
   Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Mathematics
GA XG7BR
UT WOS:000717043900001
OA gold
DA 2022-04-17
ER

PT J
AU Govindarajan, P
   Soundarapandian, RK
   Gandomi, AH
   Patan, R
   Jayaraman, P
   Manikandan, R
AF Govindarajan, Priya
   Soundarapandian, Ravichandran Kattur
   Gandomi, Amir H.
   Patan, Rizwan
   Jayaraman, Premaladha
   Manikandan, Ramachandran
TI Classification of stroke disease using machine learning algorithms
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Stroke; Tagging; Maximum entropy; Data pre-processing; Classification;
   Machine learning
ID ISCHEMIC-STROKE; RISK-FACTORS; PREDICTION; INTERSTROKE; COUNTRIES
AB This paper presents a prototype to classify stroke that combines text mining tools and machine learning algorithms. Machine learning can be portrayed as a significant tracker in areas like surveillance, medicine, data management with the aid of suitably trained machine learning algorithms. Data mining techniques applied in this work give an overall review about the tracking of information with respect to semantic as well as syntactic perspectives. The proposed idea is to mine patients' symptoms from the case sheets and train the system with the acquired data. In the data collection phase, the case sheets of 507 patients were collected from Sugam Multispecialty Hospital, Kumbakonam, Tamil Nadu, India. Next, the case sheets were mined using tagging and maximum entropy methodologies, and the proposed stemmer extracts the common and unique set of attributes to classify the strokes. Then, the processed data were fed into various machine learning algorithms such as artificial neural networks, support vector machine, boosting and bagging and random forests. Among these algorithms, artificial neural networks trained with a stochastic gradient descent algorithm outperformed the other algorithms with a higher classification accuracy of 95% and a smaller standard deviation of 14.69.
C1 [Govindarajan, Priya] SASTRA Deemed Univ, Dept Comp Sci, Kumbakonam, India.
   [Soundarapandian, Ravichandran Kattur; Jayaraman, Premaladha; Manikandan, Ramachandran] SASTRA Deemed Univ, Dept Informat & Commun Technol, Thanjavur, India.
   [Gandomi, Amir H.] Stevens Inst Technol, Sch Business, Hoboken, NJ 07030 USA.
   [Patan, Rizwan] Galgotias Univ, Sch Comp Sci & Engn, Greater Noida, India.
RP Gandomi, AH (corresponding author), Stevens Inst Technol, Sch Business, Hoboken, NJ 07030 USA.
EM priya@src.sastra.edu; raviks@it.sastra.edu; a.h.gandomi@stevens.edu;
   patan.rizwan@galgotiasuniversity.edu.in; premaladha@ict.sastra.edu;
   manikandan75@core.sastra.edu
RI Ramachandran, Manikandan/B-2783-2014; Jayaraman,
   Premaladha/AAE-7440-2021; Gandomi, Amir H/J-7595-2013; PATAN,
   RIZWAN/C-4451-2017
OI Ramachandran, Manikandan/0000-0001-6116-2132; Gandomi, Amir
   H/0000-0002-2798-0104; PATAN, RIZWAN/0000-0003-4878-1988; govindarajan,
   priya/0000-0001-5835-802X
NR 40
TC 12
Z9 13
U1 7
U2 19
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD FEB
PY 2020
VL 32
IS 3
SI SI
BP 817
EP 828
DI 10.1007/s00521-019-04041-y
PG 12
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KJ4IY
UT WOS:000512022900016
DA 2022-04-17
ER

PT C
AU Li, QF
   Huang, ZC
   Lu, WJ
   Hong, C
   Qu, HE
   He, H
   Zhang, WZ
AF Li, Qifei
   Huang, Zhicong
   Lu, Wen-jie
   Hong, Cheng
   Qu, Hunter
   He, Hui
   Zhang, Weizhe
GP IEEE
TI HomoPAl: A Secure Collaborative Machine Learning Platform based on
   Homomorphic Encryption
SO 2020 IEEE 36TH INTERNATIONAL CONFERENCE ON DATA ENGINEERING (ICDE 2020)
SE IEEE International Conference on Data Engineering
LA English
DT Proceedings Paper
CT IEEE 36th International Conference on Data Engineering (ICDE)
CY APR 20-24, 2020
CL Dallas, TX
SP IEEE, IEEE Comp Soc
DE homomorphic encryption; machine learning
AB Homomorphic Encryption (HE) allows encrypted data to be processed without decryption, which could maximize the protection of user privacy without affecting the data utility. Thanks to strides made by cryptographers in the past few years, the efficiency of HE has been drastically improved, and machine learning on homomorphically encrypted data has become possible. Several works have explored machine learning based on HE, but most of them are restricted to the outsourced scenario, where all the data comes from a single data owner. We propose HomoPAl, an HE -based secure collaborative machine learning system, enabling a more promising scenario, where data from multiple data owners could be securely processed. Moreover, we integrate our system with the popular MPI framework to achieve parallel HE computations. Experiments show that our system can train a logistic regression model on millions of homomorphically encrypted data in less than two minutes.
C1 [Li, Qifei; He, Hui; Zhang, Weizhe] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Peoples R China.
   [Huang, Zhicong; Lu, Wen-jie; Hong, Cheng; Qu, Hunter] Alibaba Grp, Gemini Lab, Hangzhou, Peoples R China.
   [Li, Qifei] Alibaba Grp, Hangzhou, Peoples R China.
RP Li, QF (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Peoples R China.
EM 7feilee@gmail.com; zhicong.hzc@alibaba-inc.com;
   juhou.lwj@alibaba-inc.com; vince.hc@alibaba-inc.com;
   fuping.qfp@alibaba-inc.com; hehui@hit.edu.cn; wzzhang@hit.edu.cn
NR 14
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
SN 1084-4627
BN 978-1-7281-2903-7
J9 PROC INT CONF DATA
PY 2020
BP 1713
EP 1717
DI 10.1109/ICDE48307.2020.00152
PG 5
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ3CR
UT WOS:000584252700145
DA 2022-04-17
ER

PT C
AU Li, RG
   Liu, M
   Xu, DW
   Gao, JQ
   Wu, FD
   Zhu, LH
AF Li, Ruiguang
   Liu, Ming
   Xu, Dawei
   Gao, Jiaqi
   Wu, Fudong
   Zhu, Liehuang
BE Lu, W
   Zhang, Y
   Wen, W
   Yan, H
   Li, C
TI A Review of Machine Learning Algorithms for Text Classification
SO CYBER SECURITY, CNCERT 2021
SE Communications in Computer and Information Science
LA English
DT Proceedings Paper
CT 18th Annual Conference on China Cyber Security (CNCERT)
CY JUL 20-21, 2021
CL Beijing, PEOPLES R CHINA
DE Natural language processing; Text classification; Machine learning;
   Neural network
AB Text classification is a basic task in the field of natural language processing, and it is a basic technology for information retrieval, questioning and answering system, emotion analysis and other advanced tasks. It is one of the earliest application of machine learning algorithm, and has achieved good results. In this paper, we made a review of the traditional and state-of-the-art machine learning algorithms for text classification, such as Naive Bayes, Supporting Vector Machine, Decision Tree, K Nearest Neighbor, Random Forest and neural networks. Then, we discussed the advantages and disadvantages of all kinds of machine learning algorithms in depth. Finally, we made a summary that neural networks and deep learning will become the main research topic in the future.
C1 [Li, Ruiguang; Xu, Dawei; Zhu, Liehuang] Beijing Inst Technol, Sch Cyberspace Sci & Technol, Beijing, Peoples R China.
   [Li, Ruiguang; Liu, Ming] Coordinat Ctr China, Natl Comp Network Emergency Response Tech Team, Beijing, Peoples R China.
   [Xu, Dawei; Gao, Jiaqi; Wu, Fudong] Changchun Univ, Changchun, Peoples R China.
RP Li, RG (corresponding author), Beijing Inst Technol, Sch Cyberspace Sci & Technol, Beijing, Peoples R China.; Li, RG (corresponding author), Coordinat Ctr China, Natl Comp Network Emergency Response Tech Team, Beijing, Peoples R China.
EM lrg@cert.org.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [U2003206, 62106060]
FX This work was supported by the National Natural Science Foundation of
   China under Grant U2003206 and 62106060.
NR 6
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER-VERLAG SINGAPORE PTE LTD
PI SINGAPORE
PA 152 BEACH ROAD, #21-01/04 GATEWAY EAST, SINGAPORE, 189721, SINGAPORE
SN 1865-0929
EI 1865-0937
BN 978-981-16-9229-1; 978-981-16-9228-4
J9 COMM COM INF SC
PY 2022
VL 1506
BP 226
EP 234
DI 10.1007/978-981-16-9229-1_14
PG 9
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS7QF
UT WOS:000765993900014
OA hybrid
DA 2022-04-17
ER

PT J
AU Lee, I
   Shin, YJ
AF Lee, In
   Shin, Yong Jae
TI Machine learning for enterprises: Applications, algorithm selection, and
   challenges
SO BUSINESS HORIZONS
LA English
DT Article
DE Machine learning; Artificial intelligence; Deep learning; Big data;
   Neural networks; Chatbot; Innovation capability; Resources and
   capabilities
AB Machine learning holds great promise for lowering product and service costs, speeding up business processes, and serving customers better. It is recognized as one of the most important application areas in this era of unprecedented technological development, and its adoption is gaining momentum across almost all industries. In view of this, we offer a brief discussion of categories of machine learning and then present three types of machine-learning usage at enterprises. We then discuss the trade-off between the accuracy and interpretability of machine-learning algorithms, a crucial consideration in selecting the right algorithm for the task at hand. We next outline three cases of machine-learning development in financial services. Finally, we discuss challenges all managers must confront in deploying machine-learning applications. (C) 2019 Kelley School of Business, Indiana University. Published by Elsevier Inc. All rights reserved.
C1 [Lee, In] Western Illinois Univ, Sch Comp Sci, Macomb, IL 61455 USA.
   [Shin, Yong Jae] Hankyong Natl Univ, Anseong 17579, South Korea.
RP Shin, YJ (corresponding author), Hankyong Natl Univ, Anseong 17579, South Korea.
EM i-lee@wiu.edu; yjshin@hknu.ac.kr
RI SHIN, YONG JAE/AAJ-2870-2020
NR 60
TC 41
Z9 42
U1 19
U2 70
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0007-6813
EI 1873-6068
J9 BUS HORIZONS
JI Bus. Horiz.
PD MAR-APR
PY 2020
VL 63
IS 2
SI SI
BP 157
EP 170
DI 10.1016/j.bushor.2019.10.005
PG 14
WC Business
WE Social Science Citation Index (SSCI)
SC Business & Economics
GA KR8FX
UT WOS:000517852500004
DA 2022-04-17
ER

PT C
AU Senthil, KK
   Kavethanjali, V
   Preethi, S
   Vasanthapriya, V
AF Senthil, Kumar K.
   Kavethanjali, V
   Preethi, S.
   Vasanthapriya, V.
GP IEEE
TI Lung - Pleura Carcinoma Detection Using Machine Learning
SO ICSPC'21: 2021 3RD INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND
   COMMUNICATION (ICPSC)
SE International Conference on Signal Processing and Communications SPCOM
LA English
DT Proceedings Paper
CT 3rd International Conference on Signal Processing and Communication
   (ICPSC)
CY MAY 13-14, 2021
CL Coimbatore, INDIA
SP Karunya Inst Technol & Sci, Dept Elect & Commun Engn, IEEE
DE Lung Diseases; Pleural-Carcinoma detection; Classifications; Machine
   Learning Algorithms and Comparative Analysis
AB Identification of pleural carcinoma using classification equipment with 98.30% accuracy is presented in this work. To evaluate the effectiveness of the Machine Learning Algorithms, which is divided into clinical, and health data from patients who were part of the collection of lung cancer diagnostic data. These algorithms used to predict and analyze the effectiveness of various machine-learning algorithms associated with lung disease based on medical and patient health data and to guide patients and physicians in early detection or early treatment options. Separation processes are performed with different machine learning algorithms and success levels are indicated. Various algorithms were tested to achieve success rates of approximately 98.30% obtained. Among the tried algorithms, Linear Discriminant Analysis provides the most effective isolation process.
C1 [Senthil, Kumar K.; Kavethanjali, V; Preethi, S.; Vasanthapriya, V.] Rajalakshmi Inst Technol, Dept Elect & Commun, Chennai, Tamil Nadu, India.
RP Senthil, KK (corresponding author), Rajalakshmi Inst Technol, Dept Elect & Commun, Chennai, Tamil Nadu, India.
EM senthilkumar.k@ritchennai.edu.in;
   kavethanjali.v.2017.ece@ritchennai.edu.in;
   preethi.s.2017.ece@ritchennai.edu.in;
   vasanthapriya.v.2017.ece@ritchennai.edu.in
OI K, Senthil Kumar/0000-0002-3220-6201
NR 20
TC 0
Z9 0
U1 1
U2 2
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2474-9168
EI 2474-915X
BN 978-1-6654-2864-4
J9 INT CO SIG PROC COMM
PY 2021
BP 294
EP 298
DI 10.1109/ICSPC51351.2021.9451769
PG 5
WC Engineering, Electrical & Electronic; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering; Telecommunications
GA BS1DM
UT WOS:000687834500062
DA 2022-04-17
ER

PT J
AU Kim, DH
   Boo, SB
   Hong, HC
   Yeo, WG
   Lee, NY
AF Kim, Dae-Hyun
   Boo, Seung Bin
   Hong, Hyeon Cheol
   Yeo, Won Gu
   Lee, Nam Yong
TI Machine Vision-based Defect Detection Using Deep Learning Algorithm
SO JOURNAL OF THE KOREAN SOCIETY FOR NONDESTRUCTIVE TESTING
LA Korean
DT Article
DE Deep Learning; AI; Machine vision; Defect detection
AB Currently, there are numerous methods for detecting product defects by combining deep learning and machine vision, which are the core technologies of the fourth industrial revolution. In this study, we have developed a software that can identify defects, based on deep learning and machine vision, using the Keras open source library. The software was used to determine the defect based on an image of the regular product, and then identify its location using probability distribution. In addition, three verification experiments were carried out, the first which is a basic verification experiment, using an image produced by an image editor, the second, using an assembly block; and finally, a semi-real application experiment using an electric bread-board. Through these experiments, it was confirmed that machine vision-based defect detection system using deep learning algorithm could idetify the defects and pinpoint their locations.
C1 [Kim, Dae-Hyun; Boo, Seung Bin; Hong, Hyeon Cheol; Yeo, Won Gu; Lee, Nam Yong] Seoul Natl Univ Sci & Technol, Dept Mech & Automot Engn, Seoul, South Korea.
RP Kim, DH (corresponding author), Seoul Natl Univ Sci & Technol, Dept Mech & Automot Engn, Seoul, South Korea.
EM dkim@seoultech.ac.kr
NR 7
TC 1
Z9 1
U1 12
U2 29
PU KOREAN SOC NONDESTRUCTIVE TESTING
PI SEOUL
PA KOREA SCIENCE & TECHNOLOGY BLDG, RM 710, 635-4, YEOKSAM-DONG,
   KANGNAM-GU, SEOUL, 135-703, SOUTH KOREA
SN 1225-7842
EI 2287-402X
J9 J KOREAN SOC NONDES
JI J. Korean Soc. Nondestruct. Test.
PD FEB
PY 2020
VL 40
IS 1
BP 47
EP 52
DI 10.7779/JKSNT.2020.40.1.47
PG 6
WC Materials Science, Characterization & Testing
WE Emerging Sources Citation Index (ESCI)
SC Materials Science
GA KU8EX
UT WOS:000519946000007
DA 2022-04-17
ER

PT J
AU Tummalapalli, S
   Kumar, L
   Neti, LBM
   Krishna, A
AF Tummalapalli, Sahithi
   Kumar, Lov
   Neti, Lalita Bhanu Murthy
   Krishna, Aneesh
TI Detection of web service anti-patterns using weighted extreme learning
   machine
SO COMPUTER STANDARDS & INTERFACES
LA English
DT Article
DE Anti-Pattern; Weighted extreme learning machine (WELM); Extreme learning
   machine (ELM); Service-Oriented architecture; Web service; Source code
   metric
ID SUPPORT VECTOR MACHINE
AB 'Anti-Pattern' is a term often used by software engineers and practitioners nowadays. An anti-pattern is a supplement of the design pattern. Similar to design patterns, an anti-pattern is a template and a repeatable way of solving a specific problem, but in a non-optimal and ineffective way. Therefore, there is a requirement for the timely identification and modification of anti-patterns to increase software systems performance and efficiency. Anti-pattern detection using the source code metric can be used as an initial step in the software development life cycle, both to reduce the maintenance of the software system and to improve the quality of the software. The work in this paper empirically investigates the effectiveness of two machine learning algorithms, i.e., Extreme Learning Machine (ELM) and Weighted Extreme Learning Machine (WELM), with four different kernels in detecting web service anti-patterns. This work also investigates the application of different aggregation techniques and data sampling techniques to handle imbalanced data in predicting five different anti-patterns. The inference of this research is studied over 226 WSDL (Web Service Description Language) files. The experimental findings reveal that the model developed by WELM has superior prediction accuracy compared to the model developed by ELM.
C1 [Tummalapalli, Sahithi; Kumar, Lov; Neti, Lalita Bhanu Murthy] BITS Pilani, Hyderabad Campus, Hyderabad, India.
   [Krishna, Aneesh] Curtin Univ, Perth, WA, Australia.
RP Tummalapalli, S (corresponding author), BITS Pilani, Hyderabad Campus, Hyderabad, India.
EM sahithitummalapalli@gmail.com; lovkumar@hyderabad.bits-pilani.ac.in;
   bhanu@hyderabad.bits-pilani.ac.in; A.Krishna@curtin.edu.au
NR 47
TC 0
Z9 0
U1 4
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0920-5489
EI 1872-7018
J9 COMPUT STAND INTER
JI Comput. Stand. Interfaces
PD AUG
PY 2022
VL 82
AR 103621
DI 10.1016/j.csi.2022.103621
PG 15
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YN3BE
UT WOS:000747135500001
DA 2022-04-17
ER

PT J
AU Horvat, T
   Job, J
AF Horvat, Tomislav
   Job, Josip
TI The use of machine learning in sport outcome prediction: A review
SO WILEY INTERDISCIPLINARY REVIEWS-DATA MINING AND KNOWLEDGE DISCOVERY
LA English
DT Review
DE learning algorithms; machine learning; outcome prediction; sport
ID NETWORKS; GAME
AB The increase in the volume of structured and unstructured data related to more than just sport events leads to the development and increased use of techniques that extract information and employ machine-learning algorithms in predicting process outcomes based on input but not necessarily output data. Taking sports into consideration, predicting outcomes, and extracting valuable information has become appealing not only to sports workers but also to the wider audience, particularly in the areas of team management and sports betting. The aim of this article is to review the existing machine learning (ML) algorithms in predicting sport outcomes. Over 100 papers were analyzed and only some of these papers were taken into consideration. Almost all of the analyzed papers use some sort of feature selection and feature extraction, most often prior to using the machine-learning algorithm. As an evaluation method of ML algorithms, researchers, in most cases, use data segmentation with data being chronologically distributed. In addition to data segmentation, researchers also use thek-cross-evaluation method. Sport predictions are usually treated as a classification problem with one class being predicted and rare cases being predicted as numerical values. Mostly used ML models are neural networks using data segmentation. This article is categorized under: Technologies > Machine Learning Technologies > Prediction
C1 [Horvat, Tomislav] Univ North, Dept Elect Engn, 104,Brigade 3, Varazhdin, Croatia.
   [Job, Josip] Josip Juraj Strossmayer Univ Osijek, Fac Elect Engn Comp Sci & Informat Technol Osijek, Osijek, Croatia.
RP Horvat, T (corresponding author), Univ North, Dept Elect Engn, 104,Brigade 3, Varazhdin, Croatia.
EM tomislav.horvat@unin.hr
OI Job, Josip/0000-0002-6998-5907; Horvat, Tomislav/0000-0002-8358-3218
FU University North; Faculty of Electrical Engineering, Computer Science,
   and Information Technology Osijek, Josip Juraj Strossmayer University of
   Osijek
FX This work serves as an initial stage in the development of a doctoral
   dissertation on the outcome prediction in sport and was supported by the
   University North and Faculty of Electrical Engineering, Computer
   Science, and Information Technology Osijek, Josip Juraj Strossmayer
   University of Osijek.
NR 63
TC 12
Z9 12
U1 17
U2 36
PU WILEY PERIODICALS, INC
PI SAN FRANCISCO
PA ONE MONTGOMERY ST, SUITE 1200, SAN FRANCISCO, CA 94104 USA
SN 1942-4787
EI 1942-4795
J9 WIRES DATA MIN KNOWL
JI Wiley Interdiscip. Rev.-Data Mining Knowl. Discov.
PD SEP
PY 2020
VL 10
IS 5
AR e1380
DI 10.1002/widm.1380
EA JUN 2020
PG 28
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA NE7SG
UT WOS:000544029400001
DA 2022-04-17
ER

PT J
AU Guan, QY
   Qu, ZS
   Zeng, M
   Zhao, PB
   Liu, JY
AF Guan, Qiuyu
   Qu, Zhenshen
   Zeng, Ming
   Zhao, Pengbo
   Liu, Junyu
TI Feasibility analysis of machine learning applied to magnetized plasma
   diagnosis
SO CONTRIBUTIONS TO PLASMA PHYSICS
LA English
DT Article; Early Access
DE machine learning; magnetized plasma; probe diagnostics
AB In the paper, machine learning is demonstrated for the diagnostic enhancement of magnetized plasma probes. In the plasma experiment, the magnetic field greatly affects the properties of plasma and the performance of the probe, which limits the range of measurement parameters and reduces the accuracy of probe diagnostic results. Existing probe correction methods based on improved theory and mechanics cannot completely eliminate the influence of magnetic field and often introduce additional errors. In this paper, a novel machine learning method is proposed to improve magnetized plasma probe diagnostic based on existing methods and traditional probe correction theory. The pressure of the plasma, the total voltage of the circuit, and the magnetic induction intensity are used as input parameters, and the electron density obtained from the probe diagnostics are used as output parameters. The paper presents experiments to analyse the original probe results and the probe results revised by magnetic field probe theory through the machine learning algorithm and compare them with the results of theoretical simulations. The experimental results prove that the machine learning model based on revised data has better learning efficiency and prediction results, which can expand the application scope of traditional probe correction theory and predict results closer to the theoretical value.
C1 [Guan, Qiuyu; Qu, Zhenshen; Zeng, Ming; Zhao, Pengbo] Harbin Inst Technol, Space Control & Inertial Technol Res Ctr, Harbin, Peoples R China.
   [Liu, Junyu] Kyoto Univ, Grad Sch Informat, Kyoto, Japan.
RP Qu, ZS (corresponding author), Harbin Inst Technol, Space Control & Inertial Technol Res Ctr, Harbin, Peoples R China.
EM miraland@hit.edu.cn
NR 18
TC 0
Z9 0
U1 3
U2 3
PU WILEY-V C H VERLAG GMBH
PI WEINHEIM
PA POSTFACH 101161, 69451 WEINHEIM, GERMANY
SN 0863-1042
EI 1521-3986
J9 CONTRIB PLASM PHYS
JI Contrib. Plasma Phys.
AR e202100152
DI 10.1002/ctpp.202100152
EA FEB 2022
PG 10
WC Physics, Fluids & Plasmas
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Physics
GA YX6BI
UT WOS:000754185700001
DA 2022-04-17
ER

PT J
AU Le, DH
AF Duc-Hau Le
TI Machine learning-based approaches for disease gene prediction
SO BRIEFINGS IN FUNCTIONAL GENOMICS
LA English
DT Review
DE disease gene prediction; machine learning; binary classification; unary
   classification; semi-supervised learning; advanced learning models
ID NETWORK MEDICINE; RANDOM-WALK; TOPOLOGICAL FEATURES; PRIORITIZATION;
   DATABASE; SUPPORT; KERNEL; CLASSIFICATION; ASSOCIATIONS; PROTEINS
AB Disease gene prediction is an essential issue in biomedical research. In the early days, annotation-based approaches were proposed for this problem. With the development of high-throughput technologies, interaction data between genes/proteins have grown quickly and covered almost genome and proteome; thus, network-based methods for the problem become prominent. In parallel, machine learning techniques, which formulate the problem as a classification, have also been proposed. Here, we firstly show a roadmap of the machine learning-based methods for the disease gene prediction. In the beginning, the problem was usually approached using a binary classification, where positive and negative training sample sets are comprised of disease genes and non-disease genes, respectively. The disease genes are ones known to be associated with diseases; meanwhile, non-disease genes were randomly selected from those not yet known to be associated with diseases. However, the later may contain unknown disease genes. To overcome this uncertainty of defining the non-disease genes, more realistic approaches have been proposed for the problem, such as unary and semi-supervised classification. Recently, more advanced methods, including ensemble learning, matrix factorization and deep learning, have been proposed for the problem. Secondly, 12 representative machine learning-based methods for the disease gene prediction were examined and compared in terms of prediction performance and running time. Finally, their advantages, disadvantages, interpretability and trust were also analyzed and discussed.
C1 [Duc-Hau Le] Vingrp Big Data Inst, Dept Computat Biomed, Hanoi, Vietnam.
RP Le, DH (corresponding author), Vingrp Big Data Inst, Dept Computat Biomed, Hanoi, Vietnam.
EM hauldhut@gmail.com
OI Le, Duc-Hau/0000-0002-4951-5916
FU Vietnam National Foundation for Science and Technology Development
   (NAFOSTED)National Foundation for Science & Technology Development
   (NAFOSTED) [102.01-2017.14]
FX This research is funded by Vietnam National Foundation for Science and
   Technology Development (NAFOSTED) under grant number 102.01-2017.14.
NR 117
TC 2
Z9 2
U1 7
U2 22
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 2041-2649
EI 2041-2657
J9 BRIEF FUNCT GENOMICS
JI Brief. Funct. Genomics
PD SEP-NOV
PY 2020
VL 19
IS 5-6
BP 350
EP 363
DI 10.1093/bfgp/elaa013
PG 14
WC Biotechnology & Applied Microbiology; Genetics & Heredity
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biotechnology & Applied Microbiology; Genetics & Heredity
GA PS6OK
UT WOS:000608045700004
PM 32567652
DA 2022-04-17
ER

PT J
AU Akcay, M
   Etiz, D
   Celik, O
   Ozen, A
AF Akcay, Melek
   Etiz, Durmus
   Celik, Ozer
   Ozen, Alaattin
TI Evaluation of Prognosis in Nasopharyngeal Cancer Using Machine Learning
SO TECHNOLOGY IN CANCER RESEARCH & TREATMENT
LA English
DT Article
DE nasopharyngeal cancer; radiotherapy; prognosis; machine learning
ID INTENSITY-MODULATED RADIOTHERAPY; BARR-VIRUS DNA; NEUTROPHIL-LYMPHOCYTE
   RATIO; LACTATE-DEHYDROGENASE LEVEL; LONG-TERM SURVIVAL; POOR-PROGNOSIS;
   CARCINOMA; PREDICTS; ANEMIA
AB Background and Aim:
   Although the prognosis of nasopharyngeal cancer largely depends on a classification based on the tumor-lymph node metastasis staging system, patients at the same stage may have different clinical outcomes. This study aimed to evaluate the survival prognosis of nasopharyngeal cancer using machine learning.
   Settings and Design:
   Original, retrospective.
   Materials and Methods:
   A total of 72 patients with a diagnosis of nasopharyngeal cancer who received radiotherapy +/- chemotherapy were included in the study. The contribution of patient, tumor, and treatment characteristics to the survival prognosis was evaluated by machine learning using the following techniques: logistic regression, artificial neural network, XGBoost, support-vector clustering, random forest, and Gaussian Naive Bayes.
   Results:
   In the analysis of the data set, correlation analysis, and binary logistic regression analyses were applied. Of the 18 independent variables, 10 were found to be effective in predicting nasopharyngeal cancer-related mortality: age, weight loss, initial neutrophil/lymphocyte ratio, initial lactate dehydrogenase, initial hemoglobin, radiotherapy duration, tumor diameter, number of concurrent chemotherapy cycles, and T and N stages. Gaussian Naive Bayes was determined as the best algorithm to evaluate the prognosis of machine learning techniques (accuracy rate: 88%, area under the curve score: 0.91, confidence interval: 0.68-1, sensitivity: 75%, specificity: 100%).
   Conclusion:
   Many factors affect prognosis in cancer, and machine learning algorithms can be used to determine which factors have a greater effect on survival prognosis, which then allows further research into these factors. In the current study, Gaussian Naive Bayes was identified as the best algorithm for the evaluation of prognosis of nasopharyngeal cancer.
C1 [Akcay, Melek; Etiz, Durmus; Ozen, Alaattin] Osmangazi Univ, Dept Radiat Oncol, Fac Med, TR-26480 Eskisehir, Turkey.
   [Celik, Ozer] Eskisehir Osmangazi Univ, Dept Math Comp, Eskisehir, Turkey.
RP Akcay, M (corresponding author), Osmangazi Univ, Dept Radiat Oncol, Fac Med, TR-26480 Eskisehir, Turkey.
EM mcakcay@ogu.edu.tr
RI Çelik, Özer/AAF-5237-2021; Etiz, Durmuş/AAB-1660-2020; Özen,
   Alaattin/ABG-9988-2020; YAKAR, Melek/V-8395-2019
OI Çelik, Özer/0000-0002-4409-3101; Etiz, Durmuş/0000-0002-2225-0364; 
NR 46
TC 3
Z9 3
U1 0
U2 7
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1533-0346
EI 1533-0338
J9 TECHNOL CANCER RES T
JI Technol. Cancer Res. Treat.
PD MAR 5
PY 2020
VL 19
AR 1533033820909829
DI 10.1177/1533033820909829
PG 9
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA LA9KQ
UT WOS:000524259500001
PM 32138606
OA Green Published, gold
DA 2022-04-17
ER

PT C
AU Chowanda, A
   Sutoyo, R
   Meiliana
   Tanachutiwat, S
AF Chowanda, Andry
   Sutoyo, Rhio
   Meiliana
   Tanachutiwat, Sansiri
BE Budiharto, W
   Kurniawan, A
   Suhartono, D
   Chowanda, A
   Gunawan, AAS
   Udjaja, Y
TI Exploring Text-based Emotions Recognition Machine Learning Techniques on
   Social Media Conversation
SO 5TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND COMPUTATIONAL
   INTELLIGENCE 2020
SE Procedia Computer Science
LA English
DT Proceedings Paper
CT 5th International Conference on Computer Science and Computational
   Intelligence (ICCSCI)
CY NOV 19-20, 2020
CL ELECTR NETWORK
DE Machine Learning; Emotions Recognition; Social Media; Text-based
   Emotions
AB Emotions hold a paramount role in the conversation, as it expresses context to the conversation. Text/word in conversation consists of lexical and contextual meanings. Extracting emotions from text has been an interesting work recent thees years. With the advancement of machine learning techniques and hardware to support the machine learning process, recognising emotions from a text with machine learning provides promising and significant results. This research aims to explore several popular machine learning to recognise emotions from a conversation in social media. The algorithms proposed in this research are ranged from traditional machine learning to deep learning techniques. The dataset used in this paper is provided by AffectiveTweets, with a baseline of F1 S core of 0.71 with word N-grams and SentiStrength. The research contributes extensive explorations in a number of machine learning algorithms, resulting in a total of 2302 features sets were explored, where each features sets has 100-1000 features extracted from the text. The results demonstrate Generalised Linear Model provides the best Accuracy score (0.92), Recall (0.902), Precision (0.902), Fl score (0.901) with standard deviation of accuracy of 1, 2%. (C) 2021 The Authors. Published by Elsevier B.V.
C1 [Chowanda, Andry; Sutoyo, Rhio; Meiliana] Bina Nusantara Univ, Sch Comp Sci, Comp Sci Dept, Jakarta 11480, Indonesia.
   [Tanachutiwat, Sansiri] King Mongkuts Univ Technol North Bangkok, Sirindhorn Int TGGS, Bangkok, Thailand.
RP Chowanda, A (corresponding author), Bina Nusantara Univ, Sch Comp Sci, Comp Sci Dept, Jakarta 11480, Indonesia.
EM achowanda@binus.edu
RI Chowanda, Andry/AFS-4986-2022; Chowanda, Andry/C-3146-2016
OI Chowanda, Andry/0000-0002-2150-414X; Chowanda, Andry/0000-0002-2150-414X
FU Directorate General of Research and Development Strengthening,
   Indonesian Ministry of Research, Technology, and Higher
   EducationMinistry of Research and Technology of the Republic of
   Indonesia (RISTEK) [225/SP2H/LT/DRPM/2019, 088/LL3/PG/2020,
   039/VR.RTT/IV/2019]
FX This work is supported by Directorate General of Research and
   Development Strengthening, Indonesian Ministry of Research, Technology,
   and Higher Education, as a part of Penelitian Terapan Unggulan Perguruan
   Tinggi Research Grant to Binus University titled "Perancangan Model
   Komputasi untuk Komunikasi Dyadic dengan Menggunakan Algoritma Deep
   Learning" or "Designing a Computational Model for Dyadic Communication
   Using a Deep Learning Algorithm" with contract number:
   225/SP2H/LT/DRPM/2019, 088/LL3/PG/2020, 039/VR.RTT/IV/2019. We also
   would like to extend our gratitute to NVIDIA Corporation with the
   donation of the Titan V Pascal GPU used for this research.
NR 17
TC 1
Z9 1
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0509
J9 PROCEDIA COMPUT SCI
PY 2021
VL 179
BP 821
EP 828
DI 10.1016/j.procs.2021.01.099
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR5DK
UT WOS:000654256300102
OA gold
DA 2022-04-17
ER

PT J
AU Vaka, AR
   Soni, B
   Reddy, KS
AF Vaka, Anji Reddy
   Soni, Badal
   Reddy, Sudheer K.
TI Breast cancer detection by leveraging Machine Learning
SO ICT EXPRESS
LA English
DT Article
DE Machine Learning; Classification; Breast cancer; Deep learning
AB India has witnessed 30% of the cases of breast cancer during the last few years and it is likely to increase. Breast cancer in India accounts that one woman is diagnosed every two minutes and every nine minutes, one woman dies. Early detection and diagnosis can save the lives of cancer patients. This paper presents a novel method to detect breast cancer by employing techniques of Machine Learning. The authors carried out an experimental analysis on a dataset to evaluate the performance. The proposed method has produced highly accurate and efficient results when compared to the existing methods. (C) 2020 The Korean Institute of Communications and Information Sciences (KICS). Publishing services by Elsevier B.V.
C1 [Vaka, Anji Reddy; Soni, Badal] Natl Inst Technol, Dept CSE, Silchar, India.
EM sudheercse@gmail.com
RI K, Sudheer Reddy/AAF-6553-2019
OI K, Sudheer Reddy/0000-0001-5371-9869
NR 9
TC 20
Z9 20
U1 6
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2405-9595
J9 ICT EXPRESS
JI ICT Express
PD DEC
PY 2020
VL 6
IS 4
BP 320
EP 324
DI 10.1016/j.icte.2020.04.009
PG 5
WC Computer Science, Information Systems; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA OX3GB
UT WOS:000593456300011
OA gold
DA 2022-04-17
ER

PT J
AU Tuladhar, A
   Gill, S
   Ismail, Z
   Forkert, ND
AF Tuladhar, Anup
   Gill, Sascha
   Ismail, Zahinoor
   Forkert, Nils D.
CA Alzheimers Dis Neuroimaging Initia
TI Building machine learning models without sharing patient data: A
   simulation-based analysis of distributed learning by ensembling
SO JOURNAL OF BIOMEDICAL INFORMATICS
LA English
DT Article
DE Artificial neural networks; Distributed learning; Machine learning;
   Medical information systems; Random forest; Support vector machines
ID PRIVACY
AB The development of machine learning solutions in medicine is often hindered by difficulties associated with sharing patient data. Distributed learning aims to train machine learning models locally without requiring data sharing. However, the utility of distributed learning for rare diseases, with only a few training examples at each contributing local center, has not been investigated. The aim of this work was to simulate distributed learning models by ensembling with artificial neural networks (ANN), support vector machines (SVM), and random forests (RF) and evaluate them using four medical datasets. Distributed learning by ensembling locally trained agents improved performance compared to models trained using the data from a single institution, even in cases where only a very few training examples are available per local center. Distributed learning improved when more locally trained models were added to the ensemble. Local class imbalance reduced distributed SVM performance but did not impact distributed RF and ANN classification. Our results suggest that distributed learning by ensembling can be used to train machine learning models without sharing patient data and is suitable to use with small datasets.
C1 [Tuladhar, Anup; Forkert, Nils D.] Univ Calgary, Dept Radiol, Calgary, AB, Canada.
   [Tuladhar, Anup; Gill, Sascha; Ismail, Zahinoor; Forkert, Nils D.] Univ Calgary, Hotchkiss Brain Inst, Calgary, AB, Canada.
   [Gill, Sascha; Ismail, Zahinoor; Forkert, Nils D.] Univ Calgary, Dept Clin Neurosci, Calgary, AB, Canada.
   [Ismail, Zahinoor] Univ Calgary, Dept Community Hlth Sci, Calgary, AB, Canada.
   [Ismail, Zahinoor] Univ Calgary, Dept Psychiat, Calgary, AB, Canada.
   [Ismail, Zahinoor] Univ Calgary, OBrien Inst Publ Hlth, Calgary, AB, Canada.
   [Forkert, Nils D.] Univ Calgary, Alberta Childrens Hosp Res Inst, Calgary, AB, Canada.
RP Tuladhar, A (corresponding author), 3330 Hosp Dr NW,HSC Bldg,Room 2913, Calgary, AB T2N 4N1, Canada.
EM anup.tuladhar@ucalgary.ca
RI Tuladhar, Anup/AAL-7139-2020; Forkert, Nils Daniel/K-6273-2012
OI Tuladhar, Anup/0000-0002-3942-2732; Forkert, Nils
   Daniel/0000-0003-2556-3224
FU Heart and Stroke Foundation of CanadaHeart & Stroke Foundation of Canada
   [G-17-0018368]; River Fund at Calgary Foundation; T. Chen Fong
   Fellowship in Medical Imaging Science
FX This work is supported by the Heart and Stroke Foundation of Canada
   Grant in aid (G-17-0018368), the River Fund at Calgary Foundation, and
   the T. Chen Fong Fellowship in Medical Imaging Science to AT.
NR 21
TC 6
Z9 7
U1 5
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1532-0464
EI 1532-0480
J9 J BIOMED INFORM
JI J. Biomed. Inform.
PD JUN
PY 2020
VL 106
AR 103424
DI 10.1016/j.jbi.2020.103424
PG 9
WC Computer Science, Interdisciplinary Applications; Medical Informatics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Medical Informatics
GA LY0VE
UT WOS:000540241000001
PM 32335226
OA Bronze
DA 2022-04-17
ER

PT J
AU Chan, MF
   Witztum, A
   Valdes, G
AF Chan, Maria F.
   Witztum, Alon
   Valdes, Gilmer
TI Integration of AI and Machine Learning in Radiotherapy QA
SO FRONTIERS IN ARTIFICIAL INTELLIGENCE
LA English
DT Review
DE artificial intelligence; machine learning; radiotherapy; quality
   assurance; IMRT; VMAT
AB The use of machine learning and other sophisticated models to aid in prediction and decision making has become widely popular across a breadth of disciplines. Within the greater diagnostic radiology, radiation oncology, and medical physics communities promising work is being performed in tissue classification and cancer staging, outcome prediction, automated segmentation, treatment planning, and quality assurance as well as other areas. In this article, machine learning approaches are explored, highlighting specific applications in machine and patient-specific quality assurance (QA). Machine learning can analyze multiple elements of a delivery system on its performance over time including the multileaf collimator (MLC), imaging system, mechanical and dosimetric parameters. Virtual Intensity-Modulated Radiation Therapy (IMRT) QA can predict passing rates using different measurement techniques, different treatment planning systems, and different treatment delivery machines across multiple institutions. Prediction of QA passing rates and other metrics can have profound implications on the current IMRT process. Here we cover general concepts of machine learning in dosimetry and various methods used in virtual IMRT QA, as well as their clinical applications.
C1 [Chan, Maria F.] Mem Sloan Kettering Canc Ctr, Dept Med Phys, 1275 York Ave, New York, NY 10021 USA.
   [Witztum, Alon; Valdes, Gilmer] Univ Calif San Francisco, Dept Radiat Oncol, San Francisco, CA USA.
RP Chan, MF (corresponding author), Mem Sloan Kettering Canc Ctr, Dept Med Phys, 1275 York Ave, New York, NY 10021 USA.
EM chanm@mskcc.org
FU NIH/NCI Cancer Center Support Grant [P30 CA008748]
FX This research was funded in part through the NIH/NCI Cancer Center
   Support Grant P30 CA008748.
NR 37
TC 12
Z9 12
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2624-8212
J9 FRONT ARTIF INTELL
JI Front. Artif. Intell.
PY 2020
VL 3
AR 577620
DI 10.3389/frai.2020.577620
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA VK7OE
UT WOS:000751673300089
PM 33733216
OA Green Published, gold
DA 2022-04-17
ER

PT C
AU Suneetha, ARVN
   Arulmurugan, A
AF Suneetha, Avvaru R. V. Naga
   Arulmurugan, A.
GP IEEE
TI Current Trends in Machine Learning Algorithms and Application on Health
   Sensor Data
SO PROCEEDINGS OF THE 2021 FIFTH INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN
   SOCIAL, MOBILE, ANALYTICS AND CLOUD) (I-SMAC 2021)
LA English
DT Proceedings Paper
CT 5th International Conference on IoT in Social, Mobile, Analytics and
   Cloud (I-SMAC)
CY NOV 11-13, 2021
CL ELECTR NETWORK
SP IEEE, SCAD Inst Technol
DE Machine Learning; Trending Machine Learning Algorithms; Deep Learning;
   Hierarchical Temporal Memory; Distributed Cloud Computing; Spark; Health
   Sensor Data; Mobile Health
AB This paper is focused with currently trending machine learning algorithms (deep learning, Hierarchical temporal memory) and their application in health sensor data. Also, it captures some of the challenges faced during application of machine learning algorithms and also focuses on some advantages and limitations in applying specific machine learning algorithms in health sensor data. Lastly, it covers focuses on sensor big data and machine learning integration.
C1 [Suneetha, Avvaru R. V. Naga; Arulmurugan, A.] Vignans Fdn Sci Technol & Res, Dept Comp Sci & Engn, Guntur 522213, Andhra Pradesh, India.
   [Suneetha, Avvaru R. V. Naga] Vignan Inst Technol & Sci, Dept Comp Sci & Engn, Pochampally M 508284, Telangana, India.
RP Suneetha, ARVN (corresponding author), Vignans Fdn Sci Technol & Res, Dept Comp Sci & Engn, Guntur 522213, Andhra Pradesh, India.; Suneetha, ARVN (corresponding author), Vignan Inst Technol & Sci, Dept Comp Sci & Engn, Pochampally M 508284, Telangana, India.
EM suneethaavvaru@gmail.com
NR 22
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-6654-2642-8
PY 2021
BP 322
EP 327
DI 10.1109/I-SMAC52330.2021.9640739
PG 6
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS7GZ
UT WOS:000760875500055
DA 2022-04-17
ER

PT J
AU Mangalathu, S
   Jeon, JS
AF Mangalathu, Sujith
   Jeon, Jong-Su
TI Regional Seismic Risk Assessment of Infrastructure Systems through
   Machine Learning: Active Learning Approach
SO JOURNAL OF STRUCTURAL ENGINEERING
LA English
DT Article
DE Machine learning; Active learning; Column failure mode; Bridge tagging;
   Regional seismic risk
ID BRIDGE CLASSES; PERFORMANCE; PREDICTION; MODE
AB Regional seismic risk assessment involves many infrastructure systems, and it is computationally intensive to conduct an indi-vidual simulation of each system. This paper suggests an approach using active learning to select informative samples that help build machine learning models with fewer samples for regional damage assessment. The potential of the approach is demonstrated with (1) failure mode prediction of bridge columns, and (2) regional damage assessment of the California two-span bridge inventory with seat abutments. The active learning approach involves the selection of column attributes or bridge models that are more informative to the creation of machine learning based decision boundaries. The results reveal that an active learning target model based on 100 bridge samples can achieve a level of accuracy of 80%, which is equivalent to a machine learning model based on 480 bridge samples in the case of damage prediction following an earthquake. With the proposed approach, the computational complexity associated with regional risk assessment of bridge systems with specific attributes can be drastically reduced. The proposed approach also will help plan experimental studies that are more informative for damage assessment. DOI: 10.1061/(ASCE)ST.1943-541X.0002831. (c) 2020 American Society of Civil Engineers.
C1 [Mangalathu, Sujith] Mangalathu, Puthoor PO, Kollam 691507, Kerala, India.
   [Jeon, Jong-Su] Hanyang Univ, Dept Civil & Environm Engn, Seoul 04763, South Korea.
RP Jeon, JS (corresponding author), Hanyang Univ, Dept Civil & Environm Engn, Seoul 04763, South Korea.
EM sujithmss@gatech.edu; jongsujeon@hanyang.ac.kr
OI Jeon, Jong-Su/0000-0001-6657-7265
FU National Research Foundation of Korea (NRF) - Korean government (MSIT)
   [2020R1A4A1018826]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korean government (MSIT) (No.
   2020R1A4A1018826).
NR 35
TC 7
Z9 7
U1 5
U2 22
PU ASCE-AMER SOC CIVIL ENGINEERS
PI RESTON
PA 1801 ALEXANDER BELL DR, RESTON, VA 20191-4400 USA
SN 0733-9445
EI 1943-541X
J9 J STRUCT ENG
JI J. Struct. Eng.
PD DEC
PY 2020
VL 146
IS 12
AR 04020269
DI 10.1061/(ASCE)ST.1943-541X.0002831
PG 11
WC Construction & Building Technology; Engineering, Civil
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Construction & Building Technology; Engineering
GA OL3AX
UT WOS:000585214300013
DA 2022-04-17
ER

PT J
AU Sarnovsky, M
   Paralic, J
AF Sarnovsky, Martin
   Paralic, Jan
TI Hierarchical Intrusion Detection Using Machine Learning and Knowledge
   Model
SO SYMMETRY-BASEL
LA English
DT Article
DE intrusion detection; machine learning; classification; knowledge
   modelling
ID DETECTION SYSTEM
AB Intrusion detection systems (IDS) present a critical component of network infrastructures. Machine learning models are widely used in the IDS to learn the patterns in the network data and to detect the possible attacks in the network traffic. Ensemble models combining a variety of different machine learning models proved to be efficient in this domain. On the other hand, knowledge models have been explicitly designed for the description of the attacks and used in ontology-based IDS. In this paper, we propose a hierarchical IDS based on the original symmetrical combination of machine learning approach with knowledge-based approach to support detection of existing types and severity of new types of network attacks. Multi-stage hierarchical prediction consists of the predictive models able to distinguish the normal connections from the attacks and then to predict the attack classes and concrete attack types. The knowledge model enables to navigate through the attack taxonomy and to select the appropriate model to perform a prediction on the selected level. Designed IDS was evaluated on a widely used KDD 99 dataset and compared to similar approaches.
C1 [Sarnovsky, Martin; Paralic, Jan] Tech Univ Kosice, Dept Cybernet & Artificial Intelligence, Fac Elect Engn & Informat, Letna 9, Kosice 04001, Slovakia.
RP Sarnovsky, M (corresponding author), Tech Univ Kosice, Dept Cybernet & Artificial Intelligence, Fac Elect Engn & Informat, Letna 9, Kosice 04001, Slovakia.
EM martin.sarnovsky@tuke.sk; jan.paralic@tuke.sk
RI Sarnovsky, Martin/Z-4954-2019; Paralic, Jan/H-5393-2013
OI Sarnovsky, Martin/0000-0003-3019-8364; Paralic, Jan/0000-0002-4603-0411
FU Slovak Research and Development AgencySlovak Research and Development
   Agency [APVV-16-0213]; VEGA projectVedecka grantova agentura MSVVaS SR a
   SAV (VEGA) [1/0493/16]
FX This work was supported by Slovak Research and Development Agency under
   the contract No. APVV-16-0213 and by the VEGA project under grant No.
   1/0493/16.
NR 30
TC 13
Z9 13
U1 3
U2 6
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2073-8994
J9 SYMMETRY-BASEL
JI Symmetry-Basel
PD FEB
PY 2020
VL 12
IS 2
AR 203
DI 10.3390/sym12020203
PG 14
WC Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics
GA KW4PJ
UT WOS:000521147600007
OA gold
DA 2022-04-17
ER

PT C
AU Randby, T
   Marciano, R
AF Randby, Teddy
   Marciano, Richard
BE Wu, XT
   Jermaine, C
   Xiong, L
   Hu, XH
   Kotevska, O
   Lu, SY
   Xu, WJ
   Aluru, S
   Zhai, CX
   Al-Masri, E
   Chen, ZY
   Saltz, J
TI Digital Curation and Machine Learning Experimentation in Archives
SO 2020 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA)
SE IEEE International Conference on Big Data
LA English
DT Proceedings Paper
CT 8th IEEE International Conference on Big Data (Big Data)
CY DEC 10-13, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, IBM, Ankura
DE Digital Curation; Computational Archival Science (CAS); Machine
   Learning; FDR Presidential Library and Museum; Morgenthau Holocaust
   Project; Machine Learning
AB In this paper, we present a series of experiments we conducted over the summer of 2020 with the FDR Morgenthau Holocaust Collections at the FDR Presidential Library and Museum, in order to unlock hard-to-reach information in the collections and improve access to the public and researchers. We extract detailed Subject Index metadata from Table of Contents images towards creating better finding aids. We demonstrate how digital curation of archival collections are a necessary preparation step for use with supervised Machine Learning algorithms. Finally, we introduce the notion of historical contextualization of Machine Learning models in order to create culturally-aware training models.
C1 [Randby, Teddy] Univ North Carolina Chapel Hill, Adv Informat Collaboratory AIC, Chapel Hill, NC 27599 USA.
   [Marciano, Richard] Univ Maryland, Coll Informat Studies, College Pk, MD USA.
RP Randby, T (corresponding author), Univ North Carolina Chapel Hill, Adv Informat Collaboratory AIC, Chapel Hill, NC 27599 USA.
EM tedrandby@gmail.com; marciano@umd.edu
FU 2020-2022 IMLS Laura Bush 21st Century Librarian Program: "Piloting an
   Online Collaborative Network for Integrating Computational Thinking into
   Library and Archival Education and Practice"
FX We wish to acknowledge funding from the 2020-2022 IMLS Laura Bush 21st
   Century Librarian Program: "Piloting an Online Collaborative Network for
   Integrating Computational Thinking into Library and Archival Education
   and Practice." Also, a deep appreciation for the support of staff from
   the FDR Presidential Library: Kirsten Carter, Supervisory Archivist,
   Bill Harris, Deputy Director, and Dr. Abby Gondek, Morgenthau
   Scholar-in-Residence, Roosevelt Institute at the FDR Presidential
   Library & Museum. Also, we wish to recognize the contributions of Renee
   Geary, Librarian and member of the 2020 Digital Curation for Information
   Professionals Certificate who performed a series of digital curation
   analyses on this collection that informed the development of this paper.
NR 6
TC 0
Z9 0
U1 3
U2 4
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2639-1589
BN 978-1-7281-6251-5
J9 IEEE INT CONF BIG DA
PY 2020
BP 1904
EP 1913
DI 10.1109/BigData50022.2020.9377788
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR6NZ
UT WOS:000662554702005
DA 2022-04-17
ER

PT J
AU Mahdi, MN
   Zabil, MHM
   Ahmad, AR
   Ismail, R
   Yusoff, Y
   Cheng, LK
   Azmi, MSB
   Natiq, H
   Naidu, HH
AF Mahdi, Mohammed Najah
   Mohamed Zabil, Mohd Hazli
   Ahmad, Abdul Rahim
   Ismail, Roslan
   Yusoff, Yunus
   Cheng, Lim Kok
   Azmi, Muhammad Sufyian Bin Mohd
   Natiq, Hayder
   Happala Naidu, Hushalini
TI Software Project Management Using Machine Learning Technique-A Review
SO APPLIED SCIENCES-BASEL
LA English
DT Review
DE machine learning technique; software project estimation; software
   estimation; software project management; project risk assessment
ID SUPPORT VECTOR MACHINE; COST ESTIMATION; RISK; PREDICTION; KNOWLEDGE;
   MODEL; SYSTEM; INTELLIGENCE; REGRESSION; ALGORITHM
AB Project management planning and assessment are of great significance in project performance activities. Without a realistic and logical plan, it isn't easy to handle project management efficiently. This paper presents a wide-ranging comprehensive review of papers on the application of Machine Learning in software project management. Besides, this paper presents an extensive literature analysis of (1) machine learning, (2) software project management, and (3) techniques from three main libraries, Web Science, Science Directs, and IEEE Explore. One-hundred and eleven papers are divided into four categories in these three repositories. The first category contains research and survey papers on software project management. The second category includes papers that are based on machine-learning methods and strategies utilized on projects; the third category encompasses studies on the phases and tests that are the parameters used in machine-learning management and the final classes of the results from the study, contribution of studies in the production, and the promotion of machine-learning project prediction. Our contribution also offers a more comprehensive perspective and a context that would be important for potential work in project risk management. In conclusion, we have shown that project risk assessment by machine learning is more successful in minimizing the loss of the project, thereby increasing the likelihood of the project success, providing an alternative way to efficiently reduce the project failure probabilities, and increasing the output ratio for growth, and it also facilitates analysis on software fault prediction based on accuracy.
C1 [Mahdi, Mohammed Najah] Univ Tenaga Nas, Inst Informat & Comp Energy, Kajang 43000, Malaysia.
   [Mohamed Zabil, Mohd Hazli; Ahmad, Abdul Rahim; Ismail, Roslan; Yusoff, Yunus; Cheng, Lim Kok; Azmi, Muhammad Sufyian Bin Mohd] Univ Tenaga Nas, Coll Comp & Informat CCI, Kajang 43000, Malaysia.
   [Natiq, Hayder] Imam Jaafar Al Sadiq Univ, Dept Comp Technol, Informat Technol Collage, Baghdad 10064, Iraq.
   [Happala Naidu, Hushalini] Univ Tenaga Nas, Uniten R&D Sdn Bhd, Kajang 43000, Malaysia.
RP Mahdi, MN (corresponding author), Univ Tenaga Nas, Inst Informat & Comp Energy, Kajang 43000, Malaysia.
EM Najah.Mahdi@uniten.edu.my; hazli@uniten.edu.my; Abdrahim@uniten.edu.my;
   roslan@uniten.edu.my; yunusy@yniten.edu.my; Kokcheng@uniten.edu.my;
   sufyian@uniten.edu.my; hayder.natiq@sadiq.edu.iq;
   hushalini@uniten.edu.my
RI Natiq, Hayder/AAO-7283-2020; Mahdi, Mohammed/AAF-3659-2021
OI Natiq, Hayder/0000-0003-1303-9089; Mahdi, Mohammed/0000-0001-8718-6458;
   Mohamed Zabil, Mohd Hazli/0000-0001-6187-2564
FU Universiti Tenaga Nasional (UNITEN); UNITEN R&D Sdn Bhd, under TNB Seed
   Grant [U-TC-RD-19-10]
FX This work is generously funded by the Universiti Tenaga Nasional
   (UNITEN) and UNITEN R&D Sdn Bhd, under TNB Seed Grant project
   U-TC-RD-19-10 titled "Smart Software Projects Management Assessment
   System.
NR 168
TC 1
Z9 1
U1 19
U2 26
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD JUN
PY 2021
VL 11
IS 11
AR 5183
DI 10.3390/app11115183
PG 39
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Materials Science; Physics
GA SP4NP
UT WOS:000659647000001
OA gold
DA 2022-04-17
ER

PT J
AU Xuan, CD
   Nguyen, HD
   Nikolaevich, TV
AF Cho Do Xuan
   Hoa Dinh Nguyen
   Nikolaevich, Tisenko Victor
TI Malicious URL Detection based on Machine Learning
SO INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS
LA English
DT Article
DE URL; malicious URL detection; feature extraction; feature selection;
   machine learning
AB Currently, the risk of network information insecurity is increasing rapidly in number and level of danger. The methods mostly used by hackers today is to attack end-to-end technology and exploit human vulnerabilities. These techniques include social engineering, phishing, pharming, etc. One of the steps in conducting these attacks is to deceive users with malicious Uniform Resource Locators (URLs). As a results, malicious URL detection is of great interest nowadays. There have been several scientific studies showing a number of methods to detect malicious URLs based on machine learning and deep learning techniques. In this paper, we propose a malicious URL detection method using machine learning techniques based on our proposed URL behaviors and attributes. Moreover, bigdata technology is also exploited to improve the capability of detection malicious URLs based on abnormal behaviors. In short, the proposed detection system consists of a new set of URLs features and behaviors, a machine learning algorithm, and a bigdata technology. The experimental results show that the proposed URL attributes and behavior can help improve the ability to detect malicious URL significantly. This is suggested that the proposed system may be considered as an optimized and friendly used solution for malicious URL detection.
C1 [Cho Do Xuan; Hoa Dinh Nguyen] Posts & Telecommun Inst Technol, Informat Secur Dept, Hanoi, Vietnam.
   [Cho Do Xuan; Hoa Dinh Nguyen] FPT Univ, Informat Assurance Dept, Hanoi, Vietnam.
   [Nikolaevich, Tisenko Victor] Peter Great St Petersburg Polytech Univ, Syst Automat Design, Polytech Skaya 29, St Petersburg, Russia.
RP Xuan, CD (corresponding author), Posts & Telecommun Inst Technol, Informat Secur Dept, Hanoi, Vietnam.; Xuan, CD (corresponding author), FPT Univ, Informat Assurance Dept, Hanoi, Vietnam.
NR 15
TC 2
Z9 2
U1 2
U2 6
PU SCIENCE & INFORMATION SAI ORGANIZATION LTD
PI WEST YORKSHIRE
PA 19 BOLLING RD, BRADFORD, WEST YORKSHIRE, 00000, ENGLAND
SN 2158-107X
EI 2156-5570
J9 INT J ADV COMPUT SC
JI Int. J. Adv. Comput. Sci. Appl.
PD JAN
PY 2020
VL 11
IS 1
BP 148
EP 153
PG 6
WC Computer Science, Theory & Methods
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA KS7DY
UT WOS:000518467600019
DA 2022-04-17
ER

PT J
AU d'Amato, C
AF d'Amato, Claudia
TI Machine Learning for the Semantic Web: Lessons learnt and next research
   directions
SO SEMANTIC WEB
LA English
DT Article
DE Machine Learning; symbol-based methods; numeric-based methods
AB Machine Learning methods have been introduced in the Semantic Web for solving problems such as link and type prediction, ontology enrichment and completion (both at terminological and assertional level). Whilst initially mainly focussing on symbol-based solutions, recently numeric-based approaches have received major attention, motivated by the need to scale on the very large Web of Data. In this paper, the most representative proposals, belonging to the aforementioned categories are surveyed, jointly with the analysis of their main peculiarities and drawbacks. Afterwards the main envisioned research directions for further developing Machine Learning solutions for the Semantic Web are presented.
C1 [d'Amato, Claudia] Univ Bari, Dept Comp Sci, Via Orabona 4, I-70126 Bari, Italy.
RP d'Amato, C (corresponding author), Univ Bari, Dept Comp Sci, Via Orabona 4, I-70126 Bari, Italy.
EM claudia.damato@uniba.it
RI d'Amato, Claudia/C-1142-2013
OI d'Amato, Claudia/0000-0002-3385-987X
NR 61
TC 8
Z9 8
U1 3
U2 6
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1570-0844
EI 2210-4968
J9 SEMANT WEB
JI Semant. Web
PY 2020
VL 11
IS 1
BP 195
EP 203
DI 10.3233/SW-200388
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KJ8IH
UT WOS:000512298900020
DA 2022-04-17
ER

PT J
AU Stevens, B
   Colonius, T
AF Stevens, Ben
   Colonius, Tim
TI Enhancement of shock-capturing methods via machine learning
SO THEORETICAL AND COMPUTATIONAL FLUID DYNAMICS
LA English
DT Article
DE Shock capturing; Machine learning; Fluid mechanics
ID FINITE-DIFFERENCE SCHEMES; ESSENTIALLY NONOSCILLATORY SCHEME
AB In recent years, machine learning has been used to create data-driven solutions to problems for which an algorithmic solution is intractable, as well as fine-tuning existing algorithms. This research applies machine learning to the development of an improved finite-volume method for simulating PDEs with discontinuous solutions. Shock-capturing methods make use of nonlinear switching functions that are not guaranteed to be optimal. Because data can be used to learn nonlinear relationships, we train a neural network to improve the results of a fifth-order WENO method. We post-process the outputs of the neural network to guarantee that the method is consistent. The training data consist of the exact mapping between cell averages and interpolated values for a set of integrable functions that represent waveforms we would expect to see while simulating a PDE. We demonstrate our method on linear advection of a discontinuous function, the inviscid Burgers' equation, and the 1-D Euler equations. For the latter, we examine the Shu-Osher model problem for turbulence-shock wave interactions. We find that our method outperforms WENO in simulations where the numerical solution becomes overly diffused due to numerical viscosity.
C1 [Stevens, Ben; Colonius, Tim] CALTECH, Dept Mech & Civil Engn, Pasadena, CA 91125 USA.
RP Stevens, B (corresponding author), CALTECH, Dept Mech & Civil Engn, Pasadena, CA 91125 USA.
EM bstevens@caltech.edu
OI Stevens, Benjamin/0000-0002-3410-5922; Colonius, Tim/0000-0003-0326-3909
FU National Science Foundation Graduate Research FellowshipNational Science
   Foundation (NSF) [1745301]
FX This material is based upon work supported by the National Science
   Foundation Graduate Research Fellowship under Grant No. 1745301.
NR 31
TC 5
Z9 6
U1 1
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0935-4964
EI 1432-2250
J9 THEOR COMP FLUID DYN
JI Theor. Comput. Fluid Dyn.
PD AUG
PY 2020
VL 34
IS 4
SI SI
BP 483
EP 496
DI 10.1007/s00162-020-00531-1
EA MAY 2020
PG 14
WC Mechanics; Physics, Fluids & Plasmas
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Mechanics; Physics
GA NB0LJ
UT WOS:000535098000001
OA Green Submitted, Green Accepted
DA 2022-04-17
ER

PT J
AU Avalos, O
AF Avalos, Omar
TI GSA for machine learning problems: A comprehensive overview
SO APPLIED MATHEMATICAL MODELLING
LA English
DT Article
DE Gravitational search algorithm; Machine learning; Classification;
   Clustering problem; Data mining
ID GRAVITATIONAL SEARCH ALGORITHM; OPTIMIZATION ALGORITHM;
   FEATURE-SELECTION; K-MEANS; IDENTIFICATION; RECOGNITION; IMAGERY
AB The rapidly increasing data volume produced daily is encouraging to generate novel procedures for extracting suitable information from such data. Machine learning is an application of artificial intelligence which is employed to provide relevant knowledge extracted from data, due to such characteristics, the adoption of machine learning approaches is one of the most accepted alternatives for this purpose nowadays. On the other hand, many machine learning applications turn into complex tasks due to the nature of data and the procedure that these must be subjected to collecting appropriate information. Alternatively, metaheuristic techniques are optimization algorithms widely used for treating complex tasks efficiently. The Gravitational Search Algorithm (GSA) is an optimization method based on the Newtonian gravitational laws and the interaction of masses, this procedure has proved interesting results due to the employed operators for correct balancing the exploration and exploitation stages, avoiding the common flaws present in existing optimization techniques such as the premature convergence onto local minimal. In this study, a comprehensive overview of the GSA applied in several machine learning applications is carried out. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Avalos, Omar] Univ Guadalajara, Dept Elect, CUCEI, Guadalajara, Jalisco, Mexico.
RP Avalos, O (corresponding author), Univ Guadalajara, Dept Elect, CUCEI, Guadalajara, Jalisco, Mexico.
EM omar.aalvarez@academicos.udg.mx
RI Avalos, Omar/AAG-7781-2021
OI Avalos, Omar/0000-0003-3859-3414; Abdullahi Tope,
   Sulyman/0000-0001-9723-7810
NR 95
TC 3
Z9 3
U1 0
U2 8
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0307-904X
EI 1872-8480
J9 APPL MATH MODEL
JI Appl. Math. Model.
PD APR
PY 2021
VL 92
BP 261
EP 280
DI 10.1016/j.apm.2020.11.013
PG 20
WC Engineering, Multidisciplinary; Mathematics, Interdisciplinary
   Applications; Mechanics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Mathematics; Mechanics
GA QF8KX
UT WOS:000617140400013
DA 2022-04-17
ER

PT J
AU Borrego-Carazo, J
   Castells-Rufas, D
   Biempica, E
   Carrabina, J
AF Borrego-Carazo, Juan
   Castells-Rufas, David
   Biempica, Ernesto
   Carrabina, Jordi
TI Resource-Constrained Machine Learning for ADAS: A Systematic Review
SO IEEE ACCESS
LA English
DT Review
DE Machine learning; Task analysis; Automotive engineering; Hardware;
   Systematics; Computational modeling; Adaptation models; Machine
   learning; embedded software; automotive engineering; GPU; FPGA; ADAS
ID SUPPORT VECTOR MACHINE; RECOGNITION; SEARCH
AB The advent of machine learning (ML) methods for the industry has opened new possibilities in the automotive domain, especially for Advanced Driver Assistance Systems (ADAS). These methods mainly focus on specific problems ranging from traffic sign and light recognition to pedestrian detection. In most cases, the computational resources and power budget found in ADAS systems are constrained while most machine learning methods are computationally intensive. The usual solution consists in adapting the ML models to comply with the memory and real-time (RT) requirements for inference. Some models are easily adapted to resource-constrained hardware, such as Support Vector Machines, while others, like Neural Networks, need more complex processes to fit into the desired hardware. The ADAS hardware (HW platforms) are diverse, from complex MPSoC CPUs down to classical MCUs, DPSs and application-specific FPGAs and ASICs or specific GPU platforms (such as the NVIDIA families Tegra or Jetson). Therefore, there is a tradeoff between the complexity of the ML model implemented and the selected platform that impacts the performance metrics: function results, energy consumption and speed (latency and throughput). In this paper, a survey in the form of systematic review is conducted to analyze the scope of the published research works that embed ML models into resource-constrained implementations for ADAS applications and what are the achievements regarding the ML performance, energy and speed trade-off.
C1 [Borrego-Carazo, Juan; Biempica, Ernesto] Kostal Elect SA, RD, Barcelona 08181, Spain.
   [Borrego-Carazo, Juan; Castells-Rufas, David; Carrabina, Jordi] Univ Autonoma Barcelona, Microelect & Elect Syst Dept, Cerdanyola Del Valles 08193, Spain.
RP Borrego-Carazo, J (corresponding author), Kostal Elect SA, RD, Barcelona 08181, Spain.; Borrego-Carazo, J (corresponding author), Univ Autonoma Barcelona, Microelect & Elect Syst Dept, Cerdanyola Del Valles 08193, Spain.
EM juan.borrego@uab.cat
RI Carazo, Juan Borrego/AAV-7303-2020; Carrabina, Jordi/K-7916-2014
OI Carazo, Juan Borrego/0000-0003-3223-8227; Castells-Rufas,
   David/0000-0002-7181-9705; Carrabina, Jordi/0000-0002-9540-8759
FU Spanish Ministry of Science, Innovation and UniversitiesSpanish
   Government [RTI2018-095209-B-C22]; Catalan Government [2017SGR1624,
   2018DI30]
FX This work was partly supported by the Spanish Ministry of Science,
   Innovation and Universities under grant RTI2018-095209-B-C22, and by the
   Catalan Government under grants 2017SGR1624 and 2018DI30.
NR 148
TC 9
Z9 9
U1 7
U2 26
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 40573
EP 40598
DI 10.1109/ACCESS.2020.2976513
PG 26
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA LC7ZU
UT WOS:000525553100015
OA gold
DA 2022-04-17
ER

PT J
AU Liilington, JNP
   Gout, TL
   Harrison, MT
   Farnan, I
AF Liilington, Joseph N. P.
   Gout, Thomas L.
   Harrison, Mike T.
   Farnan, Ian
TI Predicting radioactive waste glass dissolution with machine learning
SO JOURNAL OF NON-CRYSTALLINE SOLIDS
LA English
DT Article
DE Machine learning; Leaching; Nuclear waste glass; Dissolution
ID HIGH-LEVEL WASTE; NUCLEAR GLASS; GRAAL MODEL; SON68; TERM; MAGNESIUM;
   CORROSION; SURFACE; RATES
AB The vitrification of high-level nuclear waste within borosilicate glass and its disposition within a multi-barrier repository deep underground is accepted as the best form of disposal. Here, the ability of machine learning to predict both static and dynamic glass leaching behavior is analysed using large-scale unstructured multi-source data, covering a diverse range of experimental conditions and glass compositions. Machine learning can accurately predict leaching behavior, predict missing data, and time forecast. Accuracy depends upon the type of learning algorithm, model input variables, and diversity or size of the underlying dataset. For static leaching, the bagged random forest method predicts well, even when either pH or glass composition are neglected as input variables, additionally showing potential in predicting independent glass dissolution data. For dynamic leaching, accuracy improves if replacing final pH with a species dissolution rate as an input variable, although results show no preferred output species (Si, Na, or Al).
C1 [Liilington, Joseph N. P.; Gout, Thomas L.; Farnan, Ian] Univ Cambridge, Dept Earth Sci, Downing St, Cambridge CB2 3EQ, England.
   [Harrison, Mike T.] Natl Nucl Lab, Cent Lab, Seascale CA20 1PG, Cumbria, England.
RP Liilington, JNP (corresponding author), Univ Cambridge, Dept Earth Sci, Downing St, Cambridge CB2 3EQ, England.
EM jnpl2@cam.ac.uk
RI Farnan, Ian/M-3881-2014
OI Farnan, Ian/0000-0001-7844-5112; Gout, Thomas/0000-0002-6930-0381
FU EPSRCUK Research & Innovation (UKRI)Engineering & Physical Sciences
   Research Council (EPSRC) [EP/L015900/1]; EPSRCUK Research & Innovation
   (UKRI)Engineering & Physical Sciences Research Council (EPSRC)
   [EP/I036400/1] Funding Source: UKRI
FX This project was funded and supervised as part of an EPSRC funded
   Imperial -Cambridge-Open University(ICO) Centre for Doctoral Training
   (CDT) PhD project (EPSRC Grant number: EP/L015900/1).
NR 40
TC 8
Z9 8
U1 5
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0022-3093
EI 1873-4812
J9 J NON-CRYST SOLIDS
JI J. Non-Cryst. Solids
PD APR 1
PY 2020
VL 533
AR 119852
DI 10.1016/j.jnoncrysol.2019.119852
PG 19
WC Materials Science, Ceramics; Materials Science, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Materials Science
GA KW9MF
UT WOS:000521507100011
OA Green Submitted
DA 2022-04-17
ER

PT C
AU Nassif, AB
   AlaaEddin, M
   Sahib, AA
AF Nassif, Ali Bou
   AlaaEddin, Maha
   Sahib, Amna Akram
GP IEEE
TI Machine Learning Models for Stock Price Prediction
SO 2020 SEVENTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY TRENDS
   (ITT 2020)
LA English
DT Proceedings Paper
CT 7th International Conference on Information Technology Trends (ITT)
CY NOV 25-26, 2020
CL Higher Coll Technol, ELECTR NETWORK
SP Higher Coll Technol, Fac Comp Informat Sci
HO Higher Coll Technol
DE Grunfeld investment data; machine learning; regression
AB In 1950, there was a well-known investment data which was most generally used informational sets in the entirety of the applied econometrics in the United States called "Grunfeld investment data". The full dataset points out errors and inconsistencies in several currently available versions. The main goal of this paper is to use Machine Learning and Statistical models to clean up data and to predict the stock price using the Grunfeld investment data.
C1 [Nassif, Ali Bou; AlaaEddin, Maha; Sahib, Amna Akram] Univ Sharjah, Dept Comp Engn, Sharjah, U Arab Emirates.
RP Nassif, AB (corresponding author), Univ Sharjah, Dept Comp Engn, Sharjah, U Arab Emirates.
EM anassif@sharjah.ac.ae; malaaeddin@sharjah.ac.ae; U16103026@sharjah.ac.ae
NR 16
TC 0
Z9 0
U1 1
U2 5
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-8378-7
PY 2020
BP 67
EP 71
DI 10.1109/ITT51279.2020.9320871
PG 5
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR6IT
UT WOS:000661250900012
DA 2022-04-17
ER

PT J
AU Krishnan, C
   Mohan, V
   Ray, S
AF Krishnan, Chethan
   Mohan, Vyshnav
   Ray, Soham
TI Machine Learning N=8,D=5 Gauged Supergravity
SO FORTSCHRITTE DER PHYSIK-PROGRESS OF PHYSICS
LA English
DT Article
DE machine learning; supergravity
ID ADS(7) X S(4); N=8 SUPERGRAVITY; SELF-DUALITY; REDUCTION; CONSISTENCY
AB Type IIB string theory on a 5-sphere gives rise to N=8,SO(6) gauged supergravity in five dimensions. Motivated by the fact that this is the context of the most widely studied example of the AdS/CFT correspondence, we undertake an investigation of its critical points. The scalar manifold is an E6(6)/USp(8) coset, and the challenge is that it is 42-dimensional. We take a Machine Learning approach to the problem using TensorFlow, and this results in a substantial increase in the number of known critical points. Our list of 32 critical points contains all five of the previously known ones, including an N=2 supersymmetric point identified by Khavaev, Pilch and Warner.
C1 [Krishnan, Chethan; Mohan, Vyshnav; Ray, Soham] Indian Inst Sci, Ctr High Energy Phys, Bangalore 560012, Karnataka, India.
RP Krishnan, C (corresponding author), Indian Inst Sci, Ctr High Energy Phys, Bangalore 560012, Karnataka, India.
EM chethan.krishnan@gmail.com
NR 22
TC 12
Z9 12
U1 0
U2 0
PU WILEY-V C H VERLAG GMBH
PI WEINHEIM
PA POSTFACH 101161, 69451 WEINHEIM, GERMANY
SN 0015-8208
EI 1521-3978
J9 FORTSCHR PHYS
JI Fortschritte Phys.-Prog. Phys.
PD MAY
PY 2020
VL 68
IS 5
AR 2000027
DI 10.1002/prop.202000027
EA MAR 2020
PG 15
WC Physics, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Physics
GA LR4II
UT WOS:000520517400001
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Li, P
AF Li, Peng
TI Research on radar signal recognition based on automatic machine learning
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Radar signal recognition; Automatic machine learning; AUTO-SKLEARN
   algorithm; Model integration
ID PERFORMANCE EVALUATION; PREDICTION; TREE
AB With the advancement of machine learning and radar technology, machine learning is becoming more and more widely used in the field of radar. Radar scanning, signal acquisition and processing, one-dimensional range image, radar SAR, ISAR image recognition, radar tracking and guidance are all integrated into machine learning technology, but machine learning technology relies heavily on human machine learning experts for radar signal recognition. In order to realize the automation of radar signal recognition by machine learning, this paper proposes an automatic machine learning AUTO-SKLEARN system and applies it to radar radiation source signals. Identification: Firstly, this paper briefly introduces the classification of traditional machine learning algorithms and the types of algorithms specifically included in each type of algorithm. On this basis, the machine learning Bayesian algorithm is introduced. Secondly, the automatic machine learning AUTO based on Bayesian algorithm is proposed. -SKLEARN system, elaborates the process of AUTO-SKLEARN system in solving automatic selection algorithm and hyperparameter optimization, including meta-learning and its program implementation and automatic model integration construction. Finally, this paper introduces the process of automatic machine learning applied to radar emitter signal recognition. Through data simulation and experiment, the effect of traditional machine learning k-means algorithm and automatic machine learning AUTO-SKLEARN system in radar signal recognition is compared, which shows that automatic machine learning is feasible for radar signal recognition. The automatic machine learning AUTO-SKLEARN system can significantly improve the accuracy of the radar emitter signal recognition process, and the scheme is more reliable in signal recognition stability.
C1 [Li, Peng] Chongqing Univ, Coll Microelect & Commun Engn, Chongqing, Peoples R China.
   [Li, Peng] Chongqing Univ Arts & Sci, Sch Elect & Elect Engn, Chongqing, Peoples R China.
RP Li, P (corresponding author), Chongqing Univ, Coll Microelect & Commun Engn, Chongqing, Peoples R China.; Li, P (corresponding author), Chongqing Univ Arts & Sci, Sch Elect & Elect Engn, Chongqing, Peoples R China.
EM lipeng663073@cqu.edu.cn
NR 26
TC 11
Z9 11
U1 32
U2 85
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD APR
PY 2020
VL 32
IS 7
SI SI
BP 1959
EP 1969
DI 10.1007/s00521-019-04494-1
PG 11
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KY4QF
UT WOS:000522553100014
DA 2022-04-17
ER

PT C
AU Keya, MS
   Akter, H
   Rahman, MA
   Rahman, MM
   Emon, MU
   Zulfiker, MS
AF Keya, Maria Sultana
   Akter, Himu
   Rahman, Md Atiqur
   Rahman, Md Mahbobur
   Emon, Minhaz Uddin
   Zulfiker, Md Sabab
GP IEEE
TI Comparison of Different Machine Learning Algorithms for Detecting
   Bankruptcy
SO PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION
   TECHNOLOGIES (ICICT 2021)
LA English
DT Proceedings Paper
CT 6th International Conference on Inventive Computation Technologies
   (ICICT)
CY JAN 20-22, 2021
CL Coimbatore, INDIA
SP IEEE, SVR Tech Campus
DE Machine Learning; prediction; bankruptcy; accuracy
AB There has been severe experiments from academics and merchandisers concerning models for Predicting bankruptcy. The paper propounds an extensive rethink of work done during 5 years in the petition of intellectual strategy to accomplish bankruptcy prediction problems. Several machine learning directions are being used in this research paper for Predicting bankruptcy. Some algorithms: AdaBoost, Decision tree, J48, Bagging, Random Forest are used in this paper. By traditional models, machine learning models offer enhancing bankruptcy prediction accuracy. Different types of models are tested using several evaluation metrics. The five years Bagging accuracy range is 95% within 97% among another model. Here include kfold cross-validation(k=10) to measure our accuracy. Bagging accuracy is high in this paper. Confusion matrix is used to recount the perfection of a classification model that gives true values for knowing.
C1 [Keya, Maria Sultana; Akter, Himu; Rahman, Md Atiqur; Rahman, Md Mahbobur; Emon, Minhaz Uddin; Zulfiker, Md Sabab] Daffodil Int Univ, Dhaka, Bangladesh.
RP Keya, MS (corresponding author), Daffodil Int Univ, Dhaka, Bangladesh.
EM maria15-1215@diu.edu.bd; himul5-1212@diu.edu.bd;
   atiqur15-1283@diu.edu.bd; mahbobur15-1217@diu.edu.bd;
   minhaz15-1294@diu.edu.bd; sabab.cse@diu.edu.bd
OI Zulfiker, Md. Sabab/0000-0001-6848-6789
NR 17
TC 0
Z9 0
U1 4
U2 4
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-8501-9
PY 2021
BP 705
EP 712
DI 10.1109/ICICT50816.2021.9358587
PG 8
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BS4RZ
UT WOS:000722293800122
DA 2022-04-17
ER

PT J
AU Maceda, GYC
   Li, YQ
   Lusseyran, F
   Morzynski, M
   Noack, BR
AF Cornejo Maceda, Guy Y.
   Li, Yiqing
   Lusseyran, Francois
   Morzynski, Marek
   Noack, Bernd R.
TI Stabilization of the fluidic pinball with gradient-enriched machine
   learning control
SO JOURNAL OF FLUID MECHANICS
LA English
DT Article
DE flow control; machine learning; wakes
AB We stabilize the flow past a cluster of three rotating cylinders - the fluidic pinball - with automated gradient-enriched machine learning algorithms. The control laws command the rotation speed of each cylinder in an open- and closed-loop manner. These laws are optimized with respect to the average distance from the target steady solution in three successively richer search spaces. First, stabilization is pursued with steady symmetric forcing. Second, we allow for asymmetric steady forcing. And third, we determine an optimal feedback controller employing nine velocity probes downstream. As expected, the control performance increases with every generalization of the search space. Surprisingly, both open- and closed-loop optimal controllers include an asymmetric forcing, which surpasses symmetric forcing. Intriguingly, the best performance is achieved by a combination of phasor control and asymmetric steady forcing. We hypothesize that asymmetric forcing is typical for pitchfork bifurcated dynamics of nominally symmetric configurations. Key enablers are automated machine learning algorithms augmented with gradient search: explorative gradient method for the open-loop parameter optimization and a gradient-enriched machine learning control (gMLC) for the feedback optimization. Gradient-enriched machine learning control learns the control law significantly faster thanpreviously employed genetic programming control. The gMLC source code is freely available online.
C1 [Cornejo Maceda, Guy Y.; Lusseyran, Francois] Univ Paris Saclay, CNRS, Lab Interdisciplinaire Sci Numer, F-91400 Orsay, France.
   [Li, Yiqing; Noack, Bernd R.] Harbin Inst Technol Shenzhen, Ctr Turbulence Control, Room 312,Bldg C, Shenzhen 518058, Peoples R China.
   [Morzynski, Marek] Poznan Univ Tech, Dept Virtual Engn, Jana Pawla II 24, PL-60965 Poznan, Poland.
   [Noack, Bernd R.] Tech Univ Berlin, Inst Stromungsmech & Tech Akust ISTA, Muller Breslau Str 8, D-10623 Berlin, Germany.
RP Noack, BR (corresponding author), Harbin Inst Technol Shenzhen, Ctr Turbulence Control, Room 312,Bldg C, Shenzhen 518058, Peoples R China.; Noack, BR (corresponding author), Tech Univ Berlin, Inst Stromungsmech & Tech Akust ISTA, Muller Breslau Str 8, D-10623 Berlin, Germany.
EM bernd.noack@hit.edu.cn
RI Morzynski, Marek/O-7432-2014; Noack, Bernd/B-1242-2012
OI Morzynski, Marek/0000-0002-6315-415X; CORNEJO MACEDA, Guy
   Yoslan/0000-0001-7499-7569; Lusseyran, Francois/0000-0001-8606-9321;
   Noack, Bernd/0000-0001-5935-1962; Li, Yiqing/0000-0003-2547-5363
FU French National Research Agency (ANR) via FLOwCON project 'Controle
   d'ecoulements turbulents en boucle fermee par apprentissage
   automatique'French National Research Agency (ANR) [ANR-17-ASTR-0022];
   German National Science Foundation (DFG)German Research Foundation (DFG)
   [SE 2504/1-1, SE 2504/3-1]; iCODE Institute, research project of the
   IDEX Paris-Saclay; Hadamard Mathematics LabEx (LMH)
   [ANR-11-LABX-0056-LMH]
FX This work is supported by the French National Research Agency (ANR) via
   FLOwCON project `Controle d'ecoulements turbulents en boucle fermee par
   apprentissage automatique' funded by the ANR-17-ASTR-0022, the German
   National Science Foundation (DFG grants SE 2504/1-1 and SE 2504/3-1),
   the iCODE Institute, research project of the IDEX Paris-Saclay and by
   the Hadamard Mathematics LabEx (LMH) through the grant number
   ANR-11-LABX-0056-LMH in the `Programme des Investissements d'Avenir'.
NR 64
TC 4
Z9 4
U1 9
U2 14
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0022-1120
EI 1469-7645
J9 J FLUID MECH
JI J. Fluid Mech.
PD APR 29
PY 2021
VL 917
AR A42
DI 10.1017/jfm.2021.301
PG 43
WC Mechanics; Physics, Fluids & Plasmas
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Mechanics; Physics
GA RU7CM
UT WOS:000645301800001
OA Green Submitted, hybrid
DA 2022-04-17
ER

PT J
AU Geng, ZL
   Johnson, D
   Fedkiw, R
AF Geng, Zhenglin
   Johnson, Dan
   Fedkiw, Ronald
TI Coercing machine learning to output physically accurate results
SO JOURNAL OF COMPUTATIONAL PHYSICS
LA English
DT Article
DE Machine learning; Physical simulation
ID DATA-DRIVEN; COLLISIONS; ALGORITHM; MODELS
AB Many machine/deep learning artificial neural networks are trained to simply be interpolation functions that map input variables to output values interpolated from the training data in a linear/nonlinear fashion. Even when the input/output pairs of the training data are physically accurate (e.g. the results of an experiment or numerical simulation), interpolated quantities can deviate quite far from being physically accurate. Although one could project the output of a network into a physically feasible region, such a postprocess is not captured by the energy function minimized when training the network; thus, the final projected result could incorrectly deviate quite far from the training data. We propose folding any such projection or postprocess directly into the network so that the final result is correctly compared to the training data by the energy function. Although we propose a general approach, we illustrate its efficacy on a specific convolutional neural network that takes in human pose parameters (joint rotations) and outputs a prediction of vertex positions representing a triangulated cloth mesh. While the original network outputs vertex positions with erroneously high stretching and compression energies, the new network trained with our physics "prior" remedies these issues producing highly improved results. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Geng, Zhenglin; Johnson, Dan; Fedkiw, Ronald] Stanford Univ, 353 Jane Stanford Way, Stanford, CA 94305 USA.
RP Geng, ZL (corresponding author), Stanford Univ, 353 Jane Stanford Way, Stanford, CA 94305 USA.
EM zhenglin@stanford.edu
FU ONROffice of Naval Research [N000014-13-1-0346, N00014-17-1-2174];
   JD.com; VMWare Fellowship; Stanford Graduate FellowshipStanford
   University
FX Research supported in part by ONR N000014-13-1-0346, ONR
   N00014-17-1-2174, and JD.com. We would like to thank both Reza and
   Behzad at ONR for supporting our efforts into machine learning. ZG is
   supported by a VMWare Fellowship. DJ is supported by a Stanford Graduate
   Fellowship. We would also like to thank Robert Huang and William Tsu for
   their kind donation of an Nvidia TITAN X GPU which was used to run
   experiments. This paper is dedicated to the late John McCarthy who
   coined the term Artificial Intelligence; the last author appreciates the
   many conversations he had with John not only on artificial intelligence
   but also on fluid dynamics (especially, the mixing of cream into John's
   coffee).
NR 56
TC 9
Z9 9
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0021-9991
EI 1090-2716
J9 J COMPUT PHYS
JI J. Comput. Phys.
PD APR 1
PY 2020
VL 406
AR 109099
DI 10.1016/j.jcp.2019.109099
PG 17
WC Computer Science, Interdisciplinary Applications; Physics, Mathematical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Physics
GA KN4QG
UT WOS:000514822600014
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Lyytinen, K
   Nickerson, JV
   King, JL
AF Lyytinen, Kalle
   Nickerson, Jeffrey, V
   King, John L.
TI Metahuman systems = humans plus machines that learn
SO JOURNAL OF INFORMATION TECHNOLOGY
LA English
DT Article
DE Machine learning; learning theory; technology; work groups; job design;
   organizational forms; monitoring; embodiment; autonomy
ID INFORMATION; DELEGATION; INNOVATION; MECHANISMS; OWNERSHIP; AUTHORITY;
   COMPUTER; FINTECH; PROGRAM; ECONOMY
AB Metahuman systems are new, emergent, sociotechnical systems where machines that learn join human learning and create original systemic capabilities. Metahuman systems will change many facets of the way we think about organizations and work. They will push information systems research in new directions that may involve a revision of the field's research goals, methods and theorizing. Information systems researchers can look beyond the capabilities and constraints of human learning toward hybrid human/machine learning systems that exhibit major differences in scale, scope and speed. We review how these changes influence organization design and goals. We identify four organizational level generic functions critical to organize metahuman systems properly: delegating, monitoring, cultivating, and reflecting. We show how each function raises new research questions for the field. We conclude by noting that improved understanding of metahuman systems will primarily come from learning-by-doing as information systems scholars try out new forms of hybrid learning in multiple settings to generate novel, generalizable, impactful designs. Such trials will result in improved understanding of metahuman systems. This need for large-scale experimentation will push many scholars out from their comfort zone, because it calls for the revitalization of action research programs that informed the first wave of socio-technical research at the dawn of automating work systems.
C1 [Lyytinen, Kalle] Case Western Reserve Univ, Management Design, Cleveland, OH 44106 USA.
   [Nickerson, Jeffrey, V] Stevens Inst Technol, Res, Hoboken, NJ 07030 USA.
   [Nickerson, Jeffrey, V] Stevens Inst Technol, Sch Business, Hoboken, NJ 07030 USA.
   [King, John L.] Univ Michigan, Sch Informat, Ann Arbor, MI 48109 USA.
RP Nickerson, JV (corresponding author), Stevens Inst Technol, Hoboken, NJ 07030 USA.
EM jnickerson@stevens.edu
NR 195
TC 11
Z9 11
U1 25
U2 25
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0268-3962
EI 1466-4437
J9 J INF TECHNOL-UK
JI J. Inf. Technol.
PD DEC
PY 2021
VL 36
IS 4
BP 427
EP 445
DI 10.1177/0268396220915917
PG 19
WC Computer Science, Information Systems; Information Science & Library
   Science; Management
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Information Science & Library Science; Business &
   Economics
GA WS1QY
UT WOS:000714965400005
DA 2022-04-17
ER

PT C
AU Caporusso, N
   Helms, T
   Zhang, P
AF Caporusso, Nicholas
   Helms, Trent
   Zhang, Peng
BE Ahram, T
TI A Meta-Language Approach for Machine Learning
SO ADVANCES IN ARTIFICIAL INTELLIGENCE, SOFTWARE AND SYSTEMS ENGINEERING
SE Advances in Intelligent Systems and Computing
LA English
DT Proceedings Paper
CT 10th Int Conf on Appl Human Factors and Ergon (AHFE) / AHFE Int Conf
   Human Factors in Artificial Intelligence and Social Comp / AHFE Int Conf
   on Human Factors, Software, Serv and Syst Engn / AHFE Int Conf of Human
   Factors in Energy
CY JUL 24-28, 2019
CL Washington, DC
SP AHFE
DE End-user development; Artificial intelligence; Machine learning; Neural
   networks; Meta-design; Goal question metric
AB In the last decade, machine learning has increasingly been utilized for solving various types of problems in different domains, such as, manufacturing finance, and healthcare. However, designing and fine-tuning algorithms require extensive expertise in artificial intelligence. Although many software packages wrap the complexity of machine learning and simplify their use, programming skills are still needed for operating algorithms and interpreting their results. Additionally, as machine learning experts and non-technical users have different backgrounds and skills, they experience issues in exchanging information about requirements, features, and structure of input and output data.
   This paper introduces a meta-language based on the Goal-Question-Metric paradigm to facilitate the design of machine learning algorithms and promote end-user development. The proposed methodology was initially developed to formalize the relationship between conceptual goals, operational questions, and quantitative metrics, so that measurable items can help quantify qualitative goals. Conversely, in our work, we apply it to machine learning with a two-fold objective: (1) empower non-technical users to operate artificial intelligence systems, and (2) provide all the stakeholders, such as, programmers and domain experts, with a modeling language.
C1 [Caporusso, Nicholas; Helms, Trent; Zhang, Peng] Ft Hays State Univ, 600 Pk St, Hays, KS 67601 USA.
RP Caporusso, N (corresponding author), Ft Hays State Univ, 600 Pk St, Hays, KS 67601 USA.
EM n_caporusso@fhsu.edu; tehelms@mail.fhsu.edu;
   p_zhang15_sia.se@mail.fhsu.edu
NR 25
TC 0
Z9 0
U1 1
U2 11
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2194-5357
EI 2194-5365
BN 978-3-030-20454-9; 978-3-030-20453-2
J9 ADV INTELL SYST
PY 2020
VL 965
BP 192
EP 201
DI 10.1007/978-3-030-20454-9_19
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BO1CL
UT WOS:000494940300019
DA 2022-04-17
ER

PT J
AU Evangelista, E
AF Evangelista, Edmund
TI A Hybrid Machine Learning Framework for Predicting Students' Performance
   in Virtual Learning Environment
SO INTERNATIONAL JOURNAL OF EMERGING TECHNOLOGIES IN LEARNING
LA English
DT Article
DE machine learning; Weka; predictive model; ensemble; student performance
   prediction; classification algorithm; virtual learning
ID FEATURE-SELECTION
AB Virtual Learning Environments (VLE), such as Moodie and Blackboard, store vast data to help identify students' performance and engagement. As a result, researchers have been focusing their efforts on assisting educational institutions in providing machine learning models to predict at-risk students and to improve their performance. However, it requires an efficient approach to construct a model that can ultimately provide accurate predictions. Consequently, this study proposed a hybrid machine learning framework to predict students' performance using eight classification algorithms and three ensemble methods (Bagging, Boosting, Voting) to determine the best-performing predictive model. In addition, this study used filter-based and wrapper-based feature selection techniques to select the best features of the dataset related to students' performance. The obtained results reveal that the ensemble methods recorded higher predictive accuracy when compared to single classifiers. Furthermore, the accuracy of the models improved due to the feature selection techniques utilized in this study.
C1 [Evangelista, Edmund] Zayed Univ, Abu Dhabi Campus, Abu Dhabi, U Arab Emirates.
RP Evangelista, E (corresponding author), Zayed Univ, Abu Dhabi Campus, Abu Dhabi, U Arab Emirates.
EM edmund.evangelista@zu.ac.ae
FU Zayed University (Abu Dhabi Campus) [R21042]; College of Technological
   Innovation [R21042]; Department of Information Systems and Technology
   Management [R21042]
FX The author wishes to thank Zayed University (Abu Dhabi Campus) , the
   College of Technological Innovation, and the Department of Information
   Systems and Technology Management for their exceptional support and
   start-up grant (R21042) provided in completing this study.
NR 63
TC 0
Z9 0
U1 2
U2 2
PU KASSEL UNIV PRESS GMBH
PI KASSEL
PA DIAGONALE 10, D-34127 KASSEL, GERMANY
EI 1863-0383
J9 INT J EMERG TECHNOL
JI Int. J. Emerg. Technol. Learn.
PY 2021
VL 16
IS 24
BP 255
EP 272
DI 10.3991/ijet.v16i24.26151
PG 18
WC Education & Educational Research
WE Emerging Sources Citation Index (ESCI)
SC Education & Educational Research
GA YI0NI
UT WOS:000743553900017
OA gold
DA 2022-04-17
ER

PT J
AU Yang, SW
   Hyon, YK
   Na, HS
   Jin, L
   Lee, JG
   Park, JM
   Lee, JY
   Shin, JH
   Lim, JS
   Na, YG
   Jeon, K
   Ha, T
   Kim, J
   Song, KH
AF Yang, Seung Woo
   Hyon, Yun Kyong
   Na, Hyun Seok
   Jin, Long
   Lee, Jae Geun
   Park, Jong Mok
   Lee, Ji Yong
   Shin, Ju Hyun
   Lim, Jae Sung
   Na, Yong Gil
   Jeon, Kiwan
   Ha, Taeyoung
   Kim, Jinbum
   Song, Ki Hak
TI Machine learning prediction of stone-free success in patients with
   urinary stone after treatment of shock wave lithotripsy
SO BMC UROLOGY
LA English
DT Article
DE Lithotripsy; Machine learning; Artificial intelligence
ID HOUNSFIELD UNITS; SKELETAL-MUSCLE; TOMOGRAPHY; SARCOPENIA; DISTANCE;
   SKIN
AB Background The aims of this study were to determine the predictive value of decision support analysis for the shock wave lithotripsy (SWL) success rate and to analyze the data obtained from patients who underwent SWL to assess the factors influencing the outcome by using machine learning methods. Methods We retrospectively reviewed the medical records of 358 patients who underwent SWL for urinary stone (kidney and upper-ureter stone) between 2015 and 2018 and evaluated the possible prognostic features, including patient population characteristics, urinary stone characteristics on a non-contrast, computed tomographic image. We performed 80% training set and 20% test set for the predictions of success and mainly used decision tree-based machine learning algorithms, such as random forest (RF), extreme gradient boosting trees (XGBoost), and light gradient boosting method (LightGBM). Results In machine learning analysis, the prediction accuracies for stone-free were 86.0, 87.5, and 87.9%, and those for one-session success were 78.0, 77.4, and 77.0% using RF, XGBoost, and LightGBM, respectively. In predictions for stone-free, LightGBM yielded the best accuracy and RF yielded the best one in those for one-session success among those methods. The sensitivity and specificity values for machine learning analytics are (0.74 to 0.78 and 0.92 to 0.93) for stone-free and (0.79 to 0.81 and 0.74 to 0.75) for one-session success, respectively. The area under curve (AUC) values for machine learning analytics are (0.84 to 0.85) for stone-free and (0.77 to 0.78) for one-session success and their 95% confidence intervals (CIs) are (0.730 to 0.933) and (0.673 to 0.866) in average of methods, respectively. Conclusions We applied a selected machine learning analysis to predict the result after treatment of SWL for urinary stone. About 88% accurate machine learning based predictive model was evaluated. The importance of machine learning algorithm can give matched insights to domain knowledge on effective and influential factors for SWL success outcomes.
C1 [Yang, Seung Woo; Na, Hyun Seok; Jin, Long; Lee, Jae Geun; Park, Jong Mok; Lee, Ji Yong; Shin, Ju Hyun; Lim, Jae Sung; Na, Yong Gil; Song, Ki Hak] Chungnam Natl Univ, Dept Urol, Coll Med, Chungnam Natl Univ Hosp, 282 Monwha Ro, Daejeon 35015, South Korea.
   [Hyon, Yun Kyong; Jeon, Kiwan; Ha, Taeyoung] Natl Inst Math Sci, Div Med Math, 70 Yuseong Daero 1689beon Gil, Daejeon 34047, South Korea.
   [Kim, Jinbum] Konyang Univ, Coll Med, Dept Urol, Konyang Univ Hosp, 158 Gwanjeodong Ro, Daejeon 35365, South Korea.
RP Song, KH (corresponding author), Chungnam Natl Univ, Dept Urol, Coll Med, Chungnam Natl Univ Hosp, 282 Monwha Ro, Daejeon 35015, South Korea.
EM urosong@cnu.ac.kr
FU Chungnam National University Hospital Research Fund; National Institute
   for Mathematical Sciences (NIMS) - Korea government [NIMS-B20900000]
FX This research was supported by the Chungnam National University Hospital
   Research Fund, 2018-2019. This research was also supported by National
   Institute for Mathematical Sciences (NIMS) grant funded by the Korea
   government, 2020 (No. NIMS-B20900000). Chungnam National University
   Hospital Research Fund support the design of the study. NIMS-B20900000
   was mainly used for analysis of machine learning.
NR 30
TC 4
Z9 4
U1 2
U2 4
PU BMC
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 1471-2490
J9 BMC UROL
JI BMC Urol.
PD JUL 3
PY 2020
VL 20
IS 1
AR 88
DI 10.1186/s12894-020-00662-x
PG 8
WC Urology & Nephrology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Urology & Nephrology
GA MK5AD
UT WOS:000548798700003
PM 32620102
OA Green Published, gold
DA 2022-04-17
ER

PT C
AU Takahashi, S
   Higa, H
AF Takahashi, Shinto
   Higa, Hiroki
GP IEEE
TI EMG-Based Interface Using Machine Learning
SO 2020 5TH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATICS AND
   BIOMEDICAL SCIENCES (ICIIBMS 2020)
SE International Conference on Intelligent Informatics and Biomedical
   Sciences ICIIBMS
LA English
DT Proceedings Paper
CT 5th International Conference on Intelligent Informatics and Biomedical
   Sciences (ICIIBMS)
CY NOV 18-20, 2020
CL Naha, JAPAN
SP Univ Ryukyus, OIST, ONCT, ACS Publicat, IEEE Fukuoka Sect
DE EMG Signal; Machine Learning; Myoelectric Prosthesis
AB This paper presents an EMG (electromyogram)based input interface using machine learning for people with physical disabilities of the extremities. We have developed a virtual hand that can be operated in virtual environment using EMG signals. In this paper, we performed a lifting object task and box and block test task with the virtual hand. From the experimental results of the lifting object tasks, it was confirmed that six wrist joint movements were classified, and that an experimental subject appropriately lifted objects with the virtual hand in the virtual space. In the box and block tests task, it was confirmed that he moved block(s) to the opposite side of the box 9 times within 60 sec.
C1 [Takahashi, Shinto] Univ Ryukyus, Grad Sch Engn & Sci, Nishihara, Okinawa, Japan.
   [Higa, Hiroki] Univ Ryukyus, Faculy Engn, Nishihara, Okinawa, Japan.
RP Takahashi, S (corresponding author), Univ Ryukyus, Grad Sch Engn & Sci, Nishihara, Okinawa, Japan.
EM k208522@eve.u-ryukyu.ac.jp
FU JSPS KAKENHIMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) [C-19K11349]
FX This work is partly supported by JSPS KAKENHI, Grant-in-Aid for
   Scientific Research (C): Grant C-19K11349.
NR 9
TC 0
Z9 0
U1 2
U2 2
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2189-8723
BN 978-1-7281-8022-9
J9 INT CONF INTEL INFOR
PY 2020
BP 57
EP 60
DI 10.1109/CIIBMS50712.2020.9336203
PG 4
WC Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Engineering, Biomedical; Medical Informatics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Medical Informatics
GA BR6DG
UT WOS:000659932400013
DA 2022-04-17
ER

PT C
AU Tahir, GA
   Loo, CK
AF Tahir, Ghalib Ahmed
   Loo, Chu Kiong
GP IEEE
TI Mitigating Catastrophic Forgetting In Adaptive Class Incremental Extreme
   Learning Machine Through Neuron Clustering
SO 2020 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS
   (SMC)
SE IEEE International Conference on Systems Man and Cybernetics Conference
   Proceedings
LA English
DT Proceedings Paper
CT IEEE International Conference on Systems, Man, and Cybernetics (SMC)
CY OCT 11-14, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Syst Man & Cybernet Soc, IEEE Brain, Intheon, Guger Technologies
DE Catastrophic Forgetting; Neuron Clustering; Extreme Learning Machine;
   Continual Learning; Food Recognition
AB Catastrophic forgetting is a major problem that affects neural networks during progressive learning. In it, the previously learned representation vanishes as the network learns new information. The extreme learning machine is one of the variants of the neural network. It is used in many domains due to fast training and good generalization ability. However, like other neural networks, it suffers from catastrophic forgetting and negative forward and backward transfer during the progression of neurons in incremental learning. The study hypothesizes that it is due to overlapping in hidden neurons and output weights. The global representation by an activation function further supports this hypothesis. To address this, the study proposes a neuron clustering approach to mitigate it in an adaptive class incremental extreme learning machine. The neuron clustering method activates k nearest neurons during learning and testing. It helps to partition the network to select overlapping subnetwork. Experimental results on four food datasets show that the proposed approach reduces negative forward and backward transfer when neurons are added incrementally during progressive learning.
C1 [Tahir, Ghalib Ahmed; Loo, Chu Kiong] Univ Malaya, Dept Artificial Intelligence, Adv Robot Lab, FSKTM, Kuala Lumpur, Malaysia.
RP Tahir, GA (corresponding author), Univ Malaya, Dept Artificial Intelligence, Adv Robot Lab, FSKTM, Kuala Lumpur, Malaysia.
EM ghalib@siswa.um.edu.my; ckloo.um@um.edu.my
FU ONRG NICOP Grant from the Office of Naval Research Global, UKOffice of
   Naval Research [IF017-2018]; IIRG Grant from University of Malaya
   [IIRG002C-19HWB]; International Collaboration Fund for project
   Developmental Cognitive Robot with Continual Lifelong Learning from
   MESTECC, Malaysia [IF0318M1006]; Partnership Grant Malaysia [RK012-2019]
FX This research was supported by the ONRG NICOP Grant (Project No:
   IF017-2018) from the Office of Naval Research Global, UK; IIRG Grant
   (IIRG002C-19HWB) from University of Malaya and International
   Collaboration Fund for project Developmental Cognitive Robot with
   Continual Lifelong Learning (IF0318M1006) from MESTECC, Malaysia and
   Partnership Grant (PROJECT NO :RK012-2019) Malaysia.
NR 23
TC 0
Z9 0
U1 0
U2 2
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1062-922X
BN 978-1-7281-8526-2
J9 IEEE SYS MAN CYBERN
PY 2020
BP 3903
EP 3910
PG 8
WC Computer Science, Cybernetics; Computer Science, Information Systems
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS1DD
UT WOS:000687430603146
DA 2022-04-17
ER

PT J
AU Jameel, SK
   Aydin, S
   Ghaeb, NH
AF Jameel, Samer Kais
   Aydin, Sezgin
   Ghaeb, Nebras H.
TI Machine Learning Techniques for Corneal Diseases Diagnosis: A Survey
SO INTERNATIONAL JOURNAL OF IMAGE AND GRAPHICS
LA English
DT Article
DE Machine learning; corneal disease diagnosis; computer-aided diagnosis
   (CAD)
ID COMPUTER-AIDED DIAGNOSIS; KERATOCONUS DETECTION; NEURAL-NETWORK;
   CLASSIFICATION; SYSTEM
AB Machine learning techniques become more related to medical researches by using medical images as a dataset. It is categorized and analyzed for ultimate effectiveness in diagnosis or decision-making for diseases. Machine learning techniques have been exploited in numerous researches related to corneal diseases, contribution to ophthalmologists for diagnosing the diseases and comprehending the way automated learning techniques act. Nevertheless, confusion still exists in the type of data used, whether it is images, data extracted from images or clinical data, the course reliant on the type of device for obtaining them. In this study, the researches that used machine learning were reviewed and classified in terms of the kind of utilized machine for capturing data, along with the latest updates in sophisticated approaches for corneal disease diagnostic techniques.
C1 [Jameel, Samer Kais] Aksary Univ, Elect Elect & Comp Engn Dept, Aksaray, Turkey.
   [Jameel, Samer Kais] Raparin Univ, Sulaymaniyah, Iraq.
   [Aydin, Sezgin] Tarsus Univ, Fac Engn, Dept Nat & Math Sci, Mersin, Turkey.
   [Ghaeb, Nebras H.] Univ Baghdad, Dept Biomed Engn, Al Khawarezmi Engn Coll, Baghdad, Iraq.
RP Jameel, SK (corresponding author), Aksary Univ, Elect Elect & Comp Engn Dept, Aksaray, Turkey.; Jameel, SK (corresponding author), Raparin Univ, Sulaymaniyah, Iraq.
EM samer.kais@uor.edu.krd; 01sezgin@gmail.com;
   nebras@kecbu.uobaghdad.edu.iq
RI Al Anbaki, Nebras/E-9285-2016
OI Al Anbaki, Nebras/0000-0002-9812-0718
NR 49
TC 0
Z9 0
U1 2
U2 3
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0219-4678
EI 1793-6756
J9 INT J IMAGE GRAPH
JI Int. J. Image Graph.
PD APR
PY 2021
VL 21
IS 02
AR 2150016
DI 10.1142/S0219467821500169
PG 18
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA RW6JQ
UT WOS:000646628900012
DA 2022-04-17
ER

PT J
AU Blaschke, T
   Feldmann, C
   Bajorath, J
AF Blaschke, Thomas
   Feldmann, Christian
   Bajorath, Juergen
TI Prediction of Promiscuity Cliffs Using Machine Learning
SO MOLECULAR INFORMATICS
LA English
DT Article
DE multitarget activity; promiscuity; polypharmacology; machine learning;
   deep learning; structure-promiscuity relationships
ID IDENTIFIES PROMISCUITY; DRUG DISCOVERY; POLYPHARMACOLOGY
AB Compounds with the ability to interact with multiple targets, also called promiscuous compounds, provide the basis for polypharmacological drug discovery. In recent years, a plethora of structural analogs with different promiscuity has been identified. Nevertheless, the molecular origins of promiscuity remain to be elucidated. In this study, we systematically extracted different structural analogs with varying promiscuity using the matched molecular pair (MMP) formalism from public biological screening and medicinal chemistry data. Care was taken to eliminate all compounds with potential false-positive activity annotations from the analysis. Promiscuity predictions were then attempted at the level of compound pairs representing promiscuity cliffs (PCs; formed by analogs with large promiscuity differences) and corresponding non-PC MMPs (analog pairs without significant promiscuity differences). To address this prediction task, different machine learning models were generated and the results were compared with single compound predictions. PCs encoding promiscuity differences were found to contain more structure-promiscuity relationship information than sets of individual promiscuous compounds. In addition, feature analysis was carried out revealing key contributions to the correct prediction of PCs and non-PC MMPs via machine learning.
C1 [Blaschke, Thomas; Feldmann, Christian; Bajorath, Juergen] Rheinische Friedrich Wilhelms Univ, LIMES Program Unit Chem Biol & Med Chem, B IT, Dept Life Sci Informat, Endenicher Allee 19c, D-53115 Bonn, Germany.
RP Bajorath, J (corresponding author), Rheinische Friedrich Wilhelms Univ, LIMES Program Unit Chem Biol & Med Chem, B IT, Dept Life Sci Informat, Endenicher Allee 19c, D-53115 Bonn, Germany.
EM bajorath@bit.uni-bonn.de
OI Bajorath, Jurgen/0000-0002-0557-5714
NR 42
TC 1
Z9 1
U1 1
U2 3
PU WILEY-V C H VERLAG GMBH
PI WEINHEIM
PA POSTFACH 101161, 69451 WEINHEIM, GERMANY
SN 1868-1743
EI 1868-1751
J9 MOL INFORM
JI Mol. Inf.
PD JAN
PY 2021
VL 40
IS 1
DI 10.1002/minf.202000196
EA SEP 2020
PG 11
WC Chemistry, Medicinal; Computer Science, Interdisciplinary Applications;
   Mathematical & Computational Biology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Pharmacology & Pharmacy; Computer Science; Mathematical & Computational
   Biology
GA PQ4GR
UT WOS:000573517300001
PM 32881355
OA Green Published, hybrid
DA 2022-04-17
ER

PT J
AU Ma, YL
   Han, RZ
   Wang, WZ
AF Ma, Yilin
   Han, Ruizhu
   Wang, Weizhong
TI Portfolio optimization with return prediction using deep learning and
   machine learning
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Financial trading; Return prediction; Portfolio optimization; Deep
   learning; Machine learning
ID STOCK-MARKET PREDICTION; TIME-SERIES; NEURAL-NETWORKS; RANDOM FORESTS;
   MODEL; SELECTION
AB Integrating return prediction of traditional time series models in portfolio formation can improve the performance of original portfolio optimization model. Since machine learning and deep learning models have shown overwhelming superiority than time series models, this paper combines return prediction in portfolio formation with two machine learning models, i.e., random forest (RF) and support vector regression (SVR), and three deep learning models, i.e., LSTM neural network, deep multilayer perceptron (DMLP) and convolutional neural network. To be specific, this paper first applies these prediction models for stock preselection before portfolio formation. Then, this paper incorporates their predictive results in advancing mean-variance (MV) and omega portfolio optimization models. In order to present the superiority of these models, portfolio models with autoregressive integrated moving average's return prediction are used as benchmarks. Evaluation is based on historical data of 9 years from 2007 to 2015 of component stocks of China securities 100 index. Experimental results show that MV and omega models with RF return prediction, i.e., RF+MVF and RF+OF, outperform the other models. Further, RF+MVF is superior to RF+OF. Due to the high turnover of these two models, this paper discusses their performance after deducting the transaction fee cased by turnover. Experiments present that RF+MVF still performs the best among MVF models and omega model with SVR prediction (SVR+OF) performs the best among OF models. Moreover, RF+MVF performs better than SVR+OF and high turnover erodes nearly half of their total returns especially for RF+OF and RF+MVF. Therefore, this paper recommends investors to build MVF with RF return prediction for daily trading investment.
C1 [Ma, Yilin; Han, Ruizhu; Wang, Weizhong] Southeast Univ, Sch Econ & Management, 2 Southeast Univ Rd, Nanjing 211189, Peoples R China.
RP Han, RZ (corresponding author), Southeast Univ, Sch Econ & Management, 2 Southeast Univ Rd, Nanjing 211189, Peoples R China.
EM ylmaseu@163.com; daodao-777@163.com; wangweizhongky@163.com
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [71390335]
FX This research was supported by the National Natural Science Foundation
   of China (No. 71390335).
NR 64
TC 11
Z9 11
U1 29
U2 128
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD MAR 1
PY 2021
VL 165
AR 113973
DI 10.1016/j.eswa.2020.113973
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Operations Research & Management Science
GA PL0IE
UT WOS:000602816000011
DA 2022-04-17
ER

PT J
AU Usman, M
   Wang, WX
   Wang, KY
   Yelen, C
   Dini, N
   Khurshid, S
AF Usman, Muhammad
   Wang, Wenxi
   Wang, Kaiyuan
   Yelen, Cagdas
   Dini, Nima
   Khurshid, Sarfraz
TI A study of learning likely data structure properties using machine
   learning models
SO INTERNATIONAL JOURNAL ON SOFTWARE TOOLS FOR TECHNOLOGY TRANSFER
LA English
DT Article
DE Data structure invariants; Machine learning; Korat; Learnability
AB Data structure properties are important for many testing and analysis tasks. For example, model checkers use these properties to find program faults. These properties are often written manually which can be error prone and lead to false alarms. This paper presents the results of controlled experiments performed using existing machine learning (ML) models on various data structures. These data structures are dynamic and reside on the program heap. We use ten data structure subjects and ten ML models to evaluate the learnability of data structure properties. The study reveals five key findings. One, most of the ML models perform well in learning data structure properties, but some of the ML models such as quadratic discriminant analysis and Gaussian naive Bayes are not suitable for learning data structure properties. Two, most of the ML models have high performance even when trained on just 1% of data samples. Three, certain data structure properties such as binary heap and red black tree are more learnable than others. Four, there are no significant differences between the learnability of varied-size (i.e., up to a certain size) and fixed-size data structures. Five, there can be significant differences in performance based on the encoding used. These findings show that using machine learning models to learn data structure properties is very promising. We believe that these properties, once learned, can be used to provide a run-time check to see whether a program state at a particular point satisfies the learned property. Learned properties can also be employed in the future to automate static and dynamic analysis, which would enhance software testing and verification techniques.
C1 [Usman, Muhammad; Wang, Wenxi; Wang, Kaiyuan; Yelen, Cagdas; Dini, Nima; Khurshid, Sarfraz] Univ Texas Austin, Austin, TX 78712 USA.
RP Usman, M (corresponding author), Univ Texas Austin, Austin, TX 78712 USA.
EM muhammadusman@utexas.edu; wenxiw@utexas.edu; kaiyuanw@utexas.edu;
   cagdas@utexas.edu; nima.dini@utexas.cdu; khurshid@utexas.edu
FU US National Science FoundationNational Science Foundation (NSF)
   [CCF-1704790, CCF-1718903]
FX We thank Rohan Garg, Emily Ginsburg, Michael Herrington, Tara Kuruvilla,
   Raghav Prakash and the anonymous reviewers for helpful feedback and
   comments. This research was partially supported by the US National
   Science Foundation under Grant Nos. CCF-1704790 and CCF-1718903.
NR 67
TC 1
Z9 1
U1 4
U2 6
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1433-2779
EI 1433-2787
J9 INT J SOFTW TOOLS TE
JI Int. J. Softw. Tools Technol. Transf.
PD OCT
PY 2020
VL 22
IS 5
SI SI
BP 601
EP 615
DI 10.1007/s10009-020-00577-w
EA JUN 2020
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NT9OM
UT WOS:000538700800001
DA 2022-04-17
ER

PT J
AU Bujang, SDA
   Selamat, A
   Ibrahim, R
   Krejcar, O
   Herrera-Viedma, E
   Fujita, H
   Ghani, NAM
AF Bujang, Siti Dianah Abdul
   Selamat, Ali
   Ibrahim, Roliana
   Krejcar, Ondrej
   Herrera-Viedma, Enrique
   Fujita, Hamido
   Ghani, Nor Azura Md.
TI Multiclass Prediction Model for Student Grade Prediction Using Machine
   Learning
SO IEEE ACCESS
LA English
DT Article
DE Predictive models; Prediction algorithms; Support vector machines;
   Machine learning; Classification algorithms; Data models; Machine
   learning algorithms; Machine learning; predictive model; imbalanced
   problem; student grade prediction; multi-class classification
ID EDUCATIONAL DATA; ANALYTICS
AB Today, predictive analytics applications became an urgent desire in higher educational institutions. Predictive analytics used advanced analytics that encompasses machine learning implementation to derive high-quality performance and meaningful information for all education levels. Mostly know that student grade is one of the key performance indicators that can help educators monitor their academic performance. During the past decade, researchers have proposed many variants of machine learning techniques in education domains. However, there are severe challenges in handling imbalanced datasets for enhancing the performance of predicting student grades. Therefore, this paper presents a comprehensive analysis of machine learning techniques to predict the final student grades in the first semester courses by improving the performance of predictive accuracy. Two modules will be highlighted in this paper. First, we compare the accuracy performance of six well-known machine learning techniques namely Decision Tree (J48), Support Vector Machine (SVM), Naive Bayes (NB), K-Nearest Neighbor (kNN), Logistic Regression (LR) and Random Forest (RF) using 1282 real student's course grade dataset. Second, we proposed a multiclass prediction model to reduce the overfitting and misclassification results caused by imbalanced multi-classification based on oversampling Synthetic Minority Oversampling Technique (SMOTE) with two features selection methods. The obtained results show that the proposed model integrates with RF give significant improvement with the highest f-measure of 99.5%. This proposed model indicates the comparable and promising results that can enhance the prediction performance model for imbalanced multi-classification for student grade prediction.
C1 [Bujang, Siti Dianah Abdul; Selamat, Ali] Univ Teknol Malaysia, Malaysia Japan Int Inst Technol MJIIT, Kuala Lumpur 54100, Malaysia.
   [Selamat, Ali; Ibrahim, Roliana] Univ Teknol Malaysia, Sch Comp, Fac Engn, Johor Baharu 81310, Malaysia.
   [Selamat, Ali; Ibrahim, Roliana] Univ Teknol Malaysia, Sch Comp, Fac Engn, Media & Games Ctr Excellence MagicX, Johor Baharu 81310, Malaysia.
   [Krejcar, Ondrej] Univ Hradec Kralove, Fac Informat & Management, Hradec Kralove 50003, Czech Republic.
   [Herrera-Viedma, Enrique] Univ Granada, Andalusian Res Inst Data Sci & Computat Intellige, Dept Comp Sci & AI, Granada 18071, Spain.
   [Fujita, Hamido] I SOMET Inc Assoc, Morioka, Iwate 0200104, Japan.
   [Ghani, Nor Azura Md.] Univ Teknol MARA, Fac Comp & Math Sci, Shah Alam 40450, Selangor, Malaysia.
RP Selamat, A (corresponding author), Univ Teknol Malaysia, Malaysia Japan Int Inst Technol MJIIT, Kuala Lumpur 54100, Malaysia.; Selamat, A (corresponding author), Univ Teknol Malaysia, Sch Comp, Fac Engn, Johor Baharu 81310, Malaysia.; Selamat, A (corresponding author), Univ Teknol Malaysia, Sch Comp, Fac Engn, Media & Games Ctr Excellence MagicX, Johor Baharu 81310, Malaysia.
EM aselamat@utm.my
RI Selamat, Ali/E-9645-2011; Fujita, Hamido/D-6249-2012; Krejcar,
   Ondrej/A-8639-2008; Herrera-Viedma, Enrique/C-2704-2008
OI Selamat, Ali/0000-0001-9746-8459; Fujita, Hamido/0000-0001-5256-210X;
   Krejcar, Ondrej/0000-0002-5992-2574; abdul bujang, siti
   dianah/0000-0003-3306-3246; Herrera-Viedma, Enrique/0000-0002-7922-4984
FU Ministry of Higher EducationScience and Technology Development Fund
   (STDF)Ministry of Higher Education & Scientific Research (MHESR)
   [FRGS/1/2018/ICT04/UTM/01/1]; Specific Research Project (SPEV) at the
   Faculty of Informatics and Management, University of Hradec Kralove,
   Czech Republic [2102-2021]; Universiti Teknologi Malaysia (UTM)
   [Vot-20H04]; Malaysia Research University Network (MRUN) [4L876]
FX This work was supported in part by the Ministry of Higher Education
   through the Fundamental Research Scheme under Grant
   FRGS/1/2018/ICT04/UTM/01/1, in part by the Speci~c Research Project
   (SPEV) at the Faculty of Informatics and Management, University of
   Hradec Kralove, Czech Republic, under Grant 2102-2021, in part by the
   Universiti Teknologi Malaysia (UTM) under Research University Grant
   Vot-20H04, and in part by the Malaysia Research University Network
   (MRUN) under Grant Vot 4L876.
NR 40
TC 2
Z9 2
U1 19
U2 30
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 95608
EP 95621
DI 10.1109/ACCESS.2021.3093563
PG 14
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA TJ8CQ
UT WOS:000673703100001
OA gold, Green Published
DA 2022-04-17
ER

PT J
AU Soares, N
   de Aguiar, EP
   Souza, AC
   Goliatt, L
AF Soares, Nielson
   de Aguiar, Eduardo Pestana
   Souza, Amanda Campos
   Goliatt, Leonardo
TI Unsupervised machine learning techniques to prevent faults in railroad
   switch machines
SO INTERNATIONAL JOURNAL OF CRITICAL INFRASTRUCTURE PROTECTION
LA English
DT Article
DE Railroad switch; Computational intelligence; Machine learning; Failure
   prediction
ID CLASSIFICATION; MODEL
AB Railroad switch machines are essential electromechanical equipment in a railway network, and the occurrence of failures in such equipment can cause railroad interruptions and lead to potential economic losses. Thus, early diagnosis of these failures can represent a reduction in costs and an increase in productivity. This paper aims to propose a predictive model based on computational intelligence techniques, to solve this problem. The applied methodology includes feature extraction and selection procedures based on hypothesis tests and unsupervised machine learning models. The proposed model was tested in a database made available by a Brazilian railway company and proved to be efficient once it has considered critical operations conducted in the vicinity of the ones classified as faults.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Soares, Nielson; de Aguiar, Eduardo Pestana; Souza, Amanda Campos; Goliatt, Leonardo] Univ Fed Juiz de Fora, Juiz De Fora, MG, Brazil.
RP Goliatt, L (corresponding author), Univ Fed Juiz de Fora, Juiz De Fora, MG, Brazil.
RI de Aguiar, Eduardo Pestana/Y-2138-2019
OI de Aguiar, Eduardo Pestana/0000-0001-7458-8976
FU MRS Logistica S.A.; Federal University of Juiz de Fora; CAPESCoordenacao
   de Aperfeicoamento de Pessoal de Nivel Superior (CAPES) [001]
FX This work was supported by MRS Logistica S.A., Federal University of
   Juiz de Fora and CAPES Finance Code 001.
NR 56
TC 2
Z9 2
U1 5
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1874-5482
EI 2212-2087
J9 INT J CRIT INFR PROT
JI Int. J. Crit. Infrastruct. Prot.
PD JUN
PY 2021
VL 33
AR 100423
DI 10.1016/j.ijcip.2021.100423
EA FEB 2021
PG 14
WC Computer Science, Information Systems; Engineering, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SD4VT
UT WOS:000651372100006
DA 2022-04-17
ER

PT J
AU Caiafa, CF
   Sun, Z
   Tanaka, T
   Marti-Puig, P
   Sole-Casals, J
AF Caiafa, Cesar F.
   Sun, Zhe
   Tanaka, Toshihisa
   Marti-Puig, Pere
   Sole-Casals, Jordi
TI Machine Learning Methods with Noisy, Incomplete or Small Datasets
SO APPLIED SCIENCES-BASEL
LA English
DT Editorial Material
DE artificial intelligence; imperfect dataset; imperfect dataset; machine
   learning
ID NEURAL-NETWORK; CLASSIFICATION; IMPACT
AB In this article, we present a collection of fifteen novel contributions on machine learning methods with low-quality or imperfect datasets, which were accepted for publication in the special issue "Machine Learning Methods with Noisy, Incomplete or Small Datasets", Applied Sciences (ISSN 2076-3417). These papers provide a variety of novel approaches to real-world machine learning problems where available datasets suffer from imperfections such as missing values, noise or artefacts. Contributions in applied sciences include medical applications, epidemic management tools, methodological work, and industrial applications, among others. We believe that this special issue will bring new ideas for solving this challenging problem, and will provide clear examples of application in real-world scenarios.
C1 [Caiafa, Cesar F.] UNLP, CONICET, CIC PBA, Inst Argentino Radioastron CCT La Plata, RA-1894 V Elisa, Argentina.
   [Sun, Zhe] RIKEN, Head Off Informat Syst & Cybersecur, Computat Engn Applicat Unit, Wako, Saitama 3510198, Japan.
   [Tanaka, Toshihisa] Tokyo Univ Agr & Technol, Dept Elect & Elect Engn, Tokyo 1848588, Japan.
   [Marti-Puig, Pere; Sole-Casals, Jordi] Cent Univ Catalonia, Univ Vic, Data & Signal Proc Res Grp, Barcelona 08500, Spain.
RP Caiafa, CF (corresponding author), UNLP, CONICET, CIC PBA, Inst Argentino Radioastron CCT La Plata, RA-1894 V Elisa, Argentina.; Sole-Casals, J (corresponding author), Cent Univ Catalonia, Univ Vic, Data & Signal Proc Res Grp, Barcelona 08500, Spain.
EM ccaiafa@gmail.com; zhe.sun.vk@riken.jp; tanakt@cc.tuat.ac.jp;
   pere.marti@uvic.cat; jordi.sole@uvic.cat
RI Solé-Casals, Jordi/B-7754-2008; Marti-Puig, Pere/I-2797-2015
OI Solé-Casals, Jordi/0000-0002-6534-1979; Marti-Puig,
   Pere/0000-0001-6582-4551; Caiafa, Cesar F./0000-0001-5437-6095; zhe,
   sun/0000-0002-6531-0769
NR 15
TC 0
Z9 0
U1 6
U2 12
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD MAY
PY 2021
VL 11
IS 9
AR 4132
DI 10.3390/app11094132
PG 4
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Materials Science; Physics
GA SB3OR
UT WOS:000649908600001
OA Green Published
DA 2022-04-17
ER

PT J
AU Sepulveda, NFE
   Sinha, JK
AF Espinoza Sepulveda, Natalia F.
   Sinha, Jyoti K.
TI Blind Application of Developed Smart Vibration-Based Machine Learning
   (SVML) Model for Machine Faults Diagnosis to Different Machine
   Conditions
SO JOURNAL OF VIBRATION ENGINEERING & TECHNOLOGIES
LA English
DT Article
DE Machine fault diagnosis; Vibration analysis; Machine learning;
   Artificial neural network; Pattern recognition
ID PRINCIPAL COMPONENT ANALYSIS; SPEED; IDENTIFICATION; CLASSIFICATION
AB Purpose The development and application of intelligent models to perform vibration-based condition monitoring in industry seems to be receiving attention in recent years. A number of such research studies using the artificial intelligence, machine learning, pattern recognition, etc., are available in the literature on this topic. These studies essentially used the machine vibration responses with known machine faults to develop smart fault diagnosis models. These models are yet to be tested for all kinds of machine faults and/or different operating conditions. Therefore, the purpose is to develop a generic machine faults diagnosis model that can be applied blindly to any identical machines with high confidence level in accuracy of the predictions.
   Methods In this paper, a supervised smart fault diagnosis model is developed. This model is developed using the available measured vibration responses for the different rotor faults simulated on an experimental rotating rig operating at a constant speed. The developed smart vibration-based machine learning (SVML) model is then blindly tested to identify the healthy and faulty conditions of the rig when operating at different speeds.
   Results and conclusions Several scenarios are proposed and examined during the development of the SVML model. It is observed that scenario of the vibration measurements simultaneously from all bearings from a machine is capable to fully map the machine dynamics in the VML model. Therefore, this developed when applied blindly to the sets of data at a different machine speed, the results are observed to be encouraging. The results clearly show a possibility for a centralised vibration-based condition monitoring (CVCM) model for identical machines operating at different rotating speeds.
C1 [Espinoza Sepulveda, Natalia F.; Sinha, Jyoti K.] Univ Manchester, Sch Engn, Dept Mech Aerosp & Civil Engn MACE, Dynam Lab, Manchester M13 9PL, Lancs, England.
RP Sinha, JK (corresponding author), Univ Manchester, Sch Engn, Dept Mech Aerosp & Civil Engn MACE, Dynam Lab, Manchester M13 9PL, Lancs, England.
EM natalia.espinozasepulveda@postgrad.manchester.ac.uk;
   jyoti.sinha@manchester.ac.uk
FU CONICYT (Comision Nacional de Investigacion Cientifica y
   Tecnologica/Chilean National Commission for Scientific and Technological
   Research) "Becas Chile" Doctorate's Fellowship programme [72190062]
FX Jyoti K. Sinha acknowledges his Ph.D. students then Dr Keri Elbhbah for
   the development of the rig, and Dr Akilu Kaltungo and Dr Adrian Nembhard
   for the experiments and experimental data that are used in this study.
   Natalia Fernanda Espinoza Sepulveda acknowledges the support by CONICYT
   (Comision Nacional de Investigacion Cientifica y Tecnologica/Chilean
   National Commission for Scientific and Technological Research) "Becas
   Chile" Doctorate's Fellowship programme; Grant no. 72190062 for her
   Ph.D. study.
NR 22
TC 5
Z9 5
U1 2
U2 4
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 2523-3920
EI 2523-3939
J9 J VIB ENG TECHNOL
JI J. Vib. Eng. Technol.
PD JUN
PY 2021
VL 9
IS 4
BP 587
EP 596
DI 10.1007/s42417-020-00250-1
EA OCT 2020
PG 10
WC Engineering, Mechanical; Mechanics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Mechanics
GA SD7KV
UT WOS:000577457000001
OA hybrid
DA 2022-04-17
ER

PT J
AU Moruzzi, C
AF Moruzzi, Caterina
TI Learning through creativity: how creativity can help machine learning
   achieving deeper understanding
SO RIVISTA ITALIANA DI FILOSOFIA DEL LINGUAGGIO
LA English
DT Article
DE creativity; artificial intelligence; autonomy; problem-solving; machine
   learning
ID PHILOSOPHY
AB In this paper, I address the difficult task of analysing the nature of creativity by suggesting a more objective way of defining it. In particular, I propose a minimal account of creativity as autonomous problem-solving process. This definition is aimed at providing a baseline that researchers working in different fields can agree on and that can then be refined on a case by case basis. Developing our insight on the nature of creativity is increasingly necessary in the light of recent developments in the field of Artificial Intelligence. In the second part of the paper, I discuss how an investigation on the main features of human creativity can support the advancement of machine learning models in their current areas of weakness, such as intuition, originality, innovation, and flexibility. I suggest how methods such as modelling the human brain or simulation can be useful to extract the main mechanisms underlying creative processes and to translate them to machine learning applications. This can eventually aid both the development of machine learning systems that achieve a deeper and more intuitive understanding and our exploration of human creativity.
C1 [Moruzzi, Caterina] Univ Konstanz, Constance, Germany.
RP Moruzzi, C (corresponding author), Univ Konstanz, Constance, Germany.
EM caterina.moruzzi@uni-konstanz.de
RI Moruzzi, Caterina/AAF-4019-2021
OI Moruzzi, Caterina/0000-0002-9728-3873
NR 49
TC 0
Z9 0
U1 1
U2 1
PU UNIV STUDI CALABRIA
PI ARCAVACATA DI RENDE
PA CAMPUS ARCAVACATA, VIA PIETRO BUCCI, ARCAVACATA DI RENDE, CS 87036,
   ITALY
SN 2036-6728
J9 RIV ITAL FILOS LINGU
JI Riv. Ital. Filos. Linguaggio
PY 2020
VL 14
IS 2
BP 35
EP 46
DI 10.4396/AISB201904
PG 12
WC Language & Linguistics
WE Emerging Sources Citation Index (ESCI)
SC Linguistics
GA PM1LE
UT WOS:000603569100004
DA 2022-04-17
ER

PT C
AU Dashtipour, K
   Taylor, W
   Ansari, S
   Zahid, A
   Gogate, M
   Ahmad, J
   Assaleh, K
   Arshad, K
   Imran, MA
   Abbasi, Q
AF Dashtipour, Kia
   Taylor, William
   Ansari, Shuja
   Zahid, Adnan
   Gogate, Mandar
   Ahmad, Jawad
   Assaleh, Khaled
   Arshad, Kamran
   Imran, Muhammad Ali
   Abbasi, Qammer
BE Rehman, MU
   Zoha, A
TI Detecting Alzheimer's Disease Using Machine Learning Methods
SO BODY AREA NETWORKS: SMART IOT AND BIG DATA FOR INTELLIGENT HEALTH
   MANAGEMENT
SE Lecture Notes of the Institute for Computer Sciences Social Informatics
   and Telecommunications Engineering
LA English
DT Proceedings Paper
CT 16th European-Alliance-for-Innovation (EAI) International Conference on
   Body Area Networks (BodyNets)
CY OCT 25-26, 2021
CL ELECTR NETWORK
SP European Alliance Innovat
DE Machine learning; Deep learning; Detecting Alzheimer
ID DEMENTIA
AB As the world is experiencing population growth, the portion of the older people, aged 65 and above, is also growing at a faster rate. As a result, the dementia with Alzheimer's disease is expected to increase rapidly in the next few years. Currently, healthcare systems require an accurate detection of the disease for its treatment and prevention. Therefore, it has become essential to develop a framework for early detection of Alzheimer's disease to avoid complications. To this end, a novel framework, based on machine-learning (ML) and deep-learning (DL) methods, is proposed to detect Alzheimer's disease. In particular, the performance of different ML and DL algorithms has been evaluated against their detection accuracy. The experimental results state that bidirectional long short-term memory (BiLSTM) outperforms the ML methods with a detection accuracy of 91.28%. Furthermore, the comparison with the state-of-the-art indicates the superiority of the our framework over the other proposed approaches in the literature.
C1 [Dashtipour, Kia; Taylor, William; Ansari, Shuja; Imran, Muhammad Ali; Abbasi, Qammer] Univ Glasgow, James Watt Sch Engn, Glasgow, Lanark, Scotland.
   [Zahid, Adnan] Heriot Watt Univ, Sch Engn & Phys Sci, Edinburgh EH14 4AS, Midlothian, Scotland.
   [Dashtipour, Kia; Gogate, Mandar; Ahmad, Jawad] Edinburgh Napier Univ, Sch Comp, Edinburgh, Midlothian, Scotland.
   [Assaleh, Khaled; Arshad, Kamran] Ajman Univ, Fac Engn & IT, Ajman 346, U Arab Emirates.
   [Imran, Muhammad Ali] Ajman Univ, Artificial Intelligence Res Ctr AIRC, Ajman, U Arab Emirates.
RP Dashtipour, K (corresponding author), Univ Glasgow, James Watt Sch Engn, Glasgow, Lanark, Scotland.; Dashtipour, K (corresponding author), Edinburgh Napier Univ, Sch Comp, Edinburgh, Midlothian, Scotland.
EM kia.dashtipour@glasgow.ac.uk
FU Ajman University Internal Research Grant
FX This work is supported in part by the Ajman University Internal Research
   Grant.
NR 51
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1867-8211
EI 1867-822X
BN 978-3-030-95593-9; 978-3-030-95592-2
J9 L N INST COMP SCI SO
PY 2022
VL 420
BP 89
EP 100
DI 10.1007/978-3-030-95593-9_8
PG 12
WC Computer Science, Theory & Methods; Health Care Sciences & Services;
   Information Science & Library Science; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Health Care Sciences & Services; Information Science &
   Library Science; Telecommunications
GA BS8OY
UT WOS:000774502300008
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Cecchinato, G
   Foschi, LC
AF Cecchinato, Graziano
   Foschi, Laura Carlotta
TI Perusall: University learning-teaching innovation employing social
   annotation and machine learning
SO QWERTY
LA English
DT Article
DE Perusall; Social Annotation; Machine Learning; Peer Instruction;
   Learning-Teaching Innovation
ID FEEDBACK; ONLINE; PARTICIPATION; PERFORMANCE; AGREEMENT; ESSAYS
AB This paper presents the learning-teaching innovation process of a University course. The traditional elements of the teaching-learning process (lecture, study, exam) involving students in ongoing activities have changed. The paper focuses on the learning changes introduced by social annotation activities carried out through the Perusall web environment. In particular, Perusall functionalities that assess students' participation were examined. These rely on multiple indicators set by the teacher, and a Machine Learning algorithm, which assesses the quality of annotations. A study was carried out to examine the validity of this process by analysing the relationship between Perusall algorithm's scores and teacher's scores, and how students perceive the automated scoring. The relationship was investigated through the Spearman correlation coefficient and Kendall's coefficient of concordance. Thematic analysis was used to analyse the qualitative data concerning students' perceptions. The results indicate that the Perusall algorithm provided scores quite similar to those of the teacher, and that students positively perceived the automated scoring.
C1 [Cecchinato, Graziano; Foschi, Laura Carlotta] Univ Padua, Padua, Italy.
RP Cecchinato, G (corresponding author), Univ Padua, Padua, Italy.
EM graziano.cecchinato@unipd.it
NR 64
TC 1
Z9 1
U1 2
U2 2
PU PROGEDIT
PI BARI
PA PROGEDIT, BARI, 00000, ITALY
SN 1828-7344
EI 2240-2950
J9 QWERTY
JI Qwerty
PY 2020
VL 15
IS 2
SI SI
BP 45
EP 67
DI 10.30557/QW000030
PG 23
WC Computer Science, Interdisciplinary Applications
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA PY2QZ
UT WOS:000611894700004
OA gold
DA 2022-04-17
ER

PT J
AU Zzaman, RU
   Nowreen, S
   Khan, IM
   Islam, MR
   Ibtehaz, N
   Rahman, MS
   Zahid, A
   Farzana, D
   Sharmin, A
   Rahman, MS
AF Zzaman, Rashed Uz
   Nowreen, Sara
   Khan, Irtesam Mahmud
   Islam, Md Rajibul
   Ibtehaz, Nabil
   Rahman, M. Saifur
   Zahid, Anwar
   Farzana, Dilruba
   Sharmin, Afroza
   Rahman, M. Sohel
TI A Machine Learning-based Approach for Groundwater Mapping
SO NATURAL RESOURCES RESEARCH
LA English
DT Article
DE Groundwater; Force-mode pump; Hydrogeological factors; Machine learning;
   Prediction; Suction-mode pump
ID LEVEL; MODELS; ANN
AB In Bangladesh, groundwater is the main source of both drinking water and irrigation. Suction lift pumps and force mode of operation are the predominant technologies for groundwater abstraction in Bangladesh. For a sustainable usage policy, it is thus important to identify which technology would be more appropriate for which area in Bangladesh. With that aim in mind, this paper proposes a methodology that leverages the power of machine learning that can potentially learn intricate relationships between the (annual maximum) groundwater level (GWL) and the relevant hydrogeological factors (HGFs). A number of machine learning algorithms-both classification and regression models-was trained. Our classification models were trained as a binary classifier to predict the abstraction technology of a particular point. Notably, our best classification model was based on the Random Forest algorithm, which achieved an accuracy of 91% and an excellent value of 96% for the area under receiver operating characteristics curve, indicating its strong discriminant capability. We also identified (elevation derived from) digital elevation model, specific yield and lithology as the three most important HGFs for GWL in Bangladesh. On the other hand, to predict the actual (annual maximum) GWL, we employed a two-stage approach, where we first employed the above-mentioned classification model to identify the suitable abstraction technology for the point of interest and subsequently predict the actual GWL using the appropriate Random Forest regressor. This also had a reasonable accuracy (minimum absolute error was less than 1 for suction mode and less than 5 for the force mode). Finally, using our prediction models, we prepared groundwater (technology) maps for the whole Bangladesh.
C1 [Zzaman, Rashed Uz; Nowreen, Sara] BUET, Inst Water & Flood Management, Dhaka 1000, Bangladesh.
   [Khan, Irtesam Mahmud; Islam, Md Rajibul; Ibtehaz, Nabil; Rahman, M. Saifur; Rahman, M. Sohel] BUET, Dept CSE, ECE Bldg, Dhaka 1205, Bangladesh.
   [Zahid, Anwar] Bangladesh Water Dev Board, Dhaka, Bangladesh.
   [Farzana, Dilruba] Dept Publ Hlth Engn DPHE, Dhaka, Bangladesh.
   [Sharmin, Afroza] Bangladesh Agr Dev Corp, Dhaka, Bangladesh.
RP Nowreen, S (corresponding author), BUET, Inst Water & Flood Management, Dhaka 1000, Bangladesh.; Rahman, MS (corresponding author), BUET, Dept CSE, ECE Bldg, Dhaka 1205, Bangladesh.
EM snowreen@iwfm.buet.ac.bd; msrahman@cse.buet.ac.bd
OI Nowreen, Sara/0000-0001-8116-4020; Khan, Irtesam
   Mahmud/0000-0002-0170-518X; Rahman, M. Sohel/0000-0001-9419-6478;
   Ibtehaz, Nabil/0000-0003-3625-5972
FU ICT Division, Bangladesh; AI for Earth Grant
FX This work is part of the project titled 'Development of IoT enabled data
   logger to monitor groundwater and analysis of the collected data' under
   the innovation fund of ICT Division, Bangladesh. It was further
   supported by the AI for Earth Grant for a project titled "GWMap:
   Applying Machine Learning to map groundwater levels in Bangladesh.''
NR 58
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1520-7439
EI 1573-8981
J9 NAT RESOUR RES
JI Nat. Resour. Res.
PD FEB
PY 2022
VL 31
IS 1
BP 281
EP 299
DI 10.1007/s11053-021-09977-4
EA NOV 2021
PG 19
WC Geosciences, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Geology
GA ZE7LC
UT WOS:000721669800001
DA 2022-04-17
ER

PT J
AU Maass, W
   Storey, VC
AF Maass, Wolfgang
   Storey, Veda C.
TI Pairing conceptual modeling with machine learning
SO DATA & KNOWLEDGE ENGINEERING
LA English
DT Article
DE Conceptual modeling; Machine learning; Methodologies and tools; Models;
   Database management; Artificial intelligence; Framework for
   incorporating conceptual modeling into data science projects
ID INFORMATION-SYSTEMS; BIG DATA; NEURAL-NETWORKS; BLACK-BOX; QUALITY;
   REQUIREMENTS; ANALYTICS; SELECTION; GOAL; INTELLIGENCE
AB Both conceptual modeling and machine learning have long been recognized as important areas of research. With the increasing emphasis on digitizing and processing large amounts of data for business and other applications, it would be helpful to consider how these areas of research can complement each other. To understand how they can be paired, we provide an overview of machine learning foundations and development cycle. We then examine how conceptual modeling can be applied to machine learning and propose a framework for incorporating conceptual modeling into data science projects. The framework is illustrated by applying it to a healthcare application. For the inverse pairing, machine learning can impact conceptual modeling through text and rule mining, as well as knowledge graphs. The pairing of conceptual modeling and machine learning in this way should help lay the foundations for future research.
C1 [Maass, Wolfgang] German Res Ctr Artificial Intelligence DFKI, D-66123 Saarbrucken, Germany.
   [Maass, Wolfgang] Saarland Univ, Saarland Informat Campus, D-66123 Saarbrucken, Germany.
   [Storey, Veda C.] Georgia State Univ, J Mack Robinson Coll Business, Atlanta, GA 30302 USA.
RP Maass, W (corresponding author), German Res Ctr Artificial Intelligence DFKI, D-66123 Saarbrucken, Germany.
EM wolfgang.maass@dfki.de; vstorey@gsu.edu
OI Storey, Veda/0000-0002-8735-1553; Maass, Wolfgang/0000-0003-4057-0924
FU German Ministry for Economic Affairs and Energy, project EVAREST
   [00586504]
FX This work was partially funded by the German Ministry for Economic
   Affairs and Energy, project EVAREST (grant ID: 00586504) .
NR 228
TC 1
Z9 1
U1 3
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0169-023X
EI 1872-6933
J9 DATA KNOWL ENG
JI Data Knowl. Eng.
PD JUL
PY 2021
VL 134
AR 101909
DI 10.1016/j.datak.2021.101909
EA JUL 2021
PG 35
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA TQ6AQ
UT WOS:000678361100002
OA Green Submitted, hybrid
DA 2022-04-17
ER

PT J
AU Le, D
   Son, T
   Yao, XC
AF Le, David
   Son, Taeyoon
   Yao, Xincheng
TI Machine learning in optical coherence tomography angiography
SO EXPERIMENTAL BIOLOGY AND MEDICINE
LA English
DT Review
DE Retina; retinopathy; optical coherence tomography angiography;
   artificial intelligence; machine learning; deep learning; convolutional
   neural network
ID ARTERY-VEIN DIFFERENTIATION; SICKLE-CELL RETINOPATHY; MACULAR
   DEGENERATION; DIABETIC-RETINOPATHY; DEEP; CLASSIFICATION;
   RECONSTRUCTION; IMAGES
AB Optical coherence tomography angiography (OCTA) offers a noninvasive label-free solution for imaging retinal vasculatures at the capillary level resolution. In principle, improved resolution implies a better chance to reveal subtle microvascular distortions associated with eye diseases that are asymptomatic in early stages. However, massive screening requires experienced clinicians to manually examine retinal images, which may result in human error and hinder objective screening. Recently, quantitative OCTA features have been developed to standardize and document retinal vascular changes. The feasibility of using quantitative OCTA features for machine learning classification of different retinopathies has been demonstrated. Deep learning-based applications have also been explored for automatic OCTA image analysis and disease classification. In this article, we summarize recent developments of quantitative OCTA features, machine learning image analysis, and classification.
C1 [Le, David; Son, Taeyoon; Yao, Xincheng] Univ Illinois, Dept Bioengn, Chicago, IL 60607 USA.
   [Yao, Xincheng] Univ Illinois, Dept Ophthalmol & Visual Sci, Chicago, IL 60612 USA.
RP Yao, XC (corresponding author), Univ Illinois, Dept Bioengn, Chicago, IL 60607 USA.; Yao, XC (corresponding author), Univ Illinois, Dept Ophthalmol & Visual Sci, Chicago, IL 60612 USA.
EM xcy@uic.edu
OI Son, Taeyoon/0000-0001-7273-5880; YAO, XINCHENG/0000-0002-0356-3242
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [R01 EY023522, R01 EY030101,
   R01EY030842, R01EY029673, P30 EY001792, T32AG057468]; Richard and Loan
   Hill endowment; Research to Prevent BlindnessResearch to Prevent
   Blindness (RPB)
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This
   research was supported in part by NIH grants R01 EY023522, R01 EY030101,
   R01EY030842, R01EY029673, P30 EY001792; T32AG057468; by Richard and Loan
   Hill endowment; by unrestricted grant from Research to Prevent
   Blindness.
NR 65
TC 2
Z9 2
U1 10
U2 12
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1535-3702
EI 1535-3699
J9 EXP BIOL MED
JI Exp. Biol. Med.
PD OCT
PY 2021
VL 246
IS 20
SI SI
BP 2170
EP 2183
AR 15353702211026581
DI 10.1177/15353702211026581
EA JUL 2021
PG 14
WC Medicine, Research & Experimental
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Research & Experimental Medicine
GA WN1CM
UT WOS:000682764500001
PM 34279136
OA Bronze
DA 2022-04-17
ER

PT J
AU Liu, WX
   Zhu, Y
   Wu, YQ
   Chen, C
   Hong, Y
   Yue, YA
   Zhang, JC
   Hou, B
AF Liu, Wenxiang
   Zhu, Yang
   Wu, Yongqiang
   Chen, Cen
   Hong, Yang
   Yue, Yanan
   Zhang, Jingchao
   Hou, Bo
TI Molecular Dynamics and Machine Learning in Catalysts
SO CATALYSTS
LA English
DT Review
DE catalysts; molecular dynamics; reactive force field; machine learning
ID REACTIVE FORCE-FIELD; DENSITY-FUNCTIONAL THEORY; OXYGEN-REDUCTION;
   HOMOGENEOUS CATALYSIS; MECHANICAL-PROPERTIES; MATERIALS DISCOVERY;
   CHARGE-TRANSFER; REAXFF; OXIDE; OXIDATION
AB Given the importance of catalysts in the chemical industry, they have been extensively investigated by experimental and numerical methods. With the development of computational algorithms and computer hardware, large-scale simulations have enabled influential studies with more atomic details reflecting microscopic mechanisms. This review provides a comprehensive summary of recent developments in molecular dynamics, including ab initio molecular dynamics and reaction force-field molecular dynamics. Recent research on both approaches to catalyst calculations is reviewed, including growth, dehydrogenation, hydrogenation, oxidation reactions, bias, and recombination of carbon materials that can guide catalyst calculations. Machine learning has attracted increasing interest in recent years, and its combination with the field of catalysts has inspired promising development approaches. Its applications in machine learning potential, catalyst design, performance prediction, structure optimization, and classification have been summarized in detail. This review hopes to shed light and perspective on ML approaches in catalysts.
C1 [Liu, Wenxiang; Yue, Yanan] Wuhan Univ, Sch Power & Mech Engn, Wuhan 430072, Peoples R China.
   [Zhu, Yang; Wu, Yongqiang] Weichai Power CO Ltd, Weifang 261061, Peoples R China.
   [Chen, Cen] Firebird Biomol Sci LLC, Alachua, FL 32615 USA.
   [Hong, Yang] Georgia Inst Technol, Sch Chem & Biochem, Atlanta, GA 30332 USA.
   [Zhang, Jingchao] NVIDIA AI Technol Ctr NVAITC, Santa Clara, CA 95051 USA.
   [Hou, Bo] Cardiff Univ, Sch Phys & Astron, Cardiff CF24 3AA, Wales.
RP Yue, YA (corresponding author), Wuhan Univ, Sch Power & Mech Engn, Wuhan 430072, Peoples R China.; Zhang, JC (corresponding author), NVIDIA AI Technol Ctr NVAITC, Santa Clara, CA 95051 USA.; Hou, B (corresponding author), Cardiff Univ, Sch Phys & Astron, Cardiff CF24 3AA, Wales.
EM 2020202080035@whu.edu.cn; zhuy@weichai.com; wuyq@weichai.com;
   cchen@firebirdbio.com; yhong321@gatech.edu; yyue@whu.edu.cn;
   jingchaoz@nvidia.com; houb6@cardiff.ac.uk
RI Hou, Bo/AAB-4273-2019; Zhang, Jingchao/N-3267-2014
OI Hou, Bo/0000-0001-9918-8223; Zhang, Jingchao/0000-0001-5289-6062
FU National Natural Science Foundations of ChinaNational Natural Science
   Foundation of China (NSFC) [52076156]; National Key Research and
   Development Program [2019YFE0119900]; Fundamental Research Funds for the
   Central UniversitiesFundamental Research Funds for the Central
   Universities [2042020kf0194]
FX Y. Yue acknowledges the support from the National Natural Science
   Foundations of China (No. 52076156), National Key Research and
   Development Program (No. 2019YFE0119900), and Fundamental Research Funds
   for the Central Universities (No. 2042020kf0194).
NR 174
TC 1
Z9 1
U1 55
U2 59
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2073-4344
J9 CATALYSTS
JI Catalysts
PD SEP
PY 2021
VL 11
IS 9
AR 1129
DI 10.3390/catal11091129
PG 20
WC Chemistry, Physical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry
GA UV8IA
UT WOS:000699713500001
OA Green Accepted, gold
DA 2022-04-17
ER

PT J
AU Balaji, TK
   Annavarapu, CSR
   Bablani, A
AF Balaji, T. K.
   Annavarapu, Chandra Sekhara Rao
   Bablani, Annushree
TI Machine learning algorithms for social media analysis: A survey
SO COMPUTER SCIENCE REVIEW
LA English
DT Review
DE Social Media; Machine learning; Social network analysis; Applications of
   social media analysis
ID SENTIMENT ANALYSIS; RECOMMENDER SYSTEMS; BIG DATA; BEHAVIORAL-ANALYSIS;
   DESTINATION IMAGE; FEATURE-SELECTION; NEURAL-NETWORKS; CLASSIFICATION;
   TWITTER; USER
AB Social Media (SM) are the most widespread and rapid data generation applications on the Internet increase the study of these data. However, the efficient processing of such massive data is challenging, so we require a system that learns from these data, like machine learning. Machine learning methods make the systems to learn itself. Many papers are published on SM using machine learning approaches over the past few decades. In this paper, we provide a comprehensive survey of multiple applications of SM analysis using robust machine learning algorithms. Initially, we discuss a summary of machine learning algorithms, which are used in SM analysis. After that, we provide a detailed survey of machine learning approaches to SM analysis. Furthermore, we summarize the challenges and benefits of Machine Learning usages in SM analysis. Finally, we presented open issues and consequences in SM analysis for further research.
   (c) 2021 Elsevier Inc. All rights reserved.
C1 [Balaji, T. K.; Bablani, Annushree] Indian Inst Informat Technol, Dept Comp Sci & Engn, Sri City 517646, Andhra Pradesh, India.
   [Annavarapu, Chandra Sekhara Rao] Indian Sch Mines, Indian Inst Technol, Dept Comp Sci & Engn, Dhanbad 826004, Jharkhand, India.
RP Annavarapu, CSR (corresponding author), Indian Sch Mines, Indian Inst Technol, Dept Comp Sci & Engn, Dhanbad 826004, Jharkhand, India.
EM balajitk7@gmail.com; acsrao@iitism.ac.in; annushree.bablani@iiits.in
RI T K, BALAJI/G-4070-2018
OI T K, BALAJI/0000-0003-4448-2948
NR 247
TC 7
Z9 7
U1 27
U2 44
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1574-0137
EI 1876-7745
J9 COMPUT SCI REV
JI Comput. Sci. Rev.
PD MAY
PY 2021
VL 40
AR 100395
DI 10.1016/j.cosrev.2021.100395
EA MAR 2021
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA SV0EF
UT WOS:000663500200010
DA 2022-04-17
ER

PT J
AU Bertsimas, D
   Digalakis, V
AF Bertsimas, Dimitris
   Digalakis, Vassilis, Jr.
TI The backbone method for ultra-high dimensional sparse machine learning
SO MACHINE LEARNING
LA English
DT Article; Early Access
DE Ultra-high dimensional machine learning; Sparse machine learning; Mixed
   integer optimization; Sparse regression; Decision trees; Feature
   Selection
ID GENERALIZED LINEAR-MODELS; SCALABLE ALGORITHMS; VARIABLE SELECTION;
   SUBSPACE METHOD; REGRESSION; CLASSIFICATION; REGULARIZATION;
   OPTIMIZATION; APPROXIMATION; SHRINKAGE
AB We present the backbone method, a general framework that enables sparse and interpretable supervised machine learning methods to scale to ultra-high dimensional problems. We solve sparse regression problems with 107 features in minutes and 108 features in hours, as well as decision tree problems with 105 features in minutes. The proposed method operates in two phases: we first determine the backbone set, consisting of potentially relevant features, by solving a number of tractable subproblems; then, we solve a reduced problem, considering only the backbone features. For the sparse regression problem, our theoretical analysis shows that, under certain assumptions and with high probability, the backbone set consists of the truly relevant features. Numerical experiments on both synthetic and realworld datasets demonstrate that our method outperforms or competes with state-of-the-art methods in ultra-high dimensional problems, and competes with optimal solutions in problems where exact methods scale, both in terms of recovering the truly relevant features and in its out-of-sample predictive performance.
C1 [Bertsimas, Dimitris; Digalakis, Vassilis, Jr.] MIT, Operat Res Ctr, Cambridge, MA 02139 USA.
   [Bertsimas, Dimitris] MIT, Sloan Sch Management, Cambridge, MA 02139 USA.
RP Bertsimas, D (corresponding author), MIT, Operat Res Ctr, Cambridge, MA 02139 USA.; Bertsimas, D (corresponding author), MIT, Sloan Sch Management, Cambridge, MA 02139 USA.
EM dbertsim@mit.edu; vvdig@mit.edu
OI Bertsimas, Dimitris/0000-0002-1985-1003
NR 88
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0885-6125
EI 1573-0565
J9 MACH LEARN
JI Mach. Learn.
DI 10.1007/s10994-021-06123-2
EA JAN 2022
PG 52
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YK7LL
UT WOS:000745389900002
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Kim, YM
   Shin, SJ
   Cho, HW
AF Kim, Young-Min
   Shin, Seung-Jun
   Cho, Hae-Won
TI Predictive Modeling for Machining Power Based on Multi-source Transfer
   Learning in Metal Cutting
SO INTERNATIONAL JOURNAL OF PRECISION ENGINEERING AND MANUFACTURING-GREEN
   TECHNOLOGY
LA English
DT Article
DE Energy-efficient machining; Machining power; Predictive analytics;
   Sustainable manufacturing; Transfer learning; Machine learning
AB Energy efficiency has become crucial in the metal cutting industry. Machining power has therefore become an important metric because it directly affects the energy consumed during the operation of a machine tool. Attempts to predict machining power using machine learning have relied on the training datasets processed from actual machining data to derive the numerical relationship between process parameters and machining power. However, real fields hardly provide training datasets because of the difficulties in data collection; consequently, traditional learning approaches are ineffective in such data-scarce or -absent environment. This paper proposes a transfer learning approach for the predictive modeling of machining power. The proposed approach creates machining power prediction models by transferring the knowledge acquired from prior machining to the target machining context where machining power data are absent. The proposed approach performs domain adaptation by adding workpiece material properties to the original feature space for accommodating different machining power patterns dependent on the types of workpiece materials. A case study demonstrates that the training datasets obtained from the fabrication of steel and aluminum materials can be successfully used to create the power-predictive models that anticipate machining power for titanium material.
C1 [Kim, Young-Min] Hanyang Univ, Grad Sch Technol & Innovat Management, Seoul, South Korea.
   [Shin, Seung-Jun] Hanyang Univ, Div Interdisciplinary Ind Studies, Seoul, South Korea.
   [Cho, Hae-Won] Hanyang Univ, Dept Appl Syst, Seoul, South Korea.
RP Shin, SJ (corresponding author), Hanyang Univ, Div Interdisciplinary Ind Studies, Seoul, South Korea.
EM sjshin@hanyang.ac.kr
FU Basic Research Program in Science and Engineering through the Ministry
   of Education of the Republic of Korea; National Research Foundation
   [NRF-2018R1D1A1B07047100]
FX This work was supported by the Basic Research Program in Science and
   Engineering through the Ministry of Education of the Republic of Korea
   and the National Research Foundation (NRF-2018R1D1A1B07047100).
NR 32
TC 2
Z9 2
U1 8
U2 17
PU KOREAN SOC PRECISION ENG
PI SEOUL
PA RM 306, KWANGMYUNG BLDG, 5-4 NONHYUN-DONG, KANGNAM-GU, SEOUL, 135-010,
   SOUTH KOREA
SN 2288-6206
EI 2198-0810
J9 INT J PR ENG MAN-GT
JI Int. J. Precis Eng Manuf-Green Technol.
PD JAN
PY 2022
VL 9
IS 1
BP 107
EP 125
DI 10.1007/s40684-021-00327-6
EA MAR 2021
PG 19
WC Green & Sustainable Science & Technology; Engineering, Manufacturing;
   Engineering, Mechanical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Science & Technology - Other Topics; Engineering
GA YF9CX
UT WOS:000629093200003
DA 2022-04-17
ER

PT C
AU Shaver, A
   Liu, ZP
   Thapa, N
   Roy, K
   Gokaraju, B
   Yuan, XO
AF Shaver, Addison
   Liu, Zhipeng
   Thapa, Niraj
   Roy, Kaushik
   Gokaraju, Balakrishna
   Yuan, Xiaohon
GP IEEE
TI Anomaly Based Intrusion Detection for IoT with Machine Learning
SO 2020 IEEE APPLIED IMAGERY PATTERN RECOGNITION WORKSHOP (AIPR): TRUSTED
   COMPUTING, PRIVACY, AND SECURING MULTIMEDIA
SE IEEE Applied Imagery Pattern Recognition Workshop
LA English
DT Proceedings Paper
CT IEEE Applied Imagery Pattern Recognition Workshop (AIPR)
CY OCT 13-15, 2020
CL ELECTR NETWORK
SP IEEE
DE IoT; IDS; Machine Learning
ID DETECTION SYSTEM
AB The Internet of Things (IOT) is the network that connects smart devices over the Internet These devices are increasingly found in every facet of life, providing distributed data computing power and improving the accessibility of everyday routines in many households. However, these connected devices expand and so does the risk that they become valuable targets for malicious threats. This is because, IoT devices have lower power and computation management, meaning that traditional methods of security like encryption or firewalls tend to be unworkable to secure these devices. Therefore, Intrusion Detection Systems (IDSs) provide an alternative for securing IoT devices, by classifying with anomaly detection, whether a network communication is a potential attack Enhancing existing IDS by integrating various common machine learning models could provide a logical solution to this issue. In this study, we contribute by reviewing and comparing various machine learning (ML) models with intrusion detection. In this comparative analysis, the experimental results from the integrated ML models were promising with an achieved 99% accuracy rates in both binary and multiclass classifiers for intrusion detection.
C1 [Shaver, Addison; Liu, Zhipeng; Thapa, Niraj; Roy, Kaushik; Yuan, Xiaohon] North Carolina A&T State Univ, Comp Sci Dept, Greensboro, NC 27411 USA.
   [Gokaraju, Balakrishna] North Carolina A&T State Univ, Computat Data Sci & Engn Dept, Greensboro, NC 27411 USA.
RP Roy, K (corresponding author), North Carolina A&T State Univ, Comp Sci Dept, Greensboro, NC 27411 USA.
EM kroy@ncat.edu
FU CISCO systems, Inc.
FX This research is based upon the work supported partially by the CISCO
   systems, Inc.
NR 30
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1550-5219
BN 978-1-7281-8243-8
J9 IEEE APP IMG PAT
PY 2020
DI 10.1109/AIPR50011.2020.9425199
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Imaging Science & Photographic Technology
GA BR9HA
UT WOS:000675595400025
DA 2022-04-17
ER

PT J
AU Kayhan, BM
   Yildiz, G
AF Kayhan, Behice Meltem
   Yildiz, Gokalp
TI Reinforcement learning applications to machine scheduling problems: a
   comprehensive literature review
SO JOURNAL OF INTELLIGENT MANUFACTURING
LA English
DT Review; Early Access
DE Reinforcement learning; Q-learning; Machine scheduling; Job shop
   scheduling problem; Parallel machine scheduling problems
ID MEAN WEIGHTED TARDINESS; POLICIES; SYSTEM; OPTIMIZATION; SMARTGANTT
AB Reinforcement learning (RL) is one of the most remarkable branches of machine learning and attracts the attention of researchers from numerous fields. Especially in recent years, the RL methods have been applied to machine scheduling problems and are among the top five most encouraging methods for scheduling literature. Therefore, in this study, a comprehensive literature review about RL methods applications to machine scheduling problems was conducted. In this regard, Scopus and Web of Science databases were searched very inclusively using the proper keywords. As a result of the comprehensive research, 80 papers were found, published between 1995 and 2020. These papers were analyzed considering different aspects of the problem such as applied algorithms, machine environments, job and machine characteristics, objectives, benchmark methods, and a detailed classification scheme was constructed. Job shop scheduling, unrelated parallel machine scheduling, and single machine scheduling problems were found as the most studied problem type. The main contributions of the study are to examine essential aspects of reinforcement learning in machine scheduling problems, identify the most frequently investigated problem types, objectives, and constraints, and reveal the deficiencies and promising areas in the related literature. This study can help researchers who wish to study in this field through the comprehensive analysis of the related literature.
C1 [Kayhan, Behice Meltem; Yildiz, Gokalp] Dokuz Eylul Univ, Dept Ind Engn, TR-35397 Izmir, Turkey.
RP Kayhan, BM (corresponding author), Dokuz Eylul Univ, Dept Ind Engn, TR-35397 Izmir, Turkey.
EM meltem.kayhan@deu.edu.tr
NR 107
TC 0
Z9 0
U1 57
U2 57
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0956-5515
EI 1572-8145
J9 J INTELL MANUF
JI J. Intell. Manuf.
DI 10.1007/s10845-021-01847-3
EA OCT 2021
PG 25
WC Computer Science, Artificial Intelligence; Engineering, Manufacturing
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WJ1AD
UT WOS:000708780800001
DA 2022-04-17
ER

PT J
AU Borrellas, P
   Unceta, I
AF Borrellas, Pol
   Unceta, Irene
TI The Challenges of Machine Learning and Their Economic Implications
SO ENTROPY
LA English
DT Article
DE machine learning; AI regulation; algorithmic accountability; welfare
   economics
ID EXPLANATION; PREDICTION; CANCER; MODEL
AB The deployment of machine learning models is expected to bring several benefits. Nevertheless, as a result of the complexity of the ecosystem in which models are generally trained and deployed, this technology also raises concerns regarding its (1) interpretability, (2) fairness, (3) safety, and (4) privacy. These issues can have substantial economic implications because they may hinder the development and mass adoption of machine learning. In light of this, the purpose of this paper was to determine, from a positive economics point of view, whether the free use of machine learning models maximizes aggregate social welfare or, alternatively, regulations are required. In cases in which restrictions should be enacted, policies are proposed. The adaptation of current tort and anti-discrimination laws is found to guarantee an optimal level of interpretability and fairness. Additionally, existing market solutions appear to incentivize machine learning operators to equip models with a degree of security and privacy that maximizes aggregate social welfare. These findings are expected to be valuable to inform the design of efficient public policies.
C1 [Borrellas, Pol; Unceta, Irene] Univ Ramon Llull, ESADE, Dept Operat Innovat & Data Sci, Barcelona 08022, Spain.
RP Unceta, I (corresponding author), Univ Ramon Llull, ESADE, Dept Operat Innovat & Data Sci, Barcelona 08022, Spain.
EM pol.borrellas@esade.edu; irene.unceta@esade.edu
RI Unceta, Irene/AAO-3995-2021
OI Unceta, Irene/0000-0002-7422-1493
NR 99
TC 1
Z9 1
U1 4
U2 14
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1099-4300
J9 ENTROPY-SWITZ
JI Entropy
PD MAR
PY 2021
VL 23
IS 3
AR 275
DI 10.3390/e23030275
PG 23
WC Physics, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Physics
GA RD6DW
UT WOS:000633567100001
PM 33668772
OA gold, Green Published
DA 2022-04-17
ER

PT J
AU Zheng, YF
   Chen, BD
   Wang, SY
   Wang, WQ
   Qin, W
AF Zheng, Yunfei
   Chen, Badong
   Wang, Shiyuan
   Wang, Weiqun
   Qin, Wei
TI Mixture Correntropy-Based Kernel Extreme Learning Machines
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article
DE Kernel; Optimization; Learning systems; Robustness; Support vector
   machines; Mean square error methods; Extreme learning machine (ELM);
   kernel method; mixture correntropy; online learning
ID FIXED-POINT ALGORITHM; UNIVERSAL APPROXIMATION; CONVERGENCE; REGRESSION;
   NETWORKS; EEG
AB Kernel-based extreme learning machine (KELM), as a natural extension of ELM to kernel learning, has achieved outstanding performance in addressing various regression and classification problems. Compared with the basic ELM, KELM has a better generalization ability owing to no needs of the number of hidden nodes given beforehand and random projection mechanism. Since KELM is derived under the minimum mean square error (MMSE) criterion for the Gaussian assumption of noise, its performance may deteriorate under the non-Gaussian cases, seriously. To improve the robustness of KELM, this article proposes a mixture correntropy-based KELM (MC-KELM), which adopts the recently proposed maximum mixture correntropy criterion as the optimization criterion, instead of using the MMSE criterion. In addition, an online sequential version of MC-KELM (MCOS-KELM) is developed to deal with the case that the data arrive sequentially (one-by-one or chunk-by-chunk). Experimental results on regression and classification data sets are reported to validate the performance superiorities of the new methods.
C1 [Zheng, Yunfei; Chen, Badong] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Peoples R China.
   [Wang, Shiyuan] Southwest Univ, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
   [Wang, Weiqun] Chinese Acad Sci, State Key Lab Management & Control Complex Syst, Inst Automat, Beijing 100190, Peoples R China.
   [Qin, Wei] Xidian Univ, Sch Life Sci & Technol, Xian 710071, Peoples R China.
RP Chen, BD (corresponding author), Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Peoples R China.
EM zhengyf@stu.xjtu.edu.cn; chenbd@mail.xjtu.edu.cn; wsy@swu.edu.cn;
   weiqun.wang@ia.ac.cn; wqin@xidian.edu.cn
OI Wang, Shiyuan/0000-0002-5028-5839; Wang, Weiqun/0000-0001-6981-297X
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [91648208, 61976175]; National Natural
   Science Foundation-Shenzhen Joint Research Program [U1613219]; Key
   Project of Natural Science Basic Research Plan in Shaanxi Province of
   China [2019JZ-05]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 91648208 and Grant 61976175, in part by
   the National Natural Science Foundation-Shenzhen Joint Research Program
   under Grant U1613219, and in part by the Key Project of Natural Science
   Basic Research Plan in Shaanxi Province of China under Grant 2019JZ-05.
NR 72
TC 2
Z9 2
U1 12
U2 12
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PD FEB
PY 2022
VL 33
IS 2
BP 811
EP 825
DI 10.1109/TNNLS.2020.3029198
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Theory & Methods; Engineering,
   Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YU4LL
UT WOS:000752016400031
PM 33079685
DA 2022-04-17
ER

PT C
AU Collaris, D
   van Wijk, JJ
AF Collaris, Dennis
   van Wijk, Jarke J.
BE Beck, F
   Seo, J
   Wang, C
TI ExplainExplore: Visual Exploration of Machine Learning Explanations
SO 2020 IEEE PACIFIC VISUALIZATION SYMPOSIUM (PACIFICVIS)
SE IEEE Pacific Visualization Symposium
LA English
DT Proceedings Paper
CT IEEE Pacific Visualization Symposium (PacificVis)
CY APR 14-17, 2020
CL Tianjin, PEOPLES R CHINA
SP IEEE, IEEE Comp Soc, IEEE Comp Soc Visualizat & Graph Tech Comm
DE Human-centered computing; Visualization; Computing methodologies;
   Machine learning
ID RULES
AB Machine learning models often exhibit complex behavior that is difficult to understand. Recent research in explainable AI has produced promising techniques to explain the inner workings of such models using feature contribution vectors. These vectors are helpful in a wide variety of applications. However, there are many parameters involved in this process and determining which settings are best is difficult due to the subjective nature of evaluating interpretability. To this end, we introduce EXPLAINEXPLORE: an interactive explanation system to explore explanations that fit the subjective preference of data scientists. We leverage the domain knowledge of the data scientist to find optimal parameter settings and instance perturbations, and enable the discussion of the model and its explanation with domain experts. We present a use case on a real-world dataset to demonstrate the effectiveness of our approach for the exploration and tuning of machine learning explanations.
C1 [Collaris, Dennis; van Wijk, Jarke J.] Eindhoven Univ Technol, Eindhoven, Netherlands.
RP Collaris, D (corresponding author), Eindhoven Univ Technol, Eindhoven, Netherlands.
EM d.a.c.collaris@tue.nl; j.j.v.wijk@tue.nl
OI Collaris, Dennis/0000-0001-7612-9319
FU Dutch Research Council (NWO)Netherlands Organization for Scientific
   Research (NWO) [628.003.001]
FX The authors would like to thank Achmea BV for their generous
   collaboration and feedback. This work is part of the research programme
   Commit2Data, specifically the RATE Analytics project with project number
   628.003.001, which is financed by the Dutch Research Council (NWO).
NR 61
TC 7
Z9 7
U1 0
U2 2
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2165-8765
BN 978-1-7281-5697-2
J9 IEEE PAC VIS SYMP
PY 2020
BP 26
EP 35
DI 10.1109/PacificVis48177.2020.7090
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BQ1ZO
UT WOS:000578516400004
OA Green Published
DA 2022-04-17
ER

PT J
AU Phong, TV
   Ly, HB
   Trinh, PT
   Prakash, I
   Hoan, DT
AF Tran Van Phong
   Hai-Bang Ly
   Phan Trong Trinh
   Prakash, Indra
   Dao Trung Hoan
TI Landslide susceptibility mapping using Forest by Penalizing Attributes
   (FPA) algorithm based machine learning approach
SO VIETNAM JOURNAL OF EARTH SCIENCES
LA English
DT Article
DE Landslide susceptibility mapping; machine learning; AUC; ROC; GIS;
   Vietnam
AB Landslide susceptibility mapping is a helpful tool for assessment and management of landslides of an area. In this study, we have applied first time Forest by Penalizing Attributes (FPA) algorithm-based Machine Learning (ML) approach for mapping of landslide susceptibility at Muong Lay district (Vietnam). For this aim, 217 historical landslides locations were identified and analyzed for the development of FPA model and generation of susceptibility map. Nine landslide topographical and geo-environmental conditioning factors (curvature, geology/lithology, aspect, distance from faults, rivers and roads, weathering crust, slope, and deep division) were utilized to construct the training and validating datasets for landslide modeling. Different quantitative statistical indices including Area Under the Receiver Operating Characteristic (ROC) curve (AUC) were used to evaluate the performance of the model. The results indicate that the predictive capability of the FPA is very good for landslide susceptibility mapping on both training (AUC = 0.935) and validating (AUC = 0.882) datasets. Thus, the novel FPA based ML model can be utilized for the development of accurate landslide susceptibility map of the study area and this approach can also be applied in other landslide prone areas.
C1 [Tran Van Phong; Phan Trong Trinh] Vietnam Acad Sci & Technol, Inst Geol Sci, Hanoi, Vietnam.
   [Hai-Bang Ly] Univ Transport Technol, Hanoi 100000, Vietnam.
   [Prakash, Indra] Govt Gujarat, Dept Sci & Technol, Bhaskarcharya Inst Space Applicat & Geoinformat B, Gandhinagar 382002, India.
   [Dao Trung Hoan] Ctr Informat & Archives & Journal Geol CIAJG, Hanoi, Vietnam.
RP Ly, HB (corresponding author), Univ Transport Technol, Hanoi 100000, Vietnam.
EM banglh@utt.edu.vn
RI Trong, Trinh Phan/C-3053-2011
OI Trong, Trinh Phan/0000-0001-7015-6500
FU project "Geological hazards assessment of Dien Bien -Lai Chau fault zone
   base on application machine learning, artificial intelligence"
   [VAST05.05/20-21]
FX We thank the support from the project "Geological hazards assessment of
   Dien Bien -Lai Chau fault zone base on application machine learning,
   artificial intelligence", VAST05.05/20-21.
NR 25
TC 5
Z9 5
U1 2
U2 3
PU VIETNAM ACAD SCIENCE & TECHNOLOGY-VAST
PI HANOI
PA FLR 3-A16 BUILDING, 18 HOANG QUOC VIET, CAU GIAY, HANOI, VIETNAM
SN 0866-7187
EI 2615-9783
J9 VIETNAM J EARTH SCI
JI Vietnam J. Earth Sci.
PY 2020
VL 42
IS 3
BP 237
EP 246
DI 10.15625/0866-7187/42/3/15047
PG 10
WC Geosciences, Multidisciplinary
WE Emerging Sources Citation Index (ESCI)
SC Geology
GA NO9AH
UT WOS:000569778200003
OA gold
DA 2022-04-17
ER

PT C
AU Goodman, G
   Hirt, Q
   Shimizu, C
   Ktistakis, IP
   Alamaniotis, M
   Bourbakis, N
AF Goodman, Garrett
   Hirt, Quinn
   Shimizu, Cogan
   Ktistakis, Iosif Papadakis
   Alamaniotis, Miltiadis
   Bourbakis, Nikolaos
BE Alamaniotis, M
   Pan, S
TI Methods for Prediction Optimization of the Constrained State-Preserved
   Extreme Learning Machine
SO 2020 IEEE 32ND INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL
   INTELLIGENCE (ICTAI)
SE Proceedings-International Conference on Tools With Artificial
   Intelligence
LA English
DT Proceedings Paper
CT 32nd IEEE International Conference on Tools with Artificial Intelligence
   (ICTAI)
CY NOV 09-11, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, Biol & Artificial Intelligence Fdn
DE Neural Networks; Training; Machine Learning; Extreme Learning Machine;
   Constrained State-Preserved Extreme Learning Machine; Accuracy
   Optimization
AB Finding the maximum testing accuracy in Machine Learning has been the goal since its conception. From this goal, neural networks have been the primary source of continual improvements in prediction performance. Traditionally, backpropagation has been the primary way of training neural networks and the Levenberg-Marquardt (LM) backpropagation has become the fastest method. Recently, the Extreme Learning Machine was introduced which randomizes weights and biases of hidden layers and uses the Moore-Penrose generalized inverse of a matrix to calculate the output weights and biases, providing competitive results at significantly faster training times. In this study, we continue our work on the Constrained State-Preserved Extreme Learning Machine (CSPELM) with a Forest optimization (CSPELMF) and epsilon constraint Rangefinder (CSPELMR). Furthermore, we provide hyper-parameter settings for the CSPELM to optimize accuracy over training time. Our results show that our methods outperformed the LM backpropagation in a majority of the 13 tested datasets and that the CSPELMF and CSPELMR matched or outperformed the CSPELM in all classification datasets.
C1 [Goodman, Garrett; Hirt, Quinn] Wright State Univ, Dayton, OH 45435 USA.
   [Shimizu, Cogan] Kansas State Univ, Manhattan, KS 66506 USA.
   [Ktistakis, Iosif Papadakis] ASML, Wilton, CT 06897 USA.
   [Alamaniotis, Miltiadis] Univ Texas San Antonio, San Antonio, TX USA.
   [Bourbakis, Nikolaos] Wright State Univ, CART Ctr, Dayton, OH 45435 USA.
RP Goodman, G (corresponding author), Wright State Univ, Dayton, OH 45435 USA.; Ktistakis, IP (corresponding author), ASML, Wilton, CT 06897 USA.
EM garrett.goodman@wright.edu; hirt.14@wright.edu; coganmshimizu@ksu.edu;
   sktistakisp@gmail.com; miltos.alamaniotis@utsa.edu;
   nikolaos.bourbakis@wright.edu
FU  [ONR-CART-N00014-18-1-2144]
FX This work was supported in part by the grant ONR-CART-N00014-18-1-2144.
NR 26
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1082-3409
BN 978-1-7281-9228-4
J9 PROC INT C TOOLS ART
PY 2020
BP 639
EP 646
DI 10.1109/ICTAI50040.2020.00103
PG 8
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR4AM
UT WOS:000649734800093
DA 2022-04-17
ER

PT C
AU Kartal, YS
   Kutlu, M
AF Kartal, Yavuz Selim
   Kutlu, Mucahid
GP IEEE
TI Machine Learning Based Text Summarization for Turkish News
SO 2020 28TH SIGNAL PROCESSING AND COMMUNICATIONS APPLICATIONS CONFERENCE
   (SIU)
SE Signal Processing and Communications Applications Conference
LA Turkish
DT Proceedings Paper
CT 28th Signal Processing and Communications Applications Conference (SIU)
CY OCT 05-07, 2020
CL ELECTR NETWORK
SP Istanbul Medipol Univ
DE Text Summarization; Machine Learning
AB In this paper, we propose an automatic text summarization model for Turkish news articles using machine learning models. Our proposed model uses sentence position, speech expression, presence of named entities and statements, term frequency and title similarity as features. We construct and share a new dataset for Turkish text summarization. In our experiments, we show that all our features we use have a positive impact on the performance of the system. In addition, we show that our model outperforms the latent semantic analysis based baseline method.
C1 [Kartal, Yavuz Selim; Kutlu, Mucahid] TOBB Ekon & Teknol Univ, Bilgisayar Muhendisligi Bolumu, Ankara, Turkey.
RP Kartal, YS (corresponding author), TOBB Ekon & Teknol Univ, Bilgisayar Muhendisligi Bolumu, Ankara, Turkey.
EM ykartal@etu.edu.tr; m.kutlu@etu.edu.tr
NR 13
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2165-0608
BN 978-1-7281-7206-4
J9 SIG PROCESS COMMUN
PY 2020
PG 4
WC Engineering, Electrical & Electronic; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering; Telecommunications
GA BR4SW
UT WOS:000653136100070
DA 2022-04-17
ER

PT C
AU Baby, ST
   Karunakaran, V
AF Baby, Steffy T.
   Karunakaran, V
GP IEEE
TI Prediction Of Diabetics Using Machine Learning Classifiers:A Review
SO PROCEEDINGS OF THE 2021 FIFTH INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN
   SOCIAL, MOBILE, ANALYTICS AND CLOUD) (I-SMAC 2021)
LA English
DT Proceedings Paper
CT 5th International Conference on IoT in Social, Mobile, Analytics and
   Cloud (I-SMAC)
CY NOV 11-13, 2021
CL ELECTR NETWORK
SP IEEE, SCAD Inst Technol
DE Machine Learning; Support Vector Machine; Principal Component Analysis;
   Artificial Neural Network; Fuzzy logic
AB Machine learning is a branch of artificial intelligence d that enables the creation of computer systems that can learn from their experiences without needing to be programmed for each situation. Machine learning is critical in today's environment to remove human effort and produce higher automation with fewer errors. In today's environment, diabetes is one of the most serious metabolic disorders. Diabetes is a long-term health problem. Every day, a large number of people become victims, and many are ignorant whether they have it or not and also millions of people are affected globally. The Pima Indian Diabetic Data Set is used in the majority of the relevant publications. Early diabetes identification is critical since it reduces the risk of death from the disease. Artificial neural networks, principal component analysis, decision trees, genetic algorithms, fuzzy logic, and other machine learning techniques have all been examined and compared.
C1 [Baby, Steffy T.; Karunakaran, V] Karunya Inst Technol & Sci, Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
RP Baby, ST (corresponding author), Karunya Inst Technol & Sci, Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
NR 27
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-6654-2642-8
PY 2021
BP 530
EP 537
DI 10.1109/I-SMAC52330.2021.9640806
PG 8
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS7GZ
UT WOS:000760875500089
DA 2022-04-17
ER

PT J
AU Nguyen, LT
   Nguyen, HT
   Afanasiev, AD
   Nguyen, TV
AF Nguyen, Long The
   Nguyen, Huong Thu
   Afanasiev, Alexander Diomidovich
   Nguyen, Tao Van
TI Automatic Identification Fingerprint Based on Machine Learning Method
SO JOURNAL OF THE OPERATIONS RESEARCH SOCIETY OF CHINA
LA English
DT Article; Early Access
DE Fingerprint identification; Feature extraction; Image segmentation;
   Wavelet transform; Neural network algorithm; Machine learning
ID CLASSIFICATION
AB The fingerprint identification technology has been developed and applied effectively to security systems in financial transactions, personal information security, national security, and other fields. In this paper, we proposed the development of a fingerprint identification system based on image processing methods that clarify fingerprint contours, using machine learning methods to increase processing speed and increase the accuracy of the fingerprint identification process. The identification system consists of the following main steps: improving image quality and image segmentation to identify the fingerprint area, extracting features, and matching the database. The accuracy of the system reached 97.75% on the mixed high- and low-quality fingerprint database.
C1 [Nguyen, Long The; Afanasiev, Alexander Diomidovich] Irkutsk Natl Res Tech Univ, Inst Informat Technol & Data Sci, Lab Artificial Intelligence & Machine Learning, Irkutsk, Russia.
   [Nguyen, Huong Thu] Irkutsk Natl Res Tech Univ, Baikal Sch BRICS, Irkutsk, Russia.
   [Nguyen, Huong Thu; Nguyen, Tao Van] Thai Nguyen Univ, Univ Informat & Commun Technol, Thai Nguyen, Vietnam.
RP Nguyen, LT (corresponding author), Irkutsk Natl Res Tech Univ, Inst Informat Technol & Data Sci, Lab Artificial Intelligence & Machine Learning, Irkutsk, Russia.
EM thelongit88@gmail.com; thuhuongyb@gmail.com; aad@istu.edu;
   nvtao@ictu.edu.vn
RI , Nguyen The Long/O-8627-2019; Afanasyev, Alexander/AAV-3412-2021; Thu
   Huong, Nguyen/AAG-7775-2020
OI , Nguyen The Long/0000-0002-9507-8198; Afanasyev,
   Alexander/0000-0001-8745-1725; Thu Huong, Nguyen/0000-0002-7009-2815
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [00001, 00010]; Chongqing Municipal Education
   Commission [KJ120616]
FX This research was supported by the National Natural Science Foundation
   of China (Nos. 00001 and 00010) and Chongqing Municipal Education
   Commission No. KJ120616).
NR 29
TC 0
Z9 0
U1 3
U2 6
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 2194-668X
EI 2194-6698
J9 J OPER RES SOC CHINA
JI J. Oper. Res. Soc. China
DI 10.1007/s40305-020-00332-7
EA JAN 2021
PG 12
WC Operations Research & Management Science
WE Emerging Sources Citation Index (ESCI)
SC Operations Research & Management Science
GA PN4LB
UT WOS:000604451100001
DA 2022-04-17
ER

PT J
AU Burlig, F
   Knittel, C
   Rapson, D
   Reguant, M
   Wolfram, C
AF Burlig, Fiona
   Knittel, Christopher
   Rapson, David
   Reguant, Mar
   Wolfram, Catherine
TI Machine Learning from Schools about Energy Efficiency
SO JOURNAL OF THE ASSOCIATION OF ENVIRONMENTAL AND RESOURCE ECONOMISTS
LA English
DT Article
DE energy efficiency; machine learning; schools
ID INVESTMENTS DELIVER; PROPENSITY SCORE; REGRESSION; ECONOMICS; INFERENCE;
   PROGRAM
AB We use high-frequency panel data on electricity consumption to study the effectiveness of energy efficiency upgrades in K-12 schools in California. Using a panel fixed effects approach, we find that these upgrades deliver between 12% and 86% of expected savings, depending on specification and treatment of outliers. Using machine learning to inform our specification choice, we estimate a narrower range: 52%-98%, with a central estimate of 60%. These results imply that upgrades are performing less well than ex ante predictions on average, although we can reject some of the very low realization rates found in prior work.
C1 [Burlig, Fiona] Univ Chicago, Harris Sch Publ Policy, Chicago, IL 60637 USA.
   [Burlig, Fiona] Univ Chicago, Energy Policy Inst, Chicago, IL 60637 USA.
   [Burlig, Fiona; Knittel, Christopher; Reguant, Mar; Wolfram, Catherine] NBER, Cambridge, MA 02138 USA.
   [Knittel, Christopher] MIT, Sloan Sch Management, Cambridge, MA 02139 USA.
   [Knittel, Christopher] MIT, Ctr Energy & Environm Policy Res, Cambridge, MA 02139 USA.
   [Rapson, David] Univ Calif Davis, Dept Econ, Davis, CA 95616 USA.
   [Reguant, Mar] Northwestern Univ, Dept Econ, Ctr Econ & Policy Res CEPR, Evanston, IL 60208 USA.
   [Wolfram, Catherine] Univ Calif Berkeley, Haas Sch Business, Berkeley, CA 94720 USA.
   [Wolfram, Catherine] Univ Calif Berkeley, Energy Inst Haas, Berkeley, CA 94720 USA.
RP Burlig, F (corresponding author), Univ Chicago, Harris Sch Publ Policy, Chicago, IL 60637 USA.; Burlig, F (corresponding author), Univ Chicago, Energy Policy Inst, Chicago, IL 60637 USA.; Burlig, F (corresponding author), NBER, Cambridge, MA 02138 USA.
EM burlig@uchicago.edu; knittel@mit.edu; dsrapson@ucdavis.edu;
   mar.reguant@northwestern.edu; cwolfram@berkeley.edu
OI Reguant, Mar/0000-0001-8877-5780; Rapson, David/0000-0001-8711-7030
NR 58
TC 10
Z9 10
U1 4
U2 13
PU UNIV CHICAGO PRESS
PI CHICAGO
PA 1427 E 60TH ST, CHICAGO, IL 60637-2954 USA
SN 2333-5955
EI 2333-5963
J9 J ASSOC ENVIRON RESO
JI J. Assoc. Environ. Resour. Econ.
PD NOV 1
PY 2020
VL 7
IS 6
BP 1181
EP 1217
DI 10.1086/710606
PG 37
WC Economics; Environmental Studies
WE Social Science Citation Index (SSCI)
SC Business & Economics; Environmental Sciences & Ecology
GA NS2PX
UT WOS:000572110600001
OA Green Submitted, Green Published
DA 2022-04-17
ER

PT J
AU Vu, AT
   Gulati, S
   Vogel, PA
   Grunwald, T
   Bergs, T
AF Anh Tuan Vu
   Gulati, Shrey
   Vogel, Paul-Alexander
   Grunwald, Tim
   Bergs, Thomas
TI Machine learning-based predictive modeling of contact heat transfer
SO INTERNATIONAL JOURNAL OF HEAT AND MASS TRANSFER
LA English
DT Article
DE Thermal contact conductance; Machine learning; Data-driven modeling;
   Infrared thermography; Glass molding
ID MOLECULAR-DYNAMICS; SURFACE-ROUGHNESS; CONDUCTANCE; TEMPERATURE;
   RESISTANCE
AB Heat transfer phenomena at the interface between two contacting solids are highly complex involving multiple influencing factors. Over the years, a large amount of experiments were carried out to determine the contact heat transfer coefficients between two dissimilar joint materials. However, there are still no existing theoretical or physics-based models that satisfactorily predict the contact heat transfer coefficients. By taking advantage of the existing data, in contrast, machine learning promises a powerful method, capable of predicting the contact heat transfer coefficients for different material pairs and contact conditions. This research introduces a robust machine learning-based model that succeeds in precisely estimating the heat transfer across the interfaces between glass and steel, a material pair widely used in hot forming of glass. The data used for training and validating the machine learning models were determined experimentally by means of infrared thermography. The datasets consisted of contact heat transfer coefficients with dependence on three factors - interfacial temperature, contact pressure, and surface finishes. Aim of this study is to analyze the prediction accuracy and interpretability of various supervised learning algorithms in order to realize the machine learning models that are able to capture the underlying physics governing the heat transfer phenomena at the glass-mold interface. Finally, the results were compared with those estimated by a theoretical model and a numerical simulation model. The comparison demonstrates enhancements in prediction accuracy enabled by the data-driven method. This study indicates accurate and efficient strategies for solving thermal problems in hot glass forming processes. (C) 2021 Elsevier Ltd. All rights reserved.
C1 [Anh Tuan Vu; Gulati, Shrey; Vogel, Paul-Alexander; Grunwald, Tim; Bergs, Thomas] Fraunhofer Inst Prod Technol IPT, Fine Machining & Opt, Aachen, Germany.
   [Bergs, Thomas] Rhein Westfal TH Aachen, Lab Machine Tools & Prod Engn WZL, Aachen, Germany.
RP Vu, AT (corresponding author), Fraunhofer Inst Prod Technol IPT, Fine Machining & Opt, Aachen, Germany.
EM anh.tuan.vu@ipt.fraunhofer.de
OI Vu, Anh Tuan/0000-0002-5965-0169
NR 44
TC 3
Z9 3
U1 20
U2 44
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0017-9310
EI 1879-2189
J9 INT J HEAT MASS TRAN
JI Int. J. Heat Mass Transf.
PD AUG
PY 2021
VL 174
AR 121300
DI 10.1016/j.ijheatmasstransfer.2021.121300
EA APR 2021
PG 11
WC Thermodynamics; Engineering, Mechanical; Mechanics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Thermodynamics; Engineering; Mechanics
GA RY0PM
UT WOS:000647617700015
DA 2022-04-17
ER

PT C
AU Kavitha, M
   Gnaneswar, G
   Dinesh, R
   Sai, YR
   Suraj, RS
AF Kavitha, M.
   Gnaneswar, G.
   Dinesh, R.
   Sai, Y. Rohith
   Suraj, R. Sai
GP IEEE
TI Heart Disease Prediction using Hybrid machine Learning Model
SO PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION
   TECHNOLOGIES (ICICT 2021)
LA English
DT Proceedings Paper
CT 6th International Conference on Inventive Computation Technologies
   (ICICT)
CY JAN 20-22, 2021
CL Coimbatore, INDIA
SP IEEE, SVR Tech Campus
DE Cleveland Heart Disease Database; Decision Trees; Random forest; Hybrid
   algorithm; Machine learning
AB Heart disease causes a significant mortality rate around the world, and it has become a health threat for many people. Early prediction of heart disease may save many lives; detecting cardiovascular diseases like heart attacks, coronary artery diseases etc., isa critical challenge by the regular clinical data analysis. Machine learning (ML) can bring an effective solution for decision making and accurate predictions. The medical industry is showing enormous development in using machine learning techniques. In the proposed work, a novel machine learning approach is proposed to predict heart disease. The proposed study used the Cleveland heart disease dataset, and data mining techniques such as regression and classification are used. Machine learning techniques Random Forest and Decision Tree are applied. The novel technique of the machine learning model is designed. In implementation, 3 machine learning algorithms are used, they are 1. Random Forest, 2. Decision Tree and 3. Hybrid model (Hybrid of random forest and decision tree). Experimental results show an accuracy level of 88.7% through the heart disease prediction model with the hybrid model. The interface is designed to get the user's input parameter to predict the heart disease, for which we used a hybrid model of Decision Tree and Random Forest.
C1 [Kavitha, M.; Gnaneswar, G.; Dinesh, R.; Sai, Y. Rohith; Suraj, R. Sai] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, AP, India.
RP Kavitha, M (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, AP, India.
EM mkavita@kluniversity.in; gnanegullapalli@gmai1.co;
   rampallidinesh@gmail.com; rohithsai@gmail.com; rangasaisuraj@gmail.com
RI Modepalli, Kavitha/AAR-9630-2020
OI Modepalli, Kavitha/0000-0003-1963-8330
NR 17
TC 3
Z9 3
U1 5
U2 5
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-8501-9
PY 2021
BP 1329
EP 1333
DI 10.1109/ICICT50816.2021.9358597
PG 5
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BS4RZ
UT WOS:000722293800224
DA 2022-04-17
ER

PT C
AU Mana, SC
   Sasipraba, T
AF Mana, Suja Cherukullapurath
   Sasipraba, T.
GP IEEE
TI A Machine Learning Based Implementation of Product and Service
   Recommendation Models
SO 2021 7TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENERGY SYSTEMS (ICEES)
SE International Conference on Electrical Energy Systems-ICEES
LA English
DT Proceedings Paper
CT 7th International Conference on Electrical Energy Systems (ICEES)
CY FEB 11-13, 2021
CL Sri Sivasubramania Nadar Coll Engn, ELECTR NETWORK
SP Sri Sivasubramania Nadar Coll Engn, Dept Elect & Elect Engn, Prince Sultan Univ, Inst Elect & Elect Engineers Madras Sect
HO Sri Sivasubramania Nadar Coll Engn
DE machine learning; recommendation system; support vector machine
AB Most of the internet based companies are now relying on the capabilities of recommendation models to increase their product sales. By applying efficient recommendation models businesses can track their customer preferences and effectively recommend products to users thereby increasing their sales. This paper describes the prototype implementation of two recommendations models using machine learning algorithms. The first prototype system is a banking service recommendation system and the second one is a movie recommendation system. These prototype implementations are evidence of how effectively machine learning algorithms can be applied for designing recommendation models.
C1 [Mana, Suja Cherukullapurath; Sasipraba, T.] Sathyabama Inst Sci & Technol, Sch Comp, Chennai, Tamil Nadu, India.
RP Mana, SC (corresponding author), Sathyabama Inst Sci & Technol, Sch Comp, Chennai, Tamil Nadu, India.
EM cmsuja@gmail.com; vc@sathyabama.ac.in
RI Mana, Suja Cherukullapurath/C-1413-2019
OI Mana, Suja Cherukullapurath/0000-0001-7708-0676
NR 12
TC 0
Z9 0
U1 6
U2 9
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2693-3942
EI 2693-3934
BN 978-1-7281-7612-3
J9 INT CONF ELECTR ENER
PY 2021
BP 543
EP 547
DI 10.1109/ICEES51510.2021.9383732
PG 5
WC Energy & Fuels; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Energy & Fuels; Engineering
GA BR8DE
UT WOS:000670885800097
DA 2022-04-17
ER

PT J
AU Johnson, C
   Lu, T
   Rivera, P
   McDonald, D
   Pritchett, S
   Peng, L
AF Johnson, Caleb
   Lu, Tao
   Rivera, Pedro
   McDonald, Devon
   Pritchett, Samuel
   Peng, Lu
TI iChain: Peer-To-Peer Machine Learning Powered by Blockchain Technology
SO FRONTIERS IN BLOCKCHAIN
LA English
DT Article
DE blockchain; ethereum; peer-to-peer; machine learning; transactions
AB iChain is an application which was created to help meet the growing demand of machine learning. It allows users to pay those with powerful machines to run machine learning tasks for them, bypassing the need for a significant investment in a powerful computer to run it themselves. This is similar to services like a render farm. Our application functions using the Ethereum blockchain which ensures security and decentralization, as well as providing a platform for payment transactions. This article will discuss the background on machine learning and blockchain, the application, how it works, how the data moves through it, and how to use it. We hope our application will enable many without the funds to build or buy a powerful computer to experiment with and utilize complex machine learning tasks.
C1 [Johnson, Caleb; Lu, Tao; Rivera, Pedro; McDonald, Devon; Pritchett, Samuel; Peng, Lu] Louisiana State Univ, Div Elect & Comp Engn, Baton Rouge, LA 70803 USA.
RP Peng, L (corresponding author), Louisiana State Univ, Div Elect & Comp Engn, Baton Rouge, LA 70803 USA.
EM lpeng@lsu.edu
NR 18
TC 0
Z9 0
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 2624-7852
J9 FRONT BLOCKCHAIN
JI Front. Blockchain
PD JUL 12
PY 2021
VL 4
AR 676159
DI 10.3389/fbloc.2021.676159
PG 8
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA TP9RO
UT WOS:000677929600001
OA gold
DA 2022-04-17
ER

PT J
AU Minerali, E
   Foil, DH
   Zorn, KM
   Lane, TR
   Ekins, S
AF Minerali, Eni
   Foil, Daniel H.
   Zorn, Kimberley M.
   Lane, Thomas R.
   Ekins, Sean
TI Comparing Machine Learning Algorithms for Predicting Drug-Induced Liver
   Injury (DILI)
SO MOLECULAR PHARMACEUTICS
LA English
DT Article
DE Assay Central; bayesian; drug-induced liver injury; machine learning;
   MegaTox
ID HEPATOTOXICITY; TOXICOLOGY; ATRIUM(R); WITHDRAWN; AGREEMENT; MODEL; RISK
AB Drug-induced liver injury (DILI) is one the most unpredictable adverse reactions to xenobiotics in humans and the leading cause of postmarketing withdrawals of approved drugs. To date, these drugs have been collated by the FDA to form the DILIRank database, which classifies DILI severity and potential. These classifications have been used by various research groups in generating computational predictions for this type of liver injury. Recently, groups from Pfizer and AstraZeneca have collated DILI in vitro data and physicochemical properties for compounds that can be used along with data from the FDA to build machine learning models for DILI. In this study, we have used these data sets, as well as the Biopharmaceutics Drug Disposition Classification System data set, to generate Bayesian machine learning models with our inhouse software, Assay Central. The performance of all machine learning models was assessed through both the internal 5-fold cross-validation metrics and prediction accuracy of an external test set of compounds with known hepatotoxicity. The best-performing Bayesian model was based on the DILI-concern category from the DILIRank database with an ROC of 0.814, a sensitivity of 0.741, a specificity of 0.755, and an accuracy of 0.746. A comparison of alternative machine learning algorithms, such as k-nearest neighbors, support vector classification, AdaBoosted decision trees, and deep learning methods, produced similar statistics to those generated with the Bayesian algorithm in Assay Central. This study demonstrates machine learning models grouped in a tool called MegaTox that can be used to predict early-stage clinical compounds, as well as recent FDA-approved drugs, to identify potential DILI.
C1 [Minerali, Eni; Foil, Daniel H.; Zorn, Kimberley M.; Lane, Thomas R.; Ekins, Sean] Collaborat Pharmaceut Inc, Raleigh, NC 27606 USA.
RP Ekins, S (corresponding author), Collaborat Pharmaceut Inc, Raleigh, NC 27606 USA.
EM sean@collaborationspharma.com
RI Foil, Daniel/AAJ-1809-2021
OI Foil, Daniel/0000-0003-0512-8997; Minerali, Eni/0000-0002-7018-7021
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [R44GM122196-02A1, 1R43ES031038-01];
   National Institute of Environmental Health Sciences of the National
   Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   of Environmental Health Sciences (NIEHS) [R43ES031038]
FX We acknowledge Dr. Alex Clark (Molecular Materials Informatics) for
   Assay Central support and Mr. Valery Tkachenko for machine learning
   support. We kindly acknowledge NIH funding to develop the software from
   R44GM122196-02A1 "Centralized assay data sets for modelling support of
   small drug discovery organizations" from NIGMS and NIEHS for
   1R43ES031038-01 and MegaTox for analyzing and visualizing data across
   different screening systems. Research reported in this publication was
   supported by the National Institute of Environmental Health Sciences of
   the National Institutes of Health under Award Number R43ES031038. The
   content is solely the responsibility of the authors and does not
   necessarily represent the official views of the National Institutes of
   Health.
NR 58
TC 19
Z9 19
U1 7
U2 26
PU AMER CHEMICAL SOC
PI WASHINGTON
PA 1155 16TH ST, NW, WASHINGTON, DC 20036 USA
SN 1543-8384
J9 MOL PHARMACEUT
JI Mol. Pharm.
PD JUL 6
PY 2020
VL 17
IS 7
BP 2628
EP 2637
DI 10.1021/acs.molpharmaceut.0c00326
PG 10
WC Medicine, Research & Experimental; Pharmacology & Pharmacy
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Research & Experimental Medicine; Pharmacology & Pharmacy
GA MK0CS
UT WOS:000548455300033
PM 32422053
OA Green Accepted
DA 2022-04-17
ER

PT C
AU Ben Rabah, N
   Kirsch Pinheiro, M
   Le Grand, B
   Jaffal, A
   Souveyet, C
AF Ben Rabah, Nourhene
   Kirsch Pinheiro, Manuele
   Le Grand, Benedicte
   Jaffal, Ali
   Souveyet, Carine
GP IEEE
TI Machine Learning for a Context Mining Facility
SO 2020 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND
   COMMUNICATIONS WORKSHOPS (PERCOM WORKSHOPS)
SE International Conference on Pervasive Computing and Communications
LA English
DT Proceedings Paper
CT IEEE International Conference on Pervasive Computing and Communications
   (PerCom)
CY MAR 23-27, 2020
CL Austin, TX
SP IEEE
DE context mining; context data; machine learning
ID AWARE; PREDICTION; FRAMEWORK; SYSTEMS
AB This paper considers generalizing context reasoning capabilities through a context mining facility offered to all Information System applications. This facility requires mining context data at the system scale, which raises several challenges for Machine Learning approaches used for such mining. Through a detailed literature review, we analyze these approaches with regard to the requirements of such a context mining facility at the Information System level, pointing to the potential and to the challenges raised by this perspective.
C1 [Ben Rabah, Nourhene; Kirsch Pinheiro, Manuele; Le Grand, Benedicte; Jaffal, Ali; Souveyet, Carine] Univ Paris 1 Pantheon Sorbonne, Ctr Rech Informat, Paris, France.
RP Ben Rabah, N (corresponding author), Univ Paris 1 Pantheon Sorbonne, Ctr Rech Informat, Paris, France.
EM Nourhene.Ben-Rabah@univ-paris1.fr;
   Manuele.Kirsch-Pinheiro@univ-paris1.fr;
   Benedicte.Le-Grand@univ-paris1.fr; Ali.Jaffal@univ-paris1.fr;
   Carine.Souveyet@univ-paris1.fr
NR 48
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2474-2503
BN 978-1-7281-4716-1
J9 INT CONF PERVAS COMP
PY 2020
PG 7
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Telecommunications
GA BQ6OA
UT WOS:000612838200049
DA 2022-04-17
ER

PT J
AU Rasheed, F
   Wahid, A
AF Rasheed, Fareeha
   Wahid, Abdul
TI Learning style detection in E-learning systems using machine learning
   techniques
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Machine learning; Classification; Learning style; E-learning
ID IDENTIFICATION; PRECISION
AB Learning style plays a vital role in helping students retain learned concepts for a longer time and also improves the understanding of the concepts. Learning styles in offline and online scenarios are recognized using questionnaires. The recent trend is to identify and use attributes to detect the learning style of the learner automatically without disturbing the learner. The paper is an extension of the authors' earlier work with some changes to the methodology. In this paper, the authors have identified new attributes and scaled-down the attributes identified earlier, which would help identify the learner's learning style. The authors implemented classification algorithms and compared the accuracy of the different algorithms on the dataset. Various interesting patterns are observed in learner's behaviour while learning different types of concepts in different situations.
C1 [Rasheed, Fareeha; Wahid, Abdul] Maulana Azad Natl Urdu Univ, Dept Comp Sci & Informat Technol, Hyderabad, India.
RP Rasheed, F (corresponding author), Maulana Azad Natl Urdu Univ, Dept Comp Sci & Informat Technol, Hyderabad, India.
EM fareeha_zarish22@yahoo.com; awahid@manuu.edu.in
RI Rasheed, Fareeha/AAC-3014-2022; Wahid, Abdul/AAB-8183-2022; Rasheed,
   Fareeha/N-4159-2017
OI Rasheed, Fareeha/0000-0002-0996-9921; Wahid, Abdul/0000-0001-6729-7775;
   Rasheed, Fareeha/0000-0002-0996-9921
NR 65
TC 4
Z9 4
U1 4
U2 7
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD JUL 15
PY 2021
VL 174
AR 114774
DI 10.1016/j.eswa.2021.114774
EA MAR 2021
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Operations Research & Management Science
GA SU4ZF
UT WOS:000663146900010
DA 2022-04-17
ER

PT C
AU Pintye, I
AF Pintye, Istvan
GP IEEE
TI Machine learning methods in Smartphone-Based Activity Recognition
SO 2020 IEEE 14TH INTERNATIONAL SYMPOSIUM ON APPLIED COMPUTATIONAL
   INTELLIGENCE AND INFORMATICS (SACI 2020)
LA English
DT Proceedings Paper
CT IEEE 14th International Symposium on Applied Computational Intelligence
   and Informatics (SACI)
CY MAY 21-23, 2020
CL Timisoara, ROMANIA
SP IEEE
DE Human activity recognition; Machine Learning; Artificial Neural Net;
   Python; Sci-Kit Learn; Keras
AB In this paper, we present a system for human physical Activity Recognition (AR) using smartphone with embedded sensors. This paper addresses the question whether there is a comfortable way to predict human activities based on collected data from smartphone embedded gyroscope and accelerometer. Computational background of this work based on self-learning machine learning methods. In order to train the machine learning algorithms, The University of California, Irvine (UCI) dataset was used and the different models were compared. After selecting the best model further modifications were suggested in order to improve the accuracy of the model. At the end 96.88% accuracy was reached.
C1 [Pintye, Istvan] SZTAKI, Inst Comp Sci & Control, Lab Parallel & Distributed Syst, Budapest, Hungary.
   [Pintye, Istvan] Obuda Univ, Doctoral Sch Appl Informat & Appl Math, Budapest, Hungary.
RP Pintye, I (corresponding author), SZTAKI, Inst Comp Sci & Control, Lab Parallel & Distributed Syst, Budapest, Hungary.; Pintye, I (corresponding author), Obuda Univ, Doctoral Sch Appl Informat & Appl Math, Budapest, Hungary.
EM istvan.pintye@sztaki.hu
FU European H2020 NEANIAS project [863448]; Hungarian Scientific Research
   Fund (OTKA)Orszagos Tudomanyos Kutatasi Alapprogramok (OTKA) [132838]
FX The presented work was partially funded by the European H2020 NEANIAS
   project under grant No. 863448, and by the Hungarian Scientific Research
   Fund (OTKA) under project No. 132838. We thank for the usage of MTA
   Cloud (https://cloud.mta.hu/) that significantly helped us achieving the
   results published in this paper.
NR 9
TC 2
Z9 2
U1 1
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-7281-7376-4
PY 2020
BP 153
EP 158
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ6BK
UT WOS:000610510000025
OA Green Accepted
DA 2022-04-17
ER

PT C
AU Sahagun, MAM
AF Sahagun, Mary Anne M.
GP IEEE
TI Prediction of Electronics Engineering Student's Learning Style using
   Machine Learning
SO 2021 1ST CONFERENCE ON ONLINE TEACHING FOR MOBILE EDUCATION (OT4ME)
LA English
DT Proceedings Paper
CT 1st Conference on Online Teaching for Mobile Education (OT4ME)
CY NOV 22-25, 2021
CL ELECTR NETWORK
SP Univ Alcala, SEPIE, European Union, Erasmus+ Programme, European Univ Fdn, Lodz Univ Technol, Univ Latvia, Univ Naples Federico II, IEEE Spain Secc, MIT Square, Univ Naples Federico II, Dipartimento Ingn Elettrica Tecnologie Informatzione
DE VARK; decision tree; machine learning; confusion matrix; prediction
AB The learning style of students is oftentimes not considered in teaching strategies in an engineering program and as a result, educators used teaching strategies not suited to the majority's preference, students become inattentive and unresponsive in an e-learning class. The study was conducted to identify and predict the learning style of third-year electronics engineering students using the Visual, Auditory, Reading/Writing, and Kinesthetic Model (VARK). The significance of the study is the use of machine learning to automatically predict the student's style of learning. The prediction of learning style was divided into two: single-modal learning style and multi-modal learning style. Results show that 87% are a single-modal type of learners and only 13% are a multi-modal type. The Decision Tree is the optimized prediction model for the study. This study would provide faculty an efficient way of determining the learning style of their students and in effect, faculty will be able to adjust teaching strategies that match the learning style of the students.
C1 [Sahagun, Mary Anne M.] Don Honorio Ventura State Univ, Dept Elect Engn, Villa De Bacolor, Pampanga, Philippines.
RP Sahagun, MAM (corresponding author), Don Honorio Ventura State Univ, Dept Elect Engn, Villa De Bacolor, Pampanga, Philippines.
EM mamsahagun@gmail.com
NR 22
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-6654-2814-9
PY 2021
BP 42
EP 49
DI 10.1109/OT4ME53559.2021.9638868
PG 8
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods; Education & Educational Research
WE Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Computer Science; Education & Educational Research
GA BS7PH
UT WOS:000765760500008
DA 2022-04-17
ER

PT S
AU Brunton, SL
   Noack, BR
   Koumoutsakos, P
AF Brunton, Steven L.
   Noack, Bernd R.
   Koumoutsakos, Petros
BE Davis, SH
   Moin, P
TI Machine Learning for Fluid Mechanics
SO ANNUAL REVIEW OF FLUID MECHANICS, VOL 52
SE Annual Review of Fluid Mechanics
LA English
DT Review; Book Chapter
DE machine learning; data-driven modeling; optimization; control
ID ARTIFICIAL NEURAL-NETWORKS; EVOLUTIONARY ALGORITHMS; DATA-DRIVEN; SENSOR
   PLACEMENT; TURBULENCE; SYSTEMS; FLOWS; MODEL; OPTIMIZATION;
   IDENTIFICATION
AB The field of fluid mechanics is rapidly advancing, driven by unprecedented volumes of data from experiments, field measurements, and large-scale simulations at multiple spatiotemporal scales. Machine learning (ML) offers a wealth of techniques to extract information from data that can be translated into knowledge about the underlying fluid mechanics. Moreover, ML algorithms can augment domain knowledge and automate tasks related to flow control and optimization. This article presents an overview of past history, current developments, and emerging opportunities of ML for fluid mechanics. We outline fundamental ML methodologies and discuss their uses for understanding, modeling, optimizing, and controlling fluid flows. The strengths and limitations of these methods are addressed from the perspective of scientific inquiry that considers data as an inherent part of modeling, experiments, and simulations. ML provides a powerful information-processing framework that can augment, and possibly even transform, current lines of fluid mechanics research and industrial applications.
C1 [Brunton, Steven L.] Univ Washington, Dept Mech Engn, Seattle, WA 98195 USA.
   [Noack, Bernd R.] Univ Paris Saclay, LIMSI, CNRS, UPR 3251, F-91403 Orsay, France.
   [Noack, Bernd R.] Tech Univ Berlin, Inst Stromungsmech & Tech Akust, D-10634 Berlin, Germany.
   [Koumoutsakos, Petros] Swiss Fed Inst Technol, Computat Sci & Engn Lab, CH-8092 Zurich, Switzerland.
RP Koumoutsakos, P (corresponding author), Swiss Fed Inst Technol, Computat Sci & Engn Lab, CH-8092 Zurich, Switzerland.
EM petros@ethz.ch
RI Brunton, Steven/AAG-3871-2019; Noack, Bernd R./B-1242-2012
OI Brunton, Steven/0000-0002-6565-5118; Noack, Bernd R./0000-0001-5935-1962
FU Army Research Office (ARO) [W911NF-17-1-0306, W911NF-17-1-0422]; Air
   Force Office of Scientific Research (AFOSR)United States Department of
   DefenseAir Force Office of Scientific Research (AFOSR)
   [FA9550-18-1-0200]; LIMSI-CNRS; Universite Paris Sud (SMEMaG); French
   National Research AgencyFrench National Research Agency (ANR)
   [ANR-11-IDEX-0003-02, ANR-17-ASTR-0022]; German Research
   FoundationGerman Research Foundation (DFG) [CRC880, SE 2504/2-1, SE
   2504/3-1]; ERC Advanced Investigator Award (FMCoBe) [34117]; Swiss
   National Science FoundationSwiss National Science Foundation
   (SNSF)European Commission; Swiss National Supercomputing Centre
FX S.L.B. acknowledges funding from the Army Research Office (ARO
   W911NF-17-1-0306, W911NF-17-1-0422) and the Air Force Office of
   Scientific Research (AFOSR FA9550-18-1-0200). B.R.N. acknowledges
   funding from LIMSI-CNRS, Universite Paris Sud (SMEMaG), the French
   National Research Agency (ANR-11-IDEX-0003-02, ANR-17-ASTR-0022), and
   the German Research Foundation (CRC880, SE 2504/2-1, SE 2504/3-1). P.K.
   acknowledges funding from an ERC Advanced Investigator Award (FMCoBe,
   No. 34117), the Swiss National Science Foundation, and the Swiss
   National Supercomputing Centre. The authors are grateful for discussions
   with Nathan Kutz (University of Washington), Jean-Christophe Loiseau
   (ENSAM Paris-Tech, Paris), Francois Lusseyran (LIMSI-CNRS, Paris), Guido
   Novati (ETH Zurich), Luc Pastur (ENSTA ParisTech, Paris), and Pantelis
   Vlachas (ETH Zurich).
NR 166
TC 365
Z9 378
U1 188
U2 460
PU ANNUAL REVIEWS
PI PALO ALTO
PA 4139 EL CAMINO WAY, PO BOX 10139, PALO ALTO, CA 94303-0897 USA
SN 0066-4189
EI 1545-4479
BN 978-0-8243-0752-3
J9 ANNU REV FLUID MECH
JI Annu. Rev. Fluid Mech.
PY 2020
VL 52
BP 477
EP 508
DI 10.1146/annurev-fluid-010719-060214
PG 32
WC Mechanics; Physics, Fluids & Plasmas
WE Book Citation Index – Science (BKCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Mechanics; Physics
GA BO2PT
UT WOS:000507468800019
OA Green Submitted, Bronze
HC Y
HP Y
DA 2022-04-17
ER

PT J
AU Hegde, J
   Rokseth, B
AF Hegde, Jeevith
   Rokseth, Borge
TI Applications of machine learning methods for engineering risk assessment
   - A review
SO SAFETY SCIENCE
LA English
DT Review
DE Risk assessment; Machine learning; Artificial neural network; Review
ID SUPPORT VECTOR MACHINE; LANDSLIDE SUSCEPTIBILITY ASSESSMENT; DATA-MINING
   APPROACH; NEURAL-NETWORKS; BIG DATA; SAFETY ANALYSIS; TRANSPORTATION
   SYSTEMS; CONSTRUCTION SAFETY; INJURY SEVERITY; DRIVING SAFETY
AB The purpose of this article is to present a structured review of publications utilizing machine learning methods to aid in engineering risk assessment. A keyword search is performed to retrieve relevant articles from the databases of Scopus and Engineering Village. The search results are filtered according to seven selection criteria. The filtering process resulted in the retrieval of one hundred and twenty-four relevant research articles. Statistics based on different categories from the citation database is presented. By reviewing the articles, additional categories, such as the type of machine learning algorithm used, the type of input source used, the type of industry targeted, the type of implementation, and the intended risk assessment phase are also determined. The findings show that the automotive industry is leading the adoption of machine learning algorithms for risk assessment. Artificial neural networks are the most applied machine learning method to aid in engineering risk assessment. Additional findings from the review process are also presented in this article.
C1 [Hegde, Jeevith; Rokseth, Borge] Norwegian Univ Sci & Technol, Dept Marine Technol, Otto Nielsen Veg 10, N-7491 Trondheim, Norway.
RP Hegde, J (corresponding author), Norwegian Univ Sci & Technol, Dept Marine Technol, Otto Nielsen Veg 10, N-7491 Trondheim, Norway.
EM jeevith.hegde@ntnu.no
FU Department of Marine Technology, Norwegian University of Science and
   Technology (NTNU); Norwegian Research CouncilResearch Council of
   NorwayEuropean Commission [280934, 280655]; project Online risk
   management and risk control for autonomous ships (ORCAS); DNVGL
   [280655]; Rolls Royce MarineRolls-Royce Holding Group [280655]
FX The authors would like to thank an anonymous colleague and the two
   anonymous reviewers for providing constructive feedback on an earlier
   version of this article. The first author would like to acknowledge the
   funding support received from the Department of Marine Technology,
   Norwegian University of Science and Technology (NTNU) and the expert
   feedback received from the partners of the Autonomous subsea
   intervention (SEAVENTION) project (280934) funded by the Norwegian
   Research Council. The second author is funded by the project Online risk
   management and risk control for autonomous ships (ORCAS). The Norwegian
   Research Council, DNVGL and Rolls Royce Marine are acknowledged as
   sponsors of project number 280655.
NR 139
TC 73
Z9 73
U1 85
U2 167
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-7535
EI 1879-1042
J9 SAFETY SCI
JI Saf. Sci.
PD FEB
PY 2020
VL 122
AR 104492
DI 10.1016/j.ssci.2019.09.015
PG 16
WC Engineering, Industrial; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Engineering; Operations Research & Management Science
GA JS5YE
UT WOS:000500381500027
OA Green Published, hybrid
HC Y
HP N
DA 2022-04-17
ER

PT C
AU Zhang, L
   Blaauwbroek, L
   Piotrowski, B
   Cerny, P
   Kaliszyk, C
   Urban, J
AF Zhang, Liao
   Blaauwbroek, Lasse
   Piotrowski, Bartosz
   Cerny, Prokop
   Kaliszyk, Cezary
   Urban, Josef
BE Kamareddine, F
   Coen, CS
TI Online Machine Learning Techniques for Coq: A Comparison
SO INTELLIGENT COMPUTER MATHEMATICS (CICM 2021)
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 14th International Conference on Intelligent Computer Mathematics (CICM)
CY JUL 26-31, 2021
CL ELECTR NETWORK
DE Interactive theorem proving; Coq; Machine learning; Online learning;
   Gradient boosted trees; Random forest
AB We present a comparison of several online machine learning techniques for tactical learning and proving in the Coq proof assistant. This work builds on top of Tactician, a plugin for Coq that learns from proofs written by the user to synthesize new proofs. Learning happens in an online manner, meaning that Tactician's machine learning model is updated immediately every time the user performs a step in an interactive proof. This has important advantages compared to the more studied offline learning systems: (1) it provides the user with a seamless, interactive experience with Tactician and, (2) it takes advantage of locality of proof similarity, which means that proofs similar to the current proof are likely to be found close by. We implement two online methods, namely approximate k-nearest neighbors based on locality sensitive hashing forests and random decision forests. Additionally, we conduct experiments with gradient boosted trees in an offline setting using XGBoost. We compare the relative performance of Tactician using these three learning methods on Coq's standard library.
C1 [Zhang, Liao; Blaauwbroek, Lasse; Piotrowski, Bartosz; Cerny, Prokop; Urban, Josef] Czech Tech Univ, Prague, Czech Republic.
   [Blaauwbroek, Lasse] Radboud Univ Nijmegen, Nijmegen, Netherlands.
   [Zhang, Liao; Kaliszyk, Cezary] Univ Innsbruck, Innsbruck, Austria.
   [Piotrowski, Bartosz; Kaliszyk, Cezary] Univ Warsaw, Warsaw, Poland.
RP Zhang, L (corresponding author), Czech Tech Univ, Prague, Czech Republic.; Zhang, L (corresponding author), Univ Innsbruck, Innsbruck, Austria.
RI Kaliszyk, Cezary/H-8791-2016
OI Kaliszyk, Cezary/0000-0002-8273-6059
FU ERCEuropean Research Council (ERC)European Commission [714034 SMART];
   European Regional Development Fund under the project AIReasoning
   [CZ.02.1.01/0.0/0.0/15 003/0000466]; Ministry of Education, Youth and
   Sports within the dedicated program ERC CZ under the project POSTMAN
   [LL1902]
FX This work was supported by the ERC grant no. 714034 SMART, by the
   European Regional Development Fund under the project AI&Reasoning (reg.
   no. CZ.02.1.01/0.0/0.0/15 003/0000466), and by the Ministry of
   Education, Youth and Sports within the dedicated program ERC CZ under
   the project POSTMAN no. LL1902.
NR 27
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-81097-9; 978-3-030-81096-2
J9 LECT NOTES ARTIF INT
PY 2021
VL 12833
BP 67
EP 83
DI 10.1007/978-3-030-81097-9_5
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods; Mathematics, Applied; Logic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Mathematics; Science & Technology - Other Topics
GA BS2VL
UT WOS:000707054900005
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Tseng, HH
   Wei, LS
   Cu, SN
   Luo, Y
   Ten Haken, RK
   El Naqa, I
AF Tseng, Huan-Hsin
   Wei, Lise
   Cu, Sunan
   Luo, Yi
   Ten Haken, Randall K.
   El Naqa, Issam
TI Machine Learning and Imaging Informatics in Oncology
SO ONCOLOGY
LA English
DT Review
DE Oncology; Machine learning; Imaging informatics
ID TEXTURAL FEATURES; CANCER; VALIDATION; REGRESSION
AB In the era of personalized and precision medicine, informatics technologies utilizing machine learning (ML) and quantitative imaging are witnessing a rapidly increasing role in medicine in general and in oncology in particular. This expanding role ranges from computer-aided diagnosis to decision support of treatments with the potential to transform the current landscape of cancer management. In this review, we aim to provide an overview of ML methodologies and imaging informatics techniques and their recent application in modern oncology. We will review example applications of ML in oncology from the literature, identify current challenges and highlight future potentials.
C1 [Tseng, Huan-Hsin; Wei, Lise; Cu, Sunan; Luo, Yi; Ten Haken, Randall K.; El Naqa, Issam] Univ Michigan, Dept Radiat Oncol, 519W William St, Ann Arbor, MI 48103 USA.
RP El Naqa, I (corresponding author), Univ Michigan, Dept Radiat Oncol, 519W William St, Ann Arbor, MI 48103 USA.
EM ielnaqa@med.umich.edu
RI Naqa, Issam El/T-3066-2019; cui, sunan/AAA-3286-2020
OI Naqa, Issam El/0000-0001-6023-1132; cui, sunan/0000-0002-8846-9449
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [P01 CA059827];
   NATIONAL CANCER INSTITUTEUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Cancer
   Institute (NCI) [P01CA059827, R37CA222215] Funding Source: NIH RePORTER
FX This work was supported in part by the National Institutes of Health P01
   CA059827.
NR 69
TC 21
Z9 21
U1 2
U2 16
PU KARGER
PI BASEL
PA ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND
SN 0030-2414
EI 1423-0232
J9 ONCOLOGY-BASEL
JI Oncology
PD JUN
PY 2020
VL 98
IS 6
BP 344
EP 362
DI 10.1159/000493575
PG 19
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA MC8QK
UT WOS:000543544000005
PM 30472716
OA Green Accepted, hybrid
DA 2022-04-17
ER

PT C
AU Torres, JA
   Kissiov, I
   Essam, M
   Hartig, C
   Gardner, R
   Jantzen, K
   Schueler, S
   Niehoff, M
AF Torres, J. Andres
   Kissiov, Ivan
   Essam, Mohamed
   Hartig, Carsten
   Gardner, Richard
   Jantzen, Ken
   Schueler, Stefan
   Niehoff, Martin
GP IEEE
TI Machine Learning Assisted New Product Setup
SO 2020 31ST ANNUAL SEMI ADVANCED SEMICONDUCTOR MANUFACTURING CONFERENCE
   (ASMC)
SE Advanced Semiconductor Manufacturing Conference and Workshop-Proceedings
LA English
DT Proceedings Paper
CT 31st Annual SEMI Advanced Semiconductor Manufacturing Conference (ASMC)
CY AUG 24-26, 2020
CL Saratoga Springs, NY
SP SEMI
DE Yield Methodologies; machine learning
AB In the past, concepts like critical area analysis, have been successfully implemented to predict random and systematic layout induced effects. This has enabled semiconductor companies to have an initial estimate as to how a fixed process will respond to a variety of different designs. However, as the number of individual products increases, along with a reduction in the total number of wafers per product, it becomes increasingly difficult to determine which process parameters will lead to the highest possible yield for each individual product. We have outlined a methodology using machine learning that combines process and design data to greatly reduce the time needed for setting up new products. We have shown that similar designs (based on our feature extraction) behave similarly in the fab, thus allowing us to construct models that can eventually be used to find the optimal process conditions for a given design. Due to the nature or process optimization, this methodology also explores the use of SHAPley additive explanations (SHAP) in order to "interface" with existing human and physical explanations of the observations, thus providing a mechanism to assess the quality and reliability of the numerically derived models.
C1 [Torres, J. Andres] Mentor, Design Silicon, Wilsonville, OR 97070 USA.
   [Kissiov, Ivan] Mentor, Design Silicon, Fremont, CA USA.
   [Essam, Mohamed; Jantzen, Ken] Mentor, WW Foundry Semi Solut, Austin, TX USA.
   [Hartig, Carsten] GLOBALFOUNDRIES, Integrat & Yield, Dresden, Germany.
   [Gardner, Richard] Mentor, Strateg Accounts, Wilsonville, OR USA.
   [Schueler, Stefan] GLOBALFOUNDRIES, Global Tapeout Operat, Dresden, Germany.
   [Niehoff, Martin] Mentor, WW Foundry Semi Solut, Dresden, Germany.
RP Torres, JA (corresponding author), Mentor, Design Silicon, Wilsonville, OR 97070 USA.
EM andres_torres@mentor.com; ivan_kissiov@mentor.com;
   Mohamed_Essam@mentor.com; earsten.hartig@globalfoundries.com;
   richard_gardner@mentor.com; Ken_Jantzen@mentor.com;
   stefan.schueler@globalfoundries.com; Martin_Niehoff@mentor.com
OI E.Mohammed, Mohammed/0000-0001-7808-4548
FU ECSEL Joint Undertaking (JU) [826589]; European UnionEuropean Commission
FX Part of the work presented in this project has received funding from the
   ECSEL Joint Undertaking (JU) under grant agreement No 826589. The JU
   receives support from the European Union's Horizon 2020 research and
   innovation programme and Netherlands, Belgium, Germany, France, Italy,
   Austria, Hungary, Romania, Sweden and Israel
NR 3
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1078-8743
BN 978-1-7281-5876-1
J9 ASMC PROC
PY 2020
PG 5
WC Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering
GA BR1EI
UT WOS:000631799000010
DA 2022-04-17
ER

PT J
AU Wang, M
   Wang, T
   Luo, YF
   He, K
   Pan, L
   Li, Z
   Cui, ZQ
   Liu, ZH
   Tu, JQ
   Chen, XD
AF Wang, Ming
   Wang, Ting
   Luo, Yifei
   He, Ke
   Pan, Liang
   Li, Zheng
   Cui, Zequn
   Liu, Zhihua
   Tu, Jiaqi
   Chen, Xiaodong
TI Fusing Stretchable Sensing Technology with Machine Learning for
   Human-Machine Interfaces
SO ADVANCED FUNCTIONAL MATERIALS
LA English
DT Review
DE artificial intelligence; electronic skin; human&#8211; machine
   interfaces; machine learning; stretchable sensors
AB Sensors and algorithms are two fundamental elements to construct intelligent systems. The recent progress in machine learning (ML) has produced great advancements in intelligent systems, owing to the powerful data analysis capability of ML algorithms. However, the performance of most systems is still hindered by sensing techniques that typically rely on rigid and bulky sensor devices, which cannot conform to irregularly curved and dynamic surfaces for high-quality data acquisition. Skin-like stretchable sensing technology with unique characteristics, such as high conformability, low modulus, and light weight, has been recently developed to solve this issue. Here, the recent progress in the fusion of emerging stretchable electronics and ML technology, for bioelectrical signal recognition, tactile perception, and multimodal integration is summarized, and the challenges and future developments are further discussed. These efforts aim to accelerate various perception and reasoning tasks for advanced intelligent applications, such as human-machine interfaces, healthcare, and robotics.
C1 [Wang, Ming; Wang, Ting; Luo, Yifei; He, Ke; Pan, Liang; Li, Zheng; Cui, Zequn; Liu, Zhihua; Tu, Jiaqi; Chen, Xiaodong] Nanyang Technol Univ, Sch Mat Sci & Engn, Max Planck NTU Joint Lab Artificial Senses, Innovat Ctr Flexible Devices iFLEX, 50 Nanyang Ave, Singapore 639798, Singapore.
   [Tu, Jiaqi] Inst Flexible Elect Technol THU, Jiaxing 314000, Zhejiang, Peoples R China.
RP Chen, XD (corresponding author), Nanyang Technol Univ, Sch Mat Sci & Engn, Max Planck NTU Joint Lab Artificial Senses, Innovat Ctr Flexible Devices iFLEX, 50 Nanyang Ave, Singapore 639798, Singapore.
EM chenxd@ntu.edu.sg
RI Chen, Xiaodong/A-4537-2009; Luo, Yifei/AAU-4334-2021
OI Chen, Xiaodong/0000-0002-3312-1664; Luo, Yifei/0000-0002-4454-6318; Cui,
   Zequn/0000-0002-4389-4214
FU Agency for Science, Technology and Research (A*STAR) under its AME
   Programmatic Funding Scheme for the Project of Cyber-Physiochemical
   Interfaces [A18A1b0045]; Singapore Ministry of EducationMinistry of
   Education, Singapore [MOE2017-T2-2-107, MOE2019-T2-2-022]; National
   Research Foundation (NRF), Prime Minister's office, Singapore, under its
   NRF InvestigatorshipNational Research Foundation, Singapore
   [NRF-NRFI2017-07]
FX The authors thank the financial support from the Agency for Science,
   Technology and Research (A*STAR) under its AME Programmatic Funding
   Scheme for the Project of Cyber-Physiochemical Interfaces (Project
   #A18A1b0045), Singapore Ministry of Education (MOE2017-T2-2-107 and
   MOE2019-T2-2-022), and the National Research Foundation (NRF), Prime
   Minister's office, Singapore, under its NRF Investigatorship
   (NRF-NRFI2017-07).
NR 132
TC 11
Z9 11
U1 52
U2 123
PU WILEY-V C H VERLAG GMBH
PI WEINHEIM
PA POSTFACH 101161, 69451 WEINHEIM, GERMANY
SN 1616-301X
EI 1616-3028
J9 ADV FUNCT MATER
JI Adv. Funct. Mater.
PD SEP
PY 2021
VL 31
IS 39
SI SI
AR 2008807
DI 10.1002/adfm.202008807
EA MAR 2021
PG 13
WC Chemistry, Multidisciplinary; Chemistry, Physical; Nanoscience &
   Nanotechnology; Materials Science, Multidisciplinary; Physics, Applied;
   Physics, Condensed Matter
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Science & Technology - Other Topics; Materials Science;
   Physics
GA UU2WC
UT WOS:000630216300001
DA 2022-04-17
ER

PT J
AU Zhao, TH
   Wang, MH
   Zhou, B
AF Zhao, Tian-Hui
   Wang, Ming-Hao
   Zhou, Bin
TI Optimal quantum state transformations based on machine learning
SO QUANTUM INFORMATION PROCESSING
LA English
DT Article
DE Quantum state transformation; Machine learning; Quantum cloning
ID CLONING; INFORMATION; CANNOT
AB It is well known that quantum algorithms may solve problems efficiently that are intractable using conventional algorithms. Quantum algorithms can be designed with a set of universal quantum gates that transform input states into desired output states. However, designing quantum algorithms that transform states in desired ways is challenging due to its complexity. In this paper, we propose a machine learning framework for the transformation of unknown states into their corresponding target states. Specifically, a parameterized quantum circuit learns a given task by tuning its parameters. After the learning is done, the circuit is competent for the quantum task. This allows us to circumvent cumbersome circuit design based on universal quantum gates. If perfect transformation is forbidden by quantum theory, an optimal transformation can be obtained in terms of fidelity. This provides a research method to study various quantum no-go theorems that characterize the intrinsic gap between quantum and classical information. As examples, quantum state rotation and quantum state cloning are studied using numerical simulations. We also show the good robustness of our machine learning framework to corrupted training data, which is a very nice property for physical implementation on near-term noisy intermediate-scale quantum devices.
C1 [Zhao, Tian-Hui; Wang, Ming-Hao; Zhou, Bin] Hubei Univ, Dept Phys, Wuhan 430062, Peoples R China.
RP Wang, MH (corresponding author), Hubei Univ, Dept Phys, Wuhan 430062, Peoples R China.
EM wangmh@hubu.edu.cn; binzhou@hubu.edu.cn
OI wang, ming hao/0000-0003-2491-2330
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [12074107]; Natural Science Foundation of
   Hubei Province of ChinaNatural Science Foundation of Hubei Province
   [2020CFB263]; program for outstanding young and middle-aged scientific
   and technological innovation team of colleges and universities in Hubei
   Province [T2020001]
FX This work was supported by the National Natural Science Foundation of
   China (under Grant No. 12074107), Natural Science Foundation of Hubei
   Province of China (under Grant No. 2020CFB263), and the program for
   outstanding young and middle-aged scientific and technological
   innovation team of colleges and universities in Hubei Province (under
   Grant No. T2020001).
NR 47
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1570-0755
EI 1573-1332
J9 QUANTUM INF PROCESS
JI Quantum Inf. Process.
PD JUN
PY 2021
VL 20
IS 6
AR 212
DI 10.1007/s11128-021-03148-3
PG 18
WC Quantum Science & Technology; Physics, Multidisciplinary; Physics,
   Mathematical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Physics
GA SU7SQ
UT WOS:000663332700001
DA 2022-04-17
ER

PT J
AU Cuocolo, R
   Caruso, M
   Perillo, T
   Ugga, L
   Petretta, M
AF Cuocolo, Renato
   Caruso, Martina
   Perillo, Teresa
   Ugga, Lorenzo
   Petretta, Mario
TI Machine Learning in oncology: A clinical appraisal
SO CANCER LETTERS
LA English
DT Review
DE Machine learning; Artificial intelligence; Deep learning; Radiogenomics;
   Precision oncology
ID ARTIFICIAL-INTELLIGENCE; NEURAL-NETWORK; BREAST-CANCER; SURVIVAL; MRI;
   CLASSIFICATION; PREDICTION; MEDICINE; FEATURES; IMAGES
AB Machine learning (ML) is a branch of artificial intelligence centered on algorithms which do not need explicit prior programming to function but automatically learn from available data, creating decision models to complete tasks. ML-based tools have numerous promising applications in several fields of medicine. Its use has grown following the increased availability of patient data due to technological advances such as digital health records and high-volume information extraction from medical images. Multiple ML algorithms have been proposed for applications in oncology. For instance, they have been employed for oncological risk assessment, automated segmentation, lesion detection, characterization, grading and staging, prediction of prognosis and therapy response.
   In the near future, ML could become essential part of every step of oncological screening strategies and patients' management thus leading to precision medicine.
C1 [Cuocolo, Renato; Caruso, Martina; Perillo, Teresa; Ugga, Lorenzo] Univ Naples Federico II, Dept Adv Biomed Sci, Via S Pansini 5, I-80131 Naples, Italy.
   [Petretta, Mario] Univ Naples Federico II, Dept Translat Med Sci, Via S Pansini 5, I-80131 Naples, Italy.
RP Perillo, T (corresponding author), Univ Naples Federico II, Dept Adv Biomed Sci, Via S Pansini 5, I-80131 Naples, Italy.
EM tperillo3@gmail.com
RI Cuocolo, Renato/G-3147-2018; Ugga, Lorenzo/AAI-2644-2019
OI Cuocolo, Renato/0000-0002-1452-1574; Ugga, Lorenzo/0000-0001-7811-4612;
   Perillo, Teresa/0000-0002-3840-7637
NR 89
TC 32
Z9 32
U1 6
U2 49
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0304-3835
EI 1872-7980
J9 CANCER LETT
JI Cancer Lett.
PD JUL 1
PY 2020
VL 481
BP 55
EP 62
DI 10.1016/j.canlet.2020.03.032
PG 8
WC Oncology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Oncology
GA LG7QS
UT WOS:000528291300006
PM 32251707
DA 2022-04-17
ER

PT J
AU Zheng, LK
   Xiang, Y
   Sheng, CX
AF Zheng, Longkui
   Xiang, Yang
   Sheng, Chenxing
TI Multi-feature learning-based extreme learning machine for rolling
   bearing fault diagnosis
SO PROCEEDINGS OF THE INSTITUTION OF MECHANICAL ENGINEERS PART O-JOURNAL OF
   RISK AND RELIABILITY
LA English
DT Article; Early Access
DE Multi-feature learning; extreme learning machine; fault diagnosis;
   experience pool; rolling bearing
ID NEURAL-NETWORK; CLASSIFICATION; PACKET
AB Rolling bearing has been becoming an important part of human life and work. The working environment of rolling bearing is very complex and variable, which makes it difficult for fault diagnosis and monitor of rolling bearing from raw vibration data. Then, in this paper, a novel multi-feature learning-based extreme learning machine is proposed for rolling bearing fault diagnosis (FL-ELM). Extreme learning machine (ELM) is a fast and generalized algorithm proposed for training single-hidden-layer feed-forward networks (SLFNs), which has fast computing speed and small testing error. The novel architecture has two hidden layers and an experience pool sandwiched between two hidden layers. The first hidden layer consists of multi-feature learning methods. The experience pool is used to sort and choose new data, with old data being filtered out. Firstly, the first hidden layer is adopted for feature extraction. Secondly, the experience pool is used to rearrange and select data, which is extracted by first hidden layer. Thirdly, ELM is employed to further learn and classify. The proposed method (FL-ELM) is applied to the rolling bearing fault diagnosis. The results confirm that the proposed method is more effective than traditional methods and standard deep learning methods.
C1 [Zheng, Longkui; Xiang, Yang; Sheng, Chenxing] Wuhan Univ Technol, Sch Energy & Power Engn, Wuhan, Peoples R China.
   [Zheng, Longkui; Xiang, Yang] Minist Commun, Key Lab Marine Power Engn & Technol, Wuhan, Peoples R China.
RP Xiang, Y (corresponding author), Wuhan Univ Technol, 1178 Heping Ave, Wuhan 430000, Peoples R China.
EM yxiang@whut.edu.cn
FU NSFC-Zhejiang Joint Found for the Integration of Industrialization and
   informatization [U1709215]; National Natural Science Foundation of
   ChinaNational Natural Science Foundation of China (NSFC) [51079118,
   51279148]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   was supported by the NSFC-Zhejiang Joint Found for the Integration of
   Industrialization and informatization (project nos. U1709215), and the
   National Natural Science Foundation of China (project nos. 51079118 and
   51279148).
NR 38
TC 0
Z9 0
U1 16
U2 16
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1748-006X
EI 1748-0078
J9 P I MECH ENG O-J RIS
JI Proc. Inst. Mech. Eng. Part O-J. Risk Reliab.
AR 1748006X211048585
DI 10.1177/1748006X211048585
EA OCT 2021
PG 17
WC Engineering, Multidisciplinary; Engineering, Industrial; Operations
   Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Operations Research & Management Science
GA WE6AQ
UT WOS:000705706400001
DA 2022-04-17
ER

PT J
AU De Santana, PM
AF De Santana, Pedro Maia
TI RF-Based Machine Learning Solution for Indoor Person Detection
SO INTERNATIONAL JOURNAL OF INTERDISCIPLINARY TELECOMMUNICATIONS AND
   NETWORKING
LA English
DT Article
DE Entropy; Feature Mapping; Human Detection; Machine Learning; RF; SDR;
   Supervised Learning; USRP
AB Machine learning techniques applied to radio frequency (RF) signals are used for many applications in addition to data communication. In this paper, the authors propose a machine learning solution for classifying the number of people within an indoor ambient. The main idea is to identify a pattern of received signal characteristics according to the number of people. Experimental measurements are performed using a software-defined radio platform inside a laboratory. The data collected is postprocessed by applying a feature mapping technique based on mean, standard deviation, and Shannon information entropy. This feature-space data is then used to train a supervised machine learning network for classifying scenarios with zero, one, two, and three people inside. The proposed solution presents significant accuracy in classification performance.
C1 [De Santana, Pedro Maia] Samsung SIDIA, Sao Paulo, Brazil.
RP De Santana, PM (corresponding author), Samsung SIDIA, Sao Paulo, Brazil.
RI Sousa, Vicente/R-6972-2019
OI Sousa, Vicente/0000-0003-2859-6136
NR 15
TC 0
Z9 0
U1 0
U2 0
PU IGI GLOBAL
PI HERSHEY
PA 701 E CHOCOLATE AVE, STE 200, HERSHEY, PA 17033-1240 USA
SN 1941-8663
EI 1941-8671
J9 INT J INTERDISCIP TE
JI Int. J. Interdiscip. Telecommun. Netw.
PD APR-JUN
PY 2021
VL 13
IS 2
BP 42
EP 50
DI 10.4018/IJITN.2021040104
PG 9
WC Telecommunications
WE Emerging Sources Citation Index (ESCI)
SC Telecommunications
GA RG1EL
UT WOS:000635277400004
DA 2022-04-17
ER

PT C
AU Wu, N
   Farokhi, F
   Smith, D
   Kaafar, MA
AF Wu, Nan
   Farokhi, Farhad
   Smith, David
   Kaafar, Mohamed Ali
GP IEEE
TI The Value of Collaboration in Convex Machine Learning with Differential
   Privacy
SO 2020 IEEE SYMPOSIUM ON SECURITY AND PRIVACY (SP 2020)
SE IEEE Symposium on Security and Privacy
LA English
DT Proceedings Paper
CT 41st IEEE Symposium on Security and Privacy (SP)
CY MAY 18-21, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc
DE Machine learning; Differential privacy; Stochastic gradient algorithm
ID REGRESSION
AB In this paper, we apply machine learning to distributed private data owned by multiple data owners, entities with access to non-overlapping training datasets. We use noisy, differentially-private gradients to minimize the fitness cost of the machine learning model using stochastic gradient descent. We quantify the quality of the trained model, using the fitness cost, as a function of privacy budget and size of the distributed datasets to capture the trade-off between privacy and utility in machine learning. This way, we can predict the outcome of collaboration among privacy-aware data owners prior to executing potentially computationally-expensive machine learning algorithms. Particularly, we show that the difference between the fitness of the trained machine learning model using differentially-private gradient queries and the fitness of the trained machine model in the absence of any privacy concerns is inversely proportional to the size of the training datasets squared and the privacy budget squared. We successfully validate the performance prediction with the actual performance of the proposed privacy-aware learning algorithms, applied to: financial datasets for determining interest rates of loans using regression; and detecting credit card frauds using support vector machines.
C1 [Wu, Nan; Kaafar, Mohamed Ali] Macquarie Univ, N Ryde, NSW, Australia.
   [Farokhi, Farhad; Smith, David; Kaafar, Mohamed Ali] CSIRO, Data61, Canberra, ACT, Australia.
   [Farokhi, Farhad] Univ Melbourne, Melbourne, Vic 3010, Australia.
   [Smith, David] Australian Natl Univ, Canberra, ACT, Australia.
RP Wu, N (corresponding author), Macquarie Univ, N Ryde, NSW, Australia.
RI Farokhi, Farhad/M-2683-2018
OI Farokhi, Farhad/0000-0002-5102-7073; Kaafar, Mohamed
   Ali/0000-0003-2714-0276
FU "Data Privacy in AI Platforms (DPAIP): Risks Quantification and Defence
   Apparatus" project from the Next Generation Technologies Fund by the
   Defence Science and Technology (DST) in the Australian Department of
   Defence; DataRing project - NSW Cyber Security Network; Singtel Optus
   pty ltd through the Optus Macquarie University Cyber Security Hub
FX We would like to thank Nicolas Papernot for shepherding our paper. His
   comments and suggestions greatly helped in improving the paper. The work
   has been funded, in part, by the "Data Privacy in AI Platforms (DPAIP):
   Risks Quantification and Defence Apparatus" project from the Next
   Generation Technologies Fund by the Defence Science and Technology (DST)
   in the Australian Department of Defence and the DataRing project funded
   by the NSW Cyber Security Network and Singtel Optus pty ltd through the
   Optus Macquarie University Cyber Security Hub.
NR 34
TC 8
Z9 8
U1 9
U2 17
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
SN 1081-6011
BN 978-1-7281-3497-0
J9 P IEEE S SECUR PRIV
PY 2020
BP 304
EP 317
DI 10.1109/SP40000.2020.00025
PG 14
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BQ7OO
UT WOS:000618063500019
OA Green Submitted, Bronze, Green Accepted
DA 2022-04-17
ER

PT J
AU Nakagawa, PI
   Pires, LF
   Moreira, JLR
   Santos, LOBD
   Bukhsh, F
AF Nakagawa, Patricia Inoue
   Pires, Luis Ferreira
   Moreira, Joao Luiz Rebelo
   Santos, Luiz Olavo Bonino da Silva
   Bukhsh, Faiza
TI Semantic Description of Explainable Machine Learning Workflows for
   Improving Trust
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE XAI; machine learning; semantic web technologies; ontology
AB Explainable Machine Learning comprises methods and techniques that enable users to better understand the machine learning functioning and results. This work proposes an ontology that represents explainable machine learning experiments, allowing data scientists and developers to have a holistic view, a better understanding of the explainable machine learning process, and to build trust. We developed the ontology by reusing an existing domain-specific ontology (ML-SCHEMA) and grounding it in the Unified Foundational Ontology (UFO), aiming at achieving interoperability. The proposed ontology is structured in three modules: (1) the general module, (2) the specific module, and (3) the explanation module. The ontology was evaluated using a case study in the scenario of the COVID-19 pandemic using healthcare data from patients, which are sensitive data. In the case study, we trained a Support Vector Machine to predict mortality of patients infected with COVID-19 and applied existing explanation methods to generate explanations from the trained model. Based on the case study, we populated the ontology and queried it to ensure that it fulfills its intended purpose and to demonstrate its suitability.
C1 [Nakagawa, Patricia Inoue; Pires, Luis Ferreira; Moreira, Joao Luiz Rebelo; Santos, Luiz Olavo Bonino da Silva; Bukhsh, Faiza] Univ Twente, Fac Elect Engn Math & Comp Sci EEMCS, NL-7522 NB Enschede, Netherlands.
RP Nakagawa, PI (corresponding author), Univ Twente, Fac Elect Engn Math & Comp Sci EEMCS, NL-7522 NB Enschede, Netherlands.
EM patyinoue@gmail.com; l.ferreirapires@utwente.nl;
   j.luizrebelomoreira@utwente.nl; l.o.boninodasilvasantos@utwente.nl;
   f.a.bukhsh@utwente.nl
OI Ferreira Pires, Luis/0000-0001-7432-7653; Moreira,
   Joao/0000-0002-4547-7000; Bonino da Silva Santos, Luiz
   Olavo/0000-0002-1164-1351
FU Orange Tulip Scholarship
FX The author (P. I. Nakagawa) was supported by the Orange Tulip
   Scholarship to fund its master studies.
NR 34
TC 0
Z9 0
U1 1
U2 1
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD NOV
PY 2021
VL 11
IS 22
AR 10804
DI 10.3390/app112210804
PG 18
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Materials Science; Physics
GA XG5UU
UT WOS:000724818600001
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Ji, M
   Hu, SK
   Zhang, Y
   Cheng, TCE
   Jiang, YW
AF Ji, Min
   Hu, Shengkai
   Zhang, Yuan
   Cheng, T. C. E.
   Jiang, Yiwei
TI Parallel-machine scheduling with identical machine resource capacity
   limits and DeJong's learning effect
SO INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH
LA English
DT Article; Early Access
DE Parallel machine; scheduling; resource consumption; machine resource
   capacity; DeJong&#8217; s learning effect; approximation algorithm
ID TIME
AB We consider parallel-machine scheduling with identical machine resource capacity limits and DeJong's learning effect. Each job has a resource consumption requirement and a normal processing time. The actual processing time of a job is a function of its normal processing time, subject to DeJong's learning effect, while the resource consumption of a job is a function of its actual processing time. Each machine has the same resource capacity limit. The objective is to maximise the minimum machine load. Considering three resource consumption functions, namely, linear, concave, and convex, we show that all three scheduling models are NP-hard and propose two approximation algorithms for the models and analyse their worst-case ratios.
C1 [Ji, Min; Hu, Shengkai; Zhang, Yuan; Jiang, Yiwei] Zhejiang Gongshang Univ, Contemporary Business & Trade Res Ctr, Sch Management & E Business, Hangzhou 310018, Peoples R China.
   [Cheng, T. C. E.] Hong Kong Polytech Univ, Dept Logist & Maritime Studies, Kowloon, Hong Kong, Peoples R China.
RP Jiang, YW (corresponding author), Zhejiang Gongshang Univ, Contemporary Business & Trade Res Ctr, Sch Management & E Business, Hangzhou 310018, Peoples R China.
EM ywjiang@zjgsu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [11971434]; Zhejiang Provincial Natural
   Science Foundation of ChinaNatural Science Foundation of Zhejiang
   Province [LY21G010002]; Contemporary Business and Trade Research Center
   of Zhejiang Gongshang University, keyResearch Institute of Social
   Sciences andHumanities of the Ministry of Education of China; Hong Kong
   PolytechnicUniversity under the Fung Yiu King-Wing Hang Bank Endowed
   Professorship in Business Administration
FX This research was supported in part by the National Natural Science
   Foundation of China [Grant number 11971434], Zhejiang Provincial Natural
   Science Foundation of China [Grant number LY21G010002], and the
   Contemporary Business and Trade Research Center of Zhejiang Gongshang
   University, which is a keyResearch Institute of Social Sciences
   andHumanities of the Ministry of Education of China. Cheng was supported
   in part by TheHong Kong PolytechnicUniversity under the Fung Yiu
   King-Wing Hang Bank Endowed Professorship in Business Administration.
NR 26
TC 1
Z9 1
U1 6
U2 15
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0020-7543
EI 1366-588X
J9 INT J PROD RES
JI Int. J. Prod. Res.
DI 10.1080/00207543.2021.1902011
EA MAR 2021
PG 13
WC Engineering, Industrial; Engineering, Manufacturing; Operations Research
   & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Operations Research & Management Science
GA RF7LG
UT WOS:000635021100001
DA 2022-04-17
ER

PT J
AU Ostberg, NP
   Zafar, MA
   Elefteriades, JA
AF Ostberg, Nicolai P.
   Zafar, Mohammad A.
   Elefteriades, John A.
TI Machine learning: principles and applications for thoracic surgery
SO EUROPEAN JOURNAL OF CARDIO-THORACIC SURGERY
LA English
DT Review
DE Machine learning; Supervised learning; Deep learning; Predictive models;
   Prognostication
ID HEALTH-CARE; DISSECTION
AB OBJECTIVES: Machine learning (ML) has experienced a revolutionary decade with advances across many disciplines. We seek to understand how recent advances in ML are going to specifically influence the practice of surgery in the future with a particular focus on thoracic surgery.
   METHODS: Review of relevant literature in both technical and clinical domains.
   RESULTS: ML is a revolutionary technology that promises to change the way that surgery is practiced in the near future. Spurred by an advance in computing power and the volume of data produced in healthcare, ML has shown remarkable ability to master tasks that had once been reserved for physicians. Supervised learning, unsupervised learning and reinforcement learning are all important techniques that can be leveraged to improve care. Five key applications of ML to cardiac surgery include diagnostics, surgical skill assessment, postoperative prognostication, augmenting intraoperative performance and accelerating translational research. Some key limitations of ML include lack of interpretability, low quality and volumes of relevant clinical data, ethical limitations and difficulties with clinical implementation.
   CONCLUSIONS: In the future, the practice of cardiac surgery will be greatly augmented by ML technologies, ultimately leading to improved surgical performance and better patient outcomes.
C1 [Ostberg, Nicolai P.; Zafar, Mohammad A.; Elefteriades, John A.] Yale Univ, Yale New Haven Hosp, Sch Med, Aort Inst, New Haven, CT 06519 USA.
   [Ostberg, Nicolai P.] NYU, Grossman Sch Med, New York, NY USA.
RP Elefteriades, JA (corresponding author), Yale Univ, Aort Inst Yale New Haven, Sch Med, Clin Bldg CB 317,789 Howard Ave, New Haven, CT 06519 USA.
EM john.elefteriades@yale.edu
RI Zafar, Mohammad Abdullah/ABB-5091-2021
OI Zafar, Mohammad Abdullah/0000-0003-1666-199X; Ostberg,
   Nicolai/0000-0002-8223-4585
NR 42
TC 5
Z9 5
U1 0
U2 0
PU OXFORD UNIV PRESS INC
PI CARY
PA JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA
SN 1010-7940
EI 1873-734X
J9 EUR J CARDIO-THORAC
JI Eur. J. Cardio-Thorac. Surg.
PD AUG
PY 2021
VL 60
IS 2
BP 213
EP 221
DI 10.1093/ejcts/ezab095
EA MAR 2021
PG 9
WC Cardiac & Cardiovascular Systems; Respiratory System; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Cardiovascular System & Cardiology; Respiratory System; Surgery
GA XS0ML
UT WOS:000732612500002
PM 33748840
OA Bronze
DA 2022-04-17
ER

PT J
AU Bodenhofer, U
   Haslinger-Eisterer, B
   Minichmayer, A
   Hermanutz, G
   Meier, J
AF Bodenhofer, Ulrich
   Haslinger-Eisterer, Bettina
   Minichmayer, Alexander
   Hermanutz, Georg
   Meier, Jens
TI Machine learning-based risk profile classification of patients
   undergoing elective heart valve surgery
SO EUROPEAN JOURNAL OF CARDIO-THORACIC SURGERY
LA English
DT Article
DE heart valve surgery; machine learning; random forest; support vector
   machine
ID CARDIAC-SURGERY; EUROSCORE II; MORTALITY; MODELS; STRATIFICATION;
   SUPERIOR; SOCIETY; CANCER; SCORE
AB OBJECTIVES: Machine learning methods potentially provide a highly accurate and detailed assessment of expected individual patient risk before elective cardiac surgery. Correct anticipation of this risk allows for the improved counselling of patients and avoidance of possible complications. We therefore investigated the benefit of modern machine learning methods in personalized risk prediction for patients undergoing elective heart valve surgery.
   METHODS: We performed a monocentric retrospective study in patients who underwent elective heart valve surgery between 1 January 2008 and 31 December 2014 at our centre. We used random forests, artificial neural networks and support vector machines to predict the 30-day mortality from a subset of 129 available demographic and preoperative parameters. Exclusion criteria were reoperation of the same patient, patients who needed anterograde cerebral perfusion due to aortic arch surgery and patients with grown-up congenital heart disease. Finally, the cohort consisted of 2229 patients with a 30-day mortality of 3.86% (86 of 2229 cases). This trial has been registered at clinicaltrials.gov (NCT03724123).
   RESULTS: The final random forest model trained on the entire data set provided an out-of-bag area under the receiver operator characteristics curve (AUC) of 0.839, which significantly outperformed the European System for Cardiac Operative Risk Evaluation (EuroSCORE) (AUC = 0.704) and a model trained only on the subset of features EuroSCORE uses (AUC = 0.745).
   CONCLUSIONS: Advanced machine learning methods can predict outcomes of valve surgery procedures with higher accuracy than established risk scores based on logistic regression on pre-selected parameters. This approach is generalizable to other elective high-risk interventions and allows for training models to the cohorts of specific institutions
C1 [Bodenhofer, Ulrich] Univ Appl Sci Upper Austria, Sch Informat Commun & Media, Hagenberg, Austria.
   [Bodenhofer, Ulrich; Hermanutz, Georg] Johannes Kepler Univ Linz, Inst Machine Learning, Linz, Austria.
   [Haslinger-Eisterer, Bettina; Minichmayer, Alexander; Meier, Jens] Kepler Univ Linz, Kepler Univ Clin, Inst Anesthesiol & Crit Care Med, Linz, Austria.
RP Meier, J (corresponding author), Johannes Kepler Univ Linz, Kepler Univ Clin, Dept Anesthesiol & Crit Care, Altenberger Str 69, A-4040 Linz, Austria.
EM jens.meier@kepleruniklinikum.at
OI Bodenhofer, Ulrich/0000-0001-6859-8828
NR 30
TC 1
Z9 1
U1 0
U2 0
PU OXFORD UNIV PRESS INC
PI CARY
PA JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA
SN 1010-7940
EI 1873-734X
J9 EUR J CARDIO-THORAC
JI Eur. J. Cardio-Thorac. Surg.
PD DEC
PY 2021
VL 60
IS 6
BP 1378
EP 1385
DI 10.1093/ejcts/ezab219
EA MAY 2021
PG 8
WC Cardiac & Cardiovascular Systems; Respiratory System; Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Cardiovascular System & Cardiology; Respiratory System; Surgery
GA YI0OV
UT WOS:000743557800024
PM 34050368
OA Bronze
DA 2022-04-17
ER

PT J
AU Sakaguchi, K
   Ohsaki, M
   Kimura, T
AF Sakaguchi, Kazuma
   Ohsaki, Makoto
   Kimura, Toshiaki
TI Machine Learning for Extracting Features of Approximate Optimal Brace
   Locations for Steel Frames
SO FRONTIERS IN BUILT ENVIRONMENT
LA English
DT Article
DE machine learning; steel frame; brace; optimal location; support vector
   machine
ID SUPPORT VECTOR MACHINE; NEURAL-NETWORK; TOPOLOGY OPTIMIZATION;
   PREDICTION; PLACEMENT
AB A method is presented for extracting features of approximate optimal brace types and locations for large-scale steel building frames. The frame is subjected to static seismic loads, and the maximum stress in the frame members is minimized under constraints on the number of braces in each story and the maximum interstory drift angle. A new formulation is presented for extracting important features of brace types and locations from the machine learning results using a support vector machine with radial basis function kernel. A nonlinear programming problem is to be solved for finding the optimal values of the components of the matrix for condensing the features of a large-scale frame to those of a small-scale frame so that the important features of the large-scale frame can be extracted from the machine learning results of the small-scale frame. It is shown in the numerical examples that the important features of a 24-story frame are successfully extracted using the machine learning results of a 12-story frame.
C1 [Sakaguchi, Kazuma; Ohsaki, Makoto] Kyoto Univ, Dept Architecture & Architectural Engn, Kyoto, Japan.
   [Kimura, Toshiaki] Nagoya City Univ, Grad Sch Design & Architecture, Nagoya, Aichi, Japan.
RP Ohsaki, M (corresponding author), Kyoto Univ, Dept Architecture & Architectural Engn, Kyoto, Japan.
EM ohsaki@archi.kyoto-u.ac.jp
RI Ohsaki, Makoto/E-2021-2011
OI Ohsaki, Makoto/0000-0003-4935-8874
FU JSPS KAKENHIMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) [JP18K18898,
   JP20H04467]
FX This study is partly supported by JSPS KAKENHI No. JP18K18898 and
   JP20H04467.
NR 45
TC 0
Z9 0
U1 1
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2297-3362
J9 FRONT BUILT ENVIRON
JI Front. Built Environ.
PD FEB 5
PY 2021
VL 6
AR 616455
DI 10.3389/fbuil.2020.616455
PG 13
WC Construction & Building Technology; Engineering, Civil
WE Emerging Sources Citation Index (ESCI)
SC Construction & Building Technology; Engineering
GA QJ1MJ
UT WOS:000619453800001
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU de Carvalho, HDP
   Fagundes, R
   Santos, W
AF Pereira de Carvalho, Halcyon Davys
   Fagundes, Roberta
   Santos, Wylliams
TI Extreme Learning Machine Applied to Software Development Effort
   Estimation
SO IEEE ACCESS
LA English
DT Article
DE Extreme learning machine; machine learning; effort estimation; software
   development; project management
AB The project management process has been used in the area of Software Engineering to support project managers to keep projects under control. One of the essential processes in Software Engineering is to conduct an accurate and reliable estimation of the required effort to complete the project. This article's objectives are: i) to identify the variables that influence the estimation based on the correlation, and ii) to apply the Extreme Learning Machine - ELM model for effort estimation and compare it with the literature models. Thus, it was investigated which technique has better effort prediction accuracy. The models were compared with each other based on predictive precision in the criterion of absolute mean residue (MAR) and statistical tests. The main findings in this study were: i) important variables for effort estimation and; ii) the results indicated that the ELM model presents the best results compared to the models in the literature for estimating software design effort. In this way, the use of Machine Learning techniques in the effort estimation process can increase the chances of success in the accuracy of the time estimates and the project's costs.
C1 [Pereira de Carvalho, Halcyon Davys; Fagundes, Roberta; Santos, Wylliams] Univ Pernambuco, Dept Comp Engn, BR-50720001 Recife, PE, Brazil.
RP de Carvalho, HDP; Fagundes, R; Santos, W (corresponding author), Univ Pernambuco, Dept Comp Engn, BR-50720001 Recife, PE, Brazil.
EM hdpc@ecomp.poli.br; roberta.fagundes@upe.br; wbs@upe.br
OI Carvalho, Halcyon/0000-0001-8933-5912; Santos,
   Wylliams/0000-0003-2578-1248
FU Improvement Coordination of Higher Education Personnel-Brazil
   (CAPES)Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior
   (CAPES) [001]
FX This work was supported by the Improvement Coordination of Higher
   Education Personnel-Brazil (CAPES) under Grant 001.
NR 48
TC 0
Z9 0
U1 3
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 92676
EP 92687
DI 10.1109/ACCESS.2021.3091313
PG 12
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA TK1JQ
UT WOS:000673924100001
OA gold
DA 2022-04-17
ER

PT J
AU Ashrafuzzaman, M
AF Ashrafuzzaman, Md
TI Artificial Intelligence, Machine Learning and Deep Learning in Ion
   Channel Bioinformatics
SO MEMBRANES
LA English
DT Review
DE ion channel; bioinformatics; artificial intelligence; deep learning;
   machine learning; channel classification; mutation
ID SEVERE MYOCLONIC EPILEPSY; SUPPORT VECTOR MACHINE; SEQUENCE DATABASE;
   MEMBRANE-PROTEIN; GENOME CONTENT; PREDICTION; CLASSIFICATION; MUTATIONS;
   EVOLUTION; SCN1A
AB Ion channels are linked to important cellular processes. For more than half a century, we have been learning various structural and functional aspects of ion channels using biological, physiological, biochemical, and biophysical principles and techniques. In recent days, bioinformaticians and biophysicists having the necessary expertise and interests in computer science techniques including versatile algorithms have started covering a multitude of physiological aspects including especially evolution, mutations, and genomics of functional channels and channel subunits. In these focused research areas, the use of artificial intelligence (AI), machine learning (ML), and deep learning (DL) algorithms and associated models have been found very popular. With the help of available articles and information, this review provide an introduction to this novel research trend. Ion channel understanding is usually made considering the structural and functional perspectives, gating mechanisms, transport properties, channel protein mutations, etc. Focused research on ion channels and related findings over many decades accumulated huge data which may be utilized in a specialized scientific manner to fast conclude pinpointed aspects of channels. AI, ML, and DL techniques and models may appear as helping tools. This review aims at explaining the ways we may use the bioinformatics techniques and thus draw a few lines across the avenue to let the ion channel features appear clearer.
C1 [Ashrafuzzaman, Md] King Saud Univ, Coll Sci, Dept Biochem, Riyadh 11451, Saudi Arabia.
RP Ashrafuzzaman, M (corresponding author), King Saud Univ, Coll Sci, Dept Biochem, Riyadh 11451, Saudi Arabia.
EM mashrafuzzaman@ksu.edu.sa
RI Ashrafuzzaman/O-7750-2014
OI Ashrafuzzaman/0000-0001-8454-3173
FU Deputyship for Research and Innovation, "Ministry of Education" in Saudi
   Arabia [IFKSURP-000]
FX The authors extend their appreciation to the Deputyship for Research and
   Innovation, "Ministry of Education" in Saudi Arabia for funding this
   research work through the Project no. (IFKSURP-000).
NR 83
TC 0
Z9 0
U1 13
U2 16
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2077-0375
J9 MEMBRANES-BASEL
JI Membranes
PD SEP
PY 2021
VL 11
IS 9
AR 672
DI 10.3390/membranes11090672
PG 35
WC Biochemistry & Molecular Biology; Chemistry, Physical; Engineering,
   Chemical; Materials Science, Multidisciplinary; Polymer Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biochemistry & Molecular Biology; Chemistry; Engineering; Materials
   Science; Polymer Science
GA UV5XR
UT WOS:000699551400001
PM 34564489
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Ruggieri, S
   Cardellicchio, A
   Leggieri, V
   Uva, G
AF Ruggieri, Sergio
   Cardellicchio, Angelo
   Leggieri, Valeria
   Uva, Giuseppina
TI Machine-learning based vulnerability analysis of existing buildings
SO AUTOMATION IN CONSTRUCTION
LA English
DT Article
DE Vulnerability analysis; Existing buildings; Machine-learning
ID DAMAGE ASSESSMENT; SCALE; BACKPROPAGATION; INVENTORY; DATABASE
AB The paper presents a machine-learning based framework, named VULMA (VULnerability analysis using MAchinelearning), for vulnerability analysis of existing buildings. The underlying idea is to provide an indication of the seismic vulnerability by exploiting available photographs, which can be properly processed to provide some input data for empirical vulnerability algorithms. To this scope, a complete processing pipeline has been defined, which consists in four consecutive modules offering different and specific services. The first module, Street VULMA, performs the image gathering starting from the raw data; the second module, Data VULMA, provides a mean for the data labelling and storage; the third module, Bi VULMA, uses the collected data to train several machine-learning models for image classification; the fourth module, In VULMA, performs a ranking of the images, their analysis and consequently assigns the vulnerability index. The proposed procedure has been employed on the existing building portfolio in an extended area of the municipality of Bisceglie, Puglia, Southern Italy, for which all the modules have been tested and, above all, the machine-learning models of Bi VULMA have been trained. After, in order to test the efficiency and the reliability of the proposed tools, the entire procedure has been applied on five case study buildings. The results in terms of vulnerability index have been compared with the manual computations performed by the authors applying the same algorithm. Despite the proposed tool could be improved or modified in some of its modules, the obtained results show a good effectiveness of VULMA, which opens new scenarios in the field of vulnerability assessment procedures and risk mitigation strategies.
C1 [Ruggieri, Sergio; Cardellicchio, Angelo; Leggieri, Valeria; Uva, Giuseppina] Polytech Univ Bari, DICATECH Dept, Bari, Italy.
RP Ruggieri, S (corresponding author), Polytech Univ Bari, DICATECH Dept, Bari, Italy.
EM sergio.ruggieri@poliba.it
RI Ruggieri, Sergio/AAD-3361-2022
OI Ruggieri, Sergio/0000-0001-5119-8967; Cardellicchio,
   Angelo/0000-0003-3313-4817
NR 65
TC 9
Z9 9
U1 8
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0926-5805
EI 1872-7891
J9 AUTOMAT CONSTR
JI Autom. Constr.
PD DEC
PY 2021
VL 132
AR 103936
DI 10.1016/j.autcon.2021.103936
EA SEP 2021
PG 19
WC Construction & Building Technology; Engineering, Civil
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Construction & Building Technology; Engineering
GA UZ1NL
UT WOS:000701978400007
DA 2022-04-17
ER

PT J
AU Rodrigues, CE
   Nascimento, CL
   Rade, DA
AF Rodrigues, Clayton Eduardo
   Nascimento Junior, Cairo Lucio
   Rade, Domingos Alves
TI Application of Machine Learning Techniques and Spectrum Images of
   Vibration Orbits for Fault Classification of Rotating Machines
SO JOURNAL OF CONTROL AUTOMATION AND ELECTRICAL SYSTEMS
LA English
DT Article
DE Rotating machines; Machine fault diagnosis; Spectral image; Vibration;
   Machine learning
ID FEATURE-EXTRACTION; DIAGNOSIS; ROTOR; MOTIONS; SYSTEM; CRACK
AB A comparative analysis of machine learning techniques for fault diagnosis of rotating machines based on images of vibration spectra is presented. The feature extraction of different types of faults, including unbalance, misalignment, shaft crack, rotor-stator rubbing, and hydrodynamic instability, is performed by processing spectral images of vibration orbits acquired during the machine run-up. The classifiers are trained with simulated data and tested with both simulated and experimental data. The latter are obtained from laboratory measurements performed on an rotor-disc system supported on hydrodynamic bearings. To generate the simulated data, a numerical model is developed using the finite element method. Deep learning, ensemble and traditional classification methods are evaluated. The ability of the methods to generalize the image classification is evaluated based on their performance in classifying experimental test patterns that were not used during training. The results of this research indicate that, despite considerable computational cost, the method based on convolutional neural networks presents the best performance.
C1 [Rodrigues, Clayton Eduardo] Petr Brasileiro SA Petrobras, Sao Jose Dos Campos, SP, Brazil.
   [Nascimento Junior, Cairo Lucio] Inst Tecnol Aeronaut ITA, Div Elect Engn, Sao Jose Dos Campos, SP, Brazil.
   [Rade, Domingos Alves] Inst Tecnol Aeronaut ITA, Div Mech Engn, Sao Jose Dos Campos, SP, Brazil.
RP Rodrigues, CE (corresponding author), Petr Brasileiro SA Petrobras, Sao Jose Dos Campos, SP, Brazil.
EM crodrigues@petrobras.com.br; cairo@ita.br; rade@ita.br
RI Nascimento, Cairo L./B-8173-2013
OI Nascimento, Cairo L./0000-0002-2418-0320; , Clayton/0000-0002-2213-1007
FU Fundacao de Amparo a Pesquisa do Estado de Sao Paulo -FAPESPFundacao de
   Amparo a Pesquisa do Estado de Sao Paulo (FAPESP) [2015/20363-6]
FX An early version of paper was presented at XXIII Congresso Brasileiro de
   Automatica (CBA 2020). The authors express their appreciation to the
   Petrobras company for making the experimental test bench available for
   this research. D. A. Rade also gratefully acknowledges the funding
   provided by Fundacao de Amparo a Pesquisa do Estado de Sao Paulo -FAPESP
   (grant #2015/20363-6).
NR 38
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2195-3880
EI 2195-3899
J9 J CONTROL AUTOM ELEC
JI J. Control Autom. Electr. Syst.
PD FEB
PY 2022
VL 33
IS 1
SI SI
BP 333
EP 344
DI 10.1007/s40313-021-00805-x
EA OCT 2021
PG 12
WC Automation & Control Systems
WE Emerging Sources Citation Index (ESCI)
SC Automation & Control Systems
GA XU3JL
UT WOS:000704619400001
DA 2022-04-17
ER

PT C
AU Guo, CA
   Goldstein, T
   Hannun, A
   van der Maaten, L
AF Guo, Chuan
   Goldstein, Tom
   Hannun, Awni
   van der Maaten, Laurens
BE Daume, H
   Singh, A
TI Certified Data Removal from Machine Learning Models
SO INTERNATIONAL CONFERENCE ON MACHINE LEARNING, VOL 119
SE Proceedings of Machine Learning Research
LA English
DT Proceedings Paper
CT International Conference on Machine Learning (ICML)
CY JUL 13-18, 2020
CL ELECTR NETWORK
AB Good data stewardship requires removal of data at the request of the data's owner. This raises the question if and how a trained machine-learning model, which implicitly stores information about its training data, should be affected by such a removal request. Is it possible to "remove" data from a machine-learning model? We study this problem by defining certified removal: a very strong theoretical guarantee that a model from which data is removed cannot be distinguished from a model that never observed the data to begin with. We develop a certified-removal mechanism for linear classifiers and empirically study learning settings in which this mechanism is practical.
C1 [Guo, Chuan] Cornell Univ, Dept Comp Sci, Ithaca, NY 14850 USA.
   [Goldstein, Tom; Hannun, Awni; van der Maaten, Laurens] Facebook AI Res, New York, NY 10003 USA.
RP Guo, CA (corresponding author), Cornell Univ, Dept Comp Sci, Ithaca, NY 14850 USA.; van der Maaten, L (corresponding author), Facebook AI Res, New York, NY 10003 USA.
EM cg563@cornell.edu; lvdmaaten@gmail.com
NR 34
TC 3
Z9 3
U1 0
U2 0
PU JMLR-JOURNAL MACHINE LEARNING RESEARCH
PI SAN DIEGO
PA 1269 LAW ST, SAN DIEGO, CA, UNITED STATES
SN 2640-3498
J9 PR MACH LEARN RES
PY 2020
VL 119
PG 11
WC Computer Science, Artificial Intelligence
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS0LL
UT WOS:000683178503088
DA 2022-04-17
ER

PT J
AU Gittler, T
   Scholze, S
   Rupenyan, A
   Wegener, K
AF Gittler, Thomas
   Scholze, Stephan
   Rupenyan, Alisa
   Wegener, Konrad
TI Machine Tool Component Health Identification with Unsupervised Learning
SO JOURNAL OF MANUFACTURING AND MATERIALS PROCESSING
LA English
DT Article
DE condition monitoring; machine learning; prognostics and health
   monitoring; unsupervised learning; machine tools; manufacturing
ID DATA ANALYTICS; CHALLENGES; FUTURE
AB Unforeseen machine tool component failures cause considerable losses. This study presents a new approach to unsupervised machine component condition identification. It uses test cycle data of machine components in healthy and various faulty conditions for modelling. The novelty in the approach consists of the time series representation as features, the filtering of the features for statistical significance, and the use of this feature representation to train a clustering model. The benefit in the proposed approach is its small engineering effort, the potential for automation, the small amount of data necessary for training and updating the model, and the potential to distinguish between multiple known and unknown conditions. Online measurements on machines in unknown conditions are performed to predict the component condition with the aid of the trained model. The approach was exemplarily tested and verified on different healthy and faulty states of a grinding machine axis. For the accurate classification of the component condition, different clustering algorithms were evaluated and compared. The proposed solution demonstrated encouraging results as it accurately classified the component condition. It requires little data, is straightforward to implement and update, and is able to precisely differentiate minor differences of faults in test cycle time series.
C1 [Gittler, Thomas; Wegener, Konrad] Swiss Fed Inst Technol, Inst Machine Tools & Mfg IWF, CH-8092 Zurich, Switzerland.
   [Scholze, Stephan] Agathon AG, CH-4512 Bellach, Switzerland.
   [Rupenyan, Alisa] Swiss Fed Inst Technol, Inspire AG, CH-8005 Zurich, Switzerland.
RP Gittler, T (corresponding author), Swiss Fed Inst Technol, Inst Machine Tools & Mfg IWF, CH-8092 Zurich, Switzerland.
EM gittler@inspire.ethz.ch; stephan.scholze@agathon.ch;
   rupenyan@inspire.ethz.ch; wegener@iwf.mavt.ethz.ch
RI Rupenyan, Alisa/AAR-8404-2021
OI Rupenyan, Alisa/0000-0002-2170-8564; Gittler,
   Thomas/0000-0002-1932-2494; Scholze, Stephan/0000-0002-4473-2081
FU Innosuisse agency [2155002643]
FX This work was supported by the Innosuisse agency under Grant 2155002643.
   The authors would like to express their gratitude for the financial
   research support.
NR 30
TC 4
Z9 4
U1 2
U2 2
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2504-4494
J9 J MANUF MATER PROC
JI J. Manuf. Mater. Process.
PD SEP
PY 2020
VL 4
IS 3
AR 86
DI 10.3390/jmmp4030086
PG 15
WC Engineering, Manufacturing; Engineering, Mechanical; Materials Science,
   Multidisciplinary
WE Emerging Sources Citation Index (ESCI)
SC Engineering; Materials Science
GA OG8XH
UT WOS:000582159200001
OA gold, Green Published
DA 2022-04-17
ER

PT C
AU Molnar, C
   Casalicchio, G
   Bischl, B
AF Molnar, Christoph
   Casalicchio, Giuseppe
   Bischl, Bernd
BE Koprinska, I
   Kamp, M
   Appice, A
   Loglisci, C
   Antonie, L
   Zimmermann, A
   Guidotti, R
   Ozgobek, O
TI Interpretable Machine Learning - A Brief History, State-of-the-Art and
   Challenges
SO ECML PKDD 2020 WORKSHOPS
SE Communications in Computer and Information Science
LA English
DT Proceedings Paper
CT European Conference on Machine Learning and Principles and Practice of
   Knowledge Discovery in Databases (ECML PKDD)
CY SEP 14-18, 2020
CL ELECTR NETWORK
SP Fraunhofer IAIS, ASML, F Secure, Roche, Amazon, Science, EURA NOVA, Google, NEC, Internet & Data Lab, KNIME, Qualcomm, AI Res, imec, FWO, Ghent Univ, Springer, Visitgent, gentcongres, AI Growth
DE Interpretable Machine Learning; Explainable artificial intelligence
ID VARIABLE IMPORTANCE; RANDOM FORESTS; SELECTION; CLASSIFICATION; MODELS;
   RULES
AB We present a brief history of the field of interpretable machine learning (IML), give an overview of state-of-the-art interpretation methods and discuss challenges. Research in IML has boomed in recent years. As young as the field is, it has over 200 years old roots in regression modeling and rule-based machine learning, starting in the 1960s. Recently, many new IML methods have been proposed, many of them model-agnostic, but also interpretation techniques specific to deep learning and tree-based ensembles. IML methods either directly analyze model components, study sensitivity to input perturbations, or analyze local or global surrogate approximations of the ML model. The field approaches a state of readiness and stability, with many methods not only proposed in research, but also implemented in open-source software. But many important challenges remain for IML, such as dealing with dependent features, causal interpretation, and uncertainty estimation, which need to be resolved for its successful application to scientific problems. A further challenge is a missing rigorous definition of interpretability, which is accepted by the community. To address the challenges and advance the field, we urge to recall our roots of interpretable, data-driven modeling in statistics and (rule-based) ML, but also to consider other areas such as sensitivity analysis, causal inference, and the social sciences.
C1 [Molnar, Christoph; Casalicchio, Giuseppe; Bischl, Bernd] Ludwig Maximilians Univ Munchen, Dept Stat, Ludwigstr 33, D-80539 Munich, Germany.
RP Molnar, C (corresponding author), Ludwig Maximilians Univ Munchen, Dept Stat, Ludwigstr 33, D-80539 Munich, Germany.
EM christoph.molnar@stat.uni-muenchen.de
FU Bavarian State Ministry of Science and the Arts; German Federal Ministry
   of Education and Research (BMBF)Federal Ministry of Education & Research
   (BMBF) [01IS18036A]
FX This project is funded by the Bavarian State Ministry of Science and the
   Arts and coordinated by the Bavarian Research Institute for Digital
   Transformation (bidt) and supported by the German Federal Ministry of
   Education and Research (BMBF) under Grant No. 01IS18036A. The authors of
   this work take full responsibilities for its content.
NR 131
TC 17
Z9 17
U1 7
U2 7
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1865-0929
EI 1865-0937
BN 978-3-030-65965-3; 978-3-030-65964-6
J9 COMM COM INF SC
PY 2020
VL 1323
BP 417
EP 431
DI 10.1007/978-3-030-65965-3_28
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Interdisciplinary Applications; Computer
   Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS4YI
UT WOS:000724139600027
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Liu, GY
   Chen, M
   Liu, YX
   Layden, D
   Cappellaro, P
AF Liu, Genyue
   Chen, Mo
   Liu, Yi-Xiang
   Layden, David
   Cappellaro, Paola
TI Repetitive readout enhanced by machine learning
SO MACHINE LEARNING-SCIENCE AND TECHNOLOGY
LA English
DT Article
DE NV center; repetitive readout; machine learning;
   preparation-by-measurement; quantum information
ID NUCLEAR-MAGNETIC-RESONANCE; ELECTRON-SPIN; QUANTUM; SPECTROSCOPY; ATOMS
AB Single-shot readout is a key component for scalable quantum information processing. However, many solid-state qubits with favorable properties lack the single-shot readout capability. One solution is to use the repetitive quantum-non-demolition readout technique, where the qubit is correlated with an ancilla, which is subsequently read out. The readout fidelity is therefore limited by the back-action on the qubit from the measurement. Traditionally, a threshold method is taken, where only the total photon count is used to discriminate qubit state, discarding all the information of the back-action hidden in the time trace of repetitive readout measurement. Here we show by using machine learning (ML), one obtains higher readout fidelity by taking advantage of the time trace data. ML is able to identify when back-action happened, and correctly read out the original state. Since the information is already recorded (but usually discarded), this improvement in fidelity does not consume additional experimental time, and could be directly applied to preparation-by-measurement and quantum metrology applications involving repetitive readout.
C1 [Liu, Genyue; Chen, Mo; Liu, Yi-Xiang; Layden, David; Cappellaro, Paola] MIT, Elect Res Lab, Cambridge, MA 02139 USA.
   [Chen, Mo] MIT, Dept Mech Engn, Cambridge, MA 02139 USA.
   [Liu, Yi-Xiang; Layden, David; Cappellaro, Paola] MIT, Dept Nucl Sci & Engn, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
RP Cappellaro, P (corresponding author), MIT, Elect Res Lab, Cambridge, MA 02139 USA.; Cappellaro, P (corresponding author), MIT, Dept Nucl Sci & Engn, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
EM pcappell@mit.edu
RI Cappellaro, Paola/B-1413-2010
OI Cappellaro, Paola/0000-0003-3207-594X; /0000-0002-2394-2442
FU NSF grant EFRI-ACQUIRE [1641064]; Skoltech
FX This work was supported in part by the NSF grant EFRI-ACQUIRE 1641064
   and by Skoltech.
NR 59
TC 12
Z9 12
U1 2
U2 2
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
EI 2632-2153
J9 MACH LEARN-SCI TECHN
JI Mach. Learn.-Sci. Technol.
PD MAR 1
PY 2020
VL 1
IS 1
AR 015003
DI 10.1088/2632-2153/ab4e24
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Science & Technology - Other Topics
GA SR0JW
UT WOS:000660732800001
OA gold, Green Submitted, Green Published
DA 2022-04-17
ER

PT J
AU Tian, YJ
   Zhang, YQ
AF Tian, Yingjie
   Zhang, Yuqi
TI A comprehensive survey on regularization strategies in machine learning
SO INFORMATION FUSION
LA English
DT Article
DE Overfitting; Generalization; Regularization; Machine learning
ID COVARIANCE-MATRIX ESTIMATION; P-LAPLACIAN REGULARIZATION;
   FEATURE-SELECTION; SPARSE REGULARIZATION; VARIABLE SELECTION;
   NEURAL-NETWORKS; ROBUST PCA; IMAGE; REGRESSION; APPROXIMATION
AB In machine learning, the model is not as complicated as possible. Good generalization ability means that the model not only performs well on the training data set, but also can make good prediction on new data. Regularization imposes a penalty on model's complexity or smoothness, allowing for good generalization to unseen data even when training on a finite training set or with an inadequate iteration. Deep learning has developed rapidly in recent years. Then the regularization has a broader definition: regularization is a technology aimed at improving the generalization ability of a model. This paper gave a comprehensive study and a state-of-the-art review of the regularization strategies in machine learning. Then the characteristics and comparisons of regularizations were presented. In addition, it discussed how to choose a regularization for the specific task. For specific tasks, it is necessary for regularization technology to have good mathematical characteristics. Meanwhile, new regularization techniques can be constructed by extending and combining existing regularization techniques. Finally, it concluded current opportunities and challenges of regularization technologies, as well as many open concerns and research trends.
C1 [Tian, Yingjie] Univ Chinese Acad Sci, Sch Econ & Management, Beijing 100190, Peoples R China.
   [Zhang, Yuqi] Univ Chinese Acad Sci, Sch Math Sci, Beijing 100049, Peoples R China.
   [Tian, Yingjie; Zhang, Yuqi] Chinese Acad Sci, Res Ctr Fictitious Econ & Data Sci, Beijing 100190, Peoples R China.
   [Tian, Yingjie; Zhang, Yuqi] Chinese Acad Sci, Key Lab Big Data Min & Knowledge Management, Beijing 100190, Peoples R China.
RP Tian, YJ (corresponding author), Univ Chinese Acad Sci, Sch Econ & Management, Beijing 100190, Peoples R China.
EM tyj@ucas.ac.cn; zhangyuqi201@mails.ucas.ac.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [12071458, 71731009]
FX This work has been partially supported by grants from: National Natural
   Science Foundation of China (No. 12071458, 71731009) .
NR 166
TC 1
Z9 1
U1 9
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1566-2535
EI 1872-6305
J9 INFORM FUSION
JI Inf. Fusion
PD APR
PY 2022
VL 80
BP 146
EP 166
DI 10.1016/j.inffus.2021.11.005
EA NOV 2021
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XF8MH
UT WOS:000724320000009
DA 2022-04-17
ER

PT J
AU Cobos-Torres, JC
   Reyes, PA
   Mendez, CF
AF Cobos-Torres, Juan-Carlos
   Arias Reyes, Pablo
   Fernando Mendez, Carlos
TI Problem-Based Learning for an Electrical Machines Course
SO INTERNATIONAL JOURNAL OF EMERGING TECHNOLOGIES IN LEARNING
LA English
DT Article
DE Continuing education; Simulation; Electrical engineering; Problem based
   learning; Static Machines
ID PBL
AB This article seeks to describe the implementation of a problem-based learning (PBL) teaching-learning method in a university classroom. The aim is for the student through given real-life situations to acquire knowledge, abilities, and attitudes in the subject of electrical machines in the undergraduate electrical engineering program of the Catholic University of Cuenca. Solving problems related to static machines will be similar to the problems that students will face in their professional lives; namely, to be able to identify a static machine and its operation, parameters, model its equivalent circuits (open- and short-circuit tests), calculate losses, and carry out hysteresis loop measurement. Most of these concepts are abstract and challenging for students to assimilate. Therefore, the present research shows how using the PBL model in studying static machines improves the academic performance and achievement of students in an experimental group. There was an improvement of 7 points out of 100 in relation to the average of the grades of three groups of students from previous semesters. Also, the standard deviation is lower in the experimental group (SD 4.5584), which shows that most of the students improved in their performance. Finally, there was no failure of the study year nor remedial exams among this group.
C1 [Cobos-Torres, Juan-Carlos] Catholic Univ Cuenca, Cuenca, Ecuador.
   [Arias Reyes, Pablo] Catholic Univ Cuenca, Elect Engn Dept, Energy Power Area & Smart Energy Simulat Lab, Cuenca, Ecuador.
   [Fernando Mendez, Carlos] Catholic Univ Cuenca, Acad Unit Engn Ind & Construct, Cuenca, Ecuador.
RP Cobos-Torres, JC (corresponding author), Catholic Univ Cuenca, Cuenca, Ecuador.
EM juan.cobos@ucacue.edu.ec
FU Smart University 2.0 program - Optimizacion energetica del sistema de
   recaudo en Unidades de Transporte Urbano
FX The research leading to these results has received funding from Smart
   University 2.0 program, funded by "Optimizacion energetica del sistema
   de recaudo en Unidades de Transporte Urbano".
NR 18
TC 0
Z9 0
U1 2
U2 2
PU KASSEL UNIV PRESS GMBH
PI KASSEL
PA DIAGONALE 10, D-34127 KASSEL, GERMANY
SN 1863-0383
J9 INT J EMERG TECHNOL
JI Int. J. Emerg. Technol. Learn.
PY 2020
VL 15
IS 22
BP 192
EP 203
DI 10.3991/ijet.v15i22.16871
PG 12
WC Education & Educational Research
WE Emerging Sources Citation Index (ESCI)
SC Education & Educational Research
GA PA2WQ
UT WOS:000595494400012
OA gold
DA 2022-04-17
ER

PT C
AU Oliveira, SD
   Canuto, AMP
   Carvalho, BM
   Kreutz, ME
AF Oliveira, Samuel da S.
   Canuto, Anne M. P.
   Carvalho, Bruno M.
   Kreutz, Marcio E.
GP IEEE
TI Machine Learning Based Seismic Region Classification
SO 2020 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
LA English
DT Proceedings Paper
CT International Joint Conference on Neural Networks (IJCNN) held as part
   of the IEEE World Congress on Computational Intelligence (IEEE WCCI)
CY JUL 19-24, 2020
CL ELECTR NETWORK
SP IEEE, IEEE Computat Intelligence Soc, Int Neural Network Soc
DE Seismc Signals; Seismic Processing; Machine Learning
AB It has become increasingly common in academic and industrial environments the necessity to process huge amounts of seismic signals. Several researchers have been seeking for ways to improve and optimize the processing of these enormous amounts of data that are related to routine demands of geophysicists. One of these demands is the classification of distinct seismic regions captured by the same seismograph, a task that could take up to months of manual data processing. In this paper, we propose the usage of machine learning techniques to the task of the classification of seismic regions, in order to achieve accurate results with better performance and speed. The algorithms K-NN, MLP, Naive Bayes and Decision Tree were used for tests as base classifiers and also combined on ensemble methods. We also employed Deep Learning techniques, namely, a pure RNN network, and a variation of RNN called LSTM. The best results were achieved when using heterogeneous classifiers, showing accuracy rates of up to 98.52 %. The results show that one can build an efficient seismic region classification system even when few classified data are already available for a specific seismograph setting.
C1 [Oliveira, Samuel da S.; Canuto, Anne M. P.; Carvalho, Bruno M.; Kreutz, Marcio E.] Univ Fed Rio Grande do Norte, Dept Comp Sci & Appl Math, Natal, RN, Brazil.
RP Oliveira, SD (corresponding author), Univ Fed Rio Grande do Norte, Dept Comp Sci & Appl Math, Natal, RN, Brazil.
EM samuel@imd.ufrn.br; anne@dimap.ufrn.br; bruno@dimap.ufrn.br;
   kreutz@dimap.ufrn.br
OI da Silva Oliveira, Samuel/0000-0002-0104-0704
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior Brasil
   (CAPES)Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior
   (CAPES) [001]
FX This study was financed in part by the Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior Brasil (CAPES) Finance Code 001.
NR 25
TC 3
Z9 2
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2161-4393
BN 978-1-7281-6926-2
J9 IEEE IJCNN
PY 2020
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ9MM
UT WOS:000626021402125
DA 2022-04-17
ER

PT J
AU He, Y
   Ye, ZYF
   Liu, XY
   Wei, ZJ
   Qiu, F
   Li, HF
   Zheng, Y
   Ouyang, DF
AF He, Yuan
   Ye, Zhuyifan
   Liu, Xinyang
   Wei, Zhengjie
   Qiu, Fen
   Li, Hai-Feng
   Zheng, Ying
   Ouyang, Defang
TI Can machine learning predict drug nanocrystals?
SO JOURNAL OF CONTROLLED RELEASE
LA English
DT Article
DE Machine learning; Nanocrystals; Particle size; Polydispersity index
   (PDI); Prediction
ID POORLY SOLUBLE DRUGS; FORMULATION DEVELOPMENT; NANOSUSPENSIONS;
   TECHNOLOGY; SOLUBILITY; DELIVERY; BIOAVAILABILITY; DISCOVERY; FEATURES
AB Nanocrystals have exhibited great advantage for enhancing the dissolution rate of water insoluble drugs due to the reduced size to nanoscale. However, current pharmaceutical approaches for nanocrystals formulation development highly depend on the expert experience and trial-and-error attempts which remain time and resource consuming. In this research, we utilized machine learning techniques to predict the particle size and polydispersity index (PDI) of nanocrystals. Firstly, 910 nanocrystal size data and 341 PDI data by three preparation methods (ball wet milling (BWM) method, high-pressure homogenization (HPH) method and antisolvent precipitation (ASP) method) were collected for the construction of the prediction models. The results demonstrated that light gradient boosting machine (LightGBM) exhibited well performance for the nanocrystals size and PDI prediction with BWM and HPH methods, but relatively poor predictions for ASP method. The possible reasons for the poor prediction refer to low quality of data because of the poor reproducibility and instability of nanocrystals by ASP method, which also confirm that current commercialized products were mainly manufactured by BWM and HPH approaches. Notably, the contribution of the influence factors was ranked by the LightGBM, which demonstrated that milling time, cycle index and concentration of stabilizer are crucial factors for nanocrystals prepared by BWM, HPH and ASP, respectively. Furthermore, the model generalizations and prediction accuracies of LightGBM were confirmed experimentally by the newly prepared nanocrystals. In conclusion, the machine learning techniques can be successfully utilized for the predictions of nanocrystals prepared by BWM and HPH methods. Our research also reveals a new way for nanotechnology manufacture.
C1 [He, Yuan; Ye, Zhuyifan; Liu, Xinyang; Wei, Zhengjie; Qiu, Fen; Zheng, Ying; Ouyang, Defang] Univ Macau, Inst Chinese Med Sci ICMS, State Key Lab Qual Res Chinese Med, Macau, Peoples R China.
   [Li, Hai-Feng] Univ Macau, Inst Appl Phys & Mat Engn, Macau, Peoples R China.
RP Zheng, Y; Ouyang, DF (corresponding author), Univ Macau, Inst Chinese Med Sci ICMS, State Key Lab Qual Res Chinese Med, Macau, Peoples R China.
EM yzheng@umac.mo; defangouyang@umac.mo
RI Ouyang, Defang/AAW-1087-2020; Li, Hai-Feng/AAZ-1811-2021
OI Li, Hai-Feng/0000-0001-8186-1125; Ouyang, Defang/0000-0002-8052-4773
FU Macau Science and Technology Development Fund (FDCT) [0029/2018/A1];
   University of Macau [MYRG2019-00032-ICMS, MYRG2019-00041-ICMS]
FX This work was supported by the Macau Science and Technology Development
   Fund (FDCT) (Grant No. 0029/2018/A1) and the Research Grant of the
   University of Macau [MYRG2019-00032-ICMS & MYRG2019-00041-ICMS].
NR 38
TC 14
Z9 15
U1 5
U2 35
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0168-3659
EI 1873-4995
J9 J CONTROL RELEASE
JI J. Control. Release
PD JUN 10
PY 2020
VL 322
BP 274
EP 285
DI 10.1016/j.jconrel.2020.03.043
PG 12
WC Chemistry, Multidisciplinary; Pharmacology & Pharmacy
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Pharmacology & Pharmacy
GA LT5TR
UT WOS:000537133900005
PM 32234511
DA 2022-04-17
ER

PT J
AU Shamshirband, S
   Mosavi, A
   Rabczuk, T
   Nabipour, N
   Chau, KW
AF Shamshirband, Shahaboddin
   Mosavi, Amir
   Rabczuk, Timon
   Nabipour, Narjes
   Chau, Kwok-wing
TI Prediction of significant wave height; comparison between nested grid
   numerical model, and machine learning models of artificial neural
   networks, extreme learning and support vector machines
SO ENGINEERING APPLICATIONS OF COMPUTATIONAL FLUID MECHANICS
LA English
DT Article
DE Numerical modeling; nested grid; wind waves; machine learning; extreme
   learning machines; deep learning
ID COASTAL REGIONS; INTELLIGENCE; GENERATION; WIND
AB Estimation of wave height is essential for several coastal engineering applications. This study advances a nested grid numerical model and compare its efficiency with three machine learning (ML) methods of artificial neural networks (ANN), extreme learning machines (ELM) and support vector regression (SVR) for wave height modeling. The models are trained by surface wind data. The results demonstrate that all the models generally provide sound predictions. Due to the high level of variability in the bathymetry of the study area, implementation of the nested grid with different Whitecapping coefficient is a suitable approach to improve the efficiency of the numerical models. Performance on the ML models do not differ remarkably even though the ELM model slightly outperforms the other models.
C1 [Shamshirband, Shahaboddin] Ton Duc Thang Univ, Dept Management Sci & Technol Dev, Ho Chi Minh City, Vietnam.
   [Shamshirband, Shahaboddin] Ton Duc Thang Univ, Fac Informat Technol, Ho Chi Minh City, Vietnam.
   [Mosavi, Amir] Tech Univ Dresden, Fac Civil Engn, Dresden, Germany.
   [Mosavi, Amir] Obuda Univ, Kando Kalman Fac Elect Engn, Budapest, Hungary.
   [Mosavi, Amir] J Selye Univ, Dept Math, Komarno, Slovakia.
   [Mosavi, Amir; Rabczuk, Timon] Bauhaus Univ Weimar, Inst Struct Mech, Weimar, Germany.
   [Mosavi, Amir] Oxford Brookes Univ, Sch Built Environm, Oxford, England.
   [Mosavi, Amir] Thuringian Inst Sustainabil & Climate Protect, Jena, Germany.
   [Nabipour, Narjes] Duy Tan Univ, Inst Res & Dev, Da Nang, Vietnam.
   [Chau, Kwok-wing] Hong Kong Polytech Univ, Dept Civil & Environm Engn, Hong Kong, Peoples R China.
RP Mosavi, A (corresponding author), Tech Univ Dresden, Fac Civil Engn, Dresden, Germany.; Mosavi, A (corresponding author), Obuda Univ, Kando Kalman Fac Elect Engn, Budapest, Hungary.; Mosavi, A (corresponding author), J Selye Univ, Dept Math, Komarno, Slovakia.; Mosavi, A (corresponding author), Bauhaus Univ Weimar, Inst Struct Mech, Weimar, Germany.; Mosavi, A (corresponding author), Oxford Brookes Univ, Sch Built Environm, Oxford, England.; Mosavi, A (corresponding author), Thuringian Inst Sustainabil & Climate Protect, Jena, Germany.; Nabipour, N (corresponding author), Duy Tan Univ, Inst Res & Dev, Da Nang, Vietnam.
EM amir.mosavi@mailbox.dresden.de; Narjesnabipour@duytan.edu.vn
RI Mosavi, Amir/I-7440-2018; S. Band, Shahab/ABB-2469-2020; S.Band,
   Shahab/AAD-3311-2021; Chau, Kwok-wing/E-5235-2011; S.Band,
   Shahab/ABI-7388-2020; Rabczuk, Timon/A-3067-2009
OI Mosavi, Amir/0000-0003-4842-0613; S. Band, Shahab/0000-0001-6109-1311;
   Chau, Kwok-wing/0000-0001-6457-161X; S.Band, Shahab/0000-0002-8963-731X;
   Rabczuk, Timon/0000-0002-7150-296X
FU TU DresdenEuropean Commission; European UnionEuropean Commission
   [EFOP-3.6.1-16-2016-00010, 2017-1.3.1-VKE-2017-00025]; Research AMP;
   Innovation Operational Programme - European Regional Development Fund
   [NFP313010T504]
FX We acknowledge the open access funding by the publication fund of the TU
   Dresden. Also, we acknowledge the financial support of the Hungarian
   State and the European Union under the EFOP-3.6.1-16-2016-00010 project
   and the 2017-1.3.1-VKE-2017-00025 project. This research has been
   additionally supported by the Project: 'Support of research and
   development activities of the J. Selye University in the field of
   Digital Slovakia and creative industry' of the Research & Innovation
   Operational Programme (ITMS code: NFP313010T504) co-funded by the
   European Regional Development Fund.
NR 26
TC 24
Z9 24
U1 9
U2 10
PU HONG KONG POLYTECHNIC UNIV, DEPT CIVIL & STRUCTURAL ENG
PI HONG KONG
PA HUNG HOM, KOWLOON, HONG KONG, 00000, PEOPLES R CHINA
SN 1994-2060
EI 1997-003X
J9 ENG APPL COMP FLUID
JI Eng. Appl. Comp. Fluid Mech.
PD JAN 1
PY 2020
VL 14
IS 1
BP 805
EP 817
DI 10.1080/19942060.2020.1773932
PG 13
WC Engineering, Multidisciplinary; Engineering, Mechanical; Mechanics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Mechanics
GA ME1QL
UT WOS:000544436100001
OA gold
DA 2022-04-17
ER

PT J
AU Chang, MC
   Canseco, JA
   Nicholson, KJ
   Patel, N
   Vaccaro, AR
AF Chang, Michael
   Canseco, Jose A.
   Nicholson, Kristen J.
   Patel, Neil
   Vaccaro, Alexander R.
TI The Role of Machine Learning in Spine Surgery: The Future Is Now
SO FRONTIERS IN SURGERY
LA English
DT Review
DE machine learning; deep learning; artificial intelligence; spine surgery;
   orthopedic surgery
ID ARTIFICIAL-INTELLIGENCE; AUGMENTED REALITY; PEDICLE-SCREW; COMPRESSION
   FRACTURES; NEURAL-NETWORKS; MIXED REALITY; POINTS; CLASSIFICATION;
   SEGMENTATION; MODELS
AB The recent influx of machine learning centered investigations in the spine surgery literature has led to increased enthusiasm as to the prospect of using artificial intelligence to create clinical decision support tools, optimize postoperative outcomes, and improve technologies used in the operating room. However, the methodology underlying machine learning in spine research is often overlooked as the subject matter is quite novel and may be foreign to practicing spine surgeons. Improper application of machine learning is a significant bioethics challenge, given the potential consequences of over- or underestimating the results of such studies for clinical decision-making processes. Proper peer review of these publications requires a baseline familiarity of the language associated with machine learning, and how it differs from classical statistical analyses. This narrative review first introduces the overall field of machine learning and its role in artificial intelligence, and defines basic terminology. In addition, common modalities for applying machine learning, including classification and regression decision trees, support vector machines, and artificial neural networks are examined in the context of examples gathered from the spine literature. Lastly, the ethical challenges associated with adapting machine learning for research related to patient care, as well as future perspectives on the potential use of machine learning in spine surgery, are discussed specifically.
C1 [Chang, Michael; Canseco, Jose A.; Patel, Neil; Vaccaro, Alexander R.] Thomas Jefferson Univ, Dept Orthopaed Surg, Philadelphia, PA 19107 USA.
   [Chang, Michael; Canseco, Jose A.; Nicholson, Kristen J.; Patel, Neil; Vaccaro, Alexander R.] Rothman Orthopaed Instd, Philadelphia, PA 19107 USA.
RP Canseco, JA (corresponding author), Thomas Jefferson Univ, Dept Orthopaed Surg, Philadelphia, PA 19107 USA.; Canseco, JA (corresponding author), Rothman Orthopaed Instd, Philadelphia, PA 19107 USA.
EM jose.canseco@rothmanortho.com
FU Rothman Orthopaedic Institute; Department of Orthopaedic Surgery at
   Thomas Jefferson University
FX This study was funded internally by the Rothman Orthopaedic Institute
   and the Department of Orthopaedic Surgery at Thomas Jefferson
   University.
NR 80
TC 10
Z9 10
U1 4
U2 15
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 2296-875X
J9 FRONT SURG
JI Front. Surg.
PD AUG 21
PY 2020
VL 7
AR 54
DI 10.3389/fsurg.2020.00054
PG 15
WC Surgery
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Surgery
GA NM7NE
UT WOS:000568280500001
PM 32974382
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Doucet, M
   Samarakoon, AM
   Do, C
   Heller, WT
   Archibald, R
   Tennant, DA
   Proffen, T
   Granroth, GE
AF Doucet, Mathieu
   Samarakoon, Anjana M.
   Do, Changwoo
   Heller, William T.
   Archibald, Richard
   Alan Tennant, D.
   Proffen, Thomas
   Granroth, Garrett E.
TI Machine learning for neutron scattering at ORNL*
SO MACHINE LEARNING-SCIENCE AND TECHNOLOGY
LA English
DT Article
DE neutron scattering; machine learning; spectroscopy; diffraction; sans;
   super resolution
ID BRAGG PEAKS; OAK-RIDGE; TOOL; RESOLUTION
AB Machine learning (ML) offers exciting new opportunities to extract more information from scattering data. At neutron scattering user facilities, ML has the potential to help accelerate scientific productivity by empowering facility users with insight into their data which has traditionally been supplied by scattering experts. Such support can help in both speeding up common modeling problems for users, as well as help solve harder problems that are normally time consuming and difficult to address with standard methods. This article explores the recent ML work undertaken at Oak Ridge National Laboratory involving neutron scattering data. We cover materials structure modeling for diffuse scattering, powder diffraction, and small-angle scattering. We also discuss how ML can help to model the response of the instrument more precisely, as well as enable quick extraction of information from neutron data. The application of super-resolution techniques to small-angle scattering and peak extraction for diffraction will be discussed.
C1 [Doucet, Mathieu; Samarakoon, Anjana M.; Do, Changwoo; Heller, William T.; Proffen, Thomas; Granroth, Garrett E.] Oak Ridge Natl Lab, Neutron Scattering Div, Oak Ridge, TN 37831 USA.
   [Archibald, Richard] Oak Ridge Natl Lab, Comp Sci & Math Div, Oak Ridge, TN 37831 USA.
   [Alan Tennant, D.] Oak Ridge Natl Lab, Mat Sci & Technol Div, Oak Ridge, TN 37831 USA.
   [Alan Tennant, D.] Oak Ridge Natl Lab, Shull Wollan Ctr Joint Inst Neutron Sci, Oak Ridge, TN 37831 USA.
RP Doucet, M (corresponding author), Oak Ridge Natl Lab, Neutron Scattering Div, Oak Ridge, TN 37831 USA.
EM doucetm@ornl.gov
RI Tennant, David A/Q-2497-2015; Granroth, Garrett E/G-3576-2012; Doucet,
   Mathieu/A-5333-2010; Proffen, Thomas/B-3585-2009; Archibald,
   Rick/I-6238-2016
OI Tennant, David A/0000-0002-9575-3368; Granroth, Garrett
   E/0000-0002-7583-8778; Doucet, Mathieu/0000-0002-5560-6478; Heller,
   William/0000-0001-6456-2975; Proffen, Thomas/0000-0002-1408-6031;
   Archibald, Rick/0000-0002-4538-9780
FU DOEUnited States Department of Energy (DOE) [DE-AC05-00OR22725];
   Scientific Discovery through Advanced Computing (SciDAC) - U S
   Department of Energy, Office of Science, Advanced Scientific Computing
   Research through FASTMath InstitutesUnited States Department of Energy
   (DOE); Laboratory Directed Research and Development Program of ORNL;
   ExaLearn, an Exascale Computing Project, DOEUnited States Department of
   Energy (DOE)
FX A portion of this research used resources at the SNS, a Department of
   Energy (DOE) Office of Science User Facility operated by ORNL. Part of
   the research was sponsored by ExaLearn, an Exascale Computing Project,
   DOE. ORNL is managed by UT-Battelle LLC for DOE under Contract
   DE-AC05-00OR22725. We acknowledge the support by the Scientific
   Discovery through Advanced Computing (SciDAC) funded by U S Department
   of Energy, Office of Science, Advanced Scientific Computing Research
   through FASTMath Institutes. Portions of the diffuse scattering and SANS
   research were sponsored by the Laboratory Directed Research and
   Development Program of ORNL, managed by UT-Battelle, LLC, for the U S
   Department of Energy. The DTO work was run on the HPC resources of the
   OLCF. We acknowledge the contributions of B Sullivan, K Barros, C
   Batista, V Lynch, P Langan. We had useful discussion with J Y Y Lin, and
   Y-M Lee.
NR 66
TC 2
Z9 2
U1 6
U2 6
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
EI 2632-2153
J9 MACH LEARN-SCI TECHN
JI Mach. Learn.-Sci. Technol.
PD JUN
PY 2021
VL 2
IS 2
AR 023001
DI 10.1088/2632-2153/abcf88
PG 12
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Science & Technology - Other Topics
GA SR2NN
UT WOS:000660880200001
OA gold
DA 2022-04-17
ER

PT J
AU Sharma, T
   Shah, M
AF Sharma, Toshita
   Shah, Manan
TI A comprehensive review of machine learning techniques on diabetes
   detection
SO VISUAL COMPUTING FOR INDUSTRY BIOMEDICINE AND ART
LA English
DT Review
DE Machine learning; Deep learning; Health care; Diabetes detection
ID DISEASE; DIAGNOSIS; PREDICT; SYSTEM; ONSET; RISK
AB Diabetes mellitus has been an increasing concern owing to its high morbidity, and the average age of individual affected by of individual affected by this disease has now decreased to mid-twenties. Given the high prevalence, it is necessary to address with this problem effectively. Many researchers and doctors have now developed detection techniques based on artificial intelligence to better approach problems that are missed due to human errors. Data mining techniques with algorithms such as - density-based spatial clustering of applications with noise and ordering points to identify the cluster structure, the use of machine vision systems to learn data on facial images, gain better features for model training, and diagnosis via presentation of iridocyclitis for detection of the disease through iris patterns have been deployed by various practitioners. Machine learning classifiers such as support vector machines, logistic regression, and decision trees, have been comparative discussed various authors. Deep learning models such as artificial neural networks and recurrent neural networks have been considered, with primary focus on long short-term memory and convolutional neural network architectures in comparison with other machine learning models. Various parameters such as the root-mean-square error, mean absolute errors, area under curves, and graphs with varying criteria are commonly used. In this study, challenges pertaining to data inadequacy and model deployment are discussed. The future scope of such methods has also been discussed, and new methods are expected to enhance the performance of existing models, allowing them to attain greater insight into the conditions on which the prevalence of the disease depends.
C1 [Sharma, Toshita] Nirma Univ, Dept Elect & Commun Technol, Ahmadabad 382481, Gujarat, India.
   [Shah, Manan] Pandit Deendayal Energy Univ, Sch Technol, Dept Chem Engn, Gandhinagar 382426, Gujarat, India.
RP Shah, M (corresponding author), Pandit Deendayal Energy Univ, Sch Technol, Dept Chem Engn, Gandhinagar 382426, Gujarat, India.
EM manan.shah@spt.pdpu.ac.in
NR 58
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER SINGAPORE PTE LTD
PI SINGAPORE
PA #04-01 CENCON I, 1 TANNERY RD, SINGAPORE 347719, SINGAPORE
EI 2524-4442
J9 VIS COMPUT IND BIOME
JI Vis. Comput. Ind. Biomed. Art
PD DEC 3
PY 2021
VL 4
IS 1
AR 30
DI 10.1186/s42492-021-00097-7
PG 16
WC Computer Science, Interdisciplinary Applications; Engineering,
   Electrical & Electronic; Imaging Science & Photographic Technology
WE Emerging Sources Citation Index (ESCI)
SC Computer Science; Engineering; Imaging Science & Photographic Technology
GA XI4DO
UT WOS:000726064600002
PM 34862560
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Fu, RS
   Aseri, M
   Singh, P
   Srinivasan, K
AF Fu, Runshan
   Aseri, Manmohan
   Singh, ParamVir
   Srinivasan, Kannan
TI "Un"Fair Machine Learning Algorithms
SO MANAGEMENT SCIENCE
LA English
DT Article; Early Access
DE algorithmic bias; economics of arti; intelligence; fair machine
   learning; equal impact; equal treatment
ID DISPARATE-IMPACT; BIAS
AB Ensuring fairness in algorithmic decision making is a crucial policy issue. Current legislation ensures fairness by barring algorithm designers from using demographic information in their decision making. As a result, to be legally compliant, the algorithms need to ensure equal treatment. However, in many cases, ensuring equal treatment leads to disparate impact particularly when there are differences among groups based on demographic classes. In response, several "fair" machine learning (ML) algorithms that require impact parity (e.g., equal opportunity) at the cost of equal treatment have recently been proposed to adjust for the societal inequalities. Advocates of fair ML propose changing the law to allow the use of protected class-specific decision rules. We show that the proposed fair ML algorithms that require impact parity, while conceptually appealing, can make everyone worse off, including the very class they aim to protect. Compared with the current law, which requires treatment parity, the fair ML algorithms, which require impact parity, limit the benefits of a more accurate algorithm for a firm. As a result, profit maximizing firms could underinvest in learning, that is, improving the accuracy of their machine learning algorithms. We show that the investment in learning decreases when misclassification is costly, which is exactly the case when greater accuracy is otherwise desired. Our paper highlights the importance of considering strategic behavior of stake holders when developing and evaluating fair ML algorithms. Overall, our results indicate that fair ML algorithms that require impact parity, if turned into law, may not be able to deliver some of the anticipated benefits.
C1 [Fu, Runshan] Carnegie Mellon Univ, Heinz Coll, Pittsburgh, PA 15213 USA.
   [Aseri, Manmohan] Univ Pittsburgh, Joseph M Katz Grad Sch Business, Pittsburgh, PA 15260 USA.
   [Singh, ParamVir; Srinivasan, Kannan] Carnegie Mellon Univ, Tepper Sch Business, Pittsburgh, PA 15213 USA.
RP Fu, RS (corresponding author), Carnegie Mellon Univ, Heinz Coll, Pittsburgh, PA 15213 USA.
EM runshanf@cmu.edu; maseri@katz.pitt.edu; psidhu@cmu.edu; kannans@cmu.edu
OI Aseri, Manmohan/0000-0001-6943-2432
NR 27
TC 0
Z9 0
U1 30
U2 30
PU INFORMS
PI CATONSVILLE
PA 5521 RESEARCH PARK DR, SUITE 200, CATONSVILLE, MD 21228 USA
SN 0025-1909
EI 1526-5501
J9 MANAGE SCI
JI Manage. Sci.
DI 10.1287/mnsc.2021.4065
EA OCT 2021
PG 24
WC Management; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Business & Economics; Operations Research & Management Science
GA WL0PV
UT WOS:000710119200001
DA 2022-04-17
ER

PT J
AU Apsemidis, A
   Psarakis, S
   Moguerza, JM
AF Apsemidis, Anastasios
   Psarakis, Stelios
   Moguerza, Javier M.
TI A review of machine learning kernel methods in statistical process
   monitoring
SO COMPUTERS & INDUSTRIAL ENGINEERING
LA English
DT Review
DE Kernel methods; Support vector machines; Statistical process monitoring;
   Multivariate control charts; Machine learning
ID SUPPORT VECTOR MACHINE; CONTROL CHART PATTERNS; INDEPENDENT COMPONENT
   ANALYSIS; ARTIFICIAL NEURAL-NETWORKS; MULTIVARIATE CONTROL CHART;
   SINGULAR-SPECTRUM ANALYSIS; FAULT-DETECTION; VARIANCE SHIFTS; DETECTION
   SYSTEM; RECOGNITION
AB The complexity of modern problems turns increasingly larger in industrial environments, so the classical process monitoring techniques have to adapt to deal with those problems. This is one of the reasons why new Machine and Statistical Learning methodologies have become very popular in the statistical community. Specifically, this article is focused on machine learning kernel methods techniques in the process monitoring field. After explaining the idea of kernel methods we thoroughly examine the process monitoring articles that make use of kernel models and the way in which these models are combined with other Machine Learning approaches. Finally, we summarize the whole picture of the literature and mention some remarkable points.
C1 [Apsemidis, Anastasios; Psarakis, Stelios] Athens Univ Econ & Business, Dept Stat, Athens, Greece.
   [Moguerza, Javier M.] Rey Juan Carlos Univ, Sch Comp Sci, Madrid, Spain.
RP Apsemidis, A (corresponding author), Athens Univ Econ & Business, Dept Stat, Athens, Greece.
EM apsemidis@aueb.gr; psarakis@aueb.gr; javier.moguerza@urjc.es
RI Moguerza, Javier M./AAA-6836-2020; Psarakis, Stelios/AAJ-3023-2021
FU Spanish Ministry of Science, Innovation and Universities
   [MTM2015-63710-P, RTI2018-094269-B-I00]; Statistical Methodology Lab of
   the Department of Statistics of the Athens University of Economics
   Business
FX This work has been partially supported by projects of the Spanish
   Ministry of Science, Innovation and Universities GROMA (reference:
   MTM2015-63710-P) and MODAS-IN (reference: RTI2018-094269-B-I00) and the
   Statistical Methodology Lab of the Department of Statistics of the
   Athens University of Economics & Business.
NR 106
TC 17
Z9 18
U1 10
U2 45
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0360-8352
EI 1879-0550
J9 COMPUT IND ENG
JI Comput. Ind. Eng.
PD APR
PY 2020
VL 142
AR 106376
DI 10.1016/j.cie.2020.106376
PG 12
WC Computer Science, Interdisciplinary Applications; Engineering,
   Industrial
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LC5OA
UT WOS:000525375800050
DA 2022-04-17
ER

PT J
AU Herrera-Ibata, DM
AF Herrera-Ibata, Diana M.
TI Machine Learning and Perturbation Theory Machine Learning (PTML) in
   Medicinal Chemistry, Biotechnology, and Nanotechnology
SO CURRENT TOPICS IN MEDICINAL CHEMISTRY
LA English
DT Review
DE Perturbation theory; Machine learning; Drug discovery; Protein targets;
   New materials; ChEMBL
ID SUPPORT VECTOR MACHINES; RATIONAL DRUG DESIGN; IN-SILICO DISCOVERY;
   SIMULTANEOUS PREDICTION; AIDS EPIDEMIOLOGY; MULTIOUTPUT MODEL; COMPLEX
   NETWORKS; NEURAL-NETWORKS; QSAR; INHIBITORS
AB Recently, different authors have reported Perturbation Theory (PT) methods combined with machine learning (ML) to obtain PTML (PT + ML) models. They have applied PTML models to the study of different biological systems. Here we present one state-of-art review about the different applications of PTML models in Organic Synthesis, Medicinal Chemistry, Protein Research, and Technology. The aim of the models is to find relations between the molecular descriptors and the biological characteristics to predict key properties of new compounds. An area where the ML has been very useful is the drug discovery process. The entire process of drug discovery leads to the generation of lots of data, and it is also a costly and time-consuming process. ML comes with the opportunity of analyzing significant amounts of chemical data obtaining outcomes to find potential drug candidates.
C1 [Herrera-Ibata, Diana M.] Fdn Univ Agr Colombia, Fac Med Vet, Uniagr, Bogota 111166, Colombia.
RP Herrera-Ibata, DM (corresponding author), Fdn Univ Agr Colombia, Fac Med Vet, Uniagr, Bogota 111166, Colombia.
EM herrerai.diana@uniagraria.edu.co
NR 94
TC 0
Z9 0
U1 12
U2 21
PU BENTHAM SCIENCE PUBL LTD
PI SHARJAH
PA EXECUTIVE STE Y-2, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB
   EMIRATES
SN 1568-0266
EI 1873-5294
J9 CURR TOP MED CHEM
JI Curr. Top. Med. Chem.
PY 2021
VL 21
IS 7
BP 649
EP 660
DI 10.2174/1568026621666210121153413
PG 12
WC Chemistry, Medicinal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Pharmacology & Pharmacy
GA QX0JT
UT WOS:000629037100006
PM 33475073
DA 2022-04-17
ER

PT J
AU Alelyani, S
AF Alelyani, Salem
TI Detection and Evaluation of Machine Learning Bias
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE machine learning bias; bias detection; bias evaluation; KL divergence;
   explainable models; cognitive bias
ID INFORMATION
AB Machine learning models are built using training data, which is collected from human experience and is prone to bias. Humans demonstrate a cognitive bias in their thinking and behavior, which is ultimately reflected in the collected data. From Amazon's hiring system, which was built using ten years of human hiring experience, to a judicial system that was trained using human judging practices, these systems all include some element of bias. The best machine learning models are said to mimic humans' cognitive ability, and thus such models are also inclined towards bias. However, detecting and evaluating bias is a very important step for better explainable models. In this work, we aim to explain bias in learning models in relation to humans' cognitive bias and propose a wrapper technique to detect and evaluate bias in machine learning models using an openly accessible dataset from UCI Machine Learning Repository. In the deployed dataset, the potentially biased attributes (PBAs) are gender and race. This study introduces the concept of alternation functions to swap the values of PBAs, and evaluates the impact on prediction using KL divergence. Results demonstrate females and Asians to be associated with low wages, placing some open research questions for the research community to ponder over.
C1 [Alelyani, Salem] King Khalid Univ, Ctr Artificial Intelligence CAI, Abha 61421, Saudi Arabia.
   [Alelyani, Salem] King Khalid Univ, Coll Comp Sci, Abha 61421, Saudi Arabia.
RP Alelyani, S (corresponding author), King Khalid Univ, Ctr Artificial Intelligence CAI, Abha 61421, Saudi Arabia.; Alelyani, S (corresponding author), King Khalid Univ, Coll Comp Sci, Abha 61421, Saudi Arabia.
EM s.alelyani@kku.edu.sa
RI Alelyani, Salem/AAT-8273-2020
OI Alelyani, Salem/0000-0002-4571-9073
FU Deanship of Scientific Research at King Khalid University
   [P.G.P2/100/41]
FX This research was funded by The Deanship of Scientific Research at King
   Khalid University grant number (P.G.P2/100/41).
NR 37
TC 0
Z9 0
U1 9
U2 10
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD JUL
PY 2021
VL 11
IS 14
AR 6271
DI 10.3390/app11146271
PG 17
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Chemistry; Engineering; Materials Science; Physics
GA UC0CW
UT WOS:000686204500001
OA gold
DA 2022-04-17
ER

PT C
AU Vilim, M
   Rucker, A
   Zhang, YQ
   Liu, S
   Olukotun, K
AF Vilim, Matthew
   Rucker, Alexander
   Zhang, Yaqi
   Liu, Sophia
   Olukotun, Kunle
GP IEEE
TI Gorgon: Accelerating Machine Learning from Relational Data
SO 2020 ACM/IEEE 47TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA 2020)
SE ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE
LA English
DT Proceedings Paper
CT 47th ACM/IEEE Annual International Symposium on Computer Architecture
   (ISCA)
CY MAY 30-JUN 03, 2020
CL ELECTR NETWORK
SP IEEE, ACM, IEEE Comp Soc
DE database; machine learning; accelerator; CGRA; Plasticine; Gorgon
ID BIG DATA
AB Accelerator deployment in data centers remains limited despite domain-specific architectures' promise of higher performance. Rapidly-changing applications and high NRE cost make deploying fixed-function accelerators at scale untenable. More flexible than DSAS, FPGAS are gaining traction but remain hampered by cumbersome programming models, long synthesis times, and slow clocks. Coarse-grained reconfigurable architectures (CGRA) are a compelling alternative and offer efficiency while retaining programmability-by providing general-purpose hardware and communication patterns, a single CGRA targets multiple application domains.
   One emerging application is in-database machine learning: a high-performance, low-friction interface for analytics on large databases. We co-locate database and machine learning processing in a unified reconfigurable data analytics accelerator, Gorgon, which flexibly shares resources between DB and ML without compromising performance or incurring excessive overheads in either domain. We distill and integrate database parallel patterns into an existing ML-focused CGRA, increasing area by less than 4% while outperforming a multicore software baseline by 1500X. We also explore the performance impact of unifying DB and ML in a single accelerator, showing up to 4x speedup over split accelerators.
FU DARPAUnited States Department of DefenseDefense Advanced Research
   Projects Agency (DARPA) [FA8750-17-2-0095]; NSFNational Science
   Foundation (NSF) [1937301]; Herbert Kunzel Stanford Graduate Fellowship
FX This material is based on research sponsored by DARPA under agreement
   #FA8750-17-2-0095 and by NSF under award #1937301. The U.S Government is
   authorized to reproduce and distribute reprints for Governmental
   purposes not with standing any copyright notation theron. The views and
   conclusions contained herein are those of the authors and should not be
   interpreted as necessarily representing the offficial policies or
   endorsements,either expressed or implied, of DARPA,NSF, or the U.S.
   Government. This research is also supported in part by a Herbert Kunzel
   Stanford Graduate Fellowship and members of the Stanford DAWN project:
   Teradata, Facebook, Google, Ant Financial , NEC, VMWare, and Infosys.
NR 37
TC 4
Z9 4
U1 3
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
SN 0884-7495
BN 978-1-7281-4661-4
J9 ANN I S COM
PY 2020
BP 309
EP 321
DI 10.1109/ISCA45697.2020.00035
PG 13
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BQ7MY
UT WOS:000617734800024
DA 2022-04-17
ER

PT J
AU Li, Y
   Zeng, YJ
   Liu, TC
   Jia, XF
   Huang, GB
AF Li, Yue
   Zeng, Yijie
   Liu, Tianchi
   Jia, Xiaofan
   Huang, Guang-Bin
TI Simultaneously learning affinity matrix and data representations for
   machine fault diagnosis
SO NEURAL NETWORKS
LA English
DT Article
DE Extreme learning machine; Autoencoder; Geometry information; Affinity
   matrix learning; Representation learning; Machine fault diagnosis
AB Recently, preserving geometry information of data while learning representations have attracted increasing attention in intelligent machine fault diagnosis. Existing geometry preserving methods require to predefine the similarities between data points in the original data space. The predefined affinity matrix, which is also known as the similarity matrix, is then used to preserve geometry information during the process of representations learning. Hence, the data representations are learned under the assumption of a fixed and known prior knowledge, i.e., similarities between data points. However, the assumed prior knowledge is difficult to precisely determine the real relationships between data points, especially in high dimensional space. Also, using two separated steps to learn affinity matrix and data representations may not be optimal and universal for data classification. In this paper, based on the extreme learning machine autoencoder (ELM-AE), we propose to learn the data representations and the affinity matrix simultaneously. The affinity matrix is treated as a variable and unified in the objective function of ELM-AE. Instead of predefining and fixing the affinity matrix, the proposed method adjusts the similarities by taking into account its capability of capturing the geometry information in both original data space and non-linearly mapped representation space. Meanwhile, the geometry information of original data can be preserved in the embedded representations with the help of the affinity matrix. Experimental results on several benchmark datasets demonstrate the effectiveness of the proposed method, and the empirical study also shows it is an efficient tool on machine fault diagnosis. (c) 2019 Elsevier Ltd. All rights reserved.
C1 [Li, Yue; Zeng, Yijie; Liu, Tianchi; Jia, Xiaofan; Huang, Guang-Bin] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
RP Li, Y (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
EM liyu0024@e.ntu.edu.sg; yzeng004@e.ntu.edu.sg; liut0012@e.ntu.edu.sg;
   xiaofan002@e.ntu.edu.sg; egbhuang@ntu.edu.sg
OI LI, YUE/0000-0002-8519-2114
NR 34
TC 3
Z9 3
U1 4
U2 21
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0893-6080
EI 1879-2782
J9 NEURAL NETWORKS
JI Neural Netw.
PD FEB
PY 2020
VL 122
BP 395
EP 406
DI 10.1016/j.neunet.2019.11.007
PG 12
WC Computer Science, Artificial Intelligence; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Neurosciences & Neurology
GA JZ3SN
UT WOS:000505021700029
PM 31785540
DA 2022-04-17
ER

PT C
AU Soto, PC
   Ramzy, N
   Ocker, F
   Vogel-Heuser, B
AF Soto, Patricia Centeno
   Ramzy, Nour
   Ocker, Felix
   Vogel-Heuser, Birgit
GP IEEE
TI An ontology-based approach for preprocessing in machine learning
SO INES 2021: 2021 IEEE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT
   ENGINEERING SYSTEMS
SE IEEE International Conference on Intelligent Engineering Systems
LA English
DT Proceedings Paper
CT 25th IEEE International Conference on Intelligent Engineering Systems
   (INES)
CY JUL 07-09, 2021
CL Budapest, HUNGARY
SP IEEE, Obuda Univ, IEEE Hungary Sect, Hungarian Fuzzy Assoc, IEEE IES & RAS Joint Chapter, IEEE SMC Chapter, IEEE Control Syst Chapter, IEEE Ind Elect Soc
DE semantic preprocessing; machine learning; semantic web technologies
AB Increasing pressure on internationally operating companies leads to the application of novel technologies, e.g., Machine Learning models. However, Machine Learning algorithms require preprocessing, i.e., data cleaning, which is time consuming and requires domain-specific knowledge. Formalized knowledge bases capture such domain-specific knowledge in a computer-interpretable way and have the potential to reduce manual efforts for this process. This paper presents a framework for semantic preprocessing, which is evaluated at the example of an industrial use case from the semiconductor industry.
C1 [Soto, Patricia Centeno; Ramzy, Nour] Infineon Technol AG, Munich, Germany.
   [Ocker, Felix; Vogel-Heuser, Birgit] Tech Univ Munich, Inst Automat & Informat Syst, Munich, Germany.
RP Soto, PC (corresponding author), Infineon Technol AG, Munich, Germany.
EM Patricia.CentenoSoto@infineon.com; nour.ramzy@infineon.com;
   felix.ocker@tum.de; vogel-heuser@tum.de
NR 30
TC 0
Z9 0
U1 1
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1562-5850
BN 978-1-6654-4499-6
J9 IEEE INT CONF INTELL
PY 2021
DI 10.1109/INES52918.2021.9512899
PG 6
WC Computer Science, Interdisciplinary Applications; Engineering,
   Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BS3DC
UT WOS:000709774300021
DA 2022-04-17
ER

PT J
AU Dobbelaere, MR
   Plehiers, PP
   Van de Vijver, R
   Stevens, CV
   Van Geem, KM
AF Dobbelaere, Maarten R.
   Plehiers, Pieter P.
   van de Vijver, Ruben
   V. Stevens, Christian
   Van Geem, Kevin M.
TI Machine Learning in Chemical Engineering: Strengths, Weaknesses,
   Opportunities, and Threats
SO ENGINEERING
LA English
DT Article
DE Artificial intelligence; Machine learning; Reaction engineering; Process
   engineering
ID PRINCIPAL COMPONENT ANALYSIS; K-NEAREST-NEIGHBOR;
   ARTIFICIAL-INTELLIGENCE; MOLECULAR DESCRIPTORS; NEURAL-NETWORKS;
   UNCERTAINTY QUANTIFICATION; SOLVENT SELECTION; PREDICTION; CHEMISTRY;
   DRIVEN
AB Chemical engineers rely on models for design, research, and daily decision-making, often with potentially large financial and safety implications. Previous efforts a few decades ago to combine artificial intelligence and chemical engineering for modeling were unable to fulfill the expectations. In the last five years, the increasing availability of data and computational resources has led to a resurgence in machine learning-based research. Many recent efforts have facilitated the roll-out of machine learning techniques in the research field by developing large databases, benchmarks, and representations for chemical applications and new machine learning frameworks. Machine learning has significant advantages over traditional modeling techniques, including flexibility, accuracy, and execution speed. These strengths also come with weaknesses, such as the lack of interpretability of these black-box models. The greatest opportunities involve using machine learning in time-limited applications such as real-time optimization and planning that require high accuracy and that can build on models with a self-learning ability to recognize patterns, learn from data, and become more intelligent over time. The greatest threat in artificial intelligence research today is inappropriate use because most chemical engineers have had limited training in computer science and data analysis. Nevertheless, machine learning will definitely become a trustworthy element in the modeling toolbox of chemical engineers. (C) 2021 THE AUTHORS. Published by Elsevier LTD on behalf of Chinese Academy of Engineering and Higher Education Press Limited Company.
C1 [Dobbelaere, Maarten R.; Plehiers, Pieter P.; van de Vijver, Ruben; Van Geem, Kevin M.] Univ Ghent, Dept Mat Text & Chem Engn, Chem Technol Lab, B-9052 Ghent, Belgium.
   [V. Stevens, Christian] Univ Ghent, Fac Biosci Engn, Dept Green Chem & Technol, SynBioC Res Grp, B-9000 Ghent, Belgium.
RP Van Geem, KM (corresponding author), Univ Ghent, Dept Mat Text & Chem Engn, Chem Technol Lab, B-9052 Ghent, Belgium.
EM Kevin.VanGeem@UGent.be
RI Dobbelaere, Maarten/ABD-4954-2021; Van Geem, Kevin/J-3294-2014
OI Dobbelaere, Maarten/0000-0002-8977-8569; Van Geem,
   Kevin/0000-0003-4191-4960
FU European Research Council (ERC) under the European UnionEuropean
   Research Council (ERC) [818607]; Research Foundation-Flanders (FWO)FWO
   [1150817N, 3E013419]
FX The authors acknowledge funding from the European Research Council (ERC)
   under the European Union's Horizon 2020 research and innovation
   (818607). Pieter P. Plehiers and Ruben Van de Vijver acknowledge
   financial support, respectively, from a doctoral (1150817N) and a
   postdoctoral (3E013419) fellowship from the Research Foundation-Flanders
   (FWO).
NR 177
TC 4
Z9 4
U1 25
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2095-8099
EI 2096-0026
J9 ENGINEERING-PRC
JI Engineering
PD SEP
PY 2021
VL 7
IS 9
BP 1201
EP 1211
DI 10.1016/j.eng.2021.03.019
EA NOV 2021
PG 11
WC Engineering, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA WZ3LE
UT WOS:000719871700005
OA Green Published, gold
DA 2022-04-17
ER

PT J
AU Wang, S
   Balarezo, JF
   Kandeepan, S
   Al-Hourani, A
   Chavez, KG
   Rubinstein, B
AF Wang, Song
   Balarezo, Juan Fernando
   Kandeepan, Sithamparanathan
   Al-Hourani, Akram
   Chavez, Karina Gomez
   Rubinstein, Benjamin
TI Machine Learning in Network Anomaly Detection: A Survey
SO IEEE ACCESS
LA English
DT Article
DE Anomaly detection; Training; Machine learning; Prediction algorithms;
   Feature extraction; Predictive models; Security; Machine learning;
   anomaly detection; network security; software defined network; Internet
   of Things; cloud network
ID INTRUSION DETECTION SYSTEM; GENETIC ALGORITHM; FEATURE-SELECTION; ATTACK
   DETECTION; DDOS DETECTION; SECURITY; INTERNET; CLASSIFICATION; ENSEMBLE;
   ONLINE
AB Anomalies could be the threats to the network that have ever/never happened. To protect networks against malicious access is always challenging even though it has been studied for a long time. Due to the evolution of network in both new technologies and fast growth of connected devices, network attacks are getting versatile as well. Comparing to the traditional detection approaches, machine learning is a novel and flexible method to detect intrusions in the network, it is applicable to any network structure. In this paper, we introduce the challenges of anomaly detection in the traditional network, as well as in the next generation network, and review the implementation of machine learning in the anomaly detection under different network contexts. The procedure of each machine learning category is explained, as well as the methodologies and advantages are presented. The comparison of using different machine learning models is also summarised.
C1 [Wang, Song; Balarezo, Juan Fernando; Kandeepan, Sithamparanathan; Al-Hourani, Akram; Chavez, Karina Gomez] RMIT Univ, Sch Engn, Melbourne, Vic 3000, Australia.
   [Rubinstein, Benjamin] Univ Melbourne, Sch Comp & Informat Syst, Melbourne, Vic 3010, Australia.
RP Wang, S (corresponding author), RMIT Univ, Sch Engn, Melbourne, Vic 3000, Australia.
EM s3478896@student.rmit.edu.au
RI Al-Hourani, Akram/I-6907-2016
OI Al-Hourani, Akram/0000-0003-0652-8626; Sithamparanathan,
   Kandeepan/0000-0002-9388-9173; Balarezo Serrano, Juan
   Fernando/0000-0003-2717-7570
FU Australian Government Research Training Program ScholarshipAustralian
   GovernmentDepartment of Industry, Innovation and Science
FX The work of Song Wang and Juan Fernando Balarezo was supported by the
   Australian Government Research Training Program Scholarship.
NR 109
TC 0
Z9 0
U1 10
U2 10
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 152379
EP 152396
DI 10.1109/ACCESS.2021.3126834
PG 18
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA XA2UT
UT WOS:000720509400001
OA gold
DA 2022-04-17
ER

PT J
AU Steurtewagen, B
   Van den Poel, D
AF Steurtewagen, Bram
   Van den Poel, Dirk
TI Adding interpretability to predictive maintenance by machine learning on
   sensor data
SO COMPUTERS & CHEMICAL ENGINEERING
LA English
DT Article
DE Condition-based maintenance; Machine failure prediction; Machine
   diagnosis; Machine learning; Sensor data
ID OF-THE-ART; FAULT-DIAGNOSIS; BIG DATA; PROGNOSTICS; VIBRATION
AB Condition-based maintenance (CBM) is becoming more commonplace within the petrochemical industry. While we find that previous research leveraging machine learning has provided high accuracy in the predictive aspect of machine breakdowns, the diagnostic aspect of these approaches is often lacking. This paper implements a supervised machine learning approach, with the goal of both prediction and diagnosis of machinery breakdowns, emphasizing the latter. To achieve this, it uses an XGBoost model trained on a combination of sensor and report data, and enriches the model with Shapley values for diagnostic insights. We show that this combination of statistical methods, combined with a proper data treatment, can be used to great effect and can vastly improve the diagnostic value of machine learning approaches. The insights that follow from the analysis can subsequently be leveraged by plant operators in CBM strategies or root-cause analyses. (c) 2021 Elsevier Ltd. All rights reserved.
C1 [Steurtewagen, Bram; Van den Poel, Dirk] Univ Ghent, Dept MIO Data Analyt, Tweekerkenstr 2, B-9000 Ghent, Belgium.
RP Van den Poel, D (corresponding author), Univ Ghent, Dept MIO Data Analyt, Tweekerkenstr 2, B-9000 Ghent, Belgium.
EM dirk.vandenpoel@ugent.be
OI Steurtewagen, Bram/0000-0002-2206-2371; Van den Poel,
   Dirk/0000-0002-8676-8103
NR 47
TC 1
Z9 1
U1 6
U2 11
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0098-1354
EI 1873-4375
J9 COMPUT CHEM ENG
JI Comput. Chem. Eng.
PD SEP
PY 2021
VL 152
AR 107381
DI 10.1016/j.compchemeng.2021.107381
EA JUN 2021
PG 8
WC Computer Science, Interdisciplinary Applications; Engineering, Chemical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE7SU
UT WOS:000670208800014
DA 2022-04-17
ER

PT C
AU Lindsay, M
   Kovaleski, SD
   Veal, C
   Anderson, DT
   Price, SR
AF Lindsay, Marshall
   Kovaleski, Scott D.
   Veal, Charlie
   Anderson, Derek T.
   Price, Stanton R.
BE Tian, L
   Petruccelli, JC
   Preza, C
TI Machine Learning Assisted Holography
SO COMPUTATIONAL IMAGING VI
SE Proceedings of SPIE
LA English
DT Proceedings Paper
CT Conference on Computational Imaging VI
CY APR 12-16, 2021
CL ELECTR NETWORK
SP SPIE
DE Artificial neural network (ANN); holography; machine learning (ML);
   phase retrieval
ID PHASE RETRIEVAL
AB Computer-generated holography (CGH) has enabled the formation of arbitrary images through complex spatial light modulation. The optimization of spatial light modulators (SLMs) and diffractive optical elements (DOEs) is aimed to solve the well-known phase retrieval problem. This paper proposes a physically constrained artificial neural network (ANN) designed to solve the phase retrieval problem for CGH. We show that through careful selection of model structural parameters and by limiting the scope of model optimization, we can encode Fresnel Diffraction equations directly into an ANN. We train the proposed model under reasonable environment assumptions to overfit to a single image, i.e., the model finds the SLM phase delays required to produce the desired image. The proposed model performs well with outputs that qualitatively compare well with ideal images. The method proposed in this work holds value for those who require confidence that their machine learning techniques are physically realizable.
C1 [Lindsay, Marshall; Kovaleski, Scott D.; Veal, Charlie; Anderson, Derek T.] Univ Missouri, Elect Engn & Comp Sci Dept, Columbia, MO 65211 USA.
   [Price, Stanton R.] US Army Engineer Res & Dev Ctr, Vicksburg, MS 39180 USA.
RP Lindsay, M (corresponding author), Univ Missouri, Elect Engn & Comp Sci Dept, Columbia, MO 65211 USA.
EM mblgh6@umsystem.edu
FU  [W912HZ19C0007]
FX The experiments described and the resulting data presented herein,
   unless otherwise noted, were funded under Contract W912HZ19C0007,
   managed by the U.S. Army Engineer Research and Development Center. The
   work described in this document was conducted at the University of
   Missouri -Columbia. Permission was granted by the Director of the
   Geotechnical and Structures Laboratory to publish this information.
NR 21
TC 0
Z9 0
U1 3
U2 3
PU SPIE-INT SOC OPTICAL ENGINEERING
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA
SN 0277-786X
EI 1996-756X
BN 978-1-5106-4300-0
J9 PROC SPIE
PY 2021
VL 11731
AR 1173103
DI 10.1117/12.2585836
PG 9
WC Engineering, Electrical & Electronic; Optics; Imaging Science &
   Photographic Technology
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering; Optics; Imaging Science & Photographic Technology
GA BS1WW
UT WOS:000697278100002
DA 2022-04-17
ER

PT J
AU Miolane, N
   Guigui, N
   Le Brigant, A
   Mathe, J
   Hou, B
   Thanwerdas, Y
   Heyder, S
   Peltre, O
   Koep, N
   Zaatiti, H
   Hajri, H
   Cabanes, Y
   Gerald, T
   Chauchat, P
   Shewmake, C
   Brooks, D
   Kainz, B
   Donnat, C
   Holmes, S
   Pennec, X
AF Miolane, Nina
   Guigui, Nicolas
   Le Brigant, Alice
   Mathe, Johan
   Hou, Benjamin
   Thanwerdas, Yann
   Heyder, Stefan
   Peltre, Olivier
   Koep, Niklas
   Zaatiti, Hadi
   Hajri, Hatem
   Cabanes, Yann
   Gerald, Thomas
   Chauchat, Paul
   Shewmake, Christian
   Brooks, Daniel
   Kainz, Bernhard
   Donnat, Claire
   Holmes, Susan
   Pennec, Xavier
TI Geomstats: A Python Package for Riemannian Geometry in Machine Learning
SO JOURNAL OF MACHINE LEARNING RESEARCH
LA English
DT Article
DE differential geometry; Riemannian geometry; statistics; machine
   learning; manifold
ID MANIFOLDS
AB We introduce Geomstats, an open-source Python package for computations and statistics on nonlinear manifolds such as hyperbolic spaces, spaces of symmetric positive definite matrices, Lie groups of transformations, and many more. We provide object-oriented and extensively unit-tested implementations. Manifolds come equipped with families of Riemannian metrics with associated exponential and logarithmic maps, geodesics, and parallel transport. Statistics and learning algorithms provide methods for estimation, clustering, and dimension reduction on manifolds. All associated operations are vectorized for batch computation and provide support for different execution backends-namely NumPy, PyTorch, and TensorFlow. This paper presents the package, compares it with related libraries, and provides relevant code examples. We show that Geomstats provides reliable building blocks to both foster research in differential geometry and statistics and democratize the use of Riemannian geometry in machine learning applications.
EM NMIOLANE@STANFORD.EDU; NICOLAS.GUIGUI@INRIA.FR;
   ALICE.LE-BRIGANT@UNIV-PARIS1.FR; JOHAN@FROGLABS.AI;
   BENJAMIN.HOU11@IMPERIAL.AC.UK; YANN.THANWERDAS@INRIA.FR;
   STEFAN.HEYDER@TU-ILMENAU.DE; OPELTRE@GMAIL.COM; NIKLAS.KOEP@GMAIL.COM;
   HADI.ZAATITI@IRT-SYSTEMX.FR; HATEM.HAJRI@IRT-SYSTEMX.FR;
   YANN.CABANES@GMAIL.COM; THOMAS.GERALD@LIP6.FR; PCHAUCHAT@GMAIL.COM;
   CSHEWMAKE2@GMAIL.COM; JIMRIVERS75@GMAIL.COM; B.KAINZ@IMPERIAL.AC.UK;
   CDONNAT@STANFORD.EDU; SUSAN@STAT.STANFORD.EDU; XAVIER.PENNEC@INRIA.FR
RI Kainz, Bernhard/H-3416-2016; Pennec, Xavier/L-2537-2013
OI Kainz, Bernhard/0000-0002-7813-5023; Pennec, Xavier/0000-0002-6617-7664
FU National Science FoundationNational Science Foundation (NSF) [NSF DMS
   RTG 1501767]; European Research Council (ERC) under the EU Horizon 2020
   research and innovation programEuropean Research Council (ERC) [786854];
   French Government through the 3IA Cote d'Azur Investments in the Future
   project (National Research Agency) [ANR-19-P3IA-0002]
FX This work is partially supported by the National Science Foundation,
   grant NSF DMS RTG 1501767, the Inria-Stanford associated team GeomStats,
   the European Research Council (ERC) under the EU Horizon 2020 research
   and innovation program (grant agreement GStatistics No. 786854) and by
   the French Government through the 3IA Cote d'Azur Investments in the
   Future project (National Research Agency ANR-19-P3IA-0002).
NR 33
TC 7
Z9 7
U1 1
U2 3
PU MICROTOME PUBL
PI BROOKLINE
PA 31 GIBBS ST, BROOKLINE, MA 02446 USA
SN 1532-4435
J9 J MACH LEARN RES
JI J. Mach. Learn. Res.
PY 2020
VL 21
AR 223
PG 9
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA PP3CG
UT WOS:000605743600001
DA 2022-04-17
ER

PT J
AU Gupta, A
   Suri, B
   Kumar, V
   Jain, P
AF Gupta, Aakanshi
   Suri, Bharti
   Kumar, Vijay
   Jain, Pragyashree
TI Extracting rules for vulnerabilities detection with static metrics using
   machine learning
SO INTERNATIONAL JOURNAL OF SYSTEM ASSURANCE ENGINEERING AND MANAGEMENT
LA English
DT Article
DE Software metrics; Machine learning; Static code analysis; Supervised
   learning
AB Software quality is the prime solicitude in software engineering and vulnerability is one of the major threat in this respect. Vulnerability hampers the security of the software and also impairs the quality of the software. In this paper, we have conducted experimental research on evaluating the utility of machine learning algorithms to detect the vulnerabilities. To execute this experiment; a set of software metrics was extracted using machine learning in the form of easily accessible laws. Here, 32 supervised machine learning algorithms have been considered for 3 most occurred vulnerabilities namely:Lawofdemeter,BeanMemberShouldSerialize,andLocalVariablecouldBeFinalin a software system. Using the J48 machine learning algorithm in this research, up to 96% of accurate result in vulnerability detection was achieved. The results are validated against tenfold cross validation and also, the statistical parameters like ROC curve, Kappa statistics; Recall, Precision, etc. have been used for analyzing the result.
C1 [Gupta, Aakanshi] GGS Indraprastha Univ, ASET, New Delhi, India.
   [Suri, Bharti] GGS Indraprastha Univ, Univ Sch ICT, New Delhi, India.
   [Kumar, Vijay] Amity Univ Uttar Pradesh, Dept Math, Amity Inst Appl Sci, Noida, India.
   [Jain, Pragyashree] Amity Sch Engn & Technol, New Delhi, India.
RP Kumar, V (corresponding author), Amity Univ Uttar Pradesh, Dept Math, Amity Inst Appl Sci, Noida, India.
EM aakankshi@gmail.com; bhartisuri@gmail.com; vijay_parashar@yahoo.com;
   pragyashreejain14@gmail.com
RI KUMAR, VIJAY/Y-1353-2019
OI KUMAR, VIJAY/0000-0002-2996-7181
NR 27
TC 5
Z9 5
U1 0
U2 0
PU SPRINGER INDIA
PI NEW DELHI
PA 7TH FLOOR, VIJAYA BUILDING, 17, BARAKHAMBA ROAD, NEW DELHI, 110 001,
   INDIA
SN 0975-6809
EI 0976-4348
J9 INT J SYST ASSUR ENG
JI Int. J. Syst. Assur. Eng. Manag.
PD FEB
PY 2021
VL 12
IS 1
SI SI
BP 65
EP 76
DI 10.1007/s13198-020-01036-0
EA SEP 2020
PG 12
WC Engineering, Multidisciplinary
WE Emerging Sources Citation Index (ESCI)
SC Engineering
GA QF9NX
UT WOS:000568635800002
DA 2022-04-17
ER

PT J
AU Ma, YX
   Xie, TK
   Li, JD
   Maciejewski, R
AF Ma, Yuxin
   Xie, Tiankai
   Li, Jundong
   Maciejewski, Ross
TI Explaining Vulnerabilities to Adversarial Machine Learning through
   Visual Analytics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Adversarial machine learning; data poisoning; visual analytics
ID SECURITY; CLASSIFICATION; RECOGNITION; EXPLORATION; PROGRESS
AB Machine learning models are currently being deployed in a variety of real-world applications where model predictions are used to make decisions about healthcare, bank loans, and numerous other critical tasks. As the deployment of artificial intelligence technologies becomes ubiquitous, it is unsurprising that adversaries have begun developing methods to manipulate machine learning models to their advantage. While the visual analytics community has developed methods for opening the black box of machine learning models, little work has focused on helping the user understand their model vulnerabilities in the context of adversarial attacks. In this paper, we present a visual analytics framework for explaining and exploring model vulnerabilities to adversarial attacks. Our framework employs a multi-faceted visualization scheme designed to support the analysis of data poisoning attacks from the perspective of models, data instances, features, and local structures. We demonstrate our framework through two case studies on binary classifiers and illustrate model vulnerabilities with respect to varying attack strategies.
C1 [Ma, Yuxin; Xie, Tiankai; Maciejewski, Ross] Arizona State Univ, Sch Comp Informat & Decis Syst Engn, Tempe, AZ 85287 USA.
   [Li, Jundong] Univ Virginia, Dept Elect & Comp Engn, Charlottesville, VA 22903 USA.
RP Ma, YX (corresponding author), Arizona State Univ, Sch Comp Informat & Decis Syst Engn, Tempe, AZ 85287 USA.
EM yuxinma@asu.edu; txie21@asu.edu; jl6qk@virginia.edu; rmacieje@asu.edu
FU U.S.Department of Homeland SecurityUnited States Department of Homeland
   Security (DHS) [2017-ST-061-QA0001]
FX This work was supported by the U.S.Department of Homeland Security under
   Grant Award 2017-ST-061-QA0001. The views and conclusions contained in
   this document are those of the authors and should not be interpreted as
   necessarily representing the official policies, either expressed or
   implied, of the U.S. Department of Homeland Security.
NR 70
TC 20
Z9 22
U1 3
U2 21
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2020
VL 26
IS 1
BP 1075
EP 1085
DI 10.1109/TVCG.2019.2934631
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KB0CF
UT WOS:000506166100100
PM 31478859
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Liu, CF
   Feng, L
   Wang, HB
   Liu, SL
   Liu, KY
AF Liu, Caifeng
   Feng, Lin
   Wang, Huibing
   Liu, Shenglan
   Liu, Kaiyuan
TI Cascade regression based on extreme learning machine for face alignment
SO JOURNAL OF ELECTRONIC IMAGING
LA English
DT Article
DE face alignment; cascaded regression; extreme learning machine;
   incremental learning
AB Traditional face alignment based on machine learning usually tracks the localizations of facial landmarks employing a static model trained offline where all of the training data are available in advance. When new training samples arrive, the static model must be retrained from scratch, which is excessively time-consuming and memory-consuming. It results in the limitation of its performance on sequential images with extensive variations. Therefore, the most critical and challenging aspect in this field is how to enhance the predictive capability of pretrained model incrementally. To that end, a fast and accurate online learning algorithm for face alignment is proposed. Particularly, extreme learning machine (ELM) is incorporated into a parallel cascaded regression (CR) framework, which we coin parallel cascade regression based on extreme learning machine (CRELM). The proposed model can be fast updated in an incremental way. It has a stronger prediction capability than conventional CR methods. The experimental results demonstrate that the proposed model is more accurate and efficient on still images or videos compared with the recent state-of-the-art approaches. (C) 2020 SPIE and IS&T
C1 [Liu, Caifeng; Liu, Kaiyuan] Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian, Peoples R China.
   [Feng, Lin; Liu, Shenglan] Dalian Univ Technol, Sch Innovat & Entrepreneurship, Dalian, Peoples R China.
   [Wang, Huibing] Dalian Maritime Univ, Coll Informat Sci & Technol, Dalian, Peoples R China.
RP Feng, L (corresponding author), Dalian Univ Technol, Sch Innovat & Entrepreneurship, Dalian, Peoples R China.
EM fenglin@dlut.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61972064, 61672130, 61602082, 61627808,
   91648205]; Open Program of State Key Laboratory of Software Architecture
   [SKLSAOP1701]; Liaoning Revitalization Talents Program [XLYC1806006];
   Development of Science and Technology of Guangdong Province Special Fund
   Project [2016B090910001]
FX This work was supported by the National Natural Science Foundation of
   China (Grant Nos. 61972064, 61672130, 61602082, 61627808, and 91648205),
   the Open Program of State Key Laboratory of Software Architecture (Grant
   No. SKLSAOP1701), Liaoning Revitalization Talents Program (Grant No.
   XLYC1806006), and the Development of Science and Technology of Guangdong
   Province Special Fund Project (Grant No. 2016B090910001). The authors
   declare that they have no known competing financial interests or
   personal relationships that could have appeared to influence the work
   reported in this paper.
NR 44
TC 0
Z9 0
U1 1
U2 4
PU SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA
SN 1017-9909
EI 1560-229X
J9 J ELECTRON IMAGING
JI J. Electron. Imaging
PD JUL
PY 2020
VL 29
IS 4
AR 043002
DI 10.1117/1.JEI.29.4.043002
PG 16
WC Engineering, Electrical & Electronic; Optics; Imaging Science &
   Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Optics; Imaging Science & Photographic Technology
GA OH2AU
UT WOS:000582373000016
DA 2022-04-17
ER

PT J
AU Manco, L
   Maffei, N
   Strolin, S
   Vichi, S
   Bottazzi, L
   Strigari, L
AF Manco, Luigi
   Maffei, Nicola
   Strolin, Silvia
   Vichi, Sara
   Bottazzi, Luca
   Strigari, Lidia
TI Basic of machine learning and deep learning in imaging for medical
   physicists
SO PHYSICA MEDICA-EUROPEAN JOURNAL OF MEDICAL PHYSICS
LA English
DT Article
DE Imaging; Artificial intelligence; Machine Learning; deep Learning
ID ARTIFICIAL-INTELLIGENCE; NEURAL-NETWORK; CLASSIFICATION; CANCER;
   PREDICTION; ACCURACY; SYSTEM; MODEL
AB The manuscript aims at providing an overview of the published algorithms/automation tool for artificial intelligence applied to imaging for Healthcare. A PubMed search was performed using the query string to identify the proposed approaches (algorithms/automation tools) for artificial intelligence (machine and deep learning) in a 5year period. The distribution of manuscript in the various disciplines and the investigated image types according to the AI approaches are presented. The limitation and opportunity of AI application in the clinical practice or in the next future research is discussed.
C1 [Manco, Luigi; Maffei, Nicola] AOU Modena, Med Phys Unit, Modena, Italy.
   [Strolin, Silvia; Vichi, Sara; Strigari, Lidia] IRCCS Azienda Osped Univ Bologna, Med Phys Dept, Bologna, Italy.
   [Bottazzi, Luca] Univ Modena & Reggio Emilia, Phys Dept, Modena, Italy.
RP Strigari, L (corresponding author), IRCCS Azienda Osped Univ Bologna, Med Phys Dept, Bologna, Italy.
EM lidia.strigari@aosp.bo.it
RI Strolin, Silvia/AAC-3716-2022; Strigari, Lidia/B-9352-2017; Manco,
   Luigi/K-2712-2018
OI Strigari, Lidia/0000-0003-4293-2298; Bottazzi, Luca/0000-0002-2018-2249;
   Manco, Luigi/0000-0001-9338-8638
FU Associazione Italiana per la Ricerca sul Cancro (AIRC)Fondazione AIRC
   per la ricerca sul cancro [20809]
FX This study was partially supported by Associazione Italiana per la
   Ricerca sul Cancro (AIRC) to LS (IG 2017 ID. 20809) .
NR 187
TC 5
Z9 5
U1 13
U2 20
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1120-1797
EI 1724-191X
J9 PHYS MEDICA
JI Phys. Medica
PD MAR
PY 2021
VL 83
BP 194
EP 205
DI 10.1016/j.ejmp.2021.03.026
EA APR 2021
PG 12
WC Radiology, Nuclear Medicine & Medical Imaging
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Radiology, Nuclear Medicine & Medical Imaging
GA SM6KU
UT WOS:000657712600006
PM 33826964
DA 2022-04-17
ER

PT J
AU Saiz-Manzanares, MC
   Marticorena-Sanchez, R
   Ochoa-Orihuel, J
AF Saiz-Manzanares, Maria Consuelo
   Marticorena-Sanchez, Raul
   Ochoa-Orihuel, Javier
TI Using Advanced Learning Technologies with University Students: An
   Analysis with Machine Learning Techniques
SO ELECTRONICS
LA English
DT Article
DE advanced learning technologies; LMS; machine learning; self-regulated
   learning
ID SYSTEMS
AB The use of advanced learning technologies (ALT) techniques in learning management systems (LMS) allows teachers to enhance self-regulated learning and to carry out the personalized monitoring of their students throughout the teaching-learning process. However, the application of educational data mining (EDM) techniques, such as supervised and unsupervised machine learning, is required to interpret the results of the tracking logs in LMS. The objectives of this work were (1) to determine which of the ALT resources would be the best predictor and the best classifier of learning outcomes, behaviours in LMS, and student satisfaction with teaching; (2) to determine whether the groupings found in the clusters coincide with the students' group of origin. We worked with a sample of third-year students completing Health Sciences degrees. The results indicate that the combination of ALT resources used predict 31% of learning outcomes, behaviours in the LMS, and student satisfaction. In addition, student access to automatic feedback was the best classifier. Finally, the degree of relationship between the source group and the found cluster was medium (C = 0.61). It is necessary to include ALT resources and the greater automation of EDM techniques in the LMS to facilitate their use by teachers.
C1 [Saiz-Manzanares, Maria Consuelo] Univ Burgos, Fac Ciencias Salud, Dept Ciencias Salud, Res Grp DATAHES, P Comendadores S-N, Burgos 09001, Spain.
   [Marticorena-Sanchez, Raul; Ochoa-Orihuel, Javier] Univ Burgos, Dept Ingn Informat, Escuela Politecn Super, Res Grp ADMIRABLE, Avda Cantabria S-N, Burgos 09006, Spain.
RP Saiz-Manzanares, MC (corresponding author), Univ Burgos, Fac Ciencias Salud, Dept Ciencias Salud, Res Grp DATAHES, P Comendadores S-N, Burgos 09001, Spain.
EM mcsmanzanares@ubu.es; rmartico@ubu.es; joo0003@alu.ubu.es
RI MANZANARES, MARIA CONSUELO SAIZ/K-9765-2014
OI MANZANARES, MARIA CONSUELO SAIZ/0000-0002-1736-2089; Marticorena
   Sanchez, Raul/0000-0002-2633-635X; Ochoa, Javier/0000-0002-1904-9854
FU MINISTERIO DE CIENCIA E INNOVACIONInstituto de Salud Carlos IIISpanish
   GovernmentEuropean Commission [PID2020-117111RB-I00]
FX This research was funded by the MINISTERIO DE CIENCIA E INNOVACION,
   grant number PID2020-117111RB-I00.
NR 50
TC 0
Z9 0
U1 5
U2 5
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2079-9292
J9 ELECTRONICS-SWITZ
JI Electronics
PD NOV
PY 2021
VL 10
IS 21
AR 2620
DI 10.3390/electronics10212620
PG 16
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Physics
GA XA1ZO
UT WOS:000720454300001
OA gold
DA 2022-04-17
ER

PT J
AU Lu, HF
   Iseley, T
   Matthews, J
   Liao, W
AF Lu, Hongfang
   Iseley, Tom
   Matthews, John
   Liao, Wei
TI Hybrid machine learning for pullback force forecasting during horizontal
   directional drilling
SO AUTOMATION IN CONSTRUCTION
LA English
DT Article
DE Horizontal directional drilling; Pullback force; Forecasting; Machine
   learning; Support vector machine; Multi-objective optimizer
ID SUPPORT VECTOR MACHINES; PULLING FORCES; SVM; PREDICTION; MODEL
AB This paper presents a hybrid machine learning model for predicting the pullback force in horizontal directional drilling (HDD) construction. The model combines the nondominated sorting genetic algorithm II (NSGA-II) and support vector machine (SVM). NSGA-II is used to optimize two hyperparameters in SVM. Different from other optimization algorithms, NSGA-II is a multi-objective optimizer, which considers prediction accuracy and stability. The proposed model is applied to two practical HDD projects in China. The prediction result is compared with the actual monitoring data, which shows that the mean absolute percentage errors (MAPE) are less than 7%. The primary conclusions are as follows: (1) The proposed model's accuracy and stability are better than those of the two benchmark models; (2) Machine learning models can predict the pullback force more accurately than the empirical model in the construction phase, and the maximum MAPE does not exceed 17%; (3) The running time of the proposed model is short, and it is feasible in practical application. Moreover, this paper discusses the practical application of machine learning models in HDD construction and the future development direction.
C1 [Lu, Hongfang] Southeast Univ, Sch Civil Engn, Nanjing 211189, Peoples R China.
   [Iseley, Tom; Liao, Wei] Purdue Univ, Construct Engn & Management, W Lafayette, IN 47907 USA.
   [Matthews, John] Louisiana Tech Univ, Trenchless Technol Ctr, Ruston, LA 71270 USA.
RP Lu, HF (corresponding author), Southeast Univ, Sch Civil Engn, Nanjing 211189, Peoples R China.
EM luhongfang@seu.edu.cn
OI Lu, Hongfang/0000-0002-5172-9008; Matthews, John/0000-0002-1478-5182
FU National Key Research and Development Program of China [2016YFE0200500];
   Fundamental Research Funds for the Central UniversitiesFundamental
   Research Funds for the Central Universities
FX This work is funded by The National Key Research and Development Program
   of China (2016YFE0200500) , The Fundamental Research Funds for the
   Central Universities.
NR 44
TC 7
Z9 7
U1 12
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0926-5805
EI 1872-7891
J9 AUTOMAT CONSTR
JI Autom. Constr.
PD SEP
PY 2021
VL 129
AR 103810
DI 10.1016/j.autcon.2021.103810
EA JUN 2021
PG 12
WC Construction & Building Technology; Engineering, Civil
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Construction & Building Technology; Engineering
GA UD5XB
UT WOS:000687278400006
DA 2022-04-17
ER

PT J
AU Maccarrone, G
   Morelli, G
   Spadaccini, S
AF Maccarrone, Giovanni
   Morelli, Giacomo
   Spadaccini, Sara
TI GDP Forecasting: Machine Learning, Linear or Autoregression?
SO FRONTIERS IN ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE k nearest neighborhood; machine learning; time series; GDP; forecasting
   strategies
ID YIELD CURVE; TERM STRUCTURE; SERIES; US
AB This paper compares the predictive power of different models to forecast the real U.S. GDP. Using quarterly data from 1976 to 2020, we find that the machine learning K-Nearest Neighbour (KNN) model captures the self-predictive ability of the U.S. GDP and performs better than traditional time series analysis. We explore the inclusion of predictors such as the yield curve, its latent factors, and a set of macroeconomic variables in order to increase the level of forecasting accuracy. The predictions result to be improved only when considering long forecast horizons. The use of machine learning algorithm provides additional guidance for data-driven decision making.
C1 [Maccarrone, Giovanni] Sapienza Univ Rome, Dept Econ & Social Sci, Rome, Italy.
   [Morelli, Giacomo] Sapienza Univ Rome, Dept Stat Sci, Rome, Italy.
   [Spadaccini, Sara] Sapienza Univ Rome, Dept Methods & Models Econ Terr & Finance, Rome, Italy.
   [Spadaccini, Sara] Enel Global Serv Srl, Global Data Hub, Rome, Italy.
RP Morelli, G (corresponding author), Sapienza Univ Rome, Dept Stat Sci, Rome, Italy.
EM giacomo.morelli@uniroma1.it
OI SPADACCINI, SARA/0000-0002-0571-5262
NR 39
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2624-8212
J9 FRONT ARTIF INTELL
JI Front. Artif. Intell.
PY 2021
VL 4
AR 757864
DI 10.3389/frai.2021.757864
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA YT9WW
UT WOS:000751704800164
PM 34723174
OA gold, Green Published
DA 2022-04-17
ER

PT J
AU Crowson, MG
   Lin, V
   Chen, JM
   Chan, TCY
AF Crowson, Matthew G.
   Lin, Vincent
   Chen, Joseph M.
   Chan, Timothy C. Y.
TI Machine Learning and Cochlear Implantation-A Structured Review of
   Opportunities and Challenges
SO OTOLOGY & NEUROTOLOGY
LA English
DT Article; Proceedings Paper
CT 16th Symposium on Cochlear Implants in Children (CI)
CY JUL, 2019
CL Hollywood, FL
DE Artificial; intelligence; Cochlear implantation; Machine learning
ID ARTIFICIAL NEURAL-NETWORKS; SPEECH-INTELLIGIBILITY; AUTOMATIC
   SEGMENTATION; FORMULATION PARAMETERS; PERCEPTION; CHANNEL; SYSTEM;
   NOISE; ROBOT; AUTONRT(TM)
AB Objective: The use of machine learning technology to automate intellectual processes and boost clinical process efficiency in medicine has exploded in the past 5 years. Machine learning excels in automating pattern recognition and in adapting learned representations to new settings. Moreover, machine learning techniques have the advantage of incorporating complexity and are free from many of the limitations of traditional deterministic approaches. Cochlear implants (CI) are a unique fit for machine learning techniques given the need for optimization of signal processing to fit complex environmental scenarios and individual patients' CI MAPping. However, there are many other opportunities where machine learning may assist in CI beyond signal processing. The objective of this review was to synthesize past applications of machine learning technologies for pediatric and adult CI and describe novel opportunities for research and development.
   Data Sources: The PubMed/MEDLINE, EMBASE, Scopus, and ISI Web of Know-ledge databases were mined using a directed search strategy to identify the nexus between CI and artificial intelligence/machine learning literature.
   Study Selection: Non-English language articles, articles without an available abstract or full-text, and nonrelevant articles were manually appraised and excluded. Included articles were evaluated for specific machine learning methodologies, content, and application success.
   Data Synthesis: The database search identified 298 articles. Two hundred fifty-nine articles (86.9%) were excluded based on the available abstract/full-text, language, and relevance. The remaining 39 articles were included in the review analysis. There was a marked increase in year-over-year publications from 2013 to 2018. Applications of machine learning technologies involved speech/signal processing optimization (17; 43.6% of articles), automated evoked potential measurement (6; 15.4%), postoperative performance/efficacy prediction (5; 12.8%), and surgical anatomy location prediction (3; 7.7%), and 2 (5.1%) in each of robotics, electrode placement performance, and biomaterials performance.
   Conclusion: The relationship between Cl and artificial intelligence is strengthening with a recent increase in publications reporting successful applications. Considerable effort has been directed toward augmenting signal processing and automating postoperative MAPping using machine learning algorithms. Other promising applications include augmenting CI surgery mechanics and personalized medicine approaches for boosting CI patient performance. Future opportunities include addressing scalahility and the research and clinical communities' acceptance of machine learning algorithms as effective techniques.
C1 [Crowson, Matthew G.; Lin, Vincent; Chen, Joseph M.] Univ Toronto, Sunnybrook Hlth Sci Ctr, Dept Otolaryngol HNS, Toronto, ON, Canada.
   [Chan, Timothy C. Y.] Univ Toronto, Dept Mech & Ind Engn, Toronto, ON, Canada.
RP Crowson, MG (corresponding author), Sunnybrook Hlth Sci Ctr, Dept Otolaryngol HNS, 2075 Bayview Ave, Toronto, ON M4N 3M5, Canada.
EM matthew.g.crowson@gmail.com
RI Crowson, Matthew/X-6751-2019
OI Crowson, Matthew/0000-0001-9950-0985
NR 45
TC 6
Z9 7
U1 0
U2 8
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 1531-7129
EI 1537-4505
J9 OTOL NEUROTOL
JI Otol. Neurotol.
PD JAN
PY 2020
VL 41
IS 1
BP E36
EP E45
DI 10.1097/MAO.0000000000002440
PG 10
WC Clinical Neurology; Otorhinolaryngology
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Neurosciences & Neurology; Otorhinolaryngology
GA KF2QL
UT WOS:000509092400006
PM 31644477
DA 2022-04-17
ER

PT J
AU Alcazar, J
   Leyton-Ortega, V
   Perdomo-Ortiz, A
AF Alcazar, Javier
   Leyton-Ortega, Vicente
   Perdomo-Ortiz, Alejandro
TI Classical versus quantum models in machine learning: insights from a
   finance application
SO MACHINE LEARNING-SCIENCE AND TECHNOLOGY
LA English
DT Article
DE quantum finance; quantum machine learning; generative models;
   unsupervised machine learning
AB Although several models have been proposed towards assisting machine learning (ML) tasks with quantum computers, a direct comparison of the expressive power and efficiency of classical versus quantum models for datasets originating from real-world applications is one of the key milestones towards a quantum ready era. Here, we take a first step towards addressing this challenge by performing a comparison of the widely used classical ML models known as restricted Boltzmann machines (RBMs), against a recently proposed quantum model, now known as quantum circuit Born machines (QCBMs). Both models address the same hard tasks in unsupervised generative modeling, with QCBMs exploiting the probabilistic nature of quantum mechanics and a candidate for near-term quantum computers, as experimentally demonstrated in three different quantum hardware architectures to date. To address the question of the performance of the quantum model on real-world classical data sets, we construct scenarios from a probabilistic version out of the well-known portfolio optimization problem in finance, by using time-series pricing data from asset subsets of the S&P500 stock market index. It is remarkable to find that, under the same number of resources in terms of parameters for both classical and quantum models, the quantum models seem to have superior performance on typical instances when compared with the canonical training of the RBMs. Our simulations are grounded on a hardware efficient realization of the QCBMs on ion-trap quantum computers, by using their native gate sets, and therefore readily implementable in near-term quantum devices.
C1 [Alcazar, Javier; Perdomo-Ortiz, Alejandro] Zapata Comp Canada Inc, 1 Yonge St,Suite 900, Toronto, ON M5E 1E5, Canada.
   [Alcazar, Javier] Natl Australia Bank, 88 Wood St, London EC2V 7QQ, England.
   [Leyton-Ortega, Vicente] Oak Ridge Natl Lab, Comp Sci & Engn Div, One Bethel Valley Rd, Oak Ridge, TN 37831 USA.
   [Leyton-Ortega, Vicente; Perdomo-Ortiz, Alejandro] Rigetti Comp, 2919 Seventh St, Berkeley, CA 94710 USA.
   [Perdomo-Ortiz, Alejandro] UCL, Dept Comp Sci, London WC1E 6BT, England.
RP Perdomo-Ortiz, A (corresponding author), Zapata Comp Canada Inc, 1 Yonge St,Suite 900, Toronto, ON M5E 1E5, Canada.; Perdomo-Ortiz, A (corresponding author), Rigetti Comp, 2919 Seventh St, Berkeley, CA 94710 USA.; Perdomo-Ortiz, A (corresponding author), UCL, Dept Comp Sci, London WC1E 6BT, England.
EM alejandro@zapatacomputing.com
RI Perdomo-Ortiz, Alejandro/B-4753-2009
OI Perdomo-Ortiz, Alejandro/0000-0001-7176-4719
FU ASCR Quantum Testbed Pathfinder Program at Oak Ridge National Laboratory
   under FWP [ERKJ332]
FX The authors would like to acknowledge Marcello Benedetti, Dax Koh, and
   Yudong Cao for useful feedback on an early version of this manuscript.
   V.L-O was supported by ASCR Quantum Testbed Pathfinder Program at Oak
   Ridge National Laboratory under FWP #ERKJ332.
NR 39
TC 8
Z9 8
U1 6
U2 8
PU IOP Publishing Ltd
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
EI 2632-2153
J9 MACH LEARN-SCI TECHN
JI Mach. Learn.-Sci. Technol.
PD SEP
PY 2020
VL 1
IS 3
AR 035003
DI 10.1088/2632-2153/ab9009
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Multidisciplinary Sciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Science & Technology - Other Topics
GA SR2EQ
UT WOS:000660857100001
OA Green Submitted, gold
DA 2022-04-17
ER

PT C
AU Vinothina, V
   Prathap, G
AF Vinothina, V.
   Prathap, G.
BE Bhateja, V
   Satapathy, SC
   Zhang, YD
   Aradhya, VNM
TI EVaClassifier Using Linear SVM Machine Learning Algorithm
SO INTELLIGENT COMPUTING AND COMMUNICATION, ICICC 2019
SE Advances in Intelligent Systems and Computing
LA English
DT Proceedings Paper
CT 3rd International Conference on Intelligent Computing and Communication
   (ICICC)
CY JUN 07-08, 2019
CL Dayananda Sagar Univ, Sch Engn, Bengaluru, INDIA
HO Dayananda Sagar Univ, Sch Engn
DE Support vector machine; Answer script evaluation; Supervised machine
   learning; Linear kernel; Java
AB Evaluating descriptive answer scripts is one of the challenging tasks for academicians along with their routine works and increase in the number of students enrolling in educational institution. It involves various factors such as man power, time, cost, and mental health. These factors are directly proportional to students' strengths. Hence, evaluation scheme needs to be automated to ease the work of staff. Many research activities have been carried out to automate the evaluation process and easier the work of staff. In this paper, an attempt is made to propose two classes Eva classifier using Support Vector Machine Supervised Machine Learning algorithm for auto evaluating short answers and performance of the classifier is evaluated using accuracy of answer classification.
C1 [Vinothina, V.; Prathap, G.] Kristu Jayanti Coll Autonomous, Dept Comp Sci, Bengaluru, India.
RP Vinothina, V (corresponding author), Kristu Jayanti Coll Autonomous, Dept Comp Sci, Bengaluru, India.
EM Vinothina.v@kristujayanti.com
NR 11
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER-VERLAG SINGAPORE PTE LTD
PI SINGAPORE
PA 152 BEACH ROAD, #21-01/04 GATEWAY EAST, SINGAPORE, 189721, SINGAPORE
SN 2194-5357
EI 2194-5365
BN 978-981-15-1084-7; 978-981-15-1083-0
J9 ADV INTELL SYST COMP
PY 2020
VL 1034
BP 503
EP 509
DI 10.1007/978-981-15-1084-7_48
PG 7
WC Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Imaging Science & Photographic Technology
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Imaging Science & Photographic Technology
GA BR6CS
UT WOS:000659665100048
DA 2022-04-17
ER

PT J
AU Rodrigues, F
   Rodrigues, FA
   Rodrigues, TVR
AF Rodrigues, Fabiano
   Rodrigues, Francisco Aparecido
   Rocha Rodrigues, Thelma Valeria
TI MACHINE LEARNING MODELS FOR PREDICTING SUCCESS OF STARTUPS
SO REVISTA DE GESTAO E PROJETOS
LA Portuguese
DT Article
DE Startup success prediction; Machine learning; Investment in startups;
   Crunchbase platform
AB This study analyzes results from machine learning models to predict the success of startups. As a proxy for success, we considered the investor's perspective, according to which startup buyout or IPO (Initial Public Offering) are ways to recover the investment. The literature review addresses startups and funding mechanisms, previous studies on prediction of startup success via machine learning models, and trade-offs between machine learning techniques. The empirical study comprised a quantitative research based on secondary data from the American Crunchbase platform, with startups from 171 countries. The research design used as filter startups founded between June/2010 and June/2015, as well as a prediction window from June/2015 to June/2020 to predict startup success. The final sample, after the data preprocessing stage, comprised 18,571 startups. Six binary classification models were used for success prediction: Logistic Regression, Decision Tree, Random Forest, Extreme Gradient Boosting, Support Vector Machine, and Neural Networks. In the end, the Random Forest and Extreme Gradient Boosting models had the best performance in the classification task. This article involving machine learning and startups contributes to research in hybrid fields by combining perspectives from Business and Data Science. Additionally, it contributes to investors with a tool for initial mapping of startups in search of targets with greater probability of success.
EM frodrigues@espm.br; franscisco@icmc.usp.br; tvrocha@espm.br
NR 26
TC 0
Z9 0
U1 17
U2 25
PU UNIV NOVE JULHO
PI SAO PAULO
PA AV FRANCISCO MATARAZZO 612, AGUA BRANCA, SAO PAULO, C05001-100, BRAZIL
SN 2236-0972
J9 REV GES PROJ
JI Rev. Gest. Proj.
PD MAY-AUG
PY 2021
VL 12
IS 2
BP 28
EP 55
DI 10.5585/gep.v12i2.18942
PG 28
WC Business
WE Emerging Sources Citation Index (ESCI)
SC Business & Economics
GA SS6RC
UT WOS:000661881700003
OA Green Published, gold
DA 2022-04-17
ER

PT C
AU TayebiHaghighi, S
   Koo, I
AF TayebiHaghighi, Shahnaz
   Koo, Insoo
GP IEEE
TI Fault Diagnosis of Rotating Machine Using an Indirect Observer and
   Machine Learning
SO 11TH INTERNATIONAL CONFERENCE ON ICT CONVERGENCE: DATA, NETWORK, AND AI
   IN THE AGE OF UNTACT (ICTC 2020)
SE International Conference on Information and Communication Technology
   Convergence
LA English
DT Proceedings Paper
CT 11th International Conference on Information and Communication
   Technology Convergence (ICTC) - Data, Network, and AI in the age of
   Untact (ICTC)
CY OCT 21-23, 2020
CL Jeju, SOUTH KOREA
SP Korean Inst Commun & Informat Sci, IEEE Commun Soc, IEICE Commun Soc, Minist Sci & ICT, Elect & Telecommunicat Res Inst, Korean Federat Sci & Technol Soc, Samsung Elect, LG Elect, SK Telecom, LGU+, KT, SOLiD, FRTek, Huawei, Ericsson LG, ICT Convergence Korea Forum, Soc Safety Syst Forum, 5G Based Smart Factory Standardizat Forum, Jeju Convent & Visitors Bur, Korea Assoc Photon Ind Dev
DE fault diagnosis; machine learning; proportional multi integral observer;
   support vector machine; sliding mode fault observer; rotating machine
ID SYSTEMS
AB Bearing is one of the important mechanical components to reduce friction in rotating machines. Early fault diagnosis in bearings is an important challenge to the prevention of full failure and avoiding disorder of the machine. In this paper, an indirect observer and machine learning technique are adopted for fault identification in bearing. To develop an indirect observer, in the first step, the autoregressive with uncertainty modeling technique is proposed to modeling the RMS (indirect) normal signal of bearing. After that, the robust (sliding fault detection) proportional multi integral with autoregressive external input modeling (ARPMI) observer was used to solve the unknown signal estimation in bearing. Besides, the support vector machine (SVM) technique for fault classification is proposed. The effectiveness of the proposed scheme is validated using Case Western Reverse University (CWRU) dataset. Experimental results show that, the proposed scheme improves the average performance for various rotational speed fault identification by about 10.5% and 13.5% compared with the proportional multi integral with autoregressive external input modeling (APMI) observer and proportional-integral with autoregressive external input modeling (API) observer, respectively.
C1 [TayebiHaghighi, Shahnaz; Koo, Insoo] Univ Ulsan, Dept Elect Elect & Comp Engn, Ulsan, South Korea.
RP Koo, I (corresponding author), Univ Ulsan, Dept Elect Elect & Comp Engn, Ulsan, South Korea.
EM tayebinazi74@gmail.com; iskoo@ulsan.ac.kr
FU National Research Foundation of tion in industries, Korea (NRF) grant
   through the Korean Government (MSIT) [NRF-2018R1A2B6001714]
FX This work was supported by the National Research Foundation of tion in
   industries, Korea (NRF) grant through the Korean Government (MSIT) under
   Grant NRF-2018R1A2B6001714.
NR 17
TC 1
Z9 1
U1 2
U2 2
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2162-1233
BN 978-1-7281-6758-9
J9 I C INF COMM TECH CO
PY 2020
BP 277
EP 282
PG 6
WC Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering
GA BS1LP
UT WOS:000692529100067
DA 2022-04-17
ER

PT C
AU Ma, Q
   Tsukagoshi, M
   Murata, M
AF Ma, Qing
   Tsukagoshi, Miran
   Murata, Masaki
BE Lu, Y
   Dong, M
   Soon, LK
   Gan, KH
TI Estimating Evaluation of Cosmetics Reviews with Machine Learning Methods
SO 2020 INTERNATIONAL CONFERENCE ON ASIAN LANGUAGE PROCESSING (IALP 2020)
SE International Conference on Asian Language Processing
LA English
DT Proceedings Paper
CT International Conference on Asian Language Processing (IALP)
CY DEC 04-06, 2020
CL ELECTR NETWORK
SP Monash Univ, Chinese & Oriental Languages Informat Proc Soc, IEEE Singapore Sect, IEEE, IEEE Singapore SMC Chapter
DE cosmetics review; evaluation; machine learning; dependency analysis
AB This paper presents methods for estimating evaluation of cosmetics reviews, i.e., for assigning scores to cosmetics reviews, by using three kinds of machine learning methods: support vector machine (SVM), stacked denoising autoencoder (SdA), and convolutional neural network (CNN). The experimental results show that (1) using words with various parts of speech (POSs), not only nouns, as features in vectorizing review text is effective, (2) selecting features on the basis of dependency analysis is effective, (3) the three machine learning methods have almost the same estimation precision and are much higher than a rule-based baseline method, and (4) the training cost of SVM is extremely lower than the other two methods, and SVM therefore performs the best among the three methods.
C1 [Ma, Qing; Tsukagoshi, Miran] Ryukoku Univ, Dept Appl Math & Informat, Otsu, Shiga, Japan.
   [Murata, Masaki] Tottori Univ, Dept Informat & Elect, Tottori, Japan.
RP Ma, Q (corresponding author), Ryukoku Univ, Dept Appl Math & Informat, Otsu, Shiga, Japan.
EM qma@math.ryukoku.ac.jp; ryukoku.miran.tsukagoshi@gmail.com;
   murata@tottori-u.ac.jp
FU JSPS KAKENHIMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) [19K12241]
FX This work was supported by JSPS KAKENHI Grant Number 19K12241.
NR 12
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2159-1962
EI 2159-1970
BN 978-1-7281-7689-5
J9 INT CONF ASIAN LANG
PY 2020
BP 259
EP 263
PG 5
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR4SS
UT WOS:000653101300047
DA 2022-04-17
ER

PT J
AU Jebeile, J
   Lam, V
   Raz, T
AF Jebeile, Julie
   Lam, Vincent
   Raez, Tim
TI Understanding climate change with statistical downscaling and machine
   learning
SO SYNTHESE
LA English
DT Article
DE Climate models; Understanding; Dynamical and statistical downscaling;
   Deep neural networks; Machine learning; Climate change
ID SIMULATION; MODEL
AB Machine learning methods have recently created high expectations in the climate modelling context in view of addressing climate change, but they are often considered as non-physics-based 'black boxes' that may not provide any understanding. However, in many ways, understanding seems indispensable to appropriately evaluate climate models and to build confidence in climate projections. Relying on two case studies, we compare how machine learning and standard statistical techniques affect our ability to understand the climate system. For that purpose, we put five evaluative criteria of understanding to work: intelligibility, representational accuracy, empirical accuracy, coherence with background knowledge, and assessment of the domain of validity. We argue that the two families of methods are part of the same continuum where these various criteria of understanding come in degrees, and that therefore machine learning methods do not necessarily constitute a radical departure from standard statistical tools, as far as understanding is concerned.
C1 [Jebeile, Julie; Lam, Vincent] Univ Bern, Inst Philosophy, Langgassstr 49a, CH-3012 Bern, Switzerland.
   [Jebeile, Julie; Lam, Vincent] Univ Bern, Oeschger Ctr Climate Change Res, Hsch Str 4, CH-3012 Bern, Switzerland.
   [Lam, Vincent] Univ Queensland, Sch Hist & Philosoph Inquiry, St Lucia, Qld 4072, Australia.
   [Raez, Tim] Univ Zurich, Inst Biomed Eth & Hist Med, Winterthurerstr 30, CH-8006 Zurich, Switzerland.
RP Raz, T (corresponding author), Univ Zurich, Inst Biomed Eth & Hist Med, Winterthurerstr 30, CH-8006 Zurich, Switzerland.
EM tim.raez@posteo.de
OI Jebeile, Julie/0000-0002-7164-5848; Lam, Vincent/0000-0002-4454-5382
FU Oeschger Centre for Climate Change Research; Swiss National Science
   FoundationSwiss National Science Foundation (SNSF)European Commission
   [PP00P1_170460]; cogito foundation
FX We thank the participants of the philosophy of science research
   colloquium in the Spring semester 2020 at the University of Bern for
   valuable feedback on an earlier draft of the paper. We also wish to
   thank the participants of the seminar `Philosophy of science
   perspectives on the climate challenge' and the workshop `Big data,
   machine learning, climate modelling and understanding' in the Fall
   semester 2019 at the University of Bern and supported by the Oeschger
   Centre for Climate Change Research. JJ and VL are grateful to the Swiss
   National Science Foundation for financial support (Grant PP00P1_170460).
   TR was funded by the cogito foundation.
NR 33
TC 1
Z9 1
U1 14
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0039-7857
EI 1573-0964
J9 SYNTHESE
JI Synthese
PD DEC
PY 2021
VL 199
IS 1-2
BP 1877
EP 1897
DI 10.1007/s11229-020-02865-z
EA SEP 2020
PG 21
WC History & Philosophy Of Science; Philosophy
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC History & Philosophy of Science; Philosophy
GA XA2SK
UT WOS:000572029700002
OA Green Published, Green Submitted
DA 2022-04-17
ER

PT J
AU Pandey, S
   Schumacher, J
   Sreenivasan, KR
AF Pandey, Sandeep
   Schumacher, Jorg
   Sreenivasan, Katepalli R.
TI A perspective on machine learning in turbulent flows
SO JOURNAL OF TURBULENCE
LA English
DT Article
DE Fully developed turbulence; machine learning; data-driven turbulence
   research
ID DEEP NEURAL-NETWORKS; MODEL
AB The physical complexity and the large number of degrees of freedom that can be resolved today by direct numerical simulations of turbulent flows, and by the most sophisticated experimental techniques, require new strategies to reduce and analyse the data so generated, and to model the turbulent behaviour. We discuss a few concrete examples for which the turbulence data have been analysed by machine learning tools. We also comment on work in neighbouring fields of physics, particularly astrophysical (and astronomical) work, where Big Data has been the paradigm for some time. We discuss unsupervised, semi-supervised and supervised machine learning methods to direct numerical simulations data of homogeneous isotropic turbulence, Rayleigh-Benard convection, and the minimal flow unit of a turbulent channel flow; for the last case, we discuss in some detail the application of echo state networks, this being one implementation of reservoir computing. The paper also provides a brief perspective on machine learning applications more broadly.
C1 [Pandey, Sandeep; Schumacher, Jorg] Tech Univ, Inst Thermo & Fluiddynam, Ilmenau, Germany.
   [Schumacher, Jorg; Sreenivasan, Katepalli R.] NYU, Tandon Sch Engn, New York, NY 10003 USA.
   [Sreenivasan, Katepalli R.] NYU, Courant Inst Math Sci, New York, NY 10003 USA.
   [Sreenivasan, Katepalli R.] NYU, Dept Phys, 4 Washington Pl, New York, NY 10003 USA.
RP Sreenivasan, KR (corresponding author), NYU, Tandon Sch Engn, New York, NY 10003 USA.; Sreenivasan, KR (corresponding author), NYU, Courant Inst Math Sci, New York, NY 10003 USA.; Sreenivasan, KR (corresponding author), NYU, Dept Phys, 4 Washington Pl, New York, NY 10003 USA.
EM katepalli.sreenivasan@nyu.edu
FU Deutsche ForschungsgemeinschaftGerman Research Foundation (DFG) [SCHU
   1410/30-1]; John von Neumann Institute for Computing (NIC) at the Julich
   Supercomputing Centre [HIL12]; Large Scale Project of the Gauss Centre
   for Supercomputing (GCS) at the Leibniz Rechenzentrum Garching [pr62se]
FX SP is supported by the Deutsche Forschungsgemeinschaft with grant SCHU
   1410/30-1. The research was also supported by supercomputing resources
   which were provided by the project grant HIL12 of the John von Neumann
   Institute for Computing (NIC) at the Julich Supercomputing Centre and by
   the Large Scale Project pr62se of the Gauss Centre for Supercomputing
   (GCS) at the Leibniz Rechenzentrum Garching.
NR 55
TC 19
Z9 19
U1 10
U2 22
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1468-5248
J9 J TURBUL
JI J. Turbul.
PD OCT 2
PY 2020
VL 21
IS 9-10
SI SI
BP 567
EP 584
DI 10.1080/14685248.2020.1757685
EA APR 2020
PG 18
WC Mechanics; Physics, Fluids & Plasmas
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Mechanics; Physics
GA OI0AL
UT WOS:000531942300001
DA 2022-04-17
ER

PT C
AU Ozmen, E
   Aydin, AG
   Balaban, HS
   Kamci, AK
AF Ozmen, Emirhan
   Aydin, Ahmet Gunhan
   Balaban, Halim Sinan
   Kamci, Ahmet Kerim
GP IEEE
TI Antenna Scanning Type Classification using Machine Learning
SO 2020 28TH SIGNAL PROCESSING AND COMMUNICATIONS APPLICATIONS CONFERENCE
   (SIU)
SE Signal Processing and Communications Applications Conference
LA Turkish
DT Proceedings Paper
CT 28th Signal Processing and Communications Applications Conference (SIU)
CY OCT 05-07, 2020
CL ELECTR NETWORK
SP Istanbul Medipol Univ
DE Antenna Scan Type Classification; Machine Learning; Electronic Warfare
AB In this paper, a machine learning based method for antenna scanning type classification in electronic warfare systems is proposed. The proposed method, unlike other methods in the literature, does not require extra resources. In the simulations, it has been observed that radar scanning types can be successfully classified.
C1 [Ozmen, Emirhan; Balaban, Halim Sinan; Kamci, Ahmet Kerim] ASELSAN AS, Radar Elekt Harp & Istihbarat Sistemleri, Ankara, Turkey.
   [Ozmen, Emirhan] Hacettepe Univ, Elekt & Elekt Muhendisligi Bolumu, Ankara, Turkey.
   [Aydin, Ahmet Gunhan] Bogazici Univ, Elekt & Elekt Muhendisligi Bolumu, Istanbul, Turkey.
RP Ozmen, E (corresponding author), ASELSAN AS, Radar Elekt Harp & Istihbarat Sistemleri, Ankara, Turkey.; Ozmen, E (corresponding author), Hacettepe Univ, Elekt & Elekt Muhendisligi Bolumu, Ankara, Turkey.
EM eozmen@aselsan.com.tr; hsbalaban@aselsan.com.tr;
   ahmetkamci@aselsan.com.tr
NR 7
TC 0
Z9 0
U1 1
U2 1
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2165-0608
BN 978-1-7281-7206-4
J9 SIG PROCESS COMMUN
PY 2020
PG 4
WC Engineering, Electrical & Electronic; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Engineering; Telecommunications
GA BR4SW
UT WOS:000653136100168
DA 2022-04-17
ER

PT C
AU Ardabili, S
   Mosavi, A
   Varkonyi-Koczy, AR
AF Ardabili, Sina
   Mosavi, Amir
   Varkonyi-Koczy, Annamaria R.
BE VarkonyiKoczy, AR
TI Advances in Machine Learning Modeling Reviewing Hybrid and Ensemble
   Methods
SO ENGINEERING FOR SUSTAINABLE FUTURE
SE Lecture Notes in Networks and Systems
LA English
DT Proceedings Paper
CT 18th International Conference on Global Research and Education
   Inter-Academia
CY SEP 04-07, 2019
CL Obuda Univ, HUNGARY
HO Obuda Univ
DE Machine learning; Deep learning; Ensemble models
ID PREDICTION; CLASSIFICATION; ANFIS
AB The conventional machine learning (ML) algorithms are continuously advancing and evolving at a fast-paced by introducing the novel learning algorithms. ML models are continually improving using hybridization and ensemble techniques to empower computation, functionality, robustness, and accuracy aspects of modeling. Currently, numerous hybrid and ensemble ML models have been introduced. However, they have not been surveyed in a comprehensive manner. This paper presents the state of the art of novel ML models and their performance and application domains through a novel taxonomy.
C1 [Ardabili, Sina] Inst Adv Studies Koszeg, Koszeg, Hungary.
   [Mosavi, Amir; Varkonyi-Koczy, Annamaria R.] Obuda Univ, Kalman Kando Fac Elect Engn, Budapest, Hungary.
   [Mosavi, Amir] Oxford Brookes Univ, Sch Built Environm, Oxford OX3 0BP, England.
   [Varkonyi-Koczy, Annamaria R.] J Selye Univ, Dept Math & Informat, Komarno, Slovakia.
RP Mosavi, A (corresponding author), Obuda Univ, Kalman Kando Fac Elect Engn, Budapest, Hungary.; Mosavi, A (corresponding author), Oxford Brookes Univ, Sch Built Environm, Oxford OX3 0BP, England.
EM amir.mosavi@kvk.uni-obuda.hu
RI Ardabili, Sina Faizollahzadeh/X-8072-2019; Ardabili, Sina/ABE-9690-2021;
   Mosavi, Amir/I-7440-2018
OI Ardabili, Sina Faizollahzadeh/0000-0002-7744-7906; Mosavi,
   Amir/0000-0003-4842-0613
FU Project: "Support of research and development activities of the J. Selye
   University in the field of Digital Slovakia and creative industry" of
   the Research & Innovation Operational Programme - European Regional
   Development Fund [NFP313010T504]
FX This publication has been supported by the Project: "Support of research
   and development activities of the J. Selye University in the field of
   Digital Slovakia and creative industry" of the Research & Innovation
   Operational Programme (ITMS code: NFP313010T504) co-funded by the
   European Regional Development Fund.
NR 86
TC 30
Z9 30
U1 1
U2 3
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2367-3370
EI 2367-3389
BN 978-3-030-36841-8; 978-3-030-36840-1
J9 LECT NOTE NETW SYST
PY 2020
VL 101
BP 215
EP 227
DI 10.1007/978-3-030-36841-8_21
PG 13
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods; Multidisciplinary Sciences
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Science & Technology - Other Topics
GA BR5RF
UT WOS:000656863600021
DA 2022-04-17
ER

PT J
AU Jablon, LS
   Avila, SL
   Borba, B
   Mourao, GL
   Freitas, FL
   Penz, CA
AF Jablon, Leonardo S.
   Avila, Sergio L.
   Borba, Bruno
   Mourao, Gustavo L.
   Freitas, Fabrizio L.
   Penz, Cesar A.
TI Diagnosis of rotating machine unbalance using machine learning
   algorithms on vibration orbital features
SO JOURNAL OF VIBRATION AND CONTROL
LA English
DT Article
DE Orbits; diagnosis; machine learning algorithms; vibration; industrial
   application
ID BEARINGS
AB The diagnosis of failures in rotating machines has been subject to studies because of its benefits to maintenance improvement. Condition monitoring reduces maintenance costs, increases reliability and availability, and extends the useful life of critical rotating machinery in industry ambiance. Machine learning techniques have been evolving rapidly, and its applications are bringing better performance to many fields. This study presents a new strategy to improve the diagnosis performance of rotating machines using machine learning strategies on vibration orbital features. The advantage of using orbits in comparison to other vibration measurement systems is the simplicity of the instrumentation involved as well as the information multiplicity contained in the orbit. On the other hand, rolling element bearings are prevalent in industrial machinery. This type of bearing has less orbital oscillation and is noisier than sliding contact bearings. Therefore, it is more difficult to extract useful information. Practical results on an industry motor workbench with rolling element bearings are presented, and the algorithm robustness is evaluated by calculating diagnosis accuracy using inputs with different signal-to-noise ratios. For this kind of noisy scenario where signal analysis is naturally tough, the algorithm classifies approximately 85% of the time correctly. In a completely harsh environment, where the signal-to-noise ratio can be smaller than -25 dB, the accuracy achieved is close to 60%. These statistics show that the strategy proposed can be robust for rotating machine unbalance condition diagnosis even in the worst scenarios, which is required for industrial applications.
C1 [Jablon, Leonardo S.; Borba, Bruno; Mourao, Gustavo L.; Freitas, Fabrizio L.] AQTECH Power Prognosis Inc, Florianopolis, SC, Brazil.
   [Jablon, Leonardo S.; Avila, Sergio L.; Penz, Cesar A.] Fed Inst Santa Catarina, Dept Electrotech Engn, Florianopolis, SC, Brazil.
RP Avila, SL (corresponding author), Fed Inst Educ Sci & Technol Santa Catarina, Ave Mauro Ramos 950, BR-88075010 Florianopolis, SC, Brazil.
EM sergio.avila@ifsc.edu.br
RI Avila, Sergio Luciano/AAH-6370-2021
OI Avila, Sergio Luciano/0000-0002-0018-196X
FU Santa Catarina State Research and Innovation Support Foundation (FAPESC)
   [219TR322]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   was supported by the Santa Catarina State Research and Innovation
   Support Foundation (FAPESC) under grant n. 219TR322.
NR 21
TC 2
Z9 2
U1 1
U2 6
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1077-5463
EI 1741-2986
J9 J VIB CONTROL
JI J. Vib. Control
PD FEB
PY 2021
VL 27
IS 3-4
BP 468
EP 476
AR 1077546320929830
DI 10.1177/1077546320929830
EA MAY 2020
PG 9
WC Acoustics; Engineering, Mechanical; Mechanics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Acoustics; Engineering; Mechanics
GA QF1IO
UT WOS:000534523400001
DA 2022-04-17
ER

PT C
AU Cleary, A
   Yoo, K
   Samuel, P
   George, S
   Sun, F
   Israel, SA
AF Cleary, Alison
   Yoo, Kristopher
   Samuel, Paul
   George, Sean
   Sun, Fei
   Israel, Steven A.
GP IEEE
TI Machine Learning on Small UAVs
SO 2020 IEEE APPLIED IMAGERY PATTERN RECOGNITION WORKSHOP (AIPR): TRUSTED
   COMPUTING, PRIVACY, AND SECURING MULTIMEDIA
SE IEEE Applied Imagery Pattern Recognition Workshop
LA English
DT Proceedings Paper
CT IEEE Applied Imagery Pattern Recognition Workshop (AIPR)
CY OCT 13-15, 2020
CL ELECTR NETWORK
SP IEEE
DE UAV; Machine Learning; On-board Processing; Workflow; Robotic Operating
   System (ROS)
AB Commonly, machine learning (ML) workflows for training and inferencing occur in resource rich environments. Draper Laboratory is pushing ML to the edge. This paper shows the concept of operations (CONOPs), design parameters, and constraints the team faced for edge implementation. The overarching requirement is to fully integrate the machine learning element into the small unmanned aerial vehicle (UAV) or drone. Given the limited payload capacity and power available on small UAVs, integration of computing resources sufficient to host both ML and Autonomy functions is a challenge. Past efforts have relied on an Intel NUC as the primary processing unit. However, recent advances in GPUs provide greater computational power at low-SWaP, compatibility with ML algorithms, and sufficient CPU resources to host the UAVs autonomy element. More recently developed processing units, designed specifically for ML applications at the edge, enable scaled down variants of the algorithms for integration onto significantly smaller platforms. In this paper, we identify a common software architecting strategy that enables a micro UAV (- 150 grams) supported by a traditional CPU and a small UAV (3 kg) configured with a GPU. Draper's automation strategy leverages the open-source Robotic Operating System (ROS). The ML models were built using open-source Python Pytorch libraries. We provide the flight test results for a vehicle detection algorithm. Future applications will include visual navigation and tracking.
C1 [Cleary, Alison; Yoo, Kristopher; Samuel, Paul; George, Sean; Sun, Fei; Israel, Steven A.] Charles Stark Draper Lab Inc, Cambridge, MA 02139 USA.
RP Cleary, A (corresponding author), Charles Stark Draper Lab Inc, Cambridge, MA 02139 USA.
EM acleary@draper.com; kyoo@draper.com; psamuel@draper.com;
   sgeorge@draper.com; fsun@draper.com; israel@draper.com
FU Draper's System Engineering Division
FX The team would like to thank Draper's System Engineering Division for
   funding this research. The funding enabled Draper to build a common
   workflow to incorporate ML models across multiple UAV programs.
NR 3
TC 0
Z9 0
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1550-5219
BN 978-1-7281-8243-8
J9 IEEE APP IMG PAT
PY 2020
DI 10.1109/AIPR50011.2020.9425090
PG 5
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical & Electronic; Imaging Science &
   Photographic Technology
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Imaging Science & Photographic Technology
GA BR9HA
UT WOS:000675595400010
DA 2022-04-17
ER

PT J
AU Baron, B
   Musolesi, M
AF Baron, Benjamin
   Musolesi, Mirco
TI Interpretable Machine Learning for Privacy-Preserving Pervasive Systems
SO IEEE PERVASIVE COMPUTING
LA English
DT Article
DE Privacy; Machine learning; Task analysis; Data privacy; Computational
   modeling; Feature extraction
AB Our everyday interactions with pervasive systems generate traces that capture various aspects of human behavior and enable machine learning algorithms to extract latent information about users. In this paper, we propose a machine learning interpretability framework that enables users to understand how these generated traces violate their privacy.
C1 [Baron, Benjamin] UCL, London, England.
   [Musolesi, Mirco] UCL, Data Sci, London, England.
RP Baron, B (corresponding author), UCL, London, England.
EM b.baron@ucl.ac.uk
FU EPSRCUK Research & Innovation (UKRI)Engineering & Physical Sciences
   Research Council (EPSRC) [EP/L018829/2] Funding Source: UKRI
NR 20
TC 1
Z9 1
U1 1
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1536-1268
EI 1558-2590
J9 IEEE PERVAS COMPUT
JI IEEE Pervasive Comput.
PD JAN-MAR
PY 2020
VL 19
IS 1
BP 73
EP 82
DI 10.1109/MPRV.2019.2918540
PG 10
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA KU9UC
UT WOS:000520068800009
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Bechelli, S
   Delhommelle, J
AF Bechelli, Solene
   Delhommelle, Jerome
TI Machine Learning and Deep Learning Algorithms for Skin Cancer
   Classification from Dermoscopic Images
SO BIOENGINEERING-BASEL
LA English
DT Article
DE skin cancer; image classification; deep learning; machine learning;
   convolutional neural network
AB We carry out a critical assessment of machine learning and deep learning models for the classification of skin tumors. Machine learning (ML) algorithms tested in this work include logistic regression, linear discriminant analysis, k-nearest neighbors classifier, decision tree classifier and Gaussian naive Bayes, while deep learning (DL) models employed are either based on a custom Convolutional Neural Network model, or leverage transfer learning via the use of pre-trained models (VGG16, Xception and ResNet50). We find that DL models, with accuracies up to 0.88, all outperform ML models. ML models exhibit accuracies below 0.72, which can be increased to up to 0.75 with ensemble learning. To further assess the performance of DL models, we test them on a larger and more imbalanced dataset. Metrics, such as the F-score and accuracy, indicate that, after fine-tuning, pre-trained models perform extremely well for skin tumor classification. This is most notably the case for VGG16, which exhibits an F-score of 0.88 and an accuracy of 0.88 on the smaller database, and metrics of 0.70 and 0.88, respectively, on the larger database.
C1 [Bechelli, Solene; Delhommelle, Jerome] Univ North Dakota, Dept Biomed Engn, Grand Forks, ND 58202 USA.
   [Bechelli, Solene; Delhommelle, Jerome] Univ North Dakota, Tech Accelerator, MetaSimulat Nonequilibrium Proc MSNEP Grp, Grand Forks, ND 58202 USA.
   [Delhommelle, Jerome] Univ North Dakota, Dept Chem, Grand Forks, ND 58202 USA.
   [Delhommelle, Jerome] Univ North Dakota, Sch Elect Engn & Comp Sci, Grand Forks, ND 58202 USA.
RP Delhommelle, J (corresponding author), Univ North Dakota, Dept Biomed Engn, Grand Forks, ND 58202 USA.; Delhommelle, J (corresponding author), Univ North Dakota, Tech Accelerator, MetaSimulat Nonequilibrium Proc MSNEP Grp, Grand Forks, ND 58202 USA.; Delhommelle, J (corresponding author), Univ North Dakota, Dept Chem, Grand Forks, ND 58202 USA.; Delhommelle, J (corresponding author), Univ North Dakota, Sch Elect Engn & Comp Sci, Grand Forks, ND 58202 USA.
EM solene.bechelli@und.edu; jerome.delhommelle@und.edu
FU NSFNational Science Foundation (NSF) [OIA-1946202]
FX Partial funding for this research was provided by NSF through award
   OIA-1946202.
NR 59
TC 0
Z9 0
U1 0
U2 0
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2306-5354
J9 BIOENGINEERING-BASEL
JI Bioengineering-Basel
PD MAR
PY 2022
VL 9
IS 3
AR 97
DI 10.3390/bioengineering9030097
PG 18
WC Biotechnology & Applied Microbiology; Engineering, Biomedical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biotechnology & Applied Microbiology; Engineering
GA 0D7LA
UT WOS:000776171200001
PM 35324786
OA gold, Green Published
DA 2022-04-17
ER

PT C
AU Abramson, W
   Hall, AJ
   Papadopoulos, P
   Pitropakis, N
   Buchanan, WJ
AF Abramson, Will
   Hall, Adam James
   Papadopoulos, Pavlos
   Pitropakis, Nikolaos
   Buchanan, William J.
BE Gritzalis, S
   Weippl, ER
   Kotsis, G
   Tjoa, AM
   Khalil, I
TI A Distributed Trust Framework for Privacy-Preserving Machine Learning
SO TRUST, PRIVACY AND SECURITY IN DIGITAL BUSINESS, TRUSTBUS 2020
SE Lecture Notes in Computer Science
LA English
DT Proceedings Paper
CT 17th International Conference on Trust, Privacy and Security in Digital
   Business (TrustBus)
CY SEP 14-17, 2020
CL ELECTR NETWORK
SP Software Competence Ctr Hagenberg, JVU, Inst Telecooperat, Informat Integrat & Web Based Applicat & Serv
DE Trust; Machine learning; Federated learning; Decentralised Identifiers;
   Verifiable credentials
AB When training a machine learning model, it is standard procedure for the researcher to have full knowledge of both the data and model. However, this engenders a lack of trust between data owners and data scientists. Data owners are justifiably reluctant to relinquish control of private information to third parties. Privacy-preserving techniques distribute computation in order to ensure that data remains in the control of the owner while learning takes place. However, architectures distributed amongst multiple agents introduce an entirely new set of security and trust complications, including data poisoning and model theft. This paper outlines a distributed infrastructure which can be used to facilitate peer-to-peer trust between entities; collaboratively performing a privacy-preserving workflow. Our outlined prototype enables the initialisation of industry gatekeepers and governance bodies as credential issuers under a certain application domain. Before participating in the distributed learning workflow, malicious actors must first negotiate valid credentials from these gatekeepers. We detail a proof of concept using Hyperledger Aries, Decentralised Identifiers (DIDs) and Verifiable Credentials (VCs) to establish a distributed trust architecture during a privacy-preserving machine learning experiment. Specifically, we utilise secure and authenticated DID communication channels in order to facilitate a federated learning workflow related to mental health care data.
C1 [Abramson, Will; Hall, Adam James; Papadopoulos, Pavlos; Pitropakis, Nikolaos; Buchanan, William J.] Edinburgh Napier Univ, Blockpass Ident Lab, Edinburgh, Midlothian, Scotland.
RP Buchanan, WJ (corresponding author), Edinburgh Napier Univ, Blockpass Ident Lab, Edinburgh, Midlothian, Scotland.
EM will.abramson@napier.ac.uk; adam.hall@napier.ac.uk;
   pavlos.papadopoulos@napier.ac.uk; n.pitropakis@napier.ac.uk;
   b.buchanan@napier.ac.uk
RI Papadopoulos, Pavlos/AAC-4693-2021
OI Papadopoulos, Pavlos/0000-0001-5927-6026
NR 54
TC 3
Z9 3
U1 2
U2 2
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 0302-9743
EI 1611-3349
BN 978-3-030-58986-8; 978-3-030-58985-1
J9 LECT NOTES COMPUT SC
PY 2020
VL 12395
BP 205
EP 220
DI 10.1007/978-3-030-58986-8_14
PG 16
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory & Methods
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS5EC
UT WOS:000728363800014
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Liu, YH
   Li, WJ
   Zhang, X
   Lewenstein, M
   Su, G
   Ran, SJ
AF Liu, Yuhan
   Li, Wen-Jun
   Zhang, Xiao
   Lewenstein, Maciej
   Su, Gang
   Ran, Shi-Ju
TI Entanglement-Based Feature Extraction by Tensor Network Machine Learning
SO FRONTIERS IN APPLIED MATHEMATICS AND STATISTICS
LA English
DT Article
DE quantum entanglement; machine learning; tensor network; image
   classification; feature extraction
ID MATRIX PRODUCT STATES; RENORMALIZATION-GROUP; IMAGE COMPRESSION; QUANTUM
AB It is a hot topic how entanglement, a quantity from quantum information theory, can assist machine learning. In this work, we implement numerical experiments to classify patterns/images by representing the classifiers as matrix product states (MPS). We show how entanglement can interpret machine learning by characterizing the importance of data and propose a feature extraction algorithm. We show on the MNIST dataset that when reducing the number of the retained pixels to 1/10 of the original number, the decrease of the ten-class testing accuracy is only O (10(-3)), which significantly improves the efficiency of the MPS machine learning. Our work improves machine learning's interpretability and efficiency under the MPS representation by using the properties of MPS representing entanglement.
C1 [Liu, Yuhan] Univ Chicago, Dept Phys, Chicago, IL 60637 USA.
   [Li, Wen-Jun; Su, Gang] Univ Chinese Acad Sci, Sch Phys Sci, Beijing, Peoples R China.
   [Zhang, Xiao] Sun Yat Sen Univ, Dept Phys, Guangzhou, Peoples R China.
   [Lewenstein, Maciej] Barcelona Inst Sci & Technol, ICFO Inst Ciencies Foton, Barcelona, Spain.
   [Lewenstein, Maciej] ICREA, Pg Lluis Companys 23, Barcelona, Spain.
   [Su, Gang] Univ Chinese Acad Sci, Kavli Inst Theoret Sci, Beijing, Peoples R China.
   [Su, Gang] Univ Chinese Acad Sci, CAS Ctr Excellence Topol Quantum Computat, Beijing, Peoples R China.
   [Ran, Shi-Ju] Capital Normal Univ, Dept Phys, Beijing, Peoples R China.
RP Su, G (corresponding author), Univ Chinese Acad Sci, Sch Phys Sci, Beijing, Peoples R China.; Su, G (corresponding author), Univ Chinese Acad Sci, Kavli Inst Theoret Sci, Beijing, Peoples R China.; Su, G (corresponding author), Univ Chinese Acad Sci, CAS Ctr Excellence Topol Quantum Computat, Beijing, Peoples R China.; Ran, SJ (corresponding author), Capital Normal Univ, Dept Phys, Beijing, Peoples R China.
EM gsu@ucas.ac.cn; sjran@cnu.edu.cn
FU ERC AdG OSYRIS (ERC-2013AdG) [339106]; Spanish Ministry MINECOSpanish
   Government [FIS201679508-P, SEV-2015-0522]; Generalitat de Catalunya
   (AGAUR Grant) [2017 SGR 1341]; Fundacio Privada CellexFoundation CELLEX;
   EU FETPRO QUIC (H2020-FETPROACT-2014) [641122]; National Science
   CentreNational Science Centre, Poland; Poland-Symfonia Grant
   [2016/20/W/ST4/00314]; Fundacio Catalunya -La Pedrera; Beijing Natural
   Science FoundationBeijing Natural Science Foundation [1192005, Z180013];
   Foundation of Beijing Education Committees [KM202010028013]; Academy for
   Multidisciplinary Studies, Capital Normal University; National Natural
   Science Foundation of ChinaNational Natural Science Foundation of China
   (NSFC) [11404413]; Natural Science Foundation of Guangdong
   ProvinceNational Natural Science Foundation of Guangdong Province
   [2015A030313188]; Guangdong Science and Technology Innovation Youth
   Talent Program [2016TQ03X688]; NSFCNational Natural Science Foundation
   of China (NSFC) [11834014]; National Key R&D Program of China
   [2018FYA0305804]; Strategetic Priority Research Program of the Chinese
   Academy of Sciences [XDB28000000]; Beijing Municipal Science and
   Technology CommissionBeijing Municipal Science & Technology Commission
   [Z190011]; Generalitat de Catalunya (CERCA/Program)Generalitat de
   Catalunya
FX This work was supported by ERC AdG OSYRIS (ERC-2013AdG Grant No.
   339106), Spanish Ministry MINECO (National Plan 15 Grant: FISICATEAMO
   No. FIS201679508-P, SEVERO OCHOA No. SEV-2015-0522), Generalitat de
   Catalunya (AGAUR Grant No. 2017 SGR 1341 and CERCA/Program), Fundacio
   Privada Cellex, EU FETPRO QUIC (H2020-FETPROACT-2014 No. 641122), the
   National Science Centre, and Poland-Symfonia Grant No.
   2016/20/W/ST4/00314. S-JR was supported by Fundacio Catalunya -La
   Pedrera. Ignacio Cirac Program Chair and is supported by Beijing Natural
   Science Foundation (Grant No. 1192005 and No. Z180013), Foundation of
   Beijing Education Committees (Grant No. KM202010028013), and the Academy
   for Multidisciplinary Studies, Capital Normal University. XZ is
   supported by the National Natural Science Foundation of China (No.
   11404413), the Natural Science Foundation of Guangdong Province (No.
   2015A030313188), and the Guangdong Science and Technology Innovation
   Youth Talent Program (Grant No. 2016TQ03X688). ML acknowledges the
   support by Capital Normal University on academic visiting. W-JL and GS
   are supported by in part by the NSFC (Grant No. 11834014), the National
   Key R&D Program of China (Grant No. 2018FYA0305804), the Strategetic
   Priority Research Program of the Chinese Academy of Sciences (Grant No.
   XDB28000000), and Beijing Municipal Science and Technology Commission
   (Grant No. Z190011).
NR 104
TC 0
Z9 0
U1 2
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 2297-4687
J9 FRONT APPL MATH STAT
JI Front. Appl. Math. Stat.
PD AUG 6
PY 2021
VL 7
DI 10.3389/fams.2021.716044
PG 10
WC Mathematics, Interdisciplinary Applications
WE Emerging Sources Citation Index (ESCI)
SC Mathematics
GA UD3ZV
UT WOS:000687149100001
OA gold, Green Submitted
DA 2022-04-17
ER

PT J
AU Chanda, S
   Raghucharan, MC
   Reddy, KSKK
   Chaudhari, V
   Somala, SN
AF Chanda, Sarit
   Raghucharan, M. C.
   Reddy, K. S. K. Karthik
   Chaudhari, Vasudeo
   Somala, Surendra Nadh
TI Duration prediction of Chilean strong motion data using machine learning
SO JOURNAL OF SOUTH AMERICAN EARTH SCIENCES
LA English
DT Article
DE Duration; Significant-duration; Inslab; Classifiers; Machine learning
   algorithms
ID STRONG GROUND MOTION; EQUATIONS; SITE
AB Chile is rocked by inslab, interface as well as crustal events. Duration estimates based on Chilean strong motion flatfile is used to predict total duration as well as significant-duration. We use six different machine learning algorithms k-nearest neighbours, support vector machine, Random forest, Neural network, AdaBoost, decision tree and estimate the accuracies of prediction for each component (EW, NS, Z) of ground motion for different tectonic environments. The estimates of duration using machine learning are found to be quite accurate and the best performing machine learning algorithm in prediction of the total duration and the significant-duration are highlighted.
C1 [Chanda, Sarit; Raghucharan, M. C.; Reddy, K. S. K. Karthik; Chaudhari, Vasudeo; Somala, Surendra Nadh] Indian Inst Technol Hyderabad, Hyderabad, India.
RP Somala, SN (corresponding author), Indian Inst Technol Hyderabad, Dept Civil Engn, Hyderabad, India.
EM surendra@iith.ac.in
RI Chanda, Sarit/AAQ-8634-2021; Chaudhari, Vasudeo/AAU-5716-2021; K.S.K,
   Karthik reddy/AAV-5681-2021
OI Chanda, Sarit/0000-0002-0710-2240; Chaudhari,
   Vasudeo/0000-0002-4378-180X; K.S.K, Karthik reddy/0000-0002-2966-9328
FU Ministry of Earth Sciences, India [MoES/P, (304) /2016]; Department of
   Science and TechnologyDepartment of Science & Technology (India)
   [INT/RUS/RFBR/P335]
FX Funding from the Ministry of Earth Sciences, India MoES/P.O. (Seismo) /1
   (304) /2016 is greatly acknowledged. This work is also partly funded by
   the Department of Science and Technology through grant number
   INT/RUS/RFBR/P335.
NR 13
TC 1
Z9 1
U1 4
U2 4
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0895-9811
EI 1873-0647
J9 J S AM EARTH SCI
JI J. South Am. Earth Sci.
PD AUG
PY 2021
VL 109
AR 103253
DI 10.1016/j.jsames.2021.103253
EA MAR 2021
PG 8
WC Geosciences, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Geology
GA TE8VJ
UT WOS:000670284800002
DA 2022-04-17
ER

PT J
AU Oh, SH
   Lee, HJ
   Roh, TS
AF Oh, Seok-Hwan
   Lee, Hyoung Jin
   Roh, Tae-Seong
TI New Design Method of Solid Propellant Grain Using Machine Learning
SO PROCESSES
LA English
DT Article
DE solid rocket motor; grain design; machine learning; support vector
   machine
ID OPTIMIZATION
AB The correlation between solid propellant grain configuration and burning surface area profile is a complicated nonlinear problem. Nonlinear optimization has been adopted to design grain configurations that satisfied the objective area profiles. However, as conventional design methods are impractical, with limited performance, it is necessary to investigate alternatives. Useful information for grain design can be obtained by analyzing the aforementioned correlation. However, this aspect has not been studied owing to the requirement of large amounts of data and analysis techniques. In this study, machine learning was used to develop a new design method. The objective of machine learning was to train a model to classify classes of data. The database stores various sets of configuration variables and their classes. The proposed Gaussian kernel-based support vector machine model predicts the class of newly designed grains. The results verified that the model accurately predicted the class of the set of configuration variables and can be used to modify the set of configuration variables to satisfy the requirement. Thus, it was confirmed that machine learning is an appropriate approach to grain design; however, further research is needed to analyze its practicality.
C1 [Oh, Seok-Hwan; Lee, Hyoung Jin; Roh, Tae-Seong] Inha Univ, Dept Aerosp Engn, 36 Gaetbeol Ro, Incheon 21999, South Korea.
RP Roh, TS (corresponding author), Inha Univ, Dept Aerosp Engn, 36 Gaetbeol Ro, Incheon 21999, South Korea.
EM shoh@inha.ac.kr; hyoungjin.lee@inha.ac.kr; tsroh@inha.ac.kr
OI Oh, Seok-Hwan/0000-0002-9121-6784; Lee, Hyoung Jin/0000-0002-5544-347X
FU INHA UNIVERSITY Research Grant (2019)
FX This work was supported by the INHA UNIVERSITY Research Grant (2019).
NR 26
TC 1
Z9 1
U1 6
U2 7
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2227-9717
J9 PROCESSES
JI Processes
PD JUN
PY 2021
VL 9
IS 6
AR 910
DI 10.3390/pr9060910
PG 12
WC Engineering, Chemical
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA SY7IN
UT WOS:000666057100001
OA gold
DA 2022-04-17
ER

PT J
AU Srivastava, S
   Lopez, BI
   Kumar, H
   Jang, M
   Chai, HH
   Park, W
   Park, JE
   Lim, D
AF Srivastava, Swati
   Lopez, Bryan Irvine
   Kumar, Himansu
   Jang, Myoungjin
   Chai, Han-Ha
   Park, Woncheoul
   Park, Jong-Eun
   Lim, Dajeong
TI Prediction of Hanwoo Cattle Phenotypes from Genotypes Using Machine
   Learning Methods
SO ANIMALS
LA English
DT Article
DE genomic prediction; machine learning; Hanwoo
ID CARCASS TRAITS; REGRESSION
AB Simple Summary Machine learning has been extensively used in analyzing big data and in conditions where the number of parameters is much bigger than the number of observations. Recently, there have been an increasing number of successful applications of machine learning in genomic prediction as this method makes weaker assumptions, is capable of dealing with the dimensionality problem, and can be more flexible for describing complex relationships. In this study, we evaluated the predictive ability of three machine learning methods, namely, random forest (RF), extreme gradient boosting (XGB), and support vector machine (SVM), when predicting the carcass traits of Hanwoo cattle. These machine learning algorithms were compared with the standard linear method (GBLUP). Our results revealed that XGB method had the best predictive correlation for carcass weight and marbling score. Meanwhile, the best predictive correlation for backfat thickness and eye muscle area was delivered by GBLUP. Moreover, in terms of mean squared error (MSE) of prediction, GBLUP delivered the lowest MSE value for all traits. Hanwoo was originally raised for draft purposes, but the increase in local demand for red meat turned that purpose into full-scale meat-type cattle rearing; it is now considered one of the most economically important species and a vital food source for Koreans. The application of genomic selection in Hanwoo breeding programs in recent years was expected to lead to higher genetic progress. However, better statistical methods that can improve the genomic prediction accuracy are required. Hence, this study aimed to compare the predictive performance of three machine learning methods, namely, random forest (RF), extreme gradient boosting method (XGB), and support vector machine (SVM), when predicting the carcass weight (CWT), marbling score (MS), backfat thickness (BFT) and eye muscle area (EMA). Phenotypic and genotypic data (53,866 SNPs) from 7324 commercial Hanwoo cattle that were slaughtered at the age of around 30 months were used. The results showed that the boosting method XGB showed the highest predictive correlation for CWT and MS, followed by GBLUP, SVM, and RF. Meanwhile, the best predictive correlation for BFT and EMA was delivered by GBLUP, followed by SVM, RF, and XGB. Although XGB presented the highest predictive correlations for some traits, we did not find an advantage of XGB or any machine learning methods over GBLUP according to the mean squared error of prediction. Thus, we still recommend the use of GBLUP in the prediction of genomic breeding values for carcass traits in Hanwoo cattle.
C1 [Srivastava, Swati; Lopez, Bryan Irvine; Kumar, Himansu; Jang, Myoungjin; Chai, Han-Ha; Park, Woncheoul; Park, Jong-Eun; Lim, Dajeong] Rural Dev Adm, Div Anim Genom & Bioinformat, Natl Inst Anim Sci, Wonju 55365, South Korea.
RP Park, JE; Lim, D (corresponding author), Rural Dev Adm, Div Anim Genom & Bioinformat, Natl Inst Anim Sci, Wonju 55365, South Korea.
EM swati051@gmail.com; irvinelopez@korea.kr; himanshu.genetics@gmail.com;
   minijmj@naver.com; hanha@korea.kr; wcpark1982@korea.kr;
   jepark0105@korea.kr; lim.dj@korea.kr
OI Park, Jong-Eun/0000-0003-0718-3463; Kumar, Himansu/0000-0002-4335-4517;
   Lopez, Bryan Irvine/0000-0002-3288-5849; , Han-ha/0000-0001-7752-3967;
   Lim, Dajeong/0000-0003-3966-9150
FU AGENDA project of the National Institute of Animal Science, Rural
   Development Administration, Republic of Korea [PJ01316901, PJ015658];
   2021 RDA Research Associate Fellowship Program of the National Institute
   of Animal Science, Rural Development Administration, Republic of Korea
FX This work was supported by the AGENDA project (PJ01316901 and PJ015658)
   and the 2021 RDA Research Associate Fellowship Program of the National
   Institute of Animal Science, Rural Development Administration, Republic
   of Korea.
NR 34
TC 1
Z9 1
U1 4
U2 4
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 2076-2615
J9 ANIMALS-BASEL
JI Animals
PD JUL
PY 2021
VL 11
IS 7
AR 2066
DI 10.3390/ani11072066
PG 8
WC Agriculture, Dairy & Animal Science; Veterinary Sciences; Zoology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Agriculture; Veterinary Sciences; Zoology
GA TN1FM
UT WOS:000675988600001
PM 34359194
OA gold, Green Published
DA 2022-04-17
ER

PT C
AU Ionescu, MS
   Negoita, O
AF Ionescu, Marian Sorin
   Negoita, Olivia
BE Bratianu, C
   Zbuchea, A
   Anghel, F
   Hrib, B
TI SPECIFIC MACHINE LEARNING ALGORITHMS AS EFFICIENT SOLUTIONS FOR COMPLEX
   BUSINESS PROCESSES
SO STRATEGICA: PREPARING FOR TOMORROW, TODAY
SE Strategica
LA English
DT Proceedings Paper
CT 8th International Academic Conference on Strategica - Preparing for
   Tomorrow, Today
CY OCT 15-16, 2020
CL Bucharest, ROMANIA
DE Machine Learning; Business Process; Algorithms; Optimization;
   Transparency
ID ANALYTICS
AB This paper presents and critically investigates some unsupervised and supervised algorithms specific to machine learning, which are particularly suited for business processes and their high dynamical evolution. We particularly highlight the general merits of machine learning and mathematical foundation in the big data era and its importance for applications to industrial and business processes, in the context of well- defined economic problems, with their variables and, especially, the predictive functions to be solved. Then, the paper discusses some existing algorithms and their mathematical formulations and merits, based on existing literature and recent usage in various economic applications. Such machine learning algorithms form today a calculation distribution framework, available in open-source software for storing data and running applications such as Handoop. We also reveal the importance of robustness and of data quality, as many of the business ecosystems are currently filled with dirty and useless data, Finally, we suggest that for precisely observing, quantifying and predicting the performance progress of organizational management, transparency for the users of machine learning is required, as opposed to traditional rather opaque machine learning processes. Finally, the proposed algorithms overview and discussion is helpful to provide first steps in learning how to apply machine learning to make your business more efficient, more effective and more profitable.
C1 [Ionescu, Marian Sorin; Negoita, Olivia] Univ Politehn Bucuresti, FAIMA, Splaiul Independentei 313, Bucharest 060042, Romania.
RP Ionescu, MS (corresponding author), Univ Politehn Bucuresti, FAIMA, Splaiul Independentei 313, Bucharest 060042, Romania.
EM marian.ionescu@man.ase.ro
NR 15
TC 0
Z9 0
U1 0
U2 1
PU TRITONIC PUBL HOUSE
PI BUCHAREST
PA 5, COACAZELOR ST, SECTOR 2, BUCHAREST, 022651, ROMANIA
SN 2392-702X
BN 978-606-749-508-9
J9 STRATEGICA
PY 2020
BP 209
EP 223
PG 15
WC Management; Social Sciences, Interdisciplinary
WE Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Business & Economics; Social Sciences - Other Topics
GA BR5FY
UT WOS:000654987700016
DA 2022-04-17
ER

PT J
AU Lin, SL
AF Lin, Shih-Lin
TI Application of Machine Learning to a Medium Gaussian Support Vector
   Machine in the Diagnosis of Motor Bearing Faults
SO ELECTRONICS
LA English
DT Article
DE machine learning; Gaussian support vector machine; motor fault diagnosis
ID DAMAGE DETECTION; ACCELEROMETERS; MODEL; ROTOR
AB In recent years, artificial intelligence technology has been widely used in fault prediction and health management (PHM). The machine learning algorithm is widely used in the condition monitoring of rotating machines, and normal and fault data can be obtained through the data acquisition and monitoring system. After analyzing the data and establishing a model, the system can automatically learn the features from the input data to predict the failure of the maintenance and diagnosis equipment, which is important for motor maintenance. This research proposes a medium Gaussian support vector machine (SVM) method for the application of machine learning and constructs a feature space by extracting the characteristics of the vibration signal collected on the spot based on experience. Different methods were used to cluster and classify features to classify motor health. The influence of different Gaussian kernel functions, such as fine, medium, and coarse, on the performance of the SVM algorithm was analyzed. The experimental data verify the performance of various models through the data set released by the Case Western Reserve University Motor Bearing Data Center. As the motor often has noise interference in the actual application environment, a simulated Gaussian white noise was added to the original vibration data in order to verify the performance of the research method in a noisy environment. The results summarize the classification results of related motor data sets derived recently from the use of motor fault detection and diagnosis using different machine learning algorithms. The results show that the medium Gaussian SVM method improves the reliability and accuracy of motor bearing fault estimation, detection, and identification under variable crack-size and load conditions. This paper also provides a detailed discussion of the predictive analytical capabilities of machine learning algorithms, which can be used as a reference for the future motor predictive maintenance analysis of electric vehicles.
C1 [Lin, Shih-Lin] Natl Changhua Univ Educ, Grad Inst Vehicle Engn, 1 Jin De Rd, Changhua 50007, Taiwan.
RP Lin, SL (corresponding author), Natl Changhua Univ Educ, Grad Inst Vehicle Engn, 1 Jin De Rd, Changhua 50007, Taiwan.
EM lin040@cc.ncue.edu.tw
RI Lin, Shih-Lin/AGG-3443-2022
OI Lin, Shih-Lin/0000-0002-0234-8786
FU Ministry of Science and Technology, TaiwanMinistry of Science and
   Technology, Taiwan [MOST 109-2222-E-230-001-MY2]
FX The author would like to thank the Ministry of Science and Technology,
   Taiwan, for financially supporting this research (Grant No. MOST
   109-2222-E-230-001-MY2).
NR 51
TC 2
Z9 2
U1 15
U2 17
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2079-9292
J9 ELECTRONICS-SWITZ
JI Electronics
PD SEP
PY 2021
VL 10
IS 18
AR 2266
DI 10.3390/electronics10182266
PG 22
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Physics
GA UV1BK
UT WOS:000699223100001
OA gold
DA 2022-04-17
ER

PT J
AU Liu, YY
   Welch, D
   England, R
   Stacey, J
   Harbison, S
AF Liu, Yao-Yuan
   Welch, David
   England, Ryan
   Stacey, Janet
   Harbison, SallyAnn
TI Forensic STR allele extraction using a machine learning paradigm
SO FORENSIC SCIENCE INTERNATIONAL-GENETICS
LA English
DT Article
DE STR extraction; Machine learning; Massively parallel sequencing;
   Bioinformatics
ID SIGNATURE PREP KIT; DEVELOPMENTAL VALIDATION; DNA; TOOL; IDENTIFICATION;
   CASEWORK; RAZOR; LOCI
AB We present a machine learning approach to short tandem repeat (STR) sequence detection and extraction from massively parallel sequencing data called Fragsifier. Using this approach, STRs are detected on each read by first locating the longest repeat stretches followed by locus prediction using k-mers in a machine learning sequence model. This is followed by reference flanking sequence alignment to determine precise STR boundaries. We show that Fragsifier produces genotypes that are concordant with profiles obtained using capillary electrophoresis (CE), and also compared the results with that of STRait Razor and the ForenSeq UAS. The data pre-processing and training of the sequence classifier is readily scripted, allowing the analyst to experiment with different thresholds, datasets and loci of interest, and different machine learning models.
C1 [Liu, Yao-Yuan; England, Ryan] Univ Auckland, Sch Chem Sci, Forens Sci Program, 38 Princes St, Auckland 1010, New Zealand.
   [Welch, David] Univ Auckland, Sch Comp Sci, 38 Princes St, Auckland 1010, New Zealand.
   [England, Ryan; Stacey, Janet; Harbison, SallyAnn] Inst Environm Sci & Res Ltd, Private Bag 92021, Auckland 1142, New Zealand.
RP Harbison, S (corresponding author), Inst Environm Sci & Res Ltd, Private Bag 92021, Auckland 1142, New Zealand.
EM sallyann.harbison@esr.cri.nz
OI Welch, David/0000-0002-7066-2830; England, Ryan/0000-0002-6175-5453
FU ESR Strategic Science Investment Fund
FX The work in this paper was conducted by Yao-Yuan Liu as part of the
   requirements for a PhD degree from The University of Auckland, New
   Zealand and was supported by the ESR Strategic Science Investment Fund.
   We thank Rebecca Richards and Rachel Boyle for the helpful suggestions
   in the preparation of this manuscript.
NR 25
TC 1
Z9 1
U1 0
U2 6
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 1872-4973
EI 1878-0326
J9 FORENSIC SCI INT-GEN
JI Forensic Sci. Int.-Genet.
PD JAN
PY 2020
VL 44
AR 102194
DI 10.1016/j.fsigen.2019.102194
PG 6
WC Genetics & Heredity; Medicine, Legal
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Genetics & Heredity; Legal Medicine
GA JX9MO
UT WOS:000504051100015
PM 31698330
DA 2022-04-17
ER

PT J
AU Kanchana, D
   Shobana, J
AF Kanchana, D.
   Shobana, J.
TI A mixed Approach of Deep Learning and Machine Learning Techniques for
   Improving Accuracy in Stock Analysis and Prediction
SO BIOSCIENCE BIOTECHNOLOGY RESEARCH COMMUNICATIONS
LA English
DT Article
DE MACHINE LEARNING; STOCK PREDICTION; DEEP LEARNING
AB Market prediction has been an area of interest to both investors and analysts for many years due to its unpredictable, dynamic and constantly changing existence, making accurate forecasts difficult to make. This research introduces an approach that uses machine learning to forecast stock market trends. One of the most critical activities of currency trade is world stock exchange. Securities exchange forecast is a proof of attempting to agree on the potential estimate of money-related traded device on a budgetary trade. This project clarifies the prediction of an inventory using machine learning. Many stock brokers make use of the advanced and big or time scheduling inquiry when creating stock expectations. This Proposed work uses the Linear Regression Machine Learning (ML) algorithm to drawn up from the knowledge and experience of the available stock and then utilizes the information collected to reliably forecast. Recurrent Neural Network, artificial intelligent is used to forecast stock expense for big and small capitalizations in various markets and to use the expense daily and intervals frequently updated. These methods are utilized to conjecture whether the cost of a stock later on will be higher than its cost on a given day, in light of recorded information while giving a top to bottom comprehension of the models being utilized. Thus, the mixed approach of deep learning and machine learning acquires better results with yahoo finance datasets when compared with existing algorithms.
C1 [Kanchana, D.; Shobana, J.] SRM Inst Sci & Technol, Dept Comp Applicat, Ramapuram Campus, Chennai, Tamil Nadu, India.
RP Kanchana, D (corresponding author), SRM Inst Sci & Technol, Dept Comp Applicat, Ramapuram Campus, Chennai, Tamil Nadu, India.
EM prasadjoness.ece@krct.ac.in
RI Saha, Nimai Chandra/ABH-1455-2020; D, Kanchana/AAY-9761-2021
OI Saha, Nimai Chandra/0000-0001-5171-3762; D, Kanchana/0000-0003-0791-7826
NR 21
TC 0
Z9 0
U1 2
U2 2
PU SOC SCIENCE & NATURE
PI BHOPAL
PA C-52 HOUSING BOARD COLONY, KOHE FIZA, BHOPAL, MADHYA PRADESH 462 001,
   INDIA
SN 0974-6455
J9 BIOSCI BIOTECH RES C
JI Biosci. Biotechnol. Res. Commun.
PY 2020
VL 13
IS 6
SI SI
BP 89
EP 95
PG 7
WC Biotechnology & Applied Microbiology
WE Emerging Sources Citation Index (ESCI)
SC Biotechnology & Applied Microbiology
GA RN0WW
UT WOS:000640077500016
DA 2022-04-17
ER

PT J
AU Ding, YL
   Lei, XJ
   Liao, B
   Wu, FX
AF Ding, Yulian
   Lei, Xiujuan
   Liao, Bo
   Wu, Fang-Xiang
TI Machine learning approaches for predicting biomolecule-disease
   associations
SO BRIEFINGS IN FUNCTIONAL GENOMICS
LA English
DT Review
DE biomolecule-disease association; multi-view data source; feature
   representation; machine learning; deep learning; non-negative matrix
   factorization
ID UPDATED DATABASE; NONCODING RNAS; NETWORK; MICRORNAS; GENE; INFERENCE;
   REPRESENTATION; EXPRESSION; SIMILARITY; INSIGHTS
AB Biomolecules, such as microRNAs, circRNAs, lncRNAs and genes, are functionally interdependent in human cells, and all play critical roles in diverse fundamental and vital biological processes. The dysregulations of such biomolecules can cause diseases. Identifying the associations between biomolecules and diseases can uncover the mechanisms of complex diseases, which is conducive to their diagnosis, treatment, prognosis and prevention. Due to the time consumption and cost of biologically experimental methods, many computational association prediction methods have been proposed in the past few years. In this study, we provide a comprehensive review of machine learning-based approaches for predicting disease-biomolecule associations with multi-view data sources. Firstly, we introduce some databases and general strategies for integrating multi-view data sources in the prediction models. Then we discuss several feature representation methods for machine learning-based prediction models. Thirdly, we comprehensively review machine learning-based prediction approaches in three categories: basic machine learning methods, matrix completion-based methods and deep learning-based methods, while discussing their advantages and disadvantages. Finally, we provide some perspectives for further improving biomolecule-disease prediction methods.
C1 [Ding, Yulian] Univ Saskatchewan, Div Biomed Engn, Saskatoon, SK, Canada.
   [Lei, Xiujuan] Shaanxi Normal Univ, Sch Comp Sci, Xian, Shaanxi, Peoples R China.
   [Liao, Bo] Hainan Normal Univ, Sch Math & Stat, Haikou, Hainan, Peoples R China.
   [Wu, Fang-Xiang] Univ Saskatchewan, Coll Engn, Saskatoon, SK, Canada.
   [Wu, Fang-Xiang] Univ Saskatchewan, Dept Comp Sci, Saskatoon, SK, Canada.
RP Wu, FX (corresponding author), Univ Saskatchewan, Div Biomed Engn, Saskatoon, SK, Canada.
EM faw341@mail.usask.ca
OI Wu, Fang-Xiang/0000-0002-4593-9332
FU theNatural Science and Engineering Research Council of Canada (NSERC),
   China Scholarship Council (CSC); National Natural Science Foundation of
   ChinaNational Natural Science Foundation of China (NSFC) [U19A2064]
FX Thisworkwas supported by theNatural Science and Engineering Research
   Council of Canada (NSERC), China Scholarship Council (CSC) and the
   National Natural Science Foundation of China under Grant No. U19A2064.
NR 138
TC 1
Z9 1
U1 5
U2 9
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 2041-2649
EI 2041-2657
J9 BRIEF FUNCT GENOMICS
JI Brief. Funct. Genomics
PD JUL
PY 2021
VL 20
IS 4
SI SI
BP 273
EP 287
DI 10.1093/bfgp/elab002
EA FEB 2021
PG 15
WC Biotechnology & Applied Microbiology; Genetics & Heredity
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Biotechnology & Applied Microbiology; Genetics & Heredity
GA YH9WG
UT WOS:000743509200009
PM 33554238
DA 2022-04-17
ER

PT C
AU Li, N
   Zong, TX
   Zhang, ZG
AF Li, Na
   Zong, Tianxin
   Zhang, Zhigang
GP IEEE
TI Prediction of the Electronic Work Function by Regression Algorithm in
   Machine Learning
SO 2021 IEEE 6TH INTERNATIONAL CONFERENCE ON BIG DATA ANALYTICS (ICBDA
   2021)
LA English
DT Proceedings Paper
CT IEEE 6th International Conference on Big Data Analytics (ICBDA)
CY MAR 05-08, 2021
CL Xiamen, PEOPLES R CHINA
SP IEEE, Univ Amoiensis, Xian Jiaotong Liverpool Univ, Res Inst Big Data Analyt
DE machine learning; ensemble learning; electronic work function
AB The electronic work function is a simple and basic parameter, which can well connect the properties of materials with their electronic behaviors. Three kinds of elastic modulus are used to predict the electronic work function of pure metals. Different machine learning methods are used to establish regression models, which are based on linear regression, decision tree, ensemble algorithm, support vector machine and neural network. The cross-validation method is used to improve the prediction accuracy and generalization ability, and the fit of the model is evaluated by several indicators. The results show that the fit of ensemble algorithm is better than other machine learning methods. Through this experiment, we can see that the model based on machine learning will not only become an accurate prediction of material properties, but also become a particularly useful tool to accelerate the design of alloy materials.
C1 [Li, Na; Zong, Tianxin; Zhang, Zhigang] Univ Sci & Technol Beijing, Sch Math & Phys, Beijing, Peoples R China.
RP Li, N (corresponding author), Univ Sci & Technol Beijing, Sch Math & Phys, Beijing, Peoples R China.
EM lena@ustb.edu.cn; zongtianxin@foxmail.com; zhangzhigang@sas.ustb.edu.cn
FU University of Science Technology [JG2019ZD05, JG2017Z10]
FX Thanks for the funding of major educational reform project (JG2019ZD05)
   and key educational reform project (JG2017Z10) of University of Science
   & Technology.
NR 12
TC 0
Z9 0
U1 9
U2 14
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
BN 978-1-6654-1513-2
PY 2021
BP 87
EP 91
DI 10.1109/ICBDA51983.2021.9403202
PG 5
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BR8DH
UT WOS:000670939000016
DA 2022-04-17
ER

PT J
AU Carr, P
   Wu, LR
   Zhang, ZB
AF Carr, Peter
   Wu, Liuren
   Zhang, Zhibai
TI USING MACHINE LEARNING TO PREDICT REALIZED VARIANCE
SO JOURNAL OF INVESTMENT MANAGEMENT
LA English
DT Article
DE Volatility Prediction; Machine Learning; Neural Networks; Ridge
   Regression; Option Pricing
ID VOLATILITY; OPTIONS; BOND
AB Volatility index is a portfolio of options and represents market expectation of the underlying security's future realized volatility/variance. Traditionally the index weighting is based on a variance swap pricing formula. In this paper we propose a new method for building volatility index by formulating a variance prediction problem using machine learning. We test algorithms including Ridge regression, Feedforward Neural Networks and Random Forest on S&P 500 Index option data. By conducting a time series validation we show that the new weighting method can achieve higher predictability to future return variance and require fewer options. It is also shown that the weighting method combining the traditional and the machine learning approaches performs the best.
C1 [Carr, Peter; Zhang, Zhibai] NYU, Dept Finance & Risk Engn, Tandon Sch Engn, New York, NY 10003 USA.
   [Wu, Liuren] CUNY, Baruch Coll, Zicklin Sch Business, New York, NY 10021 USA.
RP Zhang, ZB (corresponding author), NYU, Dept Finance & Risk Engn, Tandon Sch Engn, New York, NY 10003 USA.
EM petercarr@nyu.edu; liuren.wu@baruch.cuny.edu; z.zhibai@gmail.com
NR 16
TC 0
Z9 0
U1 4
U2 6
PU JOURNAL INVESTMENT MANAGEMENT
PI LAFAYETTE
PA JOURNAL INVESTMENT MANAGEMENT, LAFAYETTE, CA 00000 USA
SN 1545-9144
EI 1545-9152
J9 J INVEST MANAG
JI J. Invest. Manag.
PY 2020
VL 18
IS 2
BP 57
EP 72
PG 16
WC Business, Finance
WE Emerging Sources Citation Index (ESCI)
SC Business & Economics
GA PO3OU
UT WOS:000605079100005
DA 2022-04-17
ER

PT J
AU Bayliss, C
AF Bayliss, Christopher
TI Machine learning based simulation optimisation for urban routing
   problems
SO APPLIED SOFT COMPUTING
LA English
DT Article
DE Team orienteering problem; Learnheuristic; Traffic simulation; Machine
   learning; Metaheuristics
ID TEAM ORIENTEERING PROBLEM; PARTICLE SWARM OPTIMIZATION; TRAFFIC FLOW;
   EVOLUTIONARY ALGORITHM; VEHICLES
AB Many real world routing problems, including those in tourism and surveillance, can be formulated as team orienteering problems. The goal in such problems is to maximise the rewards collected by a fleet of vehicles whose routes must be completed within a time limit. This work considers a team orienteering problem set within a traffic simulation. In the stochastic environment of a road network, travel times depend on network structure, the demands of road users, driver behaviour and the congestion that arises from these. As a result travel times are difficult to predict. In this work a learnheuristic solution approach is proposed. Learnheuristics integrate machine learning and optimisation for solving combinatorial problems with inherent parameter learning problems-in this case travel times. The machine learning component is used to predict travel times based on data obtained from a limited budget of traffic simulation runs, a budget that is used within the run-time learnheuristic algorithm. In each iteration of the learnheuristic, the optimisation component utilises the travel time predictions of the machine learning algorithm to rapidly generate candidate solutions. The strongest candidate is tested in the traffic simulator, and the results of which are used to train the machine learning component. In a range of test instances, the effectiveness of different combinations of machine learning and optimisation components are tested. Experiments reveal that different combinations of machine learning and optimisation components produce solutions with different characteristics in terms of total reward and reliability. Local search followed by biased randomisation combined with a neural network was found to be effective in multiple instances. The question of how best to use the run-time of a learnheuristic is also addressed. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Bayliss, Christopher] Univ Liverpool, Sch Management, Liverpool L69 7ZH, Merseyside, England.
RP Bayliss, C (corresponding author), Univ Liverpool, Sch Management, Liverpool L69 7ZH, Merseyside, England.
EM Christopher.Bayliss@liverpool.ac.uk
OI bayliss, christopher/0000-0003-0031-5937
FU Erasmus+ programme [2017-1-ES01-KA103-036672]; Spanish Ministry of
   Science, Innovation, and UniversitiesSpanish Government [RED2018102642T]
FX This work has been partially supported by the Erasmus+ programme
   (2017-1-ES01-KA103-036672) and by the Spanish Ministry of Science,
   Innovation, and Universities (RED2018102642T).
NR 55
TC 4
Z9 4
U1 7
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1568-4946
EI 1872-9681
J9 APPL SOFT COMPUT
JI Appl. Soft. Comput.
PD JUL
PY 2021
VL 105
AR 107269
DI 10.1016/j.asoc.2021.107269
EA MAR 2021
PG 17
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA SE0PT
UT WOS:000651778100005
DA 2022-04-17
ER

PT J
AU Ruhe, T
AF Ruhe, Tim
TI Application of machine learning algorithms in imaging Cherenkov and
   neutrino astronomy
SO INTERNATIONAL JOURNAL OF MODERN PHYSICS A
LA English
DT Article
DE Astroparticle physics; machine learning; data mining
ID MAGIC TELESCOPES; NEURAL-NETWORKS; MAJOR UPGRADE; PERFORMANCE;
   SELECTION; DESIGN
AB Over the last decade, machine learning algorithms have become standard analysis tools in astroparticle physics, used by a variety of instruments and for an even larger variety of analyses. While a few characteristic patterns can be observed, the portability of established machine learning-based analysis chains from one experiment to another, remains challenging, as instrument-specific prerequisites and adjustments need to be addressed prior to the application. The use Boosted Decision Trees and other tree-based ensemble methods, has been established, but also recently been challenged by the overall success of Deep Neural Networks. Machine learning has been applied for particle selection and parameter reconstruction, as well as for the extraction of energy spectra. This paper aims at summarizing some of the most common approaches on the application of machine learning in astroparticle physics and at providing brief overview on how they have been applied in practice.
C1 [Ruhe, Tim] Tech Univ Dortmund, Expt Phys 5, Otto Hahn Str 4a, D-44227 Dortmund, Germany.
RP Ruhe, T (corresponding author), Tech Univ Dortmund, Expt Phys 5, Otto Hahn Str 4a, D-44227 Dortmund, Germany.
EM tim.ruhe@tu-dortmund.de
OI Ruhe, Tim/0000-0002-4080-9563
NR 62
TC 1
Z9 1
U1 3
U2 4
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0217-751X
EI 1793-656X
J9 INT J MOD PHYS A
JI Int. J. Mod. Phys. A
PD NOV 30
PY 2020
VL 35
IS 33
AR 2043004
DI 10.1142/S0217751X20430046
PG 19
WC Physics, Nuclear; Physics, Particles & Fields
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Physics
GA PG6XM
UT WOS:000599876300011
DA 2022-04-17
ER

PT C
AU Hariharan, A
   Gupta, A
   Pal, T
AF Hariharan, Ayush
   Gupta, Ankit
   Pal, Trisha
BE Arai, K
   Kapoor, S
   Bhatia, R
TI CAMLPAD: Cybersecurity Autonomous Machine Learning Platform for Anomaly
   Detection
SO ADVANCES IN INFORMATION AND COMMUNICATION, VOL 2
SE Advances in Intelligent Systems and Computing
LA English
DT Proceedings Paper
CT Future of Information and Communication Conference (FICC)
CY MAR 05-06, 2020
CL San Francisco, CA
DE Machine learning; Cybersecurity; Anomaly detection; Clustering;
   Visualization
ID INTRUSION DETECTION; DETECTION FRAMEWORK; SYSTEM
AB As machine learning and cybersecurity continue to explode in the context of the digital ecosystem, the complexity of cybersecurity data combined with complicated and evasive machine learning algorithms leads to vast difficulties in designing an end-to-end system for intelligent, automatic anomaly classification. On the other hand, traditional systems use elementary statistics techniques and are often inaccurate, leading to weak centralized data analysis platforms. In this paper, we propose a novel system that addresses these two problems, titled CAMLPAD, for Cybersecurity Autonomous Machine Learning Platform for Anomaly Detection. The CAMLPAD system's streamlined, holistic approach begins with retrieving a multitude of different species of cybersecurity data in real-time using elasticsearch, then running several machine learning algorithms, namely Isolation Forest, Histogram-Based Outlier Score (HBOS), Cluster-Based Local Outlier Factor (CBLOF), and K-Means Clustering, to process the data. Next, the calculated anomalies are visualized using Kibana and are assigned an outlier score, which serves as an indicator for whether an alert should be sent to the system administrator that there are potential anomalies in the network. After comprehensive testing of our platform in a simulated environment, the CAMLPAD system achieved an adjusted rand score of 95%, exhibiting the reliable accuracy and precision of the system. All in all, the CAMLPAD system provides an accurate, streamlined approach to real-time cybersecurity anomaly detection, delivering a novel solution that has the potential to revolutionize the cybersecurity sector.
C1 [Hariharan, Ayush; Gupta, Ankit; Pal, Trisha] Blue Cloak LLC, Sterling, VA 20164 USA.
RP Hariharan, A (corresponding author), Blue Cloak LLC, Sterling, VA 20164 USA.
EM ahariharan.research@gmail.com
NR 20
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 2194-5357
EI 2194-5365
BN 978-3-030-39442-4; 978-3-030-39441-7
J9 ADV INTELL SYST COMP
PY 2020
VL 1130
BP 705
EP 720
DI 10.1007/978-3-030-39442-4_52
PG 16
WC Computer Science, Artificial Intelligence; Telecommunications
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Telecommunications
GA BR9FM
UT WOS:000675390800052
OA Green Submitted
DA 2022-04-17
ER

PT J
AU Wang, Y
   Qiu, KF
   Muller, A
   Hou, ZL
   Zhu, ZH
   Yu, HC
AF Wang, Yu
   Qiu, Kun-Feng
   Muller, Axel
   Hou, Zhao-Liang
   Zhu, Zhi-Hai
   Yu, Hao-Cheng
TI Machine Learning Prediction of Quartz Forming-Environments
SO JOURNAL OF GEOPHYSICAL RESEARCH-SOLID EARTH
LA English
DT Article
DE machine learning; quartz; trace elements; forming environment indicator;
   classification
ID TRACE-ELEMENT COMPOSITION; LA-ICP-MS; SOUTH CHINA INSIGHTS;
   REMOTE-SENSING DATA; HYDROTHERMAL QUARTZ; EASTERN ERZGEBIRGE; BOHEMIAN
   MASSIF; MO DEPOSIT; CATHODOLUMINESCENCE; CHEMISTRY
AB Trace elements of quartz document the physical-chemical evolutions of quartz growth, which has been a great and most applied tool in the study of geological settings in quartz-forming environments. A classic method is using graphic diagram plots visualizing the quartz trace element discriminations and trends, examples including the Al-Ti diagram (Rusk, 2012, ) and the Ti-Al-Ge diagram (Schron et al., 1988, ). However, those diagrams are limited to two dimensions and cannot show the information in a higher dimension. In the study, we thus used a machine learning-based approach to evaluate quartz trace elements, and visualized them for the first time in the high-dimensional diagrams. We revisited 1,626 quartz samples from nine geological environments from previous studies, and applied a support vector machine to characterize values of the contained trace elements, including Al, Ti, Li, Ge, and Sr. We demonstrate that support vector machines can identify the crystallization environment of quartz with a significantly higher accuracy than the traditional plotting methods. Our work can massively improve the confidence on distinguishing quartz origin from different geological environments with a high efficiency. The method may also be applicable for other minerals, and we anticipate our research is a starting point for investigating mineral trace elements with machine learning techniques. Our quartz classifier can be accessed via .
C1 [Wang, Yu; Qiu, Kun-Feng; Yu, Hao-Cheng] China Univ Geosci, Sch Earth Sci & Resources, State Key Lab Geol Proc & Mineral Resources, Beijing, Peoples R China.
   [Muller, Axel] Univ Oslo, Nat Hist Museum, Oslo, Norway.
   [Muller, Axel] Nat Hist Museum, London, England.
   [Hou, Zhao-Liang] Univ Vienna, Dept Geol, Vienna, Austria.
   [Zhu, Zhi-Hai] Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi, Jiangsu, Peoples R China.
RP Qiu, KF (corresponding author), China Univ Geosci, Sch Earth Sci & Resources, State Key Lab Geol Proc & Mineral Resources, Beijing, Peoples R China.
EM kunfengqiu@qq.com
RI ; Muller, Axel/R-3258-2018
OI Qiu, Kun-Feng/0000-0002-3185-9446; Hou, Zhaoliang/0000-0003-4937-2940;
   Muller, Axel/0000-0002-1650-5762
FU National Key Research Program [2019YFA0708603]; National Natural Science
   FoundationNational Natural Science Foundation of China (NSFC) [91962106,
   42072087, 41702069]; Beijing Nova ProgramBeijing Municipal Science &
   Technology Commission [Z201100006820097]; 111 Project of Ministry of
   Science and Technology of China [BP0719021]; State Key Laboratory of Ore
   Deposit Geochemistry [201704]; European UnionEuropean Commission
   [869274]
FX This study was financially supported by the National Key Research
   Program (2019YFA0708603), the National Natural Science Foundation
   (91962106, 42072087, 41702069), the Beijing Nova Program
   (Z201100006820097), the 111 Project of Ministry of Science and
   Technology of China (BP0719021), the State Key Laboratory of Ore Deposit
   Geochemistry (201704), and the European Union's Horizon 2020 Innovation
   Program (Grant agreement no 869274, project GREENPEG: New Exploration
   Tools for European Pegmatite Green-Tech Resources).
NR 63
TC 5
Z9 5
U1 21
U2 22
PU AMER GEOPHYSICAL UNION
PI WASHINGTON
PA 2000 FLORIDA AVE NW, WASHINGTON, DC 20009 USA
SN 2169-9313
EI 2169-9356
J9 J GEOPHYS RES-SOL EA
JI J. Geophys. Res.-Solid Earth
PD AUG
PY 2021
VL 126
IS 8
AR e2021JB021925
DI 10.1029/2021JB021925
PG 11
WC Geochemistry & Geophysics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Geochemistry & Geophysics
GA UJ0WF
UT WOS:000691015100040
OA Green Published
DA 2022-04-17
ER

PT J
AU Kabathova, J
   Drlik, M
AF Kabathova, Janka
   Drlik, Martin
TI Towards Predicting Student's Dropout in University Courses Using
   Different Machine Learning Techniques
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE learning analytics; educational data mining; machine learning; dropout
   prediction
ID AT-RISK; ANALYTICS
AB Featured Application
   The found model with the best values of the performance metrics, found as the result of comparing several machine learning classifiers, can identify students at risk even though the set of educational data obtained during the course run is scarce. As a result, a suitable form of intervention at the individual e-learning course level can be applied in time.
   Early and precisely predicting the students' dropout based on available educational data belongs to the widespread research topic of the learning analytics research field. Despite the amount of already realized research, the progress is not significant and persists on all educational data levels. Even though various features have already been researched, there is still an open question, which features can be considered appropriate for different machine learning classifiers applied to the typical scarce set of educational data at the e-learning course level. Therefore, the main goal of the research is to emphasize the importance of the data understanding, data gathering phase, stress the limitations of the available datasets of educational data, compare the performance of several machine learning classifiers, and show that also a limited set of features, which are available for teachers in the e-learning course, can predict student's dropout with sufficient accuracy if the performance metrics are thoroughly considered. The data collected from four academic years were analyzed. The features selected in this study proved to be applicable in predicting course completers and non-completers. The prediction accuracy varied between 77 and 93% on unseen data from the next academic year. In addition to the frequently used performance metrics, the comparison of machine learning classifiers homogeneity was analyzed to overcome the impact of the limited size of the dataset on obtained high values of performance metrics. The results showed that several machine learning algorithms could be successfully applied to a scarce dataset of educational data. Simultaneously, classification performance metrics should be thoroughly considered before deciding to deploy the best performance classification model to predict potential dropout cases and design beneficial intervention mechanisms.
C1 [Kabathova, Janka; Drlik, Martin] Constantine Philosopher Univ Nitra, Fac Nat Sci, Dept Informat, Tr A Hlinku 1, Nitra 94901, Slovakia.
RP Drlik, M (corresponding author), Constantine Philosopher Univ Nitra, Fac Nat Sci, Dept Informat, Tr A Hlinku 1, Nitra 94901, Slovakia.
EM janka.kabathova@ukf.sk; mdrlik@ukf.sk
RI Drlik, Martin/A-9130-2012
OI Drlik, Martin/0000-0002-5958-7147; Kabathova, Janka/0000-0002-9225-7449
FU European Commission under the ERASMUS+ Programme 2018, KA2
   [2018-1-SK01-KA203-046382]; Cultural and Educational Agency of the
   Ministry of Education of the Slovak Republic [KEGA029UKF-4/2018]
FX This research was funded by the European Commission under the ERASMUS+
   Programme 2018, KA2, grant number: 2018-1-SK01-KA203-046382 "Work-Based
   Learning in Future IT Professionals Education" and the Cultural and
   Educational Agency of the Ministry of Education of the Slovak Republic,
   grant number: KEGA029UKF-4/2018 "Innovative Methods in Programming
   Education in the University Education of Teachers and IT Professionals".
NR 39
TC 5
Z9 5
U1 15
U2 26
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD APR
PY 2021
VL 11
IS 7
AR 3130
DI 10.3390/app11073130
PG 19
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Chemistry; Engineering; Materials Science; Physics
GA RK5GI
UT WOS:000638324200001
OA gold
DA 2022-04-17
ER

PT C
AU Nevils, W
   Jonas, B
   LaPorte, G
   DiGiovanni, AA
AF Nevils, William
   Jonas, Bryan
   LaPorte, Grover
   DiGiovanni, Anthony A.
BE Pham, T
   Solomon, L
TI Robust machine learning algorithms for image segmentation in biphasic
   ceramics
SO ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING FOR MULTI-DOMAIN OPERATIONS
   APPLICATIONS III
SE Proceedings of SPIE
LA English
DT Proceedings Paper
CT Conference on Artificial Intelligence and Machine Learning for
   Multi-Domain Operations Applications III
CY APR 12-16, 2021
CL ELECTR NETWORK
SP SPIE
DE Artificial Noise; Image Segmentation; U-Net; Machine Learning; Materials
   Science
AB Historically, the development of armor ceramics can be largely described as heuristic. Recently, advanced machine learning algorithms are being developed to accelerate advanced material discovery. As many important material properties depend on microstructure, segmentation algorithms applied to scanning electron microscope (SEM) images enable quantification of identified features. The desired goal is to relate key image metrics to quantified physical properties and make useful performance predictions and improvements faster than otherwise possible. Collecting large image datasets with high signal to noise ratio, even with automation, can be laborious. Moreover, traditional methods of establishing image ground truth often rely on supervised hand-tracing, which precludes application to 1000's of images. This study creates an approximate ground truth automatically using Otsu's algorithm to evaluate large image data sets with varying signal to noise ratio and understand the influence of noise on network model efficiency. The robustness of a U-net algorithm, commonly used for image segmentation, was optimized by introducing artificial noise to the training data. Initial work assessed the performance of generative adversarial networks in applying artificial noise to the images. Next, a U-net was generated while incorporating artificial and real noise into the training and validation sets respectively. The impact of training using artificial noise upon the accuracy of the resulting U-Net in segmenting real images of low quality are described below.
C1 [Nevils, William; Jonas, Bryan; LaPorte, Grover] US Mil Acad, West Point, NY 10996 USA.
   [DiGiovanni, Anthony A.] US Army, DEVCOM, Res Lab, Adelphi, MD USA.
RP Nevils, W (corresponding author), US Mil Acad, West Point, NY 10996 USA.
NR 16
TC 0
Z9 0
U1 1
U2 1
PU SPIE-INT SOC OPTICAL ENGINEERING
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA
SN 0277-786X
EI 1996-756X
BN 978-1-5106-4330-7
J9 PROC SPIE
PY 2021
VL 11746
AR 117462C
DI 10.1117/12.2585769
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA BS2PQ
UT WOS:000705912400056
DA 2022-04-17
ER

PT J
AU Veeragandham, S
   Santhi, H
AF Veeragandham, Syamasudha
   Santhi, H.
TI A REVIEW ON THE ROLE OF MACHINE LEARNING IN AGRICULTURE
SO SCALABLE COMPUTING-PRACTICE AND EXPERIENCE
LA English
DT Review
DE Machine Learning; Agriculture; Data Analysis; Training Methods and
   Sensors
AB Machine learning is a promising domain which is widely used now a days in the field of agriculture. The availability of manpower for agriculture is not enough and skill full farmers are less. Understanding the situation of the crop is not that much easy to detect and prevent the diseases in the crop. It is also widely employed in various agricultural fields such as topsoil management, yield management, water management, disease management and climate conditions. The machine learning models facilitate very fast and optimal decisions. The model of machine learning involves with training and testing to predict the accuracy of the result. The use of machine learning in agriculture helps to increase the productivity and better management on soil classification, disease detection, species management, water management, yield prediction, crop quality and weed detection. This article aims at providing detailed information on various machine learning approaches proposed in the past five years by emphasizing the advantage and disadvantages. It also compares different machine learning algorithms used in the modern agricultural field.
C1 [Veeragandham, Syamasudha; Santhi, H.] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
RP Santhi, H (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
EM syamasudha.veera2019@vitstudent.ac.in; hsanthi@vit.ac.in
OI veeragandham, syamasudha/0000-0001-7741-3143
NR 27
TC 0
Z9 0
U1 8
U2 14
PU UNIV VEST TIMISOARA, WEST UNIV TIMISOARA
PI TIMISOARA
PA BLVD VASILE PARVAN 4, TIMISOARA, TIMIS 300223, ROMANIA
SN 1895-1767
J9 SCALABLE COMPUT-PRAC
JI Scalable Comput.-Pract. Exp.
PD DEC
PY 2020
VL 21
IS 4
SI SI
BP 583
EP 589
DI 10.12694/scpe.v21i4.1699
PG 7
WC Computer Science, Software Engineering
WE Emerging Sources Citation Index (ESCI)
SC Computer Science
GA PH4ZJ
UT WOS:000600422400002
OA gold
DA 2022-04-17
ER

PT J
AU Zhang, X
   Liu, L
   Xiao, LZ
   Ji, JK
AF Zhang, Xu
   Liu, Lin
   Xiao, Luzi
   Ji, Jiakai
TI Comparison of Machine Learning Algorithms for Predicting Crime Hotspots
SO IEEE ACCESS
LA English
DT Article
DE Prediction of crime hotspots; machine learning; LSTM; built environment
ID CLASSIFIER; TRENDS; MODEL
AB Crime prediction is of great significance to the formulation of policing strategies and the implementation of crime prevention and control. Machine learning is the current mainstream prediction method. However, few studies have systematically compared different machine learning methods for crime prediction. This paper takes the historical data of public property crime from 2015 to 2018 from a section of a large coastal city in the southeast of China as research data to assess the predictive power between several machine learning algorithms. Results based on the historical crime data alone suggest that the LSTM model outperformed KNN, random forest, support vector machine, naive Bayes, and convolutional neural networks. In addition, the built environment data of points of interests (POIs) and urban road network density are input into LSTM model as covariates. It is found that the model with built environment covariates has better prediction effect compared with the original model that is based on historical crime data alone. Therefore, future crime prediction should take advantage of both historical crime data and covariates associated with criminological theories. Not all machine learning algorithms are equally effective in crime prediction.
C1 [Zhang, Xu] Guangzhou Univ, Sch Comp Sci & Cyber Engn, Guangzhou 510006, Peoples R China.
   [Zhang, Xu; Liu, Lin; Xiao, Luzi] Guangzhou Univ, Ctr Geoinformat Publ Secur, Sch Geog Sci, Guangzhou 510006, Peoples R China.
   [Liu, Lin] Univ Cincinnati, Dept Geog, Cincinnati, OH 45221 USA.
   [Ji, Jiakai] Sun Yat Sen Univ, Sch Geog & Planning, Guangzhou 510275, Peoples R China.
RP Liu, L (corresponding author), Guangzhou Univ, Ctr Geoinformat Publ Secur, Sch Geog Sci, Guangzhou 510006, Peoples R China.; Liu, L (corresponding author), Univ Cincinnati, Dept Geog, Cincinnati, OH 45221 USA.
EM lin.liu@uc.edu
OI Zhang, Xu/0000-0001-9364-0418
FU Research Team Program of Natural Science Foundation of Guangdong
   Province, China [2014A030312010]; National Key Research and Development
   Program of China [2018YFB0505500, 2018YFB0505503]; Key Program of
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41531178]; Technology Program of Guangzhou
   City, China [201804020016]; Key Project of Science
FX This work was supported in part by the Research Team Program of Natural
   Science Foundation of Guangdong Province, China, under Grant
   2014A030312010, in part by the National Key Research and Development
   Program of China under Grant 2018YFB0505500 and Grant 2018YFB0505503, in
   part by the Key Program of National Natural Science Foundation of China
   under Grant 41531178, and in part by the Key Project of Science and in
   part by Technology Program of Guangzhou City, China, under Grant
   201804020016.
NR 44
TC 5
Z9 5
U1 6
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 181302
EP 181310
DI 10.1109/ACCESS.2020.3028420
PG 9
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Telecommunications
GA OA7XE
UT WOS:000577993300001
OA gold
DA 2022-04-17
ER

PT C
AU Mojrian, S
   Pinter, G
   Joloudari, JH
   Felde, I
   Szabo-Gali, A
   Nadai, L
   Mosavi, A
AF Mojrian, Sanaz
   Pinter, Gergo
   Joloudari, Javad Hassannataj
   Felde, Imre
   Szabo-Gali, Akos
   Nadai, Laszlo
   Mosavi, Amir
GP IEEE
TI Hybrid Machine Learning Model of Extreme Learning Machine Radial basis
   function for Breast Cancer Detection and Diagnosis; a Multilayer Fuzzy
   Expert System
SO 2020 RIVF INTERNATIONAL CONFERENCE ON COMPUTING & COMMUNICATION
   TECHNOLOGIES (RIVF 2020)
SE IEEE RIVF International Conference on Computing and Communication
   Technologies Research Innovation and Vision for the Future
LA English
DT Proceedings Paper
CT RIVF International Conference on Computing and Communication
   Technologies (RIVF)
CY OCT 14-15, 2020
CL RMIT University, Ho Chi Minh City, VIETNAM
SP IEEE Vietnam Sect
HO RMIT University
DE hybrid machine learning; extreme learning machine (ELM); radial basis
   function (RBF); breast cancer; support vector machine (SVM)
ID IDENTIFICATION; PREDICTION; DISEASE; ERROR
AB Mammography is often used as the most common laboratory method for the detection of breast cancer, yet associated with the high cost and many side effects. Machine learning prediction as an alternative method has shown promising results. This paper presents a method based on a multilayer fuzzy expert system for the detection of breast cancer using an extreme learning machine (ELM) classification model integrated with radial basis function (RBF) kernel called ELM-RBF, considering the Wisconsin dataset. The performance of the proposed model is further compared with a linear-SVM model. The proposed model outperforms the linear-SVM model with RMSE, R-2, MAPE equal to 0.1719, 0.9374 and 0.0539, respectively. Furthermore, both models are studied in terms of criteria of accuracy, precision, sensitivity, specificity, validation, true positive rate (TPR), and false-negative rate (FNR). The ELM-RBF model for these criteria presents better performance compared to the SVM model.
C1 [Mojrian, Sanaz] Univ Sci & Technol, Dept Informat Technol Mazandaran, Babol, Iran.
   [Pinter, Gergo; Szabo-Gali, Akos] Obuda Univ, John von Neumann Fac Informat, Budapest, Hungary.
   [Joloudari, Javad Hassannataj] Univ Birjand, Elect & Comp Engn Fac, Birjand, Iran.
   [Felde, Imre; Nadai, Laszlo] Obuda Univ, Kalman Kando Fac Elect Engn, Budapest, Hungary.
   [Mosavi, Amir] J Selye Univ, Dept Math & Informat, Komamo, Slovakia.
   [Mosavi, Amir] Bauhaus Univ Weimar, Weimar, Germany.
RP Mosavi, A (corresponding author), J Selye Univ, Dept Math & Informat, Komamo, Slovakia.; Mosavi, A (corresponding author), Bauhaus Univ Weimar, Weimar, Germany.
RI Mosavi, Amir/I-7440-2018; Joloudari, Javad Hassannataj/AAW-2357-2020
OI Mosavi, Amir/0000-0003-4842-0613; Joloudari, Javad
   Hassannataj/0000-0001-9374-2326
FU Hungarian State; European UnionEuropean Commission
   [EFOP-3.6.1-16-2016-00010, 2017-1.3.1-VKE-2017-00025]
FX We acknowledge the financial support of this work by the Hungarian State
   and the European Union under the EFOP-3.6.1-16-2016-00010 project and
   the 2017-1.3.1-VKE-2017-00025 project.
NR 48
TC 2
Z9 2
U1 0
U2 0
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 2162-786X
BN 978-1-7281-5377-3
J9 IEEE RIVF INT CONF
PY 2020
BP 116
EP 122
PG 7
WC Computer Science, Interdisciplinary Applications; Engineering,
   Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA BR3QJ
UT WOS:000648838400021
DA 2022-04-17
ER

PT C
AU Xie, J
   Alvarez-Fernandez, I
   Sun, W
AF Xie, Jian
   Alvarez-Fernandez, Inalvis
   Sun, Wei
GP IEEE
TI A Review of Machine Learning Applications in Power System Resilience
SO 2020 IEEE POWER & ENERGY SOCIETY GENERAL MEETING (PESGM)
SE IEEE Power and Energy Society General Meeting PESGM
LA English
DT Proceedings Paper
CT IEEE-Power-and-Energy-Society General Meeting (PESGM)
CY AUG 03-06, 2020
CL ELECTR NETWORK
SP IEEE Power & Energy Soc
DE Deep Learning; Machine Learning; Power System Control; Resilience;
   Restoration
ID PREDICTION; EXTREME
AB The integration of power electronics enabled devices and the high penetration of renewable energy drastically increase the complexity of power system operation and control. Power systems are still vulnerable to large-scale blackouts caused by extreme natural events or man-made attacks. With the recent development in artificial intelligence technique, machine learning has shown a processing ability in computational, perceptual and cognitive intelligence. It is an urgent challenge to integrate the advanced machine learning technology and large amount of real-time data from wide area measurement systems and intelligent electronic devices, in order to effectively enhance power system resilience and ensure the reliable and secure operation of power systems. Therefore, this paper aims to systematically review the existing application of machine learning methods on power system resilience enhancement, to expand the interest of researchers and scholars in this topic, and to jointly promote the application of artificial intelligence in the field of power systems.
C1 [Xie, Jian; Alvarez-Fernandez, Inalvis; Sun, Wei] Univ Cent Florida, Dept Elect & Comp Engn, Orlando, FL 32816 USA.
RP Xie, J (corresponding author), Univ Cent Florida, Dept Elect & Comp Engn, Orlando, FL 32816 USA.
EM jianxie@knights.ucf.edu; AlvarezFernandez@knights.ucf.edu; sun@ucf.edu
NR 30
TC 5
Z9 5
U1 2
U2 2
PU IEEE
PI NEW YORK
PA 345 E 47TH ST, NEW YORK, NY 10017 USA
SN 1944-9925
BN 978-1-7281-5508-1
J9 IEEE POW ENER SOC GE
PY 2020
PG 5
WC Energy & Fuels; Engineering, Electrical & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Energy & Fuels; Engineering
GA BR9OU
UT WOS:000679246603050
DA 2022-04-17
ER

PT J
AU Shukla, PK
   Shukla, PK
   Bhatele, M
   Chaturvedi, AK
   Sharma, P
   Rizvi, MA
   Pathak, Y
AF Shukla, Prashant Kumar
   Shukla, Piyush Kumar
   Bhatele, Mukta
   Chaturvedi, Anoop Kumar
   Sharma, Poonam
   Rizvi, Murtaza Abbas
   Pathak, Yadunath
TI A Novel Machine Learning Model to Predict the Staying Time of
   International Migrants
SO INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS
LA English
DT Article
DE Staying time; international migrants; PSO; SVM; machine learning
ID SUPPORT VECTOR MACHINES; NEURAL-NETWORKS; CLASSIFICATION; OPTIMIZATION;
   MIGRATION; CUBE
AB In this paper, a novel machine learning model is proposed to predict the staying time of international migrants. The competitive machine learning approaches which can be used to predict the staying time of international migrants suffer from hyper-attributes tuning and over-fitting issues. Therefore, a particle swarm optimization (PSO) based support vector machine (SVM) model is proposed to predict the staying time of international migrants. Extensive experiments are performed by considering the international migrants dataset to predict the staying time of international migrants. Experimental results illustrate that the proposed approach outperforms the existing machine learning approaches in terms of f-measure, accuracy, specificity, and sensitivity.
C1 [Shukla, Prashant Kumar] Jagran Lake City Univ JLU, Sch Engn & Technol, Dept Comp Sci & Engn, Bhopal, MP, India.
   [Shukla, Piyush Kumar] Univ Inst Technol RGPV, Dept Comp Sci & Engn, Bhopal, MP, India.
   [Bhatele, Mukta] Oriental Inst Sci & Technol, Jabalpur, MP, India.
   [Chaturvedi, Anoop Kumar] Lakshmi Narain Coll Technol, Comp Sci & Engn, Bhopal, Madhya Pradesh, India.
   [Sharma, Poonam] Visvesvaraya Natl Inst Technol, Dept Comp Sci & Engn, Nagpur, Maharashtra, India.
   [Rizvi, Murtaza Abbas] NITTTR, Dept Comp Engn & Applicat, Bhopal, MP, India.
   [Pathak, Yadunath] Indian Inst Informat Technol, Dept Informat Technol, Bhopal, India.
RP Pathak, Y (corresponding author), Indian Inst Informat Technol, Dept Informat Technol, Bhopal, India.
EM yadupathak86@gmail.com
RI PATHAK, YADUNATH/AFR-0689-2022
OI PATHAK, YADUNATH/0000-0002-4062-7858
NR 50
TC 0
Z9 0
U1 9
U2 13
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-2130
EI 1793-6349
J9 INT J ARTIF INTELL T
JI Int. J. Artif. Intell. Tools
PD MAR
PY 2021
VL 30
IS 2
AR 2150002
DI 10.1142/S0218213021500020
PG 16
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA RF6HC
UT WOS:000634941800002
DA 2022-04-17
ER

PT C
AU Meinke, K
AF Meinke, Karl
GP IEEE Comp Soc
TI Active Machine Learning to Test Autonomous Driving
SO 2021 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE TESTING, VERIFICATION AND
   VALIDATION WORKSHOPS (ICSTW 2021)
SE IEEE International Conference on Software Testing Verification and
   Validation Workshops
LA English
DT Proceedings Paper
CT 14th IEEE Conference on Software Testing, Verification and Validation
   (ICST)
CY APR 12-16, 2021
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, Opus Software, CESAR Sch, Facebook
DE autonomous driving; machine learning; synthetic data; system testing
AB Autonomous driving represents a significant challenge to all software quality assurance techniques, including testing. Generative machine learning (ML) techniques including active ML have considerable potential to generate high quality synthetic test data that can complement and improve on existing techniques such as hardware-in-the-loop and road testing.
C1 [Meinke, Karl] KTH Royal Inst Technol, Sch Elect Engn & Comp Sci, S-10044 Stockholm, Sweden.
RP Meinke, K (corresponding author), KTH Royal Inst Technol, Sch Elect Engn & Comp Sci, S-10044 Stockholm, Sweden.
EM karlm@kth.se
NR 5
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
SN 2159-4848
BN 978-1-6654-4456-9
J9 IEEE ICST WORKSHOP
PY 2021
BP 286
EP 286
DI 10.1109/ICSTW52544.2021.00055
PG 1
WC Computer Science, Software Engineering
WE Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA BS0BO
UT WOS:000680833800042
DA 2022-04-17
ER

EF